{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from neuralnilm.data.loadactivations import load_nilmtk_activations\n",
    "from neuralnilm.data.syntheticaggregatesource import SyntheticAggregateSource\n",
    "from neuralnilm.data.datapipeline import DataPipeline\n",
    "from neuralnilm.data.processing import DivideBy, IndependentlyCenter\n",
    "from neuralnilm.data.datathread import DataThread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NILMTK_FILENAME = '/data/mine/vadeec/merged/ukdale.h5'\n",
    "TARGET_APPLIANCE = 'kettle'\n",
    "SEQ_LENGTH = 256\n",
    "SAMPLE_PERIOD = 6\n",
    "STRIDE = SEQ_LENGTH\n",
    "WINDOWS = {\n",
    "    'train': {\n",
    "        1: (\"2014-01-01\", \"2014-02-01\")\n",
    "    },\n",
    "    'unseen_activations_of_seen_appliances': {\n",
    "        1: (\"2014-02-02\", \"2014-02-08\")                \n",
    "    },\n",
    "    'unseen_appliances': {\n",
    "        2: (\"2013-06-01\", \"2013-06-07\")\n",
    "    }\n",
    "}\n",
    "\n",
    "LOADER_CONFIG = {\n",
    "    'nilmtk_activations': dict(\n",
    "        appliances=['kettle', 'microwave', 'washing machine'],\n",
    "        filename=NILMTK_FILENAME,\n",
    "        sample_period=SAMPLE_PERIOD,\n",
    "        windows=WINDOWS\n",
    "    )\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from neuralnilm.data.stridesource import StrideSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.data.stridesource:Loading NILMTK data...\n",
      "INFO:neuralnilm.data.stridesource:Loading data for UK-DALE_building_1...\n",
      "INFO:neuralnilm.data.stridesource:Loaded data from building UK-DALE_building_1 for fold train from 2014-01-01 00:00:06+00:00 to 2014-01-31 23:59:54+00:00.\n",
      "INFO:neuralnilm.data.stridesource:Loading data for UK-DALE_building_2...\n",
      "INFO:neuralnilm.data.stridesource:Loaded data from building UK-DALE_building_2 for fold unseen_appliances from 2013-06-01 00:00:00+01:00 to 2013-06-06 23:59:54+01:00.\n",
      "INFO:neuralnilm.data.stridesource:Loading data for UK-DALE_building_1...\n",
      "INFO:neuralnilm.data.stridesource:Loaded data from building UK-DALE_building_1 for fold unseen_activations_of_seen_appliances from 2014-02-02 00:00:00+00:00 to 2014-02-07 23:59:54+00:00.\n",
      "INFO:neuralnilm.data.stridesource:Done loading NILMTK mains data.\n"
     ]
    }
   ],
   "source": [
    "stride_source = StrideSource(\n",
    "    target_appliance=TARGET_APPLIANCE,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    filename=NILMTK_FILENAME,\n",
    "    windows=WINDOWS,\n",
    "    sample_period=SAMPLE_PERIOD,\n",
    "    stride=STRIDE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.data.loadactivations:Loading NILMTK activations...\n",
      "INFO:neuralnilm.data.loadactivations:Loading kettle for UK-DALE_building_1...\n",
      "INFO:neuralnilm.data.loadactivations:Loaded 111 kettle activations from UK-DALE_building_1.\n",
      "INFO:neuralnilm.data.loadactivations:Loading microwave for UK-DALE_building_1...\n",
      "INFO:neuralnilm.data.loadactivations:Loaded 119 microwave activations from UK-DALE_building_1.\n",
      "INFO:neuralnilm.data.loadactivations:Loading washing machine for UK-DALE_building_1...\n",
      "INFO:neuralnilm.data.loadactivations:Loaded 23 washing machine activations from UK-DALE_building_1.\n",
      "INFO:neuralnilm.data.loadactivations:Loading kettle for UK-DALE_building_2...\n",
      "INFO:neuralnilm.data.loadactivations:Loaded 31 kettle activations from UK-DALE_building_2.\n",
      "INFO:neuralnilm.data.loadactivations:Loading microwave for UK-DALE_building_2...\n",
      "INFO:neuralnilm.data.loadactivations:Loaded 30 microwave activations from UK-DALE_building_2.\n",
      "INFO:neuralnilm.data.loadactivations:Loading washing machine for UK-DALE_building_2...\n",
      "INFO:neuralnilm.data.loadactivations:Loaded 2 washing machine activations from UK-DALE_building_2.\n",
      "INFO:neuralnilm.data.loadactivations:Loading kettle for UK-DALE_building_1...\n",
      "INFO:neuralnilm.data.loadactivations:Loaded 28 kettle activations from UK-DALE_building_1.\n",
      "INFO:neuralnilm.data.loadactivations:Loading microwave for UK-DALE_building_1...\n",
      "INFO:neuralnilm.data.loadactivations:Loaded 28 microwave activations from UK-DALE_building_1.\n",
      "INFO:neuralnilm.data.loadactivations:Loading washing machine for UK-DALE_building_1...\n",
      "INFO:neuralnilm.data.loadactivations:Loaded 5 washing machine activations from UK-DALE_building_1.\n",
      "INFO:neuralnilm.data.loadactivations:Done loading NILMTK activations.\n"
     ]
    }
   ],
   "source": [
    "nilmtk_activations = load_nilmtk_activations(**LOADER_CONFIG['nilmtk_activations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train', 'unseen_activations_of_seen_appliances', 'unseen_appliances']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nilmtk_activations.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from neuralnilm.data.realaggregatesource import RealAggregateSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.data.realaggregatesource:Loading NILMTK mains...\n",
      "INFO:neuralnilm.data.realaggregatesource:Loading mains for UK-DALE_building_1...\n",
      "INFO:neuralnilm.data.realaggregatesource:Loaded mains data from building UK-DALE_building_1 for fold train from 2014-01-01 00:00:00+00:00 to 2014-01-31 23:59:54+00:00.\n",
      "INFO:neuralnilm.data.realaggregatesource:Loading mains for UK-DALE_building_2...\n",
      "INFO:neuralnilm.data.realaggregatesource:Loaded mains data from building UK-DALE_building_2 for fold unseen_appliances from 2013-06-01 00:00:00+01:00 to 2013-06-06 23:59:54+01:00.\n",
      "INFO:neuralnilm.data.realaggregatesource:Loading mains for UK-DALE_building_1...\n",
      "INFO:neuralnilm.data.realaggregatesource:Loaded mains data from building UK-DALE_building_1 for fold unseen_activations_of_seen_appliances from 2014-02-02 00:00:00+00:00 to 2014-02-07 23:59:54+00:00.\n",
      "INFO:neuralnilm.data.realaggregatesource:Done loading NILMTK mains data.\n",
      "INFO:neuralnilm.data.realaggregatesource:Found 89 sections without target for train UK-DALE_building_1.\n",
      "INFO:neuralnilm.data.realaggregatesource:Found 20 sections without target for unseen_activations_of_seen_appliances UK-DALE_building_1.\n",
      "INFO:neuralnilm.data.realaggregatesource:Found 24 sections without target for unseen_appliances UK-DALE_building_2.\n"
     ]
    }
   ],
   "source": [
    "ras = RealAggregateSource(\n",
    "    activations=nilmtk_activations,\n",
    "    target_appliance=TARGET_APPLIANCE,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    filename=NILMTK_FILENAME,\n",
    "    windows=WINDOWS,\n",
    "    sample_period=SAMPLE_PERIOD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ras.target_inclusion_prob = 0.5\n",
    "for i in range(50):\n",
    "    seq = ras.get_sequence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fig, axes = plt.subplots(2)\n",
    "#axes[0].plot(seq.input)\n",
    "#axes[1].plot(seq.target)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name', 'building', 'appliance', 'fold']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nilmtk_activations['train']['kettle']['UK-DALE_building_1'][0]._metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source = SyntheticAggregateSource(\n",
    "    activations=nilmtk_activations,\n",
    "    target_appliance=TARGET_APPLIANCE,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    allow_incomplete_target=False,\n",
    "    sample_period=SAMPLE_PERIOD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FOLD = 'train'\n",
    "#FOLD = 'unseen_activations_of_seen_appliances'\n",
    "#FOLD = 'unseen_appliances'\n",
    "seq = source.get_sequence(enable_all_appliances=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#all(seq.all_appliances.sum(axis=1) == seq.input[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fig, axes = plt.subplots(2, sharex=True)\n",
    "#seq.all_appliances.plot(ax=axes[0])\n",
    "#axes[1].plot(seq.input)\n",
    "#fig.suptitle(FOLD)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = source.get_batch(num_seq_per_batch=1024).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = DataPipeline(\n",
    "    sources=[source, ras, stride_source],\n",
    "    num_seq_per_batch=64,\n",
    "    input_processing=[DivideBy(sample.before_processing.input.flatten().std()), IndependentlyCenter()],\n",
    "    target_processing=[DivideBy(sample.before_processing.target.flatten().std())]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disaggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "nilmtk_disag_source = NILMTKDisagSource(\n",
    "    filename=NILMTK_FILENAME,\n",
    "    target_appliance=TARGET_APPLIANCE,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    buildings=[5],\n",
    "    window_per_building={},\n",
    "    stride=STRIDE,\n",
    "    sample_period=SAMPLE_PERIOD\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "disag_pipeline = deepcopy(pipeline)\n",
    "disag_pipeline.source = nilmtk_disag_source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "disaggregator = Disaggregator(\n",
    "    pipeline=disag_pipeline,\n",
    "    output_path=PATH  # \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disagregator ideas:\n",
    "\n",
    "* make a copy of pipeline but swap source for a NILMTKDisagSource\n",
    "* NILMTKDisagSource loads all data into memory (?) and iterates over chunks of it (get seq_length from pipeline.source.seq_length)\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lasagne.layers import InputLayer, RecurrentLayer, DenseLayer, ReshapeLayer\n",
    "\n",
    "def get_net_0(input_shape, target_shape=None):\n",
    "    NUM_UNITS = {\n",
    "        'dense_layer_0': 100,\n",
    "        'dense_layer_1':  50,\n",
    "        'dense_layer_2': 100\n",
    "    }\n",
    "\n",
    "    if target_shape is None:\n",
    "        target_shape = input_shape\n",
    "    \n",
    "    # Define layers\n",
    "    input_layer = InputLayer(\n",
    "        shape=input_shape\n",
    "    )\n",
    "    \n",
    "    # Dense layers\n",
    "    dense_layer_0 = DenseLayer(\n",
    "        input_layer, \n",
    "        num_units=NUM_UNITS['dense_layer_0']\n",
    "    )\n",
    "    dense_layer_1 = DenseLayer(\n",
    "        dense_layer_0, \n",
    "        num_units=NUM_UNITS['dense_layer_1']\n",
    "    )\n",
    "    dense_layer_2 = DenseLayer(\n",
    "        dense_layer_1, \n",
    "        num_units=NUM_UNITS['dense_layer_2']\n",
    "    )\n",
    "    \n",
    "    # Output\n",
    "    final_dense_layer = DenseLayer(\n",
    "        dense_layer_2,\n",
    "        num_units=target_shape[1] * target_shape[2],\n",
    "        nonlinearity=None\n",
    "    )\n",
    "    output_layer = ReshapeLayer(\n",
    "        final_dense_layer,\n",
    "        shape=target_shape\n",
    "    )\n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from neuralnilm.net import Net\n",
    "\n",
    "batch = pipeline.get_batch()\n",
    "output_layer = get_net_0(\n",
    "    batch.after_processing.input.shape, \n",
    "    batch.after_processing.target.shape\n",
    ")\n",
    "net = Net(output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neuralnilm.trainer import Trainer\n",
    "from neuralnilm.metrics import Metrics\n",
    "\n",
    "trainer = Trainer(\n",
    "    net=net,\n",
    "    data_pipeline=pipeline,\n",
    "    experiment_id=[\"4\"],\n",
    "    metrics=Metrics(state_boundaries=[4]),\n",
    "    requested_learning_rates={0: 1E-2},\n",
    "    repeat_callbacks=[\n",
    "        (1000, Trainer.save_params),\n",
    "        (1000, Trainer.plot_estimates),\n",
    "        ( 500, Trainer.validate)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '4',\n",
       " 'data': {'activations': {'nilmtk_activations': {'appliances': ['kettle',\n",
       "     'microwave',\n",
       "     'washing machine'],\n",
       "    'filename': '/data/mine/vadeec/merged/ukdale.h5',\n",
       "    'sample_period': 6,\n",
       "    'windows': {'train': {'1': ('2014-01-01', '2014-02-01')},\n",
       "     'unseen_activations_of_seen_appliances': {'1': ('2014-02-02',\n",
       "       '2014-02-08')},\n",
       "     'unseen_appliances': {'2': ('2013-06-01', '2013-06-07')}}}},\n",
       "  'pipeline': {'input_processing': [{'divisor': 610.2794799804688,\n",
       "     'name': 'DivideBy'},\n",
       "    {'name': 'IndependentlyCenter'}],\n",
       "   'num_seq_per_batch': 64,\n",
       "   'rng_seed': None,\n",
       "   'source_probabilities': [0.3333333333333333,\n",
       "    0.3333333333333333,\n",
       "    0.3333333333333333],\n",
       "   'sources': {'0': {'allow_incomplete_distractors': True,\n",
       "     'allow_incomplete_target': False,\n",
       "     'distractor_inclusion_prob': 0.25,\n",
       "     'include_incomplete_target_in_output': True,\n",
       "     'name': 'SyntheticAggregateSource',\n",
       "     'num_batches_for_validation': 16,\n",
       "     'rng_seed': None,\n",
       "     'sample_period': 6,\n",
       "     'seq_length': 256,\n",
       "     'target_appliance': 'kettle',\n",
       "     'target_inclusion_prob': 0.5,\n",
       "     'uniform_prob_of_selecting_each_building': True},\n",
       "    '1': {'allow_incomplete_target': True,\n",
       "     'allow_multiple_target_activations_in_aggregate': False,\n",
       "     'filename': '/data/mine/vadeec/merged/ukdale.h5',\n",
       "     'include_incomplete_target_in_output': True,\n",
       "     'include_multiple_targets_in_output': False,\n",
       "     'name': 'RealAggregateSource',\n",
       "     'num_batches_for_validation': 16,\n",
       "     'rng_seed': None,\n",
       "     'sample_period': 6,\n",
       "     'seq_length': 256,\n",
       "     'target_appliance': 'kettle',\n",
       "     'target_inclusion_prob': 0.5,\n",
       "     'uniform_prob_of_selecting_each_building': True,\n",
       "     'windows': {'train': {'1': ('2014-01-01', '2014-02-01')},\n",
       "      'unseen_activations_of_seen_appliances': {'1': ('2014-02-02',\n",
       "        '2014-02-08')},\n",
       "      'unseen_appliances': {'2': ('2013-06-01', '2013-06-07')}}},\n",
       "    '2': {'filename': '/data/mine/vadeec/merged/ukdale.h5',\n",
       "     'name': 'StrideSource',\n",
       "     'num_batches_for_validation': None,\n",
       "     'rng_seed': None,\n",
       "     'sample_period': 6,\n",
       "     'seq_length': 256,\n",
       "     'stride': 256,\n",
       "     'target_appliance': 'kettle',\n",
       "     'windows': {'train': {'1': ('2014-01-01', '2014-02-01')},\n",
       "      'unseen_activations_of_seen_appliances': {'1': ('2014-02-02',\n",
       "        '2014-02-08')},\n",
       "      'unseen_appliances': {'2': ('2013-06-01', '2013-06-07')}}}},\n",
       "   'target_processing': [{'divisor': 453.3784484863281, 'name': 'DivideBy'}]}},\n",
       " 'trainer': {'loss_aggregation_mode': 'mean',\n",
       "  'loss_func_name': 'squared_error',\n",
       "  'metrics': {'clip_to_zero': False,\n",
       "   'name': 'Metrics',\n",
       "   'state_boundaries': [4]},\n",
       "  'min_train_cost': inf,\n",
       "  'output_path': '/home/dk3810/temp/neural_nilm/output/4',\n",
       "  'requested_learning_rates': {'0': 0.01},\n",
       "  'updates_func_kwards': {},\n",
       "  'updates_func_name': 'nesterov_momentum'}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = trainer.report()\n",
    "report['data']['activations'] = LOADER_CONFIG\n",
    "from neuralnilm.utils import sanitise_dict_for_mongo\n",
    "sanitise_dict_for_mongo(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Starting training for 50000 iterations.\n",
      "INFO:neuralnilm.trainer:Iteration 0: Change learning rate to 1.0E-02\n",
      "INFO:neuralnilm.trainer:Compiling train cost function...\n",
      "INFO:neuralnilm.trainer:Done compiling cost function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Update # |  Train cost  | Secs per update | Source ID\n",
      "------------|--------------|-----------------|-----------\n",
      "          0 | \u001b[94m  0.987063\u001b[0m  |    5.731602     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 0: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 0: Plotting estimates.\n",
      "INFO:neuralnilm.net:Compiling deterministic output function...\n",
      "INFO:neuralnilm.net:Done compiling deterministic output function.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "          1 | \u001b[94m  0.160709\u001b[0m  |    0.087078     |   2\n",
      "          2 |   0.957761  |    0.157666     |   1\n",
      "          3 |   0.830244  |    0.199157     |   1\n",
      "          4 |   0.999763  |    0.016835     |   0\n",
      "          5 |   0.853387  |    0.046076     |   0\n",
      "          6 |   0.197959  |    0.076042     |   2\n",
      "          7 |   0.959021  |    0.146890     |   1\n",
      "          8 |   0.804767  |    0.228614     |   1\n",
      "          9 |   0.874090  |    0.154049     |   1\n",
      "         10 |   0.749080  |    0.172970     |   1\n",
      "         11 |   0.861092  |    0.128635     |   1\n",
      "         12 |   0.236778  |    0.011507     |   2\n",
      "         13 |   0.220963  |    0.089256     |   2\n",
      "         14 | \u001b[94m  0.105505\u001b[0m  |    0.005948     |   2\n",
      "         15 |   0.230192  |    0.079243     |   2\n",
      "         16 |   0.935074  |    0.030128     |   0\n",
      "         17 |   0.175348  |    0.078448     |   2\n",
      "         18 |   0.988985  |    0.028374     |   0\n",
      "         19 |   0.915494  |    0.080380     |   0\n",
      "         20 |   0.261339  |    0.006719     |   2\n",
      "         21 |   0.226457  |    0.077635     |   2\n",
      "         22 |   0.873976  |    0.142446     |   1\n",
      "         23 |   0.916757  |    0.054466     |   0\n",
      "         24 |   1.192886  |    0.052440     |   0\n",
      "         25 |   0.883646  |    0.047311     |   0\n",
      "         26 |   0.833408  |    0.055522     |   0\n",
      "         27 |   0.767385  |    0.160821     |   1\n",
      "         28 | \u001b[94m  0.056375\u001b[0m  |    0.048368     |   2\n",
      "         29 |   1.060269  |    0.040110     |   0\n",
      "         30 |   1.094423  |    0.046793     |   0\n",
      "         31 | \u001b[94m  0.000101\u001b[0m  |    0.046494     |   2\n",
      "         32 |   1.093819  |    0.083841     |   0\n",
      "         33 |   0.866143  |    0.015307     |   0\n",
      "         34 |   0.992016  |    0.075500     |   0\n",
      "         35 |   0.926430  |    0.015740     |   0\n",
      "         36 |   0.982988  |    0.044056     |   0\n",
      "         37 |   0.917544  |    0.072575     |   0\n",
      "         38 |   0.047283  |    0.029846     |   2\n",
      "         39 |   1.085335  |    0.201786     |   1\n",
      "         40 |   0.377366  |    0.018529     |   2\n",
      "         41 |   0.192621  |    0.078904     |   2\n",
      "         42 |   0.725028  |    0.167119     |   1\n",
      "         43 |   0.840651  |    0.163846     |   1\n",
      "         44 |   0.929444  |    0.159132     |   1\n",
      "         45 |   0.198226  |    0.013181     |   2\n",
      "         46 |   0.140989  |    0.076095     |   2\n",
      "         47 |   0.948747  |    0.014153     |   0\n",
      "         48 |   0.995710  |    0.084468     |   0\n",
      "         49 |   1.091946  |    0.146461     |   1\n",
      "         50 |   1.000330  |    0.141370     |   1\n",
      "         51 |   0.045207  |    0.020570     |   2\n",
      "         52 |   0.732093  |    0.212754     |   1\n",
      "         53 |   0.793052  |    0.020189     |   0\n",
      "         54 |   0.772494  |    0.154593     |   1\n",
      "         55 |   0.714521  |    0.028161     |   0\n",
      "         56 |   0.733051  |    0.192805     |   1\n",
      "         57 |   0.847952  |    0.136923     |   1\n",
      "         58 |   0.889458  |    0.030535     |   0\n",
      "         59 |   0.083343  |    0.073182     |   2\n",
      "         60 |   0.892672  |    0.039913     |   0\n",
      "         61 |   0.863204  |    0.050727     |   0\n",
      "         62 |   0.856227  |    0.175757     |   1\n",
      "         63 |   0.125883  |    0.072021     |   2\n",
      "         64 |   0.838899  |    0.023770     |   0\n",
      "         65 |   1.017336  |    0.051211     |   0\n",
      "         66 | \u001b[94m  0.000078\u001b[0m  |    0.041077     |   2\n",
      "         67 | \u001b[94m  0.000075\u001b[0m  |    0.081851     |   2\n",
      "         68 |   0.811089  |    0.164502     |   1\n",
      "         69 |   0.000090  |    0.030118     |   2\n",
      "         70 |   0.000085  |    0.081256     |   2\n",
      "         71 |   0.827118  |    0.151852     |   1\n",
      "         72 |   0.000090  |    0.003068     |   2\n",
      "         73 |   0.000085  |    0.078541     |   2\n",
      "         74 |   0.254818  |    0.048685     |   2\n",
      "         75 |   1.183661  |    0.146203     |   1\n",
      "         76 |   1.066064  |    0.153112     |   1\n",
      "         77 |   0.652079  |    0.138712     |   1\n",
      "         78 |   1.043569  |    0.034722     |   0\n",
      "         79 |   0.950625  |    0.081998     |   0\n",
      "         80 |   0.189632  |    0.010441     |   2\n",
      "         81 |   0.756503  |    0.055207     |   0\n",
      "         82 |   0.843033  |    0.207131     |   1\n",
      "         83 |   0.886845  |    0.151560     |   1\n",
      "         84 |   0.710687  |    0.163143     |   1\n",
      "         85 |   0.919581  |    0.192551     |   1\n",
      "         86 |   0.888048  |    0.020860     |   0\n",
      "         87 |   0.949743  |    0.198712     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "INFO:neuralnilm.trainer:Iteration 88: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         88 |   1.010908  |    0.007841     |   0\n",
      "         89 |   0.140232  |    0.020918     |   2\n",
      "         90 |   1.013854  |    0.191679     |   1\n",
      "         91 |   0.163167  |    0.044241     |   2\n",
      "         92 |   1.043866  |    0.042568     |   0\n",
      "         93 |   0.990117  |    0.049772     |   0\n",
      "         94 |   0.922651  |    0.193945     |   1\n",
      "         95 |   1.129313  |    0.045286     |   0\n",
      "         96 |   0.957324  |    0.160514     |   1\n",
      "         97 |   0.221252  |    0.046960     |   2\n",
      "         98 |   0.918204  |    0.184296     |   1\n",
      "         99 |   1.079406  |    0.010833     |   0\n",
      "        100 |   0.199255  |    0.080004     |   2\n",
      "        101 |   0.712468  |    0.011557     |   0\n",
      "        102 |   0.686397  |    0.086586     |   0\n",
      "        103 |   0.783824  |    0.158713     |   1\n",
      "        104 |   0.954228  |    0.011860     |   0\n",
      "        105 |   0.746834  |    0.201109     |   1\n",
      "        106 |   0.096422  |    0.027953     |   2\n",
      "        107 |   1.033614  |    0.052739     |   0\n",
      "        108 |   0.974820  |    0.080191     |   0\n",
      "        109 |   1.103847  |    0.142900     |   1\n",
      "        110 |   0.214991  |    0.048178     |   2\n",
      "        111 |   0.666909  |    0.238408     |   1\n",
      "        112 |   0.749096  |    0.098298     |   1\n",
      "        113 |   0.905584  |    0.044090     |   0\n",
      "        114 |   0.957553  |    0.049883     |   0\n",
      "        115 |   1.100658  |    0.065388     |   0\n",
      "        116 |   0.770084  |    0.137817     |   1\n",
      "        117 |   0.927499  |    0.020041     |   0\n",
      "        118 |   0.161481  |    0.074123     |   2\n",
      "        119 |   1.008742  |    0.112007     |   1\n",
      "        120 |   0.243750  |    0.048741     |   2\n",
      "        121 |   0.745467  |    0.072328     |   0\n",
      "        122 |   0.209272  |    0.021861     |   2\n",
      "        123 |   0.922967  |    0.104334     |   0\n",
      "        124 |   0.843214  |    0.105391     |   1\n",
      "        125 |   0.049227  |    0.052895     |   2\n",
      "        126 |   0.000173  |    0.023520     |   2\n",
      "        127 |   0.940167  |    0.198351     |   1\n",
      "        128 |   0.045530  |    0.010319     |   2\n",
      "        129 |   0.823827  |    0.201971     |   1\n",
      "        130 |   0.818142  |    0.112713     |   1\n",
      "        131 |   0.983554  |    0.190404     |   1\n",
      "        132 |   0.962715  |    0.017724     |   0\n",
      "        133 |   0.999514  |    0.077135     |   0\n",
      "        134 |   0.931747  |    0.146583     |   1\n",
      "        135 |   0.774572  |    0.167143     |   1\n",
      "        136 |   1.015555  |    0.029160     |   0\n",
      "        137 |   0.820020  |    0.047402     |   0\n",
      "        138 |   1.040795  |    0.196759     |   1\n",
      "        139 |   1.001557  |    0.009352     |   0\n",
      "        140 |   0.357458  |    0.043388     |   2\n",
      "        141 |   1.018987  |    0.057778     |   0\n",
      "        142 |   0.183070  |    0.053743     |   2\n",
      "        143 |   0.785646  |    0.167964     |   1\n",
      "        144 |   0.808495  |    0.014774     |   0\n",
      "        145 |   0.912590  |    0.212295     |   1\n",
      "        146 |   1.081423  |    0.011477     |   0\n",
      "        147 |   0.186509  |    0.081222     |   2\n",
      "        148 |   0.135088  |    0.023758     |   2\n",
      "        149 |   0.043641  |    0.050486     |   2\n",
      "        150 |   1.092183  |    0.082587     |   0\n",
      "        151 |   0.947322  |    0.149221     |   1\n",
      "        152 |   0.947422  |    0.139538     |   1\n",
      "        153 |   0.082023  |    0.019699     |   2\n",
      "        154 |   0.122289  |    0.050594     |   2\n",
      "        155 |   0.000261  |    0.039010     |   2\n",
      "        156 |   0.000264  |    0.079464     |   2\n",
      "        157 |   0.837376  |    0.025449     |   0\n",
      "        158 |   0.596674  |    0.221121     |   1\n",
      "        159 |   0.000282  |    0.009477     |   2\n",
      "        160 |   0.720941  |    0.199990     |   1\n",
      "        161 |   0.829551  |    0.038245     |   0\n",
      "        162 |   0.987643  |    0.044717     |   0\n",
      "        163 |   0.000287  |    0.043173     |   2\n",
      "        164 |   0.000295  |    0.075334     |   2\n",
      "        165 |   0.000281  |    0.014092     |   2\n",
      "        166 |   0.939920  |    0.080462     |   0\n",
      "        167 |   0.810141  |    0.009502     |   0\n",
      "        168 |   0.243272  |    0.090089     |   2\n",
      "        169 |   0.885598  |    0.020373     |   0\n",
      "        170 |   0.935033  |    0.071912     |   0\n",
      "        171 |   0.911029  |    0.023954     |   0\n",
      "        172 |   1.138176  |    0.077150     |   0\n",
      "        173 |   0.857197  |    0.134768     |   1\n",
      "        174 |   0.925887  |    0.198822     |   1\n",
      "        175 |   0.651847  |    0.204711     |   1\n",
      "        176 |   0.186940  |    0.006072     |   2\n",
      "        177 |   0.904450  |    0.078623     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 178: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        178 |   0.140230  |    0.021654     |   2\n",
      "        179 |   0.159086  |    0.048816     |   2\n",
      "        180 |   0.215148  |    0.076725     |   2\n",
      "        181 |   0.853749  |    0.014707     |   0\n",
      "        182 |   0.861865  |    0.076195     |   0\n",
      "        183 |   0.820892  |    0.013974     |   0\n",
      "        184 |   0.196002  |    0.086579     |   2\n",
      "        185 |   0.843443  |    0.152043     |   1\n",
      "        186 |   0.094723  |    0.005676     |   2\n",
      "        187 |   0.210223  |    0.048516     |   2\n",
      "        188 |   0.158244  |    0.040926     |   2\n",
      "        189 |   0.237362  |    0.053275     |   2\n",
      "        190 |   0.205370  |    0.037205     |   2\n",
      "        191 |   1.108616  |    0.081927     |   0\n",
      "        192 |   0.730291  |    0.159893     |   1\n",
      "        193 |   0.815002  |    0.034386     |   0\n",
      "        194 |   0.050067  |    0.050031     |   2\n",
      "        195 |   0.000365  |    0.046379     |   2\n",
      "        196 |   0.043973  |    0.031302     |   2\n",
      "        197 |   0.868703  |    0.079278     |   0\n",
      "        198 |   0.884674  |    0.171148     |   1\n",
      "        199 |   1.000261  |    0.005526     |   0\n",
      "        200 |   0.857607  |    0.148430     |   1\n",
      "        201 |   0.351643  |    0.011050     |   2\n",
      "        202 |   0.818698  |    0.194123     |   1\n",
      "        203 |   0.880014  |    0.119884     |   1\n",
      "        204 |   0.989940  |    0.028011     |   0\n",
      "        205 |   0.697902  |    0.156341     |   1\n",
      "        206 |   0.178549  |    0.043823     |   2\n",
      "        207 |   1.071127  |    0.204612     |   1\n",
      "        208 |   0.845516  |    0.006416     |   0\n",
      "        209 |   0.892511  |    0.180495     |   1\n",
      "        210 |   0.596866  |    0.147904     |   1\n",
      "        211 |   0.876437  |    0.140551     |   1\n",
      "        212 |   0.885784  |    0.004290     |   0\n",
      "        213 |   0.847054  |    0.204701     |   1\n",
      "        214 |   1.010914  |    0.006745     |   0\n",
      "        215 |   1.044863  |    0.079992     |   0\n",
      "        216 |   0.181920  |    0.038999     |   2\n",
      "        217 |   0.884464  |    0.044912     |   0\n",
      "        218 |   0.939969  |    0.039668     |   0\n",
      "        219 |   0.134913  |    0.052391     |   2\n",
      "        220 |   0.767053  |    0.051841     |   0\n",
      "        221 |   0.044580  |    0.027681     |   2\n",
      "        222 |   0.084166  |    0.076402     |   2\n",
      "        223 |   0.121238  |    0.015356     |   2\n",
      "        224 |   0.819301  |    0.189225     |   1\n",
      "        225 |   0.000487  |    0.023326     |   2\n",
      "        226 |   0.813411  |    0.079182     |   0\n",
      "        227 |   0.721074  |    0.164036     |   1\n",
      "        228 |   0.936421  |    0.129189     |   1\n",
      "        229 |   0.000503  |    0.045263     |   2\n",
      "        230 |   0.814692  |    0.045355     |   0\n",
      "        231 |   0.000518  |    0.045563     |   2\n",
      "        232 |   0.000516  |    0.024708     |   2\n",
      "        233 |   0.794029  |    0.078765     |   0\n",
      "        234 |   0.000534  |    0.022059     |   2\n",
      "        235 |   0.989036  |    0.079078     |   0\n",
      "        236 |   0.000507  |    0.021088     |   2\n",
      "        237 |   0.991945  |    0.059178     |   0\n",
      "        238 |   0.237307  |    0.045671     |   2\n",
      "        239 |   0.873530  |    0.046093     |   0\n",
      "        240 |   0.755169  |    0.046804     |   0\n",
      "        241 |   0.895392  |    0.049211     |   0\n",
      "        242 |   0.760453  |    0.179374     |   1\n",
      "        243 |   0.187561  |    0.051417     |   2\n",
      "        244 |   0.784251  |    0.162822     |   1\n",
      "        245 |   0.959605  |    0.077726     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 246: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        246 |   0.723257  |    0.017520     |   0\n",
      "        247 |   0.938478  |    0.190683     |   1\n",
      "        248 |   0.143018  |    0.003670     |   2\n",
      "        249 |   0.158283  |    0.080726     |   2\n",
      "        250 |   0.846667  |    0.021776     |   0\n",
      "        251 |   0.728548  |    0.056294     |   0\n",
      "        252 |   0.577574  |    0.169900     |   1\n",
      "        253 |   0.210958  |    0.046179     |   2\n",
      "        254 |   0.694762  |    0.209240     |   1\n",
      "        255 |   0.919985  |    0.007250     |   0\n",
      "        256 |   0.864360  |    0.042736     |   0\n",
      "        257 |   1.128016  |    0.079355     |   0\n",
      "        258 |   0.194521  |    0.040676     |   2\n",
      "        259 |   0.093851  |    0.073479     |   2\n",
      "        260 |   0.826679  |    0.023002     |   0\n",
      "        261 |   1.101629  |    0.073728     |   0\n",
      "        262 |   0.206376  |    0.023777     |   2\n",
      "        263 |   0.854128  |    0.073453     |   0\n",
      "        264 |   0.155826  |    0.024376     |   2\n",
      "        265 |   0.905548  |    0.052465     |   0\n",
      "        266 |   0.884990  |    0.150833     |   1\n",
      "        267 |   0.937356  |    0.029167     |   0\n",
      "        268 |   0.229717  |    0.056527     |   2\n",
      "        269 |   0.819738  |    0.078975     |   0\n",
      "        270 |   0.200935  |    0.020490     |   2\n",
      "        271 |   0.826019  |    0.188620     |   1\n",
      "        272 |   0.828531  |    0.136931     |   1\n",
      "        273 |   0.052633  |    0.009548     |   2\n",
      "        274 |   0.815976  |    0.199061     |   1\n",
      "        275 |   0.650727  |    0.031112     |   0\n",
      "        276 |   0.809357  |    0.207632     |   1\n",
      "        277 |   0.000682  |    0.010940     |   2\n",
      "        278 |   0.892715  |    0.051452     |   0\n",
      "        279 |   0.859923  |    0.165894     |   1\n",
      "        280 |   0.950595  |    0.044733     |   0\n",
      "        281 |   0.767058  |    0.041923     |   0\n",
      "        282 |   0.864821  |    0.157847     |   1\n",
      "        283 |   0.774203  |    0.054024     |   0\n",
      "        284 |   0.041444  |    0.062716     |   2\n",
      "        285 |   0.845394  |    0.150982     |   1\n",
      "        286 |   0.785365  |    0.085799     |   1\n",
      "        287 |   0.343388  |    0.047495     |   2\n",
      "        288 |   0.170845  |    0.038372     |   2\n",
      "        289 |   0.787531  |    0.076523     |   0\n",
      "        290 |   0.178093  |    0.011931     |   2\n",
      "        291 |   0.693401  |    0.082475     |   0\n",
      "        292 |   0.135496  |    0.006470     |   2\n",
      "        293 |   0.046545  |    0.081748     |   2\n",
      "        294 |   0.088107  |    0.008870     |   2\n",
      "        295 |   0.120551  |    0.081349     |   2\n",
      "        296 |   0.790895  |    0.016309     |   0\n",
      "        297 |   0.000765  |    0.078494     |   2\n",
      "        298 |   0.000776  |    0.038115     |   2\n",
      "        299 |   0.934155  |    0.075550     |   0\n",
      "        300 |   0.863173  |    0.029831     |   0\n",
      "        301 |   0.807427  |    0.180709     |   1\n",
      "        302 |   0.000782  |    0.054342     |   2\n",
      "        303 |   0.902154  |    0.157210     |   1\n",
      "        304 |   0.659818  |    0.141823     |   1\n",
      "        305 |   0.000781  |    0.031094     |   2\n",
      "        306 |   0.923787  |    0.074444     |   0\n",
      "        307 |   0.000828  |    0.008090     |   2\n",
      "        308 |   0.000766  |    0.087451     |   2\n",
      "        309 |   0.722308  |    0.157780     |   1\n",
      "        310 |   0.749477  |    0.179634     |   1\n",
      "        311 |   0.228043  |    0.004511     |   2\n",
      "        312 |   0.788778  |    0.079868     |   0\n",
      "        313 |   1.061792  |    0.034056     |   0\n",
      "        314 |   0.189856  |    0.053177     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 315: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        315 |   0.146803  |    0.036893     |   2\n",
      "        316 |   1.042172  |    0.077148     |   0\n",
      "        317 |   0.826518  |    0.018494     |   0\n",
      "        318 |   0.156304  |    0.047604     |   2\n",
      "        319 |   0.881055  |    0.082333     |   0\n",
      "        320 |   0.205996  |    0.009999     |   2\n",
      "        321 |   0.715756  |    0.218998     |   1\n",
      "        322 |   0.813787  |    0.012009     |   0\n",
      "        323 |   0.954540  |    0.102396     |   0\n",
      "        324 |   0.806117  |    0.131222     |   1\n",
      "        325 |   0.849560  |    0.155277     |   1\n",
      "        326 |   0.859792  |    0.144756     |   1\n",
      "        327 |   0.194047  |    0.045420     |   2\n",
      "        328 |   0.092965  |    0.042269     |   2\n",
      "        329 |   0.203785  |    0.056770     |   2\n",
      "        330 |   0.782331  |    0.152948     |   1\n",
      "        331 |   0.153383  |    0.032238     |   2\n",
      "        332 |   0.820995  |    0.193246     |   1\n",
      "        333 |   1.083004  |    0.005449     |   0\n",
      "        334 |   0.787431  |    0.214638     |   1\n",
      "        335 |   0.876822  |    0.007427     |   0\n",
      "        336 |   0.715192  |    0.055820     |   0\n",
      "        337 |   0.223474  |    0.048209     |   2\n",
      "        338 |   0.197962  |    0.041689     |   2\n",
      "        339 |   0.948296  |    0.076962     |   0\n",
      "        340 |   0.053803  |    0.033794     |   2\n",
      "        341 |   0.000863  |    0.079327     |   2\n",
      "        342 |   0.039866  |    0.017623     |   2\n",
      "        343 |   0.957414  |    0.164299     |   1\n",
      "        344 |   0.862200  |    0.056370     |   0\n",
      "        345 |   0.965308  |    0.168345     |   1\n",
      "        346 |   0.857081  |    0.139287     |   1\n",
      "        347 |   0.930303  |    0.028941     |   0\n",
      "        348 |   0.888104  |    0.080002     |   0\n",
      "        349 |   0.823159  |    0.149341     |   1\n",
      "        350 |   0.938261  |    0.040274     |   0\n",
      "        351 |   0.674023  |    0.215069     |   1\n",
      "        352 |   0.750301  |    0.140515     |   1\n",
      "        353 |   0.849308  |    0.045791     |   0\n",
      "        354 |   0.767631  |    0.044388     |   0\n",
      "        355 |   0.836527  |    0.077932     |   0\n",
      "        356 |   1.142210  |    0.026677     |   0\n",
      "        357 |   0.784086  |    0.188300     |   1\n",
      "        358 |   0.918409  |    0.008763     |   0\n",
      "        359 |   0.335673  |    0.101901     |   2\n",
      "        360 |   0.654952  |    0.170333     |   1\n",
      "        361 |   0.815039  |    0.024120     |   0\n",
      "        362 |   0.778102  |    0.158933     |   1\n",
      "        363 |   0.856907  |    0.013763     |   0\n",
      "        364 |   0.846335  |    0.086263     |   0\n",
      "        365 |   0.872496  |    0.019783     |   0\n",
      "        366 |   0.163845  |    0.070952     |   2\n",
      "        367 |   0.696992  |    0.202032     |   1\n",
      "        368 |   0.610300  |    0.147187     |   1\n",
      "        369 |   0.915140  |    0.105545     |   1\n",
      "        370 |   0.664813  |    0.086691     |   0\n",
      "        371 |   0.667645  |    0.150787     |   1\n",
      "        372 |   0.623989  |    0.020732     |   0\n",
      "        373 |   0.651442  |    0.220272     |   1\n",
      "        374 |   0.884555  |    0.143051     |   1\n",
      "        375 |   0.174891  |    0.005002     |   2\n",
      "        376 |   0.639214  |    0.206500     |   1\n",
      "        377 |   0.936591  |    0.024119     |   0\n",
      "        378 |   0.136416  |    0.082763     |   2\n",
      "        379 |   0.050017  |    0.023007     |   2\n",
      "        380 |   0.880952  |    0.073681     |   0\n",
      "        381 |   0.648264  |    0.200518     |   1\n",
      "        382 |   0.783304  |    0.004125     |   0\n",
      "        383 |   0.826211  |    0.145199     |   1\n",
      "        384 |   0.778283  |    0.021602     |   0\n",
      "        385 |   0.767055  |    0.043265     |   0\n",
      "        386 |   0.846165  |    0.137231     |   1\n",
      "        387 |   0.734212  |    0.135821     |   1\n",
      "        388 |   0.098456  |    0.044067     |   2\n",
      "        389 |   0.758226  |    0.203910     |   1\n",
      "        390 |   0.940470  |    0.004840     |   0\n",
      "        391 |   0.738262  |    0.092279     |   0\n",
      "        392 |   0.640312  |    0.145566     |   1\n",
      "        393 |   0.119220  |    0.016515     |   2\n",
      "        394 |   0.001109  |    0.047919     |   2\n",
      "        395 |   0.001145  |    0.076537     |   2\n",
      "        396 |   0.001101  |    0.027236     |   2\n",
      "        397 |   0.001109  |    0.049473     |   2\n",
      "        398 |   0.698424  |    0.229898     |   1\n",
      "        399 |   0.634613  |    0.156861     |   1\n",
      "        400 |   0.837191  |    0.010319     |   0\n",
      "        401 |   0.867947  |    0.076861     |   0\n",
      "        402 |   0.001193  |    0.026308     |   2\n",
      "        403 |   0.933257  |    0.083818     |   0\n",
      "        404 |   0.001086  |    0.018070     |   2\n",
      "        405 |   0.834292  |    0.200722     |   1\n",
      "        406 |   0.643285  |    0.122683     |   1\n",
      "        407 |   0.568238  |    0.180885     |   1\n",
      "        408 |   0.816707  |    0.016847     |   0\n",
      "        409 |   0.730234  |    0.062796     |   0\n",
      "        410 |   0.777878  |    0.159263     |   1\n",
      "        411 |   0.998310  |    0.189920     |   1\n",
      "        412 |   0.212593  |    0.017651     |   2\n",
      "        413 |   0.195346  |    0.052528     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 414: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        414 |   0.739517  |    0.025531     |   0\n",
      "        415 |   0.656456  |    0.086529     |   0\n",
      "        416 |   0.798723  |    0.033049     |   0\n",
      "        417 |   0.157067  |    0.076133     |   2\n",
      "        418 |   0.757252  |    0.039309     |   0\n",
      "        419 |   0.668201  |    0.202279     |   1\n",
      "        420 |   0.878831  |    0.021710     |   0\n",
      "        421 |   0.678819  |    0.203887     |   1\n",
      "        422 |   0.684496  |    0.161364     |   1\n",
      "        423 |   0.779371  |    0.042785     |   0\n",
      "        424 |   0.632453  |    0.188563     |   1\n",
      "        425 |   0.759191  |    0.049726     |   0\n",
      "        426 |   0.753414  |    0.039316     |   0\n",
      "        427 |   0.738503  |    0.212048     |   1\n",
      "        428 |   0.910357  |    0.188596     |   1\n",
      "        429 |   0.954851  |    0.043838     |   0\n",
      "        430 |   0.642845  |    0.071086     |   0\n",
      "        431 |   0.657844  |    0.023432     |   0\n",
      "        432 |   0.735157  |    0.211440     |   1\n",
      "        433 |   0.710519  |    0.204314     |   1\n",
      "        434 |   0.728747  |    0.147447     |   1\n",
      "        435 |   0.720956  |    0.220709     |   1\n",
      "        436 |   0.607981  |    0.171855     |   1\n",
      "        437 |   0.725526  |    0.171579     |   1\n",
      "        438 |   0.694140  |    0.171872     |   1\n",
      "        439 |   0.552528  |    0.163774     |   1\n",
      "        440 |   0.154017  |    0.017115     |   2\n",
      "        441 |   0.198981  |    0.046172     |   2\n",
      "        442 |   0.195792  |    0.055648     |   2\n",
      "        443 |   0.743274  |    0.160691     |   1\n",
      "        444 |   0.735229  |    0.251613     |   1\n",
      "        445 |   0.091226  |    0.075090     |   2\n",
      "        446 |   0.742264  |    0.261079     |   1\n",
      "        447 |   0.832515  |    0.155156     |   1\n",
      "        448 |   0.197785  |    0.017419     |   2\n",
      "        449 |   0.677273  |    0.129824     |   0\n",
      "        450 |   0.148168  |    0.034672     |   2\n",
      "        451 |   0.659730  |    0.263882     |   1\n",
      "        452 |   0.709270  |    0.301715     |   1\n",
      "        453 |   0.207258  |    0.108050     |   2\n",
      "        454 |   0.676847  |    0.248571     |   1\n",
      "        455 |   0.651830  |    0.035234     |   0\n",
      "        456 |   0.718438  |    0.203096     |   1\n",
      "        457 |   0.834358  |    0.151669     |   1\n",
      "        458 |   0.187708  |    0.017928     |   2\n",
      "        459 |   0.896953  |    0.190171     |   1\n",
      "        460 |   0.663196  |    0.025719     |   0\n",
      "        461 |   0.787795  |    0.194851     |   1\n",
      "        462 |   0.618792  |    0.011499     |   0\n",
      "        463 |   0.704696  |    0.078763     |   0\n",
      "        464 |   0.772801  |    0.041577     |   0\n",
      "        465 |   0.741739  |    0.205152     |   1\n",
      "        466 |   0.057403  |    0.011215     |   2\n",
      "        467 |   0.001143  |    0.045173     |   2\n",
      "        468 |   0.034177  |    0.081087     |   2\n",
      "        469 |   0.867214  |    0.166492     |   1\n",
      "        470 |   0.740553  |    0.191693     |   1\n",
      "        471 |   0.733240  |    0.027479     |   0\n",
      "        472 |   0.326590  |    0.081405     |   2\n",
      "        473 |   0.152667  |    0.031367     |   2\n",
      "        474 |   0.169726  |    0.082174     |   2\n",
      "        475 |   0.745565  |    0.191990     |   1\n",
      "        476 |   0.131837  |    0.023009     |   2\n",
      "        477 |   0.848386  |    0.072316     |   0\n",
      "        478 |   0.770634  |    0.039895     |   0\n",
      "        479 |   0.680864  |    0.048162     |   0\n",
      "        480 |   0.758491  |    0.181627     |   1\n",
      "        481 |   0.760758  |    0.039796     |   0\n",
      "        482 |   0.749938  |    0.047636     |   0\n",
      "        483 |   0.882829  |    0.147468     |   1\n",
      "        484 |   0.894279  |    0.228809     |   1\n",
      "        485 |   0.736830  |    0.027678     |   0\n",
      "        486 |   0.705339  |    0.085617     |   0\n",
      "        487 |   0.795068  |    0.043968     |   0\n",
      "        488 |   0.533979  |    0.074646     |   0\n",
      "        489 |   0.049698  |    0.075810     |   2\n",
      "        490 |   0.101708  |    0.075073     |   2\n",
      "        491 |   0.115686  |    0.044204     |   2\n",
      "        492 |   0.749172  |    0.308047     |   1\n",
      "        493 |   0.536308  |    0.107451     |   0\n",
      "        494 |   0.753012  |    0.129486     |   0\n",
      "        495 |   0.690412  |    0.252731     |   1\n",
      "        496 |   0.633552  |    0.021207     |   0\n",
      "        497 |   0.673145  |    0.089211     |   0\n",
      "        498 |   0.725052  |    0.047556     |   0\n",
      "        499 |   0.001124  |    0.120512     |   2\n",
      "        500 |   0.001174  |    0.054827     |   2\n",
      "        501 |   0.160758  |    0.081920     |   2\n",
      "        502 |   0.553543  |    0.133808     |   1\n",
      "        503 |   0.150054  |    0.044377     |   2\n",
      "        504 |   0.590168  |    0.231495     |   1\n",
      "        505 |   0.700689  |    0.108471     |   1\n",
      "        506 |   0.194022  |    0.031326     |   2\n",
      "        507 |   0.193031  |    0.077212     |   2\n",
      "        508 |   0.088809  |    0.024687     |   2\n",
      "        509 |   0.794688  |    0.198631     |   1\n",
      "        510 |   0.527563  |    0.173309     |   1\n",
      "        511 |   0.796789  |    0.015723     |   0\n",
      "        512 |   0.191554  |    0.077005     |   2\n",
      "        513 |   0.648890  |    0.148761     |   1\n",
      "        514 |   0.143748  |    0.047535     |   2\n",
      "        515 |   0.198587  |    0.040123     |   2\n",
      "        516 |   0.663666  |    0.067302     |   0\n",
      "        517 |   0.752531  |    0.071756     |   0\n",
      "        518 |   0.181808  |    0.042923     |   2\n",
      "        519 |   0.715076  |    0.069897     |   0\n",
      "        520 |   0.581094  |    0.039509     |   0\n",
      "        521 |   0.522525  |    0.157194     |   1\n",
      "        522 |   0.800308  |    0.150929     |   1\n",
      "        523 |   0.904327  |    0.012652     |   0\n",
      "        524 |   0.729074  |    0.096343     |   0\n",
      "        525 |   0.678172  |    0.162724     |   1\n",
      "        526 |   0.055655  |    0.010554     |   2\n",
      "        527 |   0.560049  |    0.202798     |   1\n",
      "        528 |   0.661316  |    0.139576     |   1\n",
      "        529 |   0.001069  |    0.058090     |   2\n",
      "        530 |   0.031213  |    0.042786     |   2\n",
      "        531 |   0.572140  |    0.042261     |   0\n",
      "        532 |   0.687055  |    0.077871     |   0\n",
      "        533 |   0.319112  |    0.025129     |   2\n",
      "        534 |   0.728617  |    0.204925     |   1\n",
      "        535 |   0.833162  |    0.134770     |   1\n",
      "        536 |   0.147101  |    0.041534     |   2\n",
      "        537 |   0.163767  |    0.062010     |   2\n",
      "        538 |   0.684289  |    0.159156     |   1\n",
      "        539 |   0.774877  |    0.035685     |   0\n",
      "        540 |   0.601343  |    0.162540     |   1\n",
      "        541 |   0.126838  |    0.032014     |   2\n",
      "        542 |   0.048668  |    0.075357     |   2\n",
      "        543 |   0.574633  |    0.023835     |   0\n",
      "        544 |   0.709915  |    0.196252     |   1\n",
      "        545 |   0.926865  |    0.162301     |   1\n",
      "        546 |   0.710152  |    0.009838     |   0\n",
      "        547 |   0.101049  |    0.072421     |   2\n",
      "        548 |   0.113001  |    0.057210     |   2\n",
      "        549 |   0.001029  |    0.028936     |   2\n",
      "        550 |   0.843404  |    0.200934     |   1\n",
      "        551 |   0.777848  |    0.135542     |   1\n",
      "        552 |   0.600406  |    0.023788     |   0\n",
      "        553 |   0.603222  |    0.178984     |   1\n",
      "        554 |   0.834847  |    0.037718     |   0\n",
      "        555 |   0.001101  |    0.045184     |   2\n",
      "        556 |   0.631472  |    0.163411     |   1\n",
      "        557 |   0.642296  |    0.078594     |   0\n",
      "        558 |   0.771057  |    0.036313     |   0\n",
      "        559 |   0.001045  |    0.052196     |   2\n",
      "        560 |   0.819457  |    0.151989     |   1\n",
      "        561 |   0.613486  |    0.048333     |   0\n",
      "        562 |   0.001104  |    0.064650     |   2\n",
      "        563 |   0.808528  |    0.147104     |   1\n",
      "        564 |   0.001215  |    0.028530     |   2\n",
      "        565 |   0.001077  |    0.071004     |   2\n",
      "        566 |   0.186535  |    0.027720     |   2\n",
      "        567 |   0.194766  |    0.043963     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 568: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        568 |   0.834910  |    0.050605     |   0\n",
      "        569 |   0.891449  |    0.043710     |   0\n",
      "        570 |   0.610390  |    0.213876     |   1\n",
      "        571 |   0.164650  |    0.026688     |   2\n",
      "        572 |   0.734538  |    0.202308     |   1\n",
      "        573 |   0.144463  |    0.008758     |   2\n",
      "        574 |   0.798412  |    0.143881     |   1\n",
      "        575 |   0.191740  |    0.036668     |   2\n",
      "        576 |   0.612802  |    0.054201     |   0\n",
      "        577 |   0.770251  |    0.148049     |   1\n",
      "        578 |   0.703349  |    0.103784     |   1\n",
      "        579 |   0.193086  |    0.034816     |   2\n",
      "        580 |   0.597458  |    0.081142     |   0\n",
      "        581 |   0.515001  |    0.153636     |   1\n",
      "        582 |   0.695947  |    0.147094     |   1\n",
      "        583 |   0.600069  |    0.045437     |   0\n",
      "        584 |   0.691912  |    0.031584     |   0\n",
      "        585 |   0.086325  |    0.074044     |   2\n",
      "        586 |   0.186672  |    0.009147     |   2\n",
      "        587 |   0.739540  |    0.211688     |   1\n",
      "        588 |   0.139526  |    0.025652     |   2\n",
      "        589 |   0.187745  |    0.038875     |   2\n",
      "        590 |   0.693547  |    0.212397     |   1\n",
      "        591 |   0.177910  |    0.003788     |   2\n",
      "        592 |   0.057431  |    0.047233     |   2\n",
      "        593 |   0.001061  |    0.073963     |   2\n",
      "        594 |   0.027119  |    0.040086     |   2\n",
      "        595 |   0.666636  |    0.045427     |   0\n",
      "        596 |   0.657959  |    0.041331     |   0\n",
      "        597 |   0.758839  |    0.204675     |   1\n",
      "        598 |   0.670094  |    0.135108     |   1\n",
      "        599 |   0.721976  |    0.004176     |   0\n",
      "        600 |   0.590645  |    0.204048     |   1\n",
      "        601 |   0.797929  |    0.006761     |   0\n",
      "        602 |   0.309883  |    0.086126     |   2\n",
      "        603 |   0.865904  |    0.029358     |   0\n",
      "        604 |   0.634125  |    0.209573     |   1\n",
      "        605 |   0.558313  |    0.140761     |   1\n",
      "        606 |   0.829171  |    0.029445     |   0\n",
      "        607 |   0.138768  |    0.083238     |   2\n",
      "        608 |   0.621686  |    0.139963     |   1\n",
      "        609 |   0.734658  |    0.178001     |   1\n",
      "        610 |   0.159275  |    0.027139     |   2\n",
      "        611 |   0.536717  |    0.042698     |   0\n",
      "        612 |   0.564291  |    0.157796     |   1\n",
      "        613 |   0.123414  |    0.012985     |   2\n",
      "        614 |   0.468899  |    0.202296     |   1\n",
      "        615 |   0.049561  |    0.040523     |   2\n",
      "        616 |   0.105617  |    0.050927     |   2\n",
      "        617 |   0.717750  |    0.193398     |   1\n",
      "        618 |   0.647809  |    0.140275     |   1\n",
      "        619 |   0.640288  |    0.014377     |   0\n",
      "        620 |   0.110028  |    0.053046     |   2\n",
      "        621 |   0.779836  |    0.199327     |   1\n",
      "        622 |   0.560987  |    0.003726     |   0\n",
      "        623 |   0.730697  |    0.151759     |   1\n",
      "        624 |   0.000996  |    0.083066     |   2\n",
      "        625 |   0.725093  |    0.148018     |   1\n",
      "        626 |   0.001071  |    0.014038     |   2\n",
      "        627 |   0.000975  |    0.089119     |   2\n",
      "        628 |   0.001060  |    0.019749     |   2\n",
      "        629 |   0.001153  |    0.080914     |   2\n",
      "        630 |   0.001023  |    0.009610     |   2\n",
      "        631 |   0.177115  |    0.054329     |   2\n",
      "        632 |   0.583927  |    0.154140     |   1\n",
      "        633 |   0.572525  |    0.042337     |   0\n",
      "        634 |   0.616066  |    0.048639     |   0\n",
      "        635 |   0.192964  |    0.016777     |   2\n",
      "        636 |   0.757575  |    0.093929     |   0\n",
      "        637 |   0.692846  |    0.148262     |   1\n",
      "        638 |   0.655873  |    0.055848     |   0\n",
      "        639 |   0.644869  |    0.218147     |   1\n",
      "        640 |   0.452833  |    0.109249     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 641: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        641 |   0.648752  |    0.038505     |   0\n",
      "        642 |   0.546234  |    0.080739     |   0\n",
      "        643 |   0.164984  |    0.028722     |   2\n",
      "        644 |   0.582427  |    0.041608     |   0\n",
      "        645 |   0.519782  |    0.044319     |   0\n",
      "        646 |   0.674804  |    0.182962     |   1\n",
      "        647 |   0.137914  |    0.084009     |   2\n",
      "        648 |   0.749559  |    0.209231     |   1\n",
      "        649 |   0.643613  |    0.145510     |   1\n",
      "        650 |   0.185408  |    0.042997     |   2\n",
      "        651 |   0.188287  |    0.056140     |   2\n",
      "        652 |   0.646026  |    0.222382     |   1\n",
      "        653 |   0.625760  |    0.137854     |   1\n",
      "        654 |   0.675273  |    0.022860     |   0\n",
      "        655 |   0.083506  |    0.082242     |   2\n",
      "        656 |   0.848023  |    0.152384     |   1\n",
      "        657 |   0.675262  |    0.186431     |   1\n",
      "        658 |   0.859060  |    0.025299     |   0\n",
      "        659 |   0.664558  |    0.076432     |   0\n",
      "        660 |   0.182735  |    0.044988     |   2\n",
      "        661 |   0.586846  |    0.048235     |   0\n",
      "        662 |   0.591719  |    0.151545     |   1\n",
      "        663 |   0.572962  |    0.040794     |   0\n",
      "        664 |   0.136904  |    0.050696     |   2\n",
      "        665 |   0.753567  |    0.045703     |   0\n",
      "        666 |   0.793912  |    0.044485     |   0\n",
      "        667 |   0.618440  |    0.028835     |   0\n",
      "        668 |   0.174880  |    0.077857     |   2\n",
      "        669 |   0.676779  |    0.140663     |   1\n",
      "        670 |   0.631793  |    0.022893     |   0\n",
      "        671 |   0.169764  |    0.086686     |   2\n",
      "        672 |   0.057757  |    0.009401     |   2\n",
      "        673 |   0.743980  |    0.100512     |   0\n",
      "        674 |   0.696568  |    0.095417     |   1\n",
      "        675 |   0.001028  |    0.043587     |   2\n",
      "        676 |   0.702536  |    0.196422     |   1\n",
      "        677 |   0.482640  |    0.007433     |   0\n",
      "        678 |   0.477709  |    0.196811     |   1\n",
      "        679 |   0.525002  |    0.140534     |   1\n",
      "        680 |   0.714566  |    0.201491     |   1\n",
      "        681 |   0.673179  |    0.007369     |   0\n",
      "        682 |   0.717194  |    0.045027     |   0\n",
      "        683 |   0.498031  |    0.049637     |   0\n",
      "        684 |   0.816869  |    0.141708     |   1\n",
      "        685 |   0.542400  |    0.023286     |   0\n",
      "        686 |   0.021800  |    0.058135     |   2\n",
      "        687 |   0.614757  |    0.139261     |   1\n",
      "        688 |   0.625312  |    0.042596     |   0\n",
      "        689 |   0.304905  |    0.074932     |   2\n",
      "        690 |   0.674646  |    0.019635     |   0\n",
      "        691 |   0.134128  |    0.053260     |   2\n",
      "        692 |   0.153069  |    0.076688     |   2\n",
      "        693 |   0.563730  |    0.146357     |   1\n",
      "        694 |   0.686221  |    0.138997     |   1\n",
      "        695 |   0.713821  |    0.017723     |   0\n",
      "        696 |   0.121928  |    0.079434     |   2\n",
      "        697 |   0.559143  |    0.009517     |   0\n",
      "        698 |   0.756477  |    0.089241     |   0\n",
      "        699 |   0.049403  |    0.033489     |   2\n",
      "        700 |   0.612400  |    0.198129     |   1\n",
      "        701 |   0.647564  |    0.008815     |   0\n",
      "        702 |   0.111911  |    0.076714     |   2\n",
      "        703 |   0.107634  |    0.028822     |   2\n",
      "        704 |   0.672402  |    0.040777     |   0\n",
      "        705 |   0.001013  |    0.074723     |   2\n",
      "        706 |   0.001091  |    0.045064     |   2\n",
      "        707 |   0.660000  |    0.040843     |   0\n",
      "        708 |   0.600677  |    0.044249     |   0\n",
      "        709 |   0.566789  |    0.023392     |   0\n",
      "        710 |   0.647174  |    0.075179     |   0\n",
      "        711 |   0.542158  |    0.027212     |   0\n",
      "        712 |   0.001026  |    0.044709     |   2\n",
      "        713 |   0.580173  |    0.039059     |   0\n",
      "        714 |   0.001121  |    0.074174     |   2\n",
      "        715 |   0.763941  |    0.182386     |   1\n",
      "        716 |   0.597732  |    0.004691     |   0\n",
      "        717 |   0.712646  |    0.190628     |   1\n",
      "        718 |   0.699838  |    0.009078     |   0\n",
      "        719 |   0.001276  |    0.052097     |   2\n",
      "        720 |   0.001104  |    0.081177     |   2\n",
      "        721 |   0.167683  |    0.013660     |   2\n",
      "        722 |   0.553459  |    0.073614     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 724: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        723 |   0.199363  |    0.009983     |   2\n",
      "        724 |   0.175355  |    0.071327     |   2\n",
      "        725 |   0.139764  |    0.017732     |   2\n",
      "        726 |   0.543461  |    0.045697     |   0\n",
      "        727 |   0.181447  |    0.049999     |   2\n",
      "        728 |   0.188847  |    0.038670     |   2\n",
      "        729 |   0.082545  |    0.055650     |   2\n",
      "        730 |   0.526046  |    0.167884     |   1\n",
      "        731 |   0.517841  |    0.199928     |   1\n",
      "        732 |   0.413116  |    0.006899     |   0\n",
      "        733 |   0.610387  |    0.138941     |   1\n",
      "        734 |   0.646778  |    0.194796     |   1\n",
      "        735 |   0.527498  |    0.151934     |   1\n",
      "        736 |   0.504878  |    0.050748     |   0\n",
      "        737 |   0.174751  |    0.046139     |   2\n",
      "        738 |   0.628004  |    0.043844     |   0\n",
      "        739 |   0.132737  |    0.029861     |   2\n",
      "        740 |   0.164878  |    0.058348     |   2\n",
      "        741 |   0.165262  |    0.044706     |   2\n",
      "        742 |   0.410709  |    0.162514     |   1\n",
      "        743 |   0.619952  |    0.210557     |   1\n",
      "        744 |   0.934410  |    0.088507     |   1\n",
      "        745 |   0.690117  |    0.139004     |   1\n",
      "        746 |   0.627461  |    0.190288     |   1\n",
      "        747 |   0.565939  |    0.160256     |   1\n",
      "        748 |   0.054921  |    0.010928     |   2\n",
      "        749 |   0.000931  |    0.074764     |   2\n",
      "        750 |   0.487185  |    0.013421     |   0\n",
      "        751 |   0.019338  |    0.091734     |   2\n",
      "        752 |   0.292246  |    0.011533     |   2\n",
      "        753 |   0.126894  |    0.085842     |   2\n",
      "        754 |   0.146192  |    0.024296     |   2\n",
      "        755 |   0.113776  |    0.083324     |   2\n",
      "        756 |   0.046135  |    0.018213     |   2\n",
      "        757 |   0.613212  |    0.198320     |   1\n",
      "        758 |   0.104650  |    0.013141     |   2\n",
      "        759 |   0.628539  |    0.206084     |   1\n",
      "        760 |   0.447296  |    0.006302     |   0\n",
      "        761 |   0.476032  |    0.053691     |   0\n",
      "        762 |   0.591273  |    0.075568     |   0\n",
      "        763 |   0.102553  |    0.021046     |   2\n",
      "        764 |   0.000845  |    0.071276     |   2\n",
      "        765 |   0.571261  |    0.040521     |   0\n",
      "        766 |   0.649662  |    0.056765     |   0\n",
      "        767 |   0.528080  |    0.040326     |   0\n",
      "        768 |   0.000940  |    0.053339     |   2\n",
      "        769 |   0.000843  |    0.050583     |   2\n",
      "        770 |   0.649200  |    0.185826     |   1\n",
      "        771 |   0.722085  |    0.148409     |   1\n",
      "        772 |   0.000961  |    0.013268     |   2\n",
      "        773 |   0.538031  |    0.072760     |   0\n",
      "        774 |   0.598659  |    0.168523     |   1\n",
      "        775 |   0.001079  |    0.014436     |   2\n",
      "        776 |   0.586171  |    0.075248     |   0\n",
      "        777 |   0.000952  |    0.021111     |   2\n",
      "        778 |   0.156610  |    0.079695     |   2\n",
      "        779 |   0.194319  |    0.028518     |   2\n",
      "        780 |   0.571641  |    0.189295     |   1\n",
      "        781 |   0.647433  |    0.020508     |   0\n",
      "        782 |   0.597069  |    0.220853     |   1\n",
      "        783 |   0.719247  |    0.148386     |   1\n",
      "        784 |   0.558309  |    0.043507     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 785: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        785 |   0.167118  |    0.056365     |   2\n",
      "        786 |   0.630199  |    0.165080     |   1\n",
      "        787 |   0.494934  |    0.199002     |   1\n",
      "        788 |   0.734388  |    0.033828     |   0\n",
      "        789 |   0.522755  |    0.197292     |   1\n",
      "        790 |   0.129514  |    0.055094     |   2\n",
      "        791 |   0.745281  |    0.042470     |   0\n",
      "        792 |   0.172845  |    0.041663     |   2\n",
      "        793 |   0.613409  |    0.041583     |   0\n",
      "        794 |   0.594012  |    0.043985     |   0\n",
      "        795 |   0.541687  |    0.041052     |   0\n",
      "        796 |   0.699721  |    0.076120     |   0\n",
      "        797 |   0.497329  |    0.156097     |   1\n",
      "        798 |   0.619597  |    0.025280     |   0\n",
      "        799 |   0.613994  |    0.218283     |   1\n",
      "        800 |   0.502602  |    0.094185     |   1\n",
      "        801 |   0.183828  |    0.042213     |   2\n",
      "        802 |   0.080509  |    0.047402     |   2\n",
      "        803 |   0.675037  |    0.059410     |   0\n",
      "        804 |   0.607729  |    0.186448     |   1\n",
      "        805 |   0.172409  |    0.018378     |   2\n",
      "        806 |   0.626195  |    0.200104     |   1\n",
      "        807 |   0.455954  |    0.006638     |   0\n",
      "        808 |   0.556126  |    0.043957     |   0\n",
      "        809 |   0.523786  |    0.052513     |   0\n",
      "        810 |   0.623386  |    0.198856     |   1\n",
      "        811 |   0.557702  |    0.008536     |   0\n",
      "        812 |   0.483658  |    0.155569     |   1\n",
      "        813 |   0.133687  |    0.064236     |   2\n",
      "        814 |   0.156996  |    0.031107     |   2\n",
      "        815 |   0.157040  |    0.051144     |   2\n",
      "        816 |   0.672389  |    0.195954     |   1\n",
      "        817 |   0.059452  |    0.007236     |   2\n",
      "        818 |   0.528935  |    0.074802     |   0\n",
      "        819 |   0.001001  |    0.020755     |   2\n",
      "        820 |   0.017530  |    0.088504     |   2\n",
      "        821 |   0.596963  |    0.141181     |   1\n",
      "        822 |   0.452163  |    0.160778     |   1\n",
      "        823 |   0.620014  |    0.154467     |   1\n",
      "        824 |   0.291634  |    0.005748     |   2\n",
      "        825 |   0.605785  |    0.212616     |   1\n",
      "        826 |   0.620640  |    0.119825     |   1\n",
      "        827 |   0.498367  |    0.078943     |   0\n",
      "        828 |   0.695012  |    0.139461     |   1\n",
      "        829 |   0.125052  |    0.028708     |   2\n",
      "        830 |   0.563601  |    0.083962     |   0\n",
      "        831 |   0.147548  |    0.027495     |   2\n",
      "        832 |   0.568957  |    0.210606     |   1\n",
      "        833 |   0.114740  |    0.009378     |   2\n",
      "        834 |   0.046820  |    0.085844     |   2\n",
      "        835 |   0.481588  |    0.017295     |   0\n",
      "        836 |   0.704002  |    0.208104     |   1\n",
      "        837 |   0.411432  |    0.151272     |   1\n",
      "        838 |   0.111393  |    0.041166     |   2\n",
      "        839 |   0.100359  |    0.043847     |   2\n",
      "        840 |   0.568523  |    0.158623     |   1\n",
      "        841 |   0.000888  |    0.014912     |   2\n",
      "        842 |   0.000966  |    0.080866     |   2\n",
      "        843 |   0.630669  |    0.025842     |   0\n",
      "        844 |   0.000876  |    0.040723     |   2\n",
      "        845 |   0.000971  |    0.045387     |   2\n",
      "        846 |   0.530899  |    0.042689     |   0\n",
      "        847 |   0.535069  |    0.073359     |   0\n",
      "        848 |   0.511034  |    0.012623     |   0\n",
      "        849 |   0.514119  |    0.073355     |   0\n",
      "        850 |   0.522494  |    0.029542     |   0\n",
      "        851 |   0.001106  |    0.044024     |   2\n",
      "        852 |   0.580092  |    0.044385     |   0\n",
      "        853 |   0.534748  |    0.166717     |   1\n",
      "        854 |   0.669640  |    0.204623     |   1\n",
      "        855 |   0.606979  |    0.024487     |   0\n",
      "        856 |   0.490870  |    0.056024     |   0\n",
      "        857 |   0.000971  |    0.052565     |   2\n",
      "        858 |   0.665324  |    0.081793     |   0\n",
      "        859 |   0.588118  |    0.142218     |   1\n",
      "        860 |   0.155455  |    0.031374     |   2\n",
      "        861 |   0.580642  |    0.208539     |   1\n",
      "        862 |   0.422992  |    0.144822     |   1\n",
      "        863 |   0.196802  |    0.031915     |   2\n",
      "        864 |   0.494900  |    0.053423     |   0\n",
      "        865 |   0.488790  |    0.191968     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 866: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        866 |   0.573794  |    0.008963     |   0\n",
      "        867 |   0.593788  |    0.135540     |   1\n",
      "        868 |   0.542488  |    0.180612     |   1\n",
      "        869 |   0.177988  |    0.012093     |   2\n",
      "        870 |   0.557610  |    0.075935     |   0\n",
      "        871 |   0.497987  |    0.030521     |   0\n",
      "        872 |   0.561053  |    0.071992     |   0\n",
      "        873 |   0.129691  |    0.025891     |   2\n",
      "        874 |   0.170708  |    0.072634     |   2\n",
      "        875 |   0.522762  |    0.033049     |   0\n",
      "        876 |   0.458934  |    0.083122     |   0\n",
      "        877 |   0.393865  |    0.144771     |   1\n",
      "        878 |   0.520013  |    0.047588     |   0\n",
      "        879 |   0.652459  |    0.048951     |   0\n",
      "        880 |   0.178992  |    0.045446     |   2\n",
      "        881 |   0.573494  |    0.054309     |   0\n",
      "        882 |   0.078495  |    0.047413     |   2\n",
      "        883 |   0.457777  |    0.040942     |   0\n",
      "        884 |   0.162996  |    0.080725     |   2\n",
      "        885 |   0.482323  |    0.013035     |   0\n",
      "        886 |   0.129721  |    0.050920     |   2\n",
      "        887 |   0.540649  |    0.152601     |   1\n",
      "        888 |   0.147020  |    0.069188     |   2\n",
      "        889 |   0.149959  |    0.021533     |   2\n",
      "        890 |   0.451545  |    0.076060     |   0\n",
      "        891 |   0.567834  |    0.141665     |   1\n",
      "        892 |   0.573305  |    0.004566     |   0\n",
      "        893 |   0.056556  |    0.086034     |   2\n",
      "        894 |   0.581381  |    0.153566     |   1\n",
      "        895 |   0.464943  |    0.009241     |   0\n",
      "        896 |   0.000898  |    0.029635     |   2\n",
      "        897 |   0.015144  |    0.036244     |   2\n",
      "        898 |   0.404956  |    0.076338     |   0\n",
      "        899 |   0.443318  |    0.011159     |   0\n",
      "        900 |   0.554505  |    0.189270     |   1\n",
      "        901 |   0.424274  |    0.053826     |   0\n",
      "        902 |   0.279253  |    0.048111     |   2\n",
      "        903 |   0.405627  |    0.039945     |   0\n",
      "        904 |   0.120048  |    0.054773     |   2\n",
      "        905 |   0.459924  |    0.209512     |   1\n",
      "        906 |   0.591304  |    0.006552     |   0\n",
      "        907 |   0.141676  |    0.053135     |   2\n",
      "        908 |   0.114378  |    0.053648     |   2\n",
      "        909 |   0.436958  |    0.176678     |   1\n",
      "        910 |   0.047150  |    0.026414     |   2\n",
      "        911 |   0.493352  |    0.049472     |   0\n",
      "        912 |   0.115967  |    0.079024     |   2\n",
      "        913 |   0.551650  |    0.147512     |   1\n",
      "        914 |   0.098189  |    0.041647     |   2\n",
      "        915 |   0.506133  |    0.204118     |   1\n",
      "        916 |   0.000820  |    0.009014     |   2\n",
      "        917 |   0.000894  |    0.078350     |   2\n",
      "        918 |   0.480084  |    0.006233     |   0\n",
      "        919 |   0.000814  |    0.092354     |   2\n",
      "        920 |   0.462545  |    0.148472     |   1\n",
      "        921 |   0.000890  |    0.050373     |   2\n",
      "        922 |   0.620349  |    0.169313     |   1\n",
      "        923 |   0.505930  |    0.029658     |   0\n",
      "        924 |   0.616886  |    0.159160     |   1\n",
      "        925 |   0.570626  |    0.151820     |   1\n",
      "        926 |   0.654173  |    0.138032     |   1\n",
      "        927 |   0.536361  |    0.030723     |   0\n",
      "        928 |   0.000999  |    0.053775     |   2\n",
      "        929 |   0.000850  |    0.051949     |   2\n",
      "        930 |   0.148399  |    0.042447     |   2\n",
      "        931 |   0.191321  |    0.042133     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 932: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        932 |   0.527055  |    0.163030     |   1\n",
      "        933 |   0.173395  |    0.023385     |   2\n",
      "        934 |   0.440787  |    0.192291     |   1\n",
      "        935 |   0.396435  |    0.006118     |   0\n",
      "        936 |   0.575270  |    0.195150     |   1\n",
      "        937 |   0.568155  |    0.016954     |   0\n",
      "        938 |   0.122111  |    0.076966     |   2\n",
      "        939 |   0.166415  |    0.045945     |   2\n",
      "        940 |   0.443061  |    0.021522     |   0\n",
      "        941 |   0.493478  |    0.079575     |   0\n",
      "        942 |   0.599817  |    0.133309     |   1\n",
      "        943 |   0.404199  |    0.012868     |   0\n",
      "        944 |   0.429950  |    0.047761     |   0\n",
      "        945 |   0.394382  |    0.042854     |   0\n",
      "        946 |   0.168354  |    0.045626     |   2\n",
      "        947 |   0.508557  |    0.080634     |   0\n",
      "        948 |   0.530778  |    0.146666     |   1\n",
      "        949 |   0.074939  |    0.050139     |   2\n",
      "        950 |   0.531991  |    0.241618     |   1\n",
      "        951 |   0.158468  |    0.042792     |   2\n",
      "        952 |   0.394107  |    0.249764     |   1\n",
      "        953 |   0.571865  |    0.198894     |   1\n",
      "        954 |   0.126399  |    0.009452     |   2\n",
      "        955 |   0.452896  |    0.085301     |   0\n",
      "        956 |   0.403498  |    0.158611     |   1\n",
      "        957 |   0.588338  |    0.050629     |   0\n",
      "        958 |   0.561101  |    0.093366     |   0\n",
      "        959 |   0.346834  |    0.219803     |   1\n",
      "        960 |   0.589447  |    0.071056     |   0\n",
      "        961 |   0.143463  |    0.082011     |   2\n",
      "        962 |   0.655380  |    0.221512     |   1\n",
      "        963 |   0.141365  |    0.071217     |   2\n",
      "        964 |   0.539410  |    0.195623     |   1\n",
      "        965 |   0.408384  |    0.146917     |   1\n",
      "        966 |   0.610725  |    0.166986     |   1\n",
      "        967 |   0.052952  |    0.084925     |   2\n",
      "        968 |   0.394201  |    0.151030     |   1\n",
      "        969 |   0.000786  |    0.045016     |   2\n",
      "        970 |   0.014149  |    0.079073     |   2\n",
      "        971 |   0.414969  |    0.203292     |   1\n",
      "        972 |   0.271057  |    0.048269     |   2\n",
      "        973 |   0.116565  |    0.059379     |   2\n",
      "        974 |   0.576693  |    0.084688     |   0\n",
      "        975 |   0.138747  |    0.008376     |   2\n",
      "        976 |   0.458333  |    0.079797     |   0\n",
      "        977 |   0.401039  |    0.249883     |   1\n",
      "        978 |   0.110751  |    0.015862     |   2\n",
      "        979 |   0.493075  |    0.215684     |   1\n",
      "        980 |   0.508470  |    0.139999     |   1\n",
      "        981 |   0.043237  |    0.047299     |   2\n",
      "        982 |   0.107584  |    0.059263     |   2\n",
      "        983 |   0.610720  |    0.192129     |   1\n",
      "        984 |   0.545076  |    0.009543     |   0\n",
      "        985 |   0.094088  |    0.075634     |   2\n",
      "        986 |   0.564450  |    0.058009     |   0\n",
      "        987 |   0.000715  |    0.052891     |   2\n",
      "        988 |   0.000792  |    0.027652     |   2\n",
      "        989 |   0.000717  |    0.078383     |   2\n",
      "        990 |   0.457783  |    0.023988     |   0\n",
      "        991 |   0.000813  |    0.071719     |   2\n",
      "        992 |   0.000903  |    0.020911     |   2\n",
      "        993 |   0.461310  |    0.050499     |   0\n",
      "        994 |   0.504701  |    0.042488     |   0\n",
      "        995 |   0.000778  |    0.045357     |   2\n",
      "        996 |   0.647698  |    0.152549     |   1\n",
      "        997 |   0.145244  |    0.028878     |   2\n",
      "        998 |   0.186380  |    0.044767     |   2\n",
      "        999 |   0.414683  |    0.078900     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 1000: Finished training epoch\n",
      "INFO:neuralnilm.trainer:Iteration 1000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 1000: Plotting estimates.\n",
      "Exception in thread neuralnilm-data-process:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 810, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/jack/workspace/python/neuralnilm/neuralnilm/data/datathread.py\", line 16, in run\n",
      "    batch = self.data_pipeline.get_batch(**self._get_batch_kwargs)\n",
      "  File \"/home/jack/workspace/python/neuralnilm/neuralnilm/data/datapipeline.py\", line 46, in get_batch\n",
      "    batch = self._source_iterators[source_id].next()\n",
      "ValueError: generator already executing\n",
      "\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       1000 |   0.168745  |    0.003961     |   2\n",
      "       1001 |   0.168012  |    0.085625     |   2\n",
      "       1002 |   0.565682  |    0.163611     |   1\n",
      "       1003 |   0.117760  |    0.006205     |   2\n",
      "       1004 |   0.530469  |    0.185141     |   1\n",
      "       1005 |   0.157315  |    0.022827     |   2\n",
      "       1006 |   0.163317  |    0.075177     |   2\n",
      "       1007 |   0.490134  |    0.047047     |   0\n",
      "       1008 |   0.368958  |    0.032687     |   0\n",
      "       1009 |   0.544806  |    0.170695     |   1\n",
      "       1010 |   0.453778  |    0.144504     |   1\n",
      "       1011 |   0.071510  |    0.081633     |   2\n",
      "       1012 |   0.149098  |    0.025985     |   2\n",
      "       1013 |   0.361523  |    0.192285     |   1\n",
      "       1014 |   0.476649  |    0.147400     |   1\n",
      "       1015 |   0.119416  |    0.030844     |   2\n",
      "       1016 |   0.606589  |    0.159232     |   1\n",
      "       1017 |   0.507003  |    0.204659     |   1\n",
      "       1018 |   0.490513  |    0.005089     |   0\n",
      "       1019 |   0.565828  |    0.163087     |   1\n",
      "       1020 |   0.487656  |    0.201358     |   1\n",
      "       1021 |   0.527815  |    0.138778     |   1\n",
      "       1022 |   0.135704  |    0.044976     |   2\n",
      "       1023 |   0.510411  |    0.204497     |   1\n",
      "       1024 |   0.136337  |    0.015931     |   2\n",
      "       1025 |   0.503104  |    0.212300     |   1\n",
      "       1026 |   0.050720  |    0.005748     |   2\n",
      "       1027 |   0.391117  |    0.083857     |   0\n",
      "       1028 |   0.000675  |    0.013791     |   2\n",
      "       1029 |   0.519925  |    0.075444     |   0\n",
      "       1030 |   0.531332  |    0.029762     |   0\n",
      "       1031 |   0.012943  |    0.052865     |   2\n",
      "       1032 |   0.379520  |    0.045373     |   0\n",
      "       1033 |   0.254808  |    0.033894     |   2\n",
      "       1034 |   0.110595  |    0.080096     |   2\n",
      "       1035 |   0.463697  |    0.016571     |   0\n",
      "       1036 |   0.524523  |    0.211340     |   1\n",
      "       1037 |   0.128866  |    0.004305     |   2\n",
      "       1038 |   0.102555  |    0.043592     |   2\n",
      "       1039 |   0.042124  |    0.045230     |   2\n",
      "       1040 |   0.448440  |    0.042612     |   0\n",
      "       1041 |   0.104803  |    0.081186     |   2\n",
      "       1042 |   0.399577  |    0.010318     |   0\n",
      "       1043 |   0.494322  |    0.083984     |   0\n",
      "       1044 |   0.516825  |    0.143877     |   1\n",
      "       1045 |   0.547348  |    0.027208     |   0\n",
      "       1046 |   0.456276  |    0.164101     |   1\n",
      "       1047 |   0.092305  |    0.028221     |   2\n",
      "       1048 |   0.543303  |    0.079183     |   0\n",
      "       1049 |   0.000659  |    0.014854     |   2\n",
      "       1050 |   0.454305  |    0.202769     |   1\n",
      "       1051 |   0.000760  |    0.005380     |   2\n",
      "       1052 |   0.000666  |    0.079428     |   2\n",
      "       1053 |   0.000772  |    0.036304     |   2\n",
      "       1054 |   0.561001  |    0.230462     |   1\n",
      "       1055 |   0.518011  |    0.147774     |   1\n",
      "       1056 |   0.668146  |    0.133145     |   1\n",
      "       1057 |   0.000868  |    0.003255     |   2\n",
      "       1058 |   0.000754  |    0.045440     |   2\n",
      "       1059 |   0.424361  |    0.043074     |   0\n",
      "       1060 |   0.139702  |    0.077460     |   2\n",
      "       1061 |   0.494110  |    0.024288     |   0\n",
      "       1062 |   0.184247  |    0.076714     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 1063: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       1063 |   0.455658  |    0.182006     |   1\n",
      "       1064 |   0.165528  |    0.005259     |   2\n",
      "       1065 |   0.439111  |    0.187535     |   1\n",
      "       1066 |   0.116724  |    0.007974     |   2\n",
      "       1067 |   0.521427  |    0.078560     |   0\n",
      "       1068 |   0.152193  |    0.035518     |   2\n",
      "       1069 |   0.463180  |    0.150185     |   1\n",
      "       1070 |   0.162305  |    0.044852     |   2\n",
      "       1071 |   0.483162  |    0.156176     |   1\n",
      "       1072 |   0.516926  |    0.151140     |   1\n",
      "       1073 |   0.496310  |    0.056783     |   0\n",
      "       1074 |   0.071700  |    0.047952     |   2\n",
      "       1075 |   0.553955  |    0.076184     |   0\n",
      "       1076 |   0.148395  |    0.009938     |   2\n",
      "       1077 |   0.422395  |    0.046886     |   0\n",
      "       1078 |   0.460001  |    0.047486     |   0\n",
      "       1079 |   0.118930  |    0.050679     |   2\n",
      "       1080 |   0.468839  |    0.041454     |   0\n",
      "       1081 |   0.131543  |    0.049465     |   2\n",
      "       1082 |   0.608482  |    0.140703     |   1\n",
      "       1083 |   0.434831  |    0.201635     |   1\n",
      "       1084 |   0.136453  |    0.003791     |   2\n",
      "       1085 |   0.504752  |    0.063111     |   0\n",
      "       1086 |   0.410774  |    0.171842     |   1\n",
      "       1087 |   0.552943  |    0.152899     |   1\n",
      "       1088 |   0.412751  |    0.130690     |   1\n",
      "       1089 |   0.052547  |    0.040315     |   2\n",
      "       1090 |   0.405152  |    0.198031     |   1\n",
      "       1091 |   0.511181  |    0.154522     |   1\n",
      "       1092 |   0.000709  |    0.006219     |   2\n",
      "       1093 |   0.408445  |    0.150774     |   1\n",
      "       1094 |   0.522081  |    0.046455     |   0\n",
      "       1095 |   0.515305  |    0.049721     |   0\n",
      "       1096 |   0.553237  |    0.140924     |   1\n",
      "       1097 |   0.012700  |    0.039361     |   2\n",
      "       1098 |   0.497492  |    0.073140     |   0\n",
      "       1099 |   0.387038  |    0.023794     |   0\n",
      "       1100 |   0.467117  |    0.077903     |   0\n",
      "       1101 |   0.253663  |    0.008493     |   2\n",
      "       1102 |   0.110705  |    0.082477     |   2\n",
      "       1103 |   0.135644  |    0.028668     |   2\n",
      "       1104 |   0.106885  |    0.056144     |   2\n",
      "       1105 |   0.528338  |    0.149347     |   1\n",
      "       1106 |   0.349682  |    0.078460     |   0\n",
      "       1107 |   0.439244  |    0.030816     |   0\n",
      "       1108 |   0.045565  |    0.040912     |   2\n",
      "       1109 |   0.473731  |    0.176315     |   1\n",
      "       1110 |   0.396804  |    0.024957     |   0\n",
      "       1111 |   0.109190  |    0.054032     |   2\n",
      "       1112 |   0.431963  |    0.207364     |   1\n",
      "       1113 |   0.091904  |    0.013760     |   2\n",
      "       1114 |   0.434970  |    0.082746     |   0\n",
      "       1115 |   0.000672  |    0.013672     |   2\n",
      "       1116 |   0.402112  |    0.075436     |   0\n",
      "       1117 |   0.396829  |    0.026468     |   0\n",
      "       1118 |   0.423077  |    0.071751     |   0\n",
      "       1119 |   0.411408  |    0.044196     |   0\n",
      "       1120 |   0.000775  |    0.046318     |   2\n",
      "       1121 |   0.408468  |    0.044569     |   0\n",
      "       1122 |   0.471072  |    0.193233     |   1\n",
      "       1123 |   0.346119  |    0.153909     |   1\n",
      "       1124 |   0.589107  |    0.152160     |   1\n",
      "       1125 |   0.411675  |    0.016108     |   0\n",
      "       1126 |   0.000697  |    0.074385     |   2\n",
      "       1127 |   0.419897  |    0.036080     |   0\n",
      "       1128 |   0.000804  |    0.074823     |   2\n",
      "       1129 |   0.528052  |    0.146943     |   1\n",
      "       1130 |   0.431059  |    0.150415     |   1\n",
      "       1131 |   0.455706  |    0.149983     |   1\n",
      "       1132 |   0.602527  |    0.141734     |   1\n",
      "       1133 |   0.379752  |    0.013114     |   0\n",
      "       1134 |   0.493971  |    0.046441     |   0\n",
      "       1135 |   0.000884  |    0.045229     |   2\n",
      "       1136 |   0.467089  |    0.081571     |   0\n",
      "       1137 |   0.000756  |    0.019481     |   2\n",
      "       1138 |   0.139967  |    0.058619     |   2\n",
      "       1139 |   0.525647  |    0.144525     |   1\n",
      "       1140 |   0.484050  |    0.141646     |   1\n",
      "       1141 |   0.407621  |    0.157520     |   1\n",
      "       1142 |   0.184458  |    0.019225     |   2\n",
      "       1143 |   0.534464  |    0.214530     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 1144: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       1144 |   0.168262  |    0.010495     |   2\n",
      "       1145 |   0.453008  |    0.160485     |   1\n",
      "       1146 |   0.296061  |    0.004725     |   0\n",
      "       1147 |   0.117301  |    0.047502     |   2\n",
      "       1148 |   0.148478  |    0.070437     |   2\n",
      "       1149 |   0.419098  |    0.057000     |   0\n",
      "       1150 |   0.315308  |    0.136931     |   1\n",
      "       1151 |   0.543188  |    0.185812     |   1\n",
      "       1152 |   0.444082  |    0.106369     |   1\n",
      "       1153 |   0.529866  |    0.145739     |   1\n",
      "       1154 |   0.153836  |    0.027662     |   2\n",
      "       1155 |   0.520359  |    0.196123     |   1\n",
      "       1156 |   0.069493  |    0.015616     |   2\n",
      "       1157 |   0.506540  |    0.205890     |   1\n",
      "       1158 |   0.438816  |    0.140751     |   1\n",
      "       1159 |   0.145274  |    0.004474     |   2\n",
      "       1160 |   0.117008  |    0.084812     |   2\n",
      "       1161 |   0.128949  |    0.017116     |   2\n",
      "       1162 |   0.390584  |    0.076296     |   0\n",
      "       1163 |   0.575630  |    0.145811     |   1\n",
      "       1164 |   0.439540  |    0.149557     |   1\n",
      "       1165 |   0.126928  |    0.040792     |   2\n",
      "       1166 |   0.541978  |    0.090061     |   0\n",
      "       1167 |   0.429346  |    0.159038     |   1\n",
      "       1168 |   0.556587  |    0.154435     |   1\n",
      "       1169 |   0.049188  |    0.008331     |   2\n",
      "       1170 |   0.461274  |    0.079463     |   0\n",
      "       1171 |   0.405878  |    0.134669     |   1\n",
      "       1172 |   0.482814  |    0.185015     |   1\n",
      "       1173 |   0.000633  |    0.009683     |   2\n",
      "       1174 |   0.012072  |    0.081007     |   2\n",
      "       1175 |   0.310125  |    0.157811     |   1\n",
      "       1176 |   0.518984  |    0.015232     |   0\n",
      "       1177 |   0.409538  |    0.204358     |   1\n",
      "       1178 |   0.246574  |    0.008425     |   2\n",
      "       1179 |   0.106924  |    0.088866     |   2\n",
      "       1180 |   0.439028  |    0.030470     |   0\n",
      "       1181 |   0.403137  |    0.076766     |   0\n",
      "       1182 |   0.459469  |    0.160516     |   1\n",
      "       1183 |   0.126682  |    0.010947     |   2\n",
      "       1184 |   0.360742  |    0.075103     |   0\n",
      "       1185 |   0.441820  |    0.017448     |   0\n",
      "       1186 |   0.451904  |    0.201534     |   1\n",
      "       1187 |   0.357083  |    0.161950     |   1\n",
      "       1188 |   0.461103  |    0.147765     |   1\n",
      "       1189 |   0.403828  |    0.025129     |   0\n",
      "       1190 |   0.106951  |    0.076037     |   2\n",
      "       1191 |   0.483139  |    0.139279     |   1\n",
      "       1192 |   0.390693  |    0.040155     |   0\n",
      "       1193 |   0.045149  |    0.070987     |   2\n",
      "       1194 |   0.106974  |    0.025668     |   2\n",
      "       1195 |   0.391011  |    0.078986     |   0\n",
      "       1196 |   0.543098  |    0.142669     |   1\n",
      "       1197 |   0.089152  |    0.009387     |   2\n",
      "       1198 |   0.472294  |    0.205875     |   1\n",
      "       1199 |   0.398952  |    0.172107     |   1\n",
      "       1200 |   0.531107  |    0.103011     |   1\n",
      "       1201 |   0.000578  |    0.071425     |   2\n",
      "       1202 |   0.463058  |    0.139104     |   1\n",
      "       1203 |   0.461653  |    0.166539     |   1\n",
      "       1204 |   0.457221  |    0.144513     |   1\n",
      "       1205 |   0.000672  |    0.018478     |   2\n",
      "       1206 |   0.000603  |    0.084730     |   2\n",
      "       1207 |   0.000693  |    0.041509     |   2\n",
      "       1208 |   0.000761  |    0.026787     |   2\n",
      "       1209 |   0.539002  |    0.082723     |   0\n",
      "       1210 |   0.459779  |    0.024647     |   0\n",
      "       1211 |   0.439915  |    0.080913     |   0\n",
      "       1212 |   0.400474  |    0.026921     |   0\n",
      "       1213 |   0.376885  |    0.076773     |   0\n",
      "       1214 |   0.384799  |    0.025614     |   0\n",
      "       1215 |   0.000672  |    0.048647     |   2\n",
      "       1216 |   0.138179  |    0.041255     |   2\n",
      "       1217 |   0.176155  |    0.073373     |   2\n",
      "       1218 |   0.425412  |    0.042800     |   0\n",
      "       1219 |   0.397861  |    0.049968     |   0\n",
      "       1220 |   0.377593  |    0.196201     |   1\n",
      "       1221 |   0.399087  |    0.005695     |   0\n",
      "       1222 |   0.429073  |    0.088093     |   0\n",
      "       1223 |   0.463046  |    0.146726     |   1\n",
      "       1224 |   0.436317  |    0.170705     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 1225: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       1225 |   0.434348  |    0.011564     |   0\n",
      "       1226 |   0.392134  |    0.176598     |   1\n",
      "       1227 |   0.477553  |    0.152468     |   1\n",
      "       1228 |   0.463962  |    0.003760     |   0\n",
      "       1229 |   0.304327  |    0.073304     |   0\n",
      "       1230 |   0.429300  |    0.029767     |   0\n",
      "       1231 |   0.486231  |    0.087616     |   0\n",
      "       1232 |   0.526895  |    0.144273     |   1\n",
      "       1233 |   0.172126  |    0.032085     |   2\n",
      "       1234 |   0.366161  |    0.074042     |   0\n",
      "       1235 |   0.115369  |    0.018381     |   2\n",
      "       1236 |   0.390651  |    0.235316     |   1\n",
      "       1237 |   0.350683  |    0.008583     |   0\n",
      "       1238 |   0.466152  |    0.212405     |   1\n",
      "       1239 |   0.151325  |    0.005389     |   2\n",
      "       1240 |   0.150971  |    0.043702     |   2\n",
      "       1241 |   0.453533  |    0.224162     |   1\n",
      "       1242 |   0.070637  |    0.004013     |   2\n",
      "       1243 |   0.482053  |    0.154809     |   1\n",
      "       1244 |   0.367711  |    0.025927     |   0\n",
      "       1245 |   0.435288  |    0.159154     |   1\n",
      "       1246 |   0.344995  |    0.038831     |   0\n",
      "       1247 |   0.392216  |    0.047718     |   0\n",
      "       1248 |   0.143937  |    0.052938     |   2\n",
      "       1249 |   0.558709  |    0.196527     |   1\n",
      "       1250 |   0.473925  |    0.101263     |   1\n",
      "       1251 |   0.400589  |    0.155043     |   1\n",
      "       1252 |   0.516455  |    0.204826     |   1\n",
      "       1253 |   0.114252  |    0.011502     |   2\n",
      "       1254 |   0.126376  |    0.086170     |   2\n",
      "       1255 |   0.126575  |    0.014904     |   2\n",
      "       1256 |   0.480992  |    0.048753     |   0\n",
      "       1257 |   0.390485  |    0.076969     |   0\n",
      "       1258 |   0.548762  |    0.164780     |   1\n",
      "       1259 |   0.443829  |    0.141596     |   1\n",
      "       1260 |   0.387024  |    0.009085     |   0\n",
      "       1261 |   0.050480  |    0.094086     |   2\n",
      "       1262 |   0.461306  |    0.144000     |   1\n",
      "       1263 |   0.346142  |    0.051787     |   0\n",
      "       1264 |   0.413908  |    0.148283     |   1\n",
      "       1265 |   0.000623  |    0.024311     |   2\n",
      "       1266 |   0.459477  |    0.199244     |   1\n",
      "       1267 |   0.012715  |    0.011217     |   2\n",
      "       1268 |   0.361588  |    0.060284     |   0\n",
      "       1269 |   0.241258  |    0.046279     |   2\n",
      "       1270 |   0.109314  |    0.043649     |   2\n",
      "       1271 |   0.353245  |    0.044298     |   0\n",
      "       1272 |   0.359384  |    0.146648     |   1\n",
      "       1273 |   0.421160  |    0.026810     |   0\n",
      "       1274 |   0.128543  |    0.084059     |   2\n",
      "       1275 |   0.113602  |    0.015962     |   2\n",
      "       1276 |   0.489176  |    0.187765     |   1\n",
      "       1277 |   0.414183  |    0.038321     |   0\n",
      "       1278 |   0.047003  |    0.055014     |   2\n",
      "       1279 |   0.336941  |    0.031454     |   0\n",
      "       1280 |   0.397583  |    0.198178     |   1\n",
      "       1281 |   0.430063  |    0.008317     |   0\n",
      "       1282 |   0.345571  |    0.077817     |   0\n",
      "       1283 |   0.384687  |    0.104415     |   1\n",
      "       1284 |   0.429702  |    0.203364     |   1\n",
      "       1285 |   0.104476  |    0.009805     |   2\n",
      "       1286 |   0.315988  |    0.076932     |   0\n",
      "       1287 |   0.304291  |    0.009944     |   0\n",
      "       1288 |   0.086961  |    0.084813     |   2\n",
      "       1289 |   0.539902  |    0.153281     |   1\n",
      "       1290 |   0.000584  |    0.004246     |   2\n",
      "       1291 |   0.000699  |    0.085136     |   2\n",
      "       1292 |   0.481784  |    0.146016     |   1\n",
      "       1293 |   0.000596  |    0.010487     |   2\n",
      "       1294 |   0.384547  |    0.204878     |   1\n",
      "       1295 |   0.355828  |    0.014839     |   0\n",
      "       1296 |   0.373230  |    0.044746     |   0\n",
      "       1297 |   0.484409  |    0.202769     |   1\n",
      "       1298 |   0.000717  |    0.015621     |   2\n",
      "       1299 |   0.312237  |    0.212761     |   1\n",
      "       1300 |   0.403712  |    0.008927     |   0\n",
      "       1301 |   0.370016  |    0.200192     |   1\n",
      "       1302 |   0.000798  |    0.027898     |   2\n",
      "       1303 |   0.297049  |    0.092811     |   0\n",
      "       1304 |   0.401304  |    0.153458     |   1\n",
      "       1305 |   0.000686  |    0.008103     |   2\n",
      "       1306 |   0.138685  |    0.091183     |   2\n",
      "       1307 |   0.395987  |    0.159472     |   1\n",
      "       1308 |   0.474173  |    0.241048     |   1\n",
      "       1309 |   0.419416  |    0.221732     |   1\n",
      "       1310 |   0.377877  |    0.069827     |   0\n",
      "       1311 |   0.401010  |    0.271737     |   1\n",
      "       1312 |   0.309446  |    0.039392     |   0\n",
      "       1313 |   0.170768  |    0.073004     |   2\n",
      "       1314 |   0.406122  |    0.219057     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 1315: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       1315 |   0.433258  |    0.071834     |   0\n",
      "       1316 |   0.481547  |    0.224129     |   1\n",
      "       1317 |   0.305760  |    0.270418     |   1\n",
      "       1318 |   0.167152  |    0.042743     |   2\n",
      "       1319 |   0.398684  |    0.078335     |   0\n",
      "       1320 |   0.335173  |    0.010858     |   0\n",
      "       1321 |   0.402088  |    0.080826     |   0\n",
      "       1322 |   0.465492  |    0.154360     |   1\n",
      "       1323 |   0.370299  |    0.130990     |   1\n",
      "       1324 |   0.412103  |    0.178442     |   1\n",
      "       1325 |   0.401433  |    0.184048     |   1\n",
      "       1326 |   0.113546  |    0.024376     |   2\n",
      "       1327 |   0.142027  |    0.060608     |   2\n",
      "       1328 |   0.537868  |    0.147473     |   1\n",
      "       1329 |   0.142800  |    0.040149     |   2\n",
      "       1330 |   0.065635  |    0.044214     |   2\n",
      "       1331 |   0.134206  |    0.058360     |   2\n",
      "       1332 |   0.438125  |    0.139668     |   1\n",
      "       1333 |   0.111425  |    0.032157     |   2\n",
      "       1334 |   0.412405  |    0.071109     |   0\n",
      "       1335 |   0.396137  |    0.038722     |   0\n",
      "       1336 |   0.365556  |    0.089564     |   0\n",
      "       1337 |   0.343612  |    0.147178     |   1\n",
      "       1338 |   0.122758  |    0.013816     |   2\n",
      "       1339 |   0.122831  |    0.043153     |   2\n",
      "       1340 |   0.048400  |    0.051167     |   2\n",
      "       1341 |   0.000548  |    0.081603     |   2\n",
      "       1342 |   0.412420  |    0.156841     |   1\n",
      "       1343 |   0.361944  |    0.191226     |   1\n",
      "       1344 |   0.012791  |    0.040375     |   2\n",
      "       1345 |   0.403506  |    0.199356     |   1\n",
      "       1346 |   0.431951  |    0.139949     |   1\n",
      "       1347 |   0.296619  |    0.041203     |   0\n",
      "       1348 |   0.421985  |    0.195408     |   1\n",
      "       1349 |   0.341283  |    0.190732     |   1\n",
      "       1350 |   0.232321  |    0.005877     |   2\n",
      "       1351 |   0.378111  |    0.090829     |   0\n",
      "       1352 |   0.458472  |    0.165382     |   1\n",
      "       1353 |   0.102693  |    0.008919     |   2\n",
      "       1354 |   0.120997  |    0.065109     |   2\n",
      "       1355 |   0.426409  |    0.247335     |   1\n",
      "       1356 |   0.293968  |    0.269605     |   1\n",
      "       1357 |   0.386034  |    0.018105     |   0\n",
      "       1358 |   0.105339  |    0.081234     |   2\n",
      "       1359 |   0.343664  |    0.030049     |   0\n",
      "       1360 |   0.046258  |    0.079332     |   2\n",
      "       1361 |   0.385678  |    0.045082     |   0\n",
      "       1362 |   0.433421  |    0.184884     |   1\n",
      "       1363 |   0.450919  |    0.145162     |   1\n",
      "       1364 |   0.384193  |    0.194794     |   1\n",
      "       1365 |   0.461879  |    0.148142     |   1\n",
      "       1366 |   0.398050  |    0.010519     |   0\n",
      "       1367 |   0.427292  |    0.070456     |   0\n",
      "       1368 |   0.105695  |    0.037240     |   2\n",
      "       1369 |   0.513461  |    0.172794     |   1\n",
      "       1370 |   0.414246  |    0.166981     |   1\n",
      "       1371 |   0.252362  |    0.052028     |   0\n",
      "       1372 |   0.412941  |    0.046689     |   0\n",
      "       1373 |   0.412571  |    0.040104     |   0\n",
      "       1374 |   0.083754  |    0.070183     |   2\n",
      "       1375 |   0.488380  |    0.189691     |   1\n",
      "       1376 |   0.503116  |    0.166164     |   1\n",
      "       1377 |   0.497406  |    0.105424     |   1\n",
      "       1378 |   0.452970  |    0.198579     |   1\n",
      "       1379 |   0.000504  |    0.012806     |   2\n",
      "       1380 |   0.000609  |    0.080603     |   2\n",
      "       1381 |   0.364290  |    0.142087     |   1\n",
      "       1382 |   0.325371  |    0.047072     |   0\n",
      "       1383 |   0.337918  |    0.027866     |   0\n",
      "       1384 |   0.000504  |    0.083305     |   2\n",
      "       1385 |   0.388880  |    0.049371     |   0\n",
      "       1386 |   0.000615  |    0.042612     |   2\n",
      "       1387 |   0.000702  |    0.080820     |   2\n",
      "       1388 |   0.000607  |    0.038868     |   2\n",
      "       1389 |   0.369356  |    0.048891     |   0\n",
      "       1390 |   0.375927  |    0.161453     |   1\n",
      "       1391 |   0.372431  |    0.209567     |   1\n",
      "       1392 |   0.460967  |    0.165737     |   1\n",
      "       1393 |   0.371171  |    0.170142     |   1\n",
      "       1394 |   0.129763  |    0.014519     |   2\n",
      "       1395 |   0.166770  |    0.085888     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 1396: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       1396 |   0.349441  |    0.146487     |   1\n",
      "       1397 |   0.360880  |    0.026280     |   0\n",
      "       1398 |   0.358070  |    0.182108     |   1\n",
      "       1399 |   0.280374  |    0.007197     |   0\n",
      "       1400 |   0.161843  |    0.085589     |   2\n",
      "       1401 |   0.398263  |    0.198780     |   1\n",
      "       1402 |   0.415955  |    0.025667     |   0\n",
      "       1403 |   0.110157  |    0.075882     |   2\n",
      "       1404 |   0.343917  |    0.013257     |   0\n",
      "       1405 |   0.385344  |    0.197935     |   1\n",
      "       1406 |   0.135855  |    0.028154     |   2\n",
      "       1407 |   0.415670  |    0.045963     |   0\n",
      "       1408 |   0.352193  |    0.159972     |   1\n",
      "       1409 |   0.141238  |    0.048773     |   2\n",
      "       1410 |   0.389652  |    0.082889     |   0\n",
      "       1411 |   0.371712  |    0.144623     |   1\n",
      "       1412 |   0.065715  |    0.044291     |   2\n",
      "       1413 |   0.131197  |    0.070647     |   2\n",
      "       1414 |   0.112227  |    0.035178     |   2\n",
      "       1415 |   0.475648  |    0.143689     |   1\n",
      "       1416 |   0.354919  |    0.044212     |   0\n",
      "       1417 |   0.405136  |    0.041499     |   0\n",
      "       1418 |   0.346396  |    0.072795     |   0\n",
      "       1419 |   0.522348  |    0.139089     |   1\n",
      "       1420 |   0.419503  |    0.024396     |   0\n",
      "       1421 |   0.415890  |    0.076994     |   0\n",
      "       1422 |   0.256150  |    0.011924     |   0\n",
      "       1423 |   0.478615  |    0.198377     |   1\n",
      "       1424 |   0.380486  |    0.140161     |   1\n",
      "       1425 |   0.387392  |    0.042000     |   0\n",
      "       1426 |   0.378358  |    0.044407     |   0\n",
      "       1427 |   0.117303  |    0.072674     |   2\n",
      "       1428 |   0.350174  |    0.029660     |   0\n",
      "       1429 |   0.381607  |    0.225373     |   1\n",
      "       1430 |   0.392283  |    0.096874     |   1\n",
      "       1431 |   0.342191  |    0.048167     |   0\n",
      "       1432 |   0.463088  |    0.217532     |   1\n",
      "       1433 |   0.427227  |    0.160238     |   1\n",
      "       1434 |   0.506821  |    0.140930     |   1\n",
      "       1435 |   0.356708  |    0.145914     |   1\n",
      "       1436 |   0.122905  |    0.018226     |   2\n",
      "       1437 |   0.346467  |    0.196163     |   1\n",
      "       1438 |   0.046317  |    0.011129     |   2\n",
      "       1439 |   0.343270  |    0.079099     |   0\n",
      "       1440 |   0.410104  |    0.045543     |   0\n",
      "       1441 |   0.339583  |    0.141505     |   1\n",
      "       1442 |   0.000509  |    0.082428     |   2\n",
      "       1443 |   0.013430  |    0.016823     |   2\n",
      "       1444 |   0.325072  |    0.206736     |   1\n",
      "       1445 |   0.378398  |    0.208878     |   1\n",
      "       1446 |   0.229305  |    0.008484     |   2\n",
      "       1447 |   0.100128  |    0.088061     |   2\n",
      "       1448 |   0.126306  |    0.017810     |   2\n",
      "       1449 |   0.427378  |    0.145366     |   1\n",
      "       1450 |   0.109637  |    0.040109     |   2\n",
      "       1451 |   0.361662  |    0.208560     |   1\n",
      "       1452 |   0.431365  |    0.155006     |   1\n",
      "       1453 |   0.368459  |    0.153986     |   1\n",
      "       1454 |   0.409740  |    0.003296     |   0\n",
      "       1455 |   0.323445  |    0.074925     |   0\n",
      "       1456 |   0.404257  |    0.018340     |   0\n",
      "       1457 |   0.394645  |    0.076314     |   0\n",
      "       1458 |   0.046729  |    0.030842     |   2\n",
      "       1459 |   0.365885  |    0.072846     |   0\n",
      "       1460 |   0.376791  |    0.151865     |   1\n",
      "       1461 |   0.102202  |    0.012372     |   2\n",
      "       1462 |   0.080133  |    0.073138     |   2\n",
      "       1463 |   0.360219  |    0.026094     |   0\n",
      "       1464 |   0.000474  |    0.042339     |   2\n",
      "       1465 |   0.403490  |    0.184477     |   1\n",
      "       1466 |   0.000581  |    0.011479     |   2\n",
      "       1467 |   0.000490  |    0.079179     |   2\n",
      "       1468 |   0.369692  |    0.191868     |   1\n",
      "       1469 |   0.389725  |    0.014534     |   0\n",
      "       1470 |   0.338194  |    0.213020     |   1\n",
      "       1471 |   0.000609  |    0.009761     |   2\n",
      "       1472 |   0.000670  |    0.076171     |   2\n",
      "       1473 |   0.333788  |    0.202614     |   1\n",
      "       1474 |   0.396849  |    0.015276     |   0\n",
      "       1475 |   0.364356  |    0.053829     |   0\n",
      "       1476 |   0.000582  |    0.050170     |   2\n",
      "       1477 |   0.386805  |    0.202576     |   1\n",
      "       1478 |   0.448244  |    0.158509     |   1\n",
      "       1479 |   0.365585  |    0.005255     |   0\n",
      "       1480 |   0.382016  |    0.141429     |   1\n",
      "       1481 |   0.130307  |    0.038436     |   2\n",
      "       1482 |   0.163418  |    0.093571     |   2\n",
      "       1483 |   0.424649  |    0.135801     |   1\n",
      "       1484 |   0.287136  |    0.010836     |   0\n",
      "       1485 |   0.404179  |    0.035748     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 1486: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       1486 |   0.327673  |    0.146877     |   1\n",
      "       1487 |   0.157461  |    0.043436     |   2\n",
      "       1488 |   0.402033  |    0.073608     |   0\n",
      "       1489 |   0.418019  |    0.014236     |   0\n",
      "       1490 |   0.379394  |    0.199954     |   1\n",
      "       1491 |   0.110412  |    0.051352     |   2\n",
      "       1492 |   0.360726  |    0.051148     |   0\n",
      "       1493 |   0.330486  |    0.152241     |   1\n",
      "       1494 |   0.390342  |    0.027859     |   0\n",
      "       1495 |   0.268081  |    0.210482     |   1\n",
      "       1496 |   0.383138  |    0.045657     |   0\n",
      "       1497 |   0.354197  |    0.184505     |   1\n",
      "       1498 |   0.432673  |    0.037919     |   0\n",
      "       1499 |   0.379255  |    0.075988     |   0\n",
      "       1500 |   0.133177  |    0.005485     |   2\n",
      "       1501 |   0.345957  |    0.072025     |   0\n",
      "       1502 |   0.324092  |    0.037685     |   0\n",
      "       1503 |   0.281935  |    0.064243     |   0\n",
      "       1504 |   0.516434  |    0.167600     |   1\n",
      "       1505 |   0.303081  |    0.150866     |   1\n",
      "       1506 |   0.409846  |    0.180243     |   1\n",
      "       1507 |   0.423505  |    0.141046     |   1\n",
      "       1508 |   0.409463  |    0.139151     |   1\n",
      "       1509 |   0.459340  |    0.165170     |   1\n",
      "       1510 |   0.160646  |    0.046307     |   2\n",
      "       1511 |   0.108486  |    0.044995     |   2\n",
      "       1512 |   0.376001  |    0.216701     |   1\n",
      "       1513 |   0.317587  |    0.004933     |   0\n",
      "       1514 |   0.132569  |    0.076115     |   2\n",
      "       1515 |   0.143894  |    0.008702     |   2\n",
      "       1516 |   0.064570  |    0.082524     |   2\n",
      "       1517 |   0.444791  |    0.143553     |   1\n",
      "       1518 |   0.127993  |    0.010961     |   2\n",
      "       1519 |   0.232973  |    0.043327     |   0\n",
      "       1520 |   0.370075  |    0.177520     |   1\n",
      "       1521 |   0.371824  |    0.165829     |   1\n",
      "       1522 |   0.333685  |    0.166897     |   1\n",
      "       1523 |   0.417826  |    0.156238     |   1\n",
      "       1524 |   0.109886  |    0.041908     |   2\n",
      "       1525 |   0.388192  |    0.220247     |   1\n",
      "       1526 |   0.115700  |    0.023036     |   2\n",
      "       1527 |   0.531851  |    0.148785     |   1\n",
      "       1528 |   0.388214  |    0.059248     |   0\n",
      "       1529 |   0.112306  |    0.047127     |   2\n",
      "       1530 |   0.364138  |    0.146374     |   1\n",
      "       1531 |   0.044710  |    0.026944     |   2\n",
      "       1532 |   0.371136  |    0.077727     |   0\n",
      "       1533 |   0.384085  |    0.152857     |   1\n",
      "       1534 |   0.000449  |    0.042808     |   2\n",
      "       1535 |   0.319708  |    0.046039     |   0\n",
      "       1536 |   0.344084  |    0.050227     |   0\n",
      "       1537 |   0.330489  |    0.154947     |   1\n",
      "       1538 |   0.434149  |    0.150508     |   1\n",
      "       1539 |   0.348115  |    0.018767     |   0\n",
      "       1540 |   0.332626  |    0.211603     |   1\n",
      "       1541 |   0.356048  |    0.142734     |   1\n",
      "       1542 |   0.012141  |    0.034990     |   2\n",
      "       1543 |   0.437081  |    0.193216     |   1\n",
      "       1544 |   0.333253  |    0.009470     |   0\n",
      "       1545 |   0.359905  |    0.074024     |   0\n",
      "       1546 |   0.388235  |    0.010728     |   0\n",
      "       1547 |   0.409015  |    0.216323     |   1\n",
      "       1548 |   0.346683  |    0.185692     |   1\n",
      "       1549 |   0.433747  |    0.149812     |   1\n",
      "       1550 |   0.227105  |    0.010947     |   2\n",
      "       1551 |   0.317579  |    0.083834     |   0\n",
      "       1552 |   0.341565  |    0.142565     |   1\n",
      "       1553 |   0.340436  |    0.043216     |   0\n",
      "       1554 |   0.425356  |    0.196899     |   1\n",
      "       1555 |   0.488393  |    0.096057     |   1\n",
      "       1556 |   0.335109  |    0.204146     |   1\n",
      "       1557 |   0.093690  |    0.019959     |   2\n",
      "       1558 |   0.344080  |    0.210359     |   1\n",
      "       1559 |   0.346335  |    0.036854     |   0\n",
      "       1560 |   0.435361  |    0.146997     |   1\n",
      "       1561 |   0.118526  |    0.053670     |   2\n",
      "       1562 |   0.102361  |    0.044213     |   2\n",
      "       1563 |   0.426226  |    0.044213     |   0\n",
      "       1564 |   0.329036  |    0.107258     |   0\n",
      "       1565 |   0.421325  |    0.090617     |   1\n",
      "       1566 |   0.044130  |    0.077319     |   2\n",
      "       1567 |   0.498379  |    0.163354     |   1\n",
      "       1568 |   0.376471  |    0.091872     |   1\n",
      "       1569 |   0.321689  |    0.076418     |   0\n",
      "       1570 |   0.381956  |    0.146444     |   1\n",
      "       1571 |   0.100094  |    0.008410     |   2\n",
      "       1572 |   0.338718  |    0.076382     |   0\n",
      "       1573 |   0.356077  |    0.025242     |   0\n",
      "       1574 |   0.079921  |    0.051010     |   2\n",
      "       1575 |   0.299738  |    0.046400     |   0\n",
      "       1576 |   0.000424  |    0.040890     |   2\n",
      "       1577 |   0.410254  |    0.042948     |   0\n",
      "       1578 |   0.336508  |    0.201149     |   1\n",
      "       1579 |   0.330605  |    0.004769     |   0\n",
      "       1580 |   0.479280  |    0.163224     |   1\n",
      "       1581 |   0.427745  |    0.143773     |   1\n",
      "       1582 |   0.000517  |    0.032131     |   2\n",
      "       1583 |   0.000443  |    0.052601     |   2\n",
      "       1584 |   0.331181  |    0.151670     |   1\n",
      "       1585 |   0.456105  |    0.144981     |   1\n",
      "       1586 |   0.000525  |    0.047479     |   2\n",
      "       1587 |   0.292990  |    0.056135     |   0\n",
      "       1588 |   0.322201  |    0.174078     |   1\n",
      "       1589 |   0.352972  |    0.035477     |   0\n",
      "       1590 |   0.329379  |    0.083415     |   0\n",
      "       1591 |   0.000566  |    0.027209     |   2\n",
      "       1592 |   0.000526  |    0.047307     |   2\n",
      "       1593 |   0.318569  |    0.046351     |   0\n",
      "       1594 |   0.355214  |    0.074162     |   0\n",
      "       1595 |   0.126172  |    0.033355     |   2\n",
      "       1596 |   0.375727  |    0.056666     |   0\n",
      "       1597 |   0.410073  |    0.144266     |   1\n",
      "       1598 |   0.399987  |    0.201328     |   1\n",
      "       1599 |   0.423318  |    0.164080     |   1\n",
      "       1600 |   0.157963  |    0.006578     |   2\n",
      "       1601 |   0.362882  |    0.077104     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 1602: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       1602 |   0.363581  |    0.022320     |   0\n",
      "       1603 |   0.155100  |    0.047722     |   2\n",
      "       1604 |   0.384292  |    0.170822     |   1\n",
      "       1605 |   0.430999  |    0.140433     |   1\n",
      "       1606 |   0.102206  |    0.029947     |   2\n",
      "       1607 |   0.325888  |    0.044109     |   0\n",
      "       1608 |   0.128413  |    0.041935     |   2\n",
      "       1609 |   0.137245  |    0.073097     |   2\n",
      "       1610 |   0.061675  |    0.025256     |   2\n",
      "       1611 |   0.465823  |    0.213056     |   1\n",
      "       1612 |   0.301744  |    0.006422     |   0\n",
      "       1613 |   0.359033  |    0.045076     |   0\n",
      "       1614 |   0.361546  |    0.080669     |   0\n",
      "       1615 |   0.124387  |    0.006357     |   2\n",
      "       1616 |   0.542958  |    0.218968     |   1\n",
      "       1617 |   0.356780  |    0.154842     |   1\n",
      "       1618 |   0.105063  |    0.005203     |   2\n",
      "       1619 |   0.111766  |    0.086116     |   2\n",
      "       1620 |   0.270100  |    0.015928     |   0\n",
      "       1621 |   0.392081  |    0.186583     |   1\n",
      "       1622 |   0.112891  |    0.043340     |   2\n",
      "       1623 |   0.046525  |    0.045247     |   2\n",
      "       1624 |   0.000416  |    0.073368     |   2\n",
      "       1625 |   0.010566  |    0.022109     |   2\n",
      "       1626 |   0.281034  |    0.076270     |   0\n",
      "       1627 |   0.301395  |    0.027278     |   0\n",
      "       1628 |   0.320475  |    0.174354     |   1\n",
      "       1629 |   0.413977  |    0.042864     |   0\n",
      "       1630 |   0.441022  |    0.048257     |   0\n",
      "       1631 |   0.217756  |    0.029629     |   2\n",
      "       1632 |   0.090270  |    0.052288     |   2\n",
      "       1633 |   0.372993  |    0.213494     |   1\n",
      "       1634 |   0.298208  |    0.153304     |   1\n",
      "       1635 |   0.314066  |    0.155646     |   1\n",
      "       1636 |   0.375042  |    0.032947     |   0\n",
      "       1637 |   0.330832  |    0.161532     |   1\n",
      "       1638 |   0.247320  |    0.040469     |   0\n",
      "       1639 |   0.116407  |    0.044569     |   2\n",
      "       1640 |   0.350825  |    0.043895     |   0\n",
      "       1641 |   0.099070  |    0.043701     |   2\n",
      "       1642 |   0.042972  |    0.075979     |   2\n",
      "       1643 |   0.343201  |    0.026740     |   0\n",
      "       1644 |   0.097890  |    0.073899     |   2\n",
      "       1645 |   0.328785  |    0.023108     |   0\n",
      "       1646 |   0.078257  |    0.054681     |   2\n",
      "       1647 |   0.340167  |    0.185325     |   1\n",
      "       1648 |   0.356025  |    0.064901     |   0\n",
      "       1649 |   0.342753  |    0.196861     |   1\n",
      "       1650 |   0.324378  |    0.007642     |   0\n",
      "       1651 |   0.313483  |    0.080415     |   0\n",
      "       1652 |   0.441128  |    0.202681     |   1\n",
      "       1653 |   0.422213  |    0.145611     |   1\n",
      "       1654 |   0.000402  |    0.011349     |   2\n",
      "       1655 |   0.000509  |    0.082436     |   2\n",
      "       1656 |   0.000420  |    0.020844     |   2\n",
      "       1657 |   0.351073  |    0.169332     |   1\n",
      "       1658 |   0.000513  |    0.043729     |   2\n",
      "       1659 |   0.359137  |    0.042515     |   0\n",
      "       1660 |   0.386548  |    0.078229     |   0\n",
      "       1661 |   0.388489  |    0.030928     |   0\n",
      "       1662 |   0.365378  |    0.147708     |   1\n",
      "       1663 |   0.000541  |    0.081970     |   2\n",
      "       1664 |   0.317583  |    0.020157     |   0\n",
      "       1665 |   0.293119  |    0.078136     |   0\n",
      "       1666 |   0.000504  |    0.032164     |   2\n",
      "       1667 |   0.393160  |    0.189489     |   1\n",
      "       1668 |   0.125654  |    0.009165     |   2\n",
      "       1669 |   0.361110  |    0.078980     |   0\n",
      "       1670 |   0.562465  |    0.147725     |   1\n",
      "       1671 |   0.289393  |    0.014480     |   0\n",
      "       1672 |   0.156213  |    0.068352     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 1673: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       1673 |   0.295141  |    0.158740     |   1\n",
      "       1674 |   0.342147  |    0.185686     |   1\n",
      "       1675 |   0.151291  |    0.013387     |   2\n",
      "       1676 |   0.097463  |    0.080326     |   2\n",
      "       1677 |   0.125701  |    0.019284     |   2\n",
      "       1678 |   0.271620  |    0.050115     |   0\n",
      "       1679 |   0.134104  |    0.054654     |   2\n",
      "       1680 |   0.320662  |    0.041431     |   0\n",
      "       1681 |   0.369207  |    0.040117     |   0\n",
      "       1682 |   0.059925  |    0.055907     |   2\n",
      "       1683 |   0.284375  |    0.151055     |   1\n",
      "       1684 |   0.123716  |    0.071007     |   2\n",
      "       1685 |   0.351919  |    0.153267     |   1\n",
      "       1686 |   0.295709  |    0.183806     |   1\n",
      "       1687 |   0.341793  |    0.015088     |   0\n",
      "       1688 |   0.373898  |    0.074370     |   0\n",
      "       1689 |   0.105210  |    0.026922     |   2\n",
      "       1690 |   0.465209  |    0.202250     |   1\n",
      "       1691 |   0.308413  |    0.005622     |   0\n",
      "       1692 |   0.111531  |    0.047149     |   2\n",
      "       1693 |   0.273151  |    0.043298     |   0\n",
      "       1694 |   0.298489  |    0.040112     |   0\n",
      "       1695 |   0.432718  |    0.156406     |   1\n",
      "       1696 |   0.339454  |    0.042518     |   0\n",
      "       1697 |   0.366736  |    0.205000     |   1\n",
      "       1698 |   0.104838  |    0.030728     |   2\n",
      "       1699 |   0.348531  |    0.193065     |   1\n",
      "       1700 |   0.046553  |    0.011331     |   2\n",
      "       1701 |   0.000389  |    0.084913     |   2\n",
      "       1702 |   0.269550  |    0.015576     |   0\n",
      "       1703 |   0.405167  |    0.076986     |   0\n",
      "       1704 |   0.344357  |    0.051094     |   0\n",
      "       1705 |   0.010836  |    0.042877     |   2\n",
      "       1706 |   0.220557  |    0.053924     |   2\n",
      "       1707 |   0.363156  |    0.186675     |   1\n",
      "       1708 |   0.322708  |    0.014340     |   0\n",
      "       1709 |   0.339985  |    0.070460     |   0\n",
      "       1710 |   0.091384  |    0.041741     |   2\n",
      "       1711 |   0.225914  |    0.042313     |   0\n",
      "       1712 |   0.119234  |    0.028785     |   2\n",
      "       1713 |   0.341264  |    0.074808     |   0\n",
      "       1714 |   0.362814  |    0.029092     |   0\n",
      "       1715 |   0.325149  |    0.055057     |   0\n",
      "       1716 |   0.104753  |    0.050637     |   2\n",
      "       1717 |   0.320972  |    0.048226     |   0\n",
      "       1718 |   0.372394  |    0.162959     |   1\n",
      "       1719 |   0.044910  |    0.034855     |   2\n",
      "       1720 |   0.102214  |    0.050110     |   2\n",
      "       1721 |   0.281869  |    0.080933     |   0\n",
      "       1722 |   0.078131  |    0.007529     |   2\n",
      "       1723 |   0.318287  |    0.081549     |   0\n",
      "       1724 |   0.000388  |    0.022786     |   2\n",
      "       1725 |   0.000502  |    0.079716     |   2\n",
      "       1726 |   0.000407  |    0.007059     |   2\n",
      "       1727 |   0.000513  |    0.085272     |   2\n",
      "       1728 |   0.491609  |    0.190840     |   1\n",
      "       1729 |   0.343125  |    0.010319     |   0\n",
      "       1730 |   0.255172  |    0.050347     |   0\n",
      "       1731 |   0.412541  |    0.148481     |   1\n",
      "       1732 |   0.000535  |    0.033597     |   2\n",
      "       1733 |   0.372130  |    0.199667     |   1\n",
      "       1734 |   0.377077  |    0.132787     |   1\n",
      "       1735 |   0.000493  |    0.069684     |   2\n",
      "       1736 |   0.128174  |    0.046530     |   2\n",
      "       1737 |   0.155391  |    0.039660     |   2\n",
      "       1738 |   0.308548  |    0.077995     |   0\n",
      "       1739 |   0.328721  |    0.011151     |   0\n",
      "       1740 |   0.355637  |    0.076846     |   0\n",
      "       1741 |   0.326753  |    0.010275     |   0\n",
      "       1742 |   0.478476  |    0.153525     |   1\n",
      "       1743 |   0.263153  |    0.041639     |   0\n",
      "       1744 |   0.390678  |    0.192943     |   1\n",
      "       1745 |   0.322142  |    0.171882     |   1\n",
      "       1746 |   0.408846  |    0.141212     |   1\n",
      "       1747 |   0.303600  |    0.020392     |   0\n",
      "       1748 |   0.275343  |    0.051979     |   0\n",
      "       1749 |   0.371973  |    0.186834     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 1750: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       1750 |   0.157762  |    0.029178     |   2\n",
      "       1751 |   0.269635  |    0.049116     |   0\n",
      "       1752 |   0.102187  |    0.076089     |   2\n",
      "       1753 |   0.125046  |    0.021508     |   2\n",
      "       1754 |   0.392420  |    0.202298     |   1\n",
      "       1755 |   0.353124  |    0.149610     |   1\n",
      "       1756 |   0.136791  |    0.028157     |   2\n",
      "       1757 |   0.491672  |    0.209623     |   1\n",
      "       1758 |   0.060604  |    0.008816     |   2\n",
      "       1759 |   0.426974  |    0.190660     |   1\n",
      "       1760 |   0.119181  |    0.017262     |   2\n",
      "       1761 |   0.105061  |    0.074228     |   2\n",
      "       1762 |   0.108925  |    0.021264     |   2\n",
      "       1763 |   0.259316  |    0.078051     |   0\n",
      "       1764 |   0.107766  |    0.024597     |   2\n",
      "       1765 |   0.345223  |    0.217531     |   1\n",
      "       1766 |   0.358430  |    0.145927     |   1\n",
      "       1767 |   0.311465  |    0.016249     |   0\n",
      "       1768 |   0.044246  |    0.054671     |   2\n",
      "       1769 |   0.000384  |    0.051863     |   2\n",
      "       1770 |   0.010704  |    0.052127     |   2\n",
      "       1771 |   0.213209  |    0.042519     |   2\n",
      "       1772 |   0.299563  |    0.041950     |   0\n",
      "       1773 |   0.088452  |    0.042192     |   2\n",
      "       1774 |   0.116815  |    0.070482     |   2\n",
      "       1775 |   0.321247  |    0.042521     |   0\n",
      "       1776 |   0.097722  |    0.043865     |   2\n",
      "       1777 |   0.045248  |    0.034080     |   2\n",
      "       1778 |   0.097715  |    0.079490     |   2\n",
      "       1779 |   0.355393  |    0.037902     |   0\n",
      "       1780 |   0.350718  |    0.206327     |   1\n",
      "       1781 |   0.309350  |    0.008551     |   0\n",
      "       1782 |   0.241014  |    0.040851     |   0\n",
      "       1783 |   0.076126  |    0.044526     |   2\n",
      "       1784 |   0.359500  |    0.045874     |   0\n",
      "       1785 |   0.442040  |    0.212401     |   1\n",
      "       1786 |   0.335803  |    0.004971     |   0\n",
      "       1787 |   0.000333  |    0.027058     |   2\n",
      "       1788 |   0.403923  |    0.152984     |   1\n",
      "       1789 |   0.296275  |    0.143885     |   1\n",
      "       1790 |   0.373775  |    0.143282     |   1\n",
      "       1791 |   0.000428  |    0.074228     |   2\n",
      "       1792 |   0.318499  |    0.043011     |   0\n",
      "       1793 |   0.322693  |    0.044516     |   0\n",
      "       1794 |   0.000358  |    0.047917     |   2\n",
      "       1795 |   0.363610  |    0.074664     |   0\n",
      "       1796 |   0.330570  |    0.134901     |   1\n",
      "       1797 |   0.307167  |    0.054417     |   0\n",
      "       1798 |   0.345970  |    0.148155     |   1\n",
      "       1799 |   0.000450  |    0.045561     |   2\n",
      "       1800 |   0.304402  |    0.043451     |   0\n",
      "       1801 |   0.383503  |    0.094320     |   0\n",
      "       1802 |   0.346983  |    0.154658     |   1\n",
      "       1803 |   0.000474  |    0.008284     |   2\n",
      "       1804 |   0.000446  |    0.090247     |   2\n",
      "       1805 |   0.119533  |    0.009745     |   2\n",
      "       1806 |   0.300030  |    0.072338     |   0\n",
      "       1807 |   0.346904  |    0.149456     |   1\n",
      "       1808 |   0.150853  |    0.068066     |   2\n",
      "       1809 |   0.414842  |    0.150893     |   1\n",
      "       1810 |   0.311439  |    0.165033     |   1\n",
      "       1811 |   0.309023  |    0.015356     |   0\n",
      "       1812 |   0.400441  |    0.208163     |   1\n",
      "       1813 |   0.390731  |    0.101048     |   1\n",
      "       1814 |   0.355964  |    0.200397     |   1\n",
      "       1815 |   0.311092  |    0.006946     |   0\n",
      "       1816 |   0.331307  |    0.047320     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 1817: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       1817 |   0.146971  |    0.047780     |   2\n",
      "       1818 |   0.095132  |    0.044075     |   2\n",
      "       1819 |   0.380879  |    0.202174     |   1\n",
      "       1820 |   0.118384  |    0.005517     |   2\n",
      "       1821 |   0.351166  |    0.080727     |   0\n",
      "       1822 |   0.132789  |    0.027943     |   2\n",
      "       1823 |   0.356105  |    0.078396     |   0\n",
      "       1824 |   0.057442  |    0.031640     |   2\n",
      "       1825 |   0.406595  |    0.151705     |   1\n",
      "       1826 |   0.113852  |    0.040980     |   2\n",
      "       1827 |   0.393351  |    0.072922     |   0\n",
      "       1828 |   0.359147  |    0.037093     |   0\n",
      "       1829 |   0.227734  |    0.185854     |   1\n",
      "       1830 |   0.356406  |    0.138643     |   1\n",
      "       1831 |   0.288879  |    0.062872     |   0\n",
      "       1832 |   0.414340  |    0.152469     |   1\n",
      "       1833 |   0.103985  |    0.079690     |   2\n",
      "       1834 |   0.107797  |    0.014272     |   2\n",
      "       1835 |   0.389610  |    0.209509     |   1\n",
      "       1836 |   0.455561  |    0.143286     |   1\n",
      "       1837 |   0.105817  |    0.005191     |   2\n",
      "       1838 |   0.366046  |    0.190916     |   1\n",
      "       1839 |   0.318125  |    0.155002     |   1\n",
      "       1840 |   0.042982  |    0.043472     |   2\n",
      "       1841 |   0.000346  |    0.074807     |   2\n",
      "       1842 |   0.201870  |    0.011621     |   0\n",
      "       1843 |   0.366856  |    0.076964     |   0\n",
      "       1844 |   0.338821  |    0.029004     |   0\n",
      "       1845 |   0.365413  |    0.165782     |   1\n",
      "       1846 |   0.297762  |    0.163456     |   1\n",
      "       1847 |   0.010180  |    0.044845     |   2\n",
      "       1848 |   0.283039  |    0.152310     |   1\n",
      "       1849 |   0.312240  |    0.040469     |   0\n",
      "       1850 |   0.475250  |    0.161845     |   1\n",
      "       1851 |   0.330954  |    0.151609     |   1\n",
      "       1852 |   0.213561  |    0.005818     |   2\n",
      "       1853 |   0.302976  |    0.080081     |   0\n",
      "       1854 |   0.088167  |    0.020786     |   2\n",
      "       1855 |   0.314027  |    0.075541     |   0\n",
      "       1856 |   0.113882  |    0.008686     |   2\n",
      "       1857 |   0.098668  |    0.093377     |   2\n",
      "       1858 |   0.305774  |    0.162857     |   1\n",
      "       1859 |   0.316328  |    0.162827     |   1\n",
      "       1860 |   0.281876  |    0.150505     |   1\n",
      "       1861 |   0.317082  |    0.045970     |   0\n",
      "       1862 |   0.380724  |    0.040124     |   0\n",
      "       1863 |   0.372175  |    0.161123     |   1\n",
      "       1864 |   0.380689  |    0.139201     |   1\n",
      "       1865 |   0.285028  |    0.017734     |   0\n",
      "       1866 |   0.437188  |    0.195701     |   1\n",
      "       1867 |   0.041363  |    0.009990     |   2\n",
      "       1868 |   0.387291  |    0.188936     |   1\n",
      "       1869 |   0.098600  |    0.024987     |   2\n",
      "       1870 |   0.305932  |    0.076825     |   0\n",
      "       1871 |   0.075585  |    0.019346     |   2\n",
      "       1872 |   0.360488  |    0.197271     |   1\n",
      "       1873 |   0.299727  |    0.011771     |   0\n",
      "       1874 |   0.365461  |    0.084578     |   0\n",
      "       1875 |   0.000314  |    0.015813     |   2\n",
      "       1876 |   0.356943  |    0.073839     |   0\n",
      "       1877 |   0.398687  |    0.152505     |   1\n",
      "       1878 |   0.264624  |    0.005460     |   0\n",
      "       1879 |   0.303240  |    0.047446     |   0\n",
      "       1880 |   0.000397  |    0.045532     |   2\n",
      "       1881 |   0.000352  |    0.076450     |   2\n",
      "       1882 |   0.291569  |    0.024308     |   0\n",
      "       1883 |   0.310877  |    0.195292     |   1\n",
      "       1884 |   0.320583  |    0.014894     |   0\n",
      "       1885 |   0.000421  |    0.073153     |   2\n",
      "       1886 |   0.326650  |    0.043332     |   0\n",
      "       1887 |   0.000448  |    0.031901     |   2\n",
      "       1888 |   0.356738  |    0.208115     |   1\n",
      "       1889 |   0.305763  |    0.158327     |   1\n",
      "       1890 |   0.321424  |    0.147965     |   1\n",
      "       1891 |   0.290757  |    0.057340     |   0\n",
      "       1892 |   0.335777  |    0.159539     |   1\n",
      "       1893 |   0.000427  |    0.008423     |   2\n",
      "       1894 |   0.119679  |    0.079443     |   2\n",
      "       1895 |   0.351251  |    0.150521     |   1\n",
      "       1896 |   0.333832  |    0.150452     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 1898: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       1897 |   0.147001  |    0.016546     |   2\n",
      "       1898 |   0.321212  |    0.049613     |   0\n",
      "       1899 |   0.439354  |    0.139787     |   1\n",
      "       1900 |   0.302000  |    0.038486     |   0\n",
      "       1901 |   0.144867  |    0.038877     |   2\n",
      "       1902 |   0.095544  |    0.041473     |   2\n",
      "       1903 |   0.352353  |    0.066889     |   0\n",
      "       1904 |   0.117736  |    0.038237     |   2\n",
      "       1905 |   0.130770  |    0.085777     |   2\n",
      "       1906 |   0.376279  |    0.152782     |   1\n",
      "       1907 |   0.056819  |    0.012621     |   2\n",
      "       1908 |   0.354881  |    0.077286     |   0\n",
      "       1909 |   0.111005  |    0.019934     |   2\n",
      "       1910 |   0.330574  |    0.075366     |   0\n",
      "       1911 |   0.100230  |    0.043135     |   2\n",
      "       1912 |   0.308815  |    0.043471     |   0\n",
      "       1913 |   0.316159  |    0.079690     |   0\n",
      "       1914 |   0.106028  |    0.010766     |   2\n",
      "       1915 |   0.104545  |    0.077759     |   2\n",
      "       1916 |   0.041664  |    0.014458     |   2\n",
      "       1917 |   0.317799  |    0.043717     |   0\n",
      "       1918 |   0.273261  |    0.050558     |   0\n",
      "       1919 |   0.417068  |    0.159580     |   1\n",
      "       1920 |   0.308395  |    0.143057     |   1\n",
      "       1921 |   0.363671  |    0.150235     |   1\n",
      "       1922 |   0.344999  |    0.152920     |   1\n",
      "       1923 |   0.314127  |    0.027641     |   0\n",
      "       1924 |   0.323012  |    0.215737     |   1\n",
      "       1925 |   0.403476  |    0.095169     |   1\n",
      "       1926 |   0.000312  |    0.022640     |   2\n",
      "       1927 |   0.010313  |    0.074181     |   2\n",
      "       1928 |   0.206284  |    0.026416     |   2\n",
      "       1929 |   0.259423  |    0.042293     |   0\n",
      "       1930 |   0.086753  |    0.046115     |   2\n",
      "       1931 |   0.319157  |    0.050835     |   0\n",
      "       1932 |   0.372725  |    0.082186     |   0\n",
      "       1933 |   0.108392  |    0.021144     |   2\n",
      "       1934 |   0.292548  |    0.041333     |   0\n",
      "       1935 |   0.358202  |    0.169272     |   1\n",
      "       1936 |   0.385612  |    0.143503     |   1\n",
      "       1937 |   0.328105  |    0.039633     |   0\n",
      "       1938 |   0.321041  |    0.184262     |   1\n",
      "       1939 |   0.276064  |    0.010914     |   0\n",
      "       1940 |   0.095172  |    0.085964     |   2\n",
      "       1941 |   0.412992  |    0.150602     |   1\n",
      "       1942 |   0.413841  |    0.105930     |   1\n",
      "       1943 |   0.041281  |    0.045430     |   2\n",
      "       1944 |   0.296055  |    0.043005     |   0\n",
      "       1945 |   0.293512  |    0.168512     |   1\n",
      "       1946 |   0.345564  |    0.027941     |   0\n",
      "       1947 |   0.095398  |    0.048628     |   2\n",
      "       1948 |   0.344318  |    0.084408     |   0\n",
      "       1949 |   0.072762  |    0.012939     |   2\n",
      "       1950 |   0.000303  |    0.054111     |   2\n",
      "       1951 |   0.308481  |    0.085240     |   0\n",
      "       1952 |   0.426630  |    0.140261     |   1\n",
      "       1953 |   0.000402  |    0.042635     |   2\n",
      "       1954 |   0.365495  |    0.148404     |   1\n",
      "       1955 |   0.284036  |    0.049335     |   0\n",
      "       1956 |   0.311654  |    0.161408     |   1\n",
      "       1957 |   0.313462  |    0.160776     |   1\n",
      "       1958 |   0.250307  |    0.009745     |   0\n",
      "       1959 |   0.270982  |    0.085004     |   0\n",
      "       1960 |   0.000351  |    0.016028     |   2\n",
      "       1961 |   0.000423  |    0.077294     |   2\n",
      "       1962 |   0.361527  |    0.141374     |   1\n",
      "       1963 |   0.331161  |    0.042818     |   0\n",
      "       1964 |   0.000421  |    0.079390     |   2\n",
      "       1965 |   0.246832  |    0.163899     |   1\n",
      "       1966 |   0.427777  |    0.140069     |   1\n",
      "       1967 |   0.000400  |    0.003587     |   2\n",
      "       1968 |   0.358371  |    0.041393     |   0\n",
      "       1969 |   0.121619  |    0.043301     |   2\n",
      "       1970 |   0.144535  |    0.088970     |   2\n",
      "       1971 |   0.357671  |    0.156483     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 1972: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       1972 |   0.402387  |    0.142194     |   1\n",
      "       1973 |   0.301905  |    0.077525     |   0\n",
      "       1974 |   0.146167  |    0.026859     |   2\n",
      "       1975 |   0.405470  |    0.083826     |   0\n",
      "       1976 |   0.331449  |    0.028468     |   0\n",
      "       1977 |   0.259237  |    0.048423     |   0\n",
      "       1978 |   0.357478  |    0.076275     |   0\n",
      "       1979 |   0.264246  |    0.028394     |   0\n",
      "       1980 |   0.322512  |    0.074946     |   0\n",
      "       1981 |   0.092339  |    0.027367     |   2\n",
      "       1982 |   0.303681  |    0.078272     |   0\n",
      "       1983 |   0.117709  |    0.019951     |   2\n",
      "       1984 |   0.328320  |    0.069889     |   0\n",
      "       1985 |   0.352837  |    0.175993     |   1\n",
      "       1986 |   0.355003  |    0.180253     |   1\n",
      "       1987 |   0.307206  |    0.161795     |   1\n",
      "       1988 |   0.312350  |    0.138734     |   1\n",
      "       1989 |   0.130747  |    0.029452     |   2\n",
      "       1990 |   0.312468  |    0.197609     |   1\n",
      "       1991 |   0.057612  |    0.004063     |   2\n",
      "       1992 |   0.367021  |    0.152616     |   1\n",
      "       1993 |   0.113711  |    0.055115     |   2\n",
      "       1994 |   0.101898  |    0.040414     |   2\n",
      "       1995 |   0.104189  |    0.047939     |   2\n",
      "       1996 |   0.283464  |    0.070431     |   0\n",
      "       1997 |   0.279251  |    0.046089     |   0\n",
      "       1998 |   0.340010  |    0.160752     |   1\n",
      "       1999 |   0.404900  |    0.149240     |   1\n",
      "       2000 |   0.379961  |    0.145062     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 2000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 2000: Plotting estimates.\n",
      "Exception in thread neuralnilm-data-process:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 810, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/jack/workspace/python/neuralnilm/neuralnilm/data/datathread.py\", line 16, in run\n",
      "    batch = self.data_pipeline.get_batch(**self._get_batch_kwargs)\n",
      "  File \"/home/jack/workspace/python/neuralnilm/neuralnilm/data/datapipeline.py\", line 46, in get_batch\n",
      "    batch = self._source_iterators[source_id].next()\n",
      "ValueError: generator already executing\n",
      "\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       2001 |   0.320325  |    0.225798     |   1\n",
      "       2002 |   0.135495  |    0.009486     |   2\n",
      "       2003 |   0.086480  |    0.083423     |   2\n",
      "       2004 |   0.350776  |    0.141794     |   1\n",
      "       2005 |   0.442085  |    0.192061     |   1\n",
      "       2006 |   0.110075  |    0.018339     |   2\n",
      "       2007 |   0.332925  |    0.215636     |   1\n",
      "       2008 |   0.304002  |    0.007030     |   0\n",
      "       2009 |   0.386228  |    0.140523     |   1\n",
      "       2010 |   0.280812  |    0.055864     |   0\n",
      "       2011 |   0.324066  |    0.170774     |   1\n",
      "       2012 |   0.363277  |    0.160652     |   1\n",
      "       2013 |   0.350151  |    0.188592     |   1\n",
      "       2014 |   0.375939  |    0.166187     |   1\n",
      "       2015 |   0.125471  |    0.021434     |   2\n",
      "       2016 |   0.432215  |    0.167129     |   1\n",
      "       2017 |   0.314586  |    0.046559     |   0\n",
      "       2018 |   0.054564  |    0.042338     |   2\n",
      "       2019 |   0.349526  |    0.077652     |   0\n",
      "       2020 |   0.109192  |    0.029608     |   2\n",
      "       2021 |   0.304410  |    0.048645     |   0\n",
      "       2022 |   0.097755  |    0.077217     |   2\n",
      "       2023 |   0.104344  |    0.013030     |   2\n",
      "       2024 |   0.099494  |    0.081979     |   2\n",
      "       2025 |   0.041545  |    0.028407     |   2\n",
      "       2026 |   0.000288  |    0.048878     |   2\n",
      "       2027 |   0.281121  |    0.215908     |   1\n",
      "       2028 |   0.447237  |    0.107433     |   1\n",
      "       2029 |   0.245164  |    0.045852     |   0\n",
      "       2030 |   0.284798  |    0.053165     |   0\n",
      "       2031 |   0.505996  |    0.151003     |   1\n",
      "       2032 |   0.369540  |    0.191101     |   1\n",
      "       2033 |   0.268979  |    0.023849     |   0\n",
      "       2034 |   0.011267  |    0.067696     |   2\n",
      "       2035 |   0.311303  |    0.043070     |   0\n",
      "       2036 |   0.199557  |    0.050653     |   2\n",
      "       2037 |   0.298738  |    0.038958     |   0\n",
      "       2038 |   0.274017  |    0.075807     |   0\n",
      "       2039 |   0.082826  |    0.016707     |   2\n",
      "       2040 |   0.109212  |    0.048730     |   2\n",
      "       2041 |   0.093896  |    0.073333     |   2\n",
      "       2042 |   0.343952  |    0.142328     |   1\n",
      "       2043 |   0.041144  |    0.040785     |   2\n",
      "       2044 |   0.326814  |    0.040479     |   0\n",
      "       2045 |   0.340086  |    0.072556     |   0\n",
      "       2046 |   0.400802  |    0.147926     |   1\n",
      "       2047 |   0.324180  |    0.202547     |   1\n",
      "       2048 |   0.347020  |    0.008485     |   0\n",
      "       2049 |   0.404064  |    0.130921     |   1\n",
      "       2050 |   0.091893  |    0.047595     |   2\n",
      "       2051 |   0.072856  |    0.039101     |   2\n",
      "       2052 |   0.000269  |    0.079358     |   2\n",
      "       2053 |   0.000359  |    0.027650     |   2\n",
      "       2054 |   0.390251  |    0.205918     |   1\n",
      "       2055 |   0.271021  |    0.011378     |   0\n",
      "       2056 |   0.285640  |    0.163228     |   1\n",
      "       2057 |   0.265737  |    0.047231     |   0\n",
      "       2058 |   0.000308  |    0.045625     |   2\n",
      "       2059 |   0.331481  |    0.197170     |   1\n",
      "       2060 |   0.327845  |    0.005282     |   0\n",
      "       2061 |   0.373912  |    0.198057     |   1\n",
      "       2062 |   0.000374  |    0.007336     |   2\n",
      "       2063 |   0.267842  |    0.049864     |   0\n",
      "       2064 |   0.396710  |    0.151764     |   1\n",
      "       2065 |   0.279127  |    0.051312     |   0\n",
      "       2066 |   0.000374  |    0.048161     |   2\n",
      "       2067 |   0.000371  |    0.032631     |   2\n",
      "       2068 |   0.329856  |    0.196254     |   1\n",
      "       2069 |   0.113193  |    0.007939     |   2\n",
      "       2070 |   0.240411  |    0.144675     |   1\n",
      "       2071 |   0.416390  |    0.153086     |   1\n",
      "       2072 |   0.298215  |    0.040601     |   0\n",
      "       2073 |   0.140383  |    0.073552     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 2075: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       2074 |   0.260260  |    0.025222     |   0\n",
      "       2075 |   0.137213  |    0.044077     |   2\n",
      "       2076 |   0.341946  |    0.077961     |   0\n",
      "       2077 |   0.364790  |    0.096134     |   1\n",
      "       2078 |   0.088562  |    0.076925     |   2\n",
      "       2079 |   0.111372  |    0.018985     |   2\n",
      "       2080 |   0.312730  |    0.208801     |   1\n",
      "       2081 |   0.276003  |    0.023335     |   0\n",
      "       2082 |   0.330436  |    0.046464     |   0\n",
      "       2083 |   0.123752  |    0.042941     |   2\n",
      "       2084 |   0.314067  |    0.079917     |   0\n",
      "       2085 |   0.294657  |    0.012440     |   0\n",
      "       2086 |   0.054841  |    0.051584     |   2\n",
      "       2087 |   0.305106  |    0.150482     |   1\n",
      "       2088 |   0.108237  |    0.042059     |   2\n",
      "       2089 |   0.327496  |    0.191867     |   1\n",
      "       2090 |   0.100409  |    0.016997     |   2\n",
      "       2091 |   0.298405  |    0.084839     |   0\n",
      "       2092 |   0.103918  |    0.009802     |   2\n",
      "       2093 |   0.287719  |    0.076731     |   0\n",
      "       2094 |   0.340667  |    0.155542     |   1\n",
      "       2095 |   0.378762  |    0.150738     |   1\n",
      "       2096 |   0.282031  |    0.015672     |   0\n",
      "       2097 |   0.096999  |    0.078888     |   2\n",
      "       2098 |   0.334540  |    0.217167     |   1\n",
      "       2099 |   0.041151  |    0.007139     |   2\n",
      "       2100 |   0.000292  |    0.028910     |   2\n",
      "       2101 |   0.351200  |    0.200709     |   1\n",
      "       2102 |   0.334546  |    0.141366     |   1\n",
      "       2103 |   0.010551  |    0.028679     |   2\n",
      "       2104 |   0.205762  |    0.055552     |   2\n",
      "       2105 |   0.368750  |    0.151669     |   1\n",
      "       2106 |   0.084202  |    0.023851     |   2\n",
      "       2107 |   0.246150  |    0.197660     |   1\n",
      "       2108 |   0.377118  |    0.140096     |   1\n",
      "       2109 |   0.115446  |    0.043340     |   2\n",
      "       2110 |   0.094963  |    0.072170     |   2\n",
      "       2111 |   0.274443  |    0.022492     |   0\n",
      "       2112 |   0.277098  |    0.049201     |   0\n",
      "       2113 |   0.376047  |    0.140350     |   1\n",
      "       2114 |   0.041098  |    0.043055     |   2\n",
      "       2115 |   0.282993  |    0.214986     |   1\n",
      "       2116 |   0.322512  |    0.141156     |   1\n",
      "       2117 |   0.088967  |    0.022945     |   2\n",
      "       2118 |   0.323209  |    0.190324     |   1\n",
      "       2119 |   0.070726  |    0.015843     |   2\n",
      "       2120 |   0.285514  |    0.053612     |   0\n",
      "       2121 |   0.000256  |    0.087896     |   2\n",
      "       2122 |   0.277786  |    0.167385     |   1\n",
      "       2123 |   0.000342  |    0.019946     |   2\n",
      "       2124 |   0.358000  |    0.080026     |   0\n",
      "       2125 |   0.320217  |    0.183082     |   1\n",
      "       2126 |   0.000299  |    0.003816     |   2\n",
      "       2127 |   0.264580  |    0.197162     |   1\n",
      "       2128 |   0.255125  |    0.019261     |   0\n",
      "       2129 |   0.000365  |    0.049180     |   2\n",
      "       2130 |   0.343936  |    0.146572     |   1\n",
      "       2131 |   0.000351  |    0.044689     |   2\n",
      "       2132 |   0.000347  |    0.044333     |   2\n",
      "       2133 |   0.310808  |    0.052042     |   0\n",
      "       2134 |   0.300464  |    0.046120     |   0\n",
      "       2135 |   0.109533  |    0.068136     |   2\n",
      "       2136 |   0.325888  |    0.156250     |   1\n",
      "       2137 |   0.328954  |    0.189177     |   1\n",
      "       2138 |   0.261223  |    0.007836     |   0\n",
      "       2139 |   0.316702  |    0.071157     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 2141: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       2140 |   0.137978  |    0.025592     |   2\n",
      "       2141 |   0.131339  |    0.048178     |   2\n",
      "       2142 |   0.088009  |    0.042614     |   2\n",
      "       2143 |   0.108177  |    0.042168     |   2\n",
      "       2144 |   0.333833  |    0.076409     |   0\n",
      "       2145 |   0.121614  |    0.013017     |   2\n",
      "       2146 |   0.054540  |    0.074596     |   2\n",
      "       2147 |   0.360013  |    0.051459     |   0\n",
      "       2148 |   0.340735  |    0.148384     |   1\n",
      "       2149 |   0.268654  |    0.053937     |   0\n",
      "       2150 |   0.298734  |    0.039960     |   0\n",
      "       2151 |   0.291346  |    0.046204     |   0\n",
      "       2152 |   0.103419  |    0.050907     |   2\n",
      "       2153 |   0.096296  |    0.073801     |   2\n",
      "       2154 |   0.248988  |    0.017327     |   0\n",
      "       2155 |   0.297707  |    0.086198     |   0\n",
      "       2156 |   0.380841  |    0.159521     |   1\n",
      "       2157 |   0.099691  |    0.003978     |   2\n",
      "       2158 |   0.096757  |    0.086347     |   2\n",
      "       2159 |   0.340284  |    0.086595     |   1\n",
      "       2160 |   0.320501  |    0.049828     |   0\n",
      "       2161 |   0.039773  |    0.042617     |   2\n",
      "       2162 |   0.331737  |    0.042293     |   0\n",
      "       2163 |   0.265136  |    0.045514     |   0\n",
      "       2164 |   0.234819  |    0.048075     |   0\n",
      "       2165 |   0.000279  |    0.074612     |   2\n",
      "       2166 |   0.252716  |    0.016009     |   0\n",
      "       2167 |   0.237284  |    0.048450     |   0\n",
      "       2168 |   0.309653  |    0.072950     |   0\n",
      "       2169 |   0.354826  |    0.149885     |   1\n",
      "       2170 |   0.010653  |    0.010280     |   2\n",
      "       2171 |   0.199001  |    0.084061     |   2\n",
      "       2172 |   0.083160  |    0.020948     |   2\n",
      "       2173 |   0.268735  |    0.078269     |   0\n",
      "       2174 |   0.319246  |    0.015109     |   0\n",
      "       2175 |   0.222236  |    0.050040     |   0\n",
      "       2176 |   0.316376  |    0.194021     |   1\n",
      "       2177 |   0.374713  |    0.144995     |   1\n",
      "       2178 |   0.114731  |    0.008302     |   2\n",
      "       2179 |   0.095039  |    0.073985     |   2\n",
      "       2180 |   0.292124  |    0.050083     |   0\n",
      "       2181 |   0.040880  |    0.042711     |   2\n",
      "       2182 |   0.406242  |    0.184225     |   1\n",
      "       2183 |   0.302696  |    0.025285     |   0\n",
      "       2184 |   0.297614  |    0.092070     |   0\n",
      "       2185 |   0.289160  |    0.026961     |   0\n",
      "       2186 |   0.311837  |    0.075312     |   0\n",
      "       2187 |   0.090439  |    0.029909     |   2\n",
      "       2188 |   0.070321  |    0.076691     |   2\n",
      "       2189 |   0.311131  |    0.154366     |   1\n",
      "       2190 |   0.349023  |    0.061615     |   0\n",
      "       2191 |   0.000252  |    0.005834     |   2\n",
      "       2192 |   0.000341  |    0.077918     |   2\n",
      "       2193 |   0.361517  |    0.197725     |   1\n",
      "       2194 |   0.362289  |    0.152187     |   1\n",
      "       2195 |   0.275314  |    0.110853     |   1\n",
      "       2196 |   0.395895  |    0.151311     |   1\n",
      "       2197 |   0.440092  |    0.155597     |   1\n",
      "       2198 |   0.391634  |    0.150707     |   1\n",
      "       2199 |   0.267953  |    0.046356     |   0\n",
      "       2200 |   0.345757  |    0.042290     |   0\n",
      "       2201 |   0.000296  |    0.074466     |   2\n",
      "       2202 |   0.294896  |    0.040456     |   0\n",
      "       2203 |   0.000360  |    0.052192     |   2\n",
      "       2204 |   0.000342  |    0.049001     |   2\n",
      "       2205 |   0.296089  |    0.050221     |   0\n",
      "       2206 |   0.254640  |    0.031250     |   0\n",
      "       2207 |   0.000345  |    0.077253     |   2\n",
      "       2208 |   0.299681  |    0.017839     |   0\n",
      "       2209 |   0.352862  |    0.224236     |   1\n",
      "       2210 |   0.112819  |    0.007268     |   2\n",
      "       2211 |   0.138185  |    0.083407     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 2212: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       2212 |   0.237284  |    0.009799     |   0\n",
      "       2213 |   0.137956  |    0.086407     |   2\n",
      "       2214 |   0.300556  |    0.157351     |   1\n",
      "       2215 |   0.088268  |    0.010378     |   2\n",
      "       2216 |   0.107434  |    0.089011     |   2\n",
      "       2217 |   0.123665  |    0.019319     |   2\n",
      "       2218 |   0.296075  |    0.077041     |   0\n",
      "       2219 |   0.055064  |    0.043154     |   2\n",
      "       2220 |   0.507433  |    0.159027     |   1\n",
      "       2221 |   0.315340  |    0.140248     |   1\n",
      "       2222 |   0.103865  |    0.027626     |   2\n",
      "       2223 |   0.309681  |    0.075489     |   0\n",
      "       2224 |   0.096057  |    0.023484     |   2\n",
      "       2225 |   0.100194  |    0.081397     |   2\n",
      "       2226 |   0.096006  |    0.042685     |   2\n",
      "       2227 |   0.040099  |    0.044253     |   2\n",
      "       2228 |   0.320397  |    0.045242     |   0\n",
      "       2229 |   0.327495  |    0.191580     |   1\n",
      "       2230 |   0.255352  |    0.004817     |   0\n",
      "       2231 |   0.000282  |    0.078068     |   2\n",
      "       2232 |   0.010053  |    0.023541     |   2\n",
      "       2233 |   0.220942  |    0.044170     |   0\n",
      "       2234 |   0.194425  |    0.051933     |   2\n",
      "       2235 |   0.081301  |    0.043301     |   2\n",
      "       2236 |   0.265219  |    0.059647     |   0\n",
      "       2237 |   0.402475  |    0.144604     |   1\n",
      "       2238 |   0.109431  |    0.044474     |   2\n",
      "       2239 |   0.089064  |    0.042359     |   2\n",
      "       2240 |   0.277970  |    0.073857     |   0\n",
      "       2241 |   0.037391  |    0.022147     |   2\n",
      "       2242 |   0.088420  |    0.084836     |   2\n",
      "       2243 |   0.368518  |    0.140714     |   1\n",
      "       2244 |   0.249217  |    0.064819     |   0\n",
      "       2245 |   0.247653  |    0.155850     |   1\n",
      "       2246 |   0.068795  |    0.041565     |   2\n",
      "       2247 |   0.345076  |    0.080831     |   0\n",
      "       2248 |   0.362174  |    0.164320     |   1\n",
      "       2249 |   0.323138  |    0.148718     |   1\n",
      "       2250 |   0.318094  |    0.025639     |   0\n",
      "       2251 |   0.276350  |    0.164821     |   1\n",
      "       2252 |   0.379499  |    0.198452     |   1\n",
      "       2253 |   0.000240  |    0.006250     |   2\n",
      "       2254 |   0.000320  |    0.033297     |   2\n",
      "       2255 |   0.217631  |    0.051482     |   0\n",
      "       2256 |   0.328927  |    0.189956     |   1\n",
      "       2257 |   0.000284  |    0.026377     |   2\n",
      "       2258 |   0.438190  |    0.181873     |   1\n",
      "       2259 |   0.259376  |    0.180903     |   1\n",
      "       2260 |   0.247747  |    0.049257     |   0\n",
      "       2261 |   0.000347  |    0.048784     |   2\n",
      "       2262 |   0.292155  |    0.043140     |   0\n",
      "       2263 |   0.000329  |    0.047198     |   2\n",
      "       2264 |   0.000342  |    0.077704     |   2\n",
      "       2265 |   0.111185  |    0.029347     |   2\n",
      "       2266 |   0.267901  |    0.072292     |   0\n",
      "       2267 |   0.321302  |    0.039524     |   0\n",
      "       2268 |   0.134657  |    0.047661     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 2269: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       2269 |   0.326611  |    0.044967     |   0\n",
      "       2270 |   0.126067  |    0.072715     |   2\n",
      "       2271 |   0.328868  |    0.016695     |   0\n",
      "       2272 |   0.083427  |    0.082050     |   2\n",
      "       2273 |   0.357973  |    0.023498     |   0\n",
      "       2274 |   0.266044  |    0.071586     |   0\n",
      "       2275 |   0.328059  |    0.043867     |   0\n",
      "       2276 |   0.490331  |    0.142595     |   1\n",
      "       2277 |   0.104580  |    0.038828     |   2\n",
      "       2278 |   0.258755  |    0.043550     |   0\n",
      "       2279 |   0.121993  |    0.055940     |   2\n",
      "       2280 |   0.380056  |    0.148867     |   1\n",
      "       2281 |   0.054916  |    0.021140     |   2\n",
      "       2282 |   0.103667  |    0.057232     |   2\n",
      "       2283 |   0.302412  |    0.147733     |   1\n",
      "       2284 |   0.092718  |    0.076884     |   2\n",
      "       2285 |   0.313997  |    0.206600     |   1\n",
      "       2286 |   0.310930  |    0.141357     |   1\n",
      "       2287 |   0.271314  |    0.025013     |   0\n",
      "       2288 |   0.098527  |    0.080558     |   2\n",
      "       2289 |   0.353975  |    0.050168     |   0\n",
      "       2290 |   0.228857  |    0.046251     |   0\n",
      "       2291 |   0.212700  |    0.038313     |   0\n",
      "       2292 |   0.345348  |    0.215633     |   1\n",
      "       2293 |   0.095346  |    0.005783     |   2\n",
      "       2294 |   0.228326  |    0.049432     |   0\n",
      "       2295 |   0.317146  |    0.229070     |   1\n",
      "       2296 |   0.040624  |    0.034061     |   2\n",
      "       2297 |   0.279302  |    0.081569     |   0\n",
      "       2298 |   0.440863  |    0.149440     |   1\n",
      "       2299 |   0.284401  |    0.156389     |   1\n",
      "       2300 |   0.320465  |    0.159630     |   1\n",
      "       2301 |   0.317703  |    0.101951     |   1\n",
      "       2302 |   0.278318  |    0.076853     |   0\n",
      "       2303 |   0.347870  |    0.154786     |   1\n",
      "       2304 |   0.302979  |    0.046652     |   0\n",
      "       2305 |   0.244557  |    0.044680     |   0\n",
      "       2306 |   0.233239  |    0.043013     |   0\n",
      "       2307 |   0.324844  |    0.043182     |   0\n",
      "       2308 |   0.000253  |    0.073935     |   2\n",
      "       2309 |   0.223756  |    0.147443     |   1\n",
      "       2310 |   0.326311  |    0.077632     |   0\n",
      "       2311 |   0.314875  |    0.043354     |   0\n",
      "       2312 |   0.308597  |    0.045394     |   0\n",
      "       2313 |   0.011432  |    0.049360     |   2\n",
      "       2314 |   0.192216  |    0.045781     |   2\n",
      "       2315 |   0.372533  |    0.166931     |   1\n",
      "       2316 |   0.400923  |    0.153565     |   1\n",
      "       2317 |   0.083754  |    0.022272     |   2\n",
      "       2318 |   0.304082  |    0.075939     |   0\n",
      "       2319 |   0.372856  |    0.155649     |   1\n",
      "       2320 |   0.298358  |    0.030589     |   0\n",
      "       2321 |   0.109297  |    0.074977     |   2\n",
      "       2322 |   0.278714  |    0.013027     |   0\n",
      "       2323 |   0.304169  |    0.196705     |   1\n",
      "       2324 |   0.090954  |    0.027096     |   2\n",
      "       2325 |   0.038247  |    0.073677     |   2\n",
      "       2326 |   0.250899  |    0.140709     |   1\n",
      "       2327 |   0.397502  |    0.193195     |   1\n",
      "       2328 |   0.282148  |    0.014655     |   0\n",
      "       2329 |   0.090204  |    0.050712     |   2\n",
      "       2330 |   0.384433  |    0.021792     |   0\n",
      "       2331 |   0.342020  |    0.213916     |   1\n",
      "       2332 |   0.363312  |    0.146989     |   1\n",
      "       2333 |   0.308621  |    0.020386     |   0\n",
      "       2334 |   0.257289  |    0.196950     |   1\n",
      "       2335 |   0.068845  |    0.025033     |   2\n",
      "       2336 |   0.000230  |    0.075412     |   2\n",
      "       2337 |   0.000306  |    0.027530     |   2\n",
      "       2338 |   0.319457  |    0.207861     |   1\n",
      "       2339 |   0.399269  |    0.163342     |   1\n",
      "       2340 |   0.000274  |    0.022008     |   2\n",
      "       2341 |   0.338663  |    0.223414     |   1\n",
      "       2342 |   0.390419  |    0.148782     |   1\n",
      "       2343 |   0.321872  |    0.029401     |   0\n",
      "       2344 |   0.288240  |    0.179369     |   1\n",
      "       2345 |   0.000334  |    0.044864     |   2\n",
      "       2346 |   0.289984  |    0.069701     |   0\n",
      "       2347 |   0.363058  |    0.148773     |   1\n",
      "       2348 |   0.000315  |    0.019638     |   2\n",
      "       2349 |   0.396877  |    0.165074     |   1\n",
      "       2350 |   0.000339  |    0.025033     |   2\n",
      "       2351 |   0.314428  |    0.086283     |   0\n",
      "       2352 |   0.264733  |    0.163853     |   1\n",
      "       2353 |   0.251731  |    0.102043     |   1\n",
      "       2354 |   0.274574  |    0.080446     |   0\n",
      "       2355 |   0.109823  |    0.018713     |   2\n",
      "       2356 |   0.292192  |    0.081345     |   0\n",
      "       2357 |   0.133202  |    0.028604     |   2\n",
      "       2358 |   0.195971  |    0.046834     |   0\n",
      "       2359 |   0.305074  |    0.190805     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 2360: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       2360 |   0.317193  |    0.006302     |   0\n",
      "       2361 |   0.386959  |    0.047024     |   0\n",
      "       2362 |   0.265036  |    0.058004     |   0\n",
      "       2363 |   0.310813  |    0.156832     |   1\n",
      "       2364 |   0.278947  |    0.145631     |   1\n",
      "       2365 |   0.380193  |    0.143799     |   1\n",
      "       2366 |   0.327287  |    0.157174     |   1\n",
      "       2367 |   0.312988  |    0.041513     |   0\n",
      "       2368 |   0.399067  |    0.189528     |   1\n",
      "       2369 |   0.256510  |    0.019286     |   0\n",
      "       2370 |   0.398821  |    0.144509     |   1\n",
      "       2371 |   0.125029  |    0.045640     |   2\n",
      "       2372 |   0.269725  |    0.042686     |   0\n",
      "       2373 |   0.080187  |    0.029091     |   2\n",
      "       2374 |   0.309977  |    0.074497     |   0\n",
      "       2375 |   0.100368  |    0.013503     |   2\n",
      "       2376 |   0.304581  |    0.216278     |   1\n",
      "       2377 |   0.121797  |    0.003713     |   2\n",
      "       2378 |   0.262489  |    0.044485     |   0\n",
      "       2379 |   0.053617  |    0.051910     |   2\n",
      "       2380 |   0.300438  |    0.078999     |   0\n",
      "       2381 |   0.319230  |    0.136635     |   1\n",
      "       2382 |   0.102239  |    0.043690     |   2\n",
      "       2383 |   0.302008  |    0.075371     |   0\n",
      "       2384 |   0.328298  |    0.015292     |   0\n",
      "       2385 |   0.092556  |    0.075572     |   2\n",
      "       2386 |   0.350771  |    0.008862     |   0\n",
      "       2387 |   0.224434  |    0.085477     |   0\n",
      "       2388 |   0.274884  |    0.129202     |   1\n",
      "       2389 |   0.328636  |    0.052711     |   0\n",
      "       2390 |   0.096453  |    0.039427     |   2\n",
      "       2391 |   0.317836  |    0.043534     |   0\n",
      "       2392 |   0.347156  |    0.079345     |   0\n",
      "       2393 |   0.096585  |    0.014627     |   2\n",
      "       2394 |   0.273098  |    0.079668     |   0\n",
      "       2395 |   0.319596  |    0.044744     |   0\n",
      "       2396 |   0.284838  |    0.206605     |   1\n",
      "       2397 |   0.341022  |    0.132933     |   1\n",
      "       2398 |   0.343433  |    0.173883     |   1\n",
      "       2399 |   0.225231  |    0.010108     |   0\n",
      "       2400 |   0.040140  |    0.082374     |   2\n",
      "       2401 |   0.289145  |    0.024388     |   0\n",
      "       2402 |   0.000264  |    0.091705     |   2\n",
      "       2403 |   0.249893  |    0.143746     |   1\n",
      "       2404 |   0.343725  |    0.191190     |   1\n",
      "       2405 |   0.269899  |    0.007974     |   0\n",
      "       2406 |   0.320294  |    0.058145     |   0\n",
      "       2407 |   0.295261  |    0.229603     |   1\n",
      "       2408 |   0.323495  |    0.139702     |   1\n",
      "       2409 |   0.011580  |    0.010966     |   2\n",
      "       2410 |   0.192508  |    0.049569     |   2\n",
      "       2411 |   0.082782  |    0.047475     |   2\n",
      "       2412 |   0.347564  |    0.203876     |   1\n",
      "       2413 |   0.285319  |    0.148598     |   1\n",
      "       2414 |   0.294634  |    0.009035     |   0\n",
      "       2415 |   0.108923  |    0.054620     |   2\n",
      "       2416 |   0.290317  |    0.047123     |   0\n",
      "       2417 |   0.295489  |    0.198937     |   1\n",
      "       2418 |   0.092210  |    0.008940     |   2\n",
      "       2419 |   0.039630  |    0.078299     |   2\n",
      "       2420 |   0.261350  |    0.026228     |   0\n",
      "       2421 |   0.237221  |    0.048568     |   0\n",
      "       2422 |   0.257702  |    0.040905     |   0\n",
      "       2423 |   0.092212  |    0.078344     |   2\n",
      "       2424 |   0.304138  |    0.042550     |   0\n",
      "       2425 |   0.294786  |    0.040522     |   0\n",
      "       2426 |   0.237001  |    0.080806     |   0\n",
      "       2427 |   0.068817  |    0.005503     |   2\n",
      "       2428 |   0.260993  |    0.088679     |   0\n",
      "       2429 |   0.000221  |    0.020024     |   2\n",
      "       2430 |   0.282149  |    0.053202     |   0\n",
      "       2431 |   0.311440  |    0.195044     |   1\n",
      "       2432 |   0.000285  |    0.007673     |   2\n",
      "       2433 |   0.000260  |    0.082977     |   2\n",
      "       2434 |   0.291778  |    0.014299     |   0\n",
      "       2435 |   0.000314  |    0.081551     |   2\n",
      "       2436 |   0.000325  |    0.027237     |   2\n",
      "       2437 |   0.267470  |    0.202233     |   1\n",
      "       2438 |   0.247976  |    0.005120     |   0\n",
      "       2439 |   0.425168  |    0.144990     |   1\n",
      "       2440 |   0.380780  |    0.164193     |   1\n",
      "       2441 |   0.274768  |    0.035753     |   0\n",
      "       2442 |   0.227576  |    0.044552     |   0\n",
      "       2443 |   0.297987  |    0.048036     |   0\n",
      "       2444 |   0.264575  |    0.076116     |   0\n",
      "       2445 |   0.217841  |    0.032126     |   0\n",
      "       2446 |   0.313520  |    0.056505     |   0\n",
      "       2447 |   0.313108  |    0.164164     |   1\n",
      "       2448 |   0.167580  |    0.015396     |   0\n",
      "       2449 |   0.000322  |    0.084333     |   2\n",
      "       2450 |   0.116785  |    0.015879     |   2\n",
      "       2451 |   0.295045  |    0.054168     |   0\n",
      "       2452 |   0.323574  |    0.147895     |   1\n",
      "       2453 |   0.135433  |    0.045471     |   2\n",
      "       2454 |   0.230795  |    0.046577     |   0\n",
      "       2455 |   0.219837  |    0.053453     |   0\n",
      "       2456 |   0.301550  |    0.198979     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 2457: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       2457 |   0.244911  |    0.009202     |   0\n",
      "       2458 |   0.269536  |    0.072967     |   0\n",
      "       2459 |   0.130279  |    0.044075     |   2\n",
      "       2460 |   0.226726  |    0.045276     |   0\n",
      "       2461 |   0.264863  |    0.040422     |   0\n",
      "       2462 |   0.083376  |    0.075709     |   2\n",
      "       2463 |   0.100551  |    0.037954     |   2\n",
      "       2464 |   0.124889  |    0.045959     |   2\n",
      "       2465 |   0.053654  |    0.075834     |   2\n",
      "       2466 |   0.261439  |    0.024074     |   0\n",
      "       2467 |   0.229841  |    0.043440     |   0\n",
      "       2468 |   0.329665  |    0.146353     |   1\n",
      "       2469 |   0.243179  |    0.154914     |   1\n",
      "       2470 |   0.100609  |    0.038896     |   2\n",
      "       2471 |   0.359571  |    0.196350     |   1\n",
      "       2472 |   0.213279  |    0.209406     |   1\n",
      "       2473 |   0.271082  |    0.149660     |   1\n",
      "       2474 |   0.093055  |    0.039806     |   2\n",
      "       2475 |   0.365672  |    0.186209     |   1\n",
      "       2476 |   0.098189  |    0.025818     |   2\n",
      "       2477 |   0.314899  |    0.148923     |   1\n",
      "       2478 |   0.282198  |    0.075747     |   0\n",
      "       2479 |   0.320515  |    0.139387     |   1\n",
      "       2480 |   0.266372  |    0.041610     |   0\n",
      "       2481 |   0.091208  |    0.085891     |   2\n",
      "       2482 |   0.036658  |    0.027083     |   2\n",
      "       2483 |   0.381491  |    0.181734     |   1\n",
      "       2484 |   0.290342  |    0.013828     |   0\n",
      "       2485 |   0.000221  |    0.067541     |   2\n",
      "       2486 |   0.335662  |    0.162645     |   1\n",
      "       2487 |   0.324427  |    0.159806     |   1\n",
      "       2488 |   0.223539  |    0.028637     |   0\n",
      "       2489 |   0.010042  |    0.053182     |   2\n",
      "       2490 |   0.268847  |    0.202313     |   1\n",
      "       2491 |   0.267856  |    0.148721     |   1\n",
      "       2492 |   0.188581  |    0.007776     |   2\n",
      "       2493 |   0.078265  |    0.083331     |   2\n",
      "       2494 |   0.410094  |    0.136155     |   1\n",
      "       2495 |   0.263378  |    0.021468     |   0\n",
      "       2496 |   0.102039  |    0.084965     |   2\n",
      "       2497 |   0.322901  |    0.163401     |   1\n",
      "       2498 |   0.361885  |    0.012899     |   0\n",
      "       2499 |   0.084758  |    0.084734     |   2\n",
      "       2500 |   0.360255  |    0.145750     |   1\n",
      "       2501 |   0.125188  |    0.061147     |   2\n",
      "       2502 |   0.515037  |    0.161603     |   1\n",
      "       2503 |   0.307101  |    0.113617     |   1\n",
      "       2504 |   0.290570  |    0.212902     |   1\n",
      "       2505 |   0.297533  |    0.165240     |   1\n",
      "       2506 |   0.378536  |    0.138645     |   1\n",
      "       2507 |   0.265988  |    0.052906     |   0\n",
      "       2508 |   0.267693  |    0.196469     |   1\n",
      "       2509 |   0.302306  |    0.013516     |   0\n",
      "       2510 |   0.076323  |    0.047863     |   2\n",
      "       2511 |   0.354308  |    0.188083     |   1\n",
      "       2512 |   0.303313  |    0.165425     |   1\n",
      "       2513 |   0.322130  |    0.029189     |   0\n",
      "       2514 |   0.222320  |    0.084356     |   0\n",
      "       2515 |   0.283254  |    0.027381     |   0\n",
      "       2516 |   0.098611  |    0.051068     |   2\n",
      "       2517 |   0.326742  |    0.155768     |   1\n",
      "       2518 |   0.396465  |    0.150525     |   1\n",
      "       2519 |   0.330418  |    0.187439     |   1\n",
      "       2520 |   0.347656  |    0.009563     |   0\n",
      "       2521 |   0.118225  |    0.045054     |   2\n",
      "       2522 |   0.051337  |    0.036792     |   2\n",
      "       2523 |   0.323946  |    0.201534     |   1\n",
      "       2524 |   0.286133  |    0.007758     |   0\n",
      "       2525 |   0.096857  |    0.048539     |   2\n",
      "       2526 |   0.091897  |    0.072852     |   2\n",
      "       2527 |   0.315193  |    0.020518     |   0\n",
      "       2528 |   0.252949  |    0.185381     |   1\n",
      "       2529 |   0.284320  |    0.045402     |   0\n",
      "       2530 |   0.094896  |    0.055453     |   2\n",
      "       2531 |   0.265529  |    0.047091     |   0\n",
      "       2532 |   0.087982  |    0.043365     |   2\n",
      "       2533 |   0.039083  |    0.044261     |   2\n",
      "       2534 |   0.292822  |    0.186793     |   1\n",
      "       2535 |   0.000234  |    0.009273     |   2\n",
      "       2536 |   0.009911  |    0.082079     |   2\n",
      "       2537 |   0.428236  |    0.163567     |   1\n",
      "       2538 |   0.255026  |    0.132188     |   1\n",
      "       2539 |   0.314951  |    0.149050     |   1\n",
      "       2540 |   0.258814  |    0.148220     |   1\n",
      "       2541 |   0.245045  |    0.038415     |   0\n",
      "       2542 |   0.230971  |    0.043350     |   0\n",
      "       2543 |   0.247592  |    0.051290     |   0\n",
      "       2544 |   0.182003  |    0.032004     |   2\n",
      "       2545 |   0.076322  |    0.086547     |   2\n",
      "       2546 |   0.251321  |    0.155967     |   1\n",
      "       2547 |   0.278654  |    0.005482     |   0\n",
      "       2548 |   0.102148  |    0.045607     |   2\n",
      "       2549 |   0.086233  |    0.061630     |   2\n",
      "       2550 |   0.364153  |    0.159415     |   1\n",
      "       2551 |   0.035838  |    0.019765     |   2\n",
      "       2552 |   0.328432  |    0.217250     |   1\n",
      "       2553 |   0.391697  |    0.139195     |   1\n",
      "       2554 |   0.088100  |    0.014554     |   2\n",
      "       2555 |   0.067557  |    0.063079     |   2\n",
      "       2556 |   0.266844  |    0.204866     |   1\n",
      "       2557 |   0.347201  |    0.005035     |   0\n",
      "       2558 |   0.000207  |    0.053329     |   2\n",
      "       2559 |   0.000257  |    0.079804     |   2\n",
      "       2560 |   0.000255  |    0.029693     |   2\n",
      "       2561 |   0.232000  |    0.213079     |   1\n",
      "       2562 |   0.000298  |    0.005828     |   2\n",
      "       2563 |   0.314035  |    0.070572     |   0\n",
      "       2564 |   0.274799  |    0.047792     |   0\n",
      "       2565 |   0.000285  |    0.045793     |   2\n",
      "       2566 |   0.270880  |    0.075404     |   0\n",
      "       2567 |   0.000292  |    0.015639     |   2\n",
      "       2568 |   0.314473  |    0.198502     |   1\n",
      "       2569 |   0.283731  |    0.005177     |   0\n",
      "       2570 |   0.331994  |    0.043133     |   0\n",
      "       2571 |   0.248833  |    0.038942     |   0\n",
      "       2572 |   0.106653  |    0.079685     |   2\n",
      "       2573 |   0.130279  |    0.040768     |   2\n",
      "       2574 |   0.377845  |    0.131782     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 2575: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       2575 |   0.223110  |    0.039124     |   0\n",
      "       2576 |   0.122629  |    0.080998     |   2\n",
      "       2577 |   0.335634  |    0.007952     |   0\n",
      "       2578 |   0.080972  |    0.093330     |   2\n",
      "       2579 |   0.350885  |    0.133772     |   1\n",
      "       2580 |   0.096382  |    0.038542     |   2\n",
      "       2581 |   0.286443  |    0.080208     |   0\n",
      "       2582 |   0.118136  |    0.009535     |   2\n",
      "       2583 |   0.242290  |    0.075956     |   0\n",
      "       2584 |   0.050701  |    0.009932     |   2\n",
      "       2585 |   0.312748  |    0.073135     |   0\n",
      "       2586 |   0.280456  |    0.197144     |   1\n",
      "       2587 |   0.282737  |    0.006387     |   0\n",
      "       2588 |   0.259272  |    0.046525     |   0\n",
      "       2589 |   0.272946  |    0.050661     |   0\n",
      "       2590 |   0.095076  |    0.013537     |   2\n",
      "       2591 |   0.266132  |    0.074727     |   0\n",
      "       2592 |   0.093921  |    0.024721     |   2\n",
      "       2593 |   0.283453  |    0.041701     |   0\n",
      "       2594 |   0.283238  |    0.073284     |   0\n",
      "       2595 |   0.281554  |    0.024807     |   0\n",
      "       2596 |   0.094137  |    0.072289     |   2\n",
      "       2597 |   0.280543  |    0.044911     |   0\n",
      "       2598 |   0.354887  |    0.161425     |   1\n",
      "       2599 |   0.305221  |    0.025621     |   0\n",
      "       2600 |   0.317050  |    0.046650     |   0\n",
      "       2601 |   0.335723  |    0.166488     |   1\n",
      "       2602 |   0.244061  |    0.039216     |   0\n",
      "       2603 |   0.400509  |    0.194769     |   1\n",
      "       2604 |   0.308450  |    0.137671     |   1\n",
      "       2605 |   0.091761  |    0.045338     |   2\n",
      "       2606 |   0.039776  |    0.054157     |   2\n",
      "       2607 |   0.300417  |    0.138773     |   1\n",
      "       2608 |   0.268359  |    0.042801     |   0\n",
      "       2609 |   0.244798  |    0.037914     |   0\n",
      "       2610 |   0.407759  |    0.190433     |   1\n",
      "       2611 |   0.236146  |    0.023416     |   0\n",
      "       2612 |   0.303264  |    0.205442     |   1\n",
      "       2613 |   0.292578  |    0.107470     |   1\n",
      "       2614 |   0.277895  |    0.202762     |   1\n",
      "       2615 |   0.226559  |    0.168078     |   1\n",
      "       2616 |   0.348788  |    0.187172     |   1\n",
      "       2617 |   0.287963  |    0.015089     |   0\n",
      "       2618 |   0.221914  |    0.041671     |   0\n",
      "       2619 |   0.000225  |    0.079819     |   2\n",
      "       2620 |   0.253305  |    0.138177     |   1\n",
      "       2621 |   0.294043  |    0.054059     |   0\n",
      "       2622 |   0.307684  |    0.164835     |   1\n",
      "       2623 |   0.009627  |    0.043914     |   2\n",
      "       2624 |   0.313626  |    0.078300     |   0\n",
      "       2625 |   0.184973  |    0.023181     |   2\n",
      "       2626 |   0.080243  |    0.071518     |   2\n",
      "       2627 |   0.100634  |    0.018349     |   2\n",
      "       2628 |   0.338949  |    0.198805     |   1\n",
      "       2629 |   0.087160  |    0.026305     |   2\n",
      "       2630 |   0.306270  |    0.194158     |   1\n",
      "       2631 |   0.283331  |    0.044578     |   0\n",
      "       2632 |   0.360604  |    0.160968     |   1\n",
      "       2633 |   0.397285  |    0.147991     |   1\n",
      "       2634 |   0.293478  |    0.016257     |   0\n",
      "       2635 |   0.267966  |    0.062316     |   0\n",
      "       2636 |   0.282926  |    0.205782     |   1\n",
      "       2637 |   0.251511  |    0.008673     |   0\n",
      "       2638 |   0.278418  |    0.053469     |   0\n",
      "       2639 |   0.389565  |    0.160989     |   1\n",
      "       2640 |   0.213124  |    0.029637     |   0\n",
      "       2641 |   0.037067  |    0.082707     |   2\n",
      "       2642 |   0.230215  |    0.152105     |   1\n",
      "       2643 |   0.086667  |    0.041676     |   2\n",
      "       2644 |   0.222140  |    0.072966     |   0\n",
      "       2645 |   0.065917  |    0.014319     |   2\n",
      "       2646 |   0.299078  |    0.076508     |   0\n",
      "       2647 |   0.282871  |    0.027779     |   0\n",
      "       2648 |   0.290167  |    0.046555     |   0\n",
      "       2649 |   0.000198  |    0.045138     |   2\n",
      "       2650 |   0.000254  |    0.072131     |   2\n",
      "       2651 |   0.264356  |    0.035782     |   0\n",
      "       2652 |   0.331311  |    0.186337     |   1\n",
      "       2653 |   0.214017  |    0.023486     |   0\n",
      "       2654 |   0.000248  |    0.078588     |   2\n",
      "       2655 |   0.000292  |    0.011726     |   2\n",
      "       2656 |   0.298179  |    0.081743     |   0\n",
      "       2657 |   0.341725  |    0.128428     |   1\n",
      "       2658 |   0.270698  |    0.031442     |   0\n",
      "       2659 |   0.292438  |    0.072668     |   0\n",
      "       2660 |   0.291986  |    0.038782     |   0\n",
      "       2661 |   0.261798  |    0.205884     |   1\n",
      "       2662 |   0.289766  |    0.012015     |   0\n",
      "       2663 |   0.000290  |    0.044688     |   2\n",
      "       2664 |   0.000305  |    0.049577     |   2\n",
      "       2665 |   0.111145  |    0.048157     |   2\n",
      "       2666 |   0.309611  |    0.192621     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 2668: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       2667 |   0.129323  |    0.009544     |   2\n",
      "       2668 |   0.390777  |    0.197245     |   1\n",
      "       2669 |   0.297841  |    0.015360     |   0\n",
      "       2670 |   0.124299  |    0.074639     |   2\n",
      "       2671 |   0.078315  |    0.016561     |   2\n",
      "       2672 |   0.406783  |    0.177133     |   1\n",
      "       2673 |   0.221945  |    0.019629     |   0\n",
      "       2674 |   0.340023  |    0.204681     |   1\n",
      "       2675 |   0.301444  |    0.154293     |   1\n",
      "       2676 |   0.355617  |    0.139583     |   1\n",
      "       2677 |   0.094956  |    0.015529     |   2\n",
      "       2678 |   0.118895  |    0.078597     |   2\n",
      "       2679 |   0.249693  |    0.161758     |   1\n",
      "       2680 |   0.319905  |    0.146437     |   1\n",
      "       2681 |   0.049537  |    0.045996     |   2\n",
      "       2682 |   0.352117  |    0.191737     |   1\n",
      "       2683 |   0.342492  |    0.099533     |   1\n",
      "       2684 |   0.327813  |    0.195214     |   1\n",
      "       2685 |   0.097138  |    0.011017     |   2\n",
      "       2686 |   0.088898  |    0.078891     |   2\n",
      "       2687 |   0.326501  |    0.032031     |   0\n",
      "       2688 |   0.328945  |    0.194514     |   1\n",
      "       2689 |   0.283548  |    0.016893     |   0\n",
      "       2690 |   0.094579  |    0.081200     |   2\n",
      "       2691 |   0.091673  |    0.023676     |   2\n",
      "       2692 |   0.037767  |    0.080927     |   2\n",
      "       2693 |   0.298427  |    0.026735     |   0\n",
      "       2694 |   0.000220  |    0.049456     |   2\n",
      "       2695 |   0.377582  |    0.161164     |   1\n",
      "       2696 |   0.009132  |    0.036571     |   2\n",
      "       2697 |   0.173928  |    0.072443     |   2\n",
      "       2698 |   0.074053  |    0.039199     |   2\n",
      "       2699 |   0.096697  |    0.038790     |   2\n",
      "       2700 |   0.247398  |    0.040611     |   0\n",
      "       2701 |   0.284124  |    0.195671     |   1\n",
      "       2702 |   0.401782  |    0.142899     |   1\n",
      "       2703 |   0.302253  |    0.157817     |   1\n",
      "       2704 |   0.287151  |    0.146788     |   1\n",
      "       2705 |   0.079923  |    0.045908     |   2\n",
      "       2706 |   0.389996  |    0.150190     |   1\n",
      "       2707 |   0.289440  |    0.042457     |   0\n",
      "       2708 |   0.234767  |    0.075686     |   0\n",
      "       2709 |   0.364380  |    0.142403     |   1\n",
      "       2710 |   0.309930  |    0.047040     |   0\n",
      "       2711 |   0.277256  |    0.197217     |   1\n",
      "       2712 |   0.038027  |    0.014668     |   2\n",
      "       2713 |   0.366297  |    0.214185     |   1\n",
      "       2714 |   0.289483  |    0.144710     |   1\n",
      "       2715 |   0.084838  |    0.007737     |   2\n",
      "       2716 |   0.283211  |    0.146101     |   1\n",
      "       2717 |   0.292667  |    0.082824     |   0\n",
      "       2718 |   0.267519  |    0.134507     |   1\n",
      "       2719 |   0.305862  |    0.078743     |   0\n",
      "       2720 |   0.336005  |    0.166857     |   1\n",
      "       2721 |   0.063574  |    0.030201     |   2\n",
      "       2722 |   0.281728  |    0.053078     |   0\n",
      "       2723 |   0.316545  |    0.178822     |   1\n",
      "       2724 |   0.301884  |    0.023919     |   0\n",
      "       2725 |   0.000195  |    0.057433     |   2\n",
      "       2726 |   0.000252  |    0.052257     |   2\n",
      "       2727 |   0.304334  |    0.155599     |   1\n",
      "       2728 |   0.222490  |    0.044470     |   0\n",
      "       2729 |   0.000247  |    0.076869     |   2\n",
      "       2730 |   0.239453  |    0.010872     |   0\n",
      "       2731 |   0.301562  |    0.075013     |   0\n",
      "       2732 |   0.237067  |    0.009285     |   0\n",
      "       2733 |   0.258147  |    0.087329     |   0\n",
      "       2734 |   0.272072  |    0.154064     |   1\n",
      "       2735 |   0.000309  |    0.043603     |   2\n",
      "       2736 |   0.254019  |    0.075093     |   0\n",
      "       2737 |   0.260096  |    0.012248     |   0\n",
      "       2738 |   0.234536  |    0.077317     |   0\n",
      "       2739 |   0.000294  |    0.010702     |   2\n",
      "       2740 |   0.242133  |    0.079809     |   0\n",
      "       2741 |   0.241149  |    0.020829     |   0\n",
      "       2742 |   0.301983  |    0.175920     |   1\n",
      "       2743 |   0.000303  |    0.036271     |   2\n",
      "       2744 |   0.368453  |    0.155306     |   1\n",
      "       2745 |   0.257513  |    0.077901     |   0\n",
      "       2746 |   0.356349  |    0.142639     |   1\n",
      "       2747 |   0.388193  |    0.193747     |   1\n",
      "       2748 |   0.110745  |    0.009296     |   2\n",
      "       2749 |   0.126535  |    0.047302     |   2\n",
      "       2750 |   0.277936  |    0.161044     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 2751: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       2751 |   0.376239  |    0.163056     |   1\n",
      "       2752 |   0.122485  |    0.006401     |   2\n",
      "       2753 |   0.082918  |    0.081404     |   2\n",
      "       2754 |   0.361649  |    0.172879     |   1\n",
      "       2755 |   0.090499  |    0.004915     |   2\n",
      "       2756 |   0.114201  |    0.054867     |   2\n",
      "       2757 |   0.178527  |    0.042406     |   0\n",
      "       2758 |   0.281780  |    0.047656     |   0\n",
      "       2759 |   0.049393  |    0.035153     |   2\n",
      "       2760 |   0.351602  |    0.205341     |   1\n",
      "       2761 |   0.317147  |    0.139884     |   1\n",
      "       2762 |   0.273784  |    0.021969     |   0\n",
      "       2763 |   0.231549  |    0.080352     |   0\n",
      "       2764 |   0.236456  |    0.033064     |   0\n",
      "       2765 |   0.095707  |    0.045445     |   2\n",
      "       2766 |   0.264924  |    0.078429     |   0\n",
      "       2767 |   0.277238  |    0.023476     |   0\n",
      "       2768 |   0.087810  |    0.087875     |   2\n",
      "       2769 |   0.092791  |    0.012799     |   2\n",
      "       2770 |   0.266845  |    0.077786     |   0\n",
      "       2771 |   0.393256  |    0.149787     |   1\n",
      "       2772 |   0.360115  |    0.150153     |   1\n",
      "       2773 |   0.300758  |    0.139046     |   1\n",
      "       2774 |   0.090086  |    0.006008     |   2\n",
      "       2775 |   0.039040  |    0.044856     |   2\n",
      "       2776 |   0.250906  |    0.084956     |   0\n",
      "       2777 |   0.254475  |    0.135053     |   1\n",
      "       2778 |   0.349752  |    0.147609     |   1\n",
      "       2779 |   0.304084  |    0.024364     |   0\n",
      "       2780 |   0.000219  |    0.051652     |   2\n",
      "       2781 |   0.285050  |    0.194001     |   1\n",
      "       2782 |   0.328325  |    0.136654     |   1\n",
      "       2783 |   0.009928  |    0.044990     |   2\n",
      "       2784 |   0.173449  |    0.077847     |   2\n",
      "       2785 |   0.258738  |    0.039951     |   0\n",
      "       2786 |   0.220862  |    0.170693     |   1\n",
      "       2787 |   0.320076  |    0.199212     |   1\n",
      "       2788 |   0.338334  |    0.081449     |   1\n",
      "       2789 |   0.327262  |    0.076708     |   0\n",
      "       2790 |   0.191455  |    0.030855     |   0\n",
      "       2791 |   0.074010  |    0.050514     |   2\n",
      "       2792 |   0.275129  |    0.083811     |   0\n",
      "       2793 |   0.408460  |    0.150019     |   1\n",
      "       2794 |   0.274424  |    0.014870     |   0\n",
      "       2795 |   0.096889  |    0.078128     |   2\n",
      "       2796 |   0.081605  |    0.021230     |   2\n",
      "       2797 |   0.268635  |    0.203150     |   1\n",
      "       2798 |   0.362423  |    0.145939     |   1\n",
      "       2799 |   0.271784  |    0.010817     |   0\n",
      "       2800 |   0.262184  |    0.042355     |   0\n",
      "       2801 |   0.036648  |    0.057067     |   2\n",
      "       2802 |   0.084079  |    0.056851     |   2\n",
      "       2803 |   0.323056  |    0.194960     |   1\n",
      "       2804 |   0.298491  |    0.135528     |   1\n",
      "       2805 |   0.298028  |    0.046616     |   0\n",
      "       2806 |   0.337239  |    0.153258     |   1\n",
      "       2807 |   0.300498  |    0.149171     |   1\n",
      "       2808 |   0.259289  |    0.041092     |   0\n",
      "       2809 |   0.063084  |    0.086081     |   2\n",
      "       2810 |   0.333088  |    0.142518     |   1\n",
      "       2811 |   0.000194  |    0.028413     |   2\n",
      "       2812 |   0.000238  |    0.053474     |   2\n",
      "       2813 |   0.000246  |    0.048078     |   2\n",
      "       2814 |   0.000292  |    0.025060     |   2\n",
      "       2815 |   0.224359  |    0.079883     |   0\n",
      "       2816 |   0.000273  |    0.017920     |   2\n",
      "       2817 |   0.257838  |    0.081611     |   0\n",
      "       2818 |   0.220350  |    0.026600     |   0\n",
      "       2819 |   0.000288  |    0.046347     |   2\n",
      "       2820 |   0.101972  |    0.057570     |   2\n",
      "       2821 |   0.280161  |    0.167081     |   1\n",
      "       2822 |   0.276026  |    0.158823     |   1\n",
      "       2823 |   0.258540  |    0.022802     |   0\n",
      "       2824 |   0.226095  |    0.043646     |   0\n",
      "       2825 |   0.124110  |    0.079733     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 2827: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       2826 |   0.302248  |    0.027636     |   0\n",
      "       2827 |   0.222007  |    0.048651     |   0\n",
      "       2828 |   0.115936  |    0.056324     |   2\n",
      "       2829 |   0.295330  |    0.039371     |   0\n",
      "       2830 |   0.238218  |    0.054485     |   0\n",
      "       2831 |   0.381413  |    0.186798     |   1\n",
      "       2832 |   0.285684  |    0.008246     |   0\n",
      "       2833 |   0.410949  |    0.155666     |   1\n",
      "       2834 |   0.076578  |    0.039518     |   2\n",
      "       2835 |   0.284277  |    0.206313     |   1\n",
      "       2836 |   0.339785  |    0.108611     |   1\n",
      "       2837 |   0.309064  |    0.157877     |   1\n",
      "       2838 |   0.091426  |    0.038133     |   2\n",
      "       2839 |   0.406991  |    0.157300     |   1\n",
      "       2840 |   0.113062  |    0.038193     |   2\n",
      "       2841 |   0.240025  |    0.193300     |   1\n",
      "       2842 |   0.270477  |    0.006073     |   0\n",
      "       2843 |   0.304507  |    0.195396     |   1\n",
      "       2844 |   0.048878  |    0.040581     |   2\n",
      "       2845 |   0.093336  |    0.041667     |   2\n",
      "       2846 |   0.086881  |    0.048237     |   2\n",
      "       2847 |   0.092341  |    0.044263     |   2\n",
      "       2848 |   0.365849  |    0.197737     |   1\n",
      "       2849 |   0.338304  |    0.157123     |   1\n",
      "       2850 |   0.088565  |    0.028714     |   2\n",
      "       2851 |   0.263292  |    0.059147     |   0\n",
      "       2852 |   0.305635  |    0.169826     |   1\n",
      "       2853 |   0.039432  |    0.051383     |   2\n",
      "       2854 |   0.000217  |    0.045004     |   2\n",
      "       2855 |   0.282466  |    0.044334     |   0\n",
      "       2856 |   0.009138  |    0.074715     |   2\n",
      "       2857 |   0.167963  |    0.028715     |   2\n",
      "       2858 |   0.272727  |    0.075671     |   0\n",
      "       2859 |   0.073395  |    0.009097     |   2\n",
      "       2860 |   0.299160  |    0.080660     |   0\n",
      "       2861 |   0.093341  |    0.028907     |   2\n",
      "       2862 |   0.313579  |    0.200859     |   1\n",
      "       2863 |   0.250710  |    0.026377     |   0\n",
      "       2864 |   0.270967  |    0.215226     |   1\n",
      "       2865 |   0.263356  |    0.165863     |   1\n",
      "       2866 |   0.078857  |    0.006971     |   2\n",
      "       2867 |   0.036200  |    0.087195     |   2\n",
      "       2868 |   0.370932  |    0.140151     |   1\n",
      "       2869 |   0.304487  |    0.047819     |   0\n",
      "       2870 |   0.238464  |    0.033719     |   0\n",
      "       2871 |   0.260797  |    0.079711     |   0\n",
      "       2872 |   0.350185  |    0.151298     |   1\n",
      "       2873 |   0.307302  |    0.152304     |   1\n",
      "       2874 |   0.243283  |    0.021981     |   0\n",
      "       2875 |   0.243255  |    0.077130     |   0\n",
      "       2876 |   0.250264  |    0.016008     |   0\n",
      "       2877 |   0.083382  |    0.074931     |   2\n",
      "       2878 |   0.265483  |    0.041044     |   0\n",
      "       2879 |   0.295148  |    0.139253     |   1\n",
      "       2880 |   0.318813  |    0.152316     |   1\n",
      "       2881 |   0.063658  |    0.028125     |   2\n",
      "       2882 |   0.308063  |    0.046098     |   0\n",
      "       2883 |   0.264078  |    0.060197     |   0\n",
      "       2884 |   0.286123  |    0.138914     |   1\n",
      "       2885 |   0.000191  |    0.028287     |   2\n",
      "       2886 |   0.218823  |    0.076238     |   0\n",
      "       2887 |   0.238763  |    0.013997     |   0\n",
      "       2888 |   0.000231  |    0.080112     |   2\n",
      "       2889 |   0.228542  |    0.043009     |   0\n",
      "       2890 |   0.251019  |    0.044580     |   0\n",
      "       2891 |   0.000243  |    0.048119     |   2\n",
      "       2892 |   0.000285  |    0.085479     |   2\n",
      "       2893 |   0.339450  |    0.134408     |   1\n",
      "       2894 |   0.303666  |    0.046178     |   0\n",
      "       2895 |   0.000262  |    0.053726     |   2\n",
      "       2896 |   0.357540  |    0.140860     |   1\n",
      "       2897 |   0.304386  |    0.158162     |   1\n",
      "       2898 |   0.000276  |    0.009938     |   2\n",
      "       2899 |   0.108633  |    0.073349     |   2\n",
      "       2900 |   0.241313  |    0.026307     |   0\n",
      "       2901 |   0.340681  |    0.153402     |   1\n",
      "       2902 |   0.122768  |    0.026711     |   2\n",
      "       2903 |   0.295046  |    0.199926     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 2904: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       2904 |   0.223881  |    0.008103     |   0\n",
      "       2905 |   0.120107  |    0.078368     |   2\n",
      "       2906 |   0.377852  |    0.138271     |   1\n",
      "       2907 |   0.241195  |    0.191170     |   1\n",
      "       2908 |   0.076129  |    0.008306     |   2\n",
      "       2909 |   0.091570  |    0.072381     |   2\n",
      "       2910 |   0.113647  |    0.033554     |   2\n",
      "       2911 |   0.305851  |    0.187673     |   1\n",
      "       2912 |   0.050494  |    0.028463     |   2\n",
      "       2913 |   0.394379  |    0.159024     |   1\n",
      "       2914 |   0.092286  |    0.047657     |   2\n",
      "       2915 |   0.088193  |    0.039862     |   2\n",
      "       2916 |   0.250738  |    0.058872     |   0\n",
      "       2917 |   0.212522  |    0.049412     |   0\n",
      "       2918 |   0.285624  |    0.162242     |   1\n",
      "       2919 |   0.373687  |    0.084088     |   1\n",
      "       2920 |   0.091679  |    0.047367     |   2\n",
      "       2921 |   0.086950  |    0.047236     |   2\n",
      "       2922 |   0.038858  |    0.040718     |   2\n",
      "       2923 |   0.232778  |    0.040757     |   0\n",
      "       2924 |   0.256570  |    0.145504     |   1\n",
      "       2925 |   0.000213  |    0.045608     |   2\n",
      "       2926 |   0.314004  |    0.166583     |   1\n",
      "       2927 |   0.325399  |    0.154332     |   1\n",
      "       2928 |   0.299373  |    0.146669     |   1\n",
      "       2929 |   0.242682  |    0.024100     |   0\n",
      "       2930 |   0.331280  |    0.080957     |   0\n",
      "       2931 |   0.246739  |    0.030135     |   0\n",
      "       2932 |   0.010106  |    0.044832     |   2\n",
      "       2933 |   0.223579  |    0.045222     |   0\n",
      "       2934 |   0.234304  |    0.028862     |   0\n",
      "       2935 |   0.170637  |    0.095281     |   2\n",
      "       2936 |   0.277477  |    0.165566     |   1\n",
      "       2937 |   0.072629  |    0.010612     |   2\n",
      "       2938 |   0.098463  |    0.050439     |   2\n",
      "       2939 |   0.412702  |    0.146236     |   1\n",
      "       2940 |   0.078158  |    0.047200     |   2\n",
      "       2941 |   0.286457  |    0.076741     |   0\n",
      "       2942 |   0.261949  |    0.029645     |   0\n",
      "       2943 |   0.323845  |    0.163570     |   1\n",
      "       2944 |   0.343603  |    0.190102     |   1\n",
      "       2945 |   0.035090  |    0.005830     |   2\n",
      "       2946 |   0.336497  |    0.077521     |   0\n",
      "       2947 |   0.081638  |    0.020849     |   2\n",
      "       2948 |   0.282807  |    0.073891     |   0\n",
      "       2949 |   0.261650  |    0.038860     |   0\n",
      "       2950 |   0.306046  |    0.200401     |   1\n",
      "       2951 |   0.062358  |    0.005364     |   2\n",
      "       2952 |   0.000188  |    0.076434     |   2\n",
      "       2953 |   0.249542  |    0.022285     |   0\n",
      "       2954 |   0.237051  |    0.079268     |   0\n",
      "       2955 |   0.000226  |    0.016456     |   2\n",
      "       2956 |   0.000235  |    0.085493     |   2\n",
      "       2957 |   0.288269  |    0.181489     |   1\n",
      "       2958 |   0.195901  |    0.160830     |   1\n",
      "       2959 |   0.000276  |    0.045138     |   2\n",
      "       2960 |   0.000253  |    0.075822     |   2\n",
      "       2961 |   0.277334  |    0.146176     |   1\n",
      "       2962 |   0.000270  |    0.028413     |   2\n",
      "       2963 |   0.211505  |    0.075332     |   0\n",
      "       2964 |   0.102815  |    0.008413     |   2\n",
      "       2965 |   0.234201  |    0.095312     |   0\n",
      "       2966 |   0.268188  |    0.170271     |   1\n",
      "       2967 |   0.320956  |    0.142149     |   1\n",
      "       2968 |   0.283859  |    0.007053     |   0\n",
      "       2969 |   0.300353  |    0.214868     |   1\n",
      "       2970 |   0.305342  |    0.004717     |   0\n",
      "       2971 |   0.263552  |    0.134567     |   1\n",
      "       2972 |   0.119496  |    0.052109     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 2973: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       2973 |   0.268047  |    0.157445     |   1\n",
      "       2974 |   0.114384  |    0.015668     |   2\n",
      "       2975 |   0.239540  |    0.153186     |   1\n",
      "       2976 |   0.231194  |    0.212100     |   1\n",
      "       2977 |   0.075768  |    0.005754     |   2\n",
      "       2978 |   0.089281  |    0.044880     |   2\n",
      "       2979 |   0.324516  |    0.155144     |   1\n",
      "       2980 |   0.234560  |    0.052116     |   0\n",
      "       2981 |   0.324321  |    0.140155     |   1\n",
      "       2982 |   0.108026  |    0.028284     |   2\n",
      "       2983 |   0.048471  |    0.054160     |   2\n",
      "       2984 |   0.089215  |    0.042931     |   2\n",
      "       2985 |   0.277707  |    0.076335     |   0\n",
      "       2986 |   0.088790  |    0.014901     |   2\n",
      "       2987 |   0.297965  |    0.048469     |   0\n",
      "       2988 |   0.302234  |    0.055727     |   0\n",
      "       2989 |   0.226948  |    0.213598     |   1\n",
      "       2990 |   0.334413  |    0.146132     |   1\n",
      "       2991 |   0.280192  |    0.139445     |   1\n",
      "       2992 |   0.293915  |    0.158981     |   1\n",
      "       2993 |   0.290472  |    0.211043     |   1\n",
      "       2994 |   0.087317  |    0.003558     |   2\n",
      "       2995 |   0.089680  |    0.073304     |   2\n",
      "       2996 |   0.267515  |    0.013677     |   0\n",
      "       2997 |   0.041558  |    0.080810     |   2\n",
      "       2998 |   0.000211  |    0.023020     |   2\n",
      "       2999 |   0.343350  |    0.213516     |   1\n",
      "       3000 |   0.309032  |    0.160823     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 3000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 3000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       3001 |   0.107735  |    0.084256     |   2\n",
      "       3002 |   0.072072  |    0.026310     |   2\n",
      "       3003 |   0.264683  |    0.201985     |   1\n",
      "       3004 |   0.259219  |    0.134334     |   1\n",
      "       3005 |   0.085484  |    0.046735     |   2\n",
      "       3006 |   0.325305  |    0.076524     |   0\n",
      "       3007 |   0.110189  |    0.007466     |   2\n",
      "       3008 |   0.048191  |    0.084647     |   2\n",
      "       3009 |   0.086043  |    0.020520     |   2\n",
      "       3010 |   0.086258  |    0.079723     |   2\n",
      "       3011 |   0.261134  |    0.026819     |   0\n",
      "       3012 |   0.281049  |    0.046964     |   0\n",
      "       3013 |   0.276824  |    0.040006     |   0\n",
      "       3014 |   0.277056  |    0.046705     |   0\n",
      "       3015 |   0.314266  |    0.195057     |   1\n",
      "       3016 |   0.087993  |    0.017734     |   2\n",
      "       3017 |   0.299878  |    0.081394     |   0\n",
      "       3018 |   0.086343  |    0.025081     |   2\n",
      "       3019 |   0.038858  |    0.045691     |   2\n",
      "       3020 |   0.000204  |    0.071874     |   2\n",
      "       3021 |   0.248737  |    0.011024     |   0\n",
      "       3022 |   0.008956  |    0.083180     |   2\n",
      "       3023 |   0.165439  |    0.032949     |   2\n",
      "       3024 |   0.328615  |    0.200789     |   1\n",
      "       3025 |   0.330873  |    0.147619     |   1\n",
      "       3026 |   0.070678  |    0.009040     |   2\n",
      "       3027 |   0.222388  |    0.045341     |   0\n",
      "       3028 |   0.095741  |    0.077801     |   2\n",
      "       3029 |   0.213389  |    0.026532     |   0\n",
      "       3030 |   0.251952  |    0.048538     |   0\n",
      "       3031 |   0.212830  |    0.218598     |   1\n",
      "       3032 |   0.256385  |    0.008647     |   0\n",
      "       3033 |   0.080402  |    0.084643     |   2\n",
      "       3034 |   0.035251  |    0.006890     |   2\n",
      "       3035 |   0.244938  |    0.087923     |   0\n",
      "       3036 |   0.257037  |    0.147836     |   1\n",
      "       3037 |   0.079875  |    0.018566     |   2\n",
      "       3038 |   0.389310  |    0.193607     |   1\n",
      "       3039 |   0.063823  |    0.003206     |   2\n",
      "       3040 |   0.249916  |    0.185300     |   1\n",
      "       3041 |   0.269798  |    0.009217     |   0\n",
      "       3042 |   0.248350  |    0.075013     |   0\n",
      "       3043 |   0.000180  |    0.022500     |   2\n",
      "       3044 |   0.000208  |    0.053069     |   2\n",
      "       3045 |   0.331818  |    0.177390     |   1\n",
      "       3046 |   0.243876  |    0.020198     |   0\n",
      "       3047 |   0.269860  |    0.040708     |   0\n",
      "       3048 |   0.288863  |    0.155533     |   1\n",
      "       3049 |   0.438973  |    0.150619     |   1\n",
      "       3050 |   0.276401  |    0.046875     |   0\n",
      "       3051 |   0.297641  |    0.160695     |   1\n",
      "       3052 |   0.323049  |    0.136637     |   1\n",
      "       3053 |   0.270842  |    0.079362     |   0\n",
      "       3054 |   0.000230  |    0.030237     |   2\n",
      "       3055 |   0.248980  |    0.076547     |   0\n",
      "       3056 |   0.313337  |    0.152061     |   1\n",
      "       3057 |   0.233190  |    0.028585     |   0\n",
      "       3058 |   0.000262  |    0.073395     |   2\n",
      "       3059 |   0.256334  |    0.011756     |   0\n",
      "       3060 |   0.259001  |    0.081585     |   0\n",
      "       3061 |   0.333010  |    0.156321     |   1\n",
      "       3062 |   0.262114  |    0.161181     |   1\n",
      "       3063 |   0.000253  |    0.006957     |   2\n",
      "       3064 |   0.274754  |    0.211556     |   1\n",
      "       3065 |   0.323559  |    0.157638     |   1\n",
      "       3066 |   0.427365  |    0.135918     |   1\n",
      "       3067 |   0.348654  |    0.149551     |   1\n",
      "       3068 |   0.000277  |    0.007899     |   2\n",
      "       3069 |   0.249741  |    0.074962     |   0\n",
      "       3070 |   0.297430  |    0.153602     |   1\n",
      "       3071 |   0.096827  |    0.026257     |   2\n",
      "       3072 |   0.117690  |    0.058213     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 3073: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       3073 |   0.113166  |    0.021222     |   2\n",
      "       3074 |   0.469923  |    0.183530     |   1\n",
      "       3075 |   0.314811  |    0.046471     |   0\n",
      "       3076 |   0.270126  |    0.161017     |   1\n",
      "       3077 |   0.075416  |    0.020949     |   2\n",
      "       3078 |   0.089845  |    0.060900     |   2\n",
      "       3079 |   0.108458  |    0.039122     |   2\n",
      "       3080 |   0.326043  |    0.049449     |   0\n",
      "       3081 |   0.351048  |    0.148829     |   1\n",
      "       3082 |   0.194944  |    0.048486     |   0\n",
      "       3083 |   0.047125  |    0.043895     |   2\n",
      "       3084 |   0.358873  |    0.206898     |   1\n",
      "       3085 |   0.270773  |    0.145921     |   1\n",
      "       3086 |   0.244232  |    0.034380     |   0\n",
      "       3087 |   0.316953  |    0.209437     |   1\n",
      "       3088 |   0.088257  |    0.010145     |   2\n",
      "       3089 |   0.086548  |    0.049623     |   2\n",
      "       3090 |   0.090775  |    0.040598     |   2\n",
      "       3091 |   0.332211  |    0.084693     |   0\n",
      "       3092 |   0.347859  |    0.137569     |   1\n",
      "       3093 |   0.085578  |    0.014405     |   2\n",
      "       3094 |   0.314823  |    0.078204     |   0\n",
      "       3095 |   0.037145  |    0.048548     |   2\n",
      "       3096 |   0.246181  |    0.197915     |   1\n",
      "       3097 |   0.000204  |    0.003530     |   2\n",
      "       3098 |   0.008271  |    0.046180     |   2\n",
      "       3099 |   0.268460  |    0.079193     |   0\n",
      "       3100 |   0.287301  |    0.151397     |   1\n",
      "       3101 |   0.166446  |    0.041445     |   2\n",
      "       3102 |   0.273277  |    0.161720     |   1\n",
      "       3103 |   0.072909  |    0.003150     |   2\n",
      "       3104 |   0.096790  |    0.079415     |   2\n",
      "       3105 |   0.246743  |    0.025154     |   0\n",
      "       3106 |   0.348986  |    0.189197     |   1\n",
      "       3107 |   0.078610  |    0.030854     |   2\n",
      "       3108 |   0.036672  |    0.052627     |   2\n",
      "       3109 |   0.268703  |    0.046950     |   0\n",
      "       3110 |   0.405492  |    0.144410     |   1\n",
      "       3111 |   0.214427  |    0.060365     |   0\n",
      "       3112 |   0.311257  |    0.147455     |   1\n",
      "       3113 |   0.266524  |    0.041908     |   0\n",
      "       3114 |   0.290404  |    0.045820     |   0\n",
      "       3115 |   0.291211  |    0.080095     |   0\n",
      "       3116 |   0.311077  |    0.139219     |   1\n",
      "       3117 |   0.262856  |    0.186281     |   1\n",
      "       3118 |   0.080395  |    0.020776     |   2\n",
      "       3119 |   0.272856  |    0.187758     |   1\n",
      "       3120 |   0.335130  |    0.141931     |   1\n",
      "       3121 |   0.242534  |    0.046028     |   0\n",
      "       3122 |   0.227736  |    0.077680     |   0\n",
      "       3123 |   0.447986  |    0.144308     |   1\n",
      "       3124 |   0.270840  |    0.157387     |   1\n",
      "       3125 |   0.278585  |    0.029340     |   0\n",
      "       3126 |   0.062561  |    0.042121     |   2\n",
      "       3127 |   0.346378  |    0.196701     |   1\n",
      "       3128 |   0.000184  |    0.019260     |   2\n",
      "       3129 |   0.281743  |    0.169446     |   1\n",
      "       3130 |   0.224110  |    0.078196     |   0\n",
      "       3131 |   0.000208  |    0.005858     |   2\n",
      "       3132 |   0.000231  |    0.073433     |   2\n",
      "       3133 |   0.228767  |    0.017262     |   0\n",
      "       3134 |   0.292584  |    0.200712     |   1\n",
      "       3135 |   0.278091  |    0.009265     |   0\n",
      "       3136 |   0.298493  |    0.078279     |   0\n",
      "       3137 |   0.209613  |    0.021840     |   0\n",
      "       3138 |   0.216899  |    0.196343     |   1\n",
      "       3139 |   0.000253  |    0.011575     |   2\n",
      "       3140 |   0.276755  |    0.085299     |   0\n",
      "       3141 |   0.000239  |    0.019455     |   2\n",
      "       3142 |   0.000274  |    0.057768     |   2\n",
      "       3143 |   0.099526  |    0.042339     |   2\n",
      "       3144 |   0.114766  |    0.066726     |   2\n",
      "       3145 |   0.311503  |    0.191526     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 3146: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       3146 |   0.107236  |    0.030095     |   2\n",
      "       3147 |   0.369649  |    0.151259     |   1\n",
      "       3148 |   0.369674  |    0.141592     |   1\n",
      "       3149 |   0.069492  |    0.074356     |   2\n",
      "       3150 |   0.219264  |    0.041559     |   0\n",
      "       3151 |   0.281675  |    0.147539     |   1\n",
      "       3152 |   0.085233  |    0.039650     |   2\n",
      "       3153 |   0.290469  |    0.044047     |   0\n",
      "       3154 |   0.107691  |    0.037842     |   2\n",
      "       3155 |   0.047096  |    0.046724     |   2\n",
      "       3156 |   0.085061  |    0.043775     |   2\n",
      "       3157 |   0.213014  |    0.044441     |   0\n",
      "       3158 |   0.086367  |    0.029242     |   2\n",
      "       3159 |   0.354743  |    0.211237     |   1\n",
      "       3160 |   0.343533  |    0.087655     |   1\n",
      "       3161 |   0.087663  |    0.051568     |   2\n",
      "       3162 |   0.286364  |    0.049252     |   0\n",
      "       3163 |   0.085113  |    0.076152     |   2\n",
      "       3164 |   0.039191  |    0.014557     |   2\n",
      "       3165 |   0.000204  |    0.088108     |   2\n",
      "       3166 |   0.293051  |    0.150019     |   1\n",
      "       3167 |   0.007964  |    0.009666     |   2\n",
      "       3168 |   0.304810  |    0.205268     |   1\n",
      "       3169 |   0.259285  |    0.143031     |   1\n",
      "       3170 |   0.193032  |    0.042071     |   0\n",
      "       3171 |   0.295752  |    0.201678     |   1\n",
      "       3172 |   0.271429  |    0.010573     |   0\n",
      "       3173 |   0.246980  |    0.193063     |   1\n",
      "       3174 |   0.160978  |    0.011424     |   2\n",
      "       3175 |   0.310087  |    0.192650     |   1\n",
      "       3176 |   0.067889  |    0.008703     |   2\n",
      "       3177 |   0.283972  |    0.216156     |   1\n",
      "       3178 |   0.299061  |    0.114956     |   1\n",
      "       3179 |   0.272435  |    0.031472     |   0\n",
      "       3180 |   0.095493  |    0.076276     |   2\n",
      "       3181 |   0.306626  |    0.031275     |   0\n",
      "       3182 |   0.303274  |    0.164497     |   1\n",
      "       3183 |   0.074048  |    0.045156     |   2\n",
      "       3184 |   0.035316  |    0.039057     |   2\n",
      "       3185 |   0.317213  |    0.159519     |   1\n",
      "       3186 |   0.250784  |    0.189258     |   1\n",
      "       3187 |   0.081265  |    0.021262     |   2\n",
      "       3188 |   0.301708  |    0.140674     |   1\n",
      "       3189 |   0.289078  |    0.149342     |   1\n",
      "       3190 |   0.284935  |    0.144992     |   1\n",
      "       3191 |   0.059262  |    0.025881     |   2\n",
      "       3192 |   0.374902  |    0.185615     |   1\n",
      "       3193 |   0.299985  |    0.115226     |   1\n",
      "       3194 |   0.000185  |    0.032799     |   2\n",
      "       3195 |   0.403080  |    0.140585     |   1\n",
      "       3196 |   0.239197  |    0.074504     |   0\n",
      "       3197 |   0.274975  |    0.163654     |   1\n",
      "       3198 |   0.270228  |    0.152701     |   1\n",
      "       3199 |   0.318608  |    0.170661     |   1\n",
      "       3200 |   0.272330  |    0.027587     |   0\n",
      "       3201 |   0.280080  |    0.056439     |   0\n",
      "       3202 |   0.282373  |    0.155499     |   1\n",
      "       3203 |   0.311889  |    0.207373     |   1\n",
      "       3204 |   0.262589  |    0.144883     |   1\n",
      "       3205 |   0.000216  |    0.041034     |   2\n",
      "       3206 |   0.000237  |    0.043603     |   2\n",
      "       3207 |   0.275950  |    0.036887     |   0\n",
      "       3208 |   0.000277  |    0.075239     |   2\n",
      "       3209 |   0.256641  |    0.148379     |   1\n",
      "       3210 |   0.000245  |    0.062644     |   2\n",
      "       3211 |   0.291173  |    0.199966     |   1\n",
      "       3212 |   0.000288  |    0.016439     |   2\n",
      "       3213 |   0.308870  |    0.201098     |   1\n",
      "       3214 |   0.280429  |    0.145544     |   1\n",
      "       3215 |   0.094592  |    0.005433     |   2\n",
      "       3216 |   0.111219  |    0.080775     |   2\n",
      "       3217 |   0.331711  |    0.146976     |   1\n",
      "       3218 |   0.237276  |    0.152030     |   1\n",
      "       3219 |   0.237645  |    0.165519     |   1\n",
      "       3220 |   0.276859  |    0.040148     |   0\n",
      "       3221 |   0.276829  |    0.079725     |   0\n",
      "       3222 |   0.344089  |    0.164497     |   1\n",
      "       3223 |   0.307160  |    0.163009     |   1\n",
      "       3224 |   0.302345  |    0.147512     |   1\n",
      "       3225 |   0.254250  |    0.047112     |   0\n",
      "       3226 |   0.308516  |    0.174958     |   1\n",
      "       3227 |   0.300787  |    0.135129     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 3228: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       3228 |   0.298673  |    0.155780     |   1\n",
      "       3229 |   0.106241  |    0.027019     |   2\n",
      "       3230 |   0.310987  |    0.076248     |   0\n",
      "       3231 |   0.240998  |    0.144381     |   1\n",
      "       3232 |   0.072895  |    0.045803     |   2\n",
      "       3233 |   0.083982  |    0.029913     |   2\n",
      "       3234 |   0.105961  |    0.084283     |   2\n",
      "       3235 |   0.046063  |    0.020781     |   2\n",
      "       3236 |   0.264840  |    0.083189     |   0\n",
      "       3237 |   0.316968  |    0.143267     |   1\n",
      "       3238 |   0.290858  |    0.030058     |   0\n",
      "       3239 |   0.344368  |    0.083420     |   0\n",
      "       3240 |   0.250198  |    0.019847     |   0\n",
      "       3241 |   0.272703  |    0.184577     |   1\n",
      "       3242 |   0.244842  |    0.021954     |   0\n",
      "       3243 |   0.084753  |    0.077435     |   2\n",
      "       3244 |   0.263970  |    0.026486     |   0\n",
      "       3245 |   0.088354  |    0.062514     |   2\n",
      "       3246 |   0.271115  |    0.149495     |   1\n",
      "       3247 |   0.089257  |    0.006959     |   2\n",
      "       3248 |   0.222207  |    0.041628     |   0\n",
      "       3249 |   0.221485  |    0.055337     |   0\n",
      "       3250 |   0.240062  |    0.075634     |   0\n",
      "       3251 |   0.236870  |    0.145455     |   1\n",
      "       3252 |   0.261601  |    0.160615     |   1\n",
      "       3253 |   0.087691  |    0.048048     |   2\n",
      "       3254 |   0.278925  |    0.054062     |   0\n",
      "       3255 |   0.328718  |    0.182456     |   1\n",
      "       3256 |   0.297645  |    0.147235     |   1\n",
      "       3257 |   0.249877  |    0.044416     |   0\n",
      "       3258 |   0.292307  |    0.045470     |   0\n",
      "       3259 |   0.281841  |    0.060610     |   0\n",
      "       3260 |   0.282498  |    0.182537     |   1\n",
      "       3261 |   0.266771  |    0.012273     |   0\n",
      "       3262 |   0.282288  |    0.149832     |   1\n",
      "       3263 |   0.322793  |    0.145152     |   1\n",
      "       3264 |   0.307041  |    0.197547     |   1\n",
      "       3265 |   0.280473  |    0.160277     |   1\n",
      "       3266 |   0.040618  |    0.005125     |   2\n",
      "       3267 |   0.276112  |    0.199956     |   1\n",
      "       3268 |   0.221130  |    0.012343     |   0\n",
      "       3269 |   0.233646  |    0.081151     |   0\n",
      "       3270 |   0.254449  |    0.028787     |   0\n",
      "       3271 |   0.280897  |    0.190641     |   1\n",
      "       3272 |   0.265027  |    0.043524     |   0\n",
      "       3273 |   0.355944  |    0.162560     |   1\n",
      "       3274 |   0.254067  |    0.135696     |   1\n",
      "       3275 |   0.263172  |    0.202823     |   1\n",
      "       3276 |   0.356389  |    0.093553     |   1\n",
      "       3277 |   0.269246  |    0.043070     |   0\n",
      "       3278 |   0.281149  |    0.194452     |   1\n",
      "       3279 |   0.346292  |    0.141032     |   1\n",
      "       3280 |   0.363697  |    0.151041     |   1\n",
      "       3281 |   0.341484  |    0.155464     |   1\n",
      "       3282 |   0.236832  |    0.005494     |   0\n",
      "       3283 |   0.000214  |    0.046666     |   2\n",
      "       3284 |   0.206041  |    0.054229     |   0\n",
      "       3285 |   0.341840  |    0.147132     |   1\n",
      "       3286 |   0.325151  |    0.222824     |   1\n",
      "       3287 |   0.252474  |    0.006550     |   0\n",
      "       3288 |   0.210521  |    0.046673     |   0\n",
      "       3289 |   0.235026  |    0.041831     |   0\n",
      "       3290 |   0.229766  |    0.042434     |   0\n",
      "       3291 |   0.249136  |    0.051702     |   0\n",
      "       3292 |   0.007679  |    0.046684     |   2\n",
      "       3293 |   0.230308  |    0.078052     |   0\n",
      "       3294 |   0.223741  |    0.050561     |   0\n",
      "       3295 |   0.311262  |    0.150048     |   1\n",
      "       3296 |   0.284974  |    0.030537     |   0\n",
      "       3297 |   0.306473  |    0.159528     |   1\n",
      "       3298 |   0.158756  |    0.047205     |   2\n",
      "       3299 |   0.317043  |    0.139482     |   1\n",
      "       3300 |   0.070347  |    0.025714     |   2\n",
      "       3301 |   0.248465  |    0.092426     |   0\n",
      "       3302 |   0.279142  |    0.132557     |   1\n",
      "       3303 |   0.249922  |    0.046892     |   0\n",
      "       3304 |   0.251169  |    0.026894     |   0\n",
      "       3305 |   0.280316  |    0.198434     |   1\n",
      "       3306 |   0.327875  |    0.098852     |   1\n",
      "       3307 |   0.096535  |    0.059398     |   2\n",
      "       3308 |   0.279116  |    0.149843     |   1\n",
      "       3309 |   0.239172  |    0.167478     |   1\n",
      "       3310 |   0.080679  |    0.057844     |   2\n",
      "       3311 |   0.300021  |    0.191578     |   1\n",
      "       3312 |   0.251297  |    0.008304     |   0\n",
      "       3313 |   0.037262  |    0.078683     |   2\n",
      "       3314 |   0.356151  |    0.186749     |   1\n",
      "       3315 |   0.269209  |    0.154471     |   1\n",
      "       3316 |   0.309499  |    0.149688     |   1\n",
      "       3317 |   0.293577  |    0.155080     |   1\n",
      "       3318 |   0.216071  |    0.045362     |   0\n",
      "       3319 |   0.298209  |    0.144786     |   1\n",
      "       3320 |   0.215510  |    0.052332     |   0\n",
      "       3321 |   0.274263  |    0.188718     |   1\n",
      "       3322 |   0.283371  |    0.026053     |   0\n",
      "       3323 |   0.082232  |    0.083842     |   2\n",
      "       3324 |   0.396525  |    0.138686     |   1\n",
      "       3325 |   0.310419  |    0.036786     |   0\n",
      "       3326 |   0.378241  |    0.145560     |   1\n",
      "       3327 |   0.215027  |    0.045811     |   0\n",
      "       3328 |   0.059188  |    0.052584     |   2\n",
      "       3329 |   0.224256  |    0.224116     |   1\n",
      "       3330 |   0.208842  |    0.006304     |   0\n",
      "       3331 |   0.343244  |    0.152830     |   1\n",
      "       3332 |   0.230685  |    0.009325     |   0\n",
      "       3333 |   0.330002  |    0.149919     |   1\n",
      "       3334 |   0.305440  |    0.196537     |   1\n",
      "       3335 |   0.000189  |    0.005067     |   2\n",
      "       3336 |   0.261624  |    0.074871     |   0\n",
      "       3337 |   0.178005  |    0.021383     |   0\n",
      "       3338 |   0.325728  |    0.086851     |   0\n",
      "       3339 |   0.237305  |    0.011206     |   0\n",
      "       3340 |   0.000227  |    0.078839     |   2\n",
      "       3341 |   0.213075  |    0.021693     |   0\n",
      "       3342 |   0.000249  |    0.078300     |   2\n",
      "       3343 |   0.311808  |    0.158663     |   1\n",
      "       3344 |   0.308586  |    0.160994     |   1\n",
      "       3345 |   0.281344  |    0.151167     |   1\n",
      "       3346 |   0.285385  |    0.006884     |   0\n",
      "       3347 |   0.000281  |    0.080390     |   2\n",
      "       3348 |   0.000240  |    0.008459     |   2\n",
      "       3349 |   0.284012  |    0.077071     |   0\n",
      "       3350 |   0.291031  |    0.135043     |   1\n",
      "       3351 |   0.000277  |    0.044750     |   2\n",
      "       3352 |   0.242454  |    0.225494     |   1\n",
      "       3353 |   0.210781  |    0.152701     |   1\n",
      "       3354 |   0.206050  |    0.005911     |   0\n",
      "       3355 |   0.279957  |    0.051190     |   0\n",
      "       3356 |   0.291913  |    0.040533     |   0\n",
      "       3357 |   0.297948  |    0.038644     |   0\n",
      "       3358 |   0.314436  |    0.169685     |   1\n",
      "       3359 |   0.344059  |    0.149372     |   1\n",
      "       3360 |   0.105522  |    0.027022     |   2\n",
      "       3361 |   0.261622  |    0.044050     |   0\n",
      "       3362 |   0.112668  |    0.053520     |   2\n",
      "       3363 |   0.303995  |    0.154879     |   1\n",
      "       3364 |   0.302318  |    0.143205     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 3365: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       3365 |   0.260274  |    0.012935     |   0\n",
      "       3366 |   0.107318  |    0.074113     |   2\n",
      "       3367 |   0.460369  |    0.153523     |   1\n",
      "       3368 |   0.370480  |    0.135938     |   1\n",
      "       3369 |   0.293032  |    0.050484     |   0\n",
      "       3370 |   0.297299  |    0.176234     |   1\n",
      "       3371 |   0.272181  |    0.021020     |   0\n",
      "       3372 |   0.071267  |    0.086444     |   2\n",
      "       3373 |   0.081581  |    0.017647     |   2\n",
      "       3374 |   0.107473  |    0.079776     |   2\n",
      "       3375 |   0.300750  |    0.021152     |   0\n",
      "       3376 |   0.282658  |    0.170079     |   1\n",
      "       3377 |   0.371189  |    0.156228     |   1\n",
      "       3378 |   0.218655  |    0.048492     |   0\n",
      "       3379 |   0.335932  |    0.135663     |   1\n",
      "       3380 |   0.047986  |    0.034581     |   2\n",
      "       3381 |   0.355205  |    0.209923     |   1\n",
      "       3382 |   0.254307  |    0.013874     |   0\n",
      "       3383 |   0.085304  |    0.049702     |   2\n",
      "       3384 |   0.085932  |    0.085870     |   2\n",
      "       3385 |   0.223284  |    0.147488     |   1\n",
      "       3386 |   0.086661  |    0.019958     |   2\n",
      "       3387 |   0.089450  |    0.049507     |   2\n",
      "       3388 |   0.237498  |    0.175024     |   1\n",
      "       3389 |   0.341450  |    0.170798     |   1\n",
      "       3390 |   0.345686  |    0.151386     |   1\n",
      "       3391 |   0.040546  |    0.012156     |   2\n",
      "       3392 |   0.281183  |    0.076522     |   0\n",
      "       3393 |   0.319894  |    0.022109     |   0\n",
      "       3394 |   0.227609  |    0.073258     |   0\n",
      "       3395 |   0.000212  |    0.043327     |   2\n",
      "       3396 |   0.007786  |    0.054614     |   2\n",
      "       3397 |   0.161052  |    0.043037     |   2\n",
      "       3398 |   0.279905  |    0.149605     |   1\n",
      "       3399 |   0.224485  |    0.007825     |   0\n",
      "       3400 |   0.065431  |    0.080364     |   2\n",
      "       3401 |   0.264295  |    0.195046     |   1\n",
      "       3402 |   0.262574  |    0.013720     |   0\n",
      "       3403 |   0.093286  |    0.053953     |   2\n",
      "       3404 |   0.278923  |    0.144403     |   1\n",
      "       3405 |   0.243118  |    0.080216     |   0\n",
      "       3406 |   0.077181  |    0.011187     |   2\n",
      "       3407 |   0.036379  |    0.073839     |   2\n",
      "       3408 |   0.215457  |    0.046716     |   0\n",
      "       3409 |   0.334110  |    0.196688     |   1\n",
      "       3410 |   0.321922  |    0.134575     |   1\n",
      "       3411 |   0.328083  |    0.029458     |   0\n",
      "       3412 |   0.080607  |    0.077040     |   2\n",
      "       3413 |   0.225929  |    0.009709     |   0\n",
      "       3414 |   0.058736  |    0.075759     |   2\n",
      "       3415 |   0.000186  |    0.005927     |   2\n",
      "       3416 |   0.000219  |    0.076283     |   2\n",
      "       3417 |   0.256593  |    0.196720     |   1\n",
      "       3418 |   0.349761  |    0.160638     |   1\n",
      "       3419 |   0.239062  |    0.013853     |   0\n",
      "       3420 |   0.231075  |    0.054143     |   0\n",
      "       3421 |   0.268942  |    0.196392     |   1\n",
      "       3422 |   0.247184  |    0.006887     |   0\n",
      "       3423 |   0.327740  |    0.085108     |   0\n",
      "       3424 |   0.275621  |    0.156183     |   1\n",
      "       3425 |   0.271963  |    0.170147     |   1\n",
      "       3426 |   0.257250  |    0.171383     |   1\n",
      "       3427 |   0.000229  |    0.003682     |   2\n",
      "       3428 |   0.291669  |    0.051509     |   0\n",
      "       3429 |   0.281223  |    0.076238     |   0\n",
      "       3430 |   0.247017  |    0.029774     |   0\n",
      "       3431 |   0.257944  |    0.054817     |   0\n",
      "       3432 |   0.270695  |    0.197783     |   1\n",
      "       3433 |   0.000252  |    0.026377     |   2\n",
      "       3434 |   0.375370  |    0.193134     |   1\n",
      "       3435 |   0.000228  |    0.008931     |   2\n",
      "       3436 |   0.301674  |    0.079637     |   0\n",
      "       3437 |   0.000271  |    0.028332     |   2\n",
      "       3438 |   0.101111  |    0.096096     |   2\n",
      "       3439 |   0.112321  |    0.014311     |   2\n",
      "       3440 |   0.205592  |    0.083368     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 3441: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       3441 |   0.254998  |    0.141040     |   1\n",
      "       3442 |   0.226420  |    0.017169     |   0\n",
      "       3443 |   0.284756  |    0.080991     |   0\n",
      "       3444 |   0.289443  |    0.042322     |   0\n",
      "       3445 |   0.291606  |    0.189680     |   1\n",
      "       3446 |   0.226477  |    0.009903     |   0\n",
      "       3447 |   0.281056  |    0.077901     |   0\n",
      "       3448 |   0.105164  |    0.019844     |   2\n",
      "       3449 |   0.243417  |    0.073591     |   0\n",
      "       3450 |   0.071022  |    0.019183     |   2\n",
      "       3451 |   0.079950  |    0.054135     |   2\n",
      "       3452 |   0.106550  |    0.042715     |   2\n",
      "       3453 |   0.276775  |    0.045353     |   0\n",
      "       3454 |   0.047347  |    0.041078     |   2\n",
      "       3455 |   0.084233  |    0.086808     |   2\n",
      "       3456 |   0.289699  |    0.159840     |   1\n",
      "       3457 |   0.087531  |    0.047442     |   2\n",
      "       3458 |   0.339070  |    0.043300     |   0\n",
      "       3459 |   0.201087  |    0.043945     |   0\n",
      "       3460 |   0.086406  |    0.040756     |   2\n",
      "       3461 |   0.084116  |    0.042069     |   2\n",
      "       3462 |   0.261050  |    0.081356     |   0\n",
      "       3463 |   0.038104  |    0.028740     |   2\n",
      "       3464 |   0.267175  |    0.080304     |   0\n",
      "       3465 |   0.293019  |    0.102905     |   1\n",
      "       3466 |   0.000199  |    0.050193     |   2\n",
      "       3467 |   0.232908  |    0.208607     |   1\n",
      "       3468 |   0.007796  |    0.007432     |   2\n",
      "       3469 |   0.162314  |    0.052511     |   2\n",
      "       3470 |   0.422424  |    0.152371     |   1\n",
      "       3471 |   0.285695  |    0.144934     |   1\n",
      "       3472 |   0.227801  |    0.030552     |   0\n",
      "       3473 |   0.065953  |    0.076505     |   2\n",
      "       3474 |   0.288448  |    0.050880     |   0\n",
      "       3475 |   0.239373  |    0.133652     |   1\n",
      "       3476 |   0.093124  |    0.042499     |   2\n",
      "       3477 |   0.076211  |    0.052060     |   2\n",
      "       3478 |   0.308201  |    0.138972     |   1\n",
      "       3479 |   0.033990  |    0.013998     |   2\n",
      "       3480 |   0.347220  |    0.192421     |   1\n",
      "       3481 |   0.236912  |    0.188688     |   1\n",
      "       3482 |   0.297063  |    0.152429     |   1\n",
      "       3483 |   0.275329  |    0.039601     |   0\n",
      "       3484 |   0.078475  |    0.080112     |   2\n",
      "       3485 |   0.211588  |    0.009319     |   0\n",
      "       3486 |   0.249075  |    0.084332     |   0\n",
      "       3487 |   0.058148  |    0.034988     |   2\n",
      "       3488 |   0.311753  |    0.196980     |   1\n",
      "       3489 |   0.000183  |    0.004804     |   2\n",
      "       3490 |   0.000206  |    0.080301     |   2\n",
      "       3491 |   0.000228  |    0.018082     |   2\n",
      "       3492 |   0.237366  |    0.074776     |   0\n",
      "       3493 |   0.226417  |    0.142105     |   1\n",
      "       3494 |   0.244173  |    0.144444     |   1\n",
      "       3495 |   0.000253  |    0.048661     |   2\n",
      "       3496 |   0.000229  |    0.078523     |   2\n",
      "       3497 |   0.412903  |    0.132605     |   1\n",
      "       3498 |   0.000261  |    0.041029     |   2\n",
      "       3499 |   0.097485  |    0.053471     |   2\n",
      "       3500 |   0.291664  |    0.205564     |   1\n",
      "       3501 |   0.332246  |    0.191769     |   1\n",
      "       3502 |   0.254396  |    0.031680     |   0\n",
      "       3503 |   0.102989  |    0.049010     |   2\n",
      "       3504 |   0.303316  |    0.157800     |   1\n",
      "       3505 |   0.236452  |    0.022673     |   0\n",
      "       3506 |   0.070190  |    0.074927     |   2\n",
      "       3507 |   0.081328  |    0.030204     |   2\n",
      "       3508 |   0.294299  |    0.083097     |   0\n",
      "       3509 |   0.332995  |    0.135559     |   1\n",
      "       3510 |   0.316409  |    0.150399     |   1\n",
      "       3511 |   0.261708  |    0.033991     |   0\n",
      "       3512 |   0.292812  |    0.074435     |   0\n",
      "       3513 |   0.102422  |    0.020716     |   2\n",
      "       3514 |   0.238101  |    0.193957     |   1\n",
      "       3515 |   0.293961  |    0.014757     |   0\n",
      "       3516 |   0.314831  |    0.189542     |   1\n",
      "       3517 |   0.045747  |    0.014243     |   2\n",
      "       3518 |   0.222352  |    0.198470     |   1\n",
      "       3519 |   0.081532  |    0.045943     |   2\n",
      "       3520 |   0.242791  |    0.050914     |   0\n",
      "       3521 |   0.083515  |    0.078352     |   2\n",
      "       3522 |   0.086173  |    0.037860     |   2\n",
      "       3523 |   0.078033  |    0.042667     |   2\n",
      "       3524 |   0.278889  |    0.042315     |   0\n",
      "       3525 |   0.035337  |    0.085607     |   2\n",
      "       3526 |   0.000198  |    0.018352     |   2\n",
      "       3527 |   0.244702  |    0.202425     |   1\n",
      "       3528 |   0.261229  |    0.006406     |   0\n",
      "       3529 |   0.007735  |    0.077752     |   2\n",
      "       3530 |   0.299078  |    0.161985     |   1\n",
      "       3531 |   0.297373  |    0.139681     |   1\n",
      "       3532 |   0.248977  |    0.222120     |   1\n",
      "       3533 |   0.251383  |    0.011985     |   0\n",
      "       3534 |   0.176715  |    0.162115     |   1\n",
      "       3535 |   0.159647  |    0.045272     |   2\n",
      "       3536 |   0.364022  |    0.154478     |   1\n",
      "       3537 |   0.298222  |    0.140926     |   1\n",
      "       3538 |   0.279181  |    0.048822     |   0\n",
      "       3539 |   0.257115  |    0.081238     |   0\n",
      "       3540 |   0.254800  |    0.014428     |   0\n",
      "       3541 |   0.067476  |    0.089313     |   2\n",
      "       3542 |   0.238805  |    0.026083     |   0\n",
      "       3543 |   0.217603  |    0.041728     |   0\n",
      "       3544 |   0.094410  |    0.079351     |   2\n",
      "       3545 |   0.304045  |    0.155487     |   1\n",
      "       3546 |   0.301758  |    0.011259     |   0\n",
      "       3547 |   0.229150  |    0.191693     |   1\n",
      "       3548 |   0.073486  |    0.027303     |   2\n",
      "       3549 |   0.215242  |    0.079466     |   0\n",
      "       3550 |   0.298162  |    0.150590     |   1\n",
      "       3551 |   0.035806  |    0.047607     |   2\n",
      "       3552 |   0.267467  |    0.203316     |   1\n",
      "       3553 |   0.080667  |    0.037070     |   2\n",
      "       3554 |   0.259305  |    0.083868     |   0\n",
      "       3555 |   0.289833  |    0.135028     |   1\n",
      "       3556 |   0.341067  |    0.159209     |   1\n",
      "       3557 |   0.245207  |    0.045163     |   0\n",
      "       3558 |   0.057787  |    0.009257     |   2\n",
      "       3559 |   0.277061  |    0.083134     |   0\n",
      "       3560 |   0.000181  |    0.015318     |   2\n",
      "       3561 |   0.281097  |    0.072222     |   0\n",
      "       3562 |   0.247528  |    0.030333     |   0\n",
      "       3563 |   0.000212  |    0.038377     |   2\n",
      "       3564 |   0.203498  |    0.081372     |   0\n",
      "       3565 |   0.252332  |    0.151259     |   1\n",
      "       3566 |   0.000229  |    0.035592     |   2\n",
      "       3567 |   0.000257  |    0.071568     |   2\n",
      "       3568 |   0.000227  |    0.017289     |   2\n",
      "       3569 |   0.254988  |    0.052528     |   0\n",
      "       3570 |   0.283483  |    0.078451     |   0\n",
      "       3571 |   0.200728  |    0.017456     |   0\n",
      "       3572 |   0.000249  |    0.071423     |   2\n",
      "       3573 |   0.102500  |    0.025796     |   2\n",
      "       3574 |   0.112560  |    0.076489     |   2\n",
      "       3575 |   0.348173  |    0.153002     |   1\n",
      "       3576 |   0.299860  |    0.151608     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 3577: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       3577 |   0.105539  |    0.008326     |   2\n",
      "       3578 |   0.287871  |    0.197497     |   1\n",
      "       3579 |   0.287181  |    0.149673     |   1\n",
      "       3580 |   0.335141  |    0.137901     |   1\n",
      "       3581 |   0.266695  |    0.027320     |   0\n",
      "       3582 |   0.067360  |    0.076707     |   2\n",
      "       3583 |   0.076617  |    0.039635     |   2\n",
      "       3584 |   0.104430  |    0.040210     |   2\n",
      "       3585 |   0.235936  |    0.045174     |   0\n",
      "       3586 |   0.044990  |    0.048302     |   2\n",
      "       3587 |   0.251606  |    0.076289     |   0\n",
      "       3588 |   0.081744  |    0.012962     |   2\n",
      "       3589 |   0.086681  |    0.075832     |   2\n",
      "       3590 |   0.264460  |    0.039515     |   0\n",
      "       3591 |   0.276644  |    0.039174     |   0\n",
      "       3592 |   0.275276  |    0.201460     |   1\n",
      "       3593 |   0.239181  |    0.008041     |   0\n",
      "       3594 |   0.088315  |    0.055732     |   2\n",
      "       3595 |   0.078111  |    0.048215     |   2\n",
      "       3596 |   0.035111  |    0.040340     |   2\n",
      "       3597 |   0.204840  |    0.027770     |   0\n",
      "       3598 |   0.000191  |    0.064128     |   2\n",
      "       3599 |   0.314877  |    0.140945     |   1\n",
      "       3600 |   0.197499  |    0.052063     |   0\n",
      "       3601 |   0.214864  |    0.145003     |   1\n",
      "       3602 |   0.225271  |    0.038458     |   0\n",
      "       3603 |   0.368377  |    0.146923     |   1\n",
      "       3604 |   0.008759  |    0.047020     |   2\n",
      "       3605 |   0.160973  |    0.027060     |   2\n",
      "       3606 |   0.066287  |    0.086625     |   2\n",
      "       3607 |   0.216314  |    0.148642     |   1\n",
      "       3608 |   0.217222  |    0.154088     |   1\n",
      "       3609 |   0.090434  |    0.049368     |   2\n",
      "       3610 |   0.359881  |    0.185845     |   1\n",
      "       3611 |   0.073518  |    0.010985     |   2\n",
      "       3612 |   0.033422  |    0.043864     |   2\n",
      "       3613 |   0.075512  |    0.023435     |   2\n",
      "       3614 |   0.266873  |    0.210249     |   1\n",
      "       3615 |   0.057974  |    0.010331     |   2\n",
      "       3616 |   0.313708  |    0.075069     |   0\n",
      "       3617 |   0.000176  |    0.041152     |   2\n",
      "       3618 |   0.242365  |    0.131049     |   1\n",
      "       3619 |   0.410185  |    0.129045     |   1\n",
      "       3620 |   0.305938  |    0.039694     |   0\n",
      "       3621 |   0.207817  |    0.076584     |   0\n",
      "       3622 |   0.000198  |    0.027325     |   2\n",
      "       3623 |   0.267869  |    0.071232     |   0\n",
      "       3624 |   0.000222  |    0.013898     |   2\n",
      "       3625 |   0.000238  |    0.042214     |   2\n",
      "       3626 |   0.246533  |    0.071792     |   0\n",
      "       3627 |   0.231608  |    0.024441     |   0\n",
      "       3628 |   0.000216  |    0.050030     |   2\n",
      "       3629 |   0.000236  |    0.075076     |   2\n",
      "       3630 |   0.254133  |    0.055464     |   0\n",
      "       3631 |   0.292905  |    0.141692     |   1\n",
      "       3632 |   0.203299  |    0.041402     |   0\n",
      "       3633 |   0.289088  |    0.205117     |   1\n",
      "       3634 |   0.236051  |    0.146081     |   1\n",
      "       3635 |   0.333576  |    0.143725     |   1\n",
      "       3636 |   0.095393  |    0.043359     |   2\n",
      "       3637 |   0.110541  |    0.086577     |   2\n",
      "       3638 |   0.292309  |    0.138459     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 3639: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       3639 |   0.249123  |    0.004795     |   0\n",
      "       3640 |   0.288585  |    0.193950     |   1\n",
      "       3641 |   0.313119  |    0.131738     |   1\n",
      "       3642 |   0.249159  |    0.018025     |   0\n",
      "       3643 |   0.288135  |    0.213977     |   1\n",
      "       3644 |   0.317415  |    0.097806     |   1\n",
      "       3645 |   0.335308  |    0.158952     |   1\n",
      "       3646 |   0.345461  |    0.137786     |   1\n",
      "       3647 |   0.104760  |    0.019486     |   2\n",
      "       3648 |   0.287657  |    0.096486     |   0\n",
      "       3649 |   0.370694  |    0.132057     |   1\n",
      "       3650 |   0.284539  |    0.166002     |   1\n",
      "       3651 |   0.068727  |    0.051913     |   2\n",
      "       3652 |   0.235733  |    0.175249     |   1\n",
      "       3653 |   0.077108  |    0.017022     |   2\n",
      "       3654 |   0.101930  |    0.079932     |   2\n",
      "       3655 |   0.189445  |    0.154239     |   1\n",
      "       3656 |   0.356022  |    0.076985     |   0\n",
      "       3657 |   0.240892  |    0.041952     |   0\n",
      "       3658 |   0.046025  |    0.048812     |   2\n",
      "       3659 |   0.335342  |    0.142841     |   1\n",
      "       3660 |   0.286279  |    0.042883     |   0\n",
      "       3661 |   0.193347  |    0.075599     |   0\n",
      "       3662 |   0.288534  |    0.185877     |   1\n",
      "       3663 |   0.218321  |    0.029202     |   0\n",
      "       3664 |   0.246556  |    0.080608     |   0\n",
      "       3665 |   0.252798  |    0.194863     |   1\n",
      "       3666 |   0.266001  |    0.136569     |   1\n",
      "       3667 |   0.082983  |    0.023841     |   2\n",
      "       3668 |   0.277509  |    0.199465     |   1\n",
      "       3669 |   0.084419  |    0.012118     |   2\n",
      "       3670 |   0.227161  |    0.211354     |   1\n",
      "       3671 |   0.268880  |    0.025264     |   0\n",
      "       3672 |   0.226411  |    0.044445     |   0\n",
      "       3673 |   0.085968  |    0.049273     |   2\n",
      "       3674 |   0.081956  |    0.036829     |   2\n",
      "       3675 |   0.036127  |    0.050949     |   2\n",
      "       3676 |   0.232702  |    0.046352     |   0\n",
      "       3677 |   0.231464  |    0.167640     |   1\n",
      "       3678 |   0.334374  |    0.193289     |   1\n",
      "       3679 |   0.000199  |    0.008431     |   2\n",
      "       3680 |   0.362487  |    0.138332     |   1\n",
      "       3681 |   0.396562  |    0.141623     |   1\n",
      "       3682 |   0.273387  |    0.034250     |   0\n",
      "       3683 |   0.299901  |    0.210379     |   1\n",
      "       3684 |   0.277888  |    0.139777     |   1\n",
      "       3685 |   0.008220  |    0.015935     |   2\n",
      "       3686 |   0.275057  |    0.185467     |   1\n",
      "       3687 |   0.155839  |    0.016834     |   2\n",
      "       3688 |   0.294448  |    0.242753     |   1\n",
      "       3689 |   0.066947  |    0.004657     |   2\n",
      "       3690 |   0.269487  |    0.025348     |   0\n",
      "       3691 |   0.179688  |    0.075740     |   0\n",
      "       3692 |   0.221237  |    0.008111     |   0\n",
      "       3693 |   0.091773  |    0.078383     |   2\n",
      "       3694 |   0.297989  |    0.130236     |   1\n",
      "       3695 |   0.219135  |    0.053452     |   0\n",
      "       3696 |   0.375793  |    0.180768     |   1\n",
      "       3697 |   0.073591  |    0.017957     |   2\n",
      "       3698 |   0.278617  |    0.207654     |   1\n",
      "       3699 |   0.256333  |    0.136184     |   1\n",
      "       3700 |   0.307669  |    0.138900     |   1\n",
      "       3701 |   0.246872  |    0.055496     |   0\n",
      "       3702 |   0.289544  |    0.165931     |   1\n",
      "       3703 |   0.265069  |    0.033211     |   0\n",
      "       3704 |   0.033400  |    0.077803     |   2\n",
      "       3705 |   0.183237  |    0.139414     |   1\n",
      "       3706 |   0.255078  |    0.026590     |   0\n",
      "       3707 |   0.368126  |    0.204685     |   1\n",
      "       3708 |   0.077690  |    0.007878     |   2\n",
      "       3709 |   0.223178  |    0.194819     |   1\n",
      "       3710 |   0.056023  |    0.041906     |   2\n",
      "       3711 |   0.000179  |    0.041672     |   2\n",
      "       3712 |   0.000204  |    0.053995     |   2\n",
      "       3713 |   0.000227  |    0.047704     |   2\n",
      "       3714 |   0.362118  |    0.155448     |   1\n",
      "       3715 |   0.299358  |    0.155874     |   1\n",
      "       3716 |   0.201469  |    0.041292     |   0\n",
      "       3717 |   0.000248  |    0.091458     |   2\n",
      "       3718 |   0.310919  |    0.131515     |   1\n",
      "       3719 |   0.000219  |    0.015880     |   2\n",
      "       3720 |   0.231787  |    0.083915     |   0\n",
      "       3721 |   0.227538  |    0.022798     |   0\n",
      "       3722 |   0.000259  |    0.075796     |   2\n",
      "       3723 |   0.211486  |    0.167689     |   1\n",
      "       3724 |   0.292096  |    0.192007     |   1\n",
      "       3725 |   0.090425  |    0.006138     |   2\n",
      "       3726 |   0.292555  |    0.077151     |   0\n",
      "       3727 |   0.261275  |    0.130685     |   1\n",
      "       3728 |   0.106937  |    0.025399     |   2\n",
      "       3729 |   0.248361  |    0.217628     |   1\n",
      "       3730 |   0.282469  |    0.102565     |   1\n",
      "       3731 |   0.253792  |    0.169988     |   1\n",
      "       3732 |   0.243783  |    0.148875     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 3733: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       3733 |   0.179314  |    0.181555     |   1\n",
      "       3734 |   0.320644  |    0.083201     |   1\n",
      "       3735 |   0.099928  |    0.050039     |   2\n",
      "       3736 |   0.222846  |    0.200551     |   1\n",
      "       3737 |   0.067468  |    0.006177     |   2\n",
      "       3738 |   0.076184  |    0.051533     |   2\n",
      "       3739 |   0.221932  |    0.157368     |   1\n",
      "       3740 |   0.259564  |    0.028725     |   0\n",
      "       3741 |   0.279737  |    0.077718     |   0\n",
      "       3742 |   0.193664  |    0.011688     |   0\n",
      "       3743 |   0.263113  |    0.081092     |   0\n",
      "       3744 |   0.262043  |    0.148835     |   1\n",
      "       3745 |   0.099522  |    0.003782     |   2\n",
      "       3746 |   0.044676  |    0.045607     |   2\n",
      "       3747 |   0.357652  |    0.136816     |   1\n",
      "       3748 |   0.231221  |    0.079824     |   0\n",
      "       3749 |   0.325872  |    0.145108     |   1\n",
      "       3750 |   0.082909  |    0.005760     |   2\n",
      "       3751 |   0.080338  |    0.045074     |   2\n",
      "       3752 |   0.318648  |    0.046715     |   0\n",
      "       3753 |   0.266902  |    0.200549     |   1\n",
      "       3754 |   0.083932  |    0.004290     |   2\n",
      "       3755 |   0.303288  |    0.205512     |   1\n",
      "       3756 |   0.082270  |    0.003186     |   2\n",
      "       3757 |   0.249943  |    0.199659     |   1\n",
      "       3758 |   0.300998  |    0.147105     |   1\n",
      "       3759 |   0.310529  |    0.185566     |   1\n",
      "       3760 |   0.243479  |    0.005377     |   0\n",
      "       3761 |   0.036933  |    0.078504     |   2\n",
      "       3762 |   0.000196  |    0.027205     |   2\n",
      "       3763 |   0.269740  |    0.079072     |   0\n",
      "       3764 |   0.324464  |    0.030248     |   0\n",
      "       3765 |   0.272960  |    0.184578     |   1\n",
      "       3766 |   0.008594  |    0.035069     |   2\n",
      "       3767 |   0.294692  |    0.201376     |   1\n",
      "       3768 |   0.155866  |    0.011667     |   2\n",
      "       3769 |   0.366306  |    0.198837     |   1\n",
      "       3770 |   0.286074  |    0.145704     |   1\n",
      "       3771 |   0.064553  |    0.026897     |   2\n",
      "       3772 |   0.247563  |    0.077466     |   0\n",
      "       3773 |   0.297406  |    0.020908     |   0\n",
      "       3774 |   0.092465  |    0.044296     |   2\n",
      "       3775 |   0.275559  |    0.084479     |   0\n",
      "       3776 |   0.231070  |    0.024729     |   0\n",
      "       3777 |   0.072139  |    0.053611     |   2\n",
      "       3778 |   0.033479  |    0.061432     |   2\n",
      "       3779 |   0.079129  |    0.041092     |   2\n",
      "       3780 |   0.248489  |    0.053162     |   0\n",
      "       3781 |   0.260506  |    0.052260     |   0\n",
      "       3782 |   0.249226  |    0.057282     |   0\n",
      "       3783 |   0.204758  |    0.150322     |   1\n",
      "       3784 |   0.053876  |    0.043939     |   2\n",
      "       3785 |   0.258832  |    0.159862     |   1\n",
      "       3786 |   0.286380  |    0.161838     |   1\n",
      "       3787 |   0.301585  |    0.004498     |   0\n",
      "       3788 |   0.000180  |    0.048661     |   2\n",
      "       3789 |   0.218828  |    0.206004     |   1\n",
      "       3790 |   0.000202  |    0.017627     |   2\n",
      "       3791 |   0.321994  |    0.200189     |   1\n",
      "       3792 |   0.000234  |    0.026616     |   2\n",
      "       3793 |   0.291681  |    0.152019     |   1\n",
      "       3794 |   0.227138  |    0.045680     |   0\n",
      "       3795 |   0.000252  |    0.084224     |   2\n",
      "       3796 |   0.000218  |    0.018445     |   2\n",
      "       3797 |   0.000254  |    0.078962     |   2\n",
      "       3798 |   0.243064  |    0.025691     |   0\n",
      "       3799 |   0.312426  |    0.204865     |   1\n",
      "       3800 |   0.089208  |    0.011019     |   2\n",
      "       3801 |   0.105872  |    0.076013     |   2\n",
      "       3802 |   0.264906  |    0.165208     |   1\n",
      "       3803 |   0.267776  |    0.048899     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 3804: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       3804 |   0.098125  |    0.048475     |   2\n",
      "       3805 |   0.213879  |    0.042017     |   0\n",
      "       3806 |   0.066169  |    0.045026     |   2\n",
      "       3807 |   0.287884  |    0.196963     |   1\n",
      "       3808 |   0.303075  |    0.158686     |   1\n",
      "       3809 |   0.258332  |    0.138989     |   1\n",
      "       3810 |   0.310168  |    0.190756     |   1\n",
      "       3811 |   0.242664  |    0.003499     |   0\n",
      "       3812 |   0.307350  |    0.142154     |   1\n",
      "       3813 |   0.289255  |    0.042924     |   0\n",
      "       3814 |   0.260808  |    0.073461     |   0\n",
      "       3815 |   0.075084  |    0.014192     |   2\n",
      "       3816 |   0.344286  |    0.196741     |   1\n",
      "       3817 |   0.098041  |    0.003514     |   2\n",
      "       3818 |   0.043936  |    0.083396     |   2\n",
      "       3819 |   0.079096  |    0.026227     |   2\n",
      "       3820 |   0.257262  |    0.045005     |   0\n",
      "       3821 |   0.194901  |    0.048337     |   0\n",
      "       3822 |   0.219318  |    0.156911     |   1\n",
      "       3823 |   0.249959  |    0.216984     |   1\n",
      "       3824 |   0.322960  |    0.137479     |   1\n",
      "       3825 |   0.314847  |    0.142213     |   1\n",
      "       3826 |   0.355383  |    0.146305     |   1\n",
      "       3827 |   0.082136  |    0.018530     |   2\n",
      "       3828 |   0.218330  |    0.078879     |   0\n",
      "       3829 |   0.294171  |    0.144467     |   1\n",
      "       3830 |   0.083279  |    0.007270     |   2\n",
      "       3831 |   0.083723  |    0.087220     |   2\n",
      "       3832 |   0.244085  |    0.166985     |   1\n",
      "       3833 |   0.038873  |    0.026025     |   2\n",
      "       3834 |   0.241948  |    0.038686     |   0\n",
      "       3835 |   0.246162  |    0.191075     |   1\n",
      "       3836 |   0.230103  |    0.022606     |   0\n",
      "       3837 |   0.320401  |    0.204775     |   1\n",
      "       3838 |   0.257275  |    0.024233     |   0\n",
      "       3839 |   0.305739  |    0.178538     |   1\n",
      "       3840 |   0.254649  |    0.047172     |   0\n",
      "       3841 |   0.000193  |    0.048767     |   2\n",
      "       3842 |   0.310146  |    0.156424     |   1\n",
      "       3843 |   0.009181  |    0.043726     |   2\n",
      "       3844 |   0.270196  |    0.199278     |   1\n",
      "       3845 |   0.221855  |    0.038682     |   0\n",
      "       3846 |   0.195899  |    0.026801     |   0\n",
      "       3847 |   0.151782  |    0.045645     |   2\n",
      "       3848 |   0.199253  |    0.056657     |   0\n",
      "       3849 |   0.273124  |    0.192771     |   1\n",
      "       3850 |   0.063376  |    0.003405     |   2\n",
      "       3851 |   0.258397  |    0.047524     |   0\n",
      "       3852 |   0.088831  |    0.044459     |   2\n",
      "       3853 |   0.269618  |    0.071352     |   0\n",
      "       3854 |   0.073775  |    0.034763     |   2\n",
      "       3855 |   0.187655  |    0.202879     |   1\n",
      "       3856 |   0.034619  |    0.005107     |   2\n",
      "       3857 |   0.076940  |    0.084711     |   2\n",
      "       3858 |   0.284002  |    0.158740     |   1\n",
      "       3859 |   0.324436  |    0.152866     |   1\n",
      "       3860 |   0.238884  |    0.156536     |   1\n",
      "       3861 |   0.246669  |    0.200477     |   1\n",
      "       3862 |   0.055371  |    0.013541     |   2\n",
      "       3863 |   0.328821  |    0.189844     |   1\n",
      "       3864 |   0.227191  |    0.013959     |   0\n",
      "       3865 |   0.232799  |    0.081077     |   0\n",
      "       3866 |   0.336247  |    0.184163     |   1\n",
      "       3867 |   0.265571  |    0.165106     |   1\n",
      "       3868 |   0.292622  |    0.149518     |   1\n",
      "       3869 |   0.247049  |    0.010755     |   0\n",
      "       3870 |   0.258059  |    0.042343     |   0\n",
      "       3871 |   0.000179  |    0.061041     |   2\n",
      "       3872 |   0.294436  |    0.184373     |   1\n",
      "       3873 |   0.246614  |    0.153464     |   1\n",
      "       3874 |   0.223836  |    0.016511     |   0\n",
      "       3875 |   0.262852  |    0.138898     |   1\n",
      "       3876 |   0.000203  |    0.076558     |   2\n",
      "       3877 |   0.000233  |    0.028849     |   2\n",
      "       3878 |   0.266264  |    0.041853     |   0\n",
      "       3879 |   0.271492  |    0.077619     |   0\n",
      "       3880 |   0.000252  |    0.012209     |   2\n",
      "       3881 |   0.000221  |    0.073589     |   2\n",
      "       3882 |   0.284551  |    0.047382     |   0\n",
      "       3883 |   0.262732  |    0.148168     |   1\n",
      "       3884 |   0.299874  |    0.187733     |   1\n",
      "       3885 |   0.319452  |    0.033770     |   0\n",
      "       3886 |   0.000246  |    0.036525     |   2\n",
      "       3887 |   0.212739  |    0.084647     |   0\n",
      "       3888 |   0.308421  |    0.152356     |   1\n",
      "       3889 |   0.089888  |    0.024343     |   2\n",
      "       3890 |   0.242854  |    0.052155     |   0\n",
      "       3891 |   0.104118  |    0.042830     |   2\n",
      "       3892 |   0.313233  |    0.145809     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 3893: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       3893 |   0.230395  |    0.052700     |   0\n",
      "       3894 |   0.356859  |    0.137440     |   1\n",
      "       3895 |   0.209752  |    0.048111     |   0\n",
      "       3896 |   0.099353  |    0.045804     |   2\n",
      "       3897 |   0.282770  |    0.157614     |   1\n",
      "       3898 |   0.228230  |    0.031234     |   0\n",
      "       3899 |   0.212506  |    0.074370     |   0\n",
      "       3900 |   0.247157  |    0.024361     |   0\n",
      "       3901 |   0.246419  |    0.077600     |   0\n",
      "       3902 |   0.218877  |    0.007529     |   0\n",
      "       3903 |   0.066695  |    0.086967     |   2\n",
      "       3904 |   0.313546  |    0.178384     |   1\n",
      "       3905 |   0.074304  |    0.035571     |   2\n",
      "       3906 |   0.234993  |    0.156429     |   1\n",
      "       3907 |   0.099998  |    0.041610     |   2\n",
      "       3908 |   0.302051  |    0.137858     |   1\n",
      "       3909 |   0.044454  |    0.044334     |   2\n",
      "       3910 |   0.278584  |    0.201169     |   1\n",
      "       3911 |   0.303071  |    0.172846     |   1\n",
      "       3912 |   0.238907  |    0.094306     |   1\n",
      "       3913 |   0.280076  |    0.160562     |   1\n",
      "       3914 |   0.080512  |    0.029259     |   2\n",
      "       3915 |   0.281272  |    0.200216     |   1\n",
      "       3916 |   0.243732  |    0.165094     |   1\n",
      "       3917 |   0.278284  |    0.186062     |   1\n",
      "       3918 |   0.240947  |    0.003718     |   0\n",
      "       3919 |   0.257786  |    0.077317     |   0\n",
      "       3920 |   0.290752  |    0.154002     |   1\n",
      "       3921 |   0.317289  |    0.116251     |   1\n",
      "       3922 |   0.081064  |    0.046987     |   2\n",
      "       3923 |   0.231271  |    0.151751     |   1\n",
      "       3924 |   0.087129  |    0.034911     |   2\n",
      "       3925 |   0.254719  |    0.184833     |   1\n",
      "       3926 |   0.205935  |    0.026715     |   0\n",
      "       3927 |   0.081030  |    0.079816     |   2\n",
      "       3928 |   0.219062  |    0.028630     |   0\n",
      "       3929 |   0.035968  |    0.092673     |   2\n",
      "       3930 |   0.303132  |    0.129998     |   1\n",
      "       3931 |   0.301480  |    0.046171     |   0\n",
      "       3932 |   0.247359  |    0.135549     |   1\n",
      "       3933 |   0.000187  |    0.058025     |   2\n",
      "       3934 |   0.240998  |    0.172666     |   1\n",
      "       3935 |   0.241029  |    0.127488     |   1\n",
      "       3936 |   0.281280  |    0.142239     |   1\n",
      "       3937 |   0.333688  |    0.136412     |   1\n",
      "       3938 |   0.008453  |    0.010505     |   2\n",
      "       3939 |   0.224683  |    0.205569     |   1\n",
      "       3940 |   0.282940  |    0.166006     |   1\n",
      "       3941 |   0.309403  |    0.094514     |   1\n",
      "       3942 |   0.223282  |    0.050408     |   0\n",
      "       3943 |   0.294332  |    0.211988     |   1\n",
      "       3944 |   0.153265  |    0.005355     |   2\n",
      "       3945 |   0.222494  |    0.041608     |   0\n",
      "       3946 |   0.065662  |    0.048345     |   2\n",
      "       3947 |   0.085854  |    0.074784     |   2\n",
      "       3948 |   0.076417  |    0.028404     |   2\n",
      "       3949 |   0.267433  |    0.042954     |   0\n",
      "       3950 |   0.242398  |    0.073190     |   0\n",
      "       3951 |   0.325335  |    0.041794     |   0\n",
      "       3952 |   0.031209  |    0.042596     |   2\n",
      "       3953 |   0.069648  |    0.048308     |   2\n",
      "       3954 |   0.358901  |    0.141225     |   1\n",
      "       3955 |   0.246420  |    0.046042     |   0\n",
      "       3956 |   0.246018  |    0.157148     |   1\n",
      "       3957 |   0.293579  |    0.187187     |   1\n",
      "       3958 |   0.259009  |    0.013219     |   0\n",
      "       3959 |   0.287063  |    0.197815     |   1\n",
      "       3960 |   0.054258  |    0.003909     |   2\n",
      "       3961 |   0.222924  |    0.075129     |   0\n",
      "       3962 |   0.270798  |    0.141975     |   1\n",
      "       3963 |   0.000177  |    0.015137     |   2\n",
      "       3964 |   0.232809  |    0.075712     |   0\n",
      "       3965 |   0.291677  |    0.055298     |   0\n",
      "       3966 |   0.202275  |    0.145754     |   1\n",
      "       3967 |   0.256426  |    0.211675     |   1\n",
      "       3968 |   0.268241  |    0.090798     |   1\n",
      "       3969 |   0.172223  |    0.073074     |   0\n",
      "       3970 |   0.000197  |    0.027712     |   2\n",
      "       3971 |   0.201220  |    0.189961     |   1\n",
      "       3972 |   0.000232  |    0.044417     |   2\n",
      "       3973 |   0.000232  |    0.083945     |   2\n",
      "       3974 |   0.000216  |    0.028153     |   2\n",
      "       3975 |   0.328717  |    0.195470     |   1\n",
      "       3976 |   0.206735  |    0.009586     |   0\n",
      "       3977 |   0.000244  |    0.063572     |   2\n",
      "       3978 |   0.282707  |    0.139391     |   1\n",
      "       3979 |   0.241548  |    0.045277     |   0\n",
      "       3980 |   0.254807  |    0.163487     |   1\n",
      "       3981 |   0.283764  |    0.201242     |   1\n",
      "       3982 |   0.092764  |    0.007525     |   2\n",
      "       3983 |   0.304791  |    0.079956     |   0\n",
      "       3984 |   0.101597  |    0.009480     |   2\n",
      "       3985 |   0.295737  |    0.219957     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 3986: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       3986 |   0.341863  |    0.150997     |   1\n",
      "       3987 |   0.098940  |    0.019876     |   2\n",
      "       3988 |   0.208238  |    0.201288     |   1\n",
      "       3989 |   0.066687  |    0.024653     |   2\n",
      "       3990 |   0.075634  |    0.056367     |   2\n",
      "       3991 |   0.272611  |    0.168340     |   1\n",
      "       3992 |   0.268712  |    0.153055     |   1\n",
      "       3993 |   0.303817  |    0.137863     |   1\n",
      "       3994 |   0.095361  |    0.043661     |   2\n",
      "       3995 |   0.043336  |    0.040120     |   2\n",
      "       3996 |   0.292598  |    0.162511     |   1\n",
      "       3997 |   0.243429  |    0.049290     |   0\n",
      "       3998 |   0.253520  |    0.046055     |   0\n",
      "       3999 |   0.222787  |    0.079213     |   0\n",
      "       4000 |   0.290184  |    0.153304     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 4000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 4000: Plotting estimates.\n",
      "Exception in thread neuralnilm-data-process:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 810, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/jack/workspace/python/neuralnilm/neuralnilm/data/datathread.py\", line 16, in run\n",
      "    batch = self.data_pipeline.get_batch(**self._get_batch_kwargs)\n",
      "  File \"/home/jack/workspace/python/neuralnilm/neuralnilm/data/datapipeline.py\", line 46, in get_batch\n",
      "    batch = self._source_iterators[source_id].next()\n",
      "ValueError: generator already executing\n",
      "\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       4001 |   0.096265  |    0.084523     |   2\n",
      "       4002 |   0.250258  |    0.051153     |   0\n",
      "       4003 |   0.350771  |    0.167120     |   1\n",
      "       4004 |   0.066410  |    0.015670     |   2\n",
      "       4005 |   0.264191  |    0.052401     |   0\n",
      "       4006 |   0.074887  |    0.048115     |   2\n",
      "       4007 |   0.316935  |    0.157031     |   1\n",
      "       4008 |   0.238371  |    0.075636     |   0\n",
      "       4009 |   0.092585  |    0.013059     |   2\n",
      "       4010 |   0.186233  |    0.075424     |   0\n",
      "       4011 |   0.298957  |    0.154707     |   1\n",
      "       4012 |   0.042587  |    0.044312     |   2\n",
      "       4013 |   0.285054  |    0.157824     |   1\n",
      "       4014 |   0.323529  |    0.139364     |   1\n",
      "       4015 |   0.081386  |    0.050442     |   2\n",
      "       4016 |   0.271287  |    0.158872     |   1\n",
      "       4017 |   0.172927  |    0.151305     |   1\n",
      "       4018 |   0.236985  |    0.162099     |   1\n",
      "       4019 |   0.081816  |    0.025516     |   2\n",
      "       4020 |   0.087289  |    0.040315     |   2\n",
      "       4021 |   0.238469  |    0.077834     |   0\n",
      "       4022 |   0.081268  |    0.034542     |   2\n",
      "       4023 |   0.243967  |    0.047037     |   0\n",
      "       4024 |   0.034766  |    0.048384     |   2\n",
      "       4025 |   0.000186  |    0.075404     |   2\n",
      "       4026 |   0.008656  |    0.048913     |   2\n",
      "       4027 |   0.212218  |    0.046456     |   0\n",
      "       4028 |   0.240754  |    0.047328     |   0\n",
      "       4029 |   0.297250  |    0.194973     |   1\n",
      "       4030 |   0.242179  |    0.010482     |   0\n",
      "       4031 |   0.148945  |    0.044852     |   2\n",
      "       4032 |   0.063840  |    0.049496     |   2\n",
      "       4033 |   0.086601  |    0.046610     |   2\n",
      "       4034 |   0.074502  |    0.047846     |   2\n",
      "       4035 |   0.212429  |    0.076084     |   0\n",
      "       4036 |   0.032691  |    0.010251     |   2\n",
      "       4037 |   0.226542  |    0.075907     |   0\n",
      "       4038 |   0.273489  |    0.028282     |   0\n",
      "       4039 |   0.286049  |    0.159511     |   1\n",
      "       4040 |   0.279600  |    0.205452     |   1\n",
      "       4041 |   0.196640  |    0.006442     |   0\n",
      "       4042 |   0.268772  |    0.026574     |   0\n",
      "       4043 |   0.071310  |    0.085494     |   2\n",
      "       4044 |   0.230557  |    0.023145     |   0\n",
      "       4045 |   0.054462  |    0.058463     |   2\n",
      "       4046 |   0.000173  |    0.045967     |   2\n",
      "       4047 |   0.000194  |    0.051569     |   2\n",
      "       4048 |   0.403307  |    0.132707     |   1\n",
      "       4049 |   0.270018  |    0.042865     |   0\n",
      "       4050 |   0.000223  |    0.055602     |   2\n",
      "       4051 |   0.286002  |    0.140062     |   1\n",
      "       4052 |   0.239150  |    0.042663     |   0\n",
      "       4053 |   0.265267  |    0.071696     |   0\n",
      "       4054 |   0.197837  |    0.012548     |   0\n",
      "       4055 |   0.000229  |    0.077237     |   2\n",
      "       4056 |   0.341740  |    0.158447     |   1\n",
      "       4057 |   0.258289  |    0.136934     |   1\n",
      "       4058 |   0.249095  |    0.045296     |   0\n",
      "       4059 |   0.261122  |    0.051186     |   0\n",
      "       4060 |   0.249790  |    0.179084     |   1\n",
      "       4061 |   0.279861  |    0.154355     |   1\n",
      "       4062 |   0.290561  |    0.168344     |   1\n",
      "       4063 |   0.000209  |    0.027810     |   2\n",
      "       4064 |   0.296880  |    0.194703     |   1\n",
      "       4065 |   0.000241  |    0.006036     |   2\n",
      "       4066 |   0.237525  |    0.076596     |   0\n",
      "       4067 |   0.238104  |    0.016995     |   0\n",
      "       4068 |   0.242675  |    0.199888     |   1\n",
      "       4069 |   0.248346  |    0.140367     |   1\n",
      "       4070 |   0.188688  |    0.044439     |   0\n",
      "       4071 |   0.298786  |    0.159358     |   1\n",
      "       4072 |   0.213803  |    0.040908     |   0\n",
      "       4073 |   0.249159  |    0.187595     |   1\n",
      "       4074 |   0.271517  |    0.010989     |   0\n",
      "       4075 |   0.225004  |    0.038677     |   0\n",
      "       4076 |   0.230754  |    0.197135     |   1\n",
      "       4077 |   0.234186  |    0.158602     |   1\n",
      "       4078 |   0.093238  |    0.029429     |   2\n",
      "       4079 |   0.243446  |    0.193442     |   1\n",
      "       4080 |   0.308835  |    0.143562     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 4082: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       4081 |   0.102800  |    0.028383     |   2\n",
      "       4082 |   0.276219  |    0.166462     |   1\n",
      "       4083 |   0.249325  |    0.037401     |   0\n",
      "       4084 |   0.278264  |    0.189221     |   1\n",
      "       4085 |   0.211860  |    0.015398     |   0\n",
      "       4086 |   0.265585  |    0.076719     |   0\n",
      "       4087 |   0.216499  |    0.038163     |   0\n",
      "       4088 |   0.096243  |    0.049849     |   2\n",
      "       4089 |   0.223309  |    0.065683     |   0\n",
      "       4090 |   0.298411  |    0.133068     |   1\n",
      "       4091 |   0.233836  |    0.040968     |   0\n",
      "       4092 |   0.237341  |    0.039587     |   0\n",
      "       4093 |   0.194231  |    0.035352     |   0\n",
      "       4094 |   0.305939  |    0.145730     |   1\n",
      "       4095 |   0.202752  |    0.080948     |   0\n",
      "       4096 |   0.205787  |    0.004006     |   0\n",
      "       4097 |   0.359220  |    0.199402     |   1\n",
      "       4098 |   0.065845  |    0.006617     |   2\n",
      "       4099 |   0.071268  |    0.045102     |   2\n",
      "       4100 |   0.254171  |    0.041536     |   0\n",
      "       4101 |   0.346522  |    0.201715     |   1\n",
      "       4102 |   0.095948  |    0.009294     |   2\n",
      "       4103 |   0.276239  |    0.147286     |   1\n",
      "       4104 |   0.218101  |    0.045702     |   0\n",
      "       4105 |   0.042953  |    0.075956     |   2\n",
      "       4106 |   0.077592  |    0.020626     |   2\n",
      "       4107 |   0.196633  |    0.072925     |   0\n",
      "       4108 |   0.085081  |    0.018901     |   2\n",
      "       4109 |   0.082989  |    0.072252     |   2\n",
      "       4110 |   0.266508  |    0.198177     |   1\n",
      "       4111 |   0.079458  |    0.003869     |   2\n",
      "       4112 |   0.035264  |    0.045669     |   2\n",
      "       4113 |   0.271457  |    0.190347     |   1\n",
      "       4114 |   0.247744  |    0.191782     |   1\n",
      "       4115 |   0.266577  |    0.008564     |   0\n",
      "       4116 |   0.205564  |    0.156387     |   1\n",
      "       4117 |   0.000188  |    0.028240     |   2\n",
      "       4118 |   0.278472  |    0.081179     |   0\n",
      "       4119 |   0.283470  |    0.145519     |   1\n",
      "       4120 |   0.250329  |    0.014799     |   0\n",
      "       4121 |   0.278829  |    0.090104     |   0\n",
      "       4122 |   0.226794  |    0.160173     |   1\n",
      "       4123 |   0.218074  |    0.009909     |   0\n",
      "       4124 |   0.008192  |    0.059250     |   2\n",
      "       4125 |   0.206959  |    0.090059     |   0\n",
      "       4126 |   0.261522  |    0.015949     |   0\n",
      "       4127 |   0.221979  |    0.185423     |   1\n",
      "       4128 |   0.378148  |    0.133098     |   1\n",
      "       4129 |   0.152095  |    0.007590     |   0\n",
      "       4130 |   0.146940  |    0.086256     |   2\n",
      "       4131 |   0.235589  |    0.153491     |   1\n",
      "       4132 |   0.234282  |    0.184555     |   1\n",
      "       4133 |   0.276611  |    0.145298     |   1\n",
      "       4134 |   0.243546  |    0.043260     |   0\n",
      "       4135 |   0.306836  |    0.143344     |   1\n",
      "       4136 |   0.223152  |    0.196248     |   1\n",
      "       4137 |   0.272414  |    0.051434     |   0\n",
      "       4138 |   0.313399  |    0.158428     |   1\n",
      "       4139 |   0.297671  |    0.144302     |   1\n",
      "       4140 |   0.461911  |    0.138985     |   1\n",
      "       4141 |   0.230513  |    0.022400     |   0\n",
      "       4142 |   0.266516  |    0.080210     |   0\n",
      "       4143 |   0.236459  |    0.134865     |   1\n",
      "       4144 |   0.249668  |    0.038674     |   0\n",
      "       4145 |   0.194215  |    0.042364     |   0\n",
      "       4146 |   0.239746  |    0.081117     |   0\n",
      "       4147 |   0.260971  |    0.156365     |   1\n",
      "       4148 |   0.248469  |    0.147436     |   1\n",
      "       4149 |   0.208860  |    0.188964     |   1\n",
      "       4150 |   0.227181  |    0.003724     |   0\n",
      "       4151 |   0.063733  |    0.075395     |   2\n",
      "       4152 |   0.227800  |    0.021411     |   0\n",
      "       4153 |   0.297553  |    0.208760     |   1\n",
      "       4154 |   0.087739  |    0.005077     |   2\n",
      "       4155 |   0.246053  |    0.075992     |   0\n",
      "       4156 |   0.218345  |    0.024054     |   0\n",
      "       4157 |   0.309535  |    0.210742     |   1\n",
      "       4158 |   0.075628  |    0.004593     |   2\n",
      "       4159 |   0.229587  |    0.091060     |   1\n",
      "       4160 |   0.236888  |    0.081052     |   0\n",
      "       4161 |   0.260435  |    0.161911     |   1\n",
      "       4162 |   0.279017  |    0.134734     |   1\n",
      "       4163 |   0.271163  |    0.006066     |   0\n",
      "       4164 |   0.251119  |    0.055954     |   0\n",
      "       4165 |   0.032795  |    0.047102     |   2\n",
      "       4166 |   0.212750  |    0.207949     |   1\n",
      "       4167 |   0.076362  |    0.009320     |   2\n",
      "       4168 |   0.053427  |    0.047390     |   2\n",
      "       4169 |   0.389016  |    0.155722     |   1\n",
      "       4170 |   0.189551  |    0.146695     |   1\n",
      "       4171 |   0.000177  |    0.024129     |   2\n",
      "       4172 |   0.251881  |    0.197879     |   1\n",
      "       4173 |   0.292426  |    0.142977     |   1\n",
      "       4174 |   0.000193  |    0.039614     |   2\n",
      "       4175 |   0.244023  |    0.041532     |   0\n",
      "       4176 |   0.295914  |    0.076660     |   0\n",
      "       4177 |   0.281283  |    0.147979     |   1\n",
      "       4178 |   0.357612  |    0.149356     |   1\n",
      "       4179 |   0.314277  |    0.156981     |   1\n",
      "       4180 |   0.237983  |    0.153573     |   1\n",
      "       4181 |   0.189478  |    0.181258     |   1\n",
      "       4182 |   0.000227  |    0.005199     |   2\n",
      "       4183 |   0.231398  |    0.070563     |   0\n",
      "       4184 |   0.237059  |    0.043797     |   0\n",
      "       4185 |   0.198305  |    0.145871     |   1\n",
      "       4186 |   0.000231  |    0.080781     |   2\n",
      "       4187 |   0.248730  |    0.151673     |   1\n",
      "       4188 |   0.253984  |    0.202474     |   1\n",
      "       4189 |   0.214287  |    0.013538     |   0\n",
      "       4190 |   0.238379  |    0.157017     |   1\n",
      "       4191 |   0.265882  |    0.196054     |   1\n",
      "       4192 |   0.189115  |    0.009457     |   0\n",
      "       4193 |   0.000208  |    0.048496     |   2\n",
      "       4194 |   0.178761  |    0.042260     |   0\n",
      "       4195 |   0.250990  |    0.042282     |   0\n",
      "       4196 |   0.312025  |    0.195709     |   1\n",
      "       4197 |   0.233511  |    0.157956     |   1\n",
      "       4198 |   0.000235  |    0.003382     |   2\n",
      "       4199 |   0.257043  |    0.082785     |   0\n",
      "       4200 |   0.091410  |    0.022172     |   2\n",
      "       4201 |   0.177379  |    0.217011     |   1\n",
      "       4202 |   0.263620  |    0.011575     |   0\n",
      "       4203 |   0.193748  |    0.198422     |   1\n",
      "       4204 |   0.339477  |    0.155175     |   1\n",
      "       4205 |   0.292269  |    0.109899     |   1\n",
      "       4206 |   0.260761  |    0.158453     |   1\n",
      "       4207 |   0.101288  |    0.010902     |   2\n",
      "       4208 |   0.349058  |    0.213583     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 4209: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       4209 |   0.230713  |    0.153001     |   1\n",
      "       4210 |   0.093938  |    0.033547     |   2\n",
      "       4211 |   0.065944  |    0.048170     |   2\n",
      "       4212 |   0.071251  |    0.038356     |   2\n",
      "       4213 |   0.287716  |    0.213838     |   1\n",
      "       4214 |   0.218870  |    0.149989     |   1\n",
      "       4215 |   0.276720  |    0.154711     |   1\n",
      "       4216 |   0.093133  |    0.008364     |   2\n",
      "       4217 |   0.304833  |    0.146861     |   1\n",
      "       4218 |   0.248927  |    0.153439     |   1\n",
      "       4219 |   0.306459  |    0.157974     |   1\n",
      "       4220 |   0.041958  |    0.048725     |   2\n",
      "       4221 |   0.187179  |    0.184486     |   1\n",
      "       4222 |   0.170601  |    0.014295     |   0\n",
      "       4223 |   0.076506  |    0.080286     |   2\n",
      "       4224 |   0.079674  |    0.005818     |   2\n",
      "       4225 |   0.272099  |    0.058395     |   0\n",
      "       4226 |   0.202352  |    0.209044     |   1\n",
      "       4227 |   0.082740  |    0.004273     |   2\n",
      "       4228 |   0.207555  |    0.192337     |   1\n",
      "       4229 |   0.085224  |    0.023286     |   2\n",
      "       4230 |   0.289104  |    0.226944     |   1\n",
      "       4231 |   0.214531  |    0.114178     |   1\n",
      "       4232 |   0.281298  |    0.136511     |   1\n",
      "       4233 |   0.184119  |    0.024764     |   0\n",
      "       4234 |   0.357509  |    0.187287     |   1\n",
      "       4235 |   0.292265  |    0.011231     |   0\n",
      "       4236 |   0.264975  |    0.044542     |   0\n",
      "       4237 |   0.037212  |    0.051286     |   2\n",
      "       4238 |   0.302359  |    0.201039     |   1\n",
      "       4239 |   0.000186  |    0.018185     |   2\n",
      "       4240 |   0.326574  |    0.162269     |   1\n",
      "       4241 |   0.007530  |    0.049439     |   2\n",
      "       4242 |   0.223648  |    0.205059     |   1\n",
      "       4243 |   0.232921  |    0.012522     |   0\n",
      "       4244 |   0.282815  |    0.186858     |   1\n",
      "       4245 |   0.247747  |    0.015739     |   0\n",
      "       4246 |   0.145306  |    0.050261     |   2\n",
      "       4247 |   0.206479  |    0.192337     |   1\n",
      "       4248 |   0.275262  |    0.014400     |   0\n",
      "       4249 |   0.063081  |    0.078533     |   2\n",
      "       4250 |   0.219647  |    0.153501     |   1\n",
      "       4251 |   0.288197  |    0.052560     |   0\n",
      "       4252 |   0.087165  |    0.042532     |   2\n",
      "       4253 |   0.222069  |    0.039188     |   0\n",
      "       4254 |   0.218275  |    0.032538     |   0\n",
      "       4255 |   0.074991  |    0.054766     |   2\n",
      "       4256 |   0.298990  |    0.147779     |   1\n",
      "       4257 |   0.034220  |    0.036875     |   2\n",
      "       4258 |   0.257104  |    0.049451     |   0\n",
      "       4259 |   0.072520  |    0.048225     |   2\n",
      "       4260 |   0.051865  |    0.046556     |   2\n",
      "       4261 |   0.210181  |    0.042384     |   0\n",
      "       4262 |   0.238813  |    0.078807     |   0\n",
      "       4263 |   0.000175  |    0.016876     |   2\n",
      "       4264 |   0.336853  |    0.198880     |   1\n",
      "       4265 |   0.000195  |    0.017731     |   2\n",
      "       4266 |   0.318280  |    0.158398     |   1\n",
      "       4267 |   0.247811  |    0.073471     |   0\n",
      "       4268 |   0.187726  |    0.009869     |   0\n",
      "       4269 |   0.167831  |    0.059395     |   0\n",
      "       4270 |   0.246587  |    0.205740     |   1\n",
      "       4271 |   0.268997  |    0.185584     |   1\n",
      "       4272 |   0.000225  |    0.026889     |   2\n",
      "       4273 |   0.269362  |    0.185080     |   1\n",
      "       4274 |   0.238727  |    0.046129     |   0\n",
      "       4275 |   0.222426  |    0.023874     |   0\n",
      "       4276 |   0.000232  |    0.045972     |   2\n",
      "       4277 |   0.000201  |    0.040022     |   2\n",
      "       4278 |   0.280909  |    0.074765     |   0\n",
      "       4279 |   0.230176  |    0.034149     |   0\n",
      "       4280 |   0.285437  |    0.196858     |   1\n",
      "       4281 |   0.260602  |    0.005374     |   0\n",
      "       4282 |   0.000234  |    0.025286     |   2\n",
      "       4283 |   0.248612  |    0.073400     |   0\n",
      "       4284 |   0.256241  |    0.049244     |   0\n",
      "       4285 |   0.271839  |    0.187421     |   1\n",
      "       4286 |   0.182464  |    0.117675     |   1\n",
      "       4287 |   0.276245  |    0.193916     |   1\n",
      "       4288 |   0.182380  |    0.005080     |   0\n",
      "       4289 |   0.225130  |    0.080113     |   0\n",
      "       4290 |   0.094435  |    0.023528     |   2\n",
      "       4291 |   0.260423  |    0.049660     |   0\n",
      "       4292 |   0.316434  |    0.202925     |   1\n",
      "       4293 |   0.101246  |    0.013356     |   2\n",
      "       4294 |   0.241702  |    0.078717     |   0\n",
      "       4295 |   0.252918  |    0.021909     |   0\n",
      "       4296 |   0.205409  |    0.186851     |   1\n",
      "       4297 |   0.290471  |    0.162885     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 4298: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       4298 |   0.240155  |    0.021182     |   0\n",
      "       4299 |   0.317554  |    0.190027     |   1\n",
      "       4300 |   0.098747  |    0.026220     |   2\n",
      "       4301 |   0.170374  |    0.045360     |   0\n",
      "       4302 |   0.205252  |    0.051619     |   0\n",
      "       4303 |   0.236134  |    0.195249     |   1\n",
      "       4304 |   0.279907  |    0.112016     |   1\n",
      "       4305 |   0.223704  |    0.045552     |   0\n",
      "       4306 |   0.222234  |    0.190954     |   1\n",
      "       4307 |   0.069323  |    0.026735     |   2\n",
      "       4308 |   0.229848  |    0.228139     |   1\n",
      "       4309 |   0.265065  |    0.016104     |   0\n",
      "       4310 |   0.201969  |    0.048201     |   0\n",
      "       4311 |   0.209916  |    0.048790     |   0\n",
      "       4312 |   0.316935  |    0.164531     |   1\n",
      "       4313 |   0.311430  |    0.151003     |   1\n",
      "       4314 |   0.215960  |    0.051873     |   0\n",
      "       4315 |   0.072606  |    0.041579     |   2\n",
      "       4316 |   0.260234  |    0.147206     |   1\n",
      "       4317 |   0.302947  |    0.027461     |   0\n",
      "       4318 |   0.224386  |    0.050929     |   0\n",
      "       4319 |   0.238682  |    0.143847     |   1\n",
      "       4320 |   0.093303  |    0.046016     |   2\n",
      "       4321 |   0.181348  |    0.039946     |   0\n",
      "       4322 |   0.042753  |    0.045669     |   2\n",
      "       4323 |   0.243419  |    0.048928     |   0\n",
      "       4324 |   0.283086  |    0.151561     |   1\n",
      "       4325 |   0.241122  |    0.163469     |   1\n",
      "       4326 |   0.210216  |    0.160546     |   1\n",
      "       4327 |   0.295980  |    0.150354     |   1\n",
      "       4328 |   0.241268  |    0.030258     |   0\n",
      "       4329 |   0.077100  |    0.049170     |   2\n",
      "       4330 |   0.253826  |    0.050413     |   0\n",
      "       4331 |   0.080866  |    0.080354     |   2\n",
      "       4332 |   0.081692  |    0.009517     |   2\n",
      "       4333 |   0.200994  |    0.083692     |   0\n",
      "       4334 |   0.085774  |    0.010631     |   2\n",
      "       4335 |   0.238468  |    0.079066     |   0\n",
      "       4336 |   0.213512  |    0.019041     |   0\n",
      "       4337 |   0.218847  |    0.075295     |   0\n",
      "       4338 |   0.299962  |    0.198714     |   1\n",
      "       4339 |   0.321885  |    0.136561     |   1\n",
      "       4340 |   0.036687  |    0.027791     |   2\n",
      "       4341 |   0.000185  |    0.045561     |   2\n",
      "       4342 |   0.187441  |    0.042504     |   0\n",
      "       4343 |   0.247546  |    0.043002     |   0\n",
      "       4344 |   0.252792  |    0.073476     |   0\n",
      "       4345 |   0.241341  |    0.023520     |   0\n",
      "       4346 |   0.217513  |    0.049224     |   0\n",
      "       4347 |   0.222600  |    0.073832     |   0\n",
      "       4348 |   0.008205  |    0.020976     |   2\n",
      "       4349 |   0.146915  |    0.080189     |   2\n",
      "       4350 |   0.233031  |    0.031137     |   0\n",
      "       4351 |   0.063479  |    0.044177     |   2\n",
      "       4352 |   0.182516  |    0.080436     |   0\n",
      "       4353 |   0.203526  |    0.009689     |   0\n",
      "       4354 |   0.344457  |    0.198574     |   1\n",
      "       4355 |   0.239993  |    0.140264     |   1\n",
      "       4356 |   0.177193  |    0.048542     |   0\n",
      "       4357 |   0.197940  |    0.206453     |   1\n",
      "       4358 |   0.088687  |    0.026953     |   2\n",
      "       4359 |   0.197476  |    0.196690     |   1\n",
      "       4360 |   0.343755  |    0.195333     |   1\n",
      "       4361 |   0.295309  |    0.143833     |   1\n",
      "       4362 |   0.240569  |    0.017277     |   0\n",
      "       4363 |   0.347862  |    0.191908     |   1\n",
      "       4364 |   0.232246  |    0.013662     |   0\n",
      "       4365 |   0.228228  |    0.077750     |   0\n",
      "       4366 |   0.278479  |    0.141159     |   1\n",
      "       4367 |   0.072186  |    0.038727     |   2\n",
      "       4368 |   0.190877  |    0.055490     |   0\n",
      "       4369 |   0.239359  |    0.209858     |   1\n",
      "       4370 |   0.031756  |    0.008748     |   2\n",
      "       4371 |   0.255322  |    0.074752     |   0\n",
      "       4372 |   0.295145  |    0.139858     |   1\n",
      "       4373 |   0.071867  |    0.054377     |   2\n",
      "       4374 |   0.053532  |    0.045105     |   2\n",
      "       4375 |   0.000175  |    0.025675     |   2\n",
      "       4376 |   0.234056  |    0.214724     |   1\n",
      "       4377 |   0.233571  |    0.149826     |   1\n",
      "       4378 |   0.231251  |    0.005958     |   0\n",
      "       4379 |   0.323365  |    0.190812     |   1\n",
      "       4380 |   0.237414  |    0.019575     |   0\n",
      "       4381 |   0.317527  |    0.164359     |   1\n",
      "       4382 |   0.240331  |    0.043850     |   0\n",
      "       4383 |   0.000186  |    0.073391     |   2\n",
      "       4384 |   0.290666  |    0.019353     |   0\n",
      "       4385 |   0.210788  |    0.190376     |   1\n",
      "       4386 |   0.240838  |    0.035282     |   0\n",
      "       4387 |   0.000210  |    0.037981     |   2\n",
      "       4388 |   0.000218  |    0.078246     |   2\n",
      "       4389 |   0.327734  |    0.170200     |   1\n",
      "       4390 |   0.306483  |    0.133456     |   1\n",
      "       4391 |   0.225799  |    0.010233     |   0\n",
      "       4392 |   0.000198  |    0.079847     |   2\n",
      "       4393 |   0.299656  |    0.144596     |   1\n",
      "       4394 |   0.314920  |    0.158341     |   1\n",
      "       4395 |   0.000228  |    0.042071     |   2\n",
      "       4396 |   0.212096  |    0.047971     |   0\n",
      "       4397 |   0.241806  |    0.054363     |   0\n",
      "       4398 |   0.237937  |    0.137527     |   1\n",
      "       4399 |   0.207195  |    0.034315     |   0\n",
      "       4400 |   0.089183  |    0.044653     |   2\n",
      "       4401 |   0.273281  |    0.219111     |   1\n",
      "       4402 |   0.099167  |    0.007726     |   2\n",
      "       4403 |   0.329506  |    0.190819     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 4404: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       4404 |   0.291061  |    0.092717     |   1\n",
      "       4405 |   0.227346  |    0.041375     |   0\n",
      "       4406 |   0.093478  |    0.048563     |   2\n",
      "       4407 |   0.226550  |    0.044899     |   0\n",
      "       4408 |   0.068079  |    0.052765     |   2\n",
      "       4409 |   0.304370  |    0.160739     |   1\n",
      "       4410 |   0.185241  |    0.012925     |   0\n",
      "       4411 |   0.230567  |    0.183981     |   1\n",
      "       4412 |   0.271516  |    0.027922     |   0\n",
      "       4413 |   0.069456  |    0.048212     |   2\n",
      "       4414 |   0.092764  |    0.048395     |   2\n",
      "       4415 |   0.321097  |    0.208779     |   1\n",
      "       4416 |   0.041893  |    0.008716     |   2\n",
      "       4417 |   0.075239  |    0.075924     |   2\n",
      "       4418 |   0.079097  |    0.043941     |   2\n",
      "       4419 |   0.080983  |    0.076639     |   2\n",
      "       4420 |   0.175857  |    0.023360     |   0\n",
      "       4421 |   0.082463  |    0.049953     |   2\n",
      "       4422 |   0.317682  |    0.143417     |   1\n",
      "       4423 |   0.034163  |    0.044704     |   2\n",
      "       4424 |   0.000185  |    0.041843     |   2\n",
      "       4425 |   0.240952  |    0.046739     |   0\n",
      "       4426 |   0.007874  |    0.038465     |   2\n",
      "       4427 |   0.237723  |    0.046016     |   0\n",
      "       4428 |   0.141157  |    0.058690     |   2\n",
      "       4429 |   0.203865  |    0.201268     |   1\n",
      "       4430 |   0.268172  |    0.013702     |   0\n",
      "       4431 |   0.061917  |    0.058547     |   2\n",
      "       4432 |   0.230683  |    0.137822     |   1\n",
      "       4433 |   0.251319  |    0.224205     |   1\n",
      "       4434 |   0.249983  |    0.010403     |   0\n",
      "       4435 |   0.087273  |    0.042049     |   2\n",
      "       4436 |   0.069979  |    0.077852     |   2\n",
      "       4437 |   0.266230  |    0.158565     |   1\n",
      "       4438 |   0.201794  |    0.192622     |   1\n",
      "       4439 |   0.031979  |    0.019233     |   2\n",
      "       4440 |   0.227182  |    0.210418     |   1\n",
      "       4441 |   0.068120  |    0.008946     |   2\n",
      "       4442 |   0.051444  |    0.045046     |   2\n",
      "       4443 |   0.000174  |    0.038911     |   2\n",
      "       4444 |   0.000185  |    0.073870     |   2\n",
      "       4445 |   0.257149  |    0.176540     |   1\n",
      "       4446 |   0.273074  |    0.140743     |   1\n",
      "       4447 |   0.234938  |    0.033399     |   0\n",
      "       4448 |   0.224713  |    0.199330     |   1\n",
      "       4449 |   0.000210  |    0.034992     |   2\n",
      "       4450 |   0.272492  |    0.192742     |   1\n",
      "       4451 |   0.000215  |    0.013052     |   2\n",
      "       4452 |   0.000193  |    0.077079     |   2\n",
      "       4453 |   0.000219  |    0.015663     |   2\n",
      "       4454 |   0.368687  |    0.212980     |   1\n",
      "       4455 |   0.274849  |    0.152365     |   1\n",
      "       4456 |   0.232934  |    0.190587     |   1\n",
      "       4457 |   0.259023  |    0.011000     |   0\n",
      "       4458 |   0.247603  |    0.148796     |   1\n",
      "       4459 |   0.267416  |    0.074907     |   0\n",
      "       4460 |   0.083109  |    0.022818     |   2\n",
      "       4461 |   0.096854  |    0.049325     |   2\n",
      "       4462 |   0.227894  |    0.049945     |   0\n",
      "       4463 |   0.341905  |    0.184909     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 4464: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       4464 |   0.086629  |    0.029323     |   2\n",
      "       4465 |   0.062218  |    0.070993     |   2\n",
      "       4466 |   0.067966  |    0.020001     |   2\n",
      "       4467 |   0.217027  |    0.075205     |   0\n",
      "       4468 |   0.257994  |    0.014995     |   0\n",
      "       4469 |   0.257667  |    0.183533     |   1\n",
      "       4470 |   0.090066  |    0.028955     |   2\n",
      "       4471 |   0.271836  |    0.158051     |   1\n",
      "       4472 |   0.189438  |    0.031847     |   0\n",
      "       4473 |   0.040710  |    0.048259     |   2\n",
      "       4474 |   0.073920  |    0.047507     |   2\n",
      "       4475 |   0.288755  |    0.201324     |   1\n",
      "       4476 |   0.215006  |    0.006274     |   0\n",
      "       4477 |   0.270275  |    0.160095     |   1\n",
      "       4478 |   0.325481  |    0.146164     |   1\n",
      "       4479 |   0.080842  |    0.003330     |   2\n",
      "       4480 |   0.341664  |    0.151868     |   1\n",
      "       4481 |   0.193143  |    0.011260     |   0\n",
      "       4482 |   0.272501  |    0.082453     |   0\n",
      "       4483 |   0.185574  |    0.015408     |   0\n",
      "       4484 |   0.079409  |    0.072684     |   2\n",
      "       4485 |   0.257172  |    0.029475     |   0\n",
      "       4486 |   0.259995  |    0.084402     |   0\n",
      "       4487 |   0.245278  |    0.017784     |   0\n",
      "       4488 |   0.244404  |    0.076391     |   0\n",
      "       4489 |   0.221470  |    0.035544     |   0\n",
      "       4490 |   0.280675  |    0.222724     |   1\n",
      "       4491 |   0.177080  |    0.133968     |   1\n",
      "       4492 |   0.238839  |    0.015944     |   0\n",
      "       4493 |   0.313771  |    0.184073     |   1\n",
      "       4494 |   0.080941  |    0.054676     |   2\n",
      "       4495 |   0.263451  |    0.146008     |   1\n",
      "       4496 |   0.207740  |    0.043672     |   0\n",
      "       4497 |   0.216578  |    0.043579     |   0\n",
      "       4498 |   0.206636  |    0.083351     |   0\n",
      "       4499 |   0.264996  |    0.149036     |   1\n",
      "       4500 |   0.184190  |    0.045654     |   0\n",
      "       4501 |   0.275007  |    0.084040     |   0\n",
      "       4502 |   0.090641  |    0.014901     |   2\n",
      "       4503 |   0.228883  |    0.078660     |   0\n",
      "       4504 |   0.210008  |    0.020159     |   0\n",
      "       4505 |   0.064802  |    0.085811     |   2\n",
      "       4506 |   0.292633  |    0.134624     |   1\n",
      "       4507 |   0.065294  |    0.051893     |   2\n",
      "       4508 |   0.214635  |    0.147244     |   1\n",
      "       4509 |   0.301774  |    0.038479     |   0\n",
      "       4510 |   0.094902  |    0.046691     |   2\n",
      "       4511 |   0.229089  |    0.074386     |   0\n",
      "       4512 |   0.250237  |    0.023704     |   0\n",
      "       4513 |   0.229835  |    0.072017     |   0\n",
      "       4514 |   0.192027  |    0.019616     |   0\n",
      "       4515 |   0.043081  |    0.076913     |   2\n",
      "       4516 |   0.154613  |    0.219313     |   1\n",
      "       4517 |   0.253158  |    0.143221     |   1\n",
      "       4518 |   0.255943  |    0.006268     |   0\n",
      "       4519 |   0.075611  |    0.044153     |   2\n",
      "       4520 |   0.083227  |    0.040349     |   2\n",
      "       4521 |   0.245204  |    0.175898     |   1\n",
      "       4522 |   0.221725  |    0.048635     |   0\n",
      "       4523 |   0.218820  |    0.075554     |   0\n",
      "       4524 |   0.077239  |    0.031915     |   2\n",
      "       4525 |   0.306157  |    0.199178     |   1\n",
      "       4526 |   0.200902  |    0.014872     |   0\n",
      "       4527 |   0.225982  |    0.204833     |   1\n",
      "       4528 |   0.171356  |    0.005840     |   0\n",
      "       4529 |   0.177789  |    0.155226     |   1\n",
      "       4530 |   0.254752  |    0.047453     |   0\n",
      "       4531 |   0.271396  |    0.140483     |   1\n",
      "       4532 |   0.080198  |    0.046964     |   2\n",
      "       4533 |   0.253355  |    0.048134     |   0\n",
      "       4534 |   0.036207  |    0.033397     |   2\n",
      "       4535 |   0.213274  |    0.078990     |   0\n",
      "       4536 |   0.231703  |    0.023386     |   0\n",
      "       4537 |   0.000185  |    0.086284     |   2\n",
      "       4538 |   0.008132  |    0.025407     |   2\n",
      "       4539 |   0.138684  |    0.048777     |   2\n",
      "       4540 |   0.227423  |    0.044865     |   0\n",
      "       4541 |   0.206762  |    0.075097     |   0\n",
      "       4542 |   0.292462  |    0.027917     |   0\n",
      "       4543 |   0.230819  |    0.075714     |   0\n",
      "       4544 |   0.060567  |    0.020170     |   2\n",
      "       4545 |   0.244078  |    0.076882     |   0\n",
      "       4546 |   0.238302  |    0.185470     |   1\n",
      "       4547 |   0.228389  |    0.004912     |   0\n",
      "       4548 |   0.242270  |    0.043003     |   0\n",
      "       4549 |   0.257867  |    0.082405     |   0\n",
      "       4550 |   0.250954  |    0.025673     |   0\n",
      "       4551 |   0.167205  |    0.070504     |   0\n",
      "       4552 |   0.281070  |    0.148123     |   1\n",
      "       4553 |   0.229283  |    0.147597     |   1\n",
      "       4554 |   0.088748  |    0.011102     |   2\n",
      "       4555 |   0.207545  |    0.077734     |   0\n",
      "       4556 |   0.324624  |    0.139323     |   1\n",
      "       4557 |   0.249862  |    0.028670     |   0\n",
      "       4558 |   0.215032  |    0.078648     |   0\n",
      "       4559 |   0.075949  |    0.012945     |   2\n",
      "       4560 |   0.156023  |    0.060707     |   0\n",
      "       4561 |   0.034966  |    0.026988     |   2\n",
      "       4562 |   0.275837  |    0.181877     |   1\n",
      "       4563 |   0.203042  |    0.045348     |   0\n",
      "       4564 |   0.226353  |    0.052776     |   0\n",
      "       4565 |   0.076105  |    0.039663     |   2\n",
      "       4566 |   0.241547  |    0.182643     |   1\n",
      "       4567 |   0.052814  |    0.049503     |   2\n",
      "       4568 |   0.298802  |    0.144715     |   1\n",
      "       4569 |   0.000174  |    0.076273     |   2\n",
      "       4570 |   0.000185  |    0.032537     |   2\n",
      "       4571 |   0.000208  |    0.050504     |   2\n",
      "       4572 |   0.215879  |    0.044915     |   0\n",
      "       4573 |   0.219747  |    0.077627     |   0\n",
      "       4574 |   0.218174  |    0.039697     |   0\n",
      "       4575 |   0.000214  |    0.040123     |   2\n",
      "       4576 |   0.298720  |    0.073612     |   0\n",
      "       4577 |   0.232999  |    0.051780     |   0\n",
      "       4578 |   0.249758  |    0.196217     |   1\n",
      "       4579 |   0.273387  |    0.005770     |   0\n",
      "       4580 |   0.000194  |    0.025128     |   2\n",
      "       4581 |   0.256346  |    0.050718     |   0\n",
      "       4582 |   0.266603  |    0.140317     |   1\n",
      "       4583 |   0.000222  |    0.080125     |   2\n",
      "       4584 |   0.232954  |    0.138047     |   1\n",
      "       4585 |   0.255828  |    0.041585     |   0\n",
      "       4586 |   0.201131  |    0.049603     |   0\n",
      "       4587 |   0.204464  |    0.053346     |   0\n",
      "       4588 |   0.250919  |    0.048002     |   0\n",
      "       4589 |   0.094690  |    0.045494     |   2\n",
      "       4590 |   0.245007  |    0.156793     |   1\n",
      "       4591 |   0.194093  |    0.022118     |   0\n",
      "       4592 |   0.222597  |    0.073892     |   0\n",
      "       4593 |   0.098758  |    0.043749     |   2\n",
      "       4594 |   0.355146  |    0.163538     |   1\n",
      "       4595 |   0.217521  |    0.048818     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 4596: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       4596 |   0.094516  |    0.056514     |   2\n",
      "       4597 |   0.273528  |    0.140606     |   1\n",
      "       4598 |   0.065607  |    0.051400     |   2\n",
      "       4599 |   0.252644  |    0.196913     |   1\n",
      "       4600 |   0.065810  |    0.023483     |   2\n",
      "       4601 |   0.220376  |    0.200335     |   1\n",
      "       4602 |   0.197023  |    0.026788     |   0\n",
      "       4603 |   0.271196  |    0.092942     |   0\n",
      "       4604 |   0.091533  |    0.031879     |   2\n",
      "       4605 |   0.041607  |    0.052328     |   2\n",
      "       4606 |   0.075521  |    0.047659     |   2\n",
      "       4607 |   0.340910  |    0.146284     |   1\n",
      "       4608 |   0.202276  |    0.074354     |   0\n",
      "       4609 |   0.232480  |    0.027314     |   0\n",
      "       4610 |   0.248433  |    0.051858     |   0\n",
      "       4611 |   0.078354  |    0.043004     |   2\n",
      "       4612 |   0.079979  |    0.075714     |   2\n",
      "       4613 |   0.194451  |    0.029906     |   0\n",
      "       4614 |   0.255996  |    0.079392     |   0\n",
      "       4615 |   0.078311  |    0.026265     |   2\n",
      "       4616 |   0.035524  |    0.052090     |   2\n",
      "       4617 |   0.000185  |    0.049555     |   2\n",
      "       4618 |   0.299293  |    0.140564     |   1\n",
      "       4619 |   0.253854  |    0.050852     |   0\n",
      "       4620 |   0.007618  |    0.039599     |   2\n",
      "       4621 |   0.139658  |    0.052995     |   2\n",
      "       4622 |   0.060616  |    0.051443     |   2\n",
      "       4623 |   0.241051  |    0.142006     |   1\n",
      "       4624 |   0.204214  |    0.029176     |   0\n",
      "       4625 |   0.198958  |    0.079566     |   0\n",
      "       4626 |   0.200000  |    0.148303     |   1\n",
      "       4627 |   0.235000  |    0.211884     |   1\n",
      "       4628 |   0.218195  |    0.009216     |   0\n",
      "       4629 |   0.260362  |    0.145430     |   1\n",
      "       4630 |   0.250332  |    0.041072     |   0\n",
      "       4631 |   0.240114  |    0.076354     |   0\n",
      "       4632 |   0.087648  |    0.023504     |   2\n",
      "       4633 |   0.235459  |    0.076974     |   0\n",
      "       4634 |   0.072649  |    0.016039     |   2\n",
      "       4635 |   0.032852  |    0.090073     |   2\n",
      "       4636 |   0.244509  |    0.186801     |   1\n",
      "       4637 |   0.072781  |    0.009354     |   2\n",
      "       4638 |   0.245278  |    0.082267     |   0\n",
      "       4639 |   0.292734  |    0.150136     |   1\n",
      "       4640 |   0.053579  |    0.017239     |   2\n",
      "       4641 |   0.000174  |    0.075796     |   2\n",
      "       4642 |   0.000180  |    0.037893     |   2\n",
      "       4643 |   0.000204  |    0.047619     |   2\n",
      "       4644 |   0.190412  |    0.042081     |   0\n",
      "       4645 |   0.165241  |    0.045811     |   0\n",
      "       4646 |   0.000199  |    0.046606     |   2\n",
      "       4647 |   0.258488  |    0.162453     |   1\n",
      "       4648 |   0.000189  |    0.043990     |   2\n",
      "       4649 |   0.212277  |    0.046333     |   0\n",
      "       4650 |   0.298230  |    0.146820     |   1\n",
      "       4651 |   0.233792  |    0.197875     |   1\n",
      "       4652 |   0.000215  |    0.008286     |   2\n",
      "       4653 |   0.222516  |    0.089785     |   0\n",
      "       4654 |   0.326064  |    0.137681     |   1\n",
      "       4655 |   0.219280  |    0.030184     |   0\n",
      "       4656 |   0.267279  |    0.199704     |   1\n",
      "       4657 |   0.084378  |    0.030840     |   2\n",
      "       4658 |   0.275007  |    0.218809     |   1\n",
      "       4659 |   0.321635  |    0.150653     |   1\n",
      "       4660 |   0.278390  |    0.130395     |   1\n",
      "       4661 |   0.193118  |    0.046982     |   0\n",
      "       4662 |   0.295398  |    0.199082     |   1\n",
      "       4663 |   0.228000  |    0.003248     |   0\n",
      "       4664 |   0.208886  |    0.190834     |   1\n",
      "       4665 |   0.262422  |    0.007363     |   0\n",
      "       4666 |   0.230997  |    0.193138     |   1\n",
      "       4667 |   0.095363  |    0.043926     |   2\n",
      "       4668 |   0.250246  |    0.043209     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 4669: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       4669 |   0.252515  |    0.050739     |   0\n",
      "       4670 |   0.085552  |    0.031637     |   2\n",
      "       4671 |   0.294181  |    0.196937     |   1\n",
      "       4672 |   0.232780  |    0.011403     |   0\n",
      "       4673 |   0.253209  |    0.182698     |   1\n",
      "       4674 |   0.267237  |    0.153680     |   1\n",
      "       4675 |   0.234462  |    0.144471     |   1\n",
      "       4676 |   0.224012  |    0.012369     |   0\n",
      "       4677 |   0.253433  |    0.191840     |   1\n",
      "       4678 |   0.059579  |    0.016057     |   2\n",
      "       4679 |   0.065151  |    0.049924     |   2\n",
      "       4680 |   0.087883  |    0.043208     |   2\n",
      "       4681 |   0.228595  |    0.077820     |   0\n",
      "       4682 |   0.039700  |    0.032498     |   2\n",
      "       4683 |   0.300368  |    0.143323     |   1\n",
      "       4684 |   0.074290  |    0.073392     |   2\n",
      "       4685 |   0.073358  |    0.027356     |   2\n",
      "       4686 |   0.076011  |    0.079431     |   2\n",
      "       4687 |   0.186593  |    0.160021     |   1\n",
      "       4688 |   0.182427  |    0.016553     |   0\n",
      "       4689 |   0.187186  |    0.076061     |   0\n",
      "       4690 |   0.206950  |    0.156751     |   1\n",
      "       4691 |   0.181124  |    0.003547     |   0\n",
      "       4692 |   0.078584  |    0.066200     |   2\n",
      "       4693 |   0.260110  |    0.134100     |   1\n",
      "       4694 |   0.268096  |    0.041057     |   0\n",
      "       4695 |   0.034989  |    0.040587     |   2\n",
      "       4696 |   0.262312  |    0.050696     |   0\n",
      "       4697 |   0.290998  |    0.205449     |   1\n",
      "       4698 |   0.306656  |    0.138320     |   1\n",
      "       4699 |   0.000180  |    0.013794     |   2\n",
      "       4700 |   0.009053  |    0.046750     |   2\n",
      "       4701 |   0.219087  |    0.076022     |   0\n",
      "       4702 |   0.137341  |    0.016864     |   2\n",
      "       4703 |   0.056370  |    0.072280     |   2\n",
      "       4704 |   0.210202  |    0.046020     |   0\n",
      "       4705 |   0.085950  |    0.045114     |   2\n",
      "       4706 |   0.235871  |    0.194043     |   1\n",
      "       4707 |   0.238931  |    0.164383     |   1\n",
      "       4708 |   0.290482  |    0.144935     |   1\n",
      "       4709 |   0.214286  |    0.008507     |   0\n",
      "       4710 |   0.066946  |    0.042326     |   2\n",
      "       4711 |   0.204939  |    0.054875     |   0\n",
      "       4712 |   0.031028  |    0.024018     |   2\n",
      "       4713 |   0.068671  |    0.042711     |   2\n",
      "       4714 |   0.234899  |    0.147982     |   1\n",
      "       4715 |   0.305713  |    0.025303     |   0\n",
      "       4716 |   0.197402  |    0.075525     |   0\n",
      "       4717 |   0.048925  |    0.029621     |   2\n",
      "       4718 |   0.261612  |    0.225251     |   1\n",
      "       4719 |   0.000173  |    0.005410     |   2\n",
      "       4720 |   0.310804  |    0.083133     |   0\n",
      "       4721 |   0.188346  |    0.154962     |   1\n",
      "       4722 |   0.000180  |    0.039048     |   2\n",
      "       4723 |   0.249194  |    0.050236     |   0\n",
      "       4724 |   0.000212  |    0.053328     |   2\n",
      "       4725 |   0.291242  |    0.160980     |   1\n",
      "       4726 |   0.258239  |    0.008698     |   0\n",
      "       4727 |   0.228594  |    0.080403     |   0\n",
      "       4728 |   0.245970  |    0.008420     |   0\n",
      "       4729 |   0.212522  |    0.077735     |   0\n",
      "       4730 |   0.304278  |    0.139984     |   1\n",
      "       4731 |   0.000217  |    0.035167     |   2\n",
      "       4732 |   0.000189  |    0.040024     |   2\n",
      "       4733 |   0.255122  |    0.054980     |   0\n",
      "       4734 |   0.274816  |    0.201287     |   1\n",
      "       4735 |   0.259007  |    0.153050     |   1\n",
      "       4736 |   0.000221  |    0.006273     |   2\n",
      "       4737 |   0.089767  |    0.080061     |   2\n",
      "       4738 |   0.227357  |    0.028535     |   0\n",
      "       4739 |   0.094661  |    0.049095     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 4740: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       4740 |   0.095356  |    0.042872     |   2\n",
      "       4741 |   0.276753  |    0.148409     |   1\n",
      "       4742 |   0.064862  |    0.004499     |   2\n",
      "       4743 |   0.065246  |    0.056485     |   2\n",
      "       4744 |   0.252812  |    0.043948     |   0\n",
      "       4745 |   0.088732  |    0.052795     |   2\n",
      "       4746 |   0.250003  |    0.169361     |   1\n",
      "       4747 |   0.041152  |    0.009686     |   2\n",
      "       4748 |   0.270847  |    0.080436     |   0\n",
      "       4749 |   0.230186  |    0.152589     |   1\n",
      "       4750 |   0.222366  |    0.200093     |   1\n",
      "       4751 |   0.073115  |    0.005097     |   2\n",
      "       4752 |   0.074269  |    0.041650     |   2\n",
      "       4753 |   0.077467  |    0.075449     |   2\n",
      "       4754 |   0.239504  |    0.154548     |   1\n",
      "       4755 |   0.078798  |    0.052822     |   2\n",
      "       4756 |   0.257230  |    0.187678     |   1\n",
      "       4757 |   0.247389  |    0.009979     |   0\n",
      "       4758 |   0.035548  |    0.052186     |   2\n",
      "       4759 |   0.000179  |    0.049253     |   2\n",
      "       4760 |   0.008023  |    0.046398     |   2\n",
      "       4761 |   0.137082  |    0.041473     |   2\n",
      "       4762 |   0.208892  |    0.082344     |   0\n",
      "       4763 |   0.055443  |    0.016542     |   2\n",
      "       4764 |   0.239975  |    0.215839     |   1\n",
      "       4765 |   0.307671  |    0.080608     |   1\n",
      "       4766 |   0.255300  |    0.078323     |   0\n",
      "       4767 |   0.255110  |    0.191328     |   1\n",
      "       4768 |   0.080642  |    0.006726     |   2\n",
      "       4769 |   0.181896  |    0.053229     |   0\n",
      "       4770 |   0.277207  |    0.148524     |   1\n",
      "       4771 |   0.239119  |    0.037903     |   0\n",
      "       4772 |   0.064929  |    0.080147     |   2\n",
      "       4773 |   0.222176  |    0.015473     |   0\n",
      "       4774 |   0.273362  |    0.072297     |   0\n",
      "       4775 |   0.245730  |    0.043656     |   0\n",
      "       4776 |   0.241552  |    0.040981     |   0\n",
      "       4777 |   0.249784  |    0.224368     |   1\n",
      "       4778 |   0.317104  |    0.104553     |   1\n",
      "       4779 |   0.030467  |    0.004310     |   2\n",
      "       4780 |   0.208240  |    0.201283     |   1\n",
      "       4781 |   0.236056  |    0.045981     |   0\n",
      "       4782 |   0.281131  |    0.137853     |   1\n",
      "       4783 |   0.270091  |    0.083165     |   0\n",
      "       4784 |   0.362988  |    0.143108     |   1\n",
      "       4785 |   0.218606  |    0.011967     |   0\n",
      "       4786 |   0.239701  |    0.073927     |   0\n",
      "       4787 |   0.308689  |    0.162374     |   1\n",
      "       4788 |   0.200544  |    0.159057     |   1\n",
      "       4789 |   0.200344  |    0.149882     |   1\n",
      "       4790 |   0.067336  |    0.044631     |   2\n",
      "       4791 |   0.266903  |    0.040436     |   0\n",
      "       4792 |   0.050015  |    0.074092     |   2\n",
      "       4793 |   0.000171  |    0.029689     |   2\n",
      "       4794 |   0.000176  |    0.084425     |   2\n",
      "       4795 |   0.206894  |    0.186397     |   1\n",
      "       4796 |   0.229396  |    0.149248     |   1\n",
      "       4797 |   0.224546  |    0.016045     |   0\n",
      "       4798 |   0.243074  |    0.086879     |   0\n",
      "       4799 |   0.207647  |    0.155721     |   1\n",
      "       4800 |   0.253191  |    0.212659     |   1\n",
      "       4801 |   0.191831  |    0.009269     |   0\n",
      "       4802 |   0.000208  |    0.024178     |   2\n",
      "       4803 |   0.255523  |    0.215903     |   1\n",
      "       4804 |   0.000210  |    0.017071     |   2\n",
      "       4805 |   0.204019  |    0.205046     |   1\n",
      "       4806 |   0.283536  |    0.143698     |   1\n",
      "       4807 |   0.273629  |    0.027302     |   0\n",
      "       4808 |   0.000185  |    0.085483     |   2\n",
      "       4809 |   0.203142  |    0.149539     |   1\n",
      "       4810 |   0.277519  |    0.030524     |   0\n",
      "       4811 |   0.302277  |    0.210528     |   1\n",
      "       4812 |   0.276976  |    0.148430     |   1\n",
      "       4813 |   0.000211  |    0.006142     |   2\n",
      "       4814 |   0.228440  |    0.098212     |   0\n",
      "       4815 |   0.309018  |    0.164968     |   1\n",
      "       4816 |   0.081751  |    0.008931     |   2\n",
      "       4817 |   0.305707  |    0.080348     |   0\n",
      "       4818 |   0.260201  |    0.023500     |   0\n",
      "       4819 |   0.272195  |    0.200281     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 4821: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       4820 |   0.093261  |    0.004868     |   2\n",
      "       4821 |   0.278930  |    0.216637     |   1\n",
      "       4822 |   0.320042  |    0.162245     |   1\n",
      "       4823 |   0.305857  |    0.100201     |   1\n",
      "       4824 |   0.270129  |    0.021480     |   0\n",
      "       4825 |   0.259146  |    0.197952     |   1\n",
      "       4826 |   0.236845  |    0.025527     |   0\n",
      "       4827 |   0.262368  |    0.076053     |   0\n",
      "       4828 |   0.224989  |    0.029028     |   0\n",
      "       4829 |   0.256838  |    0.192307     |   1\n",
      "       4830 |   0.241286  |    0.008618     |   0\n",
      "       4831 |   0.091488  |    0.078423     |   2\n",
      "       4832 |   0.066019  |    0.045565     |   2\n",
      "       4833 |   0.065951  |    0.054101     |   2\n",
      "       4834 |   0.087091  |    0.039532     |   2\n",
      "       4835 |   0.240202  |    0.072122     |   0\n",
      "       4836 |   0.231530  |    0.015160     |   0\n",
      "       4837 |   0.039978  |    0.082678     |   2\n",
      "       4838 |   0.072801  |    0.007582     |   2\n",
      "       4839 |   0.194598  |    0.083530     |   0\n",
      "       4840 |   0.338065  |    0.153545     |   1\n",
      "       4841 |   0.185841  |    0.004546     |   0\n",
      "       4842 |   0.210026  |    0.033481     |   0\n",
      "       4843 |   0.080034  |    0.046302     |   2\n",
      "       4844 |   0.262189  |    0.204547     |   1\n",
      "       4845 |   0.240826  |    0.140074     |   1\n",
      "       4846 |   0.077163  |    0.037134     |   2\n",
      "       4847 |   0.257657  |    0.181901     |   1\n",
      "       4848 |   0.079882  |    0.050670     |   2\n",
      "       4849 |   0.265701  |    0.161689     |   1\n",
      "       4850 |   0.304977  |    0.131985     |   1\n",
      "       4851 |   0.209454  |    0.146912     |   1\n",
      "       4852 |   0.207434  |    0.049768     |   0\n",
      "       4853 |   0.034233  |    0.042478     |   2\n",
      "       4854 |   0.000178  |    0.094864     |   2\n",
      "       4855 |   0.190993  |    0.151273     |   1\n",
      "       4856 |   0.292556  |    0.164928     |   1\n",
      "       4857 |   0.276158  |    0.151182     |   1\n",
      "       4858 |   0.228762  |    0.020064     |   0\n",
      "       4859 |   0.268332  |    0.151528     |   1\n",
      "       4860 |   0.007941  |    0.026589     |   2\n",
      "       4861 |   0.220286  |    0.208342     |   1\n",
      "       4862 |   0.297351  |    0.148043     |   1\n",
      "       4863 |   0.237119  |    0.153886     |   1\n",
      "       4864 |   0.275336  |    0.014665     |   0\n",
      "       4865 |   0.237166  |    0.052789     |   0\n",
      "       4866 |   0.203957  |    0.049966     |   0\n",
      "       4867 |   0.135023  |    0.037940     |   2\n",
      "       4868 |   0.198221  |    0.052175     |   0\n",
      "       4869 |   0.234625  |    0.043955     |   0\n",
      "       4870 |   0.276207  |    0.194422     |   1\n",
      "       4871 |   0.058772  |    0.006797     |   2\n",
      "       4872 |   0.278092  |    0.225785     |   1\n",
      "       4873 |   0.314618  |    0.092059     |   1\n",
      "       4874 |   0.085792  |    0.039146     |   2\n",
      "       4875 |   0.190887  |    0.042775     |   0\n",
      "       4876 |   0.225103  |    0.071928     |   0\n",
      "       4877 |   0.069840  |    0.022736     |   2\n",
      "       4878 |   0.202495  |    0.104151     |   0\n",
      "       4879 |   0.269910  |    0.146030     |   1\n",
      "       4880 |   0.229908  |    0.006494     |   0\n",
      "       4881 |   0.032963  |    0.088008     |   2\n",
      "       4882 |   0.287144  |    0.094039     |   1\n",
      "       4883 |   0.070858  |    0.041128     |   2\n",
      "       4884 |   0.052671  |    0.053438     |   2\n",
      "       4885 |   0.292640  |    0.199646     |   1\n",
      "       4886 |   0.241649  |    0.033850     |   0\n",
      "       4887 |   0.262063  |    0.153433     |   1\n",
      "       4888 |   0.191993  |    0.077518     |   0\n",
      "       4889 |   0.179025  |    0.014797     |   0\n",
      "       4890 |   0.235636  |    0.105354     |   0\n",
      "       4891 |   0.179136  |    0.161063     |   1\n",
      "       4892 |   0.000169  |    0.004712     |   2\n",
      "       4893 |   0.238573  |    0.040610     |   0\n",
      "       4894 |   0.000173  |    0.050747     |   2\n",
      "       4895 |   0.226080  |    0.053705     |   0\n",
      "       4896 |   0.320568  |    0.153110     |   1\n",
      "       4897 |   0.000197  |    0.031709     |   2\n",
      "       4898 |   0.287680  |    0.166708     |   1\n",
      "       4899 |   0.266873  |    0.136459     |   1\n",
      "       4900 |   0.292005  |    0.149851     |   1\n",
      "       4901 |   0.270795  |    0.021234     |   0\n",
      "       4902 |   0.309442  |    0.196075     |   1\n",
      "       4903 |   0.000187  |    0.008893     |   2\n",
      "       4904 |   0.000181  |    0.074294     |   2\n",
      "       4905 |   0.223669  |    0.033467     |   0\n",
      "       4906 |   0.000204  |    0.048584     |   2\n",
      "       4907 |   0.280953  |    0.198002     |   1\n",
      "       4908 |   0.198264  |    0.010635     |   0\n",
      "       4909 |   0.202372  |    0.081376     |   0\n",
      "       4910 |   0.223545  |    0.024757     |   0\n",
      "       4911 |   0.267707  |    0.073210     |   0\n",
      "       4912 |   0.202739  |    0.029724     |   0\n",
      "       4913 |   0.291573  |    0.217468     |   1\n",
      "       4914 |   0.087285  |    0.003643     |   2\n",
      "       4915 |   0.095236  |    0.064917     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 4916: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       4916 |   0.274830  |    0.150871     |   1\n",
      "       4917 |   0.258996  |    0.014317     |   0\n",
      "       4918 |   0.091526  |    0.089656     |   2\n",
      "       4919 |   0.245703  |    0.030520     |   0\n",
      "       4920 |   0.212705  |    0.196774     |   1\n",
      "       4921 |   0.255542  |    0.041916     |   0\n",
      "       4922 |   0.221714  |    0.044368     |   0\n",
      "       4923 |   0.060781  |    0.072623     |   2\n",
      "       4924 |   0.249991  |    0.044808     |   0\n",
      "       4925 |   0.064502  |    0.046881     |   2\n",
      "       4926 |   0.089885  |    0.043854     |   2\n",
      "       4927 |   0.194988  |    0.201936     |   1\n",
      "       4928 |   0.041790  |    0.012980     |   2\n",
      "       4929 |   0.241197  |    0.080085     |   0\n",
      "       4930 |   0.231736  |    0.039725     |   0\n",
      "       4931 |   0.240317  |    0.198059     |   1\n",
      "       4932 |   0.209525  |    0.006378     |   0\n",
      "       4933 |   0.074237  |    0.041418     |   2\n",
      "       4934 |   0.251271  |    0.075954     |   0\n",
      "       4935 |   0.268053  |    0.016627     |   0\n",
      "       4936 |   0.258965  |    0.094572     |   0\n",
      "       4937 |   0.242441  |    0.155543     |   1\n",
      "       4938 |   0.203319  |    0.142689     |   1\n",
      "       4939 |   0.194511  |    0.024875     |   0\n",
      "       4940 |   0.231921  |    0.079637     |   0\n",
      "       4941 |   0.077748  |    0.014174     |   2\n",
      "       4942 |   0.247531  |    0.195633     |   1\n",
      "       4943 |   0.207371  |    0.027477     |   0\n",
      "       4944 |   0.078775  |    0.078223     |   2\n",
      "       4945 |   0.246884  |    0.027029     |   0\n",
      "       4946 |   0.080791  |    0.081930     |   2\n",
      "       4947 |   0.232887  |    0.009833     |   0\n",
      "       4948 |   0.234030  |    0.082778     |   0\n",
      "       4949 |   0.036357  |    0.026832     |   2\n",
      "       4950 |   0.252357  |    0.206172     |   1\n",
      "       4951 |   0.291747  |    0.135081     |   1\n",
      "       4952 |   0.248180  |    0.156938     |   1\n",
      "       4953 |   0.210758  |    0.007460     |   0\n",
      "       4954 |   0.000178  |    0.052567     |   2\n",
      "       4955 |   0.306022  |    0.193664     |   1\n",
      "       4956 |   0.215902  |    0.003217     |   0\n",
      "       4957 |   0.213469  |    0.157481     |   1\n",
      "       4958 |   0.009093  |    0.025721     |   2\n",
      "       4959 |   0.257870  |    0.072826     |   0\n",
      "       4960 |   0.281432  |    0.139611     |   1\n",
      "       4961 |   0.222348  |    0.076302     |   0\n",
      "       4962 |   0.219241  |    0.019509     |   0\n",
      "       4963 |   0.243738  |    0.046823     |   0\n",
      "       4964 |   0.133189  |    0.054534     |   2\n",
      "       4965 |   0.293868  |    0.153062     |   1\n",
      "       4966 |   0.259229  |    0.142621     |   1\n",
      "       4967 |   0.216558  |    0.044374     |   0\n",
      "       4968 |   0.256824  |    0.194430     |   1\n",
      "       4969 |   0.268851  |    0.006983     |   0\n",
      "       4970 |   0.058917  |    0.040422     |   2\n",
      "       4971 |   0.215893  |    0.040988     |   0\n",
      "       4972 |   0.234956  |    0.190279     |   1\n",
      "       4973 |   0.223436  |    0.038073     |   0\n",
      "       4974 |   0.241210  |    0.049642     |   0\n",
      "       4975 |   0.215677  |    0.210078     |   1\n",
      "       4976 |   0.087033  |    0.004417     |   2\n",
      "       4977 |   0.070166  |    0.014291     |   2\n",
      "       4978 |   0.217090  |    0.081095     |   0\n",
      "       4979 |   0.250317  |    0.165821     |   1\n",
      "       4980 |   0.251908  |    0.038934     |   0\n",
      "       4981 |   0.032496  |    0.044861     |   2\n",
      "       4982 |   0.235130  |    0.077564     |   0\n",
      "       4983 |   0.266353  |    0.147706     |   1\n",
      "       4984 |   0.265987  |    0.150716     |   1\n",
      "       4985 |   0.185070  |    0.199120     |   1\n",
      "       4986 |   0.069538  |    0.006930     |   2\n",
      "       4987 |   0.051503  |    0.074189     |   2\n",
      "       4988 |   0.243876  |    0.145297     |   1\n",
      "       4989 |   0.000170  |    0.019032     |   2\n",
      "       4990 |   0.000175  |    0.086336     |   2\n",
      "       4991 |   0.305045  |    0.140780     |   1\n",
      "       4992 |   0.000201  |    0.040898     |   2\n",
      "       4993 |   0.252655  |    0.084328     |   0\n",
      "       4994 |   0.245582  |    0.142807     |   1\n",
      "       4995 |   0.325837  |    0.160134     |   1\n",
      "       4996 |   0.000189  |    0.007093     |   2\n",
      "       4997 |   0.310471  |    0.200730     |   1\n",
      "       4998 |   0.250667  |    0.010048     |   0\n",
      "       4999 |   0.245000  |    0.075142     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 5000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 5000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       5000 |   0.201553  |    0.016195     |   0\n",
      "       5001 |   0.089676  |    0.080500     |   2\n",
      "       5002 |   0.219758  |    0.021622     |   0\n",
      "       5003 |   0.272032  |    0.080827     |   0\n",
      "       5004 |   0.262438  |    0.018925     |   0\n",
      "       5005 |   0.249409  |    0.192517     |   1\n",
      "       5006 |   0.238706  |    0.034814     |   0\n",
      "       5007 |   0.063393  |    0.044131     |   2\n",
      "       5008 |   0.295502  |    0.194554     |   1\n",
      "       5009 |   0.203308  |    0.006104     |   0\n",
      "       5010 |   0.065118  |    0.091182     |   2\n",
      "       5011 |   0.258608  |    0.188153     |   1\n",
      "       5012 |   0.243910  |    0.150042     |   1\n",
      "       5013 |   0.248574  |    0.008390     |   0\n",
      "       5014 |   0.088466  |    0.076556     |   2\n",
      "       5015 |   0.219061  |    0.189910     |   1\n",
      "       5016 |   0.239168  |    0.128006     |   1\n",
      "       5017 |   0.174954  |    0.016360     |   0\n",
      "       5018 |   0.288198  |    0.142857     |   1\n",
      "       5019 |   0.218252  |    0.076799     |   0\n",
      "       5020 |   0.040497  |    0.006734     |   2\n",
      "       5021 |   0.285517  |    0.089016     |   0\n",
      "       5022 |   0.312467  |    0.162279     |   1\n",
      "       5023 |   0.244994  |    0.007548     |   0\n",
      "       5024 |   0.072853  |    0.046441     |   2\n",
      "       5025 |   0.080174  |    0.054260     |   2\n",
      "       5026 |   0.076800  |    0.046649     |   2\n",
      "       5027 |   0.080520  |    0.039560     |   2\n",
      "       5028 |   0.290490  |    0.150784     |   1\n",
      "       5029 |   0.292190  |    0.141880     |   1\n",
      "       5030 |   0.035146  |    0.041317     |   2\n",
      "       5031 |   0.000177  |    0.082599     |   2\n",
      "       5032 |   0.007552  |    0.020412     |   2\n",
      "       5033 |   0.221662  |    0.074631     |   0\n",
      "       5034 |   0.132555  |    0.036123     |   2\n",
      "       5035 |   0.312688  |    0.150273     |   1\n",
      "       5036 |   0.265131  |    0.077693     |   0\n",
      "       5037 |   0.237565  |    0.026303     |   0\n",
      "       5038 |   0.057736  |    0.046656     |   2\n",
      "       5039 |   0.226210  |    0.089709     |   0\n",
      "       5040 |   0.219852  |    0.132975     |   1\n",
      "       5041 |   0.225688  |    0.019081     |   0\n",
      "       5042 |   0.086503  |    0.087071     |   2\n",
      "       5043 |   0.065378  |    0.014849     |   2\n",
      "       5044 |   0.188905  |    0.081035     |   0\n",
      "       5045 |   0.235076  |    0.162186     |   1\n",
      "       5046 |   0.223234  |    0.024736     |   0\n",
      "       5047 |   0.190751  |    0.211817     |   1\n",
      "       5048 |   0.240677  |    0.012723     |   0\n",
      "       5049 |   0.030413  |    0.078907     |   2\n",
      "       5050 |   0.313323  |    0.149747     |   1\n",
      "       5051 |   0.266255  |    0.030110     |   0\n",
      "       5052 |   0.068693  |    0.091845     |   2\n",
      "       5053 |   0.275639  |    0.142145     |   1\n",
      "       5054 |   0.049278  |    0.039787     |   2\n",
      "       5055 |   0.277802  |    0.157130     |   1\n",
      "       5056 |   0.000168  |    0.031634     |   2\n",
      "       5057 |   0.000174  |    0.044708     |   2\n",
      "       5058 |   0.235329  |    0.194639     |   1\n",
      "       5059 |   0.263517  |    0.156593     |   1\n",
      "       5060 |   0.000199  |    0.022204     |   2\n",
      "       5061 |   0.302792  |    0.208341     |   1\n",
      "       5062 |   0.255660  |    0.145308     |   1\n",
      "       5063 |   0.000190  |    0.008803     |   2\n",
      "       5064 |   0.259453  |    0.085493     |   0\n",
      "       5065 |   0.265110  |    0.106182     |   1\n",
      "       5066 |   0.327489  |    0.191985     |   1\n",
      "       5067 |   0.180192  |    0.006075     |   0\n",
      "       5068 |   0.000179  |    0.056680     |   2\n",
      "       5069 |   0.233072  |    0.168917     |   1\n",
      "       5070 |   0.241519  |    0.121764     |   1\n",
      "       5071 |   0.270562  |    0.139783     |   1\n",
      "       5072 |   0.195264  |    0.040527     |   0\n",
      "       5073 |   0.000211  |    0.050387     |   2\n",
      "       5074 |   0.085452  |    0.071317     |   2\n",
      "       5075 |   0.251055  |    0.009817     |   0\n",
      "       5076 |   0.307580  |    0.073036     |   0\n",
      "       5077 |   0.242487  |    0.006073     |   0\n",
      "       5078 |   0.224410  |    0.071766     |   0\n",
      "       5079 |   0.224158  |    0.136102     |   1\n",
      "       5080 |   0.091475  |    0.080911     |   2\n",
      "       5081 |   0.257619  |    0.144800     |   1\n",
      "       5082 |   0.284238  |    0.152450     |   1\n",
      "       5083 |   0.210846  |    0.011844     |   0\n",
      "       5084 |   0.269911  |    0.186364     |   1\n",
      "       5085 |   0.211557  |    0.085609     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 5086: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       5086 |   0.178589  |    0.010686     |   0\n",
      "       5087 |   0.215608  |    0.045513     |   0\n",
      "       5088 |   0.258821  |    0.096896     |   0\n",
      "       5089 |   0.190272  |    0.155242     |   1\n",
      "       5090 |   0.367840  |    0.153453     |   1\n",
      "       5091 |   0.249712  |    0.008267     |   0\n",
      "       5092 |   0.232191  |    0.081497     |   0\n",
      "       5093 |   0.183033  |    0.024875     |   0\n",
      "       5094 |   0.090659  |    0.049452     |   2\n",
      "       5095 |   0.224436  |    0.046145     |   0\n",
      "       5096 |   0.062595  |    0.046707     |   2\n",
      "       5097 |   0.243360  |    0.048260     |   0\n",
      "       5098 |   0.063570  |    0.052490     |   2\n",
      "       5099 |   0.087172  |    0.085935     |   2\n",
      "       5100 |   0.251879  |    0.032949     |   0\n",
      "       5101 |   0.228691  |    0.183167     |   1\n",
      "       5102 |   0.202220  |    0.171328     |   1\n",
      "       5103 |   0.040244  |    0.015225     |   2\n",
      "       5104 |   0.247442  |    0.223016     |   1\n",
      "       5105 |   0.197212  |    0.005008     |   0\n",
      "       5106 |   0.073485  |    0.050156     |   2\n",
      "       5107 |   0.082265  |    0.042738     |   2\n",
      "       5108 |   0.200995  |    0.042920     |   0\n",
      "       5109 |   0.241858  |    0.077197     |   0\n",
      "       5110 |   0.245121  |    0.169458     |   1\n",
      "       5111 |   0.218232  |    0.134076     |   1\n",
      "       5112 |   0.076409  |    0.036507     |   2\n",
      "       5113 |   0.153715  |    0.046908     |   0\n",
      "       5114 |   0.226676  |    0.195267     |   1\n",
      "       5115 |   0.080915  |    0.005279     |   2\n",
      "       5116 |   0.282330  |    0.094263     |   0\n",
      "       5117 |   0.210714  |    0.147624     |   1\n",
      "       5118 |   0.257978  |    0.073936     |   0\n",
      "       5119 |   0.268306  |    0.029696     |   0\n",
      "       5120 |   0.036132  |    0.048716     |   2\n",
      "       5121 |   0.247240  |    0.199290     |   1\n",
      "       5122 |   0.206083  |    0.005983     |   0\n",
      "       5123 |   0.000173  |    0.055305     |   2\n",
      "       5124 |   0.274360  |    0.054411     |   0\n",
      "       5125 |   0.236632  |    0.154777     |   1\n",
      "       5126 |   0.174293  |    0.201672     |   1\n",
      "       5127 |   0.170319  |    0.005395     |   0\n",
      "       5128 |   0.257060  |    0.162635     |   1\n",
      "       5129 |   0.008030  |    0.048492     |   2\n",
      "       5130 |   0.245154  |    0.040208     |   0\n",
      "       5131 |   0.296292  |    0.183534     |   1\n",
      "       5132 |   0.261589  |    0.007228     |   0\n",
      "       5133 |   0.224302  |    0.077956     |   0\n",
      "       5134 |   0.268805  |    0.163130     |   1\n",
      "       5135 |   0.136866  |    0.028908     |   2\n",
      "       5136 |   0.234115  |    0.190210     |   1\n",
      "       5137 |   0.058122  |    0.019479     |   2\n",
      "       5138 |   0.249655  |    0.204077     |   1\n",
      "       5139 |   0.236442  |    0.007202     |   0\n",
      "       5140 |   0.213991  |    0.084653     |   0\n",
      "       5141 |   0.317710  |    0.156327     |   1\n",
      "       5142 |   0.269191  |    0.156296     |   1\n",
      "       5143 |   0.322201  |    0.161206     |   1\n",
      "       5144 |   0.232065  |    0.141904     |   1\n",
      "       5145 |   0.206954  |    0.188016     |   1\n",
      "       5146 |   0.084315  |    0.025686     |   2\n",
      "       5147 |   0.261902  |    0.078707     |   0\n",
      "       5148 |   0.065194  |    0.041725     |   2\n",
      "       5149 |   0.328892  |    0.156061     |   1\n",
      "       5150 |   0.221542  |    0.201287     |   1\n",
      "       5151 |   0.267957  |    0.146481     |   1\n",
      "       5152 |   0.029433  |    0.043909     |   2\n",
      "       5153 |   0.257151  |    0.045085     |   0\n",
      "       5154 |   0.067083  |    0.069809     |   2\n",
      "       5155 |   0.197959  |    0.046316     |   0\n",
      "       5156 |   0.239425  |    0.025669     |   0\n",
      "       5157 |   0.219566  |    0.078744     |   0\n",
      "       5158 |   0.050509  |    0.009434     |   2\n",
      "       5159 |   0.000168  |    0.073387     |   2\n",
      "       5160 |   0.212038  |    0.053582     |   0\n",
      "       5161 |   0.217283  |    0.156970     |   1\n",
      "       5162 |   0.000173  |    0.042911     |   2\n",
      "       5163 |   0.000192  |    0.043963     |   2\n",
      "       5164 |   0.242142  |    0.179466     |   1\n",
      "       5165 |   0.000185  |    0.014981     |   2\n",
      "       5166 |   0.338680  |    0.152701     |   1\n",
      "       5167 |   0.233026  |    0.153739     |   1\n",
      "       5168 |   0.252024  |    0.195722     |   1\n",
      "       5169 |   0.000177  |    0.026896     |   2\n",
      "       5170 |   0.247709  |    0.050975     |   0\n",
      "       5171 |   0.258348  |    0.144394     |   1\n",
      "       5172 |   0.000199  |    0.006470     |   2\n",
      "       5173 |   0.254737  |    0.083660     |   0\n",
      "       5174 |   0.138142  |    0.135233     |   1\n",
      "       5175 |   0.246923  |    0.030207     |   0\n",
      "       5176 |   0.213182  |    0.195052     |   1\n",
      "       5177 |   0.255707  |    0.005104     |   0\n",
      "       5178 |   0.253741  |    0.080413     |   0\n",
      "       5179 |   0.272144  |    0.166251     |   1\n",
      "       5180 |   0.219644  |    0.132224     |   1\n",
      "       5181 |   0.087002  |    0.052561     |   2\n",
      "       5182 |   0.194791  |    0.187450     |   1\n",
      "       5183 |   0.093162  |    0.012136     |   2\n",
      "       5184 |   0.281995  |    0.147722     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 5186: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       5185 |   0.210904  |    0.040236     |   0\n",
      "       5186 |   0.267229  |    0.203404     |   1\n",
      "       5187 |   0.087347  |    0.012623     |   2\n",
      "       5188 |   0.219186  |    0.075985     |   0\n",
      "       5189 |   0.243445  |    0.054073     |   0\n",
      "       5190 |   0.314342  |    0.202490     |   1\n",
      "       5191 |   0.062290  |    0.013707     |   2\n",
      "       5192 |   0.062305  |    0.081807     |   2\n",
      "       5193 |   0.273234  |    0.060073     |   0\n",
      "       5194 |   0.269387  |    0.144687     |   1\n",
      "       5195 |   0.084828  |    0.016004     |   2\n",
      "       5196 |   0.341008  |    0.195117     |   1\n",
      "       5197 |   0.038750  |    0.011852     |   2\n",
      "       5198 |   0.237215  |    0.058232     |   0\n",
      "       5199 |   0.071475  |    0.029499     |   2\n",
      "       5200 |   0.265098  |    0.195417     |   1\n",
      "       5201 |   0.077349  |    0.005770     |   2\n",
      "       5202 |   0.303607  |    0.134785     |   1\n",
      "       5203 |   0.077553  |    0.046880     |   2\n",
      "       5204 |   0.078401  |    0.041636     |   2\n",
      "       5205 |   0.246371  |    0.079934     |   0\n",
      "       5206 |   0.186567  |    0.014445     |   0\n",
      "       5207 |   0.231089  |    0.080401     |   0\n",
      "       5208 |   0.032774  |    0.015530     |   2\n",
      "       5209 |   0.000172  |    0.079271     |   2\n",
      "       5210 |   0.008308  |    0.008677     |   2\n",
      "       5211 |   0.134666  |    0.056160     |   2\n",
      "       5212 |   0.240492  |    0.046954     |   0\n",
      "       5213 |   0.056490  |    0.048455     |   2\n",
      "       5214 |   0.083775  |    0.061993     |   2\n",
      "       5215 |   0.214423  |    0.139305     |   1\n",
      "       5216 |   0.197165  |    0.045749     |   0\n",
      "       5217 |   0.302850  |    0.152369     |   1\n",
      "       5218 |   0.224820  |    0.007250     |   0\n",
      "       5219 |   0.286390  |    0.197080     |   1\n",
      "       5220 |   0.181863  |    0.005505     |   0\n",
      "       5221 |   0.065050  |    0.059065     |   2\n",
      "       5222 |   0.204696  |    0.144362     |   1\n",
      "       5223 |   0.210076  |    0.071045     |   0\n",
      "       5224 |   0.031953  |    0.042016     |   2\n",
      "       5225 |   0.165020  |    0.178880     |   1\n",
      "       5226 |   0.235997  |    0.174858     |   1\n",
      "       5227 |   0.254218  |    0.152984     |   1\n",
      "       5228 |   0.306066  |    0.141041     |   1\n",
      "       5229 |   0.067384  |    0.082384     |   2\n",
      "       5230 |   0.049550  |    0.009938     |   2\n",
      "       5231 |   0.000165  |    0.060468     |   2\n",
      "       5232 |   0.000169  |    0.048092     |   2\n",
      "       5233 |   0.000192  |    0.083635     |   2\n",
      "       5234 |   0.000185  |    0.021749     |   2\n",
      "       5235 |   0.000175  |    0.082233     |   2\n",
      "       5236 |   0.000190  |    0.018812     |   2\n",
      "       5237 |   0.294754  |    0.196129     |   1\n",
      "       5238 |   0.079624  |    0.005588     |   2\n",
      "       5239 |   0.250501  |    0.078705     |   0\n",
      "       5240 |   0.245728  |    0.025648     |   0\n",
      "       5241 |   0.268709  |    0.048891     |   0\n",
      "       5242 |   0.283867  |    0.200634     |   1\n",
      "       5243 |   0.092056  |    0.005588     |   2\n",
      "       5244 |   0.214248  |    0.071268     |   0\n",
      "       5245 |   0.263225  |    0.152058     |   1\n",
      "       5246 |   0.270449  |    0.052439     |   0\n",
      "       5247 |   0.240040  |    0.186960     |   1\n",
      "       5248 |   0.181149  |    0.008041     |   0\n",
      "       5249 |   0.260978  |    0.073881     |   0\n",
      "       5250 |   0.301970  |    0.047883     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 5251: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       5251 |   0.235931  |    0.027091     |   0\n",
      "       5252 |   0.251392  |    0.185434     |   1\n",
      "       5253 |   0.281556  |    0.044851     |   0\n",
      "       5254 |   0.181020  |    0.042898     |   0\n",
      "       5255 |   0.284460  |    0.080358     |   0\n",
      "       5256 |   0.228730  |    0.133326     |   1\n",
      "       5257 |   0.090058  |    0.086985     |   2\n",
      "       5258 |   0.064107  |    0.009772     |   2\n",
      "       5259 |   0.243421  |    0.077864     |   0\n",
      "       5260 |   0.061483  |    0.042957     |   2\n",
      "       5261 |   0.244651  |    0.043784     |   0\n",
      "       5262 |   0.085326  |    0.054751     |   2\n",
      "       5263 |   0.271594  |    0.165610     |   1\n",
      "       5264 |   0.147519  |    0.186539     |   1\n",
      "       5265 |   0.222063  |    0.030774     |   0\n",
      "       5266 |   0.278593  |    0.199755     |   1\n",
      "       5267 |   0.234204  |    0.150481     |   1\n",
      "       5268 |   0.040958  |    0.011731     |   2\n",
      "       5269 |   0.304905  |    0.189980     |   1\n",
      "       5270 |   0.070542  |    0.005726     |   2\n",
      "       5271 |   0.197206  |    0.080876     |   0\n",
      "       5272 |   0.163806  |    0.024883     |   0\n",
      "       5273 |   0.074794  |    0.048035     |   2\n",
      "       5274 |   0.305983  |    0.211539     |   1\n",
      "       5275 |   0.181777  |    0.003401     |   0\n",
      "       5276 |   0.076179  |    0.044400     |   2\n",
      "       5277 |   0.326496  |    0.141568     |   1\n",
      "       5278 |   0.245333  |    0.042276     |   0\n",
      "       5279 |   0.078180  |    0.095335     |   2\n",
      "       5280 |   0.251191  |    0.140722     |   1\n",
      "       5281 |   0.034358  |    0.019043     |   2\n",
      "       5282 |   0.259434  |    0.201880     |   1\n",
      "       5283 |   0.213203  |    0.005681     |   0\n",
      "       5284 |   0.000170  |    0.041189     |   2\n",
      "       5285 |   0.007931  |    0.042988     |   2\n",
      "       5286 |   0.127502  |    0.052161     |   2\n",
      "       5287 |   0.055935  |    0.079010     |   2\n",
      "       5288 |   0.241623  |    0.174548     |   1\n",
      "       5289 |   0.082546  |    0.011506     |   2\n",
      "       5290 |   0.246212  |    0.185465     |   1\n",
      "       5291 |   0.206285  |    0.163235     |   1\n",
      "       5292 |   0.197762  |    0.042413     |   0\n",
      "       5293 |   0.063397  |    0.085083     |   2\n",
      "       5294 |   0.278088  |    0.133844     |   1\n",
      "       5295 |   0.243718  |    0.162051     |   1\n",
      "       5296 |   0.266905  |    0.136169     |   1\n",
      "       5297 |   0.212323  |    0.149801     |   1\n",
      "       5298 |   0.244295  |    0.045058     |   0\n",
      "       5299 |   0.029590  |    0.041095     |   2\n",
      "       5300 |   0.193914  |    0.045015     |   0\n",
      "       5301 |   0.269203  |    0.043896     |   0\n",
      "       5302 |   0.063234  |    0.043394     |   2\n",
      "       5303 |   0.048415  |    0.085992     |   2\n",
      "       5304 |   0.175293  |    0.008227     |   0\n",
      "       5305 |   0.202217  |    0.094646     |   0\n",
      "       5306 |   0.172947  |    0.165887     |   1\n",
      "       5307 |   0.267624  |    0.156707     |   1\n",
      "       5308 |   0.000165  |    0.009512     |   2\n",
      "       5309 |   0.237635  |    0.082209     |   0\n",
      "       5310 |   0.000170  |    0.026129     |   2\n",
      "       5311 |   0.262661  |    0.206805     |   1\n",
      "       5312 |   0.213105  |    0.150065     |   1\n",
      "       5313 |   0.251300  |    0.205216     |   1\n",
      "       5314 |   0.000191  |    0.015035     |   2\n",
      "       5315 |   0.218808  |    0.079648     |   0\n",
      "       5316 |   0.231378  |    0.014626     |   0\n",
      "       5317 |   0.000185  |    0.076988     |   2\n",
      "       5318 |   0.000175  |    0.045790     |   2\n",
      "       5319 |   0.239160  |    0.191158     |   1\n",
      "       5320 |   0.211157  |    0.004904     |   0\n",
      "       5321 |   0.223072  |    0.038333     |   0\n",
      "       5322 |   0.206935  |    0.053179     |   0\n",
      "       5323 |   0.000190  |    0.083116     |   2\n",
      "       5324 |   0.275420  |    0.147040     |   1\n",
      "       5325 |   0.241098  |    0.153191     |   1\n",
      "       5326 |   0.199272  |    0.033271     |   0\n",
      "       5327 |   0.087225  |    0.072683     |   2\n",
      "       5328 |   0.091349  |    0.041166     |   2\n",
      "       5329 |   0.261056  |    0.047431     |   0\n",
      "       5330 |   0.320884  |    0.142134     |   1\n",
      "       5331 |   0.165989  |    0.203481     |   1\n",
      "       5332 |   0.226262  |    0.005519     |   0\n",
      "       5333 |   0.246512  |    0.046980     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 5334: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       5334 |   0.241593  |    0.032311     |   0\n",
      "       5335 |   0.220210  |    0.077213     |   0\n",
      "       5336 |   0.265826  |    0.167519     |   1\n",
      "       5337 |   0.084060  |    0.004764     |   2\n",
      "       5338 |   0.185520  |    0.199493     |   1\n",
      "       5339 |   0.174215  |    0.146428     |   1\n",
      "       5340 |   0.059749  |    0.030146     |   2\n",
      "       5341 |   0.306086  |    0.208320     |   1\n",
      "       5342 |   0.190704  |    0.149189     |   1\n",
      "       5343 |   0.062399  |    0.013355     |   2\n",
      "       5344 |   0.236121  |    0.135165     |   1\n",
      "       5345 |   0.083015  |    0.078464     |   2\n",
      "       5346 |   0.230211  |    0.176693     |   1\n",
      "       5347 |   0.165170  |    0.156740     |   1\n",
      "       5348 |   0.272674  |    0.043238     |   0\n",
      "       5349 |   0.183700  |    0.038486     |   0\n",
      "       5350 |   0.204346  |    0.078682     |   0\n",
      "       5351 |   0.249597  |    0.024440     |   0\n",
      "       5352 |   0.258058  |    0.075564     |   0\n",
      "       5353 |   0.291339  |    0.154687     |   1\n",
      "       5354 |   0.229742  |    0.018497     |   0\n",
      "       5355 |   0.038594  |    0.081722     |   2\n",
      "       5356 |   0.069574  |    0.014182     |   2\n",
      "       5357 |   0.077560  |    0.083706     |   2\n",
      "       5358 |   0.261595  |    0.036936     |   0\n",
      "       5359 |   0.074115  |    0.044373     |   2\n",
      "       5360 |   0.214741  |    0.195661     |   1\n",
      "       5361 |   0.080673  |    0.004198     |   2\n",
      "       5362 |   0.036891  |    0.045487     |   2\n",
      "       5363 |   0.000171  |    0.040202     |   2\n",
      "       5364 |   0.222558  |    0.075755     |   0\n",
      "       5365 |   0.184173  |    0.013163     |   0\n",
      "       5366 |   0.195066  |    0.077813     |   0\n",
      "       5367 |   0.244504  |    0.024522     |   0\n",
      "       5368 |   0.190219  |    0.078814     |   0\n",
      "       5369 |   0.232413  |    0.153522     |   1\n",
      "       5370 |   0.252146  |    0.146929     |   1\n",
      "       5371 |   0.008255  |    0.049166     |   2\n",
      "       5372 |   0.271911  |    0.058418     |   0\n",
      "       5373 |   0.223599  |    0.208151     |   1\n",
      "       5374 |   0.196138  |    0.139914     |   1\n",
      "       5375 |   0.133008  |    0.010856     |   2\n",
      "       5376 |   0.227783  |    0.197151     |   1\n",
      "       5377 |   0.057681  |    0.024301     |   2\n",
      "       5378 |   0.248467  |    0.075500     |   0\n",
      "       5379 |   0.257638  |    0.048891     |   0\n",
      "       5380 |   0.285755  |    0.140630     |   1\n",
      "       5381 |   0.259458  |    0.194467     |   1\n",
      "       5382 |   0.084674  |    0.023156     |   2\n",
      "       5383 |   0.200336  |    0.197740     |   1\n",
      "       5384 |   0.225093  |    0.012160     |   0\n",
      "       5385 |   0.066289  |    0.055485     |   2\n",
      "       5386 |   0.274529  |    0.154364     |   1\n",
      "       5387 |   0.247634  |    0.050102     |   0\n",
      "       5388 |   0.183544  |    0.201788     |   1\n",
      "       5389 |   0.244981  |    0.008031     |   0\n",
      "       5390 |   0.031379  |    0.036478     |   2\n",
      "       5391 |   0.213614  |    0.203987     |   1\n",
      "       5392 |   0.229622  |    0.142798     |   1\n",
      "       5393 |   0.183290  |    0.007965     |   0\n",
      "       5394 |   0.272960  |    0.076044     |   0\n",
      "       5395 |   0.240010  |    0.048989     |   0\n",
      "       5396 |   0.069338  |    0.040817     |   2\n",
      "       5397 |   0.234857  |    0.072064     |   0\n",
      "       5398 |   0.258567  |    0.040519     |   0\n",
      "       5399 |   0.258964  |    0.051012     |   0\n",
      "       5400 |   0.234876  |    0.039957     |   0\n",
      "       5401 |   0.251412  |    0.192068     |   1\n",
      "       5402 |   0.048462  |    0.005138     |   2\n",
      "       5403 |   0.180955  |    0.078854     |   0\n",
      "       5404 |   0.255735  |    0.153381     |   1\n",
      "       5405 |   0.253651  |    0.143108     |   1\n",
      "       5406 |   0.299763  |    0.187268     |   1\n",
      "       5407 |   0.270564  |    0.153158     |   1\n",
      "       5408 |   0.000164  |    0.007755     |   2\n",
      "       5409 |   0.000168  |    0.050966     |   2\n",
      "       5410 |   0.000192  |    0.020362     |   2\n",
      "       5411 |   0.240718  |    0.219278     |   1\n",
      "       5412 |   0.247476  |    0.026482     |   0\n",
      "       5413 |   0.000184  |    0.081873     |   2\n",
      "       5414 |   0.208697  |    0.026483     |   0\n",
      "       5415 |   0.173916  |    0.054502     |   0\n",
      "       5416 |   0.223055  |    0.042678     |   0\n",
      "       5417 |   0.229260  |    0.074641     |   0\n",
      "       5418 |   0.216924  |    0.028838     |   0\n",
      "       5419 |   0.242572  |    0.070090     |   0\n",
      "       5420 |   0.149247  |    0.029210     |   0\n",
      "       5421 |   0.248048  |    0.052691     |   0\n",
      "       5422 |   0.166168  |    0.029898     |   0\n",
      "       5423 |   0.307253  |    0.183222     |   1\n",
      "       5424 |   0.000174  |    0.020695     |   2\n",
      "       5425 |   0.250871  |    0.203764     |   1\n",
      "       5426 |   0.294337  |    0.151626     |   1\n",
      "       5427 |   0.304262  |    0.157135     |   1\n",
      "       5428 |   0.272278  |    0.194532     |   1\n",
      "       5429 |   0.231592  |    0.005272     |   0\n",
      "       5430 |   0.291954  |    0.130141     |   1\n",
      "       5431 |   0.228357  |    0.040439     |   0\n",
      "       5432 |   0.225127  |    0.070551     |   0\n",
      "       5433 |   0.289320  |    0.135868     |   1\n",
      "       5434 |   0.180535  |    0.047433     |   0\n",
      "       5435 |   0.259837  |    0.147971     |   1\n",
      "       5436 |   0.212781  |    0.043205     |   0\n",
      "       5437 |   0.263324  |    0.133595     |   1\n",
      "       5438 |   0.000192  |    0.081251     |   2\n",
      "       5439 |   0.209232  |    0.166665     |   1\n",
      "       5440 |   0.292725  |    0.177136     |   1\n",
      "       5441 |   0.082962  |    0.006821     |   2\n",
      "       5442 |   0.091443  |    0.075455     |   2\n",
      "       5443 |   0.308192  |    0.138906     |   1\n",
      "       5444 |   0.229897  |    0.014795     |   0\n",
      "       5445 |   0.206307  |    0.074116     |   0\n",
      "       5446 |   0.242745  |    0.016789     |   0\n",
      "       5447 |   0.204166  |    0.071397     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 5449: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       5448 |   0.181533  |    0.043226     |   0\n",
      "       5449 |   0.212386  |    0.204147     |   1\n",
      "       5450 |   0.311953  |    0.133612     |   1\n",
      "       5451 |   0.197199  |    0.011750     |   0\n",
      "       5452 |   0.085113  |    0.079954     |   2\n",
      "       5453 |   0.058847  |    0.018142     |   2\n",
      "       5454 |   0.064364  |    0.082677     |   2\n",
      "       5455 |   0.203038  |    0.009076     |   0\n",
      "       5456 |   0.274990  |    0.181078     |   1\n",
      "       5457 |   0.257026  |    0.017789     |   0\n",
      "       5458 |   0.083061  |    0.074666     |   2\n",
      "       5459 |   0.038410  |    0.028322     |   2\n",
      "       5460 |   0.293538  |    0.191954     |   1\n",
      "       5461 |   0.240208  |    0.153111     |   1\n",
      "       5462 |   0.068706  |    0.007154     |   2\n",
      "       5463 |   0.230368  |    0.073266     |   0\n",
      "       5464 |   0.196182  |    0.029785     |   0\n",
      "       5465 |   0.235320  |    0.054017     |   0\n",
      "       5466 |   0.077056  |    0.049339     |   2\n",
      "       5467 |   0.075715  |    0.076372     |   2\n",
      "       5468 |   0.188783  |    0.031499     |   0\n",
      "       5469 |   0.255628  |    0.206830     |   1\n",
      "       5470 |   0.194583  |    0.155573     |   1\n",
      "       5471 |   0.215028  |    0.042737     |   0\n",
      "       5472 |   0.274745  |    0.045189     |   0\n",
      "       5473 |   0.074213  |    0.046416     |   2\n",
      "       5474 |   0.266190  |    0.047926     |   0\n",
      "       5475 |   0.033528  |    0.044123     |   2\n",
      "       5476 |   0.000170  |    0.053533     |   2\n",
      "       5477 |   0.241271  |    0.050039     |   0\n",
      "       5478 |   0.206932  |    0.207642     |   1\n",
      "       5479 |   0.295360  |    0.132965     |   1\n",
      "       5480 |   0.193822  |    0.025158     |   0\n",
      "       5481 |   0.197948  |    0.054997     |   0\n",
      "       5482 |   0.169043  |    0.217954     |   1\n",
      "       5483 |   0.007602  |    0.004319     |   2\n",
      "       5484 |   0.127463  |    0.072145     |   2\n",
      "       5485 |   0.208667  |    0.044542     |   0\n",
      "       5486 |   0.058004  |    0.023272     |   2\n",
      "       5487 |   0.287960  |    0.226113     |   1\n",
      "       5488 |   0.282962  |    0.140515     |   1\n",
      "       5489 |   0.241214  |    0.155587     |   1\n",
      "       5490 |   0.255134  |    0.170704     |   1\n",
      "       5491 |   0.079039  |    0.039688     |   2\n",
      "       5492 |   0.216284  |    0.045544     |   0\n",
      "       5493 |   0.232121  |    0.051570     |   0\n",
      "       5494 |   0.229926  |    0.163554     |   1\n",
      "       5495 |   0.295746  |    0.143641     |   1\n",
      "       5496 |   0.237770  |    0.043319     |   0\n",
      "       5497 |   0.061270  |    0.042704     |   2\n",
      "       5498 |   0.030990  |    0.045223     |   2\n",
      "       5499 |   0.062730  |    0.052403     |   2\n",
      "       5500 |   0.247863  |    0.160471     |   1\n",
      "       5501 |   0.080729  |    0.087992     |   2\n",
      "       5502 |   0.058505  |    0.028342     |   2\n",
      "       5503 |   0.061707  |    0.086331     |   2\n",
      "       5504 |   0.237273  |    0.156454     |   1\n",
      "       5505 |   0.082164  |    0.032626     |   2\n",
      "       5506 |   0.224771  |    0.154334     |   1\n",
      "       5507 |   0.227972  |    0.045077     |   0\n",
      "       5508 |   0.036259  |    0.047650     |   2\n",
      "       5509 |   0.246016  |    0.201564     |   1\n",
      "       5510 |   0.246860  |    0.152461     |   1\n",
      "       5511 |   0.197316  |    0.045312     |   0\n",
      "       5512 |   0.239127  |    0.182755     |   1\n",
      "       5513 |   0.292522  |    0.145013     |   1\n",
      "       5514 |   0.067871  |    0.016913     |   2\n",
      "       5515 |   0.240087  |    0.202242     |   1\n",
      "       5516 |   0.257588  |    0.008675     |   0\n",
      "       5517 |   0.220752  |    0.076300     |   0\n",
      "       5518 |   0.072747  |    0.017125     |   2\n",
      "       5519 |   0.248020  |    0.078028     |   0\n",
      "       5520 |   0.250772  |    0.159739     |   1\n",
      "       5521 |   0.076701  |    0.013444     |   2\n",
      "       5522 |   0.175379  |    0.079700     |   0\n",
      "       5523 |   0.240746  |    0.015073     |   0\n",
      "       5524 |   0.241921  |    0.203089     |   1\n",
      "       5525 |   0.072656  |    0.044827     |   2\n",
      "       5526 |   0.234905  |    0.053068     |   0\n",
      "       5527 |   0.221152  |    0.149310     |   1\n",
      "       5528 |   0.034289  |    0.048294     |   2\n",
      "       5529 |   0.000168  |    0.049192     |   2\n",
      "       5530 |   0.268177  |    0.155706     |   1\n",
      "       5531 |   0.186889  |    0.027158     |   0\n",
      "       5532 |   0.006971  |    0.071549     |   2\n",
      "       5533 |   0.231117  |    0.021950     |   0\n",
      "       5534 |   0.223178  |    0.070858     |   0\n",
      "       5535 |   0.313753  |    0.155017     |   1\n",
      "       5536 |   0.124967  |    0.008494     |   2\n",
      "       5537 |   0.227828  |    0.221217     |   1\n",
      "       5538 |   0.053986  |    0.010798     |   2\n",
      "       5539 |   0.222475  |    0.205460     |   1\n",
      "       5540 |   0.077121  |    0.007012     |   2\n",
      "       5541 |   0.062524  |    0.082155     |   2\n",
      "       5542 |   0.028780  |    0.031514     |   2\n",
      "       5543 |   0.246617  |    0.178700     |   1\n",
      "       5544 |   0.231876  |    0.158902     |   1\n",
      "       5545 |   0.062429  |    0.045015     |   2\n",
      "       5546 |   0.189403  |    0.058008     |   0\n",
      "       5547 |   0.230027  |    0.049626     |   0\n",
      "       5548 |   0.277552  |    0.049565     |   0\n",
      "       5549 |   0.239373  |    0.215931     |   1\n",
      "       5550 |   0.283346  |    0.098148     |   1\n",
      "       5551 |   0.050179  |    0.055032     |   2\n",
      "       5552 |   0.193939  |    0.031501     |   0\n",
      "       5553 |   0.216509  |    0.046185     |   0\n",
      "       5554 |   0.298852  |    0.214920     |   1\n",
      "       5555 |   0.191096  |    0.006335     |   0\n",
      "       5556 |   0.223181  |    0.153936     |   1\n",
      "       5557 |   0.208314  |    0.188297     |   1\n",
      "       5558 |   0.260837  |    0.149603     |   1\n",
      "       5559 |   0.211057  |    0.026150     |   0\n",
      "       5560 |   0.202967  |    0.202122     |   1\n",
      "       5561 |   0.247277  |    0.029773     |   0\n",
      "       5562 |   0.274773  |    0.213388     |   1\n",
      "       5563 |   0.184004  |    0.008027     |   0\n",
      "       5564 |   0.000164  |    0.040309     |   2\n",
      "       5565 |   0.289058  |    0.161504     |   1\n",
      "       5566 |   0.000167  |    0.017436     |   2\n",
      "       5567 |   0.000183  |    0.043613     |   2\n",
      "       5568 |   0.241917  |    0.080978     |   0\n",
      "       5569 |   0.000178  |    0.022124     |   2\n",
      "       5570 |   0.218308  |    0.074113     |   0\n",
      "       5571 |   0.271903  |    0.148085     |   1\n",
      "       5572 |   0.180220  |    0.038721     |   0\n",
      "       5573 |   0.178127  |    0.050134     |   0\n",
      "       5574 |   0.278534  |    0.153023     |   1\n",
      "       5575 |   0.000170  |    0.048333     |   2\n",
      "       5576 |   0.177915  |    0.156508     |   1\n",
      "       5577 |   0.296463  |    0.148092     |   1\n",
      "       5578 |   0.000186  |    0.045183     |   2\n",
      "       5579 |   0.211681  |    0.075383     |   0\n",
      "       5580 |   0.228433  |    0.014212     |   0\n",
      "       5581 |   0.183416  |    0.049971     |   0\n",
      "       5582 |   0.273448  |    0.193006     |   1\n",
      "       5583 |   0.082838  |    0.046369     |   2\n",
      "       5584 |   0.090945  |    0.042508     |   2\n",
      "       5585 |   0.208923  |    0.058267     |   0\n",
      "       5586 |   0.240330  |    0.139916     |   1\n",
      "       5587 |   0.266643  |    0.080427     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 5588: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       5588 |   0.080350  |    0.008884     |   2\n",
      "       5589 |   0.257928  |    0.091779     |   0\n",
      "       5590 |   0.262508  |    0.192098     |   1\n",
      "       5591 |   0.222204  |    0.010048     |   0\n",
      "       5592 |   0.059107  |    0.042798     |   2\n",
      "       5593 |   0.059833  |    0.040036     |   2\n",
      "       5594 |   0.168287  |    0.052144     |   0\n",
      "       5595 |   0.082455  |    0.046652     |   2\n",
      "       5596 |   0.235355  |    0.205954     |   1\n",
      "       5597 |   0.216082  |    0.157134     |   1\n",
      "       5598 |   0.236092  |    0.147719     |   1\n",
      "       5599 |   0.213374  |    0.047654     |   0\n",
      "       5600 |   0.223843  |    0.141840     |   1\n",
      "       5601 |   0.274616  |    0.141086     |   1\n",
      "       5602 |   0.212178  |    0.043852     |   0\n",
      "       5603 |   0.037455  |    0.047338     |   2\n",
      "       5604 |   0.068244  |    0.042251     |   2\n",
      "       5605 |   0.185609  |    0.071793     |   0\n",
      "       5606 |   0.074285  |    0.021610     |   2\n",
      "       5607 |   0.074599  |    0.045294     |   2\n",
      "       5608 |   0.217802  |    0.081116     |   0\n",
      "       5609 |   0.075986  |    0.017613     |   2\n",
      "       5610 |   0.035315  |    0.081617     |   2\n",
      "       5611 |   0.000166  |    0.012567     |   2\n",
      "       5612 |   0.263378  |    0.092239     |   0\n",
      "       5613 |   0.267565  |    0.165113     |   1\n",
      "       5614 |   0.189483  |    0.115463     |   1\n",
      "       5615 |   0.220234  |    0.051465     |   0\n",
      "       5616 |   0.007616  |    0.027266     |   2\n",
      "       5617 |   0.258000  |    0.080827     |   0\n",
      "       5618 |   0.276189  |    0.140259     |   1\n",
      "       5619 |   0.126299  |    0.046657     |   2\n",
      "       5620 |   0.241051  |    0.140061     |   1\n",
      "       5621 |   0.234350  |    0.019753     |   0\n",
      "       5622 |   0.205900  |    0.072023     |   0\n",
      "       5623 |   0.214521  |    0.038166     |   0\n",
      "       5624 |   0.245866  |    0.054825     |   0\n",
      "       5625 |   0.181428  |    0.170032     |   1\n",
      "       5626 |   0.183863  |    0.155065     |   1\n",
      "       5627 |   0.242468  |    0.170287     |   1\n",
      "       5628 |   0.205128  |    0.210294     |   1\n",
      "       5629 |   0.176687  |    0.003420     |   0\n",
      "       5630 |   0.267482  |    0.045703     |   0\n",
      "       5631 |   0.223103  |    0.048954     |   0\n",
      "       5632 |   0.229932  |    0.079762     |   0\n",
      "       5633 |   0.282768  |    0.147260     |   1\n",
      "       5634 |   0.250980  |    0.149314     |   1\n",
      "       5635 |   0.264967  |    0.040357     |   0\n",
      "       5636 |   0.165543  |    0.045468     |   0\n",
      "       5637 |   0.056569  |    0.044141     |   2\n",
      "       5638 |   0.199309  |    0.047691     |   0\n",
      "       5639 |   0.084848  |    0.050461     |   2\n",
      "       5640 |   0.066794  |    0.050543     |   2\n",
      "       5641 |   0.242105  |    0.059072     |   0\n",
      "       5642 |   0.210549  |    0.191663     |   1\n",
      "       5643 |   0.031355  |    0.015251     |   2\n",
      "       5644 |   0.309721  |    0.128436     |   1\n",
      "       5645 |   0.212357  |    0.024377     |   0\n",
      "       5646 |   0.156096  |    0.047111     |   0\n",
      "       5647 |   0.173894  |    0.048727     |   0\n",
      "       5648 |   0.296531  |    0.212801     |   1\n",
      "       5649 |   0.167191  |    0.008938     |   0\n",
      "       5650 |   0.070796  |    0.044456     |   2\n",
      "       5651 |   0.047921  |    0.041285     |   2\n",
      "       5652 |   0.288234  |    0.195544     |   1\n",
      "       5653 |   0.000163  |    0.006540     |   2\n",
      "       5654 |   0.235281  |    0.142633     |   1\n",
      "       5655 |   0.000166  |    0.081949     |   2\n",
      "       5656 |   0.219731  |    0.098374     |   1\n",
      "       5657 |   0.000189  |    0.044017     |   2\n",
      "       5658 |   0.206291  |    0.202743     |   1\n",
      "       5659 |   0.216987  |    0.026015     |   0\n",
      "       5660 |   0.000184  |    0.077675     |   2\n",
      "       5661 |   0.000171  |    0.023282     |   2\n",
      "       5662 |   0.000185  |    0.043005     |   2\n",
      "       5663 |   0.294294  |    0.161095     |   1\n",
      "       5664 |   0.216504  |    0.158351     |   1\n",
      "       5665 |   0.081895  |    0.043927     |   2\n",
      "       5666 |   0.242581  |    0.075660     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 5668: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       5667 |   0.088851  |    0.022445     |   2\n",
      "       5668 |   0.085585  |    0.077243     |   2\n",
      "       5669 |   0.244535  |    0.026885     |   0\n",
      "       5670 |   0.229164  |    0.062592     |   0\n",
      "       5671 |   0.060083  |    0.036740     |   2\n",
      "       5672 |   0.210833  |    0.198332     |   1\n",
      "       5673 |   0.061000  |    0.019847     |   2\n",
      "       5674 |   0.083747  |    0.075783     |   2\n",
      "       5675 |   0.244546  |    0.149604     |   1\n",
      "       5676 |   0.255211  |    0.027877     |   0\n",
      "       5677 |   0.219495  |    0.213507     |   1\n",
      "       5678 |   0.037754  |    0.018836     |   2\n",
      "       5679 |   0.067782  |    0.045224     |   2\n",
      "       5680 |   0.182532  |    0.044996     |   0\n",
      "       5681 |   0.211584  |    0.047481     |   0\n",
      "       5682 |   0.206327  |    0.044963     |   0\n",
      "       5683 |   0.305664  |    0.152560     |   1\n",
      "       5684 |   0.211982  |    0.146203     |   1\n",
      "       5685 |   0.199453  |    0.073610     |   0\n",
      "       5686 |   0.073371  |    0.035822     |   2\n",
      "       5687 |   0.258893  |    0.184519     |   1\n",
      "       5688 |   0.219843  |    0.017205     |   0\n",
      "       5689 |   0.076738  |    0.082922     |   2\n",
      "       5690 |   0.074901  |    0.024249     |   2\n",
      "       5691 |   0.219451  |    0.058878     |   0\n",
      "       5692 |   0.252155  |    0.242458     |   1\n",
      "       5693 |   0.034678  |    0.003372     |   2\n",
      "       5694 |   0.239315  |    0.162971     |   1\n",
      "       5695 |   0.231082  |    0.136588     |   1\n",
      "       5696 |   0.000165  |    0.073852     |   2\n",
      "       5697 |   0.259639  |    0.026600     |   0\n",
      "       5698 |   0.299706  |    0.210622     |   1\n",
      "       5699 |   0.007718  |    0.003047     |   2\n",
      "       5700 |   0.126316  |    0.079404     |   2\n",
      "       5701 |   0.258189  |    0.051001     |   0\n",
      "       5702 |   0.174105  |    0.181840     |   1\n",
      "       5703 |   0.054984  |    0.022214     |   2\n",
      "       5704 |   0.222032  |    0.081729     |   0\n",
      "       5705 |   0.076863  |    0.039954     |   2\n",
      "       5706 |   0.199908  |    0.184751     |   1\n",
      "       5707 |   0.062466  |    0.028275     |   2\n",
      "       5708 |   0.029279  |    0.050436     |   2\n",
      "       5709 |   0.063736  |    0.045852     |   2\n",
      "       5710 |   0.048199  |    0.073716     |   2\n",
      "       5711 |   0.243107  |    0.140380     |   1\n",
      "       5712 |   0.000162  |    0.039399     |   2\n",
      "       5713 |   0.000165  |    0.050716     |   2\n",
      "       5714 |   0.000182  |    0.039446     |   2\n",
      "       5715 |   0.000175  |    0.078404     |   2\n",
      "       5716 |   0.269530  |    0.025241     |   0\n",
      "       5717 |   0.261135  |    0.073430     |   0\n",
      "       5718 |   0.000167  |    0.014030     |   2\n",
      "       5719 |   0.231690  |    0.224040     |   1\n",
      "       5720 |   0.243966  |    0.016395     |   0\n",
      "       5721 |   0.267400  |    0.074745     |   0\n",
      "       5722 |   0.217567  |    0.033158     |   0\n",
      "       5723 |   0.294510  |    0.214381     |   1\n",
      "       5724 |   0.197240  |    0.030556     |   0\n",
      "       5725 |   0.000181  |    0.044286     |   2\n",
      "       5726 |   0.192222  |    0.041989     |   0\n",
      "       5727 |   0.149765  |    0.212045     |   1\n",
      "       5728 |   0.165962  |    0.003251     |   0\n",
      "       5729 |   0.079006  |    0.025524     |   2\n",
      "       5730 |   0.253104  |    0.044692     |   0\n",
      "       5731 |   0.210329  |    0.040394     |   0\n",
      "       5732 |   0.242344  |    0.043155     |   0\n",
      "       5733 |   0.089683  |    0.053618     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 5734: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       5734 |   0.251402  |    0.150601     |   1\n",
      "       5735 |   0.219131  |    0.015479     |   0\n",
      "       5736 |   0.243113  |    0.073940     |   0\n",
      "       5737 |   0.258855  |    0.140977     |   1\n",
      "       5738 |   0.182427  |    0.172700     |   1\n",
      "       5739 |   0.222564  |    0.077897     |   0\n",
      "       5740 |   0.291303  |    0.129854     |   1\n",
      "       5741 |   0.257047  |    0.047064     |   0\n",
      "       5742 |   0.079566  |    0.027837     |   2\n",
      "       5743 |   0.058072  |    0.042336     |   2\n",
      "       5744 |   0.159850  |    0.083917     |   0\n",
      "       5745 |   0.288109  |    0.136209     |   1\n",
      "       5746 |   0.254299  |    0.178656     |   1\n",
      "       5747 |   0.220393  |    0.139956     |   1\n",
      "       5748 |   0.186034  |    0.019660     |   0\n",
      "       5749 |   0.257844  |    0.197012     |   1\n",
      "       5750 |   0.184657  |    0.006323     |   0\n",
      "       5751 |   0.218583  |    0.039677     |   0\n",
      "       5752 |   0.059427  |    0.056127     |   2\n",
      "       5753 |   0.248237  |    0.148520     |   1\n",
      "       5754 |   0.191969  |    0.211881     |   1\n",
      "       5755 |   0.085466  |    0.006564     |   2\n",
      "       5756 |   0.209147  |    0.085938     |   0\n",
      "       5757 |   0.299986  |    0.140307     |   1\n",
      "       5758 |   0.199423  |    0.012819     |   0\n",
      "       5759 |   0.038326  |    0.073566     |   2\n",
      "       5760 |   0.066594  |    0.017464     |   2\n",
      "       5761 |   0.241959  |    0.204403     |   1\n",
      "       5762 |   0.210127  |    0.017149     |   0\n",
      "       5763 |   0.269001  |    0.211843     |   1\n",
      "       5764 |   0.289305  |    0.156247     |   1\n",
      "       5765 |   0.228439  |    0.017162     |   0\n",
      "       5766 |   0.077322  |    0.075224     |   2\n",
      "       5767 |   0.074288  |    0.021877     |   2\n",
      "       5768 |   0.201324  |    0.218206     |   1\n",
      "       5769 |   0.232426  |    0.003657     |   0\n",
      "       5770 |   0.218553  |    0.151673     |   1\n",
      "       5771 |   0.155254  |    0.048944     |   0\n",
      "       5772 |   0.071351  |    0.072654     |   2\n",
      "       5773 |   0.198917  |    0.016907     |   0\n",
      "       5774 |   0.179392  |    0.047757     |   0\n",
      "       5775 |   0.032199  |    0.074414     |   2\n",
      "       5776 |   0.222942  |    0.027602     |   0\n",
      "       5777 |   0.251420  |    0.213587     |   1\n",
      "       5778 |   0.312606  |    0.009828     |   0\n",
      "       5779 |   0.208028  |    0.075726     |   0\n",
      "       5780 |   0.255620  |    0.027795     |   0\n",
      "       5781 |   0.000164  |    0.093653     |   2\n",
      "       5782 |   0.360371  |    0.147385     |   1\n",
      "       5783 |   0.216752  |    0.019600     |   0\n",
      "       5784 |   0.316228  |    0.220936     |   1\n",
      "       5785 |   0.279694  |    0.151230     |   1\n",
      "       5786 |   0.007219  |    0.008550     |   2\n",
      "       5787 |   0.226581  |    0.077606     |   0\n",
      "       5788 |   0.128646  |    0.006401     |   2\n",
      "       5789 |   0.053331  |    0.088662     |   2\n",
      "       5790 |   0.196455  |    0.027898     |   0\n",
      "       5791 |   0.296958  |    0.200794     |   1\n",
      "       5792 |   0.175657  |    0.139073     |   1\n",
      "       5793 |   0.236149  |    0.048586     |   0\n",
      "       5794 |   0.248202  |    0.139428     |   1\n",
      "       5795 |   0.305039  |    0.111424     |   1\n",
      "       5796 |   0.081431  |    0.046661     |   2\n",
      "       5797 |   0.062375  |    0.042357     |   2\n",
      "       5798 |   0.229425  |    0.207938     |   1\n",
      "       5799 |   0.028740  |    0.006272     |   2\n",
      "       5800 |   0.208386  |    0.086693     |   0\n",
      "       5801 |   0.064004  |    0.023738     |   2\n",
      "       5802 |   0.047545  |    0.077760     |   2\n",
      "       5803 |   0.155591  |    0.216808     |   1\n",
      "       5804 |   0.000160  |    0.005406     |   2\n",
      "       5805 |   0.240031  |    0.076002     |   0\n",
      "       5806 |   0.000162  |    0.030997     |   2\n",
      "       5807 |   0.188923  |    0.057126     |   0\n",
      "       5808 |   0.180400  |    0.061997     |   0\n",
      "       5809 |   0.208819  |    0.202506     |   1\n",
      "       5810 |   0.223125  |    0.133105     |   1\n",
      "       5811 |   0.250806  |    0.049690     |   0\n",
      "       5812 |   0.000180  |    0.045362     |   2\n",
      "       5813 |   0.000169  |    0.081832     |   2\n",
      "       5814 |   0.231915  |    0.140956     |   1\n",
      "       5815 |   0.194293  |    0.195691     |   1\n",
      "       5816 |   0.215204  |    0.147997     |   1\n",
      "       5817 |   0.000164  |    0.004307     |   2\n",
      "       5818 |   0.000179  |    0.042428     |   2\n",
      "       5819 |   0.241536  |    0.087044     |   0\n",
      "       5820 |   0.154961  |    0.150221     |   1\n",
      "       5821 |   0.186062  |    0.082721     |   0\n",
      "       5822 |   0.260837  |    0.161555     |   1\n",
      "       5823 |   0.316142  |    0.169557     |   1\n",
      "       5824 |   0.296741  |    0.102482     |   1\n",
      "       5825 |   0.271449  |    0.198381     |   1\n",
      "       5826 |   0.229990  |    0.024226     |   0\n",
      "       5827 |   0.075310  |    0.046600     |   2\n",
      "       5828 |   0.219294  |    0.047913     |   0\n",
      "       5829 |   0.088633  |    0.053677     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 5830: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       5830 |   0.196944  |    0.029590     |   0\n",
      "       5831 |   0.215099  |    0.042855     |   0\n",
      "       5832 |   0.076543  |    0.038520     |   2\n",
      "       5833 |   0.270650  |    0.208833     |   1\n",
      "       5834 |   0.330330  |    0.150342     |   1\n",
      "       5835 |   0.290655  |    0.138822     |   1\n",
      "       5836 |   0.055835  |    0.007356     |   2\n",
      "       5837 |   0.204290  |    0.148775     |   1\n",
      "       5838 |   0.187451  |    0.145384     |   1\n",
      "       5839 |   0.231772  |    0.012738     |   0\n",
      "       5840 |   0.172093  |    0.078581     |   0\n",
      "       5841 |   0.058725  |    0.013494     |   2\n",
      "       5842 |   0.081117  |    0.070566     |   2\n",
      "       5843 |   0.037978  |    0.054117     |   2\n",
      "       5844 |   0.067956  |    0.040957     |   2\n",
      "       5845 |   0.222165  |    0.200734     |   1\n",
      "       5846 |   0.265870  |    0.026324     |   0\n",
      "       5847 |   0.191379  |    0.049433     |   0\n",
      "       5848 |   0.227055  |    0.214256     |   1\n",
      "       5849 |   0.209460  |    0.008061     |   0\n",
      "       5850 |   0.075474  |    0.071145     |   2\n",
      "       5851 |   0.075307  |    0.039991     |   2\n",
      "       5852 |   0.076349  |    0.046739     |   2\n",
      "       5853 |   0.033398  |    0.050733     |   2\n",
      "       5854 |   0.227633  |    0.031354     |   0\n",
      "       5855 |   0.185255  |    0.151031     |   1\n",
      "       5856 |   0.320890  |    0.150382     |   1\n",
      "       5857 |   0.282707  |    0.145695     |   1\n",
      "       5858 |   0.000163  |    0.031458     |   2\n",
      "       5859 |   0.246274  |    0.213909     |   1\n",
      "       5860 |   0.241328  |    0.146481     |   1\n",
      "       5861 |   0.191173  |    0.147591     |   1\n",
      "       5862 |   0.278455  |    0.147221     |   1\n",
      "       5863 |   0.247053  |    0.014456     |   0\n",
      "       5864 |   0.174233  |    0.199759     |   1\n",
      "       5865 |   0.282796  |    0.158374     |   1\n",
      "       5866 |   0.266749  |    0.145505     |   1\n",
      "       5867 |   0.007677  |    0.051245     |   2\n",
      "       5868 |   0.229427  |    0.065657     |   0\n",
      "       5869 |   0.250480  |    0.160160     |   1\n",
      "       5870 |   0.288161  |    0.147485     |   1\n",
      "       5871 |   0.248443  |    0.102259     |   1\n",
      "       5872 |   0.238603  |    0.143025     |   1\n",
      "       5873 |   0.125363  |    0.048690     |   2\n",
      "       5874 |   0.264812  |    0.138924     |   1\n",
      "       5875 |   0.228313  |    0.052447     |   0\n",
      "       5876 |   0.274221  |    0.180236     |   1\n",
      "       5877 |   0.053493  |    0.030981     |   2\n",
      "       5878 |   0.214448  |    0.075640     |   0\n",
      "       5879 |   0.220334  |    0.161236     |   1\n",
      "       5880 |   0.212214  |    0.013380     |   0\n",
      "       5881 |   0.076316  |    0.090867     |   2\n",
      "       5882 |   0.399737  |    0.142502     |   1\n",
      "       5883 |   0.296183  |    0.024435     |   0\n",
      "       5884 |   0.273230  |    0.045396     |   0\n",
      "       5885 |   0.227167  |    0.047105     |   0\n",
      "       5886 |   0.261724  |    0.177595     |   1\n",
      "       5887 |   0.320388  |    0.152787     |   1\n",
      "       5888 |   0.230649  |    0.179019     |   1\n",
      "       5889 |   0.236185  |    0.007136     |   0\n",
      "       5890 |   0.066596  |    0.047451     |   2\n",
      "       5891 |   0.212354  |    0.140157     |   1\n",
      "       5892 |   0.027732  |    0.048959     |   2\n",
      "       5893 |   0.275008  |    0.169383     |   1\n",
      "       5894 |   0.238553  |    0.175401     |   1\n",
      "       5895 |   0.239959  |    0.145249     |   1\n",
      "       5896 |   0.249677  |    0.047646     |   0\n",
      "       5897 |   0.244940  |    0.043183     |   0\n",
      "       5898 |   0.317827  |    0.141309     |   1\n",
      "       5899 |   0.061261  |    0.016675     |   2\n",
      "       5900 |   0.178753  |    0.075323     |   0\n",
      "       5901 |   0.281940  |    0.029423     |   0\n",
      "       5902 |   0.202618  |    0.210081     |   1\n",
      "       5903 |   0.046048  |    0.006132     |   2\n",
      "       5904 |   0.222328  |    0.051832     |   0\n",
      "       5905 |   0.229972  |    0.046356     |   0\n",
      "       5906 |   0.317783  |    0.200426     |   1\n",
      "       5907 |   0.000160  |    0.005621     |   2\n",
      "       5908 |   0.230053  |    0.203120     |   1\n",
      "       5909 |   0.000163  |    0.029582     |   2\n",
      "       5910 |   0.194702  |    0.055484     |   0\n",
      "       5911 |   0.000180  |    0.039316     |   2\n",
      "       5912 |   0.201136  |    0.039499     |   0\n",
      "       5913 |   0.000172  |    0.075912     |   2\n",
      "       5914 |   0.000163  |    0.021600     |   2\n",
      "       5915 |   0.000173  |    0.059277     |   2\n",
      "       5916 |   0.076007  |    0.028178     |   2\n",
      "       5917 |   0.271800  |    0.189881     |   1\n",
      "       5918 |   0.144451  |    0.062050     |   0\n",
      "       5919 |   0.217336  |    0.156756     |   1\n",
      "       5920 |   0.087824  |    0.073428     |   2\n",
      "       5921 |   0.230084  |    0.156758     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 5922: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       5922 |   0.080287  |    0.012527     |   2\n",
      "       5923 |   0.055557  |    0.077346     |   2\n",
      "       5924 |   0.216899  |    0.038736     |   0\n",
      "       5925 |   0.278965  |    0.151172     |   1\n",
      "       5926 |   0.060158  |    0.022152     |   2\n",
      "       5927 |   0.079401  |    0.076471     |   2\n",
      "       5928 |   0.181860  |    0.032832     |   0\n",
      "       5929 |   0.277734  |    0.071752     |   0\n",
      "       5930 |   0.038128  |    0.016895     |   2\n",
      "       5931 |   0.069401  |    0.079504     |   2\n",
      "       5932 |   0.193037  |    0.010874     |   0\n",
      "       5933 |   0.073323  |    0.076201     |   2\n",
      "       5934 |   0.235728  |    0.168101     |   1\n",
      "       5935 |   0.073302  |    0.018426     |   2\n",
      "       5936 |   0.266219  |    0.199468     |   1\n",
      "       5937 |   0.273036  |    0.027038     |   0\n",
      "       5938 |   0.264267  |    0.194025     |   1\n",
      "       5939 |   0.162535  |    0.045577     |   0\n",
      "       5940 |   0.184442  |    0.196698     |   1\n",
      "       5941 |   0.069703  |    0.034130     |   2\n",
      "       5942 |   0.261537  |    0.201443     |   1\n",
      "       5943 |   0.209120  |    0.029324     |   0\n",
      "       5944 |   0.032611  |    0.074692     |   2\n",
      "       5945 |   0.197719  |    0.034128     |   0\n",
      "       5946 |   0.231795  |    0.199924     |   1\n",
      "       5947 |   0.000161  |    0.005428     |   2\n",
      "       5948 |   0.272974  |    0.097411     |   0\n",
      "       5949 |   0.257241  |    0.134165     |   1\n",
      "       5950 |   0.007258  |    0.013855     |   2\n",
      "       5951 |   0.126469  |    0.076927     |   2\n",
      "       5952 |   0.249602  |    0.130516     |   1\n",
      "       5953 |   0.054202  |    0.021867     |   2\n",
      "       5954 |   0.080458  |    0.053988     |   2\n",
      "       5955 |   0.254625  |    0.146735     |   1\n",
      "       5956 |   0.161751  |    0.198758     |   1\n",
      "       5957 |   0.307615  |    0.143849     |   1\n",
      "       5958 |   0.218066  |    0.191390     |   1\n",
      "       5959 |   0.258370  |    0.150170     |   1\n",
      "       5960 |   0.175169  |    0.142969     |   1\n",
      "       5961 |   0.064995  |    0.042772     |   2\n",
      "       5962 |   0.263259  |    0.150996     |   1\n",
      "       5963 |   0.227104  |    0.157478     |   1\n",
      "       5964 |   0.028552  |    0.050443     |   2\n",
      "       5965 |   0.244254  |    0.127772     |   1\n",
      "       5966 |   0.174187  |    0.073575     |   0\n",
      "       5967 |   0.060797  |    0.011213     |   2\n",
      "       5968 |   0.046624  |    0.073999     |   2\n",
      "       5969 |   0.188617  |    0.014608     |   0\n",
      "       5970 |   0.000157  |    0.052700     |   2\n",
      "       5971 |   0.242886  |    0.207619     |   1\n",
      "       5972 |   0.000159  |    0.005036     |   2\n",
      "       5973 |   0.250279  |    0.036300     |   0\n",
      "       5974 |   0.000178  |    0.027932     |   2\n",
      "       5975 |   0.000170  |    0.042478     |   2\n",
      "       5976 |   0.210380  |    0.207444     |   1\n",
      "       5977 |   0.163856  |    0.005353     |   0\n",
      "       5978 |   0.209250  |    0.079132     |   0\n",
      "       5979 |   0.216688  |    0.026123     |   0\n",
      "       5980 |   0.000161  |    0.053233     |   2\n",
      "       5981 |   0.178196  |    0.043278     |   0\n",
      "       5982 |   0.000168  |    0.043790     |   2\n",
      "       5983 |   0.074562  |    0.045306     |   2\n",
      "       5984 |   0.204768  |    0.072245     |   0\n",
      "       5985 |   0.088424  |    0.018783     |   2\n",
      "       5986 |   0.257243  |    0.166394     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 5987: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       5987 |   0.081309  |    0.008460     |   2\n",
      "       5988 |   0.243577  |    0.085272     |   0\n",
      "       5989 |   0.057863  |    0.018597     |   2\n",
      "       5990 |   0.213638  |    0.207834     |   1\n",
      "       5991 |   0.198408  |    0.102659     |   1\n",
      "       5992 |   0.200719  |    0.057043     |   0\n",
      "       5993 |   0.060672  |    0.043407     |   2\n",
      "       5994 |   0.078481  |    0.072728     |   2\n",
      "       5995 |   0.231082  |    0.040072     |   0\n",
      "       5996 |   0.211897  |    0.050078     |   0\n",
      "       5997 |   0.037801  |    0.060166     |   2\n",
      "       5998 |   0.215848  |    0.163095     |   1\n",
      "       5999 |   0.209257  |    0.012436     |   0\n",
      "       6000 |   0.285990  |    0.203741     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 6000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 6000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       6001 |   0.303069  |    0.199240     |   1\n",
      "       6002 |   0.212656  |    0.019076     |   0\n",
      "       6003 |   0.191112  |    0.218082     |   1\n",
      "       6004 |   0.077938  |    0.004138     |   2\n",
      "       6005 |   0.057871  |    0.078985     |   2\n",
      "       6006 |   0.252256  |    0.150852     |   1\n",
      "       6007 |   0.257378  |    0.024769     |   0\n",
      "       6008 |   0.201617  |    0.186442     |   1\n",
      "       6009 |   0.216464  |    0.045121     |   0\n",
      "       6010 |   0.217207  |    0.190784     |   1\n",
      "       6011 |   0.277039  |    0.169970     |   1\n",
      "       6012 |   0.059350  |    0.021008     |   2\n",
      "       6013 |   0.247184  |    0.137320     |   1\n",
      "       6014 |   0.276068  |    0.142016     |   1\n",
      "       6015 |   0.173938  |    0.057090     |   0\n",
      "       6016 |   0.305503  |    0.198790     |   1\n",
      "       6017 |   0.205983  |    0.007400     |   0\n",
      "       6018 |   0.276509  |    0.157882     |   1\n",
      "       6019 |   0.215943  |    0.051147     |   0\n",
      "       6020 |   0.239780  |    0.045720     |   0\n",
      "       6021 |   0.075683  |    0.078578     |   2\n",
      "       6022 |   0.038158  |    0.022497     |   2\n",
      "       6023 |   0.067333  |    0.085179     |   2\n",
      "       6024 |   0.267854  |    0.159986     |   1\n",
      "       6025 |   0.279750  |    0.131013     |   1\n",
      "       6026 |   0.070643  |    0.005575     |   2\n",
      "       6027 |   0.070944  |    0.078891     |   2\n",
      "       6028 |   0.073502  |    0.022748     |   2\n",
      "       6029 |   0.269001  |    0.077105     |   0\n",
      "       6030 |   0.246169  |    0.026018     |   0\n",
      "       6031 |   0.231040  |    0.194590     |   1\n",
      "       6032 |   0.214464  |    0.151124     |   1\n",
      "       6033 |   0.242590  |    0.141916     |   1\n",
      "       6034 |   0.247603  |    0.151543     |   1\n",
      "       6035 |   0.031862  |    0.025450     |   2\n",
      "       6036 |   0.242286  |    0.190512     |   1\n",
      "       6037 |   0.000158  |    0.003930     |   2\n",
      "       6038 |   0.199895  |    0.051921     |   0\n",
      "       6039 |   0.242176  |    0.046979     |   0\n",
      "       6040 |   0.225244  |    0.081689     |   0\n",
      "       6041 |   0.007560  |    0.007799     |   2\n",
      "       6042 |   0.214081  |    0.073002     |   0\n",
      "       6043 |   0.196240  |    0.196885     |   1\n",
      "       6044 |   0.185802  |    0.006033     |   0\n",
      "       6045 |   0.189597  |    0.053059     |   0\n",
      "       6046 |   0.197996  |    0.045788     |   0\n",
      "       6047 |   0.223829  |    0.157070     |   1\n",
      "       6048 |   0.199821  |    0.042260     |   0\n",
      "       6049 |   0.261314  |    0.086870     |   0\n",
      "       6050 |   0.169440  |    0.189519     |   1\n",
      "       6051 |   0.323127  |    0.072876     |   1\n",
      "       6052 |   0.125124  |    0.038310     |   2\n",
      "       6053 |   0.219415  |    0.071996     |   0\n",
      "       6054 |   0.053929  |    0.026216     |   2\n",
      "       6055 |   0.198826  |    0.169045     |   1\n",
      "       6056 |   0.194946  |    0.047022     |   0\n",
      "       6057 |   0.187052  |    0.052078     |   0\n",
      "       6058 |   0.179904  |    0.149098     |   1\n",
      "       6059 |   0.230409  |    0.170290     |   1\n",
      "       6060 |   0.168774  |    0.019874     |   0\n",
      "       6061 |   0.081679  |    0.056206     |   2\n",
      "       6062 |   0.199390  |    0.056653     |   0\n",
      "       6063 |   0.247945  |    0.187103     |   1\n",
      "       6064 |   0.062726  |    0.015635     |   2\n",
      "       6065 |   0.184168  |    0.172095     |   1\n",
      "       6066 |   0.030152  |    0.074741     |   2\n",
      "       6067 |   0.064597  |    0.024457     |   2\n",
      "       6068 |   0.216297  |    0.081598     |   0\n",
      "       6069 |   0.046717  |    0.014632     |   2\n",
      "       6070 |   0.000155  |    0.078547     |   2\n",
      "       6071 |   0.241042  |    0.029464     |   0\n",
      "       6072 |   0.221439  |    0.083282     |   0\n",
      "       6073 |   0.225825  |    0.143305     |   1\n",
      "       6074 |   0.261407  |    0.144514     |   1\n",
      "       6075 |   0.000157  |    0.011117     |   2\n",
      "       6076 |   0.000172  |    0.058535     |   2\n",
      "       6077 |   0.251287  |    0.046251     |   0\n",
      "       6078 |   0.191849  |    0.063137     |   0\n",
      "       6079 |   0.249904  |    0.152010     |   1\n",
      "       6080 |   0.243014  |    0.031566     |   0\n",
      "       6081 |   0.191141  |    0.211208     |   1\n",
      "       6082 |   0.253679  |    0.137875     |   1\n",
      "       6083 |   0.222155  |    0.028080     |   0\n",
      "       6084 |   0.178755  |    0.077421     |   0\n",
      "       6085 |   0.000164  |    0.006296     |   2\n",
      "       6086 |   0.000159  |    0.079643     |   2\n",
      "       6087 |   0.000169  |    0.003995     |   2\n",
      "       6088 |   0.246976  |    0.186665     |   1\n",
      "       6089 |   0.077450  |    0.004973     |   2\n",
      "       6090 |   0.088229  |    0.080232     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 6091: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       6091 |   0.238392  |    0.147887     |   1\n",
      "       6092 |   0.077704  |    0.038696     |   2\n",
      "       6093 |   0.056584  |    0.079097     |   2\n",
      "       6094 |   0.248543  |    0.146747     |   1\n",
      "       6095 |   0.058088  |    0.041941     |   2\n",
      "       6096 |   0.210841  |    0.072402     |   0\n",
      "       6097 |   0.202258  |    0.012715     |   0\n",
      "       6098 |   0.195708  |    0.066415     |   0\n",
      "       6099 |   0.258660  |    0.140973     |   1\n",
      "       6100 |   0.280105  |    0.043965     |   0\n",
      "       6101 |   0.213316  |    0.209724     |   1\n",
      "       6102 |   0.275998  |    0.102311     |   1\n",
      "       6103 |   0.196306  |    0.027072     |   0\n",
      "       6104 |   0.241114  |    0.204114     |   1\n",
      "       6105 |   0.079593  |    0.010174     |   2\n",
      "       6106 |   0.037685  |    0.089547     |   2\n",
      "       6107 |   0.205472  |    0.037963     |   0\n",
      "       6108 |   0.198763  |    0.151310     |   1\n",
      "       6109 |   0.233100  |    0.060626     |   0\n",
      "       6110 |   0.196235  |    0.137752     |   1\n",
      "       6111 |   0.229601  |    0.074005     |   0\n",
      "       6112 |   0.242054  |    0.197608     |   1\n",
      "       6113 |   0.066980  |    0.005927     |   2\n",
      "       6114 |   0.073174  |    0.073236     |   2\n",
      "       6115 |   0.222099  |    0.165854     |   1\n",
      "       6116 |   0.293654  |    0.007937     |   0\n",
      "       6117 |   0.210082  |    0.043267     |   0\n",
      "       6118 |   0.199915  |    0.074103     |   0\n",
      "       6119 |   0.072060  |    0.023325     |   2\n",
      "       6120 |   0.205085  |    0.203382     |   1\n",
      "       6121 |   0.241123  |    0.011161     |   0\n",
      "       6122 |   0.271309  |    0.204951     |   1\n",
      "       6123 |   0.213194  |    0.007850     |   0\n",
      "       6124 |   0.217067  |    0.217440     |   1\n",
      "       6125 |   0.073223  |    0.008102     |   2\n",
      "       6126 |   0.252713  |    0.081214     |   0\n",
      "       6127 |   0.179917  |    0.024321     |   0\n",
      "       6128 |   0.031384  |    0.078919     |   2\n",
      "       6129 |   0.000155  |    0.033059     |   2\n",
      "       6130 |   0.007818  |    0.048183     |   2\n",
      "       6131 |   0.123579  |    0.081102     |   2\n",
      "       6132 |   0.228482  |    0.140194     |   1\n",
      "       6133 |   0.188545  |    0.203626     |   1\n",
      "       6134 |   0.260248  |    0.180113     |   1\n",
      "       6135 |   0.256691  |    0.129570     |   1\n",
      "       6136 |   0.250796  |    0.043871     |   0\n",
      "       6137 |   0.312698  |    0.191723     |   1\n",
      "       6138 |   0.052096  |    0.015663     |   2\n",
      "       6139 |   0.296011  |    0.196646     |   1\n",
      "       6140 |   0.081045  |    0.006498     |   2\n",
      "       6141 |   0.062205  |    0.078493     |   2\n",
      "       6142 |   0.028597  |    0.029343     |   2\n",
      "       6143 |   0.207348  |    0.203781     |   1\n",
      "       6144 |   0.199883  |    0.146665     |   1\n",
      "       6145 |   0.229472  |    0.110546     |   1\n",
      "       6146 |   0.355655  |    0.143536     |   1\n",
      "       6147 |   0.058321  |    0.049781     |   2\n",
      "       6148 |   0.216382  |    0.048251     |   0\n",
      "       6149 |   0.269437  |    0.208444     |   1\n",
      "       6150 |   0.206720  |    0.005223     |   0\n",
      "       6151 |   0.258396  |    0.213305     |   1\n",
      "       6152 |   0.241566  |    0.012038     |   0\n",
      "       6153 |   0.222148  |    0.140056     |   1\n",
      "       6154 |   0.205468  |    0.080917     |   0\n",
      "       6155 |   0.271589  |    0.158066     |   1\n",
      "       6156 |   0.268349  |    0.147485     |   1\n",
      "       6157 |   0.201342  |    0.191277     |   1\n",
      "       6158 |   0.044437  |    0.014612     |   2\n",
      "       6159 |   0.186454  |    0.079070     |   0\n",
      "       6160 |   0.224128  |    0.016076     |   0\n",
      "       6161 |   0.000152  |    0.087667     |   2\n",
      "       6162 |   0.000154  |    0.017014     |   2\n",
      "       6163 |   0.222403  |    0.222756     |   1\n",
      "       6164 |   0.186957  |    0.144297     |   1\n",
      "       6165 |   0.229835  |    0.108401     |   1\n",
      "       6166 |   0.197950  |    0.197731     |   1\n",
      "       6167 |   0.223340  |    0.010705     |   0\n",
      "       6168 |   0.295805  |    0.188449     |   1\n",
      "       6169 |   0.208305  |    0.197092     |   1\n",
      "       6170 |   0.000169  |    0.014506     |   2\n",
      "       6171 |   0.000160  |    0.042191     |   2\n",
      "       6172 |   0.224346  |    0.050854     |   0\n",
      "       6173 |   0.000155  |    0.047518     |   2\n",
      "       6174 |   0.211991  |    0.040518     |   0\n",
      "       6175 |   0.000166  |    0.079065     |   2\n",
      "       6176 |   0.074191  |    0.042325     |   2\n",
      "       6177 |   0.087424  |    0.044402     |   2\n",
      "       6178 |   0.277598  |    0.196475     |   1\n",
      "       6179 |   0.289404  |    0.109168     |   1\n",
      "       6180 |   0.251869  |    0.077199     |   0\n",
      "       6181 |   0.228807  |    0.042242     |   0\n",
      "       6182 |   0.280891  |    0.076984     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 6183: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       6183 |   0.178293  |    0.017549     |   0\n",
      "       6184 |   0.081159  |    0.087363     |   2\n",
      "       6185 |   0.334407  |    0.149266     |   1\n",
      "       6186 |   0.300813  |    0.148799     |   1\n",
      "       6187 |   0.058503  |    0.023867     |   2\n",
      "       6188 |   0.204158  |    0.056749     |   0\n",
      "       6189 |   0.191227  |    0.152556     |   1\n",
      "       6190 |   0.059913  |    0.037879     |   2\n",
      "       6191 |   0.207495  |    0.078178     |   0\n",
      "       6192 |   0.079361  |    0.014433     |   2\n",
      "       6193 |   0.218393  |    0.218463     |   1\n",
      "       6194 |   0.256850  |    0.025791     |   0\n",
      "       6195 |   0.038052  |    0.052658     |   2\n",
      "       6196 |   0.065604  |    0.041782     |   2\n",
      "       6197 |   0.187194  |    0.039974     |   0\n",
      "       6198 |   0.298589  |    0.212764     |   1\n",
      "       6199 |   0.071449  |    0.008615     |   2\n",
      "       6200 |   0.073973  |    0.077806     |   2\n",
      "       6201 |   0.071630  |    0.007268     |   2\n",
      "       6202 |   0.252489  |    0.078203     |   0\n",
      "       6203 |   0.191880  |    0.049493     |   0\n",
      "       6204 |   0.203432  |    0.196715     |   1\n",
      "       6205 |   0.216402  |    0.013492     |   0\n",
      "       6206 |   0.248006  |    0.043279     |   0\n",
      "       6207 |   0.218558  |    0.042204     |   0\n",
      "       6208 |   0.205223  |    0.203085     |   1\n",
      "       6209 |   0.031234  |    0.008527     |   2\n",
      "       6210 |   0.000153  |    0.073462     |   2\n",
      "       6211 |   0.306131  |    0.149028     |   1\n",
      "       6212 |   0.253592  |    0.148274     |   1\n",
      "       6213 |   0.007353  |    0.008852     |   2\n",
      "       6214 |   0.232860  |    0.076210     |   0\n",
      "       6215 |   0.122000  |    0.013304     |   2\n",
      "       6216 |   0.052773  |    0.093817     |   2\n",
      "       6217 |   0.214957  |    0.144981     |   1\n",
      "       6218 |   0.080652  |    0.033069     |   2\n",
      "       6219 |   0.144266  |    0.053369     |   0\n",
      "       6220 |   0.215832  |    0.049927     |   0\n",
      "       6221 |   0.063671  |    0.041516     |   2\n",
      "       6222 |   0.192322  |    0.047950     |   0\n",
      "       6223 |   0.202868  |    0.048826     |   0\n",
      "       6224 |   0.029788  |    0.044914     |   2\n",
      "       6225 |   0.061045  |    0.043074     |   2\n",
      "       6226 |   0.047262  |    0.070617     |   2\n",
      "       6227 |   0.218474  |    0.028560     |   0\n",
      "       6228 |   0.252992  |    0.199344     |   1\n",
      "       6229 |   0.230116  |    0.013505     |   0\n",
      "       6230 |   0.280999  |    0.154516     |   1\n",
      "       6231 |   0.284193  |    0.192758     |   1\n",
      "       6232 |   0.320369  |    0.137570     |   1\n",
      "       6233 |   0.203520  |    0.011040     |   0\n",
      "       6234 |   0.229672  |    0.051565     |   0\n",
      "       6235 |   0.243247  |    0.187367     |   1\n",
      "       6236 |   0.178747  |    0.170299     |   1\n",
      "       6237 |   0.000148  |    0.006554     |   2\n",
      "       6238 |   0.215480  |    0.076346     |   0\n",
      "       6239 |   0.239231  |    0.036958     |   0\n",
      "       6240 |   0.261544  |    0.186526     |   1\n",
      "       6241 |   0.309339  |    0.163028     |   1\n",
      "       6242 |   0.264371  |    0.133279     |   1\n",
      "       6243 |   0.000150  |    0.006648     |   2\n",
      "       6244 |   0.000164  |    0.084243     |   2\n",
      "       6245 |   0.000157  |    0.004993     |   2\n",
      "       6246 |   0.234949  |    0.083091     |   0\n",
      "       6247 |   0.193427  |    0.011762     |   0\n",
      "       6248 |   0.000152  |    0.075337     |   2\n",
      "       6249 |   0.000161  |    0.030612     |   2\n",
      "       6250 |   0.075572  |    0.051420     |   2\n",
      "       6251 |   0.212409  |    0.044257     |   0\n",
      "       6252 |   0.086795  |    0.045807     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 6253: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       6253 |   0.211208  |    0.043390     |   0\n",
      "       6254 |   0.079427  |    0.078440     |   2\n",
      "       6255 |   0.251988  |    0.015801     |   0\n",
      "       6256 |   0.212567  |    0.200961     |   1\n",
      "       6257 |   0.289948  |    0.034352     |   0\n",
      "       6258 |   0.054531  |    0.044050     |   2\n",
      "       6259 |   0.059750  |    0.044260     |   2\n",
      "       6260 |   0.314406  |    0.138000     |   1\n",
      "       6261 |   0.197062  |    0.200782     |   1\n",
      "       6262 |   0.244639  |    0.018225     |   0\n",
      "       6263 |   0.193992  |    0.183574     |   1\n",
      "       6264 |   0.175809  |    0.200667     |   1\n",
      "       6265 |   0.309442  |    0.139610     |   1\n",
      "       6266 |   0.289144  |    0.130681     |   1\n",
      "       6267 |   0.079015  |    0.048282     |   2\n",
      "       6268 |   0.221948  |    0.078505     |   0\n",
      "       6269 |   0.205072  |    0.022179     |   0\n",
      "       6270 |   0.271234  |    0.223215     |   1\n",
      "       6271 |   0.219326  |    0.003392     |   0\n",
      "       6272 |   0.179104  |    0.197392     |   1\n",
      "       6273 |   0.276423  |    0.146656     |   1\n",
      "       6274 |   0.303799  |    0.108726     |   1\n",
      "       6275 |   0.173624  |    0.209229     |   1\n",
      "       6276 |   0.247830  |    0.109713     |   1\n",
      "       6277 |   0.300731  |    0.155763     |   1\n",
      "       6278 |   0.241127  |    0.043002     |   0\n",
      "       6279 |   0.038490  |    0.050944     |   2\n",
      "       6280 |   0.233599  |    0.043210     |   0\n",
      "       6281 |   0.064005  |    0.081106     |   2\n",
      "       6282 |   0.247370  |    0.047922     |   0\n",
      "       6283 |   0.264842  |    0.149443     |   1\n",
      "       6284 |   0.070570  |    0.051702     |   2\n",
      "       6285 |   0.210563  |    0.044645     |   0\n",
      "       6286 |   0.183812  |    0.043695     |   0\n",
      "       6287 |   0.247015  |    0.147453     |   1\n",
      "       6288 |   0.277724  |    0.226018     |   1\n",
      "       6289 |   0.250252  |    0.005638     |   0\n",
      "       6290 |   0.073548  |    0.058432     |   2\n",
      "       6291 |   0.246866  |    0.137102     |   1\n",
      "       6292 |   0.225060  |    0.014683     |   0\n",
      "       6293 |   0.219985  |    0.093812     |   0\n",
      "       6294 |   0.069327  |    0.014001     |   2\n",
      "       6295 |   0.219035  |    0.170810     |   1\n",
      "       6296 |   0.243042  |    0.198396     |   1\n",
      "       6297 |   0.031408  |    0.005046     |   2\n",
      "       6298 |   0.194431  |    0.045365     |   0\n",
      "       6299 |   0.233493  |    0.048578     |   0\n",
      "       6300 |   0.151377  |    0.205157     |   1\n",
      "       6301 |   0.247981  |    0.137481     |   1\n",
      "       6302 |   0.000152  |    0.044789     |   2\n",
      "       6303 |   0.236942  |    0.147618     |   1\n",
      "       6304 |   0.210833  |    0.147309     |   1\n",
      "       6305 |   0.165119  |    0.006070     |   0\n",
      "       6306 |   0.175640  |    0.049029     |   0\n",
      "       6307 |   0.278827  |    0.162510     |   1\n",
      "       6308 |   0.007537  |    0.024940     |   2\n",
      "       6309 |   0.159342  |    0.048295     |   0\n",
      "       6310 |   0.122146  |    0.080844     |   2\n",
      "       6311 |   0.210198  |    0.143944     |   1\n",
      "       6312 |   0.201509  |    0.012022     |   0\n",
      "       6313 |   0.272812  |    0.200945     |   1\n",
      "       6314 |   0.050682  |    0.006158     |   2\n",
      "       6315 |   0.078808  |    0.080406     |   2\n",
      "       6316 |   0.062674  |    0.028305     |   2\n",
      "       6317 |   0.207468  |    0.084174     |   0\n",
      "       6318 |   0.319233  |    0.143262     |   1\n",
      "       6319 |   0.284966  |    0.096843     |   1\n",
      "       6320 |   0.193572  |    0.045533     |   0\n",
      "       6321 |   0.241049  |    0.082707     |   0\n",
      "       6322 |   0.268760  |    0.147777     |   1\n",
      "       6323 |   0.237402  |    0.199355     |   1\n",
      "       6324 |   0.180849  |    0.101294     |   1\n",
      "       6325 |   0.027587  |    0.045839     |   2\n",
      "       6326 |   0.244292  |    0.200254     |   1\n",
      "       6327 |   0.271428  |    0.145237     |   1\n",
      "       6328 |   0.062139  |    0.006299     |   2\n",
      "       6329 |   0.217256  |    0.225751     |   1\n",
      "       6330 |   0.228019  |    0.105753     |   1\n",
      "       6331 |   0.274391  |    0.030561     |   0\n",
      "       6332 |   0.220555  |    0.047122     |   0\n",
      "       6333 |   0.266275  |    0.085145     |   0\n",
      "       6334 |   0.257177  |    0.134048     |   1\n",
      "       6335 |   0.234519  |    0.040035     |   0\n",
      "       6336 |   0.249524  |    0.046679     |   0\n",
      "       6337 |   0.224287  |    0.039398     |   0\n",
      "       6338 |   0.044774  |    0.049576     |   2\n",
      "       6339 |   0.269593  |    0.080540     |   0\n",
      "       6340 |   0.195487  |    0.150145     |   1\n",
      "       6341 |   0.000150  |    0.039236     |   2\n",
      "       6342 |   0.243016  |    0.205377     |   1\n",
      "       6343 |   0.000151  |    0.005084     |   2\n",
      "       6344 |   0.206071  |    0.073811     |   0\n",
      "       6345 |   0.000168  |    0.028202     |   2\n",
      "       6346 |   0.000158  |    0.061144     |   2\n",
      "       6347 |   0.249008  |    0.151583     |   1\n",
      "       6348 |   0.229198  |    0.046097     |   0\n",
      "       6349 |   0.220297  |    0.211006     |   1\n",
      "       6350 |   0.000152  |    0.012577     |   2\n",
      "       6351 |   0.000162  |    0.047489     |   2\n",
      "       6352 |   0.258818  |    0.074305     |   0\n",
      "       6353 |   0.237246  |    0.053946     |   0\n",
      "       6354 |   0.187510  |    0.155974     |   1\n",
      "       6355 |   0.194642  |    0.004688     |   0\n",
      "       6356 |   0.173358  |    0.044346     |   0\n",
      "       6357 |   0.160968  |    0.046953     |   0\n",
      "       6358 |   0.219081  |    0.046476     |   0\n",
      "       6359 |   0.076731  |    0.079986     |   2\n",
      "       6360 |   0.238419  |    0.111062     |   1\n",
      "       6361 |   0.084616  |    0.045168     |   2\n",
      "       6362 |   0.186508  |    0.070739     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 6363: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       6363 |   0.193971  |    0.008043     |   0\n",
      "       6364 |   0.201761  |    0.040604     |   0\n",
      "       6365 |   0.078177  |    0.045225     |   2\n",
      "       6366 |   0.205063  |    0.039912     |   0\n",
      "       6367 |   0.056593  |    0.079645     |   2\n",
      "       6368 |   0.191984  |    0.016693     |   0\n",
      "       6369 |   0.225828  |    0.078481     |   0\n",
      "       6370 |   0.230948  |    0.026439     |   0\n",
      "       6371 |   0.212203  |    0.214735     |   1\n",
      "       6372 |   0.057060  |    0.011638     |   2\n",
      "       6373 |   0.172064  |    0.071838     |   0\n",
      "       6374 |   0.079520  |    0.036072     |   2\n",
      "       6375 |   0.038792  |    0.055209     |   2\n",
      "       6376 |   0.065339  |    0.062045     |   2\n",
      "       6377 |   0.224604  |    0.047204     |   0\n",
      "       6378 |   0.239918  |    0.203341     |   1\n",
      "       6379 |   0.073848  |    0.010061     |   2\n",
      "       6380 |   0.225074  |    0.074757     |   0\n",
      "       6381 |   0.225551  |    0.026801     |   0\n",
      "       6382 |   0.074283  |    0.078348     |   2\n",
      "       6383 |   0.235250  |    0.028546     |   0\n",
      "       6384 |   0.071960  |    0.048325     |   2\n",
      "       6385 |   0.033255  |    0.046998     |   2\n",
      "       6386 |   0.267816  |    0.182686     |   1\n",
      "       6387 |   0.194802  |    0.028749     |   0\n",
      "       6388 |   0.262732  |    0.201410     |   1\n",
      "       6389 |   0.168849  |    0.143745     |   1\n",
      "       6390 |   0.173021  |    0.054821     |   0\n",
      "       6391 |   0.149953  |    0.151565     |   1\n",
      "       6392 |   0.000151  |    0.039757     |   2\n",
      "       6393 |   0.231826  |    0.043345     |   0\n",
      "       6394 |   0.007950  |    0.054416     |   2\n",
      "       6395 |   0.264754  |    0.165440     |   1\n",
      "       6396 |   0.215766  |    0.138637     |   1\n",
      "       6397 |   0.121589  |    0.052635     |   2\n",
      "       6398 |   0.291303  |    0.147812     |   1\n",
      "       6399 |   0.136661  |    0.020918     |   0\n",
      "       6400 |   0.051550  |    0.044540     |   2\n",
      "       6401 |   0.247590  |    0.044380     |   0\n",
      "       6402 |   0.249868  |    0.046047     |   0\n",
      "       6403 |   0.272784  |    0.202335     |   1\n",
      "       6404 |   0.241716  |    0.006982     |   0\n",
      "       6405 |   0.078858  |    0.077405     |   2\n",
      "       6406 |   0.144278  |    0.009815     |   0\n",
      "       6407 |   0.220767  |    0.071622     |   0\n",
      "       6408 |   0.067179  |    0.026498     |   2\n",
      "       6409 |   0.234877  |    0.213839     |   1\n",
      "       6410 |   0.217888  |    0.155124     |   1\n",
      "       6411 |   0.205609  |    0.030552     |   0\n",
      "       6412 |   0.260046  |    0.149104     |   1\n",
      "       6413 |   0.258250  |    0.160195     |   1\n",
      "       6414 |   0.028129  |    0.006998     |   2\n",
      "       6415 |   0.258255  |    0.143566     |   1\n",
      "       6416 |   0.231039  |    0.154907     |   1\n",
      "       6417 |   0.278089  |    0.164687     |   1\n",
      "       6418 |   0.266014  |    0.019555     |   0\n",
      "       6419 |   0.059287  |    0.089396     |   2\n",
      "       6420 |   0.287578  |    0.154420     |   1\n",
      "       6421 |   0.208094  |    0.022667     |   0\n",
      "       6422 |   0.047051  |    0.082360     |   2\n",
      "       6423 |   0.256054  |    0.133996     |   1\n",
      "       6424 |   0.000148  |    0.075133     |   2\n",
      "       6425 |   0.178781  |    0.143569     |   1\n",
      "       6426 |   0.260376  |    0.143261     |   1\n",
      "       6427 |   0.170694  |    0.047663     |   0\n",
      "       6428 |   0.229600  |    0.149885     |   1\n",
      "       6429 |   0.228829  |    0.156479     |   1\n",
      "       6430 |   0.282311  |    0.151869     |   1\n",
      "       6431 |   0.000150  |    0.025024     |   2\n",
      "       6432 |   0.000163  |    0.073277     |   2\n",
      "       6433 |   0.302133  |    0.142128     |   1\n",
      "       6434 |   0.243941  |    0.079497     |   0\n",
      "       6435 |   0.243539  |    0.164518     |   1\n",
      "       6436 |   0.197457  |    0.164150     |   1\n",
      "       6437 |   0.000153  |    0.013795     |   2\n",
      "       6438 |   0.290871  |    0.194899     |   1\n",
      "       6439 |   0.143749  |    0.141240     |   1\n",
      "       6440 |   0.294906  |    0.192270     |   1\n",
      "       6441 |   0.220906  |    0.150355     |   1\n",
      "       6442 |   0.000151  |    0.004635     |   2\n",
      "       6443 |   0.265951  |    0.170312     |   1\n",
      "       6444 |   0.214781  |    0.152183     |   1\n",
      "       6445 |   0.227617  |    0.199278     |   1\n",
      "       6446 |   0.204705  |    0.096249     |   1\n",
      "       6447 |   0.221963  |    0.074734     |   0\n",
      "       6448 |   0.000156  |    0.039146     |   2\n",
      "       6449 |   0.201281  |    0.044193     |   0\n",
      "       6450 |   0.071995  |    0.037649     |   2\n",
      "       6451 |   0.084106  |    0.073985     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 6452: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       6452 |   0.073626  |    0.029673     |   2\n",
      "       6453 |   0.210602  |    0.055133     |   0\n",
      "       6454 |   0.055533  |    0.039958     |   2\n",
      "       6455 |   0.201541  |    0.040786     |   0\n",
      "       6456 |   0.056788  |    0.026231     |   2\n",
      "       6457 |   0.247994  |    0.080677     |   0\n",
      "       6458 |   0.078002  |    0.017351     |   2\n",
      "       6459 |   0.198315  |    0.086790     |   0\n",
      "       6460 |   0.213850  |    0.161862     |   1\n",
      "       6461 |   0.235535  |    0.140883     |   1\n",
      "       6462 |   0.235243  |    0.031115     |   0\n",
      "       6463 |   0.241052  |    0.154136     |   1\n",
      "       6464 |   0.037398  |    0.070258     |   2\n",
      "       6465 |   0.063130  |    0.038750     |   2\n",
      "       6466 |   0.284740  |    0.161757     |   1\n",
      "       6467 |   0.069457  |    0.040905     |   2\n",
      "       6468 |   0.205549  |    0.050476     |   0\n",
      "       6469 |   0.174396  |    0.198059     |   1\n",
      "       6470 |   0.201953  |    0.144550     |   1\n",
      "       6471 |   0.205899  |    0.197761     |   1\n",
      "       6472 |   0.241022  |    0.005521     |   0\n",
      "       6473 |   0.073112  |    0.076392     |   2\n",
      "       6474 |   0.069396  |    0.018665     |   2\n",
      "       6475 |   0.226567  |    0.196093     |   1\n",
      "       6476 |   0.184112  |    0.022057     |   0\n",
      "       6477 |   0.276141  |    0.223034     |   1\n",
      "       6478 |   0.262264  |    0.103656     |   1\n",
      "       6479 |   0.190538  |    0.190161     |   1\n",
      "       6480 |   0.219988  |    0.159988     |   1\n",
      "       6481 |   0.225050  |    0.145018     |   1\n",
      "       6482 |   0.029707  |    0.024119     |   2\n",
      "       6483 |   0.000149  |    0.092007     |   2\n",
      "       6484 |   0.232469  |    0.143480     |   1\n",
      "       6485 |   0.007665  |    0.030742     |   2\n",
      "       6486 |   0.204157  |    0.047241     |   0\n",
      "       6487 |   0.117718  |    0.051522     |   2\n",
      "       6488 |   0.050601  |    0.046371     |   2\n",
      "       6489 |   0.219172  |    0.073039     |   0\n",
      "       6490 |   0.074292  |    0.014874     |   2\n",
      "       6491 |   0.059704  |    0.078198     |   2\n",
      "       6492 |   0.203584  |    0.139135     |   1\n",
      "       6493 |   0.202548  |    0.040951     |   0\n",
      "       6494 |   0.249491  |    0.087077     |   0\n",
      "       6495 |   0.027686  |    0.015409     |   2\n",
      "       6496 |   0.058453  |    0.076789     |   2\n",
      "       6497 |   0.232630  |    0.025028     |   0\n",
      "       6498 |   0.248005  |    0.075341     |   0\n",
      "       6499 |   0.228748  |    0.155304     |   1\n",
      "       6500 |   0.257518  |    0.151603     |   1\n",
      "       6501 |   0.281100  |    0.204333     |   1\n",
      "       6502 |   0.264215  |    0.145349     |   1\n",
      "       6503 |   0.071706  |    0.047511     |   2\n",
      "       6504 |   0.266293  |    0.200610     |   1\n",
      "       6505 |   0.053071  |    0.019529     |   2\n",
      "       6506 |   0.257075  |    0.210256     |   1\n",
      "       6507 |   0.056938  |    0.010002     |   2\n",
      "       6508 |   0.078340  |    0.077526     |   2\n",
      "       6509 |   0.236198  |    0.051002     |   0\n",
      "       6510 |   0.179811  |    0.130470     |   1\n",
      "       6511 |   0.036737  |    0.042815     |   2\n",
      "       6512 |   0.059804  |    0.081267     |   2\n",
      "       6513 |   0.288877  |    0.146417     |   1\n",
      "       6514 |   0.069758  |    0.010421     |   2\n",
      "       6515 |   0.218404  |    0.079643     |   0\n",
      "       6516 |   0.071358  |    0.026664     |   2\n",
      "       6517 |   0.066152  |    0.075848     |   2\n",
      "       6518 |   0.231640  |    0.013938     |   0\n",
      "       6519 |   0.031054  |    0.078674     |   2\n",
      "       6520 |   0.275224  |    0.137701     |   1\n",
      "       6521 |   0.266417  |    0.043396     |   0\n",
      "       6522 |   0.235220  |    0.042249     |   0\n",
      "       6523 |   0.000148  |    0.045596     |   2\n",
      "       6524 |   0.168176  |    0.135712     |   1\n",
      "       6525 |   0.007421  |    0.082886     |   2\n",
      "       6526 |   0.265548  |    0.019304     |   0\n",
      "       6527 |   0.260823  |    0.154301     |   1\n",
      "       6528 |   0.116859  |    0.074073     |   2\n",
      "       6529 |   0.257076  |    0.049261     |   0\n",
      "       6530 |   0.238304  |    0.059479     |   0\n",
      "       6531 |   0.256176  |    0.150160     |   1\n",
      "       6532 |   0.299019  |    0.162790     |   1\n",
      "       6533 |   0.191908  |    0.160550     |   1\n",
      "       6534 |   0.168148  |    0.040322     |   0\n",
      "       6535 |   0.049887  |    0.055300     |   2\n",
      "       6536 |   0.265861  |    0.156378     |   1\n",
      "       6537 |   0.229272  |    0.138508     |   1\n",
      "       6538 |   0.074906  |    0.032562     |   2\n",
      "       6539 |   0.216255  |    0.050135     |   0\n",
      "       6540 |   0.249395  |    0.198219     |   1\n",
      "       6541 |   0.228053  |    0.005761     |   0\n",
      "       6542 |   0.060275  |    0.049994     |   2\n",
      "       6543 |   0.028203  |    0.016316     |   2\n",
      "       6544 |   0.060966  |    0.064762     |   2\n",
      "       6545 |   0.296205  |    0.082087     |   0\n",
      "       6546 |   0.187582  |    0.080219     |   0\n",
      "       6547 |   0.045272  |    0.079855     |   2\n",
      "       6548 |   0.208671  |    0.179933     |   1\n",
      "       6549 |   0.247625  |    0.139676     |   1\n",
      "       6550 |   0.215171  |    0.045731     |   0\n",
      "       6551 |   0.213300  |    0.197329     |   1\n",
      "       6552 |   0.000145  |    0.009199     |   2\n",
      "       6553 |   0.179800  |    0.079277     |   0\n",
      "       6554 |   0.225286  |    0.147948     |   1\n",
      "       6555 |   0.000146  |    0.040675     |   2\n",
      "       6556 |   0.238302  |    0.049424     |   0\n",
      "       6557 |   0.000158  |    0.028483     |   2\n",
      "       6558 |   0.259770  |    0.161934     |   1\n",
      "       6559 |   0.274350  |    0.074030     |   0\n",
      "       6560 |   0.000150  |    0.035116     |   2\n",
      "       6561 |   0.190055  |    0.042440     |   0\n",
      "       6562 |   0.000147  |    0.040201     |   2\n",
      "       6563 |   0.203746  |    0.085388     |   0\n",
      "       6564 |   0.229835  |    0.129493     |   1\n",
      "       6565 |   0.000155  |    0.015497     |   2\n",
      "       6566 |   0.265990  |    0.187696     |   1\n",
      "       6567 |   0.258440  |    0.052635     |   0\n",
      "       6568 |   0.075122  |    0.054407     |   2\n",
      "       6569 |   0.207424  |    0.147505     |   1\n",
      "       6570 |   0.259312  |    0.052033     |   0\n",
      "       6571 |   0.084187  |    0.036205     |   2\n",
      "       6572 |   0.179277  |    0.053138     |   0\n",
      "       6573 |   0.243015  |    0.139744     |   1\n",
      "       6574 |   0.220484  |    0.045380     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 6575: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       6575 |   0.259589  |    0.080341     |   0\n",
      "       6576 |   0.078589  |    0.009776     |   2\n",
      "       6577 |   0.056732  |    0.085210     |   2\n",
      "       6578 |   0.194718  |    0.024997     |   0\n",
      "       6579 |   0.212197  |    0.172553     |   1\n",
      "       6580 |   0.295559  |    0.178738     |   1\n",
      "       6581 |   0.057368  |    0.024949     |   2\n",
      "       6582 |   0.075574  |    0.047492     |   2\n",
      "       6583 |   0.036141  |    0.038439     |   2\n",
      "       6584 |   0.198108  |    0.077204     |   0\n",
      "       6585 |   0.191884  |    0.019295     |   0\n",
      "       6586 |   0.207840  |    0.210689     |   1\n",
      "       6587 |   0.236885  |    0.138052     |   1\n",
      "       6588 |   0.241167  |    0.142455     |   1\n",
      "       6589 |   0.247660  |    0.038771     |   0\n",
      "       6590 |   0.250631  |    0.048535     |   0\n",
      "       6591 |   0.233918  |    0.076577     |   0\n",
      "       6592 |   0.064643  |    0.004321     |   2\n",
      "       6593 |   0.230403  |    0.089870     |   0\n",
      "       6594 |   0.309803  |    0.136122     |   1\n",
      "       6595 |   0.068787  |    0.008782     |   2\n",
      "       6596 |   0.251884  |    0.160153     |   1\n",
      "       6597 |   0.220572  |    0.071166     |   0\n",
      "       6598 |   0.224164  |    0.017109     |   0\n",
      "       6599 |   0.074107  |    0.080293     |   2\n",
      "       6600 |   0.069866  |    0.028615     |   2\n",
      "       6601 |   0.172641  |    0.042096     |   0\n",
      "       6602 |   0.226253  |    0.072780     |   0\n",
      "       6603 |   0.141116  |    0.024641     |   0\n",
      "       6604 |   0.230891  |    0.077061     |   0\n",
      "       6605 |   0.197437  |    0.011747     |   0\n",
      "       6606 |   0.219161  |    0.073436     |   0\n",
      "       6607 |   0.214772  |    0.018760     |   0\n",
      "       6608 |   0.199765  |    0.062670     |   0\n",
      "       6609 |   0.259405  |    0.151123     |   1\n",
      "       6610 |   0.238284  |    0.012849     |   0\n",
      "       6611 |   0.205841  |    0.212643     |   1\n",
      "       6612 |   0.032427  |    0.027619     |   2\n",
      "       6613 |   0.248625  |    0.054381     |   0\n",
      "       6614 |   0.000147  |    0.034832     |   2\n",
      "       6615 |   0.293134  |    0.136004     |   1\n",
      "       6616 |   0.007578  |    0.075456     |   2\n",
      "       6617 |   0.213467  |    0.025136     |   0\n",
      "       6618 |   0.268054  |    0.167312     |   1\n",
      "       6619 |   0.114830  |    0.031975     |   2\n",
      "       6620 |   0.234979  |    0.160676     |   1\n",
      "       6621 |   0.210587  |    0.025224     |   0\n",
      "       6622 |   0.236154  |    0.081921     |   0\n",
      "       6623 |   0.215478  |    0.173282     |   1\n",
      "       6624 |   0.052074  |    0.007937     |   2\n",
      "       6625 |   0.077873  |    0.049638     |   2\n",
      "       6626 |   0.164162  |    0.205258     |   1\n",
      "       6627 |   0.231563  |    0.004973     |   0\n",
      "       6628 |   0.064223  |    0.074458     |   2\n",
      "       6629 |   0.329304  |    0.140006     |   1\n",
      "       6630 |   0.207166  |    0.188750     |   1\n",
      "       6631 |   0.028229  |    0.027647     |   2\n",
      "       6632 |   0.292929  |    0.196064     |   1\n",
      "       6633 |   0.288661  |    0.017870     |   0\n",
      "       6634 |   0.252180  |    0.195169     |   1\n",
      "       6635 |   0.060265  |    0.009987     |   2\n",
      "       6636 |   0.151008  |    0.203828     |   1\n",
      "       6637 |   0.202832  |    0.018252     |   0\n",
      "       6638 |   0.045203  |    0.075699     |   2\n",
      "       6639 |   0.000145  |    0.022947     |   2\n",
      "       6640 |   0.227460  |    0.046772     |   0\n",
      "       6641 |   0.221460  |    0.074664     |   0\n",
      "       6642 |   0.232157  |    0.006496     |   0\n",
      "       6643 |   0.000146  |    0.088606     |   2\n",
      "       6644 |   0.265126  |    0.200790     |   1\n",
      "       6645 |   0.000157  |    0.005249     |   2\n",
      "       6646 |   0.199120  |    0.080996     |   0\n",
      "       6647 |   0.243827  |    0.133288     |   1\n",
      "       6648 |   0.206940  |    0.072655     |   0\n",
      "       6649 |   0.210134  |    0.012215     |   0\n",
      "       6650 |   0.170484  |    0.050888     |   0\n",
      "       6651 |   0.170357  |    0.043077     |   0\n",
      "       6652 |   0.224846  |    0.043344     |   0\n",
      "       6653 |   0.185219  |    0.075404     |   0\n",
      "       6654 |   0.000150  |    0.018211     |   2\n",
      "       6655 |   0.221982  |    0.218117     |   1\n",
      "       6656 |   0.229059  |    0.147615     |   1\n",
      "       6657 |   0.000146  |    0.025973     |   2\n",
      "       6658 |   0.290156  |    0.151800     |   1\n",
      "       6659 |   0.000153  |    0.005428     |   2\n",
      "       6660 |   0.240479  |    0.191333     |   1\n",
      "       6661 |   0.193854  |    0.053182     |   0\n",
      "       6662 |   0.079316  |    0.041255     |   2\n",
      "       6663 |   0.222845  |    0.039355     |   0\n",
      "       6664 |   0.083311  |    0.047942     |   2\n",
      "       6665 |   0.292416  |    0.232100     |   1\n",
      "       6666 |   0.208471  |    0.142361     |   1\n",
      "       6667 |   0.242715  |    0.135580     |   1\n",
      "       6668 |   0.188898  |    0.007297     |   0\n",
      "       6669 |   0.190531  |    0.047467     |   0\n",
      "       6670 |   0.308449  |    0.199049     |   1\n",
      "       6671 |   0.191182  |    0.014020     |   0\n",
      "       6672 |   0.180338  |    0.044384     |   0\n",
      "       6673 |   0.290186  |    0.158620     |   1\n",
      "       6674 |   0.237456  |    0.137387     |   1\n",
      "       6675 |   0.155674  |    0.044723     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 6676: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       6676 |   0.204409  |    0.045671     |   0\n",
      "       6677 |   0.194006  |    0.072843     |   0\n",
      "       6678 |   0.080188  |    0.041787     |   2\n",
      "       6679 |   0.219705  |    0.052975     |   0\n",
      "       6680 |   0.220060  |    0.136657     |   1\n",
      "       6681 |   0.058633  |    0.059923     |   2\n",
      "       6682 |   0.241099  |    0.153762     |   1\n",
      "       6683 |   0.207009  |    0.165962     |   1\n",
      "       6684 |   0.263053  |    0.142590     |   1\n",
      "       6685 |   0.249514  |    0.024160     |   0\n",
      "       6686 |   0.229843  |    0.202323     |   1\n",
      "       6687 |   0.186883  |    0.012964     |   0\n",
      "       6688 |   0.057249  |    0.081801     |   2\n",
      "       6689 |   0.072896  |    0.040502     |   2\n",
      "       6690 |   0.219134  |    0.187360     |   1\n",
      "       6691 |   0.035963  |    0.008809     |   2\n",
      "       6692 |   0.252804  |    0.083151     |   0\n",
      "       6693 |   0.262894  |    0.152009     |   1\n",
      "       6694 |   0.062854  |    0.079080     |   2\n",
      "       6695 |   0.242585  |    0.024355     |   0\n",
      "       6696 |   0.208010  |    0.043112     |   0\n",
      "       6697 |   0.202117  |    0.072486     |   0\n",
      "       6698 |   0.070323  |    0.027824     |   2\n",
      "       6699 |   0.187046  |    0.187902     |   1\n",
      "       6700 |   0.238708  |    0.049709     |   0\n",
      "       6701 |   0.167278  |    0.160967     |   1\n",
      "       6702 |   0.072559  |    0.041955     |   2\n",
      "       6703 |   0.071929  |    0.053095     |   2\n",
      "       6704 |   0.232438  |    0.196576     |   1\n",
      "       6705 |   0.183872  |    0.007451     |   0\n",
      "       6706 |   0.032319  |    0.056340     |   2\n",
      "       6707 |   0.000146  |    0.049017     |   2\n",
      "       6708 |   0.259719  |    0.189123     |   1\n",
      "       6709 |   0.213078  |    0.026871     |   0\n",
      "       6710 |   0.007399  |    0.084090     |   2\n",
      "       6711 |   0.233771  |    0.164829     |   1\n",
      "       6712 |   0.278299  |    0.170390     |   1\n",
      "       6713 |   0.286045  |    0.154186     |   1\n",
      "       6714 |   0.228701  |    0.025964     |   0\n",
      "       6715 |   0.180655  |    0.052266     |   0\n",
      "       6716 |   0.195747  |    0.075052     |   0\n",
      "       6717 |   0.265145  |    0.014266     |   0\n",
      "       6718 |   0.218107  |    0.083976     |   0\n",
      "       6719 |   0.177527  |    0.034455     |   0\n",
      "       6720 |   0.219935  |    0.188326     |   1\n",
      "       6721 |   0.117733  |    0.048178     |   2\n",
      "       6722 |   0.050028  |    0.043069     |   2\n",
      "       6723 |   0.252091  |    0.077248     |   0\n",
      "       6724 |   0.196018  |    0.022180     |   0\n",
      "       6725 |   0.077960  |    0.085466     |   2\n",
      "       6726 |   0.257535  |    0.126964     |   1\n",
      "       6727 |   0.064271  |    0.043512     |   2\n",
      "       6728 |   0.197096  |    0.071806     |   0\n",
      "       6729 |   0.266677  |    0.027736     |   0\n",
      "       6730 |   0.268822  |    0.201038     |   1\n",
      "       6731 |   0.027334  |    0.013791     |   2\n",
      "       6732 |   0.059345  |    0.080493     |   2\n",
      "       6733 |   0.044156  |    0.013901     |   2\n",
      "       6734 |   0.225824  |    0.052047     |   0\n",
      "       6735 |   0.232953  |    0.055416     |   0\n",
      "       6736 |   0.000144  |    0.048647     |   2\n",
      "       6737 |   0.234745  |    0.030344     |   0\n",
      "       6738 |   0.000146  |    0.048190     |   2\n",
      "       6739 |   0.219059  |    0.074465     |   0\n",
      "       6740 |   0.238437  |    0.031502     |   0\n",
      "       6741 |   0.000156  |    0.074235     |   2\n",
      "       6742 |   0.000149  |    0.031429     |   2\n",
      "       6743 |   0.000145  |    0.072381     |   2\n",
      "       6744 |   0.000150  |    0.030576     |   2\n",
      "       6745 |   0.201604  |    0.210715     |   1\n",
      "       6746 |   0.213787  |    0.139868     |   1\n",
      "       6747 |   0.209972  |    0.004683     |   0\n",
      "       6748 |   0.079562  |    0.081497     |   2\n",
      "       6749 |   0.084110  |    0.018938     |   2\n",
      "       6750 |   0.179307  |    0.089354     |   0\n",
      "       6751 |   0.208754  |    0.136083     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 6752: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       6752 |   0.242696  |    0.148151     |   1\n",
      "       6753 |   0.205597  |    0.045150     |   0\n",
      "       6754 |   0.080826  |    0.045159     |   2\n",
      "       6755 |   0.187451  |    0.046642     |   0\n",
      "       6756 |   0.237273  |    0.209814     |   1\n",
      "       6757 |   0.219003  |    0.010491     |   0\n",
      "       6758 |   0.059291  |    0.040414     |   2\n",
      "       6759 |   0.197344  |    0.024808     |   0\n",
      "       6760 |   0.056810  |    0.049757     |   2\n",
      "       6761 |   0.250600  |    0.185899     |   1\n",
      "       6762 |   0.075214  |    0.026764     |   2\n",
      "       6763 |   0.223573  |    0.223501     |   1\n",
      "       6764 |   0.037036  |    0.009184     |   2\n",
      "       6765 |   0.219957  |    0.076939     |   0\n",
      "       6766 |   0.223201  |    0.144742     |   1\n",
      "       6767 |   0.245338  |    0.164505     |   1\n",
      "       6768 |   0.170762  |    0.160708     |   1\n",
      "       6769 |   0.228979  |    0.007347     |   0\n",
      "       6770 |   0.246044  |    0.194120     |   1\n",
      "       6771 |   0.240301  |    0.016272     |   0\n",
      "       6772 |   0.192124  |    0.204856     |   1\n",
      "       6773 |   0.061523  |    0.018312     |   2\n",
      "       6774 |   0.068163  |    0.076589     |   2\n",
      "       6775 |   0.071838  |    0.009520     |   2\n",
      "       6776 |   0.072296  |    0.084464     |   2\n",
      "       6777 |   0.032882  |    0.009114     |   2\n",
      "       6778 |   0.201093  |    0.078189     |   0\n",
      "       6779 |   0.183851  |    0.035957     |   0\n",
      "       6780 |   0.239856  |    0.194865     |   1\n",
      "       6781 |   0.195610  |    0.009121     |   0\n",
      "       6782 |   0.215555  |    0.049516     |   0\n",
      "       6783 |   0.000145  |    0.050832     |   2\n",
      "       6784 |   0.263268  |    0.208591     |   1\n",
      "       6785 |   0.007839  |    0.008922     |   2\n",
      "       6786 |   0.257914  |    0.052912     |   0\n",
      "       6787 |   0.224281  |    0.075988     |   0\n",
      "       6788 |   0.117886  |    0.045299     |   2\n",
      "       6789 |   0.260859  |    0.214971     |   1\n",
      "       6790 |   0.171209  |    0.013023     |   0\n",
      "       6791 |   0.239966  |    0.199478     |   1\n",
      "       6792 |   0.268363  |    0.140606     |   1\n",
      "       6793 |   0.050580  |    0.004581     |   2\n",
      "       6794 |   0.187763  |    0.043532     |   0\n",
      "       6795 |   0.078364  |    0.078591     |   2\n",
      "       6796 |   0.063767  |    0.027836     |   2\n",
      "       6797 |   0.027335  |    0.054875     |   2\n",
      "       6798 |   0.056666  |    0.079152     |   2\n",
      "       6799 |   0.215580  |    0.007290     |   0\n",
      "       6800 |   0.193993  |    0.069900     |   0\n",
      "       6801 |   0.171270  |    0.050480     |   0\n",
      "       6802 |   0.198294  |    0.035336     |   0\n",
      "       6803 |   0.045921  |    0.045911     |   2\n",
      "       6804 |   0.222751  |    0.048088     |   0\n",
      "       6805 |   0.203423  |    0.039635     |   0\n",
      "       6806 |   0.208357  |    0.078440     |   0\n",
      "       6807 |   0.267928  |    0.036647     |   0\n",
      "       6808 |   0.000143  |    0.040132     |   2\n",
      "       6809 |   0.000145  |    0.077406     |   2\n",
      "       6810 |   0.288149  |    0.161911     |   1\n",
      "       6811 |   0.000155  |    0.006460     |   2\n",
      "       6812 |   0.251971  |    0.045081     |   0\n",
      "       6813 |   0.269169  |    0.077453     |   0\n",
      "       6814 |   0.215197  |    0.021742     |   0\n",
      "       6815 |   0.184475  |    0.042887     |   0\n",
      "       6816 |   0.193519  |    0.208866     |   1\n",
      "       6817 |   0.239776  |    0.144788     |   1\n",
      "       6818 |   0.000147  |    0.009786     |   2\n",
      "       6819 |   0.000145  |    0.074712     |   2\n",
      "       6820 |   0.212186  |    0.164787     |   1\n",
      "       6821 |   0.000150  |    0.006557     |   2\n",
      "       6822 |   0.255285  |    0.201887     |   1\n",
      "       6823 |   0.263845  |    0.142649     |   1\n",
      "       6824 |   0.078325  |    0.016199     |   2\n",
      "       6825 |   0.083620  |    0.075205     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 6826: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       6826 |   0.077529  |    0.018694     |   2\n",
      "       6827 |   0.216247  |    0.196907     |   1\n",
      "       6828 |   0.204284  |    0.025001     |   0\n",
      "       6829 |   0.055058  |    0.052739     |   2\n",
      "       6830 |   0.197151  |    0.043698     |   0\n",
      "       6831 |   0.222963  |    0.075629     |   0\n",
      "       6832 |   0.210321  |    0.023546     |   0\n",
      "       6833 |   0.055853  |    0.072117     |   2\n",
      "       6834 |   0.073728  |    0.041645     |   2\n",
      "       6835 |   0.250766  |    0.041469     |   0\n",
      "       6836 |   0.036467  |    0.045426     |   2\n",
      "       6837 |   0.062537  |    0.081750     |   2\n",
      "       6838 |   0.070018  |    0.021595     |   2\n",
      "       6839 |   0.246213  |    0.203858     |   1\n",
      "       6840 |   0.256507  |    0.176667     |   1\n",
      "       6841 |   0.072013  |    0.021999     |   2\n",
      "       6842 |   0.175332  |    0.050134     |   0\n",
      "       6843 |   0.279492  |    0.191623     |   1\n",
      "       6844 |   0.068732  |    0.012485     |   2\n",
      "       6845 |   0.271817  |    0.230153     |   1\n",
      "       6846 |   0.234725  |    0.143404     |   1\n",
      "       6847 |   0.181294  |    0.004223     |   0\n",
      "       6848 |   0.284368  |    0.152247     |   1\n",
      "       6849 |   0.247741  |    0.027198     |   0\n",
      "       6850 |   0.232618  |    0.206651     |   1\n",
      "       6851 |   0.220913  |    0.009648     |   0\n",
      "       6852 |   0.245047  |    0.083218     |   0\n",
      "       6853 |   0.178353  |    0.026051     |   0\n",
      "       6854 |   0.210461  |    0.048985     |   0\n",
      "       6855 |   0.172880  |    0.052493     |   0\n",
      "       6856 |   0.031019  |    0.052764     |   2\n",
      "       6857 |   0.238014  |    0.139366     |   1\n",
      "       6858 |   0.238596  |    0.088259     |   0\n",
      "       6859 |   0.000144  |    0.012945     |   2\n",
      "       6860 |   0.007448  |    0.048529     |   2\n",
      "       6861 |   0.116095  |    0.051919     |   2\n",
      "       6862 |   0.196057  |    0.072588     |   0\n",
      "       6863 |   0.227141  |    0.144266     |   1\n",
      "       6864 |   0.205942  |    0.154929     |   1\n",
      "       6865 |   0.203987  |    0.028015     |   0\n",
      "       6866 |   0.049057  |    0.085226     |   2\n",
      "       6867 |   0.315838  |    0.159572     |   1\n",
      "       6868 |   0.193698  |    0.011990     |   0\n",
      "       6869 |   0.205258  |    0.076740     |   0\n",
      "       6870 |   0.234014  |    0.142695     |   1\n",
      "       6871 |   0.258235  |    0.153704     |   1\n",
      "       6872 |   0.075049  |    0.008109     |   2\n",
      "       6873 |   0.060549  |    0.075344     |   2\n",
      "       6874 |   0.289136  |    0.143808     |   1\n",
      "       6875 |   0.187118  |    0.060845     |   0\n",
      "       6876 |   0.283535  |    0.135953     |   1\n",
      "       6877 |   0.308689  |    0.149695     |   1\n",
      "       6878 |   0.238909  |    0.016416     |   0\n",
      "       6879 |   0.217521  |    0.215345     |   1\n",
      "       6880 |   0.177420  |    0.146977     |   1\n",
      "       6881 |   0.285465  |    0.147642     |   1\n",
      "       6882 |   0.198209  |    0.162425     |   1\n",
      "       6883 |   0.230611  |    0.159229     |   1\n",
      "       6884 |   0.247932  |    0.057793     |   0\n",
      "       6885 |   0.239537  |    0.202125     |   1\n",
      "       6886 |   0.205235  |    0.004914     |   0\n",
      "       6887 |   0.026397  |    0.038878     |   2\n",
      "       6888 |   0.145897  |    0.043864     |   0\n",
      "       6889 |   0.204127  |    0.046613     |   0\n",
      "       6890 |   0.202335  |    0.046944     |   0\n",
      "       6891 |   0.056059  |    0.046749     |   2\n",
      "       6892 |   0.043152  |    0.079971     |   2\n",
      "       6893 |   0.220553  |    0.036082     |   0\n",
      "       6894 |   0.226075  |    0.187209     |   1\n",
      "       6895 |   0.234979  |    0.159446     |   1\n",
      "       6896 |   0.000141  |    0.042787     |   2\n",
      "       6897 |   0.204112  |    0.041898     |   0\n",
      "       6898 |   0.153271  |    0.045699     |   0\n",
      "       6899 |   0.000143  |    0.079107     |   2\n",
      "       6900 |   0.213589  |    0.026353     |   0\n",
      "       6901 |   0.211730  |    0.073518     |   0\n",
      "       6902 |   0.000152  |    0.016189     |   2\n",
      "       6903 |   0.189090  |    0.046288     |   0\n",
      "       6904 |   0.265190  |    0.080154     |   0\n",
      "       6905 |   0.225169  |    0.027577     |   0\n",
      "       6906 |   0.262724  |    0.055450     |   0\n",
      "       6907 |   0.240269  |    0.154730     |   1\n",
      "       6908 |   0.174938  |    0.049704     |   0\n",
      "       6909 |   0.170236  |    0.186800     |   1\n",
      "       6910 |   0.208447  |    0.005960     |   0\n",
      "       6911 |   0.257152  |    0.053527     |   0\n",
      "       6912 |   0.238287  |    0.150408     |   1\n",
      "       6913 |   0.169575  |    0.203881     |   1\n",
      "       6914 |   0.000145  |    0.036965     |   2\n",
      "       6915 |   0.198523  |    0.051327     |   0\n",
      "       6916 |   0.000142  |    0.054035     |   2\n",
      "       6917 |   0.000148  |    0.057436     |   2\n",
      "       6918 |   0.254668  |    0.149084     |   1\n",
      "       6919 |   0.084735  |    0.049257     |   2\n",
      "       6920 |   0.083134  |    0.054115     |   2\n",
      "       6921 |   0.319397  |    0.147491     |   1\n",
      "       6922 |   0.330917  |    0.158201     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 6923: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       6923 |   0.079068  |    0.013863     |   2\n",
      "       6924 |   0.326397  |    0.205723     |   1\n",
      "       6925 |   0.058461  |    0.016843     |   2\n",
      "       6926 |   0.203066  |    0.201382     |   1\n",
      "       6927 |   0.207425  |    0.155806     |   1\n",
      "       6928 |   0.185070  |    0.009921     |   0\n",
      "       6929 |   0.056331  |    0.051846     |   2\n",
      "       6930 |   0.073803  |    0.050601     |   2\n",
      "       6931 |   0.226095  |    0.042882     |   0\n",
      "       6932 |   0.174392  |    0.076448     |   0\n",
      "       6933 |   0.215995  |    0.160410     |   1\n",
      "       6934 |   0.246851  |    0.142982     |   1\n",
      "       6935 |   0.034922  |    0.041590     |   2\n",
      "       6936 |   0.214384  |    0.047939     |   0\n",
      "       6937 |   0.246562  |    0.145651     |   1\n",
      "       6938 |   0.203258  |    0.045402     |   0\n",
      "       6939 |   0.212825  |    0.041174     |   0\n",
      "       6940 |   0.174034  |    0.040662     |   0\n",
      "       6941 |   0.197993  |    0.040857     |   0\n",
      "       6942 |   0.194144  |    0.037915     |   0\n",
      "       6943 |   0.180872  |    0.081346     |   0\n",
      "       6944 |   0.244306  |    0.137746     |   1\n",
      "       6945 |   0.249348  |    0.185918     |   1\n",
      "       6946 |   0.210845  |    0.006207     |   0\n",
      "       6947 |   0.226029  |    0.082400     |   0\n",
      "       6948 |   0.252223  |    0.142684     |   1\n",
      "       6949 |   0.240453  |    0.065746     |   0\n",
      "       6950 |   0.257490  |    0.140096     |   1\n",
      "       6951 |   0.230301  |    0.041942     |   0\n",
      "       6952 |   0.204534  |    0.078156     |   0\n",
      "       6953 |   0.187014  |    0.195492     |   1\n",
      "       6954 |   0.059032  |    0.003645     |   2\n",
      "       6955 |   0.254247  |    0.074486     |   0\n",
      "       6956 |   0.193874  |    0.154325     |   1\n",
      "       6957 |   0.275484  |    0.135649     |   1\n",
      "       6958 |   0.069501  |    0.052229     |   2\n",
      "       6959 |   0.240918  |    0.045351     |   0\n",
      "       6960 |   0.072029  |    0.047455     |   2\n",
      "       6961 |   0.070679  |    0.086726     |   2\n",
      "       6962 |   0.174537  |    0.139241     |   1\n",
      "       6963 |   0.031307  |    0.025003     |   2\n",
      "       6964 |   0.214850  |    0.077141     |   0\n",
      "       6965 |   0.000143  |    0.010028     |   2\n",
      "       6966 |   0.183906  |    0.073104     |   0\n",
      "       6967 |   0.008062  |    0.043715     |   2\n",
      "       6968 |   0.230448  |    0.046519     |   0\n",
      "       6969 |   0.193918  |    0.137870     |   1\n",
      "       6970 |   0.148702  |    0.026258     |   0\n",
      "       6971 |   0.114527  |    0.077979     |   2\n",
      "       6972 |   0.214919  |    0.018237     |   0\n",
      "       6973 |   0.213146  |    0.084441     |   0\n",
      "       6974 |   0.199319  |    0.011075     |   0\n",
      "       6975 |   0.200475  |    0.076417     |   0\n",
      "       6976 |   0.049493  |    0.027557     |   2\n",
      "       6977 |   0.078202  |    0.054590     |   2\n",
      "       6978 |   0.179272  |    0.088131     |   0\n",
      "       6979 |   0.147168  |    0.166025     |   1\n",
      "       6980 |   0.242147  |    0.141773     |   1\n",
      "       6981 |   0.217268  |    0.134443     |   1\n",
      "       6982 |   0.239251  |    0.056473     |   0\n",
      "       6983 |   0.222333  |    0.195718     |   1\n",
      "       6984 |   0.191139  |    0.154093     |   1\n",
      "       6985 |   0.180259  |    0.010188     |   0\n",
      "       6986 |   0.064580  |    0.089088     |   2\n",
      "       6987 |   0.029350  |    0.017255     |   2\n",
      "       6988 |   0.178624  |    0.218948     |   1\n",
      "       6989 |   0.193812  |    0.160940     |   1\n",
      "       6990 |   0.300727  |    0.147259     |   1\n",
      "       6991 |   0.186130  |    0.011079     |   0\n",
      "       6992 |   0.227848  |    0.238274     |   1\n",
      "       6993 |   0.171889  |    0.105399     |   1\n",
      "       6994 |   0.163719  |    0.031124     |   0\n",
      "       6995 |   0.057937  |    0.074465     |   2\n",
      "       6996 |   0.241478  |    0.136783     |   1\n",
      "       6997 |   0.045199  |    0.044158     |   2\n",
      "       6998 |   0.000141  |    0.070715     |   2\n",
      "       6999 |   0.205131  |    0.030857     |   0\n",
      "       7000 |   0.190469  |    0.218032     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 7000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 7000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       7001 |   0.265572  |    0.223385     |   1\n",
      "       7002 |   0.073456  |    0.016142     |   2\n",
      "       7003 |   0.232885  |    0.198279     |   1\n",
      "       7004 |   0.220480  |    0.147196     |   1\n",
      "       7005 |   0.056075  |    0.025771     |   2\n",
      "       7006 |   0.055420  |    0.047553     |   2\n",
      "       7007 |   0.215086  |    0.075652     |   0\n",
      "       7008 |   0.213364  |    0.150589     |   1\n",
      "       7009 |   0.242474  |    0.026406     |   0\n",
      "       7010 |   0.069077  |    0.072003     |   2\n",
      "       7011 |   0.035583  |    0.018597     |   2\n",
      "       7012 |   0.271355  |    0.211621     |   1\n",
      "       7013 |   0.260830  |    0.132095     |   1\n",
      "       7014 |   0.292099  |    0.137889     |   1\n",
      "       7015 |   0.241031  |    0.081922     |   0\n",
      "       7016 |   0.058959  |    0.013492     |   2\n",
      "       7017 |   0.070605  |    0.045381     |   2\n",
      "       7018 |   0.068222  |    0.080833     |   2\n",
      "       7019 |   0.211994  |    0.023643     |   0\n",
      "       7020 |   0.244365  |    0.187852     |   1\n",
      "       7021 |   0.067557  |    0.003206     |   2\n",
      "       7022 |   0.206644  |    0.051277     |   0\n",
      "       7023 |   0.212664  |    0.039235     |   0\n",
      "       7024 |   0.031384  |    0.077587     |   2\n",
      "       7025 |   0.166375  |    0.031250     |   0\n",
      "       7026 |   0.258066  |    0.074627     |   0\n",
      "       7027 |   0.000142  |    0.024387     |   2\n",
      "       7028 |   0.211948  |    0.079944     |   0\n",
      "       7029 |   0.007616  |    0.018838     |   2\n",
      "       7030 |   0.175746  |    0.240009     |   1\n",
      "       7031 |   0.272291  |    0.135508     |   1\n",
      "       7032 |   0.237366  |    0.077689     |   0\n",
      "       7033 |   0.113478  |    0.029049     |   2\n",
      "       7034 |   0.047632  |    0.078867     |   2\n",
      "       7035 |   0.078680  |    0.023585     |   2\n",
      "       7036 |   0.205631  |    0.077904     |   0\n",
      "       7037 |   0.281983  |    0.025973     |   0\n",
      "       7038 |   0.062384  |    0.075210     |   2\n",
      "       7039 |   0.240302  |    0.024194     |   0\n",
      "       7040 |   0.232987  |    0.079377     |   0\n",
      "       7041 |   0.241936  |    0.014361     |   0\n",
      "       7042 |   0.028184  |    0.078001     |   2\n",
      "       7043 |   0.259147  |    0.148232     |   1\n",
      "       7044 |   0.286012  |    0.156072     |   1\n",
      "       7045 |   0.198364  |    0.045382     |   0\n",
      "       7046 |   0.222976  |    0.205908     |   1\n",
      "       7047 |   0.204081  |    0.012756     |   0\n",
      "       7048 |   0.058343  |    0.077343     |   2\n",
      "       7049 |   0.043508  |    0.024253     |   2\n",
      "       7050 |   0.000138  |    0.062750     |   2\n",
      "       7051 |   0.000140  |    0.043833     |   2\n",
      "       7052 |   0.259001  |    0.149699     |   1\n",
      "       7053 |   0.169574  |    0.049104     |   0\n",
      "       7054 |   0.206229  |    0.157923     |   1\n",
      "       7055 |   0.000148  |    0.083464     |   2\n",
      "       7056 |   0.172151  |    0.012414     |   0\n",
      "       7057 |   0.239812  |    0.225706     |   1\n",
      "       7058 |   0.239857  |    0.135753     |   1\n",
      "       7059 |   0.273836  |    0.118294     |   1\n",
      "       7060 |   0.233959  |    0.189930     |   1\n",
      "       7061 |   0.000143  |    0.030144     |   2\n",
      "       7062 |   0.262670  |    0.076143     |   0\n",
      "       7063 |   0.000140  |    0.024855     |   2\n",
      "       7064 |   0.000144  |    0.081985     |   2\n",
      "       7065 |   0.210482  |    0.067617     |   0\n",
      "       7066 |   0.336733  |    0.160379     |   1\n",
      "       7067 |   0.072962  |    0.007333     |   2\n",
      "       7068 |   0.081607  |    0.080586     |   2\n",
      "       7069 |   0.176863  |    0.196698     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 7070: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       7070 |   0.214135  |    0.090278     |   1\n",
      "       7071 |   0.073410  |    0.042295     |   2\n",
      "       7072 |   0.261718  |    0.143185     |   1\n",
      "       7073 |   0.281300  |    0.164172     |   1\n",
      "       7074 |   0.052850  |    0.070738     |   2\n",
      "       7075 |   0.054647  |    0.010375     |   2\n",
      "       7076 |   0.197090  |    0.208455     |   1\n",
      "       7077 |   0.071183  |    0.019370     |   2\n",
      "       7078 |   0.228785  |    0.193324     |   1\n",
      "       7079 |   0.203804  |    0.137464     |   1\n",
      "       7080 |   0.033919  |    0.020019     |   2\n",
      "       7081 |   0.239144  |    0.186793     |   1\n",
      "       7082 |   0.271364  |    0.080234     |   0\n",
      "       7083 |   0.234592  |    0.025516     |   0\n",
      "       7084 |   0.253526  |    0.205172     |   1\n",
      "       7085 |   0.059238  |    0.008457     |   2\n",
      "       7086 |   0.226890  |    0.077237     |   0\n",
      "       7087 |   0.208646  |    0.006420     |   0\n",
      "       7088 |   0.181167  |    0.189610     |   1\n",
      "       7089 |   0.219690  |    0.087915     |   0\n",
      "       7090 |   0.290515  |    0.126034     |   1\n",
      "       7091 |   0.221803  |    0.006061     |   0\n",
      "       7092 |   0.183280  |    0.077378     |   0\n",
      "       7093 |   0.231367  |    0.046605     |   0\n",
      "       7094 |   0.184390  |    0.041236     |   0\n",
      "       7095 |   0.209043  |    0.047488     |   0\n",
      "       7096 |   0.064000  |    0.041834     |   2\n",
      "       7097 |   0.217299  |    0.072237     |   0\n",
      "       7098 |   0.073337  |    0.031300     |   2\n",
      "       7099 |   0.069447  |    0.053021     |   2\n",
      "       7100 |   0.216334  |    0.094358     |   0\n",
      "       7101 |   0.188465  |    0.006369     |   0\n",
      "       7102 |   0.222227  |    0.082290     |   0\n",
      "       7103 |   0.224225  |    0.149865     |   1\n",
      "       7104 |   0.029815  |    0.056946     |   2\n",
      "       7105 |   0.183798  |    0.184007     |   1\n",
      "       7106 |   0.285233  |    0.138322     |   1\n",
      "       7107 |   0.000138  |    0.008596     |   2\n",
      "       7108 |   0.007422  |    0.072806     |   2\n",
      "       7109 |   0.221694  |    0.136217     |   1\n",
      "       7110 |   0.227347  |    0.048746     |   0\n",
      "       7111 |   0.204497  |    0.192869     |   1\n",
      "       7112 |   0.111854  |    0.009777     |   2\n",
      "       7113 |   0.048910  |    0.078690     |   2\n",
      "       7114 |   0.205494  |    0.152345     |   1\n",
      "       7115 |   0.187999  |    0.066417     |   0\n",
      "       7116 |   0.180036  |    0.151358     |   1\n",
      "       7117 |   0.223475  |    0.138030     |   1\n",
      "       7118 |   0.074813  |    0.026875     |   2\n",
      "       7119 |   0.212238  |    0.055564     |   0\n",
      "       7120 |   0.256194  |    0.224618     |   1\n",
      "       7121 |   0.194958  |    0.004295     |   0\n",
      "       7122 |   0.236397  |    0.145927     |   1\n",
      "       7123 |   0.253057  |    0.014533     |   0\n",
      "       7124 |   0.061822  |    0.075893     |   2\n",
      "       7125 |   0.219901  |    0.021589     |   0\n",
      "       7126 |   0.302429  |    0.206516     |   1\n",
      "       7127 |   0.026809  |    0.005267     |   2\n",
      "       7128 |   0.262459  |    0.172109     |   1\n",
      "       7129 |   0.211630  |    0.132578     |   1\n",
      "       7130 |   0.227879  |    0.027856     |   0\n",
      "       7131 |   0.224774  |    0.215967     |   1\n",
      "       7132 |   0.205583  |    0.137539     |   1\n",
      "       7133 |   0.203012  |    0.006886     |   0\n",
      "       7134 |   0.170730  |    0.046591     |   0\n",
      "       7135 |   0.216721  |    0.076076     |   0\n",
      "       7136 |   0.058060  |    0.031825     |   2\n",
      "       7137 |   0.218374  |    0.046400     |   0\n",
      "       7138 |   0.239013  |    0.161910     |   1\n",
      "       7139 |   0.200759  |    0.041042     |   0\n",
      "       7140 |   0.243476  |    0.198928     |   1\n",
      "       7141 |   0.043758  |    0.016716     |   2\n",
      "       7142 |   0.000137  |    0.082473     |   2\n",
      "       7143 |   0.000138  |    0.021928     |   2\n",
      "       7144 |   0.000147  |    0.048726     |   2\n",
      "       7145 |   0.000139  |    0.074382     |   2\n",
      "       7146 |   0.210569  |    0.012502     |   0\n",
      "       7147 |   0.187611  |    0.077765     |   0\n",
      "       7148 |   0.177454  |    0.024390     |   0\n",
      "       7149 |   0.196776  |    0.044142     |   0\n",
      "       7150 |   0.225576  |    0.076613     |   0\n",
      "       7151 |   0.000138  |    0.008954     |   2\n",
      "       7152 |   0.000142  |    0.080187     |   2\n",
      "       7153 |   0.072636  |    0.017021     |   2\n",
      "       7154 |   0.211028  |    0.089434     |   0\n",
      "       7155 |   0.081588  |    0.012921     |   2\n",
      "       7156 |   0.221426  |    0.077893     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 7157: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       7157 |   0.250297  |    0.148488     |   1\n",
      "       7158 |   0.274603  |    0.153033     |   1\n",
      "       7159 |   0.219611  |    0.015529     |   0\n",
      "       7160 |   0.189740  |    0.075001     |   0\n",
      "       7161 |   0.225094  |    0.013460     |   0\n",
      "       7162 |   0.237163  |    0.046256     |   0\n",
      "       7163 |   0.079550  |    0.042798     |   2\n",
      "       7164 |   0.246677  |    0.076185     |   0\n",
      "       7165 |   0.235496  |    0.029970     |   0\n",
      "       7166 |   0.054976  |    0.040246     |   2\n",
      "       7167 |   0.258055  |    0.168518     |   1\n",
      "       7168 |   0.297870  |    0.162136     |   1\n",
      "       7169 |   0.239027  |    0.157848     |   1\n",
      "       7170 |   0.057394  |    0.028180     |   2\n",
      "       7171 |   0.215844  |    0.226286     |   1\n",
      "       7172 |   0.208756  |    0.003234     |   0\n",
      "       7173 |   0.201531  |    0.142920     |   1\n",
      "       7174 |   0.072178  |    0.043152     |   2\n",
      "       7175 |   0.034960  |    0.078089     |   2\n",
      "       7176 |   0.223764  |    0.023763     |   0\n",
      "       7177 |   0.059904  |    0.079369     |   2\n",
      "       7178 |   0.065717  |    0.027175     |   2\n",
      "       7179 |   0.217992  |    0.192064     |   1\n",
      "       7180 |   0.241111  |    0.139578     |   1\n",
      "       7181 |   0.240000  |    0.027780     |   0\n",
      "       7182 |   0.209065  |    0.080161     |   0\n",
      "       7183 |   0.070693  |    0.007193     |   2\n",
      "       7184 |   0.064956  |    0.082933     |   2\n",
      "       7185 |   0.274299  |    0.043421     |   0\n",
      "       7186 |   0.030204  |    0.051114     |   2\n",
      "       7187 |   0.176457  |    0.047035     |   0\n",
      "       7188 |   0.221759  |    0.052525     |   0\n",
      "       7189 |   0.180205  |    0.029436     |   0\n",
      "       7190 |   0.231608  |    0.058540     |   0\n",
      "       7191 |   0.275093  |    0.147626     |   1\n",
      "       7192 |   0.000138  |    0.046122     |   2\n",
      "       7193 |   0.270806  |    0.148714     |   1\n",
      "       7194 |   0.007213  |    0.028500     |   2\n",
      "       7195 |   0.272881  |    0.198221     |   1\n",
      "       7196 |   0.215391  |    0.147650     |   1\n",
      "       7197 |   0.163223  |    0.017148     |   0\n",
      "       7198 |   0.108855  |    0.084387     |   2\n",
      "       7199 |   0.050107  |    0.011791     |   2\n",
      "       7200 |   0.260837  |    0.209777     |   1\n",
      "       7201 |   0.211214  |    0.163386     |   1\n",
      "       7202 |   0.235452  |    0.003581     |   0\n",
      "       7203 |   0.306738  |    0.165995     |   1\n",
      "       7204 |   0.190114  |    0.020814     |   0\n",
      "       7205 |   0.075291  |    0.088107     |   2\n",
      "       7206 |   0.268757  |    0.142958     |   1\n",
      "       7207 |   0.060094  |    0.043197     |   2\n",
      "       7208 |   0.027105  |    0.046936     |   2\n",
      "       7209 |   0.196277  |    0.046243     |   0\n",
      "       7210 |   0.226921  |    0.083659     |   0\n",
      "       7211 |   0.180153  |    0.010619     |   0\n",
      "       7212 |   0.264473  |    0.056293     |   0\n",
      "       7213 |   0.278477  |    0.146315     |   1\n",
      "       7214 |   0.055200  |    0.029011     |   2\n",
      "       7215 |   0.324489  |    0.202739     |   1\n",
      "       7216 |   0.202505  |    0.016820     |   0\n",
      "       7217 |   0.259504  |    0.035800     |   0\n",
      "       7218 |   0.240924  |    0.164424     |   1\n",
      "       7219 |   0.204529  |    0.145594     |   1\n",
      "       7220 |   0.176148  |    0.024982     |   0\n",
      "       7221 |   0.249566  |    0.201745     |   1\n",
      "       7222 |   0.198155  |    0.005068     |   0\n",
      "       7223 |   0.203723  |    0.187326     |   1\n",
      "       7224 |   0.269913  |    0.003959     |   0\n",
      "       7225 |   0.228036  |    0.081908     |   0\n",
      "       7226 |   0.043114  |    0.008804     |   2\n",
      "       7227 |   0.299184  |    0.073646     |   0\n",
      "       7228 |   0.000135  |    0.042628     |   2\n",
      "       7229 |   0.000135  |    0.037392     |   2\n",
      "       7230 |   0.285377  |    0.189882     |   1\n",
      "       7231 |   0.000144  |    0.005807     |   2\n",
      "       7232 |   0.188189  |    0.038089     |   0\n",
      "       7233 |   0.209108  |    0.078229     |   0\n",
      "       7234 |   0.214194  |    0.031122     |   0\n",
      "       7235 |   0.220240  |    0.075563     |   0\n",
      "       7236 |   0.000136  |    0.018958     |   2\n",
      "       7237 |   0.218274  |    0.176473     |   1\n",
      "       7238 |   0.236218  |    0.073666     |   0\n",
      "       7239 |   0.000135  |    0.037643     |   2\n",
      "       7240 |   0.000139  |    0.046793     |   2\n",
      "       7241 |   0.075927  |    0.025969     |   2\n",
      "       7242 |   0.221337  |    0.041944     |   0\n",
      "       7243 |   0.219781  |    0.043371     |   0\n",
      "       7244 |   0.081455  |    0.089119     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 7245: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       7245 |   0.206183  |    0.141114     |   1\n",
      "       7246 |   0.079090  |    0.025682     |   2\n",
      "       7247 |   0.055470  |    0.087920     |   2\n",
      "       7248 |   0.232951  |    0.132024     |   1\n",
      "       7249 |   0.286784  |    0.173315     |   1\n",
      "       7250 |   0.303828  |    0.150858     |   1\n",
      "       7251 |   0.159710  |    0.194781     |   1\n",
      "       7252 |   0.057217  |    0.009328     |   2\n",
      "       7253 |   0.205633  |    0.080764     |   0\n",
      "       7254 |   0.208116  |    0.013739     |   0\n",
      "       7255 |   0.213861  |    0.087785     |   0\n",
      "       7256 |   0.070433  |    0.017506     |   2\n",
      "       7257 |   0.262260  |    0.197380     |   1\n",
      "       7258 |   0.035016  |    0.003738     |   2\n",
      "       7259 |   0.184528  |    0.079357     |   0\n",
      "       7260 |   0.060384  |    0.015579     |   2\n",
      "       7261 |   0.070806  |    0.050688     |   2\n",
      "       7262 |   0.237731  |    0.075140     |   0\n",
      "       7263 |   0.200028  |    0.155194     |   1\n",
      "       7264 |   0.252071  |    0.131416     |   1\n",
      "       7265 |   0.227241  |    0.023059     |   0\n",
      "       7266 |   0.236735  |    0.077086     |   0\n",
      "       7267 |   0.195929  |    0.016188     |   0\n",
      "       7268 |   0.234791  |    0.220521     |   1\n",
      "       7269 |   0.070651  |    0.006389     |   2\n",
      "       7270 |   0.231150  |    0.077552     |   0\n",
      "       7271 |   0.177466  |    0.016822     |   0\n",
      "       7272 |   0.069550  |    0.073074     |   2\n",
      "       7273 |   0.165641  |    0.037698     |   0\n",
      "       7274 |   0.206009  |    0.184832     |   1\n",
      "       7275 |   0.030148  |    0.041147     |   2\n",
      "       7276 |   0.157888  |    0.056109     |   0\n",
      "       7277 |   0.234554  |    0.176833     |   1\n",
      "       7278 |   0.000136  |    0.007541     |   2\n",
      "       7279 |   0.246057  |    0.075717     |   0\n",
      "       7280 |   0.190015  |    0.020731     |   0\n",
      "       7281 |   0.216408  |    0.212283     |   1\n",
      "       7282 |   0.261393  |    0.095241     |   1\n",
      "       7283 |   0.166048  |    0.048453     |   0\n",
      "       7284 |   0.007254  |    0.027396     |   2\n",
      "       7285 |   0.226763  |    0.085993     |   0\n",
      "       7286 |   0.221431  |    0.138090     |   1\n",
      "       7287 |   0.110628  |    0.054737     |   2\n",
      "       7288 |   0.048833  |    0.042325     |   2\n",
      "       7289 |   0.272904  |    0.076212     |   0\n",
      "       7290 |   0.195071  |    0.017283     |   0\n",
      "       7291 |   0.078092  |    0.079369     |   2\n",
      "       7292 |   0.060970  |    0.012485     |   2\n",
      "       7293 |   0.235429  |    0.203444     |   1\n",
      "       7294 |   0.027191  |    0.004966     |   2\n",
      "       7295 |   0.259088  |    0.074733     |   0\n",
      "       7296 |   0.235070  |    0.189669     |   1\n",
      "       7297 |   0.059494  |    0.039718     |   2\n",
      "       7298 |   0.267632  |    0.073352     |   0\n",
      "       7299 |   0.249875  |    0.011638     |   0\n",
      "       7300 |   0.043430  |    0.075395     |   2\n",
      "       7301 |   0.221504  |    0.030857     |   0\n",
      "       7302 |   0.000134  |    0.053226     |   2\n",
      "       7303 |   0.000135  |    0.041724     |   2\n",
      "       7304 |   0.000144  |    0.050734     |   2\n",
      "       7305 |   0.224183  |    0.080490     |   0\n",
      "       7306 |   0.000137  |    0.014415     |   2\n",
      "       7307 |   0.000136  |    0.079368     |   2\n",
      "       7308 |   0.196778  |    0.014123     |   0\n",
      "       7309 |   0.253849  |    0.072777     |   0\n",
      "       7310 |   0.189699  |    0.034045     |   0\n",
      "       7311 |   0.258119  |    0.077085     |   0\n",
      "       7312 |   0.240304  |    0.044453     |   0\n",
      "       7313 |   0.209415  |    0.146768     |   1\n",
      "       7314 |   0.201958  |    0.025132     |   0\n",
      "       7315 |   0.187669  |    0.044206     |   0\n",
      "       7316 |   0.236631  |    0.042540     |   0\n",
      "       7317 |   0.211773  |    0.199126     |   1\n",
      "       7318 |   0.000138  |    0.007430     |   2\n",
      "       7319 |   0.076844  |    0.054230     |   2\n",
      "       7320 |   0.082180  |    0.070852     |   2\n",
      "       7321 |   0.249465  |    0.138295     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 7323: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       7322 |   0.203214  |    0.016486     |   0\n",
      "       7323 |   0.083560  |    0.033449     |   2\n",
      "       7324 |   0.153262  |    0.045194     |   0\n",
      "       7325 |   0.055859  |    0.081055     |   2\n",
      "       7326 |   0.250030  |    0.148028     |   1\n",
      "       7327 |   0.056504  |    0.009613     |   2\n",
      "       7328 |   0.071939  |    0.080607     |   2\n",
      "       7329 |   0.154305  |    0.008103     |   0\n",
      "       7330 |   0.267211  |    0.192408     |   1\n",
      "       7331 |   0.201960  |    0.011942     |   0\n",
      "       7332 |   0.274073  |    0.193138     |   1\n",
      "       7333 |   0.036241  |    0.007427     |   2\n",
      "       7334 |   0.161436  |    0.056231     |   0\n",
      "       7335 |   0.222490  |    0.033902     |   0\n",
      "       7336 |   0.059887  |    0.044245     |   2\n",
      "       7337 |   0.070439  |    0.051842     |   2\n",
      "       7338 |   0.216540  |    0.053052     |   0\n",
      "       7339 |   0.248208  |    0.198226     |   1\n",
      "       7340 |   0.223459  |    0.004932     |   0\n",
      "       7341 |   0.253979  |    0.047880     |   0\n",
      "       7342 |   0.073787  |    0.046390     |   2\n",
      "       7343 |   0.069093  |    0.016640     |   2\n",
      "       7344 |   0.226319  |    0.092353     |   0\n",
      "       7345 |   0.199318  |    0.148327     |   1\n",
      "       7346 |   0.030698  |    0.016892     |   2\n",
      "       7347 |   0.235275  |    0.204323     |   1\n",
      "       7348 |   0.247921  |    0.198680     |   1\n",
      "       7349 |   0.000136  |    0.005424     |   2\n",
      "       7350 |   0.222290  |    0.153178     |   1\n",
      "       7351 |   0.007592  |    0.039041     |   2\n",
      "       7352 |   0.198003  |    0.074732     |   0\n",
      "       7353 |   0.136451  |    0.165539     |   1\n",
      "       7354 |   0.249248  |    0.158518     |   1\n",
      "       7355 |   0.108023  |    0.028019     |   2\n",
      "       7356 |   0.188101  |    0.071988     |   0\n",
      "       7357 |   0.048399  |    0.044966     |   2\n",
      "       7358 |   0.284170  |    0.168098     |   1\n",
      "       7359 |   0.075353  |    0.038917     |   2\n",
      "       7360 |   0.060006  |    0.045655     |   2\n",
      "       7361 |   0.208931  |    0.083420     |   0\n",
      "       7362 |   0.025654  |    0.016550     |   2\n",
      "       7363 |   0.251819  |    0.194229     |   1\n",
      "       7364 |   0.176445  |    0.029866     |   0\n",
      "       7365 |   0.193242  |    0.080635     |   0\n",
      "       7366 |   0.205940  |    0.029760     |   0\n",
      "       7367 |   0.195447  |    0.223564     |   1\n",
      "       7368 |   0.263775  |    0.100105     |   1\n",
      "       7369 |   0.180260  |    0.039919     |   0\n",
      "       7370 |   0.186980  |    0.074621     |   0\n",
      "       7371 |   0.189786  |    0.005977     |   0\n",
      "       7372 |   0.055201  |    0.094084     |   2\n",
      "       7373 |   0.044259  |    0.020077     |   2\n",
      "       7374 |   0.174248  |    0.212130     |   1\n",
      "       7375 |   0.000134  |    0.010454     |   2\n",
      "       7376 |   0.000135  |    0.046244     |   2\n",
      "       7377 |   0.000140  |    0.029371     |   2\n",
      "       7378 |   0.000136  |    0.075381     |   2\n",
      "       7379 |   0.000135  |    0.012289     |   2\n",
      "       7380 |   0.299496  |    0.092314     |   0\n",
      "       7381 |   0.205653  |    0.156617     |   1\n",
      "       7382 |   0.000137  |    0.016803     |   2\n",
      "       7383 |   0.263757  |    0.194855     |   1\n",
      "       7384 |   0.217343  |    0.169766     |   1\n",
      "       7385 |   0.195340  |    0.130673     |   1\n",
      "       7386 |   0.137502  |    0.054266     |   0\n",
      "       7387 |   0.213342  |    0.177268     |   1\n",
      "       7388 |   0.225410  |    0.003587     |   0\n",
      "       7389 |   0.280990  |    0.191942     |   1\n",
      "       7390 |   0.174030  |    0.004430     |   0\n",
      "       7391 |   0.070566  |    0.073653     |   2\n",
      "       7392 |   0.154806  |    0.029256     |   0\n",
      "       7393 |   0.199137  |    0.057167     |   0\n",
      "       7394 |   0.214814  |    0.144353     |   1\n",
      "       7395 |   0.159386  |    0.043739     |   0\n",
      "       7396 |   0.081495  |    0.050231     |   2\n",
      "       7397 |   0.265976  |    0.156005     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 7398: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       7398 |   0.074642  |    0.010761     |   2\n",
      "       7399 |   0.171507  |    0.073852     |   0\n",
      "       7400 |   0.273439  |    0.154128     |   1\n",
      "       7401 |   0.241326  |    0.089279     |   1\n",
      "       7402 |   0.053823  |    0.072813     |   2\n",
      "       7403 |   0.218880  |    0.027025     |   0\n",
      "       7404 |   0.054336  |    0.057181     |   2\n",
      "       7405 |   0.070019  |    0.040862     |   2\n",
      "       7406 |   0.277174  |    0.200516     |   1\n",
      "       7407 |   0.192670  |    0.013955     |   0\n",
      "       7408 |   0.217736  |    0.023942     |   0\n",
      "       7409 |   0.202939  |    0.046705     |   0\n",
      "       7410 |   0.267396  |    0.161141     |   1\n",
      "       7411 |   0.183351  |    0.139177     |   1\n",
      "       7412 |   0.260825  |    0.158665     |   1\n",
      "       7413 |   0.035483  |    0.013518     |   2\n",
      "       7414 |   0.059108  |    0.084237     |   2\n",
      "       7415 |   0.070997  |    0.016002     |   2\n",
      "       7416 |   0.188007  |    0.076907     |   0\n",
      "       7417 |   0.069251  |    0.019129     |   2\n",
      "       7418 |   0.067606  |    0.082678     |   2\n",
      "       7419 |   0.324027  |    0.150697     |   1\n",
      "       7420 |   0.030665  |    0.007898     |   2\n",
      "       7421 |   0.199544  |    0.041691     |   0\n",
      "       7422 |   0.181603  |    0.061034     |   0\n",
      "       7423 |   0.238151  |    0.148387     |   1\n",
      "       7424 |   0.263407  |    0.164647     |   1\n",
      "       7425 |   0.227762  |    0.041873     |   0\n",
      "       7426 |   0.201021  |    0.041608     |   0\n",
      "       7427 |   0.000134  |    0.085985     |   2\n",
      "       7428 |   0.006997  |    0.005698     |   2\n",
      "       7429 |   0.228474  |    0.086038     |   0\n",
      "       7430 |   0.256634  |    0.151477     |   1\n",
      "       7431 |   0.248941  |    0.151023     |   1\n",
      "       7432 |   0.240122  |    0.161194     |   1\n",
      "       7433 |   0.136788  |    0.007513     |   0\n",
      "       7434 |   0.237828  |    0.043917     |   0\n",
      "       7435 |   0.228924  |    0.028243     |   0\n",
      "       7436 |   0.110244  |    0.046600     |   2\n",
      "       7437 |   0.048116  |    0.045010     |   2\n",
      "       7438 |   0.077420  |    0.063204     |   2\n",
      "       7439 |   0.180305  |    0.202984     |   1\n",
      "       7440 |   0.057672  |    0.004102     |   2\n",
      "       7441 |   0.212028  |    0.041135     |   0\n",
      "       7442 |   0.171315  |    0.084682     |   0\n",
      "       7443 |   0.212280  |    0.150144     |   1\n",
      "       7444 |   0.166119  |    0.030514     |   0\n",
      "       7445 |   0.024931  |    0.076201     |   2\n",
      "       7446 |   0.255290  |    0.146067     |   1\n",
      "       7447 |   0.057223  |    0.018913     |   2\n",
      "       7448 |   0.235079  |    0.078675     |   0\n",
      "       7449 |   0.207567  |    0.023432     |   0\n",
      "       7450 |   0.210467  |    0.216378     |   1\n",
      "       7451 |   0.230963  |    0.005480     |   0\n",
      "       7452 |   0.043091  |    0.085150     |   2\n",
      "       7453 |   0.230737  |    0.159199     |   1\n",
      "       7454 |   0.150931  |    0.061450     |   0\n",
      "       7455 |   0.245357  |    0.168663     |   1\n",
      "       7456 |   0.222657  |    0.007456     |   0\n",
      "       7457 |   0.000133  |    0.048547     |   2\n",
      "       7458 |   0.221931  |    0.047263     |   0\n",
      "       7459 |   0.247358  |    0.074850     |   0\n",
      "       7460 |   0.173830  |    0.010371     |   0\n",
      "       7461 |   0.000133  |    0.075956     |   2\n",
      "       7462 |   0.198600  |    0.013134     |   0\n",
      "       7463 |   0.000137  |    0.052063     |   2\n",
      "       7464 |   0.000134  |    0.046982     |   2\n",
      "       7465 |   0.000133  |    0.046196     |   2\n",
      "       7466 |   0.000135  |    0.048568     |   2\n",
      "       7467 |   0.074358  |    0.025850     |   2\n",
      "       7468 |   0.246706  |    0.196908     |   1\n",
      "       7469 |   0.168729  |    0.015397     |   0\n",
      "       7470 |   0.080799  |    0.080484     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 7471: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       7471 |   0.074175  |    0.022053     |   2\n",
      "       7472 |   0.196133  |    0.074710     |   0\n",
      "       7473 |   0.051904  |    0.014956     |   2\n",
      "       7474 |   0.054414  |    0.077504     |   2\n",
      "       7475 |   0.204787  |    0.046652     |   0\n",
      "       7476 |   0.225406  |    0.058592     |   0\n",
      "       7477 |   0.228761  |    0.186857     |   1\n",
      "       7478 |   0.284213  |    0.138098     |   1\n",
      "       7479 |   0.067952  |    0.012279     |   2\n",
      "       7480 |   0.034958  |    0.053078     |   2\n",
      "       7481 |   0.058544  |    0.052392     |   2\n",
      "       7482 |   0.146306  |    0.215666     |   1\n",
      "       7483 |   0.253889  |    0.140825     |   1\n",
      "       7484 |   0.068542  |    0.020120     |   2\n",
      "       7485 |   0.203388  |    0.204223     |   1\n",
      "       7486 |   0.068171  |    0.020843     |   2\n",
      "       7487 |   0.239905  |    0.189733     |   1\n",
      "       7488 |   0.063844  |    0.005499     |   2\n",
      "       7489 |   0.029944  |    0.047425     |   2\n",
      "       7490 |   0.238657  |    0.051282     |   0\n",
      "       7491 |   0.289402  |    0.160790     |   1\n",
      "       7492 |   0.209338  |    0.038955     |   0\n",
      "       7493 |   0.176140  |    0.216337     |   1\n",
      "       7494 |   0.000133  |    0.021909     |   2\n",
      "       7495 |   0.179525  |    0.199850     |   1\n",
      "       7496 |   0.262666  |    0.144443     |   1\n",
      "       7497 |   0.006920  |    0.025659     |   2\n",
      "       7498 |   0.107731  |    0.044896     |   2\n",
      "       7499 |   0.131506  |    0.073633     |   0\n",
      "       7500 |   0.047162  |    0.008181     |   2\n",
      "       7501 |   0.068088  |    0.081653     |   2\n",
      "       7502 |   0.260857  |    0.044857     |   0\n",
      "       7503 |   0.288213  |    0.151175     |   1\n",
      "       7504 |   0.049100  |    0.021505     |   2\n",
      "       7505 |   0.053596  |    0.080806     |   2\n",
      "       7506 |   0.067399  |    0.030111     |   2\n",
      "       7507 |   0.033033  |    0.085921     |   2\n",
      "       7508 |   0.219651  |    0.132978     |   1\n",
      "       7509 |   0.207794  |    0.045714     |   0\n",
      "       7510 |   0.197871  |    0.054637     |   0\n",
      "       7511 |   0.232802  |    0.200229     |   1\n",
      "       7512 |   0.224591  |    0.155354     |   1\n",
      "       7513 |   0.321318  |    0.091093     |   1\n",
      "       7514 |   0.247028  |    0.182952     |   1\n",
      "       7515 |   0.202271  |    0.139605     |   1\n",
      "       7516 |   0.203928  |    0.197761     |   1\n",
      "       7517 |   0.057182  |    0.010741     |   2\n",
      "       7518 |   0.064972  |    0.047661     |   2\n",
      "       7519 |   0.067821  |    0.054129     |   2\n",
      "       7520 |   0.064903  |    0.043778     |   2\n",
      "       7521 |   0.030170  |    0.045523     |   2\n",
      "       7522 |   0.210755  |    0.082161     |   0\n",
      "       7523 |   0.189606  |    0.133243     |   1\n",
      "       7524 |   0.163758  |    0.040634     |   0\n",
      "       7525 |   0.235483  |    0.044207     |   0\n",
      "       7526 |   0.299767  |    0.074708     |   0\n",
      "       7527 |   0.000130  |    0.034544     |   2\n",
      "       7528 |   0.153035  |    0.213758     |   1\n",
      "       7529 |   0.006805  |    0.022570     |   2\n",
      "       7530 |   0.194066  |    0.050394     |   0\n",
      "       7531 |   0.104905  |    0.074397     |   2\n",
      "       7532 |   0.047263  |    0.023193     |   2\n",
      "       7533 |   0.224893  |    0.088731     |   0\n",
      "       7534 |   0.074078  |    0.027131     |   2\n",
      "       7535 |   0.199117  |    0.047484     |   0\n",
      "       7536 |   0.234909  |    0.045850     |   0\n",
      "       7537 |   0.185765  |    0.046912     |   0\n",
      "       7538 |   0.057290  |    0.041646     |   2\n",
      "       7539 |   0.026912  |    0.072117     |   2\n",
      "       7540 |   0.266201  |    0.153634     |   1\n",
      "       7541 |   0.282355  |    0.186641     |   1\n",
      "       7542 |   0.238857  |    0.008759     |   0\n",
      "       7543 |   0.170651  |    0.041112     |   0\n",
      "       7544 |   0.311615  |    0.192663     |   1\n",
      "       7545 |   0.148507  |    0.142421     |   1\n",
      "       7546 |   0.058358  |    0.029048     |   2\n",
      "       7547 |   0.042603  |    0.087504     |   2\n",
      "       7548 |   0.240329  |    0.153615     |   1\n",
      "       7549 |   0.000129  |    0.017350     |   2\n",
      "       7550 |   0.254898  |    0.076536     |   0\n",
      "       7551 |   0.176890  |    0.023229     |   0\n",
      "       7552 |   0.000129  |    0.084638     |   2\n",
      "       7553 |   0.235796  |    0.144090     |   1\n",
      "       7554 |   0.259805  |    0.163978     |   1\n",
      "       7555 |   0.268684  |    0.163025     |   1\n",
      "       7556 |   0.000135  |    0.046476     |   2\n",
      "       7557 |   0.000131  |    0.048181     |   2\n",
      "       7558 |   0.000130  |    0.044235     |   2\n",
      "       7559 |   0.186824  |    0.057544     |   0\n",
      "       7560 |   0.191702  |    0.144116     |   1\n",
      "       7561 |   0.198233  |    0.044436     |   0\n",
      "       7562 |   0.000133  |    0.042477     |   2\n",
      "       7563 |   0.255240  |    0.045067     |   0\n",
      "       7564 |   0.223497  |    0.041037     |   0\n",
      "       7565 |   0.214877  |    0.072531     |   0\n",
      "       7566 |   0.193170  |    0.044481     |   0\n",
      "       7567 |   0.179435  |    0.040878     |   0\n",
      "       7568 |   0.191641  |    0.043070     |   0\n",
      "       7569 |   0.070334  |    0.044640     |   2\n",
      "       7570 |   0.079186  |    0.047569     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 7571: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       7571 |   0.238565  |    0.151117     |   1\n",
      "       7572 |   0.076364  |    0.028733     |   2\n",
      "       7573 |   0.053458  |    0.049981     |   2\n",
      "       7574 |   0.290776  |    0.146215     |   1\n",
      "       7575 |   0.240360  |    0.076436     |   0\n",
      "       7576 |   0.054100  |    0.052087     |   2\n",
      "       7577 |   0.068296  |    0.038403     |   2\n",
      "       7578 |   0.033927  |    0.041936     |   2\n",
      "       7579 |   0.243944  |    0.194802     |   1\n",
      "       7580 |   0.213855  |    0.023750     |   0\n",
      "       7581 |   0.059582  |    0.077386     |   2\n",
      "       7582 |   0.066455  |    0.027601     |   2\n",
      "       7583 |   0.247508  |    0.078878     |   0\n",
      "       7584 |   0.236514  |    0.017694     |   0\n",
      "       7585 |   0.221999  |    0.075801     |   0\n",
      "       7586 |   0.231310  |    0.136709     |   1\n",
      "       7587 |   0.241872  |    0.207281     |   1\n",
      "       7588 |   0.149609  |    0.013940     |   0\n",
      "       7589 |   0.259580  |    0.044050     |   0\n",
      "       7590 |   0.069772  |    0.043113     |   2\n",
      "       7591 |   0.068257  |    0.047614     |   2\n",
      "       7592 |   0.176157  |    0.135417     |   1\n",
      "       7593 |   0.031878  |    0.077265     |   2\n",
      "       7594 |   0.212158  |    0.024393     |   0\n",
      "       7595 |   0.000130  |    0.050440     |   2\n",
      "       7596 |   0.252931  |    0.205678     |   1\n",
      "       7597 |   0.006460  |    0.003270     |   2\n",
      "       7598 |   0.108057  |    0.084057     |   2\n",
      "       7599 |   0.187535  |    0.017666     |   0\n",
      "       7600 |   0.050780  |    0.078897     |   2\n",
      "       7601 |   0.074852  |    0.022496     |   2\n",
      "       7602 |   0.223390  |    0.076956     |   0\n",
      "       7603 |   0.216639  |    0.027938     |   0\n",
      "       7604 |   0.058690  |    0.081880     |   2\n",
      "       7605 |   0.217659  |    0.199323     |   1\n",
      "       7606 |   0.026677  |    0.003851     |   2\n",
      "       7607 |   0.208932  |    0.205689     |   1\n",
      "       7608 |   0.059279  |    0.005308     |   2\n",
      "       7609 |   0.042155  |    0.100708     |   2\n",
      "       7610 |   0.262927  |    0.161458     |   1\n",
      "       7611 |   0.278103  |    0.103088     |   1\n",
      "       7612 |   0.233883  |    0.172994     |   1\n",
      "       7613 |   0.180229  |    0.018503     |   0\n",
      "       7614 |   0.263996  |    0.135575     |   1\n",
      "       7615 |   0.000129  |    0.047037     |   2\n",
      "       7616 |   0.000129  |    0.030287     |   2\n",
      "       7617 |   0.204480  |    0.201726     |   1\n",
      "       7618 |   0.272847  |    0.045501     |   0\n",
      "       7619 |   0.203772  |    0.046005     |   0\n",
      "       7620 |   0.228755  |    0.042870     |   0\n",
      "       7621 |   0.000135  |    0.072566     |   2\n",
      "       7622 |   0.000131  |    0.019727     |   2\n",
      "       7623 |   0.000130  |    0.084562     |   2\n",
      "       7624 |   0.000131  |    0.027011     |   2\n",
      "       7625 |   0.228051  |    0.073320     |   0\n",
      "       7626 |   0.071711  |    0.021761     |   2\n",
      "       7627 |   0.078588  |    0.054653     |   2\n",
      "       7628 |   0.206335  |    0.215299     |   1\n",
      "       7629 |   0.258907  |    0.132479     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 7631: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       7630 |   0.234871  |    0.030479     |   0\n",
      "       7631 |   0.231061  |    0.185365     |   1\n",
      "       7632 |   0.133874  |    0.006286     |   0\n",
      "       7633 |   0.242977  |    0.076729     |   0\n",
      "       7634 |   0.204611  |    0.049684     |   0\n",
      "       7635 |   0.072275  |    0.038910     |   2\n",
      "       7636 |   0.237383  |    0.200117     |   1\n",
      "       7637 |   0.218647  |    0.164342     |   1\n",
      "       7638 |   0.052030  |    0.003474     |   2\n",
      "       7639 |   0.285653  |    0.127661     |   1\n",
      "       7640 |   0.053852  |    0.047364     |   2\n",
      "       7641 |   0.260234  |    0.073755     |   0\n",
      "       7642 |   0.067654  |    0.040027     |   2\n",
      "       7643 |   0.033476  |    0.083391     |   2\n",
      "       7644 |   0.059435  |    0.008246     |   2\n",
      "       7645 |   0.063879  |    0.080885     |   2\n",
      "       7646 |   0.070056  |    0.008387     |   2\n",
      "       7647 |   0.063936  |    0.087374     |   2\n",
      "       7648 |   0.198838  |    0.047581     |   0\n",
      "       7649 |   0.268057  |    0.179489     |   1\n",
      "       7650 |   0.208878  |    0.158906     |   1\n",
      "       7651 |   0.273115  |    0.093009     |   1\n",
      "       7652 |   0.030265  |    0.057964     |   2\n",
      "       7653 |   0.314770  |    0.177693     |   1\n",
      "       7654 |   0.223580  |    0.142575     |   1\n",
      "       7655 |   0.203912  |    0.074903     |   0\n",
      "       7656 |   0.255729  |    0.043111     |   0\n",
      "       7657 |   0.000129  |    0.047147     |   2\n",
      "       7658 |   0.195985  |    0.043518     |   0\n",
      "       7659 |   0.192283  |    0.047919     |   0\n",
      "       7660 |   0.214285  |    0.043263     |   0\n",
      "       7661 |   0.006619  |    0.048637     |   2\n",
      "       7662 |   0.266718  |    0.131476     |   1\n",
      "       7663 |   0.104477  |    0.077827     |   2\n",
      "       7664 |   0.048903  |    0.023723     |   2\n",
      "       7665 |   0.075154  |    0.053901     |   2\n",
      "       7666 |   0.179979  |    0.032624     |   0\n",
      "       7667 |   0.154580  |    0.048011     |   0\n",
      "       7668 |   0.211559  |    0.194835     |   1\n",
      "       7669 |   0.219854  |    0.154635     |   1\n",
      "       7670 |   0.213000  |    0.011217     |   0\n",
      "       7671 |   0.339481  |    0.144151     |   1\n",
      "       7672 |   0.222720  |    0.041604     |   0\n",
      "       7673 |   0.055543  |    0.045445     |   2\n",
      "       7674 |   0.026451  |    0.074288     |   2\n",
      "       7675 |   0.279180  |    0.148004     |   1\n",
      "       7676 |   0.174229  |    0.043926     |   0\n",
      "       7677 |   0.057780  |    0.043926     |   2\n",
      "       7678 |   0.042681  |    0.045457     |   2\n",
      "       7679 |   0.178805  |    0.056503     |   0\n",
      "       7680 |   0.265218  |    0.185368     |   1\n",
      "       7681 |   0.000127  |    0.007845     |   2\n",
      "       7682 |   0.000128  |    0.082057     |   2\n",
      "       7683 |   0.000132  |    0.021448     |   2\n",
      "       7684 |   0.194041  |    0.088310     |   0\n",
      "       7685 |   0.279873  |    0.149376     |   1\n",
      "       7686 |   0.000129  |    0.003825     |   2\n",
      "       7687 |   0.181594  |    0.193229     |   1\n",
      "       7688 |   0.205243  |    0.020449     |   0\n",
      "       7689 |   0.000128  |    0.054669     |   2\n",
      "       7690 |   0.334794  |    0.154388     |   1\n",
      "       7691 |   0.000131  |    0.037339     |   2\n",
      "       7692 |   0.231151  |    0.043493     |   0\n",
      "       7693 |   0.068602  |    0.035298     |   2\n",
      "       7694 |   0.075913  |    0.045559     |   2\n",
      "       7695 |   0.196661  |    0.154799     |   1\n",
      "       7696 |   0.212768  |    0.042511     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 7697: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       7697 |   0.233976  |    0.184186     |   1\n",
      "       7698 |   0.071243  |    0.006162     |   2\n",
      "       7699 |   0.050056  |    0.051363     |   2\n",
      "       7700 |   0.203605  |    0.075535     |   0\n",
      "       7701 |   0.053774  |    0.017121     |   2\n",
      "       7702 |   0.221775  |    0.202321     |   1\n",
      "       7703 |   0.183001  |    0.009156     |   0\n",
      "       7704 |   0.165428  |    0.057828     |   0\n",
      "       7705 |   0.239982  |    0.145919     |   1\n",
      "       7706 |   0.186473  |    0.009846     |   0\n",
      "       7707 |   0.068551  |    0.083883     |   2\n",
      "       7708 |   0.245621  |    0.160876     |   1\n",
      "       7709 |   0.220763  |    0.162338     |   1\n",
      "       7710 |   0.187713  |    0.007265     |   0\n",
      "       7711 |   0.186926  |    0.074736     |   0\n",
      "       7712 |   0.034086  |    0.011108     |   2\n",
      "       7713 |   0.169734  |    0.226021     |   1\n",
      "       7714 |   0.058652  |    0.013071     |   2\n",
      "       7715 |   0.065584  |    0.086990     |   2\n",
      "       7716 |   0.203167  |    0.011635     |   0\n",
      "       7717 |   0.073011  |    0.082362     |   2\n",
      "       7718 |   0.061442  |    0.033889     |   2\n",
      "       7719 |   0.244752  |    0.212081     |   1\n",
      "       7720 |   0.162178  |    0.003761     |   0\n",
      "       7721 |   0.030874  |    0.061136     |   2\n",
      "       7722 |   0.148004  |    0.205472     |   1\n",
      "       7723 |   0.237751  |    0.016764     |   0\n",
      "       7724 |   0.225517  |    0.163871     |   1\n",
      "       7725 |   0.275667  |    0.203345     |   1\n",
      "       7726 |   0.000126  |    0.006294     |   2\n",
      "       7727 |   0.006297  |    0.081945     |   2\n",
      "       7728 |   0.289579  |    0.046725     |   0\n",
      "       7729 |   0.188440  |    0.035744     |   0\n",
      "       7730 |   0.162055  |    0.219137     |   1\n",
      "       7731 |   0.241440  |    0.143273     |   1\n",
      "       7732 |   0.107231  |    0.045167     |   2\n",
      "       7733 |   0.174210  |    0.026185     |   0\n",
      "       7734 |   0.228231  |    0.045980     |   0\n",
      "       7735 |   0.047078  |    0.074443     |   2\n",
      "       7736 |   0.229383  |    0.127073     |   1\n",
      "       7737 |   0.072769  |    0.017576     |   2\n",
      "       7738 |   0.237785  |    0.214564     |   1\n",
      "       7739 |   0.178158  |    0.007415     |   0\n",
      "       7740 |   0.183922  |    0.056536     |   0\n",
      "       7741 |   0.227589  |    0.150754     |   1\n",
      "       7742 |   0.057968  |    0.045011     |   2\n",
      "       7743 |   0.272152  |    0.216192     |   1\n",
      "       7744 |   0.023957  |    0.009120     |   2\n",
      "       7745 |   0.262308  |    0.167989     |   1\n",
      "       7746 |   0.054099  |    0.103042     |   2\n",
      "       7747 |   0.194416  |    0.160342     |   1\n",
      "       7748 |   0.040890  |    0.003421     |   2\n",
      "       7749 |   0.217552  |    0.078753     |   0\n",
      "       7750 |   0.000126  |    0.039958     |   2\n",
      "       7751 |   0.192140  |    0.043797     |   0\n",
      "       7752 |   0.231011  |    0.046387     |   0\n",
      "       7753 |   0.186167  |    0.040760     |   0\n",
      "       7754 |   0.199857  |    0.156794     |   1\n",
      "       7755 |   0.254385  |    0.142266     |   1\n",
      "       7756 |   0.182579  |    0.157352     |   1\n",
      "       7757 |   0.000127  |    0.023793     |   2\n",
      "       7758 |   0.258276  |    0.163165     |   1\n",
      "       7759 |   0.000131  |    0.042751     |   2\n",
      "       7760 |   0.239616  |    0.041593     |   0\n",
      "       7761 |   0.209669  |    0.038605     |   0\n",
      "       7762 |   0.000127  |    0.073230     |   2\n",
      "       7763 |   0.295328  |    0.164889     |   1\n",
      "       7764 |   0.268673  |    0.137171     |   1\n",
      "       7765 |   0.194790  |    0.007134     |   0\n",
      "       7766 |   0.208299  |    0.046815     |   0\n",
      "       7767 |   0.000126  |    0.044591     |   2\n",
      "       7768 |   0.183926  |    0.079383     |   0\n",
      "       7769 |   0.000129  |    0.045031     |   2\n",
      "       7770 |   0.153397  |    0.147801     |   1\n",
      "       7771 |   0.203953  |    0.154026     |   1\n",
      "       7772 |   0.210190  |    0.043539     |   0\n",
      "       7773 |   0.068105  |    0.079847     |   2\n",
      "       7774 |   0.075570  |    0.017326     |   2\n",
      "       7775 |   0.193850  |    0.192877     |   1\n",
      "       7776 |   0.227034  |    0.168336     |   1\n",
      "       7777 |   0.207372  |    0.156639     |   1\n",
      "       7778 |   0.214032  |    0.075770     |   0\n",
      "       7779 |   0.215852  |    0.050168     |   0\n",
      "       7780 |   0.204126  |    0.138626     |   1\n",
      "       7781 |   0.308533  |    0.152422     |   1\n",
      "       7782 |   0.179777  |    0.040640     |   0\n",
      "       7783 |   0.171998  |    0.079334     |   0\n",
      "       7784 |   0.334276  |    0.155807     |   1\n",
      "       7785 |   0.262530  |    0.076754     |   0\n",
      "       7786 |   0.204950  |    0.147100     |   1\n",
      "       7787 |   0.229428  |    0.145597     |   1\n",
      "       7788 |   0.233633  |    0.077277     |   0\n",
      "       7789 |   0.202351  |    0.014043     |   0\n",
      "       7790 |   0.204550  |    0.236970     |   1\n",
      "       7791 |   0.227400  |    0.154678     |   1\n",
      "       7792 |   0.215898  |    0.014654     |   0\n",
      "       7793 |   0.162820  |    0.151747     |   1\n",
      "       7794 |   0.295804  |    0.159022     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 7796: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       7795 |   0.266111  |    0.009445     |   0\n",
      "       7796 |   0.073152  |    0.021756     |   2\n",
      "       7797 |   0.208667  |    0.091821     |   0\n",
      "       7798 |   0.251591  |    0.155673     |   1\n",
      "       7799 |   0.203843  |    0.005053     |   0\n",
      "       7800 |   0.223396  |    0.080969     |   0\n",
      "       7801 |   0.271286  |    0.144663     |   1\n",
      "       7802 |   0.052634  |    0.022264     |   2\n",
      "       7803 |   0.200796  |    0.223267     |   1\n",
      "       7804 |   0.252695  |    0.146054     |   1\n",
      "       7805 |   0.197778  |    0.160858     |   1\n",
      "       7806 |   0.221533  |    0.133648     |   1\n",
      "       7807 |   0.259188  |    0.154445     |   1\n",
      "       7808 |   0.224037  |    0.144069     |   1\n",
      "       7809 |   0.319294  |    0.041591     |   0\n",
      "       7810 |   0.239546  |    0.150357     |   1\n",
      "       7811 |   0.227300  |    0.040620     |   0\n",
      "       7812 |   0.237283  |    0.074033     |   0\n",
      "       7813 |   0.249324  |    0.023939     |   0\n",
      "       7814 |   0.051954  |    0.039131     |   2\n",
      "       7815 |   0.069079  |    0.075360     |   2\n",
      "       7816 |   0.273217  |    0.141174     |   1\n",
      "       7817 |   0.035647  |    0.036991     |   2\n",
      "       7818 |   0.058531  |    0.079859     |   2\n",
      "       7819 |   0.193856  |    0.159685     |   1\n",
      "       7820 |   0.231773  |    0.140574     |   1\n",
      "       7821 |   0.175585  |    0.042279     |   0\n",
      "       7822 |   0.273412  |    0.075503     |   0\n",
      "       7823 |   0.063178  |    0.010548     |   2\n",
      "       7824 |   0.069782  |    0.081764     |   2\n",
      "       7825 |   0.170247  |    0.008546     |   0\n",
      "       7826 |   0.206457  |    0.072000     |   0\n",
      "       7827 |   0.065903  |    0.020605     |   2\n",
      "       7828 |   0.030125  |    0.042465     |   2\n",
      "       7829 |   0.000125  |    0.048072     |   2\n",
      "       7830 |   0.226819  |    0.177365     |   1\n",
      "       7831 |   0.187220  |    0.108508     |   1\n",
      "       7832 |   0.219968  |    0.037912     |   0\n",
      "       7833 |   0.185128  |    0.203674     |   1\n",
      "       7834 |   0.007112  |    0.019162     |   2\n",
      "       7835 |   0.289554  |    0.212970     |   1\n",
      "       7836 |   0.103718  |    0.018933     |   2\n",
      "       7837 |   0.219767  |    0.200525     |   1\n",
      "       7838 |   0.046605  |    0.006057     |   2\n",
      "       7839 |   0.073910  |    0.084282     |   2\n",
      "       7840 |   0.059470  |    0.040463     |   2\n",
      "       7841 |   0.202169  |    0.150973     |   1\n",
      "       7842 |   0.023170  |    0.007096     |   2\n",
      "       7843 |   0.052034  |    0.082237     |   2\n",
      "       7844 |   0.042441  |    0.024650     |   2\n",
      "       7845 |   0.213039  |    0.204265     |   1\n",
      "       7846 |   0.168760  |    0.014938     |   0\n",
      "       7847 |   0.263924  |    0.075728     |   0\n",
      "       7848 |   0.171811  |    0.010295     |   0\n",
      "       7849 |   0.000125  |    0.081808     |   2\n",
      "       7850 |   0.242182  |    0.144380     |   1\n",
      "       7851 |   0.000125  |    0.007864     |   2\n",
      "       7852 |   0.226553  |    0.087853     |   0\n",
      "       7853 |   0.218734  |    0.023654     |   0\n",
      "       7854 |   0.000129  |    0.081306     |   2\n",
      "       7855 |   0.189128  |    0.025219     |   0\n",
      "       7856 |   0.171118  |    0.050903     |   0\n",
      "       7857 |   0.235178  |    0.151399     |   1\n",
      "       7858 |   0.000125  |    0.040525     |   2\n",
      "       7859 |   0.000125  |    0.050810     |   2\n",
      "       7860 |   0.000126  |    0.076998     |   2\n",
      "       7861 |   0.066371  |    0.025145     |   2\n",
      "       7862 |   0.231360  |    0.044670     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 7864: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       7863 |   0.076155  |    0.041471     |   2\n",
      "       7864 |   0.228687  |    0.077254     |   0\n",
      "       7865 |   0.072577  |    0.023803     |   2\n",
      "       7866 |   0.233451  |    0.192936     |   1\n",
      "       7867 |   0.210558  |    0.140364     |   1\n",
      "       7868 |   0.218169  |    0.165300     |   1\n",
      "       7869 |   0.224066  |    0.141680     |   1\n",
      "       7870 |   0.209881  |    0.005649     |   0\n",
      "       7871 |   0.249413  |    0.050510     |   0\n",
      "       7872 |   0.190566  |    0.047543     |   0\n",
      "       7873 |   0.197362  |    0.166383     |   1\n",
      "       7874 |   0.190563  |    0.040477     |   0\n",
      "       7875 |   0.050905  |    0.076480     |   2\n",
      "       7876 |   0.051844  |    0.016339     |   2\n",
      "       7877 |   0.162916  |    0.076946     |   0\n",
      "       7878 |   0.220710  |    0.028090     |   0\n",
      "       7879 |   0.151405  |    0.225089     |   1\n",
      "       7880 |   0.272809  |    0.132652     |   1\n",
      "       7881 |   0.218857  |    0.040444     |   0\n",
      "       7882 |   0.163496  |    0.199423     |   1\n",
      "       7883 |   0.069259  |    0.023521     |   2\n",
      "       7884 |   0.216045  |    0.195322     |   1\n",
      "       7885 |   0.180811  |    0.074291     |   0\n",
      "       7886 |   0.235549  |    0.141246     |   1\n",
      "       7887 |   0.270305  |    0.165670     |   1\n",
      "       7888 |   0.270410  |    0.097718     |   1\n",
      "       7889 |   0.208311  |    0.146350     |   1\n",
      "       7890 |   0.155136  |    0.031658     |   0\n",
      "       7891 |   0.344669  |    0.187684     |   1\n",
      "       7892 |   0.251028  |    0.009731     |   0\n",
      "       7893 |   0.290586  |    0.187240     |   1\n",
      "       7894 |   0.237122  |    0.163165     |   1\n",
      "       7895 |   0.217827  |    0.159571     |   1\n",
      "       7896 |   0.251385  |    0.014815     |   0\n",
      "       7897 |   0.190170  |    0.069800     |   0\n",
      "       7898 |   0.185868  |    0.026937     |   0\n",
      "       7899 |   0.034643  |    0.074136     |   2\n",
      "       7900 |   0.059746  |    0.005978     |   2\n",
      "       7901 |   0.201644  |    0.082994     |   0\n",
      "       7902 |   0.065434  |    0.017346     |   2\n",
      "       7903 |   0.195216  |    0.083562     |   0\n",
      "       7904 |   0.269600  |    0.144627     |   1\n",
      "       7905 |   0.180650  |    0.161348     |   1\n",
      "       7906 |   0.070450  |    0.044776     |   2\n",
      "       7907 |   0.282327  |    0.044115     |   0\n",
      "       7908 |   0.066784  |    0.045842     |   2\n",
      "       7909 |   0.031451  |    0.059140     |   2\n",
      "       7910 |   0.000124  |    0.037818     |   2\n",
      "       7911 |   0.191413  |    0.047714     |   0\n",
      "       7912 |   0.185870  |    0.039389     |   0\n",
      "       7913 |   0.211113  |    0.045906     |   0\n",
      "       7914 |   0.178784  |    0.074814     |   0\n",
      "       7915 |   0.007261  |    0.022309     |   2\n",
      "       7916 |   0.104300  |    0.076481     |   2\n",
      "       7917 |   0.047785  |    0.007582     |   2\n",
      "       7918 |   0.073957  |    0.092913     |   2\n",
      "       7919 |   0.220747  |    0.189501     |   1\n",
      "       7920 |   0.059853  |    0.014718     |   2\n",
      "       7921 |   0.224434  |    0.217259     |   1\n",
      "       7922 |   0.269836  |    0.135529     |   1\n",
      "       7923 |   0.243484  |    0.009725     |   0\n",
      "       7924 |   0.277584  |    0.211381     |   1\n",
      "       7925 |   0.208253  |    0.014055     |   0\n",
      "       7926 |   0.219524  |    0.172279     |   1\n",
      "       7927 |   0.255009  |    0.082175     |   1\n",
      "       7928 |   0.182527  |    0.044124     |   0\n",
      "       7929 |   0.024515  |    0.038326     |   2\n",
      "       7930 |   0.156632  |    0.070887     |   0\n",
      "       7931 |   0.192328  |    0.025386     |   0\n",
      "       7932 |   0.055347  |    0.052863     |   2\n",
      "       7933 |   0.042500  |    0.076126     |   2\n",
      "       7934 |   0.000123  |    0.009795     |   2\n",
      "       7935 |   0.183451  |    0.080737     |   0\n",
      "       7936 |   0.000123  |    0.008307     |   2\n",
      "       7937 |   0.000126  |    0.047078     |   2\n",
      "       7938 |   0.000124  |    0.044951     |   2\n",
      "       7939 |   0.000123  |    0.073822     |   2\n",
      "       7940 |   0.000125  |    0.015945     |   2\n",
      "       7941 |   0.068448  |    0.077835     |   2\n",
      "       7942 |   0.076168  |    0.030462     |   2\n",
      "       7943 |   0.206490  |    0.048642     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 7944: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       7944 |   0.207589  |    0.158780     |   1\n",
      "       7945 |   0.070417  |    0.014581     |   2\n",
      "       7946 |   0.232660  |    0.203772     |   1\n",
      "       7947 |   0.174688  |    0.037732     |   0\n",
      "       7948 |   0.050645  |    0.039315     |   2\n",
      "       7949 |   0.215322  |    0.079776     |   0\n",
      "       7950 |   0.051702  |    0.016576     |   2\n",
      "       7951 |   0.068392  |    0.073329     |   2\n",
      "       7952 |   0.217488  |    0.148680     |   1\n",
      "       7953 |   0.034803  |    0.008974     |   2\n",
      "       7954 |   0.195927  |    0.073379     |   0\n",
      "       7955 |   0.303650  |    0.045177     |   0\n",
      "       7956 |   0.180784  |    0.214171     |   1\n",
      "       7957 |   0.289053  |    0.145453     |   1\n",
      "       7958 |   0.059019  |    0.003131     |   2\n",
      "       7959 |   0.197989  |    0.244700     |   1\n",
      "       7960 |   0.060995  |    0.005440     |   2\n",
      "       7961 |   0.162749  |    0.073226     |   0\n",
      "       7962 |   0.068717  |    0.013960     |   2\n",
      "       7963 |   0.209853  |    0.201702     |   1\n",
      "       7964 |   0.261390  |    0.146392     |   1\n",
      "       7965 |   0.201086  |    0.176957     |   1\n",
      "       7966 |   0.063006  |    0.006128     |   2\n",
      "       7967 |   0.212514  |    0.076910     |   0\n",
      "       7968 |   0.030581  |    0.043680     |   2\n",
      "       7969 |   0.247071  |    0.140529     |   1\n",
      "       7970 |   0.000122  |    0.033682     |   2\n",
      "       7971 |   0.244474  |    0.214238     |   1\n",
      "       7972 |   0.271229  |    0.136026     |   1\n",
      "       7973 |   0.216599  |    0.013094     |   0\n",
      "       7974 |   0.166195  |    0.070237     |   0\n",
      "       7975 |   0.007066  |    0.028704     |   2\n",
      "       7976 |   0.103104  |    0.075889     |   2\n",
      "       7977 |   0.045370  |    0.026700     |   2\n",
      "       7978 |   0.220270  |    0.063803     |   0\n",
      "       7979 |   0.135421  |    0.228503     |   1\n",
      "       7980 |   0.224229  |    0.145797     |   1\n",
      "       7981 |   0.075323  |    0.003597     |   2\n",
      "       7982 |   0.056850  |    0.054225     |   2\n",
      "       7983 |   0.176451  |    0.156441     |   1\n",
      "       7984 |   0.131410  |    0.150302     |   1\n",
      "       7985 |   0.022771  |    0.055260     |   2\n",
      "       7986 |   0.200957  |    0.192142     |   1\n",
      "       7987 |   0.195009  |    0.140108     |   1\n",
      "       7988 |   0.052781  |    0.014278     |   2\n",
      "       7989 |   0.197914  |    0.076833     |   0\n",
      "       7990 |   0.163958  |    0.040363     |   0\n",
      "       7991 |   0.039547  |    0.090722     |   2\n",
      "       7992 |   0.273958  |    0.146904     |   1\n",
      "       7993 |   0.217702  |    0.042918     |   0\n",
      "       7994 |   0.000121  |    0.039880     |   2\n",
      "       7995 |   0.199024  |    0.208650     |   1\n",
      "       7996 |   0.222081  |    0.137918     |   1\n",
      "       7997 |   0.184536  |    0.017831     |   0\n",
      "       7998 |   0.000121  |    0.041113     |   2\n",
      "       7999 |   0.178843  |    0.044327     |   0\n",
      "       8000 |   0.312373  |    0.153918     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 8000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 8000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       8001 |   0.311827  |    0.154120     |   1\n",
      "       8002 |   0.200282  |    0.044192     |   0\n",
      "       8003 |   0.071153  |    0.052349     |   2\n",
      "       8004 |   0.161916  |    0.195810     |   1\n",
      "       8005 |   0.052099  |    0.004544     |   2\n",
      "       8006 |   0.053450  |    0.081042     |   2\n",
      "       8007 |   0.213959  |    0.026603     |   0\n",
      "       8008 |   0.215872  |    0.082818     |   0\n",
      "       8009 |   0.267706  |    0.141039     |   1\n",
      "       8010 |   0.202842  |    0.195463     |   1\n",
      "       8011 |   0.069510  |    0.005047     |   2\n",
      "       8012 |   0.185462  |    0.206531     |   1\n",
      "       8013 |   0.205651  |    0.142796     |   1\n",
      "       8014 |   0.210801  |    0.084586     |   0\n",
      "       8015 |   0.183170  |    0.005140     |   0\n",
      "       8016 |   0.234525  |    0.224568     |   1\n",
      "       8017 |   0.236389  |    0.130183     |   1\n",
      "       8018 |   0.233693  |    0.012630     |   0\n",
      "       8019 |   0.034109  |    0.077079     |   2\n",
      "       8020 |   0.195828  |    0.017055     |   0\n",
      "       8021 |   0.058403  |    0.081283     |   2\n",
      "       8022 |   0.207586  |    0.179637     |   1\n",
      "       8023 |   0.157779  |    0.141237     |   1\n",
      "       8024 |   0.218211  |    0.051032     |   0\n",
      "       8025 |   0.280302  |    0.155994     |   1\n",
      "       8026 |   0.257874  |    0.147861     |   1\n",
      "       8027 |   0.064916  |    0.003794     |   2\n",
      "       8028 |   0.070639  |    0.039170     |   2\n",
      "       8029 |   0.299364  |    0.070087     |   0\n",
      "       8030 |   0.178416  |    0.041131     |   0\n",
      "       8031 |   0.066644  |    0.046480     |   2\n",
      "       8032 |   0.218022  |    0.081481     |   0\n",
      "       8033 |   0.251918  |    0.161385     |   1\n",
      "       8034 |   0.284472  |    0.136137     |   1\n",
      "       8035 |   0.222630  |    0.014070     |   0\n",
      "       8036 |   0.227922  |    0.078530     |   0\n",
      "       8037 |   0.031712  |    0.029302     |   2\n",
      "       8038 |   0.000120  |    0.083469     |   2\n",
      "       8039 |   0.263821  |    0.186105     |   1\n",
      "       8040 |   0.225141  |    0.136674     |   1\n",
      "       8041 |   0.007224  |    0.018215     |   2\n",
      "       8042 |   0.214164  |    0.207809     |   1\n",
      "       8043 |   0.103644  |    0.007587     |   2\n",
      "       8044 |   0.047684  |    0.041878     |   2\n",
      "       8045 |   0.074100  |    0.050259     |   2\n",
      "       8046 |   0.056663  |    0.041578     |   2\n",
      "       8047 |   0.172262  |    0.033848     |   0\n",
      "       8048 |   0.251445  |    0.057802     |   0\n",
      "       8049 |   0.296720  |    0.183267     |   1\n",
      "       8050 |   0.282881  |    0.175053     |   1\n",
      "       8051 |   0.219364  |    0.105531     |   1\n",
      "       8052 |   0.024240  |    0.047090     |   2\n",
      "       8053 |   0.235495  |    0.142970     |   1\n",
      "       8054 |   0.239555  |    0.024285     |   0\n",
      "       8055 |   0.200858  |    0.050962     |   0\n",
      "       8056 |   0.216477  |    0.159929     |   1\n",
      "       8057 |   0.182167  |    0.147926     |   1\n",
      "       8058 |   0.172771  |    0.075630     |   0\n",
      "       8059 |   0.194844  |    0.012875     |   0\n",
      "       8060 |   0.052855  |    0.057185     |   2\n",
      "       8061 |   0.215031  |    0.063587     |   0\n",
      "       8062 |   0.295889  |    0.163487     |   1\n",
      "       8063 |   0.186558  |    0.008195     |   0\n",
      "       8064 |   0.040127  |    0.051332     |   2\n",
      "       8065 |   0.000120  |    0.042476     |   2\n",
      "       8066 |   0.256984  |    0.081927     |   0\n",
      "       8067 |   0.206598  |    0.004603     |   0\n",
      "       8068 |   0.221654  |    0.215538     |   1\n",
      "       8069 |   0.246938  |    0.131988     |   1\n",
      "       8070 |   0.000120  |    0.014951     |   2\n",
      "       8071 |   0.182617  |    0.223992     |   1\n",
      "       8072 |   0.195818  |    0.099687     |   1\n",
      "       8073 |   0.000124  |    0.043165     |   2\n",
      "       8074 |   0.241151  |    0.194052     |   1\n",
      "       8075 |   0.000122  |    0.030234     |   2\n",
      "       8076 |   0.248526  |    0.165459     |   1\n",
      "       8077 |   0.000121  |    0.048844     |   2\n",
      "       8078 |   0.000122  |    0.076549     |   2\n",
      "       8079 |   0.064832  |    0.018227     |   2\n",
      "       8080 |   0.226227  |    0.075051     |   0\n",
      "       8081 |   0.076397  |    0.009155     |   2\n",
      "       8082 |   0.190387  |    0.078899     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 8083: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       8083 |   0.241214  |    0.020208     |   0\n",
      "       8084 |   0.194643  |    0.210328     |   1\n",
      "       8085 |   0.236470  |    0.139546     |   1\n",
      "       8086 |   0.234707  |    0.045484     |   0\n",
      "       8087 |   0.164182  |    0.083968     |   0\n",
      "       8088 |   0.205649  |    0.162487     |   1\n",
      "       8089 |   0.289097  |    0.165469     |   1\n",
      "       8090 |   0.240649  |    0.008684     |   0\n",
      "       8091 |   0.070947  |    0.076544     |   2\n",
      "       8092 |   0.168045  |    0.168446     |   1\n",
      "       8093 |   0.206184  |    0.115754     |   1\n",
      "       8094 |   0.052682  |    0.029800     |   2\n",
      "       8095 |   0.267356  |    0.177244     |   1\n",
      "       8096 |   0.052587  |    0.053911     |   2\n",
      "       8097 |   0.206492  |    0.036156     |   0\n",
      "       8098 |   0.162762  |    0.042748     |   0\n",
      "       8099 |   0.069658  |    0.048237     |   2\n",
      "       8100 |   0.258870  |    0.329015     |   1\n",
      "       8101 |   0.231194  |    0.131503     |   1\n",
      "       8102 |   0.200287  |    0.200641     |   1\n",
      "       8103 |   0.248194  |    0.008689     |   0\n",
      "       8104 |   0.228806  |    0.082077     |   0\n",
      "       8105 |   0.035259  |    0.016502     |   2\n",
      "       8106 |   0.057851  |    0.082320     |   2\n",
      "       8107 |   0.224310  |    0.025868     |   0\n",
      "       8108 |   0.063245  |    0.074733     |   2\n",
      "       8109 |   0.253579  |    0.036119     |   0\n",
      "       8110 |   0.211613  |    0.207921     |   1\n",
      "       8111 |   0.251507  |    0.105687     |   1\n",
      "       8112 |   0.227656  |    0.070458     |   0\n",
      "       8113 |   0.205235  |    0.165522     |   1\n",
      "       8114 |   0.221291  |    0.175940     |   1\n",
      "       8115 |   0.255349  |    0.088204     |   1\n",
      "       8116 |   0.198696  |    0.019480     |   0\n",
      "       8117 |   0.069059  |    0.074026     |   2\n",
      "       8118 |   0.228427  |    0.053612     |   0\n",
      "       8119 |   0.264200  |    0.192204     |   1\n",
      "       8120 |   0.065938  |    0.021157     |   2\n",
      "       8121 |   0.239140  |    0.149671     |   1\n",
      "       8122 |   0.248055  |    0.072453     |   0\n",
      "       8123 |   0.030897  |    0.024096     |   2\n",
      "       8124 |   0.199703  |    0.209961     |   1\n",
      "       8125 |   0.171475  |    0.011938     |   0\n",
      "       8126 |   0.241703  |    0.166832     |   1\n",
      "       8127 |   0.000120  |    0.003786     |   2\n",
      "       8128 |   0.159786  |    0.042192     |   0\n",
      "       8129 |   0.235660  |    0.040745     |   0\n",
      "       8130 |   0.218883  |    0.040799     |   0\n",
      "       8131 |   0.007396  |    0.084561     |   2\n",
      "       8132 |   0.227819  |    0.153365     |   1\n",
      "       8133 |   0.183753  |    0.026487     |   0\n",
      "       8134 |   0.107838  |    0.083296     |   2\n",
      "       8135 |   0.137133  |    0.153522     |   1\n",
      "       8136 |   0.048765  |    0.042736     |   2\n",
      "       8137 |   0.215485  |    0.052356     |   0\n",
      "       8138 |   0.183740  |    0.053505     |   0\n",
      "       8139 |   0.075065  |    0.057925     |   2\n",
      "       8140 |   0.242148  |    0.043535     |   0\n",
      "       8141 |   0.224537  |    0.049335     |   0\n",
      "       8142 |   0.176072  |    0.199021     |   1\n",
      "       8143 |   0.056895  |    0.004950     |   2\n",
      "       8144 |   0.025261  |    0.088186     |   2\n",
      "       8145 |   0.053955  |    0.022829     |   2\n",
      "       8146 |   0.177671  |    0.053168     |   0\n",
      "       8147 |   0.235754  |    0.043662     |   0\n",
      "       8148 |   0.041641  |    0.055587     |   2\n",
      "       8149 |   0.000119  |    0.006706     |   2\n",
      "       8150 |   0.207572  |    0.075862     |   0\n",
      "       8151 |   0.236101  |    0.129327     |   1\n",
      "       8152 |   0.000119  |    0.045033     |   2\n",
      "       8153 |   0.241143  |    0.194775     |   1\n",
      "       8154 |   0.218674  |    0.136643     |   1\n",
      "       8155 |   0.250438  |    0.140752     |   1\n",
      "       8156 |   0.000122  |    0.076462     |   2\n",
      "       8157 |   0.000120  |    0.036301     |   2\n",
      "       8158 |   0.000119  |    0.045091     |   2\n",
      "       8159 |   0.213037  |    0.071755     |   0\n",
      "       8160 |   0.192732  |    0.027604     |   0\n",
      "       8161 |   0.000121  |    0.050175     |   2\n",
      "       8162 |   0.184735  |    0.202341     |   1\n",
      "       8163 |   0.068633  |    0.012085     |   2\n",
      "       8164 |   0.206807  |    0.073737     |   0\n",
      "       8165 |   0.154118  |    0.033412     |   0\n",
      "       8166 |   0.186564  |    0.040928     |   0\n",
      "       8167 |   0.075668  |    0.045698     |   2\n",
      "       8168 |   0.224743  |    0.059440     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 8169: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       8169 |   0.265393  |    0.145693     |   1\n",
      "       8170 |   0.268574  |    0.107242     |   1\n",
      "       8171 |   0.226003  |    0.201346     |   1\n",
      "       8172 |   0.068538  |    0.010634     |   2\n",
      "       8173 |   0.209928  |    0.052412     |   0\n",
      "       8174 |   0.048807  |    0.055387     |   2\n",
      "       8175 |   0.242903  |    0.215116     |   1\n",
      "       8176 |   0.179461  |    0.134920     |   1\n",
      "       8177 |   0.052408  |    0.017070     |   2\n",
      "       8178 |   0.069821  |    0.079951     |   2\n",
      "       8179 |   0.182478  |    0.025652     |   0\n",
      "       8180 |   0.272624  |    0.195988     |   1\n",
      "       8181 |   0.252090  |    0.020213     |   0\n",
      "       8182 |   0.221205  |    0.075416     |   0\n",
      "       8183 |   0.253671  |    0.167070     |   1\n",
      "       8184 |   0.034215  |    0.010264     |   2\n",
      "       8185 |   0.057911  |    0.081072     |   2\n",
      "       8186 |   0.262442  |    0.021688     |   0\n",
      "       8187 |   0.227339  |    0.214906     |   1\n",
      "       8188 |   0.172407  |    0.004763     |   0\n",
      "       8189 |   0.065591  |    0.028104     |   2\n",
      "       8190 |   0.070765  |    0.075185     |   2\n",
      "       8191 |   0.234835  |    0.151896     |   1\n",
      "       8192 |   0.197805  |    0.145477     |   1\n",
      "       8193 |   0.299244  |    0.143369     |   1\n",
      "       8194 |   0.278821  |    0.209290     |   1\n",
      "       8195 |   0.228425  |    0.110089     |   1\n",
      "       8196 |   0.210663  |    0.048648     |   0\n",
      "       8197 |   0.060890  |    0.055032     |   2\n",
      "       8198 |   0.203626  |    0.198035     |   1\n",
      "       8199 |   0.028940  |    0.004772     |   2\n",
      "       8200 |   0.205722  |    0.075074     |   0\n",
      "       8201 |   0.000118  |    0.027548     |   2\n",
      "       8202 |   0.006833  |    0.081244     |   2\n",
      "       8203 |   0.212611  |    0.149727     |   1\n",
      "       8204 |   0.107374  |    0.011499     |   2\n",
      "       8205 |   0.216667  |    0.230591     |   1\n",
      "       8206 |   0.187387  |    0.004261     |   0\n",
      "       8207 |   0.207308  |    0.147736     |   1\n",
      "       8208 |   0.246448  |    0.136341     |   1\n",
      "       8209 |   0.186155  |    0.078376     |   0\n",
      "       8210 |   0.241261  |    0.140376     |   1\n",
      "       8211 |   0.047832  |    0.042258     |   2\n",
      "       8212 |   0.189269  |    0.047068     |   0\n",
      "       8213 |   0.191909  |    0.053265     |   0\n",
      "       8214 |   0.279688  |    0.039798     |   0\n",
      "       8215 |   0.241230  |    0.149299     |   1\n",
      "       8216 |   0.072173  |    0.074200     |   2\n",
      "       8217 |   0.056284  |    0.030134     |   2\n",
      "       8218 |   0.235446  |    0.204038     |   1\n",
      "       8219 |   0.022130  |    0.017082     |   2\n",
      "       8220 |   0.166720  |    0.201240     |   1\n",
      "       8221 |   0.152944  |    0.138746     |   1\n",
      "       8222 |   0.202406  |    0.018611     |   0\n",
      "       8223 |   0.049829  |    0.037481     |   2\n",
      "       8224 |   0.041141  |    0.075259     |   2\n",
      "       8225 |   0.000118  |    0.054856     |   2\n",
      "       8226 |   0.190678  |    0.180875     |   1\n",
      "       8227 |   0.125433  |    0.146867     |   1\n",
      "       8228 |   0.181689  |    0.154653     |   1\n",
      "       8229 |   0.000118  |    0.031338     |   2\n",
      "       8230 |   0.245614  |    0.209859     |   1\n",
      "       8231 |   0.211513  |    0.007731     |   0\n",
      "       8232 |   0.244353  |    0.079747     |   0\n",
      "       8233 |   0.000122  |    0.015449     |   2\n",
      "       8234 |   0.167497  |    0.054763     |   0\n",
      "       8235 |   0.212952  |    0.160997     |   1\n",
      "       8236 |   0.238525  |    0.042957     |   0\n",
      "       8237 |   0.198043  |    0.047000     |   0\n",
      "       8238 |   0.000119  |    0.078665     |   2\n",
      "       8239 |   0.212521  |    0.173189     |   1\n",
      "       8240 |   0.221001  |    0.134894     |   1\n",
      "       8241 |   0.231842  |    0.008847     |   0\n",
      "       8242 |   0.217419  |    0.095428     |   0\n",
      "       8243 |   0.000117  |    0.005300     |   2\n",
      "       8244 |   0.188486  |    0.089486     |   0\n",
      "       8245 |   0.000118  |    0.005874     |   2\n",
      "       8246 |   0.068378  |    0.059170     |   2\n",
      "       8247 |   0.212651  |    0.051079     |   0\n",
      "       8248 |   0.075635  |    0.031722     |   2\n",
      "       8249 |   0.226990  |    0.073312     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 8250: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       8250 |   0.212997  |    0.028832     |   0\n",
      "       8251 |   0.206509  |    0.076122     |   0\n",
      "       8252 |   0.192575  |    0.039246     |   0\n",
      "       8253 |   0.071149  |    0.054687     |   2\n",
      "       8254 |   0.187143  |    0.199423     |   1\n",
      "       8255 |   0.050177  |    0.010718     |   2\n",
      "       8256 |   0.167538  |    0.203551     |   1\n",
      "       8257 |   0.168806  |    0.025388     |   0\n",
      "       8258 |   0.219724  |    0.059716     |   0\n",
      "       8259 |   0.154399  |    0.210900     |   1\n",
      "       8260 |   0.193888  |    0.006771     |   0\n",
      "       8261 |   0.051982  |    0.078171     |   2\n",
      "       8262 |   0.248820  |    0.160668     |   1\n",
      "       8263 |   0.219157  |    0.207885     |   1\n",
      "       8264 |   0.204625  |    0.088503     |   1\n",
      "       8265 |   0.068077  |    0.044809     |   2\n",
      "       8266 |   0.193444  |    0.085746     |   0\n",
      "       8267 |   0.233566  |    0.155282     |   1\n",
      "       8268 |   0.033962  |    0.022093     |   2\n",
      "       8269 |   0.230999  |    0.159528     |   1\n",
      "       8270 |   0.193068  |    0.047646     |   0\n",
      "       8271 |   0.201466  |    0.074810     |   0\n",
      "       8272 |   0.057746  |    0.022675     |   2\n",
      "       8273 |   0.064275  |    0.059715     |   2\n",
      "       8274 |   0.296905  |    0.151520     |   1\n",
      "       8275 |   0.248185  |    0.209956     |   1\n",
      "       8276 |   0.233747  |    0.136750     |   1\n",
      "       8277 |   0.236242  |    0.027068     |   0\n",
      "       8278 |   0.069419  |    0.056441     |   2\n",
      "       8279 |   0.210341  |    0.201691     |   1\n",
      "       8280 |   0.189173  |    0.152994     |   1\n",
      "       8281 |   0.210729  |    0.080033     |   0\n",
      "       8282 |   0.252889  |    0.146656     |   1\n",
      "       8283 |   0.061557  |    0.004951     |   2\n",
      "       8284 |   0.164599  |    0.044726     |   0\n",
      "       8285 |   0.029396  |    0.032911     |   2\n",
      "       8286 |   0.209524  |    0.209676     |   1\n",
      "       8287 |   0.205641  |    0.024198     |   0\n",
      "       8288 |   0.206697  |    0.077403     |   0\n",
      "       8289 |   0.213502  |    0.134915     |   1\n",
      "       8290 |   0.258102  |    0.200826     |   1\n",
      "       8291 |   0.212575  |    0.154281     |   1\n",
      "       8292 |   0.000117  |    0.018414     |   2\n",
      "       8293 |   0.231103  |    0.194593     |   1\n",
      "       8294 |   0.203669  |    0.145621     |   1\n",
      "       8295 |   0.184277  |    0.152151     |   1\n",
      "       8296 |   0.006827  |    0.049713     |   2\n",
      "       8297 |   0.252201  |    0.152647     |   1\n",
      "       8298 |   0.192103  |    0.048606     |   0\n",
      "       8299 |   0.276241  |    0.209719     |   1\n",
      "       8300 |   0.156766  |    0.007430     |   0\n",
      "       8301 |   0.160857  |    0.027644     |   0\n",
      "       8302 |   0.219139  |    0.197544     |   1\n",
      "       8303 |   0.195233  |    0.017239     |   0\n",
      "       8304 |   0.213018  |    0.072263     |   0\n",
      "       8305 |   0.268750  |    0.156784     |   1\n",
      "       8306 |   0.174254  |    0.021175     |   0\n",
      "       8307 |   0.101292  |    0.081685     |   2\n",
      "       8308 |   0.224960  |    0.149355     |   1\n",
      "       8309 |   0.212769  |    0.028874     |   0\n",
      "       8310 |   0.205099  |    0.077514     |   0\n",
      "       8311 |   0.047324  |    0.029009     |   2\n",
      "       8312 |   0.074019  |    0.061448     |   2\n",
      "       8313 |   0.192413  |    0.161317     |   1\n",
      "       8314 |   0.203884  |    0.154535     |   1\n",
      "       8315 |   0.234603  |    0.039154     |   0\n",
      "       8316 |   0.196876  |    0.049195     |   0\n",
      "       8317 |   0.265578  |    0.189227     |   1\n",
      "       8318 |   0.202711  |    0.025580     |   0\n",
      "       8319 |   0.192924  |    0.072060     |   0\n",
      "       8320 |   0.058797  |    0.024893     |   2\n",
      "       8321 |   0.024925  |    0.081133     |   2\n",
      "       8322 |   0.208035  |    0.016369     |   0\n",
      "       8323 |   0.199234  |    0.197568     |   1\n",
      "       8324 |   0.053991  |    0.049424     |   2\n",
      "       8325 |   0.240702  |    0.178982     |   1\n",
      "       8326 |   0.196017  |    0.043102     |   0\n",
      "       8327 |   0.041211  |    0.042705     |   2\n",
      "       8328 |   0.000116  |    0.077084     |   2\n",
      "       8329 |   0.000117  |    0.024786     |   2\n",
      "       8330 |   0.221535  |    0.071723     |   0\n",
      "       8331 |   0.000120  |    0.026551     |   2\n",
      "       8332 |   0.200207  |    0.043544     |   0\n",
      "       8333 |   0.204161  |    0.072649     |   0\n",
      "       8334 |   0.182559  |    0.020461     |   0\n",
      "       8335 |   0.335677  |    0.165027     |   1\n",
      "       8336 |   0.203758  |    0.136314     |   1\n",
      "       8337 |   0.238085  |    0.150309     |   1\n",
      "       8338 |   0.192694  |    0.044039     |   0\n",
      "       8339 |   0.259943  |    0.145226     |   1\n",
      "       8340 |   0.170230  |    0.040388     |   0\n",
      "       8341 |   0.000117  |    0.073457     |   2\n",
      "       8342 |   0.185356  |    0.026292     |   0\n",
      "       8343 |   0.135178  |    0.192167     |   1\n",
      "       8344 |   0.000117  |    0.036270     |   2\n",
      "       8345 |   0.236424  |    0.079148     |   0\n",
      "       8346 |   0.259578  |    0.135025     |   1\n",
      "       8347 |   0.257350  |    0.076480     |   0\n",
      "       8348 |   0.256857  |    0.139641     |   1\n",
      "       8349 |   0.000118  |    0.013092     |   2\n",
      "       8350 |   0.202756  |    0.201334     |   1\n",
      "       8351 |   0.071227  |    0.005361     |   2\n",
      "       8352 |   0.073962  |    0.076277     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 8353: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       8353 |   0.231444  |    0.157194     |   1\n",
      "       8354 |   0.231297  |    0.037769     |   0\n",
      "       8355 |   0.072822  |    0.073039     |   2\n",
      "       8356 |   0.182218  |    0.023836     |   0\n",
      "       8357 |   0.184098  |    0.047934     |   0\n",
      "       8358 |   0.050663  |    0.048057     |   2\n",
      "       8359 |   0.250892  |    0.157606     |   1\n",
      "       8360 |   0.181433  |    0.197259     |   1\n",
      "       8361 |   0.273360  |    0.144917     |   1\n",
      "       8362 |   0.053452  |    0.032546     |   2\n",
      "       8363 |   0.193167  |    0.160757     |   1\n",
      "       8364 |   0.244737  |    0.143419     |   1\n",
      "       8365 |   0.213524  |    0.131536     |   1\n",
      "       8366 |   0.185636  |    0.045433     |   0\n",
      "       8367 |   0.237687  |    0.207663     |   1\n",
      "       8368 |   0.188775  |    0.004328     |   0\n",
      "       8369 |   0.071135  |    0.056274     |   2\n",
      "       8370 |   0.173258  |    0.149222     |   1\n",
      "       8371 |   0.214611  |    0.047696     |   0\n",
      "       8372 |   0.248748  |    0.034221     |   0\n",
      "       8373 |   0.178663  |    0.043018     |   0\n",
      "       8374 |   0.212923  |    0.086578     |   0\n",
      "       8375 |   0.311915  |    0.129706     |   1\n",
      "       8376 |   0.215311  |    0.037328     |   0\n",
      "       8377 |   0.223647  |    0.084415     |   0\n",
      "       8378 |   0.033680  |    0.020462     |   2\n",
      "       8379 |   0.237599  |    0.239453     |   1\n",
      "       8380 |   0.294301  |    0.083720     |   1\n",
      "       8381 |   0.196394  |    0.194410     |   1\n",
      "       8382 |   0.054793  |    0.003627     |   2\n",
      "       8383 |   0.216329  |    0.155561     |   1\n",
      "       8384 |   0.068086  |    0.054734     |   2\n",
      "       8385 |   0.264884  |    0.044023     |   0\n",
      "       8386 |   0.066587  |    0.042725     |   2\n",
      "       8387 |   0.212989  |    0.193577     |   1\n",
      "       8388 |   0.251216  |    0.139298     |   1\n",
      "       8389 |   0.063477  |    0.018652     |   2\n",
      "       8390 |   0.030457  |    0.073618     |   2\n",
      "       8391 |   0.210297  |    0.018283     |   0\n",
      "       8392 |   0.175130  |    0.090699     |   0\n",
      "       8393 |   0.269949  |    0.134947     |   1\n",
      "       8394 |   0.232715  |    0.007985     |   0\n",
      "       8395 |   0.248501  |    0.201376     |   1\n",
      "       8396 |   0.225101  |    0.096128     |   1\n",
      "       8397 |   0.179687  |    0.044602     |   0\n",
      "       8398 |   0.194149  |    0.077658     |   0\n",
      "       8399 |   0.164406  |    0.011611     |   0\n",
      "       8400 |   0.000116  |    0.075400     |   2\n",
      "       8401 |   0.007195  |    0.029974     |   2\n",
      "       8402 |   0.237671  |    0.092044     |   0\n",
      "       8403 |   0.153858  |    0.144869     |   1\n",
      "       8404 |   0.100605  |    0.045749     |   2\n",
      "       8405 |   0.047842  |    0.046784     |   2\n",
      "       8406 |   0.208537  |    0.047754     |   0\n",
      "       8407 |   0.222567  |    0.074473     |   0\n",
      "       8408 |   0.217526  |    0.027879     |   0\n",
      "       8409 |   0.072859  |    0.045981     |   2\n",
      "       8410 |   0.177807  |    0.046549     |   0\n",
      "       8411 |   0.056818  |    0.043403     |   2\n",
      "       8412 |   0.025687  |    0.083917     |   2\n",
      "       8413 |   0.214845  |    0.017343     |   0\n",
      "       8414 |   0.055852  |    0.080401     |   2\n",
      "       8415 |   0.039565  |    0.007900     |   2\n",
      "       8416 |   0.252099  |    0.074512     |   0\n",
      "       8417 |   0.269767  |    0.143445     |   1\n",
      "       8418 |   0.000114  |    0.018067     |   2\n",
      "       8419 |   0.214869  |    0.136549     |   1\n",
      "       8420 |   0.000115  |    0.073295     |   2\n",
      "       8421 |   0.000118  |    0.026411     |   2\n",
      "       8422 |   0.196760  |    0.191110     |   1\n",
      "       8423 |   0.161375  |    0.007473     |   0\n",
      "       8424 |   0.287937  |    0.080052     |   0\n",
      "       8425 |   0.238762  |    0.036411     |   0\n",
      "       8426 |   0.259276  |    0.193926     |   1\n",
      "       8427 |   0.205638  |    0.019618     |   0\n",
      "       8428 |   0.297225  |    0.205748     |   1\n",
      "       8429 |   0.228320  |    0.180253     |   1\n",
      "       8430 |   0.189494  |    0.031913     |   0\n",
      "       8431 |   0.197187  |    0.169916     |   1\n",
      "       8432 |   0.000115  |    0.045611     |   2\n",
      "       8433 |   0.293855  |    0.191215     |   1\n",
      "       8434 |   0.234815  |    0.007114     |   0\n",
      "       8435 |   0.204853  |    0.043653     |   0\n",
      "       8436 |   0.219252  |    0.074647     |   0\n",
      "       8437 |   0.253267  |    0.141558     |   1\n",
      "       8438 |   0.204085  |    0.025147     |   0\n",
      "       8439 |   0.000115  |    0.050562     |   2\n",
      "       8440 |   0.241819  |    0.209850     |   1\n",
      "       8441 |   0.000116  |    0.005533     |   2\n",
      "       8442 |   0.236287  |    0.043006     |   0\n",
      "       8443 |   0.189330  |    0.042761     |   0\n",
      "       8444 |   0.280387  |    0.148231     |   1\n",
      "       8445 |   0.205312  |    0.010097     |   0\n",
      "       8446 |   0.196437  |    0.049778     |   0\n",
      "       8447 |   0.190221  |    0.206994     |   1\n",
      "       8448 |   0.066021  |    0.006853     |   2\n",
      "       8449 |   0.244131  |    0.064596     |   0\n",
      "       8450 |   0.248153  |    0.148927     |   1\n",
      "       8451 |   0.221114  |    0.216595     |   1\n",
      "       8452 |   0.288366  |    0.145888     |   1\n",
      "       8453 |   0.226164  |    0.148235     |   1\n",
      "       8454 |   0.254979  |    0.148167     |   1\n",
      "       8455 |   0.073439  |    0.061733     |   2\n",
      "       8456 |   0.201466  |    0.128239     |   1\n",
      "       8457 |   0.251999  |    0.192053     |   1\n",
      "       8458 |   0.209600  |    0.092271     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 8459: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       8459 |   0.284497  |    0.150998     |   1\n",
      "       8460 |   0.197474  |    0.072797     |   0\n",
      "       8461 |   0.067879  |    0.021031     |   2\n",
      "       8462 |   0.182861  |    0.087242     |   0\n",
      "       8463 |   0.249600  |    0.163498     |   1\n",
      "       8464 |   0.241149  |    0.015280     |   0\n",
      "       8465 |   0.049264  |    0.075230     |   2\n",
      "       8466 |   0.212868  |    0.136033     |   1\n",
      "       8467 |   0.050713  |    0.045582     |   2\n",
      "       8468 |   0.336869  |    0.160066     |   1\n",
      "       8469 |   0.284343  |    0.191357     |   1\n",
      "       8470 |   0.231215  |    0.022959     |   0\n",
      "       8471 |   0.193940  |    0.188278     |   1\n",
      "       8472 |   0.067463  |    0.074819     |   2\n",
      "       8473 |   0.198580  |    0.144793     |   1\n",
      "       8474 |   0.032939  |    0.012793     |   2\n",
      "       8475 |   0.209269  |    0.078214     |   0\n",
      "       8476 |   0.054033  |    0.039119     |   2\n",
      "       8477 |   0.063688  |    0.043315     |   2\n",
      "       8478 |   0.261365  |    0.053305     |   0\n",
      "       8479 |   0.232069  |    0.201450     |   1\n",
      "       8480 |   0.177142  |    0.140384     |   1\n",
      "       8481 |   0.182229  |    0.082780     |   0\n",
      "       8482 |   0.183033  |    0.173435     |   1\n",
      "       8483 |   0.066055  |    0.020078     |   2\n",
      "       8484 |   0.247764  |    0.181002     |   1\n",
      "       8485 |   0.064636  |    0.011115     |   2\n",
      "       8486 |   0.031674  |    0.084841     |   2\n",
      "       8487 |   0.000114  |    0.031556     |   2\n",
      "       8488 |   0.155308  |    0.209971     |   1\n",
      "       8489 |   0.194835  |    0.012238     |   0\n",
      "       8490 |   0.006945  |    0.073874     |   2\n",
      "       8491 |   0.100355  |    0.026687     |   2\n",
      "       8492 |   0.185323  |    0.076528     |   0\n",
      "       8493 |   0.214946  |    0.018823     |   0\n",
      "       8494 |   0.240700  |    0.081417     |   0\n",
      "       8495 |   0.198330  |    0.028552     |   0\n",
      "       8496 |   0.219395  |    0.207781     |   1\n",
      "       8497 |   0.259265  |    0.110168     |   1\n",
      "       8498 |   0.154277  |    0.157305     |   1\n",
      "       8499 |   0.222175  |    0.203778     |   1\n",
      "       8500 |   0.044844  |    0.006536     |   2\n",
      "       8501 |   0.204007  |    0.205459     |   1\n",
      "       8502 |   0.218998  |    0.163522     |   1\n",
      "       8503 |   0.168399  |    0.007063     |   0\n",
      "       8504 |   0.298709  |    0.145280     |   1\n",
      "       8505 |   0.068354  |    0.031549     |   2\n",
      "       8506 |   0.174338  |    0.077087     |   0\n",
      "       8507 |   0.048766  |    0.007444     |   2\n",
      "       8508 |   0.050377  |    0.088590     |   2\n",
      "       8509 |   0.067936  |    0.011508     |   2\n",
      "       8510 |   0.261897  |    0.072566     |   0\n",
      "       8511 |   0.033038  |    0.046611     |   2\n",
      "       8512 |   0.295307  |    0.146363     |   1\n",
      "       8513 |   0.181950  |    0.204892     |   1\n",
      "       8514 |   0.054750  |    0.011891     |   2\n",
      "       8515 |   0.225603  |    0.047746     |   0\n",
      "       8516 |   0.234176  |    0.191754     |   1\n",
      "       8517 |   0.061614  |    0.008305     |   2\n",
      "       8518 |   0.212359  |    0.195767     |   1\n",
      "       8519 |   0.067080  |    0.014830     |   2\n",
      "       8520 |   0.300473  |    0.196325     |   1\n",
      "       8521 |   0.233203  |    0.019525     |   0\n",
      "       8522 |   0.241308  |    0.205932     |   1\n",
      "       8523 |   0.254328  |    0.143640     |   1\n",
      "       8524 |   0.112652  |    0.155502     |   1\n",
      "       8525 |   0.177550  |    0.008024     |   0\n",
      "       8526 |   0.063551  |    0.078515     |   2\n",
      "       8527 |   0.283458  |    0.048401     |   0\n",
      "       8528 |   0.030427  |    0.061921     |   2\n",
      "       8529 |   0.271958  |    0.150894     |   1\n",
      "       8530 |   0.000113  |    0.026652     |   2\n",
      "       8531 |   0.183789  |    0.078155     |   0\n",
      "       8532 |   0.006985  |    0.011543     |   2\n",
      "       8533 |   0.100157  |    0.079678     |   2\n",
      "       8534 |   0.045452  |    0.026251     |   2\n",
      "       8535 |   0.074363  |    0.075189     |   2\n",
      "       8536 |   0.056263  |    0.033920     |   2\n",
      "       8537 |   0.195240  |    0.047327     |   0\n",
      "       8538 |   0.202943  |    0.041286     |   0\n",
      "       8539 |   0.024868  |    0.081058     |   2\n",
      "       8540 |   0.187939  |    0.012499     |   0\n",
      "       8541 |   0.227487  |    0.196921     |   1\n",
      "       8542 |   0.054546  |    0.004900     |   2\n",
      "       8543 |   0.191403  |    0.078436     |   0\n",
      "       8544 |   0.276742  |    0.155904     |   1\n",
      "       8545 |   0.041903  |    0.022436     |   2\n",
      "       8546 |   0.000112  |    0.076530     |   2\n",
      "       8547 |   0.000112  |    0.028071     |   2\n",
      "       8548 |   0.000115  |    0.082332     |   2\n",
      "       8549 |   0.000113  |    0.029870     |   2\n",
      "       8550 |   0.255930  |    0.158020     |   1\n",
      "       8551 |   0.174684  |    0.072896     |   0\n",
      "       8552 |   0.237117  |    0.149221     |   1\n",
      "       8553 |   0.203680  |    0.041248     |   0\n",
      "       8554 |   0.000112  |    0.040178     |   2\n",
      "       8555 |   0.193621  |    0.084550     |   0\n",
      "       8556 |   0.000113  |    0.026107     |   2\n",
      "       8557 |   0.065212  |    0.046169     |   2\n",
      "       8558 |   0.272768  |    0.078876     |   0\n",
      "       8559 |   0.177053  |    0.013138     |   0\n",
      "       8560 |   0.073550  |    0.079476     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 8562: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       8561 |   0.193466  |    0.017658     |   0\n",
      "       8562 |   0.246974  |    0.078439     |   0\n",
      "       8563 |   0.066855  |    0.022668     |   2\n",
      "       8564 |   0.181227  |    0.078605     |   0\n",
      "       8565 |   0.207195  |    0.137680     |   1\n",
      "       8566 |   0.188505  |    0.040933     |   0\n",
      "       8567 |   0.193475  |    0.206998     |   1\n",
      "       8568 |   0.218091  |    0.025995     |   0\n",
      "       8569 |   0.218812  |    0.046488     |   0\n",
      "       8570 |   0.051172  |    0.073859     |   2\n",
      "       8571 |   0.222160  |    0.035945     |   0\n",
      "       8572 |   0.203479  |    0.202453     |   1\n",
      "       8573 |   0.250968  |    0.149314     |   1\n",
      "       8574 |   0.050245  |    0.048863     |   2\n",
      "       8575 |   0.187637  |    0.048963     |   0\n",
      "       8576 |   0.064728  |    0.043935     |   2\n",
      "       8577 |   0.034305  |    0.044068     |   2\n",
      "       8578 |   0.055161  |    0.074385     |   2\n",
      "       8579 |   0.068371  |    0.024671     |   2\n",
      "       8580 |   0.068521  |    0.045302     |   2\n",
      "       8581 |   0.063921  |    0.081030     |   2\n",
      "       8582 |   0.216052  |    0.132931     |   1\n",
      "       8583 |   0.028020  |    0.029569     |   2\n",
      "       8584 |   0.221083  |    0.073745     |   0\n",
      "       8585 |   0.000112  |    0.040293     |   2\n",
      "       8586 |   0.007096  |    0.045119     |   2\n",
      "       8587 |   0.189790  |    0.051197     |   0\n",
      "       8588 |   0.100755  |    0.046283     |   2\n",
      "       8589 |   0.178103  |    0.042048     |   0\n",
      "       8590 |   0.044832  |    0.073970     |   2\n",
      "       8591 |   0.207926  |    0.150225     |   1\n",
      "       8592 |   0.073352  |    0.040314     |   2\n",
      "       8593 |   0.211836  |    0.079938     |   0\n",
      "       8594 |   0.233591  |    0.025805     |   0\n",
      "       8595 |   0.058537  |    0.070113     |   2\n",
      "       8596 |   0.198843  |    0.193672     |   1\n",
      "       8597 |   0.178391  |    0.153055     |   1\n",
      "       8598 |   0.208737  |    0.047112     |   0\n",
      "       8599 |   0.175120  |    0.206941     |   1\n",
      "       8600 |   0.024331  |    0.011665     |   2\n",
      "       8601 |   0.052463  |    0.077947     |   2\n",
      "       8602 |   0.225177  |    0.007737     |   0\n",
      "       8603 |   0.192765  |    0.048748     |   0\n",
      "       8604 |   0.040899  |    0.082679     |   2\n",
      "       8605 |   0.157070  |    0.011627     |   0\n",
      "       8606 |   0.182204  |    0.081560     |   0\n",
      "       8607 |   0.196827  |    0.019981     |   0\n",
      "       8608 |   0.000111  |    0.055592     |   2\n",
      "       8609 |   0.250153  |    0.206454     |   1\n",
      "       8610 |   0.000111  |    0.017984     |   2\n",
      "       8611 |   0.206665  |    0.210975     |   1\n",
      "       8612 |   0.253213  |    0.159463     |   1\n",
      "       8613 |   0.219766  |    0.010209     |   0\n",
      "       8614 |   0.000114  |    0.084080     |   2\n",
      "       8615 |   0.000111  |    0.027829     |   2\n",
      "       8616 |   0.229927  |    0.206849     |   1\n",
      "       8617 |   0.238142  |    0.139898     |   1\n",
      "       8618 |   0.000111  |    0.086451     |   2\n",
      "       8619 |   0.229222  |    0.177939     |   1\n",
      "       8620 |   0.203765  |    0.012765     |   0\n",
      "       8621 |   0.286196  |    0.047639     |   0\n",
      "       8622 |   0.000112  |    0.073321     |   2\n",
      "       8623 |   0.209240  |    0.197442     |   1\n",
      "       8624 |   0.201917  |    0.003810     |   0\n",
      "       8625 |   0.266654  |    0.148265     |   1\n",
      "       8626 |   0.066794  |    0.042023     |   2\n",
      "       8627 |   0.217913  |    0.048539     |   0\n",
      "       8628 |   0.073098  |    0.048706     |   2\n",
      "       8629 |   0.265349  |    0.147491     |   1\n",
      "       8630 |   0.252907  |    0.138235     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 8631: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       8631 |   0.069428  |    0.021961     |   2\n",
      "       8632 |   0.234335  |    0.159629     |   1\n",
      "       8633 |   0.050860  |    0.038990     |   2\n",
      "       8634 |   0.176278  |    0.078583     |   0\n",
      "       8635 |   0.049871  |    0.005599     |   2\n",
      "       8636 |   0.063108  |    0.088368     |   2\n",
      "       8637 |   0.268060  |    0.154861     |   1\n",
      "       8638 |   0.294791  |    0.090610     |   1\n",
      "       8639 |   0.033185  |    0.042513     |   2\n",
      "       8640 |   0.208054  |    0.050105     |   0\n",
      "       8641 |   0.169529  |    0.073255     |   0\n",
      "       8642 |   0.201429  |    0.027872     |   0\n",
      "       8643 |   0.198289  |    0.072781     |   0\n",
      "       8644 |   0.055983  |    0.031993     |   2\n",
      "       8645 |   0.268660  |    0.173913     |   1\n",
      "       8646 |   0.201282  |    0.154164     |   1\n",
      "       8647 |   0.213582  |    0.148759     |   1\n",
      "       8648 |   0.217526  |    0.156842     |   1\n",
      "       8649 |   0.223141  |    0.167170     |   1\n",
      "       8650 |   0.256916  |    0.184426     |   1\n",
      "       8651 |   0.059136  |    0.029008     |   2\n",
      "       8652 |   0.068178  |    0.050640     |   2\n",
      "       8653 |   0.314447  |    0.156995     |   1\n",
      "       8654 |   0.156843  |    0.143315     |   1\n",
      "       8655 |   0.215017  |    0.043977     |   0\n",
      "       8656 |   0.173925  |    0.045609     |   0\n",
      "       8657 |   0.241342  |    0.075390     |   0\n",
      "       8658 |   0.264263  |    0.207292     |   1\n",
      "       8659 |   0.065706  |    0.004538     |   2\n",
      "       8660 |   0.030836  |    0.070726     |   2\n",
      "       8661 |   0.210179  |    0.193081     |   1\n",
      "       8662 |   0.000111  |    0.018503     |   2\n",
      "       8663 |   0.179337  |    0.075079     |   0\n",
      "       8664 |   0.007239  |    0.015968     |   2\n",
      "       8665 |   0.197278  |    0.045022     |   0\n",
      "       8666 |   0.331668  |    0.135075     |   1\n",
      "       8667 |   0.195573  |    0.074805     |   0\n",
      "       8668 |   0.153434  |    0.023133     |   0\n",
      "       8669 |   0.237825  |    0.183108     |   1\n",
      "       8670 |   0.258553  |    0.138052     |   1\n",
      "       8671 |   0.097533  |    0.046933     |   2\n",
      "       8672 |   0.045486  |    0.057007     |   2\n",
      "       8673 |   0.258128  |    0.138802     |   1\n",
      "       8674 |   0.193481  |    0.166095     |   1\n",
      "       8675 |   0.070091  |    0.012380     |   2\n",
      "       8676 |   0.182987  |    0.046109     |   0\n",
      "       8677 |   0.056683  |    0.073293     |   2\n",
      "       8678 |   0.165278  |    0.017212     |   0\n",
      "       8679 |   0.190657  |    0.073130     |   0\n",
      "       8680 |   0.025161  |    0.028449     |   2\n",
      "       8681 |   0.052680  |    0.053227     |   2\n",
      "       8682 |   0.234320  |    0.207683     |   1\n",
      "       8683 |   0.039746  |    0.004689     |   2\n",
      "       8684 |   0.000110  |    0.075319     |   2\n",
      "       8685 |   0.234746  |    0.052582     |   0\n",
      "       8686 |   0.247459  |    0.196631     |   1\n",
      "       8687 |   0.000111  |    0.006264     |   2\n",
      "       8688 |   0.239697  |    0.081886     |   0\n",
      "       8689 |   0.000114  |    0.027167     |   2\n",
      "       8690 |   0.000111  |    0.077950     |   2\n",
      "       8691 |   0.218300  |    0.031276     |   0\n",
      "       8692 |   0.251053  |    0.193376     |   1\n",
      "       8693 |   0.273560  |    0.155811     |   1\n",
      "       8694 |   0.170429  |    0.145148     |   1\n",
      "       8695 |   0.000110  |    0.073079     |   2\n",
      "       8696 |   0.237119  |    0.046747     |   0\n",
      "       8697 |   0.174615  |    0.047265     |   0\n",
      "       8698 |   0.222216  |    0.038702     |   0\n",
      "       8699 |   0.000111  |    0.084350     |   2\n",
      "       8700 |   0.217243  |    0.169160     |   1\n",
      "       8701 |   0.208942  |    0.007570     |   0\n",
      "       8702 |   0.169910  |    0.044474     |   0\n",
      "       8703 |   0.210985  |    0.044123     |   0\n",
      "       8704 |   0.064840  |    0.046033     |   2\n",
      "       8705 |   0.073074  |    0.042989     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 8706: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       8706 |   0.266134  |    0.132695     |   1\n",
      "       8707 |   0.247548  |    0.041942     |   0\n",
      "       8708 |   0.066919  |    0.084200     |   2\n",
      "       8709 |   0.049841  |    0.007832     |   2\n",
      "       8710 |   0.212920  |    0.078655     |   0\n",
      "       8711 |   0.050333  |    0.021204     |   2\n",
      "       8712 |   0.265007  |    0.056821     |   0\n",
      "       8713 |   0.209200  |    0.043969     |   0\n",
      "       8714 |   0.233119  |    0.049649     |   0\n",
      "       8715 |   0.203343  |    0.030439     |   0\n",
      "       8716 |   0.209290  |    0.083024     |   0\n",
      "       8717 |   0.188715  |    0.086441     |   1\n",
      "       8718 |   0.066181  |    0.047270     |   2\n",
      "       8719 |   0.154529  |    0.044052     |   0\n",
      "       8720 |   0.034614  |    0.039485     |   2\n",
      "       8721 |   0.184501  |    0.055732     |   0\n",
      "       8722 |   0.188862  |    0.204137     |   1\n",
      "       8723 |   0.056049  |    0.015968     |   2\n",
      "       8724 |   0.196023  |    0.201992     |   1\n",
      "       8725 |   0.191380  |    0.007214     |   0\n",
      "       8726 |   0.064232  |    0.079328     |   2\n",
      "       8727 |   0.236199  |    0.049337     |   0\n",
      "       8728 |   0.226718  |    0.143418     |   1\n",
      "       8729 |   0.191800  |    0.079061     |   0\n",
      "       8730 |   0.262371  |    0.045563     |   0\n",
      "       8731 |   0.233825  |    0.042315     |   0\n",
      "       8732 |   0.237847  |    0.080457     |   0\n",
      "       8733 |   0.067527  |    0.027587     |   2\n",
      "       8734 |   0.216856  |    0.074955     |   0\n",
      "       8735 |   0.061607  |    0.046688     |   2\n",
      "       8736 |   0.215948  |    0.156195     |   1\n",
      "       8737 |   0.030493  |    0.015773     |   2\n",
      "       8738 |   0.176098  |    0.079619     |   0\n",
      "       8739 |   0.211402  |    0.008667     |   0\n",
      "       8740 |   0.242549  |    0.080554     |   0\n",
      "       8741 |   0.000110  |    0.021645     |   2\n",
      "       8742 |   0.218533  |    0.076166     |   0\n",
      "       8743 |   0.007315  |    0.043735     |   2\n",
      "       8744 |   0.100716  |    0.042156     |   2\n",
      "       8745 |   0.163324  |    0.040672     |   0\n",
      "       8746 |   0.253966  |    0.156899     |   1\n",
      "       8747 |   0.211117  |    0.171624     |   1\n",
      "       8748 |   0.265567  |    0.188409     |   1\n",
      "       8749 |   0.194496  |    0.015257     |   0\n",
      "       8750 |   0.047123  |    0.079020     |   2\n",
      "       8751 |   0.253582  |    0.148453     |   1\n",
      "       8752 |   0.217588  |    0.157596     |   1\n",
      "       8753 |   0.214796  |    0.051214     |   0\n",
      "       8754 |   0.076753  |    0.044005     |   2\n",
      "       8755 |   0.222923  |    0.211136     |   1\n",
      "       8756 |   0.208459  |    0.115656     |   1\n",
      "       8757 |   0.056341  |    0.027373     |   2\n",
      "       8758 |   0.236451  |    0.145757     |   1\n",
      "       8759 |   0.261728  |    0.146511     |   1\n",
      "       8760 |   0.026921  |    0.012166     |   2\n",
      "       8761 |   0.055080  |    0.083222     |   2\n",
      "       8762 |   0.040608  |    0.014814     |   2\n",
      "       8763 |   0.180076  |    0.104520     |   0\n",
      "       8764 |   0.222052  |    0.149067     |   1\n",
      "       8765 |   0.206686  |    0.147828     |   1\n",
      "       8766 |   0.194245  |    0.004481     |   0\n",
      "       8767 |   0.000110  |    0.074351     |   2\n",
      "       8768 |   0.000111  |    0.038748     |   2\n",
      "       8769 |   0.224769  |    0.038950     |   0\n",
      "       8770 |   0.202291  |    0.044459     |   0\n",
      "       8771 |   0.262389  |    0.074927     |   0\n",
      "       8772 |   0.178736  |    0.019032     |   0\n",
      "       8773 |   0.227588  |    0.189677     |   1\n",
      "       8774 |   0.000112  |    0.022797     |   2\n",
      "       8775 |   0.000110  |    0.086278     |   2\n",
      "       8776 |   0.286024  |    0.136647     |   1\n",
      "       8777 |   0.000110  |    0.075654     |   2\n",
      "       8778 |   0.000111  |    0.019857     |   2\n",
      "       8779 |   0.254604  |    0.167816     |   1\n",
      "       8780 |   0.202453  |    0.147843     |   1\n",
      "       8781 |   0.224865  |    0.044299     |   0\n",
      "       8782 |   0.059417  |    0.044749     |   2\n",
      "       8783 |   0.071372  |    0.044962     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 8784: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       8784 |   0.200504  |    0.165529     |   1\n",
      "       8785 |   0.214887  |    0.064104     |   0\n",
      "       8786 |   0.219134  |    0.180743     |   1\n",
      "       8787 |   0.065319  |    0.019205     |   2\n",
      "       8788 |   0.180730  |    0.041240     |   0\n",
      "       8789 |   0.219586  |    0.075501     |   0\n",
      "       8790 |   0.047740  |    0.042518     |   2\n",
      "       8791 |   0.050002  |    0.043655     |   2\n",
      "       8792 |   0.228924  |    0.046159     |   0\n",
      "       8793 |   0.172944  |    0.045830     |   0\n",
      "       8794 |   0.064440  |    0.047784     |   2\n",
      "       8795 |   0.032256  |    0.075430     |   2\n",
      "       8796 |   0.185865  |    0.010407     |   0\n",
      "       8797 |   0.054603  |    0.050459     |   2\n",
      "       8798 |   0.208798  |    0.072320     |   0\n",
      "       8799 |   0.254501  |    0.043695     |   0\n",
      "       8800 |   0.219415  |    0.153292     |   1\n",
      "       8801 |   0.317838  |    0.140456     |   1\n",
      "       8802 |   0.260107  |    0.078534     |   0\n",
      "       8803 |   0.246071  |    0.145341     |   1\n",
      "       8804 |   0.179928  |    0.159569     |   1\n",
      "       8805 |   0.066357  |    0.071788     |   2\n",
      "       8806 |   0.064325  |    0.022098     |   2\n",
      "       8807 |   0.213568  |    0.081874     |   0\n",
      "       8808 |   0.062016  |    0.020898     |   2\n",
      "       8809 |   0.030430  |    0.077223     |   2\n",
      "       8810 |   0.178580  |    0.027822     |   0\n",
      "       8811 |   0.000109  |    0.073366     |   2\n",
      "       8812 |   0.199122  |    0.027020     |   0\n",
      "       8813 |   0.007086  |    0.042158     |   2\n",
      "       8814 |   0.098110  |    0.080027     |   2\n",
      "       8815 |   0.043797  |    0.022556     |   2\n",
      "       8816 |   0.151459  |    0.047512     |   0\n",
      "       8817 |   0.071403  |    0.054006     |   2\n",
      "       8818 |   0.189037  |    0.078146     |   0\n",
      "       8819 |   0.169841  |    0.010730     |   0\n",
      "       8820 |   0.057335  |    0.092514     |   2\n",
      "       8821 |   0.252078  |    0.158102     |   1\n",
      "       8822 |   0.214646  |    0.153020     |   1\n",
      "       8823 |   0.228144  |    0.046908     |   0\n",
      "       8824 |   0.155586  |    0.049698     |   0\n",
      "       8825 |   0.026637  |    0.077407     |   2\n",
      "       8826 |   0.054461  |    0.033072     |   2\n",
      "       8827 |   0.192205  |    0.215660     |   1\n",
      "       8828 |   0.216573  |    0.110487     |   1\n",
      "       8829 |   0.042020  |    0.053367     |   2\n",
      "       8830 |   0.346781  |    0.145220     |   1\n",
      "       8831 |   0.205518  |    0.047393     |   0\n",
      "       8832 |   0.239010  |    0.072709     |   0\n",
      "       8833 |   0.178184  |    0.032770     |   0\n",
      "       8834 |   0.235177  |    0.205109     |   1\n",
      "       8835 |   0.256715  |    0.140790     |   1\n",
      "       8836 |   0.242909  |    0.010131     |   0\n",
      "       8837 |   0.000108  |    0.070508     |   2\n",
      "       8838 |   0.000109  |    0.012777     |   2\n",
      "       8839 |   0.236751  |    0.190315     |   1\n",
      "       8840 |   0.000111  |    0.009614     |   2\n",
      "       8841 |   0.000109  |    0.048448     |   2\n",
      "       8842 |   0.185273  |    0.080419     |   0\n",
      "       8843 |   0.209799  |    0.012097     |   0\n",
      "       8844 |   0.000109  |    0.080150     |   2\n",
      "       8845 |   0.210813  |    0.137280     |   1\n",
      "       8846 |   0.000109  |    0.047982     |   2\n",
      "       8847 |   0.208182  |    0.075699     |   0\n",
      "       8848 |   0.061066  |    0.023197     |   2\n",
      "       8849 |   0.245173  |    0.074785     |   0\n",
      "       8850 |   0.200194  |    0.028931     |   0\n",
      "       8851 |   0.221664  |    0.142858     |   1\n",
      "       8852 |   0.193336  |    0.083539     |   0\n",
      "       8853 |   0.185251  |    0.027250     |   0\n",
      "       8854 |   0.203694  |    0.042982     |   0\n",
      "       8855 |   0.198337  |    0.160060     |   1\n",
      "       8856 |   0.277609  |    0.146965     |   1\n",
      "       8857 |   0.072633  |    0.030740     |   2\n",
      "       8858 |   0.267518  |    0.186230     |   1\n",
      "       8859 |   0.213455  |    0.007439     |   0\n",
      "       8860 |   0.241835  |    0.074388     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 8861: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       8861 |   0.068535  |    0.010057     |   2\n",
      "       8862 |   0.181686  |    0.076034     |   0\n",
      "       8863 |   0.214349  |    0.011383     |   0\n",
      "       8864 |   0.168746  |    0.079716     |   0\n",
      "       8865 |   0.217493  |    0.024826     |   0\n",
      "       8866 |   0.228556  |    0.201580     |   1\n",
      "       8867 |   0.215141  |    0.006804     |   0\n",
      "       8868 |   0.049966  |    0.084336     |   2\n",
      "       8869 |   0.213983  |    0.148862     |   1\n",
      "       8870 |   0.214659  |    0.141175     |   1\n",
      "       8871 |   0.247803  |    0.187849     |   1\n",
      "       8872 |   0.257090  |    0.097952     |   1\n",
      "       8873 |   0.051242  |    0.078831     |   2\n",
      "       8874 |   0.068096  |    0.025081     |   2\n",
      "       8875 |   0.213738  |    0.213051     |   1\n",
      "       8876 |   0.033530  |    0.013942     |   2\n",
      "       8877 |   0.238343  |    0.079115     |   0\n",
      "       8878 |   0.224559  |    0.151887     |   1\n",
      "       8879 |   0.189551  |    0.015388     |   0\n",
      "       8880 |   0.174795  |    0.080696     |   0\n",
      "       8881 |   0.056466  |    0.015078     |   2\n",
      "       8882 |   0.182709  |    0.076082     |   0\n",
      "       8883 |   0.059101  |    0.024914     |   2\n",
      "       8884 |   0.246772  |    0.192681     |   1\n",
      "       8885 |   0.066464  |    0.005425     |   2\n",
      "       8886 |   0.231981  |    0.157370     |   1\n",
      "       8887 |   0.149861  |    0.200594     |   1\n",
      "       8888 |   0.065858  |    0.009048     |   2\n",
      "       8889 |   0.202795  |    0.078772     |   0\n",
      "       8890 |   0.030671  |    0.013468     |   2\n",
      "       8891 |   0.207980  |    0.078470     |   0\n",
      "       8892 |   0.285461  |    0.198823     |   1\n",
      "       8893 |   0.279052  |    0.159935     |   1\n",
      "       8894 |   0.000109  |    0.023351     |   2\n",
      "       8895 |   0.235187  |    0.207322     |   1\n",
      "       8896 |   0.233459  |    0.007132     |   0\n",
      "       8897 |   0.190218  |    0.079709     |   0\n",
      "       8898 |   0.007252  |    0.041369     |   2\n",
      "       8899 |   0.221172  |    0.077260     |   0\n",
      "       8900 |   0.251579  |    0.155172     |   1\n",
      "       8901 |   0.178483  |    0.148294     |   1\n",
      "       8902 |   0.143579  |    0.160833     |   1\n",
      "       8903 |   0.098911  |    0.023508     |   2\n",
      "       8904 |   0.045444  |    0.050219     |   2\n",
      "       8905 |   0.193903  |    0.163210     |   1\n",
      "       8906 |   0.227778  |    0.043685     |   0\n",
      "       8907 |   0.071195  |    0.045750     |   2\n",
      "       8908 |   0.054593  |    0.042668     |   2\n",
      "       8909 |   0.181217  |    0.070882     |   0\n",
      "       8910 |   0.023096  |    0.014463     |   2\n",
      "       8911 |   0.224730  |    0.083551     |   0\n",
      "       8912 |   0.050491  |    0.019354     |   2\n",
      "       8913 |   0.229154  |    0.192171     |   1\n",
      "       8914 |   0.179975  |    0.008719     |   0\n",
      "       8915 |   0.041199  |    0.079185     |   2\n",
      "       8916 |   0.192202  |    0.147283     |   1\n",
      "       8917 |   0.000109  |    0.074378     |   2\n",
      "       8918 |   0.212026  |    0.146096     |   1\n",
      "       8919 |   0.000109  |    0.012923     |   2\n",
      "       8920 |   0.222950  |    0.077468     |   0\n",
      "       8921 |   0.215824  |    0.028456     |   0\n",
      "       8922 |   0.000110  |    0.048406     |   2\n",
      "       8923 |   0.216282  |    0.068941     |   0\n",
      "       8924 |   0.239263  |    0.159651     |   1\n",
      "       8925 |   0.000109  |    0.050159     |   2\n",
      "       8926 |   0.214563  |    0.141384     |   1\n",
      "       8927 |   0.214810  |    0.045781     |   0\n",
      "       8928 |   0.211553  |    0.189339     |   1\n",
      "       8929 |   0.000108  |    0.007738     |   2\n",
      "       8930 |   0.219290  |    0.045729     |   0\n",
      "       8931 |   0.205089  |    0.203580     |   1\n",
      "       8932 |   0.242740  |    0.121026     |   1\n",
      "       8933 |   0.254004  |    0.151393     |   1\n",
      "       8934 |   0.000109  |    0.030030     |   2\n",
      "       8935 |   0.217832  |    0.197646     |   1\n",
      "       8936 |   0.063218  |    0.012352     |   2\n",
      "       8937 |   0.072408  |    0.075452     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 8938: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       8938 |   0.062986  |    0.014313     |   2\n",
      "       8939 |   0.221951  |    0.095678     |   0\n",
      "       8940 |   0.184195  |    0.127320     |   1\n",
      "       8941 |   0.186807  |    0.010935     |   0\n",
      "       8942 |   0.046015  |    0.072285     |   2\n",
      "       8943 |   0.184063  |    0.051986     |   0\n",
      "       8944 |   0.185165  |    0.148709     |   1\n",
      "       8945 |   0.050199  |    0.077845     |   2\n",
      "       8946 |   0.241320  |    0.164843     |   1\n",
      "       8947 |   0.239325  |    0.139570     |   1\n",
      "       8948 |   0.271927  |    0.007762     |   0\n",
      "       8949 |   0.168778  |    0.045899     |   0\n",
      "       8950 |   0.064344  |    0.055628     |   2\n",
      "       8951 |   0.193482  |    0.054523     |   0\n",
      "       8952 |   0.236133  |    0.201082     |   1\n",
      "       8953 |   0.225222  |    0.145533     |   1\n",
      "       8954 |   0.032925  |    0.028703     |   2\n",
      "       8955 |   0.238623  |    0.205519     |   1\n",
      "       8956 |   0.221631  |    0.008772     |   0\n",
      "       8957 |   0.054217  |    0.053235     |   2\n",
      "       8958 |   0.262681  |    0.216910     |   1\n",
      "       8959 |   0.238115  |    0.100044     |   1\n",
      "       8960 |   0.199712  |    0.207460     |   1\n",
      "       8961 |   0.237048  |    0.149001     |   1\n",
      "       8962 |   0.167506  |    0.006260     |   0\n",
      "       8963 |   0.059677  |    0.077392     |   2\n",
      "       8964 |   0.212689  |    0.041942     |   0\n",
      "       8965 |   0.066286  |    0.047743     |   2\n",
      "       8966 |   0.201229  |    0.212756     |   1\n",
      "       8967 |   0.060097  |    0.015057     |   2\n",
      "       8968 |   0.232168  |    0.189306     |   1\n",
      "       8969 |   0.028321  |    0.005129     |   2\n",
      "       8970 |   0.180211  |    0.053325     |   0\n",
      "       8971 |   0.000107  |    0.036721     |   2\n",
      "       8972 |   0.188454  |    0.080949     |   0\n",
      "       8973 |   0.243381  |    0.016556     |   0\n",
      "       8974 |   0.208546  |    0.077937     |   0\n",
      "       8975 |   0.007441  |    0.027266     |   2\n",
      "       8976 |   0.230759  |    0.081270     |   0\n",
      "       8977 |   0.210506  |    0.043837     |   0\n",
      "       8978 |   0.221274  |    0.116162     |   1\n",
      "       8979 |   0.184484  |    0.151586     |   1\n",
      "       8980 |   0.093665  |    0.047203     |   2\n",
      "       8981 |   0.225010  |    0.054542     |   0\n",
      "       8982 |   0.191936  |    0.050885     |   0\n",
      "       8983 |   0.044077  |    0.043451     |   2\n",
      "       8984 |   0.208463  |    0.050546     |   0\n",
      "       8985 |   0.240456  |    0.142389     |   1\n",
      "       8986 |   0.212013  |    0.074412     |   0\n",
      "       8987 |   0.072923  |    0.010412     |   2\n",
      "       8988 |   0.285713  |    0.207236     |   1\n",
      "       8989 |   0.156718  |    0.172004     |   1\n",
      "       8990 |   0.258088  |    0.140681     |   1\n",
      "       8991 |   0.057238  |    0.053460     |   2\n",
      "       8992 |   0.024977  |    0.042476     |   2\n",
      "       8993 |   0.054550  |    0.072813     |   2\n",
      "       8994 |   0.181997  |    0.150289     |   1\n",
      "       8995 |   0.042555  |    0.037825     |   2\n",
      "       8996 |   0.000107  |    0.058412     |   2\n",
      "       8997 |   0.249237  |    0.153322     |   1\n",
      "       8998 |   0.206854  |    0.023465     |   0\n",
      "       8999 |   0.247848  |    0.082735     |   0\n",
      "       9000 |   0.304324  |    0.143015     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 9000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 9000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       9001 |   0.186791  |    0.078575     |   0\n",
      "       9002 |   0.061335  |    0.015754     |   2\n",
      "       9003 |   0.259151  |    0.073368     |   0\n",
      "       9004 |   0.246339  |    0.148988     |   1\n",
      "       9005 |   0.164101  |    0.011331     |   0\n",
      "       9006 |   0.048200  |    0.075186     |   2\n",
      "       9007 |   0.181564  |    0.016710     |   0\n",
      "       9008 |   0.228605  |    0.205611     |   1\n",
      "       9009 |   0.229358  |    0.005994     |   0\n",
      "       9010 |   0.164593  |    0.081563     |   0\n",
      "       9011 |   0.236261  |    0.023483     |   0\n",
      "       9012 |   0.161874  |    0.048326     |   0\n",
      "       9013 |   0.173391  |    0.075294     |   0\n",
      "       9014 |   0.049799  |    0.049097     |   2\n",
      "       9015 |   0.251693  |    0.146365     |   1\n",
      "       9016 |   0.064751  |    0.040738     |   2\n",
      "       9017 |   0.033623  |    0.049654     |   2\n",
      "       9018 |   0.168270  |    0.041761     |   0\n",
      "       9019 |   0.176641  |    0.051776     |   0\n",
      "       9020 |   0.216971  |    0.148957     |   1\n",
      "       9021 |   0.053082  |    0.070778     |   2\n",
      "       9022 |   0.064068  |    0.045586     |   2\n",
      "       9023 |   0.221938  |    0.199601     |   1\n",
      "       9024 |   0.215088  |    0.143343     |   1\n",
      "       9025 |   0.210074  |    0.016261     |   0\n",
      "       9026 |   0.283892  |    0.208560     |   1\n",
      "       9027 |   0.199111  |    0.004368     |   0\n",
      "       9028 |   0.365001  |    0.146880     |   1\n",
      "       9029 |   0.156554  |    0.141528     |   1\n",
      "       9030 |   0.180291  |    0.055387     |   0\n",
      "       9031 |   0.212330  |    0.201956     |   1\n",
      "       9032 |   0.248925  |    0.156936     |   1\n",
      "       9033 |   0.241403  |    0.042520     |   0\n",
      "       9034 |   0.260870  |    0.142286     |   1\n",
      "       9035 |   0.067193  |    0.051187     |   2\n",
      "       9036 |   0.246513  |    0.048125     |   0\n",
      "       9037 |   0.174020  |    0.045964     |   0\n",
      "       9038 |   0.212773  |    0.048729     |   0\n",
      "       9039 |   0.055823  |    0.033583     |   2\n",
      "       9040 |   0.235936  |    0.074785     |   0\n",
      "       9041 |   0.200057  |    0.015715     |   0\n",
      "       9042 |   0.250627  |    0.192961     |   1\n",
      "       9043 |   0.141619  |    0.154288     |   1\n",
      "       9044 |   0.210738  |    0.044599     |   0\n",
      "       9045 |   0.166790  |    0.048331     |   0\n",
      "       9046 |   0.201642  |    0.074848     |   0\n",
      "       9047 |   0.027410  |    0.014531     |   2\n",
      "       9048 |   0.000106  |    0.083127     |   2\n",
      "       9049 |   0.007229  |    0.011730     |   2\n",
      "       9050 |   0.220723  |    0.078499     |   0\n",
      "       9051 |   0.098318  |    0.020880     |   2\n",
      "       9052 |   0.200261  |    0.194359     |   1\n",
      "       9053 |   0.236653  |    0.158823     |   1\n",
      "       9054 |   0.045813  |    0.030557     |   2\n",
      "       9055 |   0.241862  |    0.153993     |   1\n",
      "       9056 |   0.215356  |    0.200308     |   1\n",
      "       9057 |   0.071647  |    0.023405     |   2\n",
      "       9058 |   0.191873  |    0.093321     |   0\n",
      "       9059 |   0.056027  |    0.007507     |   2\n",
      "       9060 |   0.023397  |    0.076992     |   2\n",
      "       9061 |   0.052828  |    0.040781     |   2\n",
      "       9062 |   0.039945  |    0.042845     |   2\n",
      "       9063 |   0.242644  |    0.074201     |   0\n",
      "       9064 |   0.000105  |    0.052063     |   2\n",
      "       9065 |   0.000105  |    0.041658     |   2\n",
      "       9066 |   0.220825  |    0.179304     |   1\n",
      "       9067 |   0.185939  |    0.045579     |   0\n",
      "       9068 |   0.159681  |    0.076619     |   0\n",
      "       9069 |   0.000107  |    0.033666     |   2\n",
      "       9070 |   0.197837  |    0.212906     |   1\n",
      "       9071 |   0.000106  |    0.006177     |   2\n",
      "       9072 |   0.185602  |    0.060249     |   0\n",
      "       9073 |   0.277289  |    0.191398     |   1\n",
      "       9074 |   0.000105  |    0.005645     |   2\n",
      "       9075 |   0.237308  |    0.078408     |   0\n",
      "       9076 |   0.000106  |    0.031012     |   2\n",
      "       9077 |   0.063258  |    0.054849     |   2\n",
      "       9078 |   0.233147  |    0.047538     |   0\n",
      "       9079 |   0.218304  |    0.049453     |   0\n",
      "       9080 |   0.197580  |    0.043067     |   0\n",
      "       9081 |   0.206516  |    0.081916     |   0\n",
      "       9082 |   0.334146  |    0.104591     |   1\n",
      "       9083 |   0.240256  |    0.185170     |   1\n",
      "       9084 |   0.263764  |    0.155085     |   1\n",
      "       9085 |   0.073133  |    0.039650     |   2\n",
      "       9086 |   0.279188  |    0.194507     |   1\n",
      "       9087 |   0.224059  |    0.221992     |   1\n",
      "       9088 |   0.135592  |    0.146392     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 9089: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       9089 |   0.066458  |    0.010598     |   2\n",
      "       9090 |   0.047417  |    0.022245     |   2\n",
      "       9091 |   0.050756  |    0.049118     |   2\n",
      "       9092 |   0.239460  |    0.198917     |   1\n",
      "       9093 |   0.266550  |    0.130903     |   1\n",
      "       9094 |   0.062458  |    0.040477     |   2\n",
      "       9095 |   0.243045  |    0.089900     |   0\n",
      "       9096 |   0.266190  |    0.087922     |   1\n",
      "       9097 |   0.239692  |    0.075808     |   0\n",
      "       9098 |   0.032101  |    0.022513     |   2\n",
      "       9099 |   0.185928  |    0.144402     |   1\n",
      "       9100 |   0.215796  |    0.218200     |   1\n",
      "       9101 |   0.230983  |    0.175137     |   1\n",
      "       9102 |   0.214370  |    0.134173     |   1\n",
      "       9103 |   0.205770  |    0.006321     |   0\n",
      "       9104 |   0.210255  |    0.045710     |   0\n",
      "       9105 |   0.236686  |    0.040823     |   0\n",
      "       9106 |   0.052970  |    0.043599     |   2\n",
      "       9107 |   0.059654  |    0.084438     |   2\n",
      "       9108 |   0.209079  |    0.142214     |   1\n",
      "       9109 |   0.067295  |    0.050552     |   2\n",
      "       9110 |   0.241380  |    0.202213     |   1\n",
      "       9111 |   0.271319  |    0.147687     |   1\n",
      "       9112 |   0.176430  |    0.053100     |   0\n",
      "       9113 |   0.182607  |    0.194471     |   1\n",
      "       9114 |   0.271379  |    0.075029     |   1\n",
      "       9115 |   0.058922  |    0.028062     |   2\n",
      "       9116 |   0.028764  |    0.079724     |   2\n",
      "       9117 |   0.172508  |    0.159438     |   1\n",
      "       9118 |   0.000104  |    0.052179     |   2\n",
      "       9119 |   0.192584  |    0.140563     |   1\n",
      "       9120 |   0.211947  |    0.092212     |   0\n",
      "       9121 |   0.243744  |    0.136544     |   1\n",
      "       9122 |   0.007439  |    0.038441     |   2\n",
      "       9123 |   0.266013  |    0.156477     |   1\n",
      "       9124 |   0.230205  |    0.044477     |   0\n",
      "       9125 |   0.224747  |    0.206638     |   1\n",
      "       9126 |   0.208639  |    0.012924     |   0\n",
      "       9127 |   0.096986  |    0.044705     |   2\n",
      "       9128 |   0.225631  |    0.157787     |   1\n",
      "       9129 |   0.223076  |    0.028142     |   0\n",
      "       9130 |   0.252422  |    0.045503     |   0\n",
      "       9131 |   0.194298  |    0.206306     |   1\n",
      "       9132 |   0.043153  |    0.019932     |   2\n",
      "       9133 |   0.210222  |    0.192824     |   1\n",
      "       9134 |   0.071873  |    0.025602     |   2\n",
      "       9135 |   0.227961  |    0.216550     |   1\n",
      "       9136 |   0.221536  |    0.151525     |   1\n",
      "       9137 |   0.250224  |    0.146735     |   1\n",
      "       9138 |   0.262825  |    0.008979     |   0\n",
      "       9139 |   0.186114  |    0.051691     |   0\n",
      "       9140 |   0.054099  |    0.043173     |   2\n",
      "       9141 |   0.022549  |    0.076394     |   2\n",
      "       9142 |   0.250678  |    0.132998     |   1\n",
      "       9143 |   0.215664  |    0.075451     |   0\n",
      "       9144 |   0.051984  |    0.022025     |   2\n",
      "       9145 |   0.197335  |    0.052302     |   0\n",
      "       9146 |   0.179866  |    0.211862     |   1\n",
      "       9147 |   0.182033  |    0.008056     |   0\n",
      "       9148 |   0.036729  |    0.040461     |   2\n",
      "       9149 |   0.000103  |    0.079626     |   2\n",
      "       9150 |   0.000104  |    0.042279     |   2\n",
      "       9151 |   0.238746  |    0.049395     |   0\n",
      "       9152 |   0.187898  |    0.152831     |   1\n",
      "       9153 |   0.205843  |    0.047973     |   0\n",
      "       9154 |   0.246379  |    0.159907     |   1\n",
      "       9155 |   0.000106  |    0.038283     |   2\n",
      "       9156 |   0.235708  |    0.049672     |   0\n",
      "       9157 |   0.247848  |    0.153390     |   1\n",
      "       9158 |   0.208175  |    0.145659     |   1\n",
      "       9159 |   0.000104  |    0.044395     |   2\n",
      "       9160 |   0.252097  |    0.163145     |   1\n",
      "       9161 |   0.000104  |    0.050823     |   2\n",
      "       9162 |   0.178854  |    0.172158     |   1\n",
      "       9163 |   0.209477  |    0.012402     |   0\n",
      "       9164 |   0.254697  |    0.170137     |   1\n",
      "       9165 |   0.000105  |    0.041485     |   2\n",
      "       9166 |   0.192862  |    0.211343     |   1\n",
      "       9167 |   0.243712  |    0.149465     |   1\n",
      "       9168 |   0.061910  |    0.012477     |   2\n",
      "       9169 |   0.212909  |    0.210715     |   1\n",
      "       9170 |   0.185626  |    0.005014     |   0\n",
      "       9171 |   0.209338  |    0.045500     |   0\n",
      "       9172 |   0.069938  |    0.041854     |   2\n",
      "       9173 |   0.233077  |    0.218726     |   1\n",
      "       9174 |   0.228944  |    0.139951     |   1\n",
      "       9175 |   0.225519  |    0.006796     |   0\n",
      "       9176 |   0.220336  |    0.080986     |   0\n",
      "       9177 |   0.170958  |    0.013484     |   0\n",
      "       9178 |   0.170789  |    0.196287     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 9179: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       9179 |   0.204545  |    0.023229     |   0\n",
      "       9180 |   0.065588  |    0.072680     |   2\n",
      "       9181 |   0.209226  |    0.007033     |   0\n",
      "       9182 |   0.222236  |    0.081923     |   0\n",
      "       9183 |   0.049719  |    0.014711     |   2\n",
      "       9184 |   0.297652  |    0.220799     |   1\n",
      "       9185 |   0.256060  |    0.141969     |   1\n",
      "       9186 |   0.155217  |    0.004923     |   0\n",
      "       9187 |   0.191201  |    0.040256     |   0\n",
      "       9188 |   0.245830  |    0.189113     |   1\n",
      "       9189 |   0.050364  |    0.006352     |   2\n",
      "       9190 |   0.257591  |    0.136806     |   1\n",
      "       9191 |   0.189057  |    0.212119     |   1\n",
      "       9192 |   0.066127  |    0.008480     |   2\n",
      "       9193 |   0.243099  |    0.073441     |   0\n",
      "       9194 |   0.174980  |    0.032992     |   0\n",
      "       9195 |   0.255360  |    0.149034     |   1\n",
      "       9196 |   0.033661  |    0.072311     |   2\n",
      "       9197 |   0.221147  |    0.025042     |   0\n",
      "       9198 |   0.236102  |    0.214018     |   1\n",
      "       9199 |   0.184199  |    0.113142     |   1\n",
      "       9200 |   0.052607  |    0.026869     |   2\n",
      "       9201 |   0.247033  |    0.096187     |   0\n",
      "       9202 |   0.293929  |    0.142395     |   1\n",
      "       9203 |   0.202411  |    0.004516     |   0\n",
      "       9204 |   0.236164  |    0.078480     |   0\n",
      "       9205 |   0.059127  |    0.032295     |   2\n",
      "       9206 |   0.220558  |    0.145631     |   1\n",
      "       9207 |   0.179000  |    0.051121     |   0\n",
      "       9208 |   0.216375  |    0.153361     |   1\n",
      "       9209 |   0.065512  |    0.041953     |   2\n",
      "       9210 |   0.263754  |    0.136596     |   1\n",
      "       9211 |   0.223854  |    0.047930     |   0\n",
      "       9212 |   0.060831  |    0.045091     |   2\n",
      "       9213 |   0.240221  |    0.082095     |   0\n",
      "       9214 |   0.030974  |    0.021185     |   2\n",
      "       9215 |   0.268574  |    0.150732     |   1\n",
      "       9216 |   0.000103  |    0.044828     |   2\n",
      "       9217 |   0.007716  |    0.041440     |   2\n",
      "       9218 |   0.206077  |    0.033119     |   0\n",
      "       9219 |   0.163786  |    0.057341     |   0\n",
      "       9220 |   0.205328  |    0.038699     |   0\n",
      "       9221 |   0.092403  |    0.044854     |   2\n",
      "       9222 |   0.044206  |    0.048379     |   2\n",
      "       9223 |   0.187790  |    0.075214     |   0\n",
      "       9224 |   0.072001  |    0.025045     |   2\n",
      "       9225 |   0.203683  |    0.094825     |   0\n",
      "       9226 |   0.254299  |    0.136861     |   1\n",
      "       9227 |   0.058234  |    0.041192     |   2\n",
      "       9228 |   0.236493  |    0.191631     |   1\n",
      "       9229 |   0.023758  |    0.009349     |   2\n",
      "       9230 |   0.186457  |    0.049379     |   0\n",
      "       9231 |   0.211732  |    0.178350     |   1\n",
      "       9232 |   0.214618  |    0.165905     |   1\n",
      "       9233 |   0.219300  |    0.201948     |   1\n",
      "       9234 |   0.181544  |    0.135185     |   1\n",
      "       9235 |   0.275827  |    0.045142     |   0\n",
      "       9236 |   0.050427  |    0.049407     |   2\n",
      "       9237 |   0.222076  |    0.141666     |   1\n",
      "       9238 |   0.200253  |    0.051645     |   0\n",
      "       9239 |   0.040624  |    0.049834     |   2\n",
      "       9240 |   0.234116  |    0.168044     |   1\n",
      "       9241 |   0.197884  |    0.139858     |   1\n",
      "       9242 |   0.000103  |    0.038151     |   2\n",
      "       9243 |   0.229648  |    0.186706     |   1\n",
      "       9244 |   0.166689  |    0.014902     |   0\n",
      "       9245 |   0.182587  |    0.205006     |   1\n",
      "       9246 |   0.222546  |    0.150398     |   1\n",
      "       9247 |   0.247867  |    0.137536     |   1\n",
      "       9248 |   0.242907  |    0.146457     |   1\n",
      "       9249 |   0.190202  |    0.167897     |   1\n",
      "       9250 |   0.211664  |    0.174103     |   1\n",
      "       9251 |   0.279740  |    0.147135     |   1\n",
      "       9252 |   0.247982  |    0.012198     |   0\n",
      "       9253 |   0.193754  |    0.055714     |   0\n",
      "       9254 |   0.234420  |    0.040800     |   0\n",
      "       9255 |   0.155527  |    0.039526     |   0\n",
      "       9256 |   0.000102  |    0.082853     |   2\n",
      "       9257 |   0.172947  |    0.013166     |   0\n",
      "       9258 |   0.227736  |    0.161635     |   1\n",
      "       9259 |   0.226337  |    0.187296     |   1\n",
      "       9260 |   0.206222  |    0.003371     |   0\n",
      "       9261 |   0.214084  |    0.078696     |   0\n",
      "       9262 |   0.241971  |    0.141760     |   1\n",
      "       9263 |   0.246540  |    0.196983     |   1\n",
      "       9264 |   0.000103  |    0.021989     |   2\n",
      "       9265 |   0.185194  |    0.221881     |   1\n",
      "       9266 |   0.000102  |    0.029788     |   2\n",
      "       9267 |   0.255356  |    0.216841     |   1\n",
      "       9268 |   0.219106  |    0.008340     |   0\n",
      "       9269 |   0.239047  |    0.046616     |   0\n",
      "       9270 |   0.176476  |    0.197694     |   1\n",
      "       9271 |   0.187457  |    0.143559     |   1\n",
      "       9272 |   0.227655  |    0.022617     |   0\n",
      "       9273 |   0.000102  |    0.078568     |   2\n",
      "       9274 |   0.218761  |    0.205005     |   1\n",
      "       9275 |   0.250715  |    0.153016     |   1\n",
      "       9276 |   0.238176  |    0.142409     |   1\n",
      "       9277 |   0.000102  |    0.005115     |   2\n",
      "       9278 |   0.264386  |    0.149162     |   1\n",
      "       9279 |   0.064562  |    0.008307     |   2\n",
      "       9280 |   0.232713  |    0.220486     |   1\n",
      "       9281 |   0.285995  |    0.159693     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 9283: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       9282 |   0.069817  |    0.022395     |   2\n",
      "       9283 |   0.248339  |    0.213304     |   1\n",
      "       9284 |   0.063519  |    0.006484     |   2\n",
      "       9285 |   0.148151  |    0.214454     |   1\n",
      "       9286 |   0.252282  |    0.005075     |   0\n",
      "       9287 |   0.243056  |    0.128328     |   1\n",
      "       9288 |   0.166500  |    0.051755     |   0\n",
      "       9289 |   0.047122  |    0.063163     |   2\n",
      "       9290 |   0.278500  |    0.164751     |   1\n",
      "       9291 |   0.049448  |    0.012788     |   2\n",
      "       9292 |   0.222855  |    0.078662     |   0\n",
      "       9293 |   0.208625  |    0.020580     |   0\n",
      "       9294 |   0.208300  |    0.077130     |   0\n",
      "       9295 |   0.171339  |    0.017428     |   0\n",
      "       9296 |   0.060661  |    0.079465     |   2\n",
      "       9297 |   0.032021  |    0.010602     |   2\n",
      "       9298 |   0.053907  |    0.050244     |   2\n",
      "       9299 |   0.056760  |    0.071576     |   2\n",
      "       9300 |   0.230957  |    0.187122     |   1\n",
      "       9301 |   0.191906  |    0.014200     |   0\n",
      "       9302 |   0.184218  |    0.119657     |   1\n",
      "       9303 |   0.066900  |    0.072856     |   2\n",
      "       9304 |   0.249171  |    0.026307     |   0\n",
      "       9305 |   0.230620  |    0.087746     |   0\n",
      "       9306 |   0.217426  |    0.153819     |   1\n",
      "       9307 |   0.209468  |    0.041402     |   0\n",
      "       9308 |   0.062001  |    0.074383     |   2\n",
      "       9309 |   0.031742  |    0.030061     |   2\n",
      "       9310 |   0.210487  |    0.215792     |   1\n",
      "       9311 |   0.166452  |    0.143020     |   1\n",
      "       9312 |   0.178772  |    0.170831     |   1\n",
      "       9313 |   0.186540  |    0.175383     |   1\n",
      "       9314 |   0.000100  |    0.019539     |   2\n",
      "       9315 |   0.267872  |    0.161042     |   1\n",
      "       9316 |   0.241417  |    0.189233     |   1\n",
      "       9317 |   0.258200  |    0.145720     |   1\n",
      "       9318 |   0.007067  |    0.043747     |   2\n",
      "       9319 |   0.257690  |    0.042732     |   0\n",
      "       9320 |   0.093252  |    0.071459     |   2\n",
      "       9321 |   0.203995  |    0.028977     |   0\n",
      "       9322 |   0.153377  |    0.039253     |   0\n",
      "       9323 |   0.044041  |    0.079427     |   2\n",
      "       9324 |   0.068376  |    0.016525     |   2\n",
      "       9325 |   0.054510  |    0.079847     |   2\n",
      "       9326 |   0.196318  |    0.171235     |   1\n",
      "       9327 |   0.168486  |    0.007278     |   0\n",
      "       9328 |   0.022876  |    0.086609     |   2\n",
      "       9329 |   0.048859  |    0.011393     |   2\n",
      "       9330 |   0.171095  |    0.085088     |   0\n",
      "       9331 |   0.208827  |    0.010406     |   0\n",
      "       9332 |   0.199990  |    0.083068     |   0\n",
      "       9333 |   0.037874  |    0.007498     |   2\n",
      "       9334 |   0.187885  |    0.076591     |   0\n",
      "       9335 |   0.219646  |    0.023493     |   0\n",
      "       9336 |   0.180231  |    0.045220     |   0\n",
      "       9337 |   0.000099  |    0.046153     |   2\n",
      "       9338 |   0.216975  |    0.137454     |   1\n",
      "       9339 |   0.297063  |    0.076068     |   0\n",
      "       9340 |   0.183306  |    0.147732     |   1\n",
      "       9341 |   0.259748  |    0.141891     |   1\n",
      "       9342 |   0.236931  |    0.028822     |   0\n",
      "       9343 |   0.256456  |    0.219584     |   1\n",
      "       9344 |   0.000099  |    0.009415     |   2\n",
      "       9345 |   0.167860  |    0.146928     |   1\n",
      "       9346 |   0.000100  |    0.028219     |   2\n",
      "       9347 |   0.213670  |    0.087376     |   0\n",
      "       9348 |   0.230577  |    0.146808     |   1\n",
      "       9349 |   0.000099  |    0.045032     |   2\n",
      "       9350 |   0.229392  |    0.105947     |   0\n",
      "       9351 |   0.251125  |    0.154282     |   1\n",
      "       9352 |   0.199056  |    0.005645     |   0\n",
      "       9353 |   0.000099  |    0.040470     |   2\n",
      "       9354 |   0.000100  |    0.049525     |   2\n",
      "       9355 |   0.068122  |    0.047129     |   2\n",
      "       9356 |   0.222117  |    0.141285     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 9358: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       9357 |   0.069796  |    0.029563     |   2\n",
      "       9358 |   0.206663  |    0.193780     |   1\n",
      "       9359 |   0.220964  |    0.025469     |   0\n",
      "       9360 |   0.171828  |    0.084438     |   0\n",
      "       9361 |   0.067174  |    0.008563     |   2\n",
      "       9362 |   0.050552  |    0.076217     |   2\n",
      "       9363 |   0.236201  |    0.013034     |   0\n",
      "       9364 |   0.234395  |    0.091266     |   0\n",
      "       9365 |   0.219433  |    0.148071     |   1\n",
      "       9366 |   0.187753  |    0.143578     |   1\n",
      "       9367 |   0.151804  |    0.169650     |   1\n",
      "       9368 |   0.224117  |    0.054493     |   0\n",
      "       9369 |   0.262049  |    0.187700     |   1\n",
      "       9370 |   0.223396  |    0.007024     |   0\n",
      "       9371 |   0.199189  |    0.079829     |   0\n",
      "       9372 |   0.198975  |    0.148901     |   1\n",
      "       9373 |   0.048743  |    0.026451     |   2\n",
      "       9374 |   0.063363  |    0.073071     |   2\n",
      "       9375 |   0.231208  |    0.033283     |   0\n",
      "       9376 |   0.235445  |    0.185446     |   1\n",
      "       9377 |   0.266973  |    0.013809     |   0\n",
      "       9378 |   0.032914  |    0.078629     |   2\n",
      "       9379 |   0.209455  |    0.030348     |   0\n",
      "       9380 |   0.203302  |    0.042504     |   0\n",
      "       9381 |   0.054201  |    0.086376     |   2\n",
      "       9382 |   0.063322  |    0.004924     |   2\n",
      "       9383 |   0.200553  |    0.073104     |   0\n",
      "       9384 |   0.216929  |    0.143021     |   1\n",
      "       9385 |   0.184893  |    0.165139     |   1\n",
      "       9386 |   0.065053  |    0.012056     |   2\n",
      "       9387 |   0.064255  |    0.046280     |   2\n",
      "       9388 |   0.223504  |    0.162609     |   1\n",
      "       9389 |   0.030336  |    0.042421     |   2\n",
      "       9390 |   0.157388  |    0.045253     |   0\n",
      "       9391 |   0.000099  |    0.045289     |   2\n",
      "       9392 |   0.162607  |    0.043568     |   0\n",
      "       9393 |   0.169061  |    0.052715     |   0\n",
      "       9394 |   0.208845  |    0.049433     |   0\n",
      "       9395 |   0.007220  |    0.036451     |   2\n",
      "       9396 |   0.203516  |    0.086393     |   0\n",
      "       9397 |   0.264731  |    0.139619     |   1\n",
      "       9398 |   0.194860  |    0.161753     |   1\n",
      "       9399 |   0.329274  |    0.150311     |   1\n",
      "       9400 |   0.094059  |    0.008515     |   2\n",
      "       9401 |   0.246739  |    0.081816     |   0\n",
      "       9402 |   0.273298  |    0.131357     |   1\n",
      "       9403 |   0.190449  |    0.009342     |   0\n",
      "       9404 |   0.204893  |    0.081559     |   0\n",
      "       9405 |   0.242126  |    0.165871     |   1\n",
      "       9406 |   0.044905  |    0.023350     |   2\n",
      "       9407 |   0.068048  |    0.059398     |   2\n",
      "       9408 |   0.307646  |    0.132453     |   1\n",
      "       9409 |   0.208846  |    0.029116     |   0\n",
      "       9410 |   0.053452  |    0.083342     |   2\n",
      "       9411 |   0.216263  |    0.160392     |   1\n",
      "       9412 |   0.023207  |    0.013546     |   2\n",
      "       9413 |   0.226134  |    0.155718     |   1\n",
      "       9414 |   0.049570  |    0.026153     |   2\n",
      "       9415 |   0.038389  |    0.062960     |   2\n",
      "       9416 |   0.171482  |    0.150782     |   1\n",
      "       9417 |   0.200553  |    0.163957     |   1\n",
      "       9418 |   0.238929  |    0.076623     |   0\n",
      "       9419 |   0.237722  |    0.165517     |   1\n",
      "       9420 |   0.287501  |    0.087291     |   1\n",
      "       9421 |   0.242551  |    0.045488     |   0\n",
      "       9422 |   0.251964  |    0.091138     |   0\n",
      "       9423 |   0.000100  |    0.009127     |   2\n",
      "       9424 |   0.000100  |    0.052649     |   2\n",
      "       9425 |   0.145190  |    0.209049     |   1\n",
      "       9426 |   0.000101  |    0.010126     |   2\n",
      "       9427 |   0.254869  |    0.073556     |   0\n",
      "       9428 |   0.000100  |    0.005864     |   2\n",
      "       9429 |   0.225622  |    0.091064     |   0\n",
      "       9430 |   0.172790  |    0.143005     |   1\n",
      "       9431 |   0.227438  |    0.030079     |   0\n",
      "       9432 |   0.235318  |    0.202419     |   1\n",
      "       9433 |   0.000099  |    0.027356     |   2\n",
      "       9434 |   0.188194  |    0.157400     |   1\n",
      "       9435 |   0.194315  |    0.027861     |   0\n",
      "       9436 |   0.250548  |    0.133820     |   1\n",
      "       9437 |   0.220629  |    0.075203     |   0\n",
      "       9438 |   0.000099  |    0.011073     |   2\n",
      "       9439 |   0.065259  |    0.079855     |   2\n",
      "       9440 |   0.070246  |    0.011061     |   2\n",
      "       9441 |   0.189239  |    0.181047     |   1\n",
      "       9442 |   0.174503  |    0.045884     |   0\n",
      "       9443 |   0.258226  |    0.192561     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 9444: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       9444 |   0.228652  |    0.143055     |   1\n",
      "       9445 |   0.208443  |    0.018656     |   0\n",
      "       9446 |   0.266639  |    0.081325     |   0\n",
      "       9447 |   0.247174  |    0.099889     |   1\n",
      "       9448 |   0.205512  |    0.048781     |   0\n",
      "       9449 |   0.176002  |    0.209123     |   1\n",
      "       9450 |   0.213122  |    0.009861     |   0\n",
      "       9451 |   0.067553  |    0.029029     |   2\n",
      "       9452 |   0.225119  |    0.201108     |   1\n",
      "       9453 |   0.273570  |    0.146346     |   1\n",
      "       9454 |   0.049901  |    0.029954     |   2\n",
      "       9455 |   0.050699  |    0.081787     |   2\n",
      "       9456 |   0.205303  |    0.137291     |   1\n",
      "       9457 |   0.153271  |    0.166774     |   1\n",
      "       9458 |   0.187685  |    0.163747     |   1\n",
      "       9459 |   0.171621  |    0.173973     |   1\n",
      "       9460 |   0.229539  |    0.147324     |   1\n",
      "       9461 |   0.196877  |    0.177466     |   1\n",
      "       9462 |   0.239517  |    0.178976     |   1\n",
      "       9463 |   0.242362  |    0.142266     |   1\n",
      "       9464 |   0.194985  |    0.115689     |   1\n",
      "       9465 |   0.238156  |    0.156038     |   1\n",
      "       9466 |   0.157010  |    0.044293     |   0\n",
      "       9467 |   0.061837  |    0.053130     |   2\n",
      "       9468 |   0.184685  |    0.145077     |   1\n",
      "       9469 |   0.234256  |    0.139862     |   1\n",
      "       9470 |   0.221602  |    0.202168     |   1\n",
      "       9471 |   0.264157  |    0.010111     |   0\n",
      "       9472 |   0.219312  |    0.172537     |   1\n",
      "       9473 |   0.031747  |    0.022652     |   2\n",
      "       9474 |   0.227430  |    0.074908     |   0\n",
      "       9475 |   0.055162  |    0.043987     |   2\n",
      "       9476 |   0.175007  |    0.201468     |   1\n",
      "       9477 |   0.207221  |    0.008461     |   0\n",
      "       9478 |   0.206752  |    0.044832     |   0\n",
      "       9479 |   0.276558  |    0.078527     |   0\n",
      "       9480 |   0.186561  |    0.026583     |   0\n",
      "       9481 |   0.235745  |    0.044686     |   0\n",
      "       9482 |   0.300876  |    0.042826     |   0\n",
      "       9483 |   0.257851  |    0.226857     |   1\n",
      "       9484 |   0.062435  |    0.007355     |   2\n",
      "       9485 |   0.066797  |    0.075383     |   2\n",
      "       9486 |   0.064698  |    0.038196     |   2\n",
      "       9487 |   0.214915  |    0.049862     |   0\n",
      "       9488 |   0.029682  |    0.040772     |   2\n",
      "       9489 |   0.000098  |    0.049519     |   2\n",
      "       9490 |   0.007848  |    0.029860     |   2\n",
      "       9491 |   0.194065  |    0.055412     |   0\n",
      "       9492 |   0.232421  |    0.212074     |   1\n",
      "       9493 |   0.211346  |    0.006198     |   0\n",
      "       9494 |   0.093035  |    0.046293     |   2\n",
      "       9495 |   0.208095  |    0.071279     |   0\n",
      "       9496 |   0.046323  |    0.038971     |   2\n",
      "       9497 |   0.225988  |    0.181317     |   1\n",
      "       9498 |   0.073157  |    0.075861     |   2\n",
      "       9499 |   0.057916  |    0.005470     |   2\n",
      "       9500 |   0.153733  |    0.040702     |   0\n",
      "       9501 |   0.068214  |    0.082575     |   2\n",
      "       9502 |   0.050414  |    0.034432     |   2\n",
      "       9503 |   0.209460  |    0.198222     |   1\n",
      "       9504 |   0.243147  |    0.012070     |   0\n",
      "       9505 |   0.204705  |    0.084699     |   0\n",
      "       9506 |   0.049015  |    0.025761     |   2\n",
      "       9507 |   0.242267  |    0.079100     |   0\n",
      "       9508 |   0.258792  |    0.153021     |   1\n",
      "       9509 |   0.216323  |    0.026963     |   0\n",
      "       9510 |   0.227853  |    0.148327     |   1\n",
      "       9511 |   0.210939  |    0.044339     |   0\n",
      "       9512 |   0.182818  |    0.082134     |   0\n",
      "       9513 |   0.202145  |    0.026226     |   0\n",
      "       9514 |   0.061993  |    0.080902     |   2\n",
      "       9515 |   0.193741  |    0.035599     |   0\n",
      "       9516 |   0.176281  |    0.203576     |   1\n",
      "       9517 |   0.188780  |    0.097176     |   1\n",
      "       9518 |   0.033853  |    0.022951     |   2\n",
      "       9519 |   0.052623  |    0.086688     |   2\n",
      "       9520 |   0.218901  |    0.105237     |   1\n",
      "       9521 |   0.059702  |    0.085729     |   2\n",
      "       9522 |   0.066099  |    0.012788     |   2\n",
      "       9523 |   0.207402  |    0.194273     |   1\n",
      "       9524 |   0.061626  |    0.037637     |   2\n",
      "       9525 |   0.205773  |    0.040470     |   0\n",
      "       9526 |   0.165955  |    0.048759     |   0\n",
      "       9527 |   0.027752  |    0.051683     |   2\n",
      "       9528 |   0.216174  |    0.205791     |   1\n",
      "       9529 |   0.198428  |    0.155293     |   1\n",
      "       9530 |   0.233681  |    0.027209     |   0\n",
      "       9531 |   0.282960  |    0.199457     |   1\n",
      "       9532 |   0.209872  |    0.015001     |   0\n",
      "       9533 |   0.231885  |    0.053495     |   0\n",
      "       9534 |   0.239091  |    0.066873     |   0\n",
      "       9535 |   0.189469  |    0.152507     |   1\n",
      "       9536 |   0.242472  |    0.018736     |   0\n",
      "       9537 |   0.287004  |    0.153141     |   1\n",
      "       9538 |   0.000098  |    0.043574     |   2\n",
      "       9539 |   0.007045  |    0.046324     |   2\n",
      "       9540 |   0.237687  |    0.198772     |   1\n",
      "       9541 |   0.235900  |    0.005440     |   0\n",
      "       9542 |   0.090709  |    0.027676     |   2\n",
      "       9543 |   0.043831  |    0.050993     |   2\n",
      "       9544 |   0.265178  |    0.149162     |   1\n",
      "       9545 |   0.188718  |    0.008078     |   0\n",
      "       9546 |   0.240786  |    0.079496     |   0\n",
      "       9547 |   0.200155  |    0.010448     |   0\n",
      "       9548 |   0.068768  |    0.073173     |   2\n",
      "       9549 |   0.190760  |    0.015765     |   0\n",
      "       9550 |   0.054829  |    0.086791     |   2\n",
      "       9551 |   0.157094  |    0.018494     |   0\n",
      "       9552 |   0.168350  |    0.206958     |   1\n",
      "       9553 |   0.023993  |    0.006136     |   2\n",
      "       9554 |   0.052839  |    0.077592     |   2\n",
      "       9555 |   0.035979  |    0.014536     |   2\n",
      "       9556 |   0.196315  |    0.076631     |   0\n",
      "       9557 |   0.216411  |    0.027453     |   0\n",
      "       9558 |   0.274028  |    0.178545     |   1\n",
      "       9559 |   0.000096  |    0.040028     |   2\n",
      "       9560 |   0.200677  |    0.073264     |   0\n",
      "       9561 |   0.151991  |    0.157983     |   1\n",
      "       9562 |   0.264092  |    0.192735     |   1\n",
      "       9563 |   0.203229  |    0.018380     |   0\n",
      "       9564 |   0.000097  |    0.034651     |   2\n",
      "       9565 |   0.214108  |    0.043028     |   0\n",
      "       9566 |   0.155565  |    0.207308     |   1\n",
      "       9567 |   0.000099  |    0.048688     |   2\n",
      "       9568 |   0.207234  |    0.189449     |   1\n",
      "       9569 |   0.214352  |    0.005651     |   0\n",
      "       9570 |   0.216449  |    0.054583     |   0\n",
      "       9571 |   0.185695  |    0.043069     |   0\n",
      "       9572 |   0.171570  |    0.048359     |   0\n",
      "       9573 |   0.131503  |    0.199827     |   1\n",
      "       9574 |   0.204533  |    0.136549     |   1\n",
      "       9575 |   0.269734  |    0.035269     |   0\n",
      "       9576 |   0.175827  |    0.213209     |   1\n",
      "       9577 |   0.158606  |    0.004929     |   0\n",
      "       9578 |   0.132939  |    0.081144     |   0\n",
      "       9579 |   0.169059  |    0.024065     |   0\n",
      "       9580 |   0.000097  |    0.047514     |   2\n",
      "       9581 |   0.000096  |    0.084597     |   2\n",
      "       9582 |   0.165936  |    0.024279     |   0\n",
      "       9583 |   0.195079  |    0.070641     |   0\n",
      "       9584 |   0.162249  |    0.149989     |   1\n",
      "       9585 |   0.246473  |    0.183653     |   1\n",
      "       9586 |   0.179020  |    0.152670     |   1\n",
      "       9587 |   0.237347  |    0.155482     |   1\n",
      "       9588 |   0.184846  |    0.148023     |   1\n",
      "       9589 |   0.000096  |    0.006431     |   2\n",
      "       9590 |   0.181322  |    0.077276     |   0\n",
      "       9591 |   0.065994  |    0.023534     |   2\n",
      "       9592 |   0.196634  |    0.084604     |   0\n",
      "       9593 |   0.233159  |    0.140320     |   1\n",
      "       9594 |   0.070866  |    0.025069     |   2\n",
      "       9595 |   0.238718  |    0.198957     |   1\n",
      "       9596 |   0.236549  |    0.032813     |   0\n",
      "       9597 |   0.223529  |    0.039886     |   0\n",
      "       9598 |   0.294926  |    0.150041     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 9599: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       9599 |   0.216451  |    0.076346     |   0\n",
      "       9600 |   0.221951  |    0.167198     |   1\n",
      "       9601 |   0.233552  |    0.025087     |   0\n",
      "       9602 |   0.214527  |    0.084617     |   0\n",
      "       9603 |   0.283111  |    0.136853     |   1\n",
      "       9604 |   0.156386  |    0.128538     |   1\n",
      "       9605 |   0.241908  |    0.042913     |   0\n",
      "       9606 |   0.152096  |    0.039626     |   0\n",
      "       9607 |   0.070389  |    0.071562     |   2\n",
      "       9608 |   0.184628  |    0.025162     |   0\n",
      "       9609 |   0.185892  |    0.050680     |   0\n",
      "       9610 |   0.146657  |    0.047774     |   0\n",
      "       9611 |   0.209522  |    0.049293     |   0\n",
      "       9612 |   0.255089  |    0.130999     |   1\n",
      "       9613 |   0.188073  |    0.077242     |   0\n",
      "       9614 |   0.307747  |    0.044116     |   0\n",
      "       9615 |   0.213295  |    0.041604     |   0\n",
      "       9616 |   0.047971  |    0.055347     |   2\n",
      "       9617 |   0.263512  |    0.154956     |   1\n",
      "       9618 |   0.154004  |    0.046045     |   0\n",
      "       9619 |   0.176142  |    0.044988     |   0\n",
      "       9620 |   0.197823  |    0.041163     |   0\n",
      "       9621 |   0.050995  |    0.042950     |   2\n",
      "       9622 |   0.066167  |    0.079091     |   2\n",
      "       9623 |   0.033410  |    0.013736     |   2\n",
      "       9624 |   0.288686  |    0.207731     |   1\n",
      "       9625 |   0.052835  |    0.041380     |   2\n",
      "       9626 |   0.061257  |    0.046637     |   2\n",
      "       9627 |   0.260090  |    0.197588     |   1\n",
      "       9628 |   0.071238  |    0.024567     |   2\n",
      "       9629 |   0.177170  |    0.052912     |   0\n",
      "       9630 |   0.177079  |    0.041175     |   0\n",
      "       9631 |   0.225971  |    0.073934     |   0\n",
      "       9632 |   0.220036  |    0.154723     |   1\n",
      "       9633 |   0.061947  |    0.043902     |   2\n",
      "       9634 |   0.172073  |    0.044085     |   0\n",
      "       9635 |   0.230653  |    0.078186     |   0\n",
      "       9636 |   0.029224  |    0.029853     |   2\n",
      "       9637 |   0.275584  |    0.152388     |   1\n",
      "       9638 |   0.246511  |    0.200011     |   1\n",
      "       9639 |   0.176894  |    0.141070     |   1\n",
      "       9640 |   0.000097  |    0.055711     |   2\n",
      "       9641 |   0.007011  |    0.045651     |   2\n",
      "       9642 |   0.250171  |    0.140881     |   1\n",
      "       9643 |   0.227303  |    0.157630     |   1\n",
      "       9644 |   0.091537  |    0.010016     |   2\n",
      "       9645 |   0.047492  |    0.058484     |   2\n",
      "       9646 |   0.174730  |    0.049495     |   0\n",
      "       9647 |   0.241469  |    0.055142     |   0\n",
      "       9648 |   0.196875  |    0.150836     |   1\n",
      "       9649 |   0.208751  |    0.054565     |   0\n",
      "       9650 |   0.228120  |    0.198789     |   1\n",
      "       9651 |   0.266844  |    0.139855     |   1\n",
      "       9652 |   0.162510  |    0.007582     |   0\n",
      "       9653 |   0.204988  |    0.051458     |   0\n",
      "       9654 |   0.282427  |    0.042508     |   0\n",
      "       9655 |   0.164638  |    0.088290     |   0\n",
      "       9656 |   0.218217  |    0.153879     |   1\n",
      "       9657 |   0.189517  |    0.007874     |   0\n",
      "       9658 |   0.069013  |    0.071591     |   2\n",
      "       9659 |   0.149105  |    0.174125     |   1\n",
      "       9660 |   0.054026  |    0.048577     |   2\n",
      "       9661 |   0.166644  |    0.039665     |   0\n",
      "       9662 |   0.200829  |    0.203680     |   1\n",
      "       9663 |   0.025285  |    0.005393     |   2\n",
      "       9664 |   0.051595  |    0.074912     |   2\n",
      "       9665 |   0.038944  |    0.025643     |   2\n",
      "       9666 |   0.223727  |    0.199067     |   1\n",
      "       9667 |   0.215368  |    0.157792     |   1\n",
      "       9668 |   0.210167  |    0.176262     |   1\n",
      "       9669 |   0.234232  |    0.143565     |   1\n",
      "       9670 |   0.233958  |    0.158496     |   1\n",
      "       9671 |   0.174923  |    0.143694     |   1\n",
      "       9672 |   0.216181  |    0.164946     |   1\n",
      "       9673 |   0.221463  |    0.163017     |   1\n",
      "       9674 |   0.219440  |    0.004687     |   0\n",
      "       9675 |   0.286814  |    0.189472     |   1\n",
      "       9676 |   0.000098  |    0.006784     |   2\n",
      "       9677 |   0.203135  |    0.081144     |   0\n",
      "       9678 |   0.237375  |    0.026641     |   0\n",
      "       9679 |   0.195994  |    0.075654     |   0\n",
      "       9680 |   0.167728  |    0.010919     |   0\n",
      "       9681 |   0.000098  |    0.082377     |   2\n",
      "       9682 |   0.189439  |    0.157128     |   1\n",
      "       9683 |   0.203853  |    0.157065     |   1\n",
      "       9684 |   0.222145  |    0.144271     |   1\n",
      "       9685 |   0.000098  |    0.006856     |   2\n",
      "       9686 |   0.264657  |    0.048873     |   0\n",
      "       9687 |   0.190820  |    0.041980     |   0\n",
      "       9688 |   0.240963  |    0.086263     |   0\n",
      "       9689 |   0.170105  |    0.155224     |   1\n",
      "       9690 |   0.181524  |    0.017734     |   0\n",
      "       9691 |   0.210604  |    0.209604     |   1\n",
      "       9692 |   0.000097  |    0.013039     |   2\n",
      "       9693 |   0.182126  |    0.163608     |   1\n",
      "       9694 |   0.000097  |    0.076483     |   2\n",
      "       9695 |   0.000097  |    0.017961     |   2\n",
      "       9696 |   0.206801  |    0.086456     |   0\n",
      "       9697 |   0.211721  |    0.143993     |   1\n",
      "       9698 |   0.066924  |    0.017025     |   2\n",
      "       9699 |   0.187968  |    0.211841     |   1\n",
      "       9700 |   0.176265  |    0.160818     |   1\n",
      "       9701 |   0.221533  |    0.143652     |   1\n",
      "       9702 |   0.290352  |    0.140783     |   1\n",
      "       9703 |   0.244548  |    0.151861     |   1\n",
      "       9704 |   0.224770  |    0.005453     |   0\n",
      "       9705 |   0.068383  |    0.080155     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 9707: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       9706 |   0.240760  |    0.027529     |   0\n",
      "       9707 |   0.219951  |    0.077561     |   0\n",
      "       9708 |   0.224205  |    0.157673     |   1\n",
      "       9709 |   0.193527  |    0.167859     |   1\n",
      "       9710 |   0.182356  |    0.046012     |   0\n",
      "       9711 |   0.068681  |    0.042768     |   2\n",
      "       9712 |   0.048326  |    0.080713     |   2\n",
      "       9713 |   0.050839  |    0.040432     |   2\n",
      "       9714 |   0.063881  |    0.041583     |   2\n",
      "       9715 |   0.204634  |    0.077716     |   0\n",
      "       9716 |   0.224722  |    0.049852     |   0\n",
      "       9717 |   0.034067  |    0.008692     |   2\n",
      "       9718 |   0.052460  |    0.081162     |   2\n",
      "       9719 |   0.060828  |    0.006343     |   2\n",
      "       9720 |   0.192497  |    0.051559     |   0\n",
      "       9721 |   0.193741  |    0.187564     |   1\n",
      "       9722 |   0.066879  |    0.030898     |   2\n",
      "       9723 |   0.061793  |    0.057403     |   2\n",
      "       9724 |   0.028759  |    0.053657     |   2\n",
      "       9725 |   0.186171  |    0.169251     |   1\n",
      "       9726 |   0.184541  |    0.164100     |   1\n",
      "       9727 |   0.230951  |    0.023210     |   0\n",
      "       9728 |   0.193565  |    0.047019     |   0\n",
      "       9729 |   0.000096  |    0.078120     |   2\n",
      "       9730 |   0.006823  |    0.024614     |   2\n",
      "       9731 |   0.229456  |    0.079816     |   0\n",
      "       9732 |   0.223149  |    0.021558     |   0\n",
      "       9733 |   0.212450  |    0.205455     |   1\n",
      "       9734 |   0.242695  |    0.087382     |   1\n",
      "       9735 |   0.092064  |    0.077214     |   2\n",
      "       9736 |   0.046857  |    0.026297     |   2\n",
      "       9737 |   0.071378  |    0.042086     |   2\n",
      "       9738 |   0.054894  |    0.042850     |   2\n",
      "       9739 |   0.025665  |    0.085936     |   2\n",
      "       9740 |   0.271421  |    0.149313     |   1\n",
      "       9741 |   0.055902  |    0.019240     |   2\n",
      "       9742 |   0.220368  |    0.190323     |   1\n",
      "       9743 |   0.038176  |    0.030503     |   2\n",
      "       9744 |   0.183492  |    0.196505     |   1\n",
      "       9745 |   0.166069  |    0.011338     |   0\n",
      "       9746 |   0.226157  |    0.080966     |   0\n",
      "       9747 |   0.219120  |    0.014395     |   0\n",
      "       9748 |   0.194483  |    0.080840     |   0\n",
      "       9749 |   0.212463  |    0.030672     |   0\n",
      "       9750 |   0.000096  |    0.081798     |   2\n",
      "       9751 |   0.000096  |    0.019570     |   2\n",
      "       9752 |   0.233824  |    0.220475     |   1\n",
      "       9753 |   0.000097  |    0.006866     |   2\n",
      "       9754 |   0.258876  |    0.166635     |   1\n",
      "       9755 |   0.000096  |    0.041398     |   2\n",
      "       9756 |   0.269155  |    0.070135     |   0\n",
      "       9757 |   0.240827  |    0.188181     |   1\n",
      "       9758 |   0.000096  |    0.005189     |   2\n",
      "       9759 |   0.158404  |    0.080560     |   0\n",
      "       9760 |   0.206819  |    0.148658     |   1\n",
      "       9761 |   0.199363  |    0.028930     |   0\n",
      "       9762 |   0.266135  |    0.198624     |   1\n",
      "       9763 |   0.160637  |    0.010251     |   0\n",
      "       9764 |   0.236406  |    0.143138     |   1\n",
      "       9765 |   0.176156  |    0.075841     |   0\n",
      "       9766 |   0.000095  |    0.027900     |   2\n",
      "       9767 |   0.195848  |    0.086058     |   0\n",
      "       9768 |   0.289274  |    0.142353     |   1\n",
      "       9769 |   0.067813  |    0.070356     |   2\n",
      "       9770 |   0.069697  |    0.021639     |   2\n",
      "       9771 |   0.189080  |    0.072984     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 9772: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       9772 |   0.067100  |    0.025880     |   2\n",
      "       9773 |   0.048203  |    0.077019     |   2\n",
      "       9774 |   0.049715  |    0.023880     |   2\n",
      "       9775 |   0.224342  |    0.217543     |   1\n",
      "       9776 |   0.062847  |    0.006359     |   2\n",
      "       9777 |   0.193745  |    0.161824     |   1\n",
      "       9778 |   0.220288  |    0.019773     |   0\n",
      "       9779 |   0.191794  |    0.200928     |   1\n",
      "       9780 |   0.231848  |    0.009952     |   0\n",
      "       9781 |   0.034187  |    0.098078     |   2\n",
      "       9782 |   0.244489  |    0.145256     |   1\n",
      "       9783 |   0.050676  |    0.042661     |   2\n",
      "       9784 |   0.197489  |    0.194727     |   1\n",
      "       9785 |   0.063706  |    0.011871     |   2\n",
      "       9786 |   0.167923  |    0.043249     |   0\n",
      "       9787 |   0.065900  |    0.071403     |   2\n",
      "       9788 |   0.242032  |    0.156531     |   1\n",
      "       9789 |   0.253376  |    0.004151     |   0\n",
      "       9790 |   0.227547  |    0.196264     |   1\n",
      "       9791 |   0.212071  |    0.037909     |   0\n",
      "       9792 |   0.261646  |    0.210793     |   1\n",
      "       9793 |   0.240413  |    0.141593     |   1\n",
      "       9794 |   0.217097  |    0.009317     |   0\n",
      "       9795 |   0.188710  |    0.083826     |   0\n",
      "       9796 |   0.062141  |    0.016248     |   2\n",
      "       9797 |   0.204056  |    0.080728     |   0\n",
      "       9798 |   0.027637  |    0.028890     |   2\n",
      "       9799 |   0.215545  |    0.076010     |   0\n",
      "       9800 |   0.236856  |    0.146397     |   1\n",
      "       9801 |   0.000094  |    0.018365     |   2\n",
      "       9802 |   0.156599  |    0.048684     |   0\n",
      "       9803 |   0.006762  |    0.041605     |   2\n",
      "       9804 |   0.260112  |    0.043486     |   0\n",
      "       9805 |   0.198841  |    0.074937     |   0\n",
      "       9806 |   0.092238  |    0.027699     |   2\n",
      "       9807 |   0.044273  |    0.041241     |   2\n",
      "       9808 |   0.208344  |    0.078576     |   0\n",
      "       9809 |   0.069402  |    0.009935     |   2\n",
      "       9810 |   0.153602  |    0.044668     |   0\n",
      "       9811 |   0.309030  |    0.200012     |   1\n",
      "       9812 |   0.254388  |    0.146646     |   1\n",
      "       9813 |   0.158641  |    0.147085     |   1\n",
      "       9814 |   0.265639  |    0.144265     |   1\n",
      "       9815 |   0.054241  |    0.023776     |   2\n",
      "       9816 |   0.023367  |    0.051600     |   2\n",
      "       9817 |   0.050817  |    0.075468     |   2\n",
      "       9818 |   0.203514  |    0.164008     |   1\n",
      "       9819 |   0.196825  |    0.197426     |   1\n",
      "       9820 |   0.258960  |    0.161439     |   1\n",
      "       9821 |   0.156995  |    0.005300     |   0\n",
      "       9822 |   0.169108  |    0.145709     |   1\n",
      "       9823 |   0.254225  |    0.044893     |   0\n",
      "       9824 |   0.038360  |    0.038390     |   2\n",
      "       9825 |   0.135462  |    0.044900     |   0\n",
      "       9826 |   0.000094  |    0.044022     |   2\n",
      "       9827 |   0.230018  |    0.137716     |   1\n",
      "       9828 |   0.000094  |    0.076180     |   2\n",
      "       9829 |   0.000095  |    0.022455     |   2\n",
      "       9830 |   0.000094  |    0.085898     |   2\n",
      "       9831 |   0.000094  |    0.025897     |   2\n",
      "       9832 |   0.188200  |    0.078728     |   0\n",
      "       9833 |   0.195764  |    0.027749     |   0\n",
      "       9834 |   0.308643  |    0.154360     |   1\n",
      "       9835 |   0.187595  |    0.041248     |   0\n",
      "       9836 |   0.178791  |    0.047743     |   0\n",
      "       9837 |   0.214183  |    0.045318     |   0\n",
      "       9838 |   0.000094  |    0.054312     |   2\n",
      "       9839 |   0.276713  |    0.134006     |   1\n",
      "       9840 |   0.161082  |    0.048023     |   0\n",
      "       9841 |   0.064918  |    0.031197     |   2\n",
      "       9842 |   0.068035  |    0.049228     |   2\n",
      "       9843 |   0.221269  |    0.170050     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 9845: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       9844 |   0.238643  |    0.010489     |   0\n",
      "       9845 |   0.268298  |    0.069383     |   0\n",
      "       9846 |   0.066793  |    0.041720     |   2\n",
      "       9847 |   0.208406  |    0.207973     |   1\n",
      "       9848 |   0.228324  |    0.154938     |   1\n",
      "       9849 |   0.244060  |    0.006093     |   0\n",
      "       9850 |   0.153715  |    0.080340     |   0\n",
      "       9851 |   0.231731  |    0.175532     |   1\n",
      "       9852 |   0.188277  |    0.004622     |   0\n",
      "       9853 |   0.153405  |    0.041179     |   0\n",
      "       9854 |   0.155269  |    0.074335     |   0\n",
      "       9855 |   0.049316  |    0.009511     |   2\n",
      "       9856 |   0.050781  |    0.088992     |   2\n",
      "       9857 |   0.064005  |    0.026375     |   2\n",
      "       9858 |   0.185982  |    0.071173     |   0\n",
      "       9859 |   0.032890  |    0.029538     |   2\n",
      "       9860 |   0.212802  |    0.198159     |   1\n",
      "       9861 |   0.204045  |    0.017073     |   0\n",
      "       9862 |   0.051434  |    0.096052     |   2\n",
      "       9863 |   0.063828  |    0.004551     |   2\n",
      "       9864 |   0.216360  |    0.080643     |   0\n",
      "       9865 |   0.298105  |    0.151762     |   1\n",
      "       9866 |   0.065341  |    0.010192     |   2\n",
      "       9867 |   0.136714  |    0.218354     |   1\n",
      "       9868 |   0.237882  |    0.159283     |   1\n",
      "       9869 |   0.201735  |    0.145993     |   1\n",
      "       9870 |   0.059547  |    0.016833     |   2\n",
      "       9871 |   0.217933  |    0.198080     |   1\n",
      "       9872 |   0.026657  |    0.041842     |   2\n",
      "       9873 |   0.203076  |    0.205790     |   1\n",
      "       9874 |   0.219124  |    0.137944     |   1\n",
      "       9875 |   0.195968  |    0.103691     |   1\n",
      "       9876 |   0.182021  |    0.153638     |   1\n",
      "       9877 |   0.000093  |    0.027258     |   2\n",
      "       9878 |   0.284955  |    0.197551     |   1\n",
      "       9879 |   0.006929  |    0.014435     |   2\n",
      "       9880 |   0.095838  |    0.083684     |   2\n",
      "       9881 |   0.248714  |    0.171718     |   1\n",
      "       9882 |   0.206294  |    0.170901     |   1\n",
      "       9883 |   0.194977  |    0.041259     |   0\n",
      "       9884 |   0.043590  |    0.042838     |   2\n",
      "       9885 |   0.200942  |    0.074201     |   0\n",
      "       9886 |   0.066447  |    0.031019     |   2\n",
      "       9887 |   0.052506  |    0.044552     |   2\n",
      "       9888 |   0.224260  |    0.183185     |   1\n",
      "       9889 |   0.022345  |    0.005070     |   2\n",
      "       9890 |   0.047440  |    0.073429     |   2\n",
      "       9891 |   0.039789  |    0.035303     |   2\n",
      "       9892 |   0.204918  |    0.208019     |   1\n",
      "       9893 |   0.244427  |    0.005445     |   0\n",
      "       9894 |   0.185515  |    0.044174     |   0\n",
      "       9895 |   0.180743  |    0.083831     |   0\n",
      "       9896 |   0.000093  |    0.016338     |   2\n",
      "       9897 |   0.000093  |    0.080190     |   2\n",
      "       9898 |   0.177483  |    0.008532     |   0\n",
      "       9899 |   0.000094  |    0.081638     |   2\n",
      "       9900 |   0.000093  |    0.008737     |   2\n",
      "       9901 |   0.194496  |    0.193556     |   1\n",
      "       9902 |   0.164718  |    0.008614     |   0\n",
      "       9903 |   0.205906  |    0.085723     |   0\n",
      "       9904 |   0.165365  |    0.141957     |   1\n",
      "       9905 |   0.197959  |    0.153606     |   1\n",
      "       9906 |   0.231410  |    0.032331     |   0\n",
      "       9907 |   0.257404  |    0.212000     |   1\n",
      "       9908 |   0.000092  |    0.008151     |   2\n",
      "       9909 |   0.208738  |    0.078280     |   0\n",
      "       9910 |   0.000092  |    0.015023     |   2\n",
      "       9911 |   0.251899  |    0.080405     |   0\n",
      "       9912 |   0.248189  |    0.130001     |   1\n",
      "       9913 |   0.059603  |    0.037696     |   2\n",
      "       9914 |   0.194455  |    0.103147     |   0\n",
      "       9915 |   0.224245  |    0.131372     |   1\n",
      "       9916 |   0.238397  |    0.181188     |   1\n",
      "       9917 |   0.181506  |    0.154131     |   1\n",
      "       9918 |   0.227232  |    0.169757     |   1\n",
      "       9919 |   0.229708  |    0.040154     |   0\n",
      "       9920 |   0.265657  |    0.189259     |   1\n",
      "       9921 |   0.067922  |    0.014397     |   2\n",
      "       9922 |   0.220880  |    0.080589     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 9924: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       9923 |   0.200169  |    0.014300     |   0\n",
      "       9924 |   0.067198  |    0.042584     |   2\n",
      "       9925 |   0.229783  |    0.211081     |   1\n",
      "       9926 |   0.208997  |    0.019221     |   0\n",
      "       9927 |   0.212901  |    0.158041     |   1\n",
      "       9928 |   0.178501  |    0.175921     |   1\n",
      "       9929 |   0.045774  |    0.006178     |   2\n",
      "       9930 |   0.051461  |    0.047258     |   2\n",
      "       9931 |   0.196467  |    0.073660     |   0\n",
      "       9932 |   0.061829  |    0.039860     |   2\n",
      "       9933 |   0.032627  |    0.042876     |   2\n",
      "       9934 |   0.197346  |    0.084471     |   0\n",
      "       9935 |   0.156679  |    0.151054     |   1\n",
      "       9936 |   0.239322  |    0.048692     |   0\n",
      "       9937 |   0.260121  |    0.197418     |   1\n",
      "       9938 |   0.170244  |    0.132818     |   1\n",
      "       9939 |   0.235524  |    0.045838     |   0\n",
      "       9940 |   0.193169  |    0.201983     |   1\n",
      "       9941 |   0.051893  |    0.004117     |   2\n",
      "       9942 |   0.179751  |    0.048016     |   0\n",
      "       9943 |   0.064551  |    0.048243     |   2\n",
      "       9944 |   0.164676  |    0.214110     |   1\n",
      "       9945 |   0.175607  |    0.128538     |   1\n",
      "       9946 |   0.068436  |    0.004523     |   2\n",
      "       9947 |   0.208200  |    0.051444     |   0\n",
      "       9948 |   0.062152  |    0.072010     |   2\n",
      "       9949 |   0.028939  |    0.047669     |   2\n",
      "       9950 |   0.169300  |    0.047261     |   0\n",
      "       9951 |   0.205974  |    0.045332     |   0\n",
      "       9952 |   0.000091  |    0.051850     |   2\n",
      "       9953 |   0.166553  |    0.205380     |   1\n",
      "       9954 |   0.007005  |    0.007006     |   2\n",
      "       9955 |   0.092461  |    0.074816     |   2\n",
      "       9956 |   0.044083  |    0.028317     |   2\n",
      "       9957 |   0.165146  |    0.076127     |   0\n",
      "       9958 |   0.171241  |    0.029334     |   0\n",
      "       9959 |   0.069741  |    0.047246     |   2\n",
      "       9960 |   0.165306  |    0.041260     |   0\n",
      "       9961 |   0.053671  |    0.043941     |   2\n",
      "       9962 |   0.198809  |    0.043825     |   0\n",
      "       9963 |   0.263043  |    0.142003     |   1\n",
      "       9964 |   0.200325  |    0.046858     |   0\n",
      "       9965 |   0.023023  |    0.070616     |   2\n",
      "       9966 |   0.222297  |    0.142533     |   1\n",
      "       9967 |   0.213422  |    0.030002     |   0\n",
      "       9968 |   0.217068  |    0.080538     |   0\n",
      "       9969 |   0.235662  |    0.144343     |   1\n",
      "       9970 |   0.174777  |    0.104548     |   1\n",
      "       9971 |   0.182894  |    0.050261     |   0\n",
      "       9972 |   0.212822  |    0.141961     |   1\n",
      "       9973 |   0.234215  |    0.047270     |   0\n",
      "       9974 |   0.050905  |    0.051002     |   2\n",
      "       9975 |   0.229403  |    0.165682     |   1\n",
      "       9976 |   0.039025  |    0.046467     |   2\n",
      "       9977 |   0.209040  |    0.042381     |   0\n",
      "       9978 |   0.000091  |    0.040582     |   2\n",
      "       9979 |   0.156930  |    0.041668     |   0\n",
      "       9980 |   0.212456  |    0.196486     |   1\n",
      "       9981 |   0.000091  |    0.005324     |   2\n",
      "       9982 |   0.169705  |    0.053456     |   0\n",
      "       9983 |   0.172260  |    0.146762     |   1\n",
      "       9984 |   0.143103  |    0.015624     |   0\n",
      "       9985 |   0.192586  |    0.071857     |   0\n",
      "       9986 |   0.179500  |    0.031727     |   0\n",
      "       9987 |   0.179691  |    0.190618     |   1\n",
      "       9988 |   0.179907  |    0.011262     |   0\n",
      "       9989 |   0.185483  |    0.080387     |   0\n",
      "       9990 |   0.000091  |    0.030341     |   2\n",
      "       9991 |   0.000091  |    0.068573     |   2\n",
      "       9992 |   0.171366  |    0.158326     |   1\n",
      "       9993 |   0.000091  |    0.015774     |   2\n",
      "       9994 |   0.243054  |    0.218821     |   1\n",
      "       9995 |   0.243797  |    0.005984     |   0\n",
      "       9996 |   0.195558  |    0.146489     |   1\n",
      "       9997 |   0.168726  |    0.040677     |   0\n",
      "       9998 |   0.239460  |    0.191165     |   1\n",
      "       9999 |   0.213064  |    0.012424     |   0\n",
      "      10000 |   0.197537  |    0.081877     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 10000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 10000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      10001 |   0.173385  |    0.076719     |   0\n",
      "      10002 |   0.191802  |    0.039246     |   0\n",
      "      10003 |   0.067496  |    0.083316     |   2\n",
      "      10004 |   0.176030  |    0.148270     |   1\n",
      "      10005 |   0.046810  |    0.025889     |   2\n",
      "      10006 |   0.178169  |    0.190523     |   1\n",
      "      10007 |   0.255928  |    0.151506     |   1\n",
      "      10008 |   0.050092  |    0.045161     |   2\n",
      "      10009 |   0.063128  |    0.071733     |   2\n",
      "      10010 |   0.031955  |    0.031533     |   2\n",
      "      10011 |   0.174873  |    0.047801     |   0\n",
      "      10012 |   0.247216  |    0.137809     |   1\n",
      "      10013 |   0.178365  |    0.026206     |   0\n",
      "      10014 |   0.201588  |    0.071974     |   0\n",
      "      10015 |   0.050753  |    0.040008     |   2\n",
      "      10016 |   0.067494  |    0.069074     |   2\n",
      "      10017 |   0.187020  |    0.149251     |   1\n",
      "      10018 |   0.064484  |    0.043036     |   2\n",
      "      10019 |   0.205432  |    0.057794     |   0\n",
      "      10020 |   0.062576  |    0.019952     |   2\n",
      "      10021 |   0.201808  |    0.207155     |   1\n",
      "      10022 |   0.029178  |    0.017868     |   2\n",
      "      10023 |   0.212167  |    0.218114     |   1\n",
      "      10024 |   0.000092  |    0.008845     |   2\n",
      "      10025 |   0.203321  |    0.164893     |   1\n",
      "      10026 |   0.247415  |    0.132172     |   1\n",
      "      10027 |   0.007121  |    0.048280     |   2\n",
      "      10028 |   0.090036  |    0.053258     |   2\n",
      "      10029 |   0.230469  |    0.158799     |   1\n",
      "      10030 |   0.221329  |    0.030918     |   0\n",
      "      10031 |   0.178836  |    0.042690     |   0\n",
      "      10032 |   0.235992  |    0.038391     |   0\n",
      "      10033 |   0.041925  |    0.047095     |   2\n",
      "      10034 |   0.228212  |    0.194718     |   1\n",
      "      10035 |   0.207228  |    0.140777     |   1\n",
      "      10036 |   0.259513  |    0.208045     |   1\n",
      "      10037 |   0.214044  |    0.135345     |   1\n",
      "      10038 |   0.069272  |    0.043147     |   2\n",
      "      10039 |   0.182110  |    0.064820     |   0\n",
      "      10040 |   0.211613  |    0.172838     |   1\n",
      "      10041 |   0.184448  |    0.146094     |   1\n",
      "      10042 |   0.236113  |    0.075852     |   0\n",
      "      10043 |   0.217754  |    0.012255     |   0\n",
      "      10044 |   0.170905  |    0.083464     |   0\n",
      "      10045 |   0.265706  |    0.138860     |   1\n",
      "      10046 |   0.053003  |    0.043077     |   2\n",
      "      10047 |   0.279382  |    0.166112     |   1\n",
      "      10048 |   0.197974  |    0.047133     |   0\n",
      "      10049 |   0.227778  |    0.075880     |   0\n",
      "      10050 |   0.194200  |    0.162032     |   1\n",
      "      10051 |   0.021963  |    0.024337     |   2\n",
      "      10052 |   0.047739  |    0.061403     |   2\n",
      "      10053 |   0.146031  |    0.083300     |   0\n",
      "      10054 |   0.037591  |    0.037445     |   2\n",
      "      10055 |   0.112969  |    0.150580     |   1\n",
      "      10056 |   0.222138  |    0.044362     |   0\n",
      "      10057 |   0.249553  |    0.079706     |   0\n",
      "      10058 |   0.000091  |    0.004819     |   2\n",
      "      10059 |   0.181955  |    0.075707     |   0\n",
      "      10060 |   0.239663  |    0.008173     |   0\n",
      "      10061 |   0.210476  |    0.081507     |   0\n",
      "      10062 |   0.162745  |    0.142876     |   1\n",
      "      10063 |   0.000090  |    0.043436     |   2\n",
      "      10064 |   0.226147  |    0.194873     |   1\n",
      "      10065 |   0.000091  |    0.038982     |   2\n",
      "      10066 |   0.158285  |    0.046615     |   0\n",
      "      10067 |   0.000090  |    0.044990     |   2\n",
      "      10068 |   0.000090  |    0.048534     |   2\n",
      "      10069 |   0.221808  |    0.072604     |   0\n",
      "      10070 |   0.000090  |    0.033469     |   2\n",
      "      10071 |   0.215043  |    0.138959     |   1\n",
      "      10072 |   0.067306  |    0.018708     |   2\n",
      "      10073 |   0.246250  |    0.071862     |   0\n",
      "      10074 |   0.067310  |    0.042686     |   2\n",
      "      10075 |   0.224543  |    0.207236     |   1\n",
      "      10076 |   0.254885  |    0.131702     |   1\n",
      "      10077 |   0.237392  |    0.050460     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 10078: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      10078 |   0.203804  |    0.145763     |   1\n",
      "      10079 |   0.067848  |    0.051855     |   2\n",
      "      10080 |   0.225759  |    0.160677     |   1\n",
      "      10081 |   0.170827  |    0.027652     |   0\n",
      "      10082 |   0.197132  |    0.078606     |   0\n",
      "      10083 |   0.214739  |    0.155415     |   1\n",
      "      10084 |   0.164714  |    0.014655     |   0\n",
      "      10085 |   0.140909  |    0.076178     |   0\n",
      "      10086 |   0.145418  |    0.150697     |   1\n",
      "      10087 |   0.211654  |    0.192990     |   1\n",
      "      10088 |   0.185195  |    0.145443     |   1\n",
      "      10089 |   0.221015  |    0.197045     |   1\n",
      "      10090 |   0.197066  |    0.017553     |   0\n",
      "      10091 |   0.216094  |    0.050891     |   0\n",
      "      10092 |   0.047084  |    0.056661     |   2\n",
      "      10093 |   0.154917  |    0.191537     |   1\n",
      "      10094 |   0.203427  |    0.156796     |   1\n",
      "      10095 |   0.051113  |    0.022905     |   2\n",
      "      10096 |   0.058014  |    0.084072     |   2\n",
      "      10097 |   0.186406  |    0.019252     |   0\n",
      "      10098 |   0.031836  |    0.041302     |   2\n",
      "      10099 |   0.198665  |    0.053702     |   0\n",
      "      10100 |   0.134565  |    0.044308     |   0\n",
      "      10101 |   0.196203  |    0.056688     |   0\n",
      "      10102 |   0.053196  |    0.025129     |   2\n",
      "      10103 |   0.207474  |    0.080654     |   0\n",
      "      10104 |   0.158973  |    0.021405     |   0\n",
      "      10105 |   0.193091  |    0.188298     |   1\n",
      "      10106 |   0.217245  |    0.151141     |   1\n",
      "      10107 |   0.059983  |    0.038671     |   2\n",
      "      10108 |   0.069445  |    0.047723     |   2\n",
      "      10109 |   0.185018  |    0.076152     |   0\n",
      "      10110 |   0.060698  |    0.013025     |   2\n",
      "      10111 |   0.028615  |    0.076548     |   2\n",
      "      10112 |   0.000090  |    0.023780     |   2\n",
      "      10113 |   0.007246  |    0.078288     |   2\n",
      "      10114 |   0.090686  |    0.039840     |   2\n",
      "      10115 |   0.044278  |    0.052861     |   2\n",
      "      10116 |   0.222911  |    0.156180     |   1\n",
      "      10117 |   0.251852  |    0.134697     |   1\n",
      "      10118 |   0.213105  |    0.032707     |   0\n",
      "      10119 |   0.181815  |    0.184667     |   1\n",
      "      10120 |   0.203330  |    0.023398     |   0\n",
      "      10121 |   0.068744  |    0.083509     |   2\n",
      "      10122 |   0.270744  |    0.146990     |   1\n",
      "      10123 |   0.174980  |    0.201548     |   1\n",
      "      10124 |   0.055002  |    0.003099     |   2\n",
      "      10125 |   0.173177  |    0.209752     |   1\n",
      "      10126 |   0.231674  |    0.134792     |   1\n",
      "      10127 |   0.266087  |    0.190742     |   1\n",
      "      10128 |   0.022590  |    0.006066     |   2\n",
      "      10129 |   0.173687  |    0.078233     |   0\n",
      "      10130 |   0.210423  |    0.024751     |   0\n",
      "      10131 |   0.049058  |    0.047224     |   2\n",
      "      10132 |   0.173529  |    0.049002     |   0\n",
      "      10133 |   0.234030  |    0.146128     |   1\n",
      "      10134 |   0.227539  |    0.049959     |   0\n",
      "      10135 |   0.036154  |    0.047904     |   2\n",
      "      10136 |   0.000090  |    0.047190     |   2\n",
      "      10137 |   0.186578  |    0.182266     |   1\n",
      "      10138 |   0.172747  |    0.011906     |   0\n",
      "      10139 |   0.000090  |    0.073334     |   2\n",
      "      10140 |   0.238745  |    0.045362     |   0\n",
      "      10141 |   0.233229  |    0.158024     |   1\n",
      "      10142 |   0.000091  |    0.026020     |   2\n",
      "      10143 |   0.000090  |    0.079316     |   2\n",
      "      10144 |   0.215244  |    0.019094     |   0\n",
      "      10145 |   0.000090  |    0.080248     |   2\n",
      "      10146 |   0.181513  |    0.015896     |   0\n",
      "      10147 |   0.000090  |    0.088393     |   2\n",
      "      10148 |   0.063555  |    0.015995     |   2\n",
      "      10149 |   0.067103  |    0.055584     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 10150: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      10150 |   0.159165  |    0.204365     |   1\n",
      "      10151 |   0.065660  |    0.005367     |   2\n",
      "      10152 |   0.045091  |    0.085029     |   2\n",
      "      10153 |   0.260490  |    0.027307     |   0\n",
      "      10154 |   0.240188  |    0.146623     |   1\n",
      "      10155 |   0.261083  |    0.049061     |   0\n",
      "      10156 |   0.191975  |    0.189881     |   1\n",
      "      10157 |   0.261969  |    0.149731     |   1\n",
      "      10158 |   0.050263  |    0.050299     |   2\n",
      "      10159 |   0.174094  |    0.151907     |   1\n",
      "      10160 |   0.207325  |    0.169072     |   1\n",
      "      10161 |   0.243666  |    0.009177     |   0\n",
      "      10162 |   0.058282  |    0.083098     |   2\n",
      "      10163 |   0.196402  |    0.157318     |   1\n",
      "      10164 |   0.265494  |    0.149002     |   1\n",
      "      10165 |   0.030725  |    0.021111     |   2\n",
      "      10166 |   0.254469  |    0.167661     |   1\n",
      "      10167 |   0.162736  |    0.019645     |   0\n",
      "      10168 |   0.225067  |    0.072950     |   0\n",
      "      10169 |   0.224853  |    0.049197     |   0\n",
      "      10170 |   0.213837  |    0.201582     |   1\n",
      "      10171 |   0.187302  |    0.101931     |   1\n",
      "      10172 |   0.184483  |    0.076804     |   0\n",
      "      10173 |   0.182759  |    0.018352     |   0\n",
      "      10174 |   0.050463  |    0.041832     |   2\n",
      "      10175 |   0.216024  |    0.072749     |   0\n",
      "      10176 |   0.258699  |    0.165073     |   1\n",
      "      10177 |   0.251180  |    0.006176     |   0\n",
      "      10178 |   0.200253  |    0.137289     |   1\n",
      "      10179 |   0.198602  |    0.037725     |   0\n",
      "      10180 |   0.061868  |    0.078636     |   2\n",
      "      10181 |   0.139250  |    0.168644     |   1\n",
      "      10182 |   0.067887  |    0.019590     |   2\n",
      "      10183 |   0.174144  |    0.162670     |   1\n",
      "      10184 |   0.180534  |    0.186814     |   1\n",
      "      10185 |   0.218668  |    0.020803     |   0\n",
      "      10186 |   0.159967  |    0.048476     |   0\n",
      "      10187 |   0.197810  |    0.195791     |   1\n",
      "      10188 |   0.167755  |    0.019771     |   0\n",
      "      10189 |   0.239388  |    0.203886     |   1\n",
      "      10190 |   0.184023  |    0.150451     |   1\n",
      "      10191 |   0.059683  |    0.009780     |   2\n",
      "      10192 |   0.028395  |    0.075445     |   2\n",
      "      10193 |   0.274668  |    0.028321     |   0\n",
      "      10194 |   0.137188  |    0.206465     |   1\n",
      "      10195 |   0.000089  |    0.038768     |   2\n",
      "      10196 |   0.182899  |    0.058514     |   0\n",
      "      10197 |   0.207355  |    0.150301     |   1\n",
      "      10198 |   0.297251  |    0.146917     |   1\n",
      "      10199 |   0.006898  |    0.070561     |   2\n",
      "      10200 |   0.226178  |    0.153444     |   1\n",
      "      10201 |   0.282405  |    0.202495     |   1\n",
      "      10202 |   0.219284  |    0.021312     |   0\n",
      "      10203 |   0.201249  |    0.094151     |   0\n",
      "      10204 |   0.215318  |    0.133412     |   1\n",
      "      10205 |   0.089544  |    0.032637     |   2\n",
      "      10206 |   0.136395  |    0.191241     |   1\n",
      "      10207 |   0.039975  |    0.037845     |   2\n",
      "      10208 |   0.205258  |    0.075123     |   0\n",
      "      10209 |   0.218720  |    0.009602     |   0\n",
      "      10210 |   0.200479  |    0.220973     |   1\n",
      "      10211 |   0.225443  |    0.159363     |   1\n",
      "      10212 |   0.193805  |    0.157929     |   1\n",
      "      10213 |   0.200346  |    0.201363     |   1\n",
      "      10214 |   0.265890  |    0.028301     |   0\n",
      "      10215 |   0.226438  |    0.218388     |   1\n",
      "      10216 |   0.189633  |    0.148295     |   1\n",
      "      10217 |   0.067758  |    0.044634     |   2\n",
      "      10218 |   0.212664  |    0.042539     |   0\n",
      "      10219 |   0.189292  |    0.045606     |   0\n",
      "      10220 |   0.052782  |    0.074552     |   2\n",
      "      10221 |   0.021238  |    0.029502     |   2\n",
      "      10222 |   0.185024  |    0.192714     |   1\n",
      "      10223 |   0.257659  |    0.138918     |   1\n",
      "      10224 |   0.183245  |    0.025647     |   0\n",
      "      10225 |   0.182765  |    0.158792     |   1\n",
      "      10226 |   0.047243  |    0.050823     |   2\n",
      "      10227 |   0.289588  |    0.197783     |   1\n",
      "      10228 |   0.185416  |    0.011901     |   0\n",
      "      10229 |   0.254563  |    0.160211     |   1\n",
      "      10230 |   0.218942  |    0.147578     |   1\n",
      "      10231 |   0.212123  |    0.007331     |   0\n",
      "      10232 |   0.160387  |    0.043357     |   0\n",
      "      10233 |   0.036364  |    0.081019     |   2\n",
      "      10234 |   0.000089  |    0.022081     |   2\n",
      "      10235 |   0.198022  |    0.186259     |   1\n",
      "      10236 |   0.253218  |    0.011028     |   0\n",
      "      10237 |   0.170686  |    0.071690     |   0\n",
      "      10238 |   0.000089  |    0.043044     |   2\n",
      "      10239 |   0.209225  |    0.151106     |   1\n",
      "      10240 |   0.238011  |    0.144860     |   1\n",
      "      10241 |   0.183908  |    0.046005     |   0\n",
      "      10242 |   0.200355  |    0.060545     |   0\n",
      "      10243 |   0.164874  |    0.139278     |   1\n",
      "      10244 |   0.000089  |    0.077909     |   2\n",
      "      10245 |   0.170834  |    0.169411     |   1\n",
      "      10246 |   0.255221  |    0.141500     |   1\n",
      "      10247 |   0.000089  |    0.051163     |   2\n",
      "      10248 |   0.000089  |    0.052413     |   2\n",
      "      10249 |   0.163468  |    0.204361     |   1\n",
      "      10250 |   0.202991  |    0.005264     |   0\n",
      "      10251 |   0.256110  |    0.039403     |   0\n",
      "      10252 |   0.209608  |    0.201694     |   1\n",
      "      10253 |   0.155465  |    0.007693     |   0\n",
      "      10254 |   0.277302  |    0.141431     |   1\n",
      "      10255 |   0.000089  |    0.006899     |   2\n",
      "      10256 |   0.257044  |    0.074493     |   0\n",
      "      10257 |   0.266188  |    0.025424     |   0\n",
      "      10258 |   0.189470  |    0.087011     |   0\n",
      "      10259 |   0.057511  |    0.015532     |   2\n",
      "      10260 |   0.289380  |    0.159610     |   1\n",
      "      10261 |   0.162071  |    0.188954     |   1\n",
      "      10262 |   0.066165  |    0.003290     |   2\n",
      "      10263 |   0.293126  |    0.141194     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 10264: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      10264 |   0.240700  |    0.022222     |   0\n",
      "      10265 |   0.229511  |    0.074578     |   0\n",
      "      10266 |   0.197775  |    0.145491     |   1\n",
      "      10267 |   0.062890  |    0.025938     |   2\n",
      "      10268 |   0.145650  |    0.201292     |   1\n",
      "      10269 |   0.204829  |    0.038972     |   0\n",
      "      10270 |   0.046227  |    0.041287     |   2\n",
      "      10271 |   0.162094  |    0.094850     |   0\n",
      "      10272 |   0.163744  |    0.160710     |   1\n",
      "      10273 |   0.140398  |    0.209953     |   1\n",
      "      10274 |   0.047879  |    0.003387     |   2\n",
      "      10275 |   0.178870  |    0.145175     |   1\n",
      "      10276 |   0.225454  |    0.045885     |   0\n",
      "      10277 |   0.060330  |    0.048227     |   2\n",
      "      10278 |   0.227670  |    0.076833     |   0\n",
      "      10279 |   0.171801  |    0.023199     |   0\n",
      "      10280 |   0.032446  |    0.076412     |   2\n",
      "      10281 |   0.051995  |    0.042481     |   2\n",
      "      10282 |   0.058797  |    0.043851     |   2\n",
      "      10283 |   0.135559  |    0.219438     |   1\n",
      "      10284 |   0.161785  |    0.021750     |   0\n",
      "      10285 |   0.186425  |    0.200113     |   1\n",
      "      10286 |   0.067261  |    0.006325     |   2\n",
      "      10287 |   0.062912  |    0.046058     |   2\n",
      "      10288 |   0.188225  |    0.200039     |   1\n",
      "      10289 |   0.162608  |    0.013743     |   0\n",
      "      10290 |   0.180194  |    0.201578     |   1\n",
      "      10291 |   0.226591  |    0.211038     |   1\n",
      "      10292 |   0.211103  |    0.015345     |   0\n",
      "      10293 |   0.029067  |    0.097143     |   2\n",
      "      10294 |   0.219884  |    0.138919     |   1\n",
      "      10295 |   0.196886  |    0.055639     |   0\n",
      "      10296 |   0.178429  |    0.167809     |   1\n",
      "      10297 |   0.238372  |    0.165492     |   1\n",
      "      10298 |   0.000087  |    0.015540     |   2\n",
      "      10299 |   0.215803  |    0.158905     |   1\n",
      "      10300 |   0.197023  |    0.044825     |   0\n",
      "      10301 |   0.215317  |    0.137462     |   1\n",
      "      10302 |   0.255661  |    0.042174     |   0\n",
      "      10303 |   0.007179  |    0.077788     |   2\n",
      "      10304 |   0.092581  |    0.029399     |   2\n",
      "      10305 |   0.193798  |    0.073949     |   0\n",
      "      10306 |   0.192127  |    0.013421     |   0\n",
      "      10307 |   0.044313  |    0.084200     |   2\n",
      "      10308 |   0.268514  |    0.141387     |   1\n",
      "      10309 |   0.203949  |    0.005013     |   0\n",
      "      10310 |   0.194277  |    0.048702     |   0\n",
      "      10311 |   0.068022  |    0.046103     |   2\n",
      "      10312 |   0.184512  |    0.203243     |   1\n",
      "      10313 |   0.158008  |    0.133549     |   1\n",
      "      10314 |   0.053565  |    0.027640     |   2\n",
      "      10315 |   0.249011  |    0.087844     |   0\n",
      "      10316 |   0.225155  |    0.140836     |   1\n",
      "      10317 |   0.220212  |    0.143259     |   1\n",
      "      10318 |   0.212134  |    0.047582     |   0\n",
      "      10319 |   0.022128  |    0.071051     |   2\n",
      "      10320 |   0.174709  |    0.020536     |   0\n",
      "      10321 |   0.209080  |    0.189704     |   1\n",
      "      10322 |   0.048650  |    0.042114     |   2\n",
      "      10323 |   0.212751  |    0.056620     |   0\n",
      "      10324 |   0.214775  |    0.051808     |   0\n",
      "      10325 |   0.035492  |    0.073395     |   2\n",
      "      10326 |   0.000087  |    0.043098     |   2\n",
      "      10327 |   0.208103  |    0.048754     |   0\n",
      "      10328 |   0.210879  |    0.041131     |   0\n",
      "      10329 |   0.000087  |    0.050017     |   2\n",
      "      10330 |   0.000088  |    0.053520     |   2\n",
      "      10331 |   0.221608  |    0.203433     |   1\n",
      "      10332 |   0.000087  |    0.006636     |   2\n",
      "      10333 |   0.000087  |    0.055165     |   2\n",
      "      10334 |   0.000087  |    0.042992     |   2\n",
      "      10335 |   0.067387  |    0.072797     |   2\n",
      "      10336 |   0.188697  |    0.029861     |   0\n",
      "      10337 |   0.066727  |    0.042707     |   2\n",
      "      10338 |   0.145173  |    0.216948     |   1\n",
      "      10339 |   0.193211  |    0.148078     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 10340: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      10340 |   0.206422  |    0.019145     |   0\n",
      "      10341 |   0.068812  |    0.051603     |   2\n",
      "      10342 |   0.047660  |    0.044775     |   2\n",
      "      10343 |   0.255922  |    0.078552     |   0\n",
      "      10344 |   0.207944  |    0.088024     |   1\n",
      "      10345 |   0.049598  |    0.040773     |   2\n",
      "      10346 |   0.059581  |    0.042935     |   2\n",
      "      10347 |   0.031922  |    0.079572     |   2\n",
      "      10348 |   0.051233  |    0.022727     |   2\n",
      "      10349 |   0.209250  |    0.084394     |   0\n",
      "      10350 |   0.060421  |    0.006590     |   2\n",
      "      10351 |   0.199235  |    0.049184     |   0\n",
      "      10352 |   0.230034  |    0.188229     |   1\n",
      "      10353 |   0.065996  |    0.042028     |   2\n",
      "      10354 |   0.057502  |    0.021710     |   2\n",
      "      10355 |   0.253706  |    0.045584     |   0\n",
      "      10356 |   0.190264  |    0.183194     |   1\n",
      "      10357 |   0.288781  |    0.136998     |   1\n",
      "      10358 |   0.207011  |    0.157882     |   1\n",
      "      10359 |   0.028263  |    0.005898     |   2\n",
      "      10360 |   0.000087  |    0.080446     |   2\n",
      "      10361 |   0.155767  |    0.143191     |   1\n",
      "      10362 |   0.007506  |    0.072155     |   2\n",
      "      10363 |   0.176284  |    0.134177     |   1\n",
      "      10364 |   0.090132  |    0.012029     |   2\n",
      "      10365 |   0.224531  |    0.176721     |   1\n",
      "      10366 |   0.232810  |    0.190114     |   1\n",
      "      10367 |   0.258211  |    0.096804     |   1\n",
      "      10368 |   0.133893  |    0.215145     |   1\n",
      "      10369 |   0.042451  |    0.011533     |   2\n",
      "      10370 |   0.166251  |    0.220708     |   1\n",
      "      10371 |   0.209822  |    0.014349     |   0\n",
      "      10372 |   0.156978  |    0.186513     |   1\n",
      "      10373 |   0.161881  |    0.146249     |   1\n",
      "      10374 |   0.067837  |    0.043021     |   2\n",
      "      10375 |   0.053000  |    0.030343     |   2\n",
      "      10376 |   0.224123  |    0.217806     |   1\n",
      "      10377 |   0.210874  |    0.093606     |   1\n",
      "      10378 |   0.223349  |    0.192179     |   1\n",
      "      10379 |   0.180527  |    0.046407     |   0\n",
      "      10380 |   0.247714  |    0.039386     |   0\n",
      "      10381 |   0.164385  |    0.100403     |   0\n",
      "      10382 |   0.226685  |    0.159024     |   1\n",
      "      10383 |   0.257245  |    0.149190     |   1\n",
      "      10384 |   0.022335  |    0.005958     |   2\n",
      "      10385 |   0.049186  |    0.077913     |   2\n",
      "      10386 |   0.194572  |    0.030030     |   0\n",
      "      10387 |   0.187955  |    0.078017     |   0\n",
      "      10388 |   0.036119  |    0.019233     |   2\n",
      "      10389 |   0.247407  |    0.213574     |   1\n",
      "      10390 |   0.164605  |    0.011441     |   0\n",
      "      10391 |   0.203683  |    0.138338     |   1\n",
      "      10392 |   0.191574  |    0.029291     |   0\n",
      "      10393 |   0.000086  |    0.085674     |   2\n",
      "      10394 |   0.201829  |    0.158392     |   1\n",
      "      10395 |   0.000086  |    0.020906     |   2\n",
      "      10396 |   0.000087  |    0.079025     |   2\n",
      "      10397 |   0.000086  |    0.024582     |   2\n",
      "      10398 |   0.175574  |    0.051328     |   0\n",
      "      10399 |   0.155833  |    0.049409     |   0\n",
      "      10400 |   0.209674  |    0.149643     |   1\n",
      "      10401 |   0.275729  |    0.165248     |   1\n",
      "      10402 |   0.000086  |    0.055853     |   2\n",
      "      10403 |   0.209105  |    0.175683     |   1\n",
      "      10404 |   0.194941  |    0.005228     |   0\n",
      "      10405 |   0.000086  |    0.083446     |   2\n",
      "      10406 |   0.182762  |    0.019735     |   0\n",
      "      10407 |   0.064306  |    0.085953     |   2\n",
      "      10408 |   0.065639  |    0.008826     |   2\n",
      "      10409 |   0.225807  |    0.072106     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 10410: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      10410 |   0.063026  |    0.019357     |   2\n",
      "      10411 |   0.173312  |    0.044396     |   0\n",
      "      10412 |   0.046675  |    0.049425     |   2\n",
      "      10413 |   0.212931  |    0.174100     |   1\n",
      "      10414 |   0.047897  |    0.048337     |   2\n",
      "      10415 |   0.150731  |    0.048088     |   0\n",
      "      10416 |   0.059121  |    0.045008     |   2\n",
      "      10417 |   0.032301  |    0.050084     |   2\n",
      "      10418 |   0.048830  |    0.039115     |   2\n",
      "      10419 |   0.057534  |    0.059254     |   2\n",
      "      10420 |   0.162794  |    0.147119     |   1\n",
      "      10421 |   0.064902  |    0.065534     |   2\n",
      "      10422 |   0.212769  |    0.153278     |   1\n",
      "      10423 |   0.058613  |    0.019863     |   2\n",
      "      10424 |   0.027759  |    0.054296     |   2\n",
      "      10425 |   0.187742  |    0.069551     |   0\n",
      "      10426 |   0.000086  |    0.024729     |   2\n",
      "      10427 |   0.268519  |    0.071073     |   0\n",
      "      10428 |   0.255535  |    0.043630     |   0\n",
      "      10429 |   0.007066  |    0.078738     |   2\n",
      "      10430 |   0.199967  |    0.020661     |   0\n",
      "      10431 |   0.087432  |    0.071611     |   2\n",
      "      10432 |   0.228008  |    0.025907     |   0\n",
      "      10433 |   0.205774  |    0.076791     |   0\n",
      "      10434 |   0.202227  |    0.027247     |   0\n",
      "      10435 |   0.156472  |    0.050345     |   0\n",
      "      10436 |   0.041387  |    0.038933     |   2\n",
      "      10437 |   0.069295  |    0.049964     |   2\n",
      "      10438 |   0.230877  |    0.051679     |   0\n",
      "      10439 |   0.208403  |    0.040199     |   0\n",
      "      10440 |   0.203888  |    0.076267     |   0\n",
      "      10441 |   0.229717  |    0.047076     |   0\n",
      "      10442 |   0.216292  |    0.199804     |   1\n",
      "      10443 |   0.235606  |    0.009105     |   0\n",
      "      10444 |   0.054996  |    0.044482     |   2\n",
      "      10445 |   0.187549  |    0.072386     |   0\n",
      "      10446 |   0.164047  |    0.026182     |   0\n",
      "      10447 |   0.288724  |    0.168183     |   1\n",
      "      10448 |   0.186276  |    0.201931     |   1\n",
      "      10449 |   0.213130  |    0.006436     |   0\n",
      "      10450 |   0.167567  |    0.053708     |   0\n",
      "      10451 |   0.246896  |    0.157904     |   1\n",
      "      10452 |   0.229118  |    0.147327     |   1\n",
      "      10453 |   0.189674  |    0.188850     |   1\n",
      "      10454 |   0.225471  |    0.018873     |   0\n",
      "      10455 |   0.023710  |    0.083961     |   2\n",
      "      10456 |   0.224175  |    0.162352     |   1\n",
      "      10457 |   0.229077  |    0.144117     |   1\n",
      "      10458 |   0.053227  |    0.026476     |   2\n",
      "      10459 |   0.220167  |    0.082463     |   0\n",
      "      10460 |   0.037067  |    0.007675     |   2\n",
      "      10461 |   0.000086  |    0.048430     |   2\n",
      "      10462 |   0.158244  |    0.050694     |   0\n",
      "      10463 |   0.203177  |    0.054923     |   0\n",
      "      10464 |   0.000086  |    0.046696     |   2\n",
      "      10465 |   0.000086  |    0.039152     |   2\n",
      "      10466 |   0.000086  |    0.075183     |   2\n",
      "      10467 |   0.000086  |    0.028630     |   2\n",
      "      10468 |   0.350077  |    0.194142     |   1\n",
      "      10469 |   0.200209  |    0.010208     |   0\n",
      "      10470 |   0.000086  |    0.081749     |   2\n",
      "      10471 |   0.264683  |    0.128879     |   1\n",
      "      10472 |   0.175658  |    0.049183     |   0\n",
      "      10473 |   0.066915  |    0.040947     |   2\n",
      "      10474 |   0.180265  |    0.043906     |   0\n",
      "      10475 |   0.218875  |    0.078875     |   0\n",
      "      10476 |   0.065612  |    0.016900     |   2\n",
      "      10477 |   0.244432  |    0.194676     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 10478: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      10478 |   0.063554  |    0.005543     |   2\n",
      "      10479 |   0.045790  |    0.056035     |   2\n",
      "      10480 |   0.048717  |    0.041033     |   2\n",
      "      10481 |   0.240442  |    0.043331     |   0\n",
      "      10482 |   0.164252  |    0.060577     |   0\n",
      "      10483 |   0.267639  |    0.171665     |   1\n",
      "      10484 |   0.232013  |    0.143082     |   1\n",
      "      10485 |   0.054770  |    0.043827     |   2\n",
      "      10486 |   0.162234  |    0.054558     |   0\n",
      "      10487 |   0.211566  |    0.148752     |   1\n",
      "      10488 |   0.030714  |    0.009536     |   2\n",
      "      10489 |   0.277150  |    0.171374     |   1\n",
      "      10490 |   0.051469  |    0.047082     |   2\n",
      "      10491 |   0.135975  |    0.040811     |   0\n",
      "      10492 |   0.159038  |    0.078407     |   0\n",
      "      10493 |   0.198885  |    0.150382     |   1\n",
      "      10494 |   0.057994  |    0.078131     |   2\n",
      "      10495 |   0.176967  |    0.018692     |   0\n",
      "      10496 |   0.064798  |    0.083626     |   2\n",
      "      10497 |   0.148584  |    0.017801     |   0\n",
      "      10498 |   0.201431  |    0.077851     |   0\n",
      "      10499 |   0.207266  |    0.175802     |   1\n",
      "      10500 |   0.168107  |    0.025487     |   0\n",
      "      10501 |   0.058137  |    0.081988     |   2\n",
      "      10502 |   0.240979  |    0.163118     |   1\n",
      "      10503 |   0.221955  |    0.112963     |   1\n",
      "      10504 |   0.265032  |    0.142906     |   1\n",
      "      10505 |   0.240472  |    0.209185     |   1\n",
      "      10506 |   0.198610  |    0.007700     |   0\n",
      "      10507 |   0.188322  |    0.072243     |   0\n",
      "      10508 |   0.213871  |    0.038741     |   0\n",
      "      10509 |   0.199017  |    0.207866     |   1\n",
      "      10510 |   0.157959  |    0.017379     |   0\n",
      "      10511 |   0.201890  |    0.046336     |   0\n",
      "      10512 |   0.160937  |    0.171680     |   1\n",
      "      10513 |   0.042746  |    0.053547     |   2\n",
      "      10514 |   0.155571  |    0.157737     |   1\n",
      "      10515 |   0.178160  |    0.079141     |   0\n",
      "      10516 |   0.214542  |    0.036497     |   0\n",
      "      10517 |   0.199902  |    0.190525     |   1\n",
      "      10518 |   0.048461  |    0.005313     |   2\n",
      "      10519 |   0.173275  |    0.055059     |   0\n",
      "      10520 |   0.194784  |    0.192480     |   1\n",
      "      10521 |   0.232492  |    0.007888     |   0\n",
      "      10522 |   0.055795  |    0.042357     |   2\n",
      "      10523 |   0.196646  |    0.047804     |   0\n",
      "      10524 |   0.204799  |    0.146649     |   1\n",
      "      10525 |   0.161367  |    0.088297     |   0\n",
      "      10526 |   0.248045  |    0.134219     |   1\n",
      "      10527 |   0.207193  |    0.040276     |   0\n",
      "      10528 |   0.165176  |    0.074985     |   0\n",
      "      10529 |   0.030773  |    0.038310     |   2\n",
      "      10530 |   0.279742  |    0.136634     |   1\n",
      "      10531 |   0.049914  |    0.080219     |   2\n",
      "      10532 |   0.062266  |    0.004883     |   2\n",
      "      10533 |   0.064803  |    0.077808     |   2\n",
      "      10534 |   0.198960  |    0.039173     |   0\n",
      "      10535 |   0.165046  |    0.042715     |   0\n",
      "      10536 |   0.231708  |    0.050256     |   0\n",
      "      10537 |   0.285766  |    0.133945     |   1\n",
      "      10538 |   0.214619  |    0.049207     |   0\n",
      "      10539 |   0.059274  |    0.041612     |   2\n",
      "      10540 |   0.173174  |    0.055966     |   0\n",
      "      10541 |   0.028020  |    0.048156     |   2\n",
      "      10542 |   0.000085  |    0.051147     |   2\n",
      "      10543 |   0.237848  |    0.154781     |   1\n",
      "      10544 |   0.171204  |    0.023133     |   0\n",
      "      10545 |   0.195798  |    0.077712     |   0\n",
      "      10546 |   0.007058  |    0.025215     |   2\n",
      "      10547 |   0.092027  |    0.045362     |   2\n",
      "      10548 |   0.250874  |    0.080404     |   0\n",
      "      10549 |   0.043410  |    0.006839     |   2\n",
      "      10550 |   0.172924  |    0.046983     |   0\n",
      "      10551 |   0.245655  |    0.200772     |   1\n",
      "      10552 |   0.177213  |    0.033826     |   0\n",
      "      10553 |   0.200338  |    0.050294     |   0\n",
      "      10554 |   0.171054  |    0.080870     |   0\n",
      "      10555 |   0.281051  |    0.163526     |   1\n",
      "      10556 |   0.260010  |    0.005415     |   0\n",
      "      10557 |   0.070936  |    0.078446     |   2\n",
      "      10558 |   0.170968  |    0.149699     |   1\n",
      "      10559 |   0.054860  |    0.015423     |   2\n",
      "      10560 |   0.024369  |    0.091354     |   2\n",
      "      10561 |   0.205490  |    0.196478     |   1\n",
      "      10562 |   0.225013  |    0.004394     |   0\n",
      "      10563 |   0.166484  |    0.025365     |   0\n",
      "      10564 |   0.216630  |    0.050027     |   0\n",
      "      10565 |   0.179200  |    0.053676     |   0\n",
      "      10566 |   0.213848  |    0.155492     |   1\n",
      "      10567 |   0.162100  |    0.072016     |   0\n",
      "      10568 |   0.174629  |    0.027082     |   0\n",
      "      10569 |   0.190228  |    0.050949     |   0\n",
      "      10570 |   0.194488  |    0.144465     |   1\n",
      "      10571 |   0.186689  |    0.038259     |   0\n",
      "      10572 |   0.184630  |    0.072693     |   0\n",
      "      10573 |   0.187364  |    0.052024     |   0\n",
      "      10574 |   0.253166  |    0.149420     |   1\n",
      "      10575 |   0.053366  |    0.039756     |   2\n",
      "      10576 |   0.179073  |    0.081026     |   0\n",
      "      10577 |   0.208821  |    0.019933     |   0\n",
      "      10578 |   0.157797  |    0.202659     |   1\n",
      "      10579 |   0.038744  |    0.020972     |   2\n",
      "      10580 |   0.117344  |    0.052821     |   0\n",
      "      10581 |   0.165694  |    0.150356     |   1\n",
      "      10582 |   0.145558  |    0.072430     |   0\n",
      "      10583 |   0.225032  |    0.024142     |   0\n",
      "      10584 |   0.000085  |    0.082606     |   2\n",
      "      10585 |   0.000086  |    0.011241     |   2\n",
      "      10586 |   0.175066  |    0.075981     |   0\n",
      "      10587 |   0.197581  |    0.022079     |   0\n",
      "      10588 |   0.196685  |    0.072765     |   0\n",
      "      10589 |   0.000086  |    0.051109     |   2\n",
      "      10590 |   0.216334  |    0.152733     |   1\n",
      "      10591 |   0.000086  |    0.030939     |   2\n",
      "      10592 |   0.000086  |    0.049881     |   2\n",
      "      10593 |   0.264224  |    0.141482     |   1\n",
      "      10594 |   0.183145  |    0.076876     |   0\n",
      "      10595 |   0.246718  |    0.149233     |   1\n",
      "      10596 |   0.220341  |    0.029656     |   0\n",
      "      10597 |   0.223114  |    0.080903     |   0\n",
      "      10598 |   0.000086  |    0.025367     |   2\n",
      "      10599 |   0.248187  |    0.192634     |   1\n",
      "      10600 |   0.066119  |    0.020816     |   2\n",
      "      10601 |   0.124856  |    0.060639     |   0\n",
      "      10602 |   0.267358  |    0.184139     |   1\n",
      "      10603 |   0.068053  |    0.011420     |   2\n",
      "      10604 |   0.281205  |    0.195232     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 10605: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      10605 |   0.175996  |    0.005799     |   0\n",
      "      10606 |   0.063161  |    0.043849     |   2\n",
      "      10607 |   0.200789  |    0.076380     |   0\n",
      "      10608 |   0.226562  |    0.019315     |   0\n",
      "      10609 |   0.221768  |    0.194925     |   1\n",
      "      10610 |   0.044176  |    0.060015     |   2\n",
      "      10611 |   0.048392  |    0.027198     |   2\n",
      "      10612 |   0.157807  |    0.049380     |   0\n",
      "      10613 |   0.216644  |    0.185412     |   1\n",
      "      10614 |   0.205012  |    0.132109     |   1\n",
      "      10615 |   0.165816  |    0.186030     |   1\n",
      "      10616 |   0.159869  |    0.149865     |   1\n",
      "      10617 |   0.057482  |    0.010556     |   2\n",
      "      10618 |   0.030455  |    0.084012     |   2\n",
      "      10619 |   0.203068  |    0.153123     |   1\n",
      "      10620 |   0.179297  |    0.145315     |   1\n",
      "      10621 |   0.221989  |    0.045918     |   0\n",
      "      10622 |   0.210461  |    0.079172     |   0\n",
      "      10623 |   0.174398  |    0.019091     |   0\n",
      "      10624 |   0.247806  |    0.192058     |   1\n",
      "      10625 |   0.202678  |    0.154782     |   1\n",
      "      10626 |   0.273214  |    0.130187     |   1\n",
      "      10627 |   0.049807  |    0.043900     |   2\n",
      "      10628 |   0.202444  |    0.078292     |   0\n",
      "      10629 |   0.225197  |    0.148056     |   1\n",
      "      10630 |   0.218800  |    0.006179     |   0\n",
      "      10631 |   0.185896  |    0.043573     |   0\n",
      "      10632 |   0.241875  |    0.183540     |   1\n",
      "      10633 |   0.061848  |    0.023381     |   2\n",
      "      10634 |   0.227575  |    0.161146     |   1\n",
      "      10635 |   0.220691  |    0.024366     |   0\n",
      "      10636 |   0.187700  |    0.072911     |   0\n",
      "      10637 |   0.186073  |    0.022458     |   0\n",
      "      10638 |   0.153576  |    0.052543     |   0\n",
      "      10639 |   0.246984  |    0.068935     |   0\n",
      "      10640 |   0.240400  |    0.159445     |   1\n",
      "      10641 |   0.188764  |    0.043749     |   0\n",
      "      10642 |   0.207109  |    0.039993     |   0\n",
      "      10643 |   0.280488  |    0.165922     |   1\n",
      "      10644 |   0.181691  |    0.136027     |   1\n",
      "      10645 |   0.190994  |    0.046510     |   0\n",
      "      10646 |   0.243310  |    0.207992     |   1\n",
      "      10647 |   0.214748  |    0.145051     |   1\n",
      "      10648 |   0.066982  |    0.005251     |   2\n",
      "      10649 |   0.192274  |    0.080369     |   0\n",
      "      10650 |   0.156250  |    0.013808     |   0\n",
      "      10651 |   0.253744  |    0.194953     |   1\n",
      "      10652 |   0.058112  |    0.046020     |   2\n",
      "      10653 |   0.173708  |    0.049204     |   0\n",
      "      10654 |   0.207899  |    0.046648     |   0\n",
      "      10655 |   0.188172  |    0.160139     |   1\n",
      "      10656 |   0.224973  |    0.027315     |   0\n",
      "      10657 |   0.027832  |    0.076606     |   2\n",
      "      10658 |   0.204933  |    0.024281     |   0\n",
      "      10659 |   0.000086  |    0.051370     |   2\n",
      "      10660 |   0.007275  |    0.070375     |   2\n",
      "      10661 |   0.090545  |    0.007333     |   2\n",
      "      10662 |   0.230643  |    0.080143     |   0\n",
      "      10663 |   0.268042  |    0.147842     |   1\n",
      "      10664 |   0.202810  |    0.009703     |   0\n",
      "      10665 |   0.187196  |    0.086573     |   0\n",
      "      10666 |   0.043734  |    0.017263     |   2\n",
      "      10667 |   0.228926  |    0.146780     |   1\n",
      "      10668 |   0.174240  |    0.045778     |   0\n",
      "      10669 |   0.072638  |    0.051498     |   2\n",
      "      10670 |   0.207390  |    0.046160     |   0\n",
      "      10671 |   0.213448  |    0.052556     |   0\n",
      "      10672 |   0.054166  |    0.045387     |   2\n",
      "      10673 |   0.219714  |    0.049170     |   0\n",
      "      10674 |   0.178145  |    0.041682     |   0\n",
      "      10675 |   0.177668  |    0.048968     |   0\n",
      "      10676 |   0.160569  |    0.076156     |   0\n",
      "      10677 |   0.241793  |    0.163542     |   1\n",
      "      10678 |   0.229048  |    0.144800     |   1\n",
      "      10679 |   0.248382  |    0.149347     |   1\n",
      "      10680 |   0.023160  |    0.011715     |   2\n",
      "      10681 |   0.050954  |    0.080456     |   2\n",
      "      10682 |   0.210768  |    0.025747     |   0\n",
      "      10683 |   0.038087  |    0.086724     |   2\n",
      "      10684 |   0.226666  |    0.147449     |   1\n",
      "      10685 |   0.198806  |    0.110754     |   1\n",
      "      10686 |   0.000086  |    0.073896     |   2\n",
      "      10687 |   0.000086  |    0.022864     |   2\n",
      "      10688 |   0.235299  |    0.207034     |   1\n",
      "      10689 |   0.207212  |    0.101270     |   1\n",
      "      10690 |   0.183072  |    0.209876     |   1\n",
      "      10691 |   0.189914  |    0.145544     |   1\n",
      "      10692 |   0.183758  |    0.031733     |   0\n",
      "      10693 |   0.219220  |    0.057803     |   0\n",
      "      10694 |   0.230556  |    0.044886     |   0\n",
      "      10695 |   0.000087  |    0.043512     |   2\n",
      "      10696 |   0.188731  |    0.084914     |   0\n",
      "      10697 |   0.000086  |    0.019031     |   2\n",
      "      10698 |   0.178905  |    0.200149     |   1\n",
      "      10699 |   0.000086  |    0.014941     |   2\n",
      "      10700 |   0.168519  |    0.052503     |   0\n",
      "      10701 |   0.000086  |    0.041710     |   2\n",
      "      10702 |   0.063472  |    0.076780     |   2\n",
      "      10703 |   0.249928  |    0.027732     |   0\n",
      "      10704 |   0.217289  |    0.142879     |   1\n",
      "      10705 |   0.209496  |    0.219386     |   1\n",
      "      10706 |   0.194104  |    0.019455     |   0\n",
      "      10707 |   0.066881  |    0.042769     |   2\n",
      "      10708 |   0.224059  |    0.154911     |   1\n",
      "      10709 |   0.216228  |    0.155306     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 10710: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      10710 |   0.233635  |    0.094004     |   1\n",
      "      10711 |   0.194879  |    0.190185     |   1\n",
      "      10712 |   0.190108  |    0.118317     |   1\n",
      "      10713 |   0.200773  |    0.148324     |   1\n",
      "      10714 |   0.062313  |    0.052590     |   2\n",
      "      10715 |   0.196948  |    0.040222     |   0\n",
      "      10716 |   0.043921  |    0.041009     |   2\n",
      "      10717 |   0.190703  |    0.076052     |   0\n",
      "      10718 |   0.185539  |    0.016576     |   0\n",
      "      10719 |   0.162187  |    0.196315     |   1\n",
      "      10720 |   0.163604  |    0.155186     |   1\n",
      "      10721 |   0.159600  |    0.023786     |   0\n",
      "      10722 |   0.163662  |    0.055772     |   0\n",
      "      10723 |   0.181330  |    0.172417     |   1\n",
      "      10724 |   0.139217  |    0.025926     |   0\n",
      "      10725 |   0.160725  |    0.163905     |   1\n",
      "      10726 |   0.274421  |    0.080763     |   0\n",
      "      10727 |   0.272081  |    0.143119     |   1\n",
      "      10728 |   0.049852  |    0.047548     |   2\n",
      "      10729 |   0.058574  |    0.045905     |   2\n",
      "      10730 |   0.165114  |    0.043167     |   0\n",
      "      10731 |   0.205189  |    0.166746     |   1\n",
      "      10732 |   0.267659  |    0.032263     |   0\n",
      "      10733 |   0.211862  |    0.196425     |   1\n",
      "      10734 |   0.133971  |    0.014725     |   0\n",
      "      10735 |   0.197502  |    0.141836     |   1\n",
      "      10736 |   0.256338  |    0.085121     |   0\n",
      "      10737 |   0.216946  |    0.155836     |   1\n",
      "      10738 |   0.248282  |    0.111649     |   1\n",
      "      10739 |   0.031224  |    0.042922     |   2\n",
      "      10740 |   0.171400  |    0.082103     |   0\n",
      "      10741 |   0.231152  |    0.144664     |   1\n",
      "      10742 |   0.196192  |    0.025195     |   0\n",
      "      10743 |   0.266779  |    0.215483     |   1\n",
      "      10744 |   0.143682  |    0.011115     |   0\n",
      "      10745 |   0.320098  |    0.159001     |   1\n",
      "      10746 |   0.180364  |    0.046254     |   0\n",
      "      10747 |   0.246339  |    0.053433     |   0\n",
      "      10748 |   0.052344  |    0.034180     |   2\n",
      "      10749 |   0.156719  |    0.032421     |   0\n",
      "      10750 |   0.219441  |    0.080203     |   0\n",
      "      10751 |   0.199025  |    0.145546     |   1\n",
      "      10752 |   0.181579  |    0.017122     |   0\n",
      "      10753 |   0.063410  |    0.082828     |   2\n",
      "      10754 |   0.068713  |    0.022596     |   2\n",
      "      10755 |   0.205601  |    0.045731     |   0\n",
      "      10756 |   0.217612  |    0.149358     |   1\n",
      "      10757 |   0.219343  |    0.029590     |   0\n",
      "      10758 |   0.059401  |    0.074092     |   2\n",
      "      10759 |   0.027519  |    0.016259     |   2\n",
      "      10760 |   0.208740  |    0.078668     |   0\n",
      "      10761 |   0.218018  |    0.025577     |   0\n",
      "      10762 |   0.000084  |    0.043724     |   2\n",
      "      10763 |   0.205408  |    0.157278     |   1\n",
      "      10764 |   0.007616  |    0.043890     |   2\n",
      "      10765 |   0.202005  |    0.204619     |   1\n",
      "      10766 |   0.214901  |    0.144960     |   1\n",
      "      10767 |   0.091275  |    0.005098     |   2\n",
      "      10768 |   0.047689  |    0.095337     |   2\n",
      "      10769 |   0.218972  |    0.148831     |   1\n",
      "      10770 |   0.069320  |    0.041238     |   2\n",
      "      10771 |   0.221576  |    0.043987     |   0\n",
      "      10772 |   0.203248  |    0.055939     |   0\n",
      "      10773 |   0.162810  |    0.163222     |   1\n",
      "      10774 |   0.262454  |    0.018672     |   0\n",
      "      10775 |   0.052801  |    0.076856     |   2\n",
      "      10776 |   0.209648  |    0.003711     |   0\n",
      "      10777 |   0.191335  |    0.178009     |   1\n",
      "      10778 |   0.192613  |    0.185175     |   1\n",
      "      10779 |   0.023848  |    0.036147     |   2\n",
      "      10780 |   0.209929  |    0.038102     |   0\n",
      "      10781 |   0.193119  |    0.085029     |   0\n",
      "      10782 |   0.259366  |    0.145211     |   1\n",
      "      10783 |   0.240784  |    0.180291     |   1\n",
      "      10784 |   0.049076  |    0.022093     |   2\n",
      "      10785 |   0.155550  |    0.047798     |   0\n",
      "      10786 |   0.038602  |    0.042875     |   2\n",
      "      10787 |   0.277560  |    0.165670     |   1\n",
      "      10788 |   0.129096  |    0.207038     |   1\n",
      "      10789 |   0.257016  |    0.196043     |   1\n",
      "      10790 |   0.229192  |    0.134990     |   1\n",
      "      10791 |   0.211461  |    0.203108     |   1\n",
      "      10792 |   0.000085  |    0.003345     |   2\n",
      "      10793 |   0.122360  |    0.195876     |   1\n",
      "      10794 |   0.190929  |    0.152560     |   1\n",
      "      10795 |   0.000086  |    0.007162     |   2\n",
      "      10796 |   0.000086  |    0.075228     |   2\n",
      "      10797 |   0.199414  |    0.033863     |   0\n",
      "      10798 |   0.000086  |    0.045149     |   2\n",
      "      10799 |   0.227111  |    0.053926     |   0\n",
      "      10800 |   0.000085  |    0.019882     |   2\n",
      "      10801 |   0.000086  |    0.054250     |   2\n",
      "      10802 |   0.059786  |    0.073851     |   2\n",
      "      10803 |   0.064760  |    0.023547     |   2\n",
      "      10804 |   0.214577  |    0.075720     |   0\n",
      "      10805 |   0.259107  |    0.140471     |   1\n",
      "      10806 |   0.277465  |    0.016904     |   0\n",
      "      10807 |   0.156878  |    0.044392     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 10809: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      10808 |   0.199489  |    0.039738     |   0\n",
      "      10809 |   0.183547  |    0.044699     |   0\n",
      "      10810 |   0.255467  |    0.159184     |   1\n",
      "      10811 |   0.195527  |    0.049322     |   0\n",
      "      10812 |   0.207405  |    0.048428     |   0\n",
      "      10813 |   0.198408  |    0.192451     |   1\n",
      "      10814 |   0.206545  |    0.163732     |   1\n",
      "      10815 |   0.129338  |    0.015064     |   0\n",
      "      10816 |   0.156647  |    0.040974     |   0\n",
      "      10817 |   0.204150  |    0.072230     |   0\n",
      "      10818 |   0.062055  |    0.027122     |   2\n",
      "      10819 |   0.042570  |    0.064214     |   2\n",
      "      10820 |   0.207341  |    0.131473     |   1\n",
      "      10821 |   0.161458  |    0.014699     |   0\n",
      "      10822 |   0.217354  |    0.073774     |   0\n",
      "      10823 |   0.049228  |    0.041842     |   2\n",
      "      10824 |   0.054768  |    0.045496     |   2\n",
      "      10825 |   0.030267  |    0.038697     |   2\n",
      "      10826 |   0.050541  |    0.037194     |   2\n",
      "      10827 |   0.060845  |    0.074573     |   2\n",
      "      10828 |   0.068603  |    0.019596     |   2\n",
      "      10829 |   0.056107  |    0.084488     |   2\n",
      "      10830 |   0.174209  |    0.168278     |   1\n",
      "      10831 |   0.234039  |    0.109964     |   1\n",
      "      10832 |   0.202724  |    0.038796     |   0\n",
      "      10833 |   0.250187  |    0.143955     |   1\n",
      "      10834 |   0.216722  |    0.095842     |   0\n",
      "      10835 |   0.203434  |    0.148450     |   1\n",
      "      10836 |   0.026866  |    0.020988     |   2\n",
      "      10837 |   0.000083  |    0.072666     |   2\n",
      "      10838 |   0.006822  |    0.022280     |   2\n",
      "      10839 |   0.088443  |    0.082736     |   2\n",
      "      10840 |   0.221748  |    0.027945     |   0\n",
      "      10841 |   0.153207  |    0.210188     |   1\n",
      "      10842 |   0.166267  |    0.017247     |   0\n",
      "      10843 |   0.154653  |    0.151825     |   1\n",
      "      10844 |   0.150584  |    0.008070     |   0\n",
      "      10845 |   0.042412  |    0.084873     |   2\n",
      "      10846 |   0.212628  |    0.142571     |   1\n",
      "      10847 |   0.217509  |    0.198321     |   1\n",
      "      10848 |   0.198875  |    0.156817     |   1\n",
      "      10849 |   0.254427  |    0.138468     |   1\n",
      "      10850 |   0.066101  |    0.048956     |   2\n",
      "      10851 |   0.049067  |    0.041432     |   2\n",
      "      10852 |   0.227056  |    0.142475     |   1\n",
      "      10853 |   0.176910  |    0.046150     |   0\n",
      "      10854 |   0.230025  |    0.162558     |   1\n",
      "      10855 |   0.021095  |    0.050914     |   2\n",
      "      10856 |   0.360943  |    0.144561     |   1\n",
      "      10857 |   0.249066  |    0.144667     |   1\n",
      "      10858 |   0.213704  |    0.192727     |   1\n",
      "      10859 |   0.221746  |    0.017691     |   0\n",
      "      10860 |   0.203375  |    0.137058     |   1\n",
      "      10861 |   0.172072  |    0.142251     |   1\n",
      "      10862 |   0.193782  |    0.078323     |   0\n",
      "      10863 |   0.237605  |    0.142341     |   1\n",
      "      10864 |   0.198942  |    0.038981     |   0\n",
      "      10865 |   0.044928  |    0.074310     |   2\n",
      "      10866 |   0.159049  |    0.024638     |   0\n",
      "      10867 |   0.198589  |    0.049610     |   0\n",
      "      10868 |   0.155027  |    0.179349     |   1\n",
      "      10869 |   0.035729  |    0.005082     |   2\n",
      "      10870 |   0.214964  |    0.073939     |   0\n",
      "      10871 |   0.000083  |    0.026792     |   2\n",
      "      10872 |   0.000083  |    0.081535     |   2\n",
      "      10873 |   0.236335  |    0.025056     |   0\n",
      "      10874 |   0.185643  |    0.082299     |   0\n",
      "      10875 |   0.167655  |    0.007514     |   0\n",
      "      10876 |   0.197095  |    0.190110     |   1\n",
      "      10877 |   0.000083  |    0.031078     |   2\n",
      "      10878 |   0.201365  |    0.189431     |   1\n",
      "      10879 |   0.264755  |    0.148458     |   1\n",
      "      10880 |   0.169986  |    0.101397     |   1\n",
      "      10881 |   0.000083  |    0.043127     |   2\n",
      "      10882 |   0.231889  |    0.038956     |   0\n",
      "      10883 |   0.263257  |    0.193487     |   1\n",
      "      10884 |   0.201773  |    0.016865     |   0\n",
      "      10885 |   0.246547  |    0.079715     |   0\n",
      "      10886 |   0.000082  |    0.022702     |   2\n",
      "      10887 |   0.222609  |    0.079768     |   0\n",
      "      10888 |   0.230347  |    0.016411     |   0\n",
      "      10889 |   0.000082  |    0.073357     |   2\n",
      "      10890 |   0.181771  |    0.193017     |   1\n",
      "      10891 |   0.066933  |    0.022320     |   2\n",
      "      10892 |   0.202536  |    0.164998     |   1\n",
      "      10893 |   0.232415  |    0.050905     |   0\n",
      "      10894 |   0.201221  |    0.044404     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 10896: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      10895 |   0.065966  |    0.040611     |   2\n",
      "      10896 |   0.064163  |    0.042819     |   2\n",
      "      10897 |   0.046493  |    0.045079     |   2\n",
      "      10898 |   0.047852  |    0.038899     |   2\n",
      "      10899 |   0.057792  |    0.043678     |   2\n",
      "      10900 |   0.184228  |    0.050237     |   0\n",
      "      10901 |   0.237585  |    0.189536     |   1\n",
      "      10902 |   0.191358  |    0.153516     |   1\n",
      "      10903 |   0.167923  |    0.166625     |   1\n",
      "      10904 |   0.144552  |    0.008712     |   0\n",
      "      10905 |   0.175341  |    0.048087     |   0\n",
      "      10906 |   0.219180  |    0.046660     |   0\n",
      "      10907 |   0.196377  |    0.199293     |   1\n",
      "      10908 |   0.179786  |    0.183393     |   1\n",
      "      10909 |   0.269867  |    0.091806     |   1\n",
      "      10910 |   0.163943  |    0.049636     |   0\n",
      "      10911 |   0.235308  |    0.209157     |   1\n",
      "      10912 |   0.208434  |    0.145662     |   1\n",
      "      10913 |   0.212072  |    0.146432     |   1\n",
      "      10914 |   0.233268  |    0.187005     |   1\n",
      "      10915 |   0.271079  |    0.101657     |   1\n",
      "      10916 |   0.221356  |    0.144891     |   1\n",
      "      10917 |   0.221769  |    0.206266     |   1\n",
      "      10918 |   0.030933  |    0.003313     |   2\n",
      "      10919 |   0.177898  |    0.049419     |   0\n",
      "      10920 |   0.050213  |    0.034993     |   2\n",
      "      10921 |   0.208873  |    0.051308     |   0\n",
      "      10922 |   0.195886  |    0.145581     |   1\n",
      "      10923 |   0.207702  |    0.201229     |   1\n",
      "      10924 |   0.173103  |    0.007118     |   0\n",
      "      10925 |   0.213244  |    0.065308     |   0\n",
      "      10926 |   0.204946  |    0.137059     |   1\n",
      "      10927 |   0.247187  |    0.044159     |   0\n",
      "      10928 |   0.242928  |    0.072961     |   0\n",
      "      10929 |   0.058048  |    0.016953     |   2\n",
      "      10930 |   0.168555  |    0.192284     |   1\n",
      "      10931 |   0.259554  |    0.146172     |   1\n",
      "      10932 |   0.062418  |    0.037447     |   2\n",
      "      10933 |   0.240369  |    0.197327     |   1\n",
      "      10934 |   0.056449  |    0.012716     |   2\n",
      "      10935 |   0.028492  |    0.064457     |   2\n",
      "      10936 |   0.000082  |    0.047529     |   2\n",
      "      10937 |   0.190958  |    0.186448     |   1\n",
      "      10938 |   0.224508  |    0.155264     |   1\n",
      "      10939 |   0.225524  |    0.016594     |   0\n",
      "      10940 |   0.194018  |    0.071551     |   0\n",
      "      10941 |   0.006903  |    0.035630     |   2\n",
      "      10942 |   0.237074  |    0.183637     |   1\n",
      "      10943 |   0.090234  |    0.006752     |   2\n",
      "      10944 |   0.044220  |    0.048346     |   2\n",
      "      10945 |   0.067956  |    0.095559     |   2\n",
      "      10946 |   0.185769  |    0.111597     |   1\n",
      "      10947 |   0.047579  |    0.052255     |   2\n",
      "      10948 |   0.243511  |    0.185909     |   1\n",
      "      10949 |   0.209691  |    0.008041     |   0\n",
      "      10950 |   0.238432  |    0.193305     |   1\n",
      "      10951 |   0.184193  |    0.013023     |   0\n",
      "      10952 |   0.220176  |    0.140010     |   1\n",
      "      10953 |   0.196649  |    0.075491     |   0\n",
      "      10954 |   0.022464  |    0.046070     |   2\n",
      "      10955 |   0.228953  |    0.207107     |   1\n",
      "      10956 |   0.239658  |    0.008246     |   0\n",
      "      10957 |   0.047422  |    0.039977     |   2\n",
      "      10958 |   0.205295  |    0.086699     |   0\n",
      "      10959 |   0.218879  |    0.126976     |   1\n",
      "      10960 |   0.207921  |    0.058684     |   0\n",
      "      10961 |   0.221250  |    0.150454     |   1\n",
      "      10962 |   0.187440  |    0.013012     |   0\n",
      "      10963 |   0.230266  |    0.193777     |   1\n",
      "      10964 |   0.037119  |    0.004711     |   2\n",
      "      10965 |   0.203900  |    0.170268     |   1\n",
      "      10966 |   0.176496  |    0.163161     |   1\n",
      "      10967 |   0.209634  |    0.028709     |   0\n",
      "      10968 |   0.198567  |    0.051621     |   0\n",
      "      10969 |   0.000081  |    0.039323     |   2\n",
      "      10970 |   0.000081  |    0.044987     |   2\n",
      "      10971 |   0.130702  |    0.043584     |   0\n",
      "      10972 |   0.000081  |    0.039765     |   2\n",
      "      10973 |   0.206347  |    0.042793     |   0\n",
      "      10974 |   0.189985  |    0.173652     |   1\n",
      "      10975 |   0.168152  |    0.045894     |   0\n",
      "      10976 |   0.000081  |    0.027594     |   2\n",
      "      10977 |   0.195138  |    0.099220     |   0\n",
      "      10978 |   0.184815  |    0.138885     |   1\n",
      "      10979 |   0.257882  |    0.047472     |   0\n",
      "      10980 |   0.212138  |    0.147603     |   1\n",
      "      10981 |   0.315594  |    0.197607     |   1\n",
      "      10982 |   0.000080  |    0.024244     |   2\n",
      "      10983 |   0.175690  |    0.223614     |   1\n",
      "      10984 |   0.194983  |    0.007662     |   0\n",
      "      10985 |   0.000080  |    0.030545     |   2\n",
      "      10986 |   0.202219  |    0.044963     |   0\n",
      "      10987 |   0.063461  |    0.042813     |   2\n",
      "      10988 |   0.176532  |    0.209344     |   1\n",
      "      10989 |   0.180341  |    0.003447     |   0\n",
      "      10990 |   0.196712  |    0.052859     |   0\n",
      "      10991 |   0.064370  |    0.055661     |   2\n",
      "      10992 |   0.260935  |    0.145130     |   1\n",
      "      10993 |   0.222687  |    0.042186     |   0\n",
      "      10994 |   0.214659  |    0.076854     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 10996: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      10995 |   0.196285  |    0.025844     |   0\n",
      "      10996 |   0.230667  |    0.074692     |   0\n",
      "      10997 |   0.063883  |    0.046121     |   2\n",
      "      10998 |   0.211348  |    0.052024     |   0\n",
      "      10999 |   0.044965  |    0.031036     |   2\n",
      "      11000 |   0.049141  |    0.073759     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 11000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 11000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      11001 |   0.241428  |    0.194978     |   1\n",
      "      11002 |   0.243576  |    0.158476     |   1\n",
      "      11003 |   0.182146  |    0.133973     |   1\n",
      "      11004 |   0.061335  |    0.025969     |   2\n",
      "      11005 |   0.235522  |    0.070375     |   0\n",
      "      11006 |   0.200553  |    0.051778     |   0\n",
      "      11007 |   0.150391  |    0.154906     |   1\n",
      "      11008 |   0.042135  |    0.043032     |   2\n",
      "      11009 |   0.047674  |    0.044418     |   2\n",
      "      11010 |   0.058266  |    0.077666     |   2\n",
      "      11011 |   0.219865  |    0.030545     |   0\n",
      "      11012 |   0.032281  |    0.073202     |   2\n",
      "      11013 |   0.230163  |    0.143037     |   1\n",
      "      11014 |   0.048785  |    0.047907     |   2\n",
      "      11015 |   0.057184  |    0.040035     |   2\n",
      "      11016 |   0.234195  |    0.090936     |   0\n",
      "      11017 |   0.159118  |    0.161103     |   1\n",
      "      11018 |   0.064476  |    0.011327     |   2\n",
      "      11019 |   0.232178  |    0.087170     |   0\n",
      "      11020 |   0.054135  |    0.023554     |   2\n",
      "      11021 |   0.027869  |    0.047819     |   2\n",
      "      11022 |   0.199373  |    0.046576     |   0\n",
      "      11023 |   0.000080  |    0.046183     |   2\n",
      "      11024 |   0.216033  |    0.080905     |   0\n",
      "      11025 |   0.161646  |    0.157027     |   1\n",
      "      11026 |   0.007037  |    0.054286     |   2\n",
      "      11027 |   0.228770  |    0.186539     |   1\n",
      "      11028 |   0.088398  |    0.008349     |   2\n",
      "      11029 |   0.194680  |    0.051090     |   0\n",
      "      11030 |   0.177811  |    0.077932     |   0\n",
      "      11031 |   0.041923  |    0.022914     |   2\n",
      "      11032 |   0.230062  |    0.043437     |   0\n",
      "      11033 |   0.230255  |    0.045201     |   0\n",
      "      11034 |   0.229790  |    0.088080     |   0\n",
      "      11035 |   0.211444  |    0.152590     |   1\n",
      "      11036 |   0.152779  |    0.195619     |   1\n",
      "      11037 |   0.245257  |    0.006916     |   0\n",
      "      11038 |   0.194937  |    0.197533     |   1\n",
      "      11039 |   0.164565  |    0.027550     |   0\n",
      "      11040 |   0.247982  |    0.161939     |   1\n",
      "      11041 |   0.240990  |    0.148761     |   1\n",
      "      11042 |   0.069385  |    0.027365     |   2\n",
      "      11043 |   0.051169  |    0.075029     |   2\n",
      "      11044 |   0.023534  |    0.015079     |   2\n",
      "      11045 |   0.230747  |    0.089626     |   0\n",
      "      11046 |   0.047543  |    0.017649     |   2\n",
      "      11047 |   0.039073  |    0.081717     |   2\n",
      "      11048 |   0.000080  |    0.015033     |   2\n",
      "      11049 |   0.191857  |    0.081047     |   0\n",
      "      11050 |   0.176649  |    0.162487     |   1\n",
      "      11051 |   0.000080  |    0.011976     |   2\n",
      "      11052 |   0.000080  |    0.080428     |   2\n",
      "      11053 |   0.172440  |    0.023958     |   0\n",
      "      11054 |   0.185844  |    0.082633     |   0\n",
      "      11055 |   0.238031  |    0.142683     |   1\n",
      "      11056 |   0.218021  |    0.039928     |   0\n",
      "      11057 |   0.174348  |    0.081882     |   0\n",
      "      11058 |   0.000080  |    0.015740     |   2\n",
      "      11059 |   0.219738  |    0.064536     |   0\n",
      "      11060 |   0.236211  |    0.163076     |   1\n",
      "      11061 |   0.000080  |    0.021587     |   2\n",
      "      11062 |   0.152325  |    0.044331     |   0\n",
      "      11063 |   0.188892  |    0.050602     |   0\n",
      "      11064 |   0.205339  |    0.072188     |   0\n",
      "      11065 |   0.000080  |    0.014117     |   2\n",
      "      11066 |   0.205351  |    0.185249     |   1\n",
      "      11067 |   0.150076  |    0.044427     |   0\n",
      "      11068 |   0.194335  |    0.049382     |   0\n",
      "      11069 |   0.231113  |    0.181713     |   1\n",
      "      11070 |   0.180950  |    0.040475     |   0\n",
      "      11071 |   0.188637  |    0.047230     |   0\n",
      "      11072 |   0.273148  |    0.049721     |   0\n",
      "      11073 |   0.194423  |    0.074368     |   0\n",
      "      11074 |   0.192238  |    0.028983     |   0\n",
      "      11075 |   0.066145  |    0.055746     |   2\n",
      "      11076 |   0.206079  |    0.149676     |   1\n",
      "      11077 |   0.215027  |    0.041058     |   0\n",
      "      11078 |   0.066592  |    0.042857     |   2\n",
      "      11079 |   0.200676  |    0.081918     |   0\n",
      "      11080 |   0.219343  |    0.133969     |   1\n",
      "      11081 |   0.198721  |    0.153861     |   1\n",
      "      11082 |   0.204433  |    0.155596     |   1\n",
      "      11083 |   0.186911  |    0.105690     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 11084: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      11084 |   0.063283  |    0.045529     |   2\n",
      "      11085 |   0.044165  |    0.031455     |   2\n",
      "      11086 |   0.048020  |    0.082479     |   2\n",
      "      11087 |   0.056319  |    0.006614     |   2\n",
      "      11088 |   0.180124  |    0.083129     |   0\n",
      "      11089 |   0.032302  |    0.013805     |   2\n",
      "      11090 |   0.050891  |    0.049932     |   2\n",
      "      11091 |   0.234782  |    0.138515     |   1\n",
      "      11092 |   0.188416  |    0.044548     |   0\n",
      "      11093 |   0.181515  |    0.143042     |   1\n",
      "      11094 |   0.253463  |    0.194416     |   1\n",
      "      11095 |   0.262509  |    0.141477     |   1\n",
      "      11096 |   0.063781  |    0.009048     |   2\n",
      "      11097 |   0.211214  |    0.072433     |   0\n",
      "      11098 |   0.159830  |    0.154335     |   1\n",
      "      11099 |   0.229274  |    0.155591     |   1\n",
      "      11100 |   0.161467  |    0.043359     |   0\n",
      "      11101 |   0.067149  |    0.045583     |   2\n",
      "      11102 |   0.211094  |    0.076014     |   0\n",
      "      11103 |   0.053796  |    0.029502     |   2\n",
      "      11104 |   0.028067  |    0.041726     |   2\n",
      "      11105 |   0.173610  |    0.086092     |   0\n",
      "      11106 |   0.000080  |    0.015082     |   2\n",
      "      11107 |   0.166541  |    0.082480     |   0\n",
      "      11108 |   0.169329  |    0.030242     |   0\n",
      "      11109 |   0.267211  |    0.153488     |   1\n",
      "      11110 |   0.007280  |    0.037610     |   2\n",
      "      11111 |   0.089327  |    0.072317     |   2\n",
      "      11112 |   0.264876  |    0.042471     |   0\n",
      "      11113 |   0.304488  |    0.153352     |   1\n",
      "      11114 |   0.207346  |    0.138732     |   1\n",
      "      11115 |   0.194616  |    0.163671     |   1\n",
      "      11116 |   0.212211  |    0.021224     |   0\n",
      "      11117 |   0.184863  |    0.192820     |   1\n",
      "      11118 |   0.043732  |    0.010671     |   2\n",
      "      11119 |   0.201859  |    0.073787     |   0\n",
      "      11120 |   0.066914  |    0.010698     |   2\n",
      "      11121 |   0.267945  |    0.212945     |   1\n",
      "      11122 |   0.047063  |    0.005514     |   2\n",
      "      11123 |   0.210090  |    0.072853     |   0\n",
      "      11124 |   0.022026  |    0.021670     |   2\n",
      "      11125 |   0.247729  |    0.084678     |   0\n",
      "      11126 |   0.260287  |    0.138080     |   1\n",
      "      11127 |   0.243336  |    0.017866     |   0\n",
      "      11128 |   0.048475  |    0.077863     |   2\n",
      "      11129 |   0.034420  |    0.018773     |   2\n",
      "      11130 |   0.226636  |    0.075497     |   0\n",
      "      11131 |   0.234386  |    0.136385     |   1\n",
      "      11132 |   0.183007  |    0.056101     |   0\n",
      "      11133 |   0.000079  |    0.057907     |   2\n",
      "      11134 |   0.258288  |    0.152753     |   1\n",
      "      11135 |   0.221896  |    0.216286     |   1\n",
      "      11136 |   0.245463  |    0.147264     |   1\n",
      "      11137 |   0.180380  |    0.012097     |   0\n",
      "      11138 |   0.282873  |    0.153611     |   1\n",
      "      11139 |   0.000079  |    0.024424     |   2\n",
      "      11140 |   0.201933  |    0.079851     |   0\n",
      "      11141 |   0.217257  |    0.140319     |   1\n",
      "      11142 |   0.000080  |    0.059146     |   2\n",
      "      11143 |   0.227665  |    0.178655     |   1\n",
      "      11144 |   0.243423  |    0.093244     |   1\n",
      "      11145 |   0.228715  |    0.072520     |   0\n",
      "      11146 |   0.153512  |    0.024158     |   0\n",
      "      11147 |   0.196515  |    0.101650     |   0\n",
      "      11148 |   0.205525  |    0.135489     |   1\n",
      "      11149 |   0.166837  |    0.072797     |   0\n",
      "      11150 |   0.184839  |    0.014440     |   0\n",
      "      11151 |   0.259835  |    0.206502     |   1\n",
      "      11152 |   0.190545  |    0.135323     |   1\n",
      "      11153 |   0.220030  |    0.031133     |   0\n",
      "      11154 |   0.222771  |    0.164267     |   1\n",
      "      11155 |   0.203254  |    0.136787     |   1\n",
      "      11156 |   0.000079  |    0.040135     |   2\n",
      "      11157 |   0.232860  |    0.049932     |   0\n",
      "      11158 |   0.000079  |    0.037533     |   2\n",
      "      11159 |   0.190032  |    0.077437     |   0\n",
      "      11160 |   0.000079  |    0.008767     |   2\n",
      "      11161 |   0.057427  |    0.078968     |   2\n",
      "      11162 |   0.207079  |    0.019350     |   0\n",
      "      11163 |   0.063705  |    0.051993     |   2\n",
      "      11164 |   0.205786  |    0.077969     |   0\n",
      "      11165 |   0.271584  |    0.128906     |   1\n",
      "      11166 |   0.180784  |    0.041896     |   0\n",
      "      11167 |   0.198247  |    0.047365     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 11168: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      11168 |   0.197627  |    0.151565     |   1\n",
      "      11169 |   0.275117  |    0.075728     |   0\n",
      "      11170 |   0.058309  |    0.020553     |   2\n",
      "      11171 |   0.196935  |    0.075791     |   0\n",
      "      11172 |   0.191651  |    0.023362     |   0\n",
      "      11173 |   0.041141  |    0.069997     |   2\n",
      "      11174 |   0.047623  |    0.023159     |   2\n",
      "      11175 |   0.223756  |    0.073665     |   0\n",
      "      11176 |   0.199197  |    0.053379     |   0\n",
      "      11177 |   0.253001  |    0.191198     |   1\n",
      "      11178 |   0.059075  |    0.009249     |   2\n",
      "      11179 |   0.238557  |    0.079819     |   0\n",
      "      11180 |   0.032057  |    0.027353     |   2\n",
      "      11181 |   0.206814  |    0.077256     |   0\n",
      "      11182 |   0.242668  |    0.025088     |   0\n",
      "      11183 |   0.051418  |    0.063601     |   2\n",
      "      11184 |   0.312884  |    0.158351     |   1\n",
      "      11185 |   0.190464  |    0.202282     |   1\n",
      "      11186 |   0.161849  |    0.011398     |   0\n",
      "      11187 |   0.061153  |    0.022497     |   2\n",
      "      11188 |   0.064366  |    0.083729     |   2\n",
      "      11189 |   0.188865  |    0.030926     |   0\n",
      "      11190 |   0.257283  |    0.162652     |   1\n",
      "      11191 |   0.188140  |    0.078561     |   0\n",
      "      11192 |   0.057565  |    0.008365     |   2\n",
      "      11193 |   0.028506  |    0.080235     |   2\n",
      "      11194 |   0.196260  |    0.023036     |   0\n",
      "      11195 |   0.209713  |    0.044817     |   0\n",
      "      11196 |   0.217315  |    0.050001     |   0\n",
      "      11197 |   0.000078  |    0.044307     |   2\n",
      "      11198 |   0.151531  |    0.186727     |   1\n",
      "      11199 |   0.170828  |    0.104645     |   1\n",
      "      11200 |   0.199472  |    0.189737     |   1\n",
      "      11201 |   0.193644  |    0.017318     |   0\n",
      "      11202 |   0.199377  |    0.082925     |   0\n",
      "      11203 |   0.212589  |    0.143193     |   1\n",
      "      11204 |   0.007083  |    0.050838     |   2\n",
      "      11205 |   0.087381  |    0.040217     |   2\n",
      "      11206 |   0.044401  |    0.078072     |   2\n",
      "      11207 |   0.213680  |    0.043065     |   0\n",
      "      11208 |   0.236445  |    0.040659     |   0\n",
      "      11209 |   0.168298  |    0.048019     |   0\n",
      "      11210 |   0.221679  |    0.041332     |   0\n",
      "      11211 |   0.206288  |    0.073951     |   0\n",
      "      11212 |   0.070289  |    0.022967     |   2\n",
      "      11213 |   0.052357  |    0.085950     |   2\n",
      "      11214 |   0.191433  |    0.159776     |   1\n",
      "      11215 |   0.159396  |    0.031833     |   0\n",
      "      11216 |   0.220544  |    0.228081     |   1\n",
      "      11217 |   0.275730  |    0.112562     |   1\n",
      "      11218 |   0.025117  |    0.039438     |   2\n",
      "      11219 |   0.189285  |    0.089074     |   0\n",
      "      11220 |   0.194349  |    0.145016     |   1\n",
      "      11221 |   0.156391  |    0.028265     |   0\n",
      "      11222 |   0.215704  |    0.223401     |   1\n",
      "      11223 |   0.169601  |    0.109096     |   1\n",
      "      11224 |   0.051504  |    0.044447     |   2\n",
      "      11225 |   0.036294  |    0.040937     |   2\n",
      "      11226 |   0.219956  |    0.081750     |   0\n",
      "      11227 |   0.192810  |    0.186079     |   1\n",
      "      11228 |   0.187926  |    0.004635     |   0\n",
      "      11229 |   0.188595  |    0.042705     |   0\n",
      "      11230 |   0.000077  |    0.043192     |   2\n",
      "      11231 |   0.000077  |    0.076163     |   2\n",
      "      11232 |   0.189166  |    0.042061     |   0\n",
      "      11233 |   0.226682  |    0.046009     |   0\n",
      "      11234 |   0.000078  |    0.076387     |   2\n",
      "      11235 |   0.202235  |    0.028737     |   0\n",
      "      11236 |   0.000078  |    0.078270     |   2\n",
      "      11237 |   0.000077  |    0.010200     |   2\n",
      "      11238 |   0.000077  |    0.079572     |   2\n",
      "      11239 |   0.062607  |    0.038805     |   2\n",
      "      11240 |   0.240489  |    0.164422     |   1\n",
      "      11241 |   0.196729  |    0.146595     |   1\n",
      "      11242 |   0.205351  |    0.085648     |   0\n",
      "      11243 |   0.264618  |    0.145071     |   1\n",
      "      11244 |   0.140953  |    0.185957     |   1\n",
      "      11245 |   0.236011  |    0.135762     |   1\n",
      "      11246 |   0.155963  |    0.011098     |   0\n",
      "      11247 |   0.167694  |    0.208940     |   1\n",
      "      11248 |   0.134018  |    0.015154     |   0\n",
      "      11249 |   0.206880  |    0.046754     |   0\n",
      "      11250 |   0.236195  |    0.078165     |   0\n",
      "      11251 |   0.174688  |    0.023016     |   0\n",
      "      11252 |   0.169776  |    0.044376     |   0\n",
      "      11253 |   0.279382  |    0.154152     |   1\n",
      "      11254 |   0.064299  |    0.020409     |   2\n",
      "      11255 |   0.195930  |    0.233058     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 11256: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      11256 |   0.155672  |    0.012054     |   0\n",
      "      11257 |   0.203940  |    0.140845     |   1\n",
      "      11258 |   0.168972  |    0.005047     |   0\n",
      "      11259 |   0.062998  |    0.042580     |   2\n",
      "      11260 |   0.045681  |    0.041208     |   2\n",
      "      11261 |   0.229311  |    0.206275     |   1\n",
      "      11262 |   0.212481  |    0.014643     |   0\n",
      "      11263 |   0.182342  |    0.073746     |   0\n",
      "      11264 |   0.231586  |    0.137357     |   1\n",
      "      11265 |   0.195696  |    0.046561     |   0\n",
      "      11266 |   0.274042  |    0.190615     |   1\n",
      "      11267 |   0.047870  |    0.027503     |   2\n",
      "      11268 |   0.057686  |    0.089959     |   2\n",
      "      11269 |   0.157105  |    0.171536     |   1\n",
      "      11270 |   0.215376  |    0.156942     |   1\n",
      "      11271 |   0.031866  |    0.044541     |   2\n",
      "      11272 |   0.051205  |    0.040510     |   2\n",
      "      11273 |   0.063010  |    0.077218     |   2\n",
      "      11274 |   0.067123  |    0.014799     |   2\n",
      "      11275 |   0.053998  |    0.082001     |   2\n",
      "      11276 |   0.027388  |    0.011403     |   2\n",
      "      11277 |   0.202590  |    0.065418     |   0\n",
      "      11278 |   0.214537  |    0.140492     |   1\n",
      "      11279 |   0.222603  |    0.041582     |   0\n",
      "      11280 |   0.178357  |    0.051054     |   0\n",
      "      11281 |   0.243475  |    0.163581     |   1\n",
      "      11282 |   0.000078  |    0.024616     |   2\n",
      "      11283 |   0.007355  |    0.087272     |   2\n",
      "      11284 |   0.180910  |    0.162162     |   1\n",
      "      11285 |   0.167066  |    0.017644     |   0\n",
      "      11286 |   0.235290  |    0.166118     |   1\n",
      "      11287 |   0.146816  |    0.141418     |   1\n",
      "      11288 |   0.224704  |    0.021642     |   0\n",
      "      11289 |   0.151449  |    0.193034     |   1\n",
      "      11290 |   0.199059  |    0.078452     |   0\n",
      "      11291 |   0.236174  |    0.156891     |   1\n",
      "      11292 |   0.204103  |    0.004640     |   0\n",
      "      11293 |   0.084265  |    0.050011     |   2\n",
      "      11294 |   0.203329  |    0.150982     |   1\n",
      "      11295 |   0.183401  |    0.145743     |   1\n",
      "      11296 |   0.042721  |    0.032464     |   2\n",
      "      11297 |   0.066793  |    0.049626     |   2\n",
      "      11298 |   0.213233  |    0.046701     |   0\n",
      "      11299 |   0.169438  |    0.071942     |   0\n",
      "      11300 |   0.049162  |    0.020287     |   2\n",
      "      11301 |   0.180138  |    0.086273     |   0\n",
      "      11302 |   0.212345  |    0.157309     |   1\n",
      "      11303 |   0.250642  |    0.099535     |   1\n",
      "      11304 |   0.181604  |    0.210914     |   1\n",
      "      11305 |   0.180213  |    0.004297     |   0\n",
      "      11306 |   0.136499  |    0.087265     |   0\n",
      "      11307 |   0.022123  |    0.008812     |   2\n",
      "      11308 |   0.191630  |    0.074138     |   0\n",
      "      11309 |   0.189224  |    0.132298     |   1\n",
      "      11310 |   0.181536  |    0.043328     |   0\n",
      "      11311 |   0.048836  |    0.073959     |   2\n",
      "      11312 |   0.221250  |    0.030332     |   0\n",
      "      11313 |   0.209000  |    0.043243     |   0\n",
      "      11314 |   0.196921  |    0.201013     |   1\n",
      "      11315 |   0.191433  |    0.191663     |   1\n",
      "      11316 |   0.188991  |    0.003080     |   0\n",
      "      11317 |   0.037421  |    0.037245     |   2\n",
      "      11318 |   0.220141  |    0.080559     |   0\n",
      "      11319 |   0.182503  |    0.147799     |   1\n",
      "      11320 |   0.168659  |    0.026055     |   0\n",
      "      11321 |   0.198448  |    0.161798     |   1\n",
      "      11322 |   0.000077  |    0.039943     |   2\n",
      "      11323 |   0.161944  |    0.077099     |   0\n",
      "      11324 |   0.000077  |    0.012508     |   2\n",
      "      11325 |   0.000077  |    0.079757     |   2\n",
      "      11326 |   0.000077  |    0.036862     |   2\n",
      "      11327 |   0.000077  |    0.038815     |   2\n",
      "      11328 |   0.000077  |    0.075565     |   2\n",
      "      11329 |   0.063677  |    0.041617     |   2\n",
      "      11330 |   0.196291  |    0.045620     |   0\n",
      "      11331 |   0.229068  |    0.041090     |   0\n",
      "      11332 |   0.063336  |    0.074100     |   2\n",
      "      11333 |   0.200059  |    0.138675     |   1\n",
      "      11334 |   0.211357  |    0.053070     |   0\n",
      "      11335 |   0.210610  |    0.148125     |   1\n",
      "      11336 |   0.287414  |    0.196930     |   1\n",
      "      11337 |   0.248890  |    0.136639     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 11338: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      11338 |   0.220526  |    0.030020     |   0\n",
      "      11339 |   0.228847  |    0.153199     |   1\n",
      "      11340 |   0.224832  |    0.007609     |   0\n",
      "      11341 |   0.198892  |    0.202952     |   1\n",
      "      11342 |   0.168354  |    0.023737     |   0\n",
      "      11343 |   0.198784  |    0.081079     |   0\n",
      "      11344 |   0.228116  |    0.154951     |   1\n",
      "      11345 |   0.059230  |    0.018086     |   2\n",
      "      11346 |   0.241127  |    0.196657     |   1\n",
      "      11347 |   0.040687  |    0.047095     |   2\n",
      "      11348 |   0.243920  |    0.146843     |   1\n",
      "      11349 |   0.048018  |    0.024708     |   2\n",
      "      11350 |   0.246285  |    0.072459     |   0\n",
      "      11351 |   0.197440  |    0.020608     |   0\n",
      "      11352 |   0.058911  |    0.054414     |   2\n",
      "      11353 |   0.030526  |    0.074731     |   2\n",
      "      11354 |   0.162427  |    0.008924     |   0\n",
      "      11355 |   0.221202  |    0.079794     |   0\n",
      "      11356 |   0.205203  |    0.031265     |   0\n",
      "      11357 |   0.050170  |    0.045216     |   2\n",
      "      11358 |   0.059076  |    0.072322     |   2\n",
      "      11359 |   0.200837  |    0.041095     |   0\n",
      "      11360 |   0.216661  |    0.046720     |   0\n",
      "      11361 |   0.064322  |    0.041103     |   2\n",
      "      11362 |   0.055417  |    0.062284     |   2\n",
      "      11363 |   0.283928  |    0.187307     |   1\n",
      "      11364 |   0.028732  |    0.008741     |   2\n",
      "      11365 |   0.000077  |    0.045388     |   2\n",
      "      11366 |   0.007223  |    0.057033     |   2\n",
      "      11367 |   0.234211  |    0.194490     |   1\n",
      "      11368 |   0.206974  |    0.140913     |   1\n",
      "      11369 |   0.161873  |    0.024892     |   0\n",
      "      11370 |   0.245078  |    0.050149     |   0\n",
      "      11371 |   0.169986  |    0.048168     |   0\n",
      "      11372 |   0.158136  |    0.189386     |   1\n",
      "      11373 |   0.084308  |    0.022731     |   2\n",
      "      11374 |   0.162931  |    0.204186     |   1\n",
      "      11375 |   0.226882  |    0.139146     |   1\n",
      "      11376 |   0.042032  |    0.010778     |   2\n",
      "      11377 |   0.065920  |    0.075821     |   2\n",
      "      11378 |   0.254753  |    0.023545     |   0\n",
      "      11379 |   0.186482  |    0.044425     |   0\n",
      "      11380 |   0.176884  |    0.090896     |   0\n",
      "      11381 |   0.213805  |    0.161450     |   1\n",
      "      11382 |   0.051775  |    0.005986     |   2\n",
      "      11383 |   0.167958  |    0.091870     |   0\n",
      "      11384 |   0.201118  |    0.112026     |   1\n",
      "      11385 |   0.225726  |    0.149154     |   1\n",
      "      11386 |   0.221780  |    0.006949     |   0\n",
      "      11387 |   0.273595  |    0.149543     |   1\n",
      "      11388 |   0.248295  |    0.171438     |   1\n",
      "      11389 |   0.202780  |    0.028800     |   0\n",
      "      11390 |   0.208413  |    0.080364     |   0\n",
      "      11391 |   0.206187  |    0.138567     |   1\n",
      "      11392 |   0.024139  |    0.045171     |   2\n",
      "      11393 |   0.050273  |    0.045094     |   2\n",
      "      11394 |   0.215193  |    0.038115     |   0\n",
      "      11395 |   0.179556  |    0.100477     |   0\n",
      "      11396 |   0.217299  |    0.135253     |   1\n",
      "      11397 |   0.039449  |    0.009129     |   2\n",
      "      11398 |   0.000076  |    0.079243     |   2\n",
      "      11399 |   0.170165  |    0.045620     |   0\n",
      "      11400 |   0.000076  |    0.041798     |   2\n",
      "      11401 |   0.185660  |    0.185058     |   1\n",
      "      11402 |   0.167404  |    0.146757     |   1\n",
      "      11403 |   0.000076  |    0.020276     |   2\n",
      "      11404 |   0.000076  |    0.077252     |   2\n",
      "      11405 |   0.168090  |    0.025479     |   0\n",
      "      11406 |   0.212129  |    0.078374     |   0\n",
      "      11407 |   0.242674  |    0.150799     |   1\n",
      "      11408 |   0.208239  |    0.152127     |   1\n",
      "      11409 |   0.000076  |    0.039980     |   2\n",
      "      11410 |   0.000076  |    0.081016     |   2\n",
      "      11411 |   0.236087  |    0.027202     |   0\n",
      "      11412 |   0.171029  |    0.071804     |   0\n",
      "      11413 |   0.058818  |    0.025194     |   2\n",
      "      11414 |   0.062619  |    0.047821     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 11415: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      11415 |   0.207937  |    0.042500     |   0\n",
      "      11416 |   0.061488  |    0.041969     |   2\n",
      "      11417 |   0.043007  |    0.053697     |   2\n",
      "      11418 |   0.046932  |    0.071964     |   2\n",
      "      11419 |   0.208943  |    0.167622     |   1\n",
      "      11420 |   0.191456  |    0.012880     |   0\n",
      "      11421 |   0.158410  |    0.074727     |   0\n",
      "      11422 |   0.193172  |    0.009364     |   0\n",
      "      11423 |   0.183199  |    0.045450     |   0\n",
      "      11424 |   0.207202  |    0.038820     |   0\n",
      "      11425 |   0.224205  |    0.080878     |   0\n",
      "      11426 |   0.169044  |    0.014469     |   0\n",
      "      11427 |   0.227391  |    0.083232     |   0\n",
      "      11428 |   0.281497  |    0.146617     |   1\n",
      "      11429 |   0.055331  |    0.015938     |   2\n",
      "      11430 |   0.247355  |    0.214562     |   1\n",
      "      11431 |   0.031651  |    0.005869     |   2\n",
      "      11432 |   0.050500  |    0.077079     |   2\n",
      "      11433 |   0.175257  |    0.035052     |   0\n",
      "      11434 |   0.224464  |    0.219343     |   1\n",
      "      11435 |   0.062980  |    0.008174     |   2\n",
      "      11436 |   0.217796  |    0.156778     |   1\n",
      "      11437 |   0.065061  |    0.012991     |   2\n",
      "      11438 |   0.052191  |    0.070900     |   2\n",
      "      11439 |   0.027172  |    0.031948     |   2\n",
      "      11440 |   0.138573  |    0.050333     |   0\n",
      "      11441 |   0.000076  |    0.076905     |   2\n",
      "      11442 |   0.191571  |    0.005794     |   0\n",
      "      11443 |   0.245446  |    0.090186     |   0\n",
      "      11444 |   0.207873  |    0.151053     |   1\n",
      "      11445 |   0.191222  |    0.140488     |   1\n",
      "      11446 |   0.228844  |    0.170811     |   1\n",
      "      11447 |   0.194252  |    0.152615     |   1\n",
      "      11448 |   0.215032  |    0.078245     |   0\n",
      "      11449 |   0.007313  |    0.005481     |   2\n",
      "      11450 |   0.208219  |    0.182573     |   1\n",
      "      11451 |   0.088816  |    0.075241     |   2\n",
      "      11452 |   0.196783  |    0.020737     |   0\n",
      "      11453 |   0.044255  |    0.079342     |   2\n",
      "      11454 |   0.067435  |    0.028813     |   2\n",
      "      11455 |   0.191244  |    0.084497     |   0\n",
      "      11456 |   0.050858  |    0.008270     |   2\n",
      "      11457 |   0.021435  |    0.089546     |   2\n",
      "      11458 |   0.211025  |    0.158007     |   1\n",
      "      11459 |   0.181294  |    0.009190     |   0\n",
      "      11460 |   0.045318  |    0.083514     |   2\n",
      "      11461 |   0.037637  |    0.024516     |   2\n",
      "      11462 |   0.000075  |    0.078790     |   2\n",
      "      11463 |   0.198817  |    0.018039     |   0\n",
      "      11464 |   0.000075  |    0.083131     |   2\n",
      "      11465 |   0.150648  |    0.013676     |   0\n",
      "      11466 |   0.238401  |    0.075618     |   0\n",
      "      11467 |   0.000075  |    0.025585     |   2\n",
      "      11468 |   0.275210  |    0.169477     |   1\n",
      "      11469 |   0.165818  |    0.008702     |   0\n",
      "      11470 |   0.204668  |    0.085253     |   0\n",
      "      11471 |   0.000075  |    0.006170     |   2\n",
      "      11472 |   0.000075  |    0.077844     |   2\n",
      "      11473 |   0.000075  |    0.030372     |   2\n",
      "      11474 |   0.059977  |    0.055463     |   2\n",
      "      11475 |   0.180603  |    0.165028     |   1\n",
      "      11476 |   0.197868  |    0.033617     |   0\n",
      "      11477 |   0.187950  |    0.055082     |   0\n",
      "      11478 |   0.202783  |    0.071275     |   0\n",
      "      11479 |   0.215229  |    0.011266     |   0\n",
      "      11480 |   0.155212  |    0.075152     |   0\n",
      "      11481 |   0.062610  |    0.011211     |   2\n",
      "      11482 |   0.214292  |    0.156779     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 11483: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      11483 |   0.223971  |    0.076065     |   0\n",
      "      11484 |   0.188725  |    0.018851     |   0\n",
      "      11485 |   0.060761  |    0.045609     |   2\n",
      "      11486 |   0.279487  |    0.158111     |   1\n",
      "      11487 |   0.164028  |    0.191931     |   1\n",
      "      11488 |   0.042993  |    0.012414     |   2\n",
      "      11489 |   0.177294  |    0.090708     |   0\n",
      "      11490 |   0.046727  |    0.006621     |   2\n",
      "      11491 |   0.294128  |    0.190237     |   1\n",
      "      11492 |   0.054079  |    0.009230     |   2\n",
      "      11493 |   0.238586  |    0.205861     |   1\n",
      "      11494 |   0.257867  |    0.145141     |   1\n",
      "      11495 |   0.030234  |    0.017403     |   2\n",
      "      11496 |   0.181365  |    0.221547     |   1\n",
      "      11497 |   0.214694  |    0.149628     |   1\n",
      "      11498 |   0.237447  |    0.143725     |   1\n",
      "      11499 |   0.050754  |    0.006674     |   2\n",
      "      11500 |   0.193822  |    0.082419     |   0\n",
      "      11501 |   0.055214  |    0.088110     |   2\n",
      "      11502 |   0.041316  |    0.019992     |   2\n",
      "      11503 |   0.225604  |    0.096347     |   0\n",
      "      11504 |   0.166240  |    0.143948     |   1\n",
      "      11505 |   0.211506  |    0.013407     |   0\n",
      "      11506 |   0.211852  |    0.081091     |   0\n",
      "      11507 |   0.046821  |    0.005221     |   2\n",
      "      11508 |   0.051686  |    0.072989     |   2\n",
      "      11509 |   0.157551  |    0.015064     |   0\n",
      "      11510 |   0.029592  |    0.078446     |   2\n",
      "      11511 |   0.246817  |    0.026095     |   0\n",
      "      11512 |   0.169440  |    0.205106     |   1\n",
      "      11513 |   0.262391  |    0.006047     |   0\n",
      "      11514 |   0.259129  |    0.073135     |   0\n",
      "      11515 |   0.244813  |    0.081449     |   0\n",
      "      11516 |   0.050247  |    0.014591     |   2\n",
      "      11517 |   0.192415  |    0.195065     |   1\n",
      "      11518 |   0.206388  |    0.042518     |   0\n",
      "      11519 |   0.178401  |    0.079095     |   0\n",
      "      11520 |   0.252506  |    0.028177     |   0\n",
      "      11521 |   0.155115  |    0.206606     |   1\n",
      "      11522 |   0.233917  |    0.149682     |   1\n",
      "      11523 |   0.056281  |    0.009599     |   2\n",
      "      11524 |   0.063303  |    0.039145     |   2\n",
      "      11525 |   0.155635  |    0.045486     |   0\n",
      "      11526 |   0.178843  |    0.078446     |   0\n",
      "      11527 |   0.223608  |    0.024671     |   0\n",
      "      11528 |   0.057226  |    0.079409     |   2\n",
      "      11529 |   0.232023  |    0.156085     |   1\n",
      "      11530 |   0.030162  |    0.005928     |   2\n",
      "      11531 | \u001b[94m  0.000074\u001b[0m  |    0.082106     |   2\n",
      "      11532 |   0.007409  |    0.028721     |   2\n",
      "      11533 |   0.245961  |    0.073469     |   0\n",
      "      11534 |   0.280906  |    0.133423     |   1\n",
      "      11535 |   0.176063  |    0.039190     |   0\n",
      "      11536 |   0.086579  |    0.043137     |   2\n",
      "      11537 |   0.223948  |    0.061113     |   0\n",
      "      11538 |   0.218695  |    0.197725     |   1\n",
      "      11539 |   0.135625  |    0.152456     |   1\n",
      "      11540 |   0.183678  |    0.047159     |   0\n",
      "      11541 |   0.250663  |    0.211978     |   1\n",
      "      11542 |   0.043589  |    0.003795     |   2\n",
      "      11543 |   0.067612  |    0.034115     |   2\n",
      "      11544 |   0.223989  |    0.073799     |   0\n",
      "      11545 |   0.213277  |    0.039750     |   0\n",
      "      11546 |   0.188214  |    0.051237     |   0\n",
      "      11547 |   0.256008  |    0.157050     |   1\n",
      "      11548 |   0.053061  |    0.078661     |   2\n",
      "      11549 |   0.219180  |    0.152670     |   1\n",
      "      11550 |   0.021912  |    0.026235     |   2\n",
      "      11551 |   0.045684  |    0.044119     |   2\n",
      "      11552 |   0.183140  |    0.078138     |   0\n",
      "      11553 |   0.192616  |    0.025624     |   0\n",
      "      11554 |   0.251895  |    0.079892     |   0\n",
      "      11555 |   0.148997  |    0.151554     |   1\n",
      "      11556 |   0.037210  |    0.077874     |   2\n",
      "      11557 |   0.000075  |    0.027109     |   2\n",
      "      11558 |   0.000075  |    0.081757     |   2\n",
      "      11559 |   0.187784  |    0.141181     |   1\n",
      "      11560 |   0.210334  |    0.021785     |   0\n",
      "      11561 |   0.000075  |    0.080607     |   2\n",
      "      11562 |   0.000075  |    0.007879     |   2\n",
      "      11563 |   0.186169  |    0.199049     |   1\n",
      "      11564 |   0.000074  |    0.007781     |   2\n",
      "      11565 |   0.000075  |    0.082645     |   2\n",
      "      11566 |   0.158224  |    0.023457     |   0\n",
      "      11567 |   0.064833  |    0.075670     |   2\n",
      "      11568 |   0.282483  |    0.152645     |   1\n",
      "      11569 |   0.214518  |    0.046585     |   0\n",
      "      11570 |   0.206549  |    0.206070     |   1\n",
      "      11571 |   0.233860  |    0.014867     |   0\n",
      "      11572 |   0.062922  |    0.045323     |   2\n",
      "      11573 |   0.171340  |    0.072711     |   0\n",
      "      11574 |   0.207096  |    0.149092     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 11575: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      11575 |   0.194986  |    0.038080     |   0\n",
      "      11576 |   0.056724  |    0.049141     |   2\n",
      "      11577 |   0.215357  |    0.207820     |   1\n",
      "      11578 |   0.043024  |    0.006759     |   2\n",
      "      11579 |   0.045596  |    0.072177     |   2\n",
      "      11580 |   0.255679  |    0.155145     |   1\n",
      "      11581 |   0.164411  |    0.043023     |   0\n",
      "      11582 |   0.196363  |    0.149052     |   1\n",
      "      11583 |   0.056884  |    0.012720     |   2\n",
      "      11584 |   0.205776  |    0.076810     |   0\n",
      "      11585 |   0.030323  |    0.014800     |   2\n",
      "      11586 |   0.156183  |    0.085256     |   0\n",
      "      11587 |   0.188725  |    0.204820     |   1\n",
      "      11588 |   0.048199  |    0.003242     |   2\n",
      "      11589 |   0.214130  |    0.162814     |   1\n",
      "      11590 |   0.194111  |    0.022697     |   0\n",
      "      11591 |   0.145086  |    0.200213     |   1\n",
      "      11592 |   0.200963  |    0.149246     |   1\n",
      "      11593 |   0.055825  |    0.012970     |   2\n",
      "      11594 |   0.062007  |    0.083089     |   2\n",
      "      11595 |   0.178260  |    0.137273     |   1\n",
      "      11596 |   0.245106  |    0.142361     |   1\n",
      "      11597 |   0.188351  |    0.039701     |   0\n",
      "      11598 |   0.179558  |    0.069916     |   0\n",
      "      11599 |   0.158348  |    0.029249     |   0\n",
      "      11600 |   0.176094  |    0.075091     |   0\n",
      "      11601 |   0.208071  |    0.027179     |   0\n",
      "      11602 |   0.056688  |    0.050294     |   2\n",
      "      11603 |   0.266042  |    0.161828     |   1\n",
      "      11604 |   0.228841  |    0.169400     |   1\n",
      "      11605 |   0.027636  |    0.003117     |   2\n",
      "      11606 | \u001b[94m  0.000074\u001b[0m  |    0.089012     |   2\n",
      "      11607 |   0.007523  |    0.017763     |   2\n",
      "      11608 |   0.083278  |    0.074694     |   2\n",
      "      11609 |   0.185666  |    0.162338     |   1\n",
      "      11610 |   0.252680  |    0.155610     |   1\n",
      "      11611 |   0.040715  |    0.044519     |   2\n",
      "      11612 |   0.132718  |    0.192748     |   1\n",
      "      11613 |   0.066831  |    0.023323     |   2\n",
      "      11614 |   0.275989  |    0.157404     |   1\n",
      "      11615 |   0.049798  |    0.040771     |   2\n",
      "      11616 |   0.170371  |    0.187323     |   1\n",
      "      11617 |   0.253761  |    0.155839     |   1\n",
      "      11618 |   0.021219  |    0.023332     |   2\n",
      "      11619 |   0.187589  |    0.073577     |   0\n",
      "      11620 |   0.041748  |    0.021448     |   2\n",
      "      11621 |   0.191709  |    0.041325     |   0\n",
      "      11622 |   0.160360  |    0.078761     |   0\n",
      "      11623 |   0.036765  |    0.009767     |   2\n",
      "      11624 |   0.233587  |    0.073607     |   0\n",
      "      11625 | \u001b[94m  0.000074\u001b[0m  |    0.038646     |   2\n",
      "      11626 |   0.198114  |    0.160849     |   1\n",
      "      11627 |   0.306414  |    0.150233     |   1\n",
      "      11628 |   0.184749  |    0.051481     |   0\n",
      "      11629 |   0.242861  |    0.153888     |   1\n",
      "      11630 |   0.188115  |    0.140934     |   1\n",
      "      11631 |   0.207883  |    0.154723     |   1\n",
      "      11632 |   0.204283  |    0.149404     |   1\n",
      "      11633 | \u001b[94m  0.000074\u001b[0m  |    0.026332     |   2\n",
      "      11634 |   0.000074  |    0.057380     |   2\n",
      "      11635 |   0.238828  |    0.135435     |   1\n",
      "      11636 |   0.000074  |    0.076277     |   2\n",
      "      11637 | \u001b[94m  0.000074\u001b[0m  |    0.024973     |   2\n",
      "      11638 |   0.227018  |    0.197276     |   1\n",
      "      11639 |   0.240302  |    0.028584     |   0\n",
      "      11640 | \u001b[94m  0.000073\u001b[0m  |    0.080223     |   2\n",
      "      11641 |   0.181912  |    0.164477     |   1\n",
      "      11642 |   0.241913  |    0.196411     |   1\n",
      "      11643 |   0.174838  |    0.150712     |   1\n",
      "      11644 |   0.059825  |    0.005978     |   2\n",
      "      11645 |   0.176314  |    0.187910     |   1\n",
      "      11646 |   0.062552  |    0.041279     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 11647: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      11647 |   0.265826  |    0.154772     |   1\n",
      "      11648 |   0.058377  |    0.006075     |   2\n",
      "      11649 |   0.046733  |    0.081273     |   2\n",
      "      11650 |   0.218449  |    0.188217     |   1\n",
      "      11651 |   0.193721  |    0.005233     |   0\n",
      "      11652 |   0.230189  |    0.074883     |   0\n",
      "      11653 |   0.181826  |    0.040326     |   0\n",
      "      11654 |   0.192911  |    0.046748     |   0\n",
      "      11655 |   0.045333  |    0.074061     |   2\n",
      "      11656 |   0.188631  |    0.028760     |   0\n",
      "      11657 |   0.207316  |    0.214000     |   1\n",
      "      11658 |   0.189988  |    0.013082     |   0\n",
      "      11659 |   0.182144  |    0.226924     |   1\n",
      "      11660 |   0.145098  |    0.137676     |   1\n",
      "      11661 |   0.185721  |    0.033405     |   0\n",
      "      11662 |   0.278310  |    0.190169     |   1\n",
      "      11663 |   0.055428  |    0.005209     |   2\n",
      "      11664 |   0.030905  |    0.077983     |   2\n",
      "      11665 |   0.188099  |    0.028810     |   0\n",
      "      11666 |   0.153246  |    0.053044     |   0\n",
      "      11667 |   0.171738  |    0.046684     |   0\n",
      "      11668 |   0.205994  |    0.150318     |   1\n",
      "      11669 |   0.045848  |    0.043111     |   2\n",
      "      11670 |   0.056375  |    0.048752     |   2\n",
      "      11671 |   0.059546  |    0.045469     |   2\n",
      "      11672 |   0.246708  |    0.108164     |   1\n",
      "      11673 |   0.052591  |    0.049507     |   2\n",
      "      11674 |   0.181967  |    0.177788     |   1\n",
      "      11675 |   0.236646  |    0.127433     |   1\n",
      "      11676 |   0.186513  |    0.010711     |   0\n",
      "      11677 |   0.025606  |    0.055387     |   2\n",
      "      11678 |   0.184046  |    0.077587     |   0\n",
      "      11679 |   0.195137  |    0.013467     |   0\n",
      "      11680 |   0.207883  |    0.077471     |   0\n",
      "      11681 |   0.193897  |    0.022514     |   0\n",
      "      11682 |   0.212467  |    0.077949     |   0\n",
      "      11683 |   0.240905  |    0.023279     |   0\n",
      "      11684 |   0.205125  |    0.191850     |   1\n",
      "      11685 |   0.192929  |    0.019691     |   0\n",
      "      11686 |   0.218793  |    0.042888     |   0\n",
      "      11687 | \u001b[94m  0.000073\u001b[0m  |    0.048967     |   2\n",
      "      11688 |   0.158609  |    0.045473     |   0\n",
      "      11689 |   0.202674  |    0.201681     |   1\n",
      "      11690 |   0.007364  |    0.006576     |   2\n",
      "      11691 |   0.211841  |    0.192212     |   1\n",
      "      11692 |   0.086802  |    0.043990     |   2\n",
      "      11693 |   0.042126  |    0.039798     |   2\n",
      "      11694 |   0.068231  |    0.084703     |   2\n",
      "      11695 |   0.171412  |    0.149479     |   1\n",
      "      11696 |   0.190068  |    0.014540     |   0\n",
      "      11697 |   0.183998  |    0.051734     |   0\n",
      "      11698 |   0.197901  |    0.187658     |   1\n",
      "      11699 |   0.186042  |    0.025075     |   0\n",
      "      11700 |   0.220150  |    0.184656     |   1\n",
      "      11701 |   0.153475  |    0.168648     |   1\n",
      "      11702 |   0.185858  |    0.162577     |   1\n",
      "      11703 |   0.217581  |    0.011496     |   0\n",
      "      11704 |   0.051521  |    0.037440     |   2\n",
      "      11705 |   0.216862  |    0.214955     |   1\n",
      "      11706 |   0.263572  |    0.145101     |   1\n",
      "      11707 |   0.220410  |    0.028749     |   0\n",
      "      11708 |   0.285904  |    0.195182     |   1\n",
      "      11709 |   0.162431  |    0.150382     |   1\n",
      "      11710 |   0.199768  |    0.032952     |   0\n",
      "      11711 |   0.218788  |    0.207793     |   1\n",
      "      11712 |   0.143722  |    0.014050     |   0\n",
      "      11713 |   0.020946  |    0.021927     |   2\n",
      "      11714 |   0.044388  |    0.076404     |   2\n",
      "      11715 |   0.037420  |    0.020296     |   2\n",
      "      11716 | \u001b[94m  0.000072\u001b[0m  |    0.082581     |   2\n",
      "      11717 |   0.000072  |    0.017340     |   2\n",
      "      11718 |   0.000072  |    0.051478     |   2\n",
      "      11719 |   0.000073  |    0.051658     |   2\n",
      "      11720 |   0.166183  |    0.238962     |   1\n",
      "      11721 |   0.000072  |    0.003820     |   2\n",
      "      11722 |   0.233642  |    0.140567     |   1\n",
      "      11723 |   0.255329  |    0.152044     |   1\n",
      "      11724 |   0.214440  |    0.023861     |   0\n",
      "      11725 | \u001b[94m  0.000072\u001b[0m  |    0.080170     |   2\n",
      "      11726 |   0.055563  |    0.014945     |   2\n",
      "      11727 |   0.195005  |    0.213812     |   1\n",
      "      11728 |   0.062487  |    0.012277     |   2\n",
      "      11729 |   0.169805  |    0.225744     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 11731: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      11730 |   0.233500  |    0.005116     |   0\n",
      "      11731 |   0.215888  |    0.192585     |   1\n",
      "      11732 |   0.193644  |    0.141929     |   1\n",
      "      11733 |   0.056751  |    0.007445     |   2\n",
      "      11734 |   0.289115  |    0.080481     |   0\n",
      "      11735 |   0.043013  |    0.028056     |   2\n",
      "      11736 |   0.198525  |    0.199849     |   1\n",
      "      11737 |   0.212774  |    0.146369     |   1\n",
      "      11738 |   0.201488  |    0.029962     |   0\n",
      "      11739 |   0.176374  |    0.164697     |   1\n",
      "      11740 |   0.044603  |    0.046903     |   2\n",
      "      11741 |   0.290998  |    0.201314     |   1\n",
      "      11742 |   0.276005  |    0.149840     |   1\n",
      "      11743 |   0.244794  |    0.141067     |   1\n",
      "      11744 |   0.055058  |    0.013034     |   2\n",
      "      11745 |   0.171570  |    0.182297     |   1\n",
      "      11746 |   0.184333  |    0.139757     |   1\n",
      "      11747 |   0.029327  |    0.041603     |   2\n",
      "      11748 |   0.245906  |    0.217412     |   1\n",
      "      11749 |   0.215331  |    0.088898     |   1\n",
      "      11750 |   0.046087  |    0.081458     |   2\n",
      "      11751 |   0.207102  |    0.118398     |   1\n",
      "      11752 |   0.171728  |    0.187342     |   1\n",
      "      11753 |   0.221847  |    0.138532     |   1\n",
      "      11754 |   0.216155  |    0.072197     |   0\n",
      "      11755 |   0.222521  |    0.010697     |   0\n",
      "      11756 |   0.233821  |    0.157259     |   1\n",
      "      11757 |   0.189726  |    0.192811     |   1\n",
      "      11758 |   0.277493  |    0.022560     |   0\n",
      "      11759 |   0.198205  |    0.181458     |   1\n",
      "      11760 |   0.052048  |    0.024002     |   2\n",
      "      11761 |   0.060942  |    0.076731     |   2\n",
      "      11762 |   0.238768  |    0.026332     |   0\n",
      "      11763 |   0.056024  |    0.058460     |   2\n",
      "      11764 |   0.201132  |    0.144982     |   1\n",
      "      11765 |   0.213536  |    0.198952     |   1\n",
      "      11766 |   0.252545  |    0.005801     |   0\n",
      "      11767 |   0.027409  |    0.078579     |   2\n",
      "      11768 | \u001b[94m  0.000070\u001b[0m  |    0.045431     |   2\n",
      "      11769 |   0.208342  |    0.040709     |   0\n",
      "      11770 |   0.184682  |    0.045653     |   0\n",
      "      11771 |   0.159782  |    0.043979     |   0\n",
      "      11772 |   0.226930  |    0.061149     |   0\n",
      "      11773 |   0.181979  |    0.186690     |   1\n",
      "      11774 |   0.007148  |    0.004960     |   2\n",
      "      11775 |   0.084257  |    0.084013     |   2\n",
      "      11776 |   0.039826  |    0.028771     |   2\n",
      "      11777 |   0.184573  |    0.081909     |   0\n",
      "      11778 |   0.066552  |    0.024698     |   2\n",
      "      11779 |   0.217889  |    0.215189     |   1\n",
      "      11780 |   0.173482  |    0.119818     |   1\n",
      "      11781 |   0.236320  |    0.182300     |   1\n",
      "      11782 |   0.052609  |    0.024294     |   2\n",
      "      11783 |   0.227271  |    0.156958     |   1\n",
      "      11784 |   0.021872  |    0.038920     |   2\n",
      "      11785 |   0.216255  |    0.194052     |   1\n",
      "      11786 |   0.204786  |    0.029118     |   0\n",
      "      11787 |   0.044871  |    0.040797     |   2\n",
      "      11788 |   0.034814  |    0.071954     |   2\n",
      "      11789 | \u001b[94m  0.000070\u001b[0m  |    0.009893     |   2\n",
      "      11790 |   0.219600  |    0.077225     |   0\n",
      "      11791 |   0.000070  |    0.040390     |   2\n",
      "      11792 |   0.000070  |    0.033747     |   2\n",
      "      11793 |   0.229483  |    0.201331     |   1\n",
      "      11794 |   0.200957  |    0.140459     |   1\n",
      "      11795 |   0.234918  |    0.145605     |   1\n",
      "      11796 |   0.207330  |    0.046771     |   0\n",
      "      11797 |   0.000070  |    0.050999     |   2\n",
      "      11798 |   0.207047  |    0.197176     |   1\n",
      "      11799 |   0.000070  |    0.014115     |   2\n",
      "      11800 |   0.195498  |    0.194058     |   1\n",
      "      11801 |   0.000070  |    0.076253     |   2\n",
      "      11802 |   0.206608  |    0.022656     |   0\n",
      "      11803 |   0.178869  |    0.077522     |   0\n",
      "      11804 |   0.221124  |    0.148344     |   1\n",
      "      11805 |   0.153622  |    0.020922     |   0\n",
      "      11806 |   0.205140  |    0.041646     |   0\n",
      "      11807 |   0.213382  |    0.040676     |   0\n",
      "      11808 |   0.248701  |    0.080471     |   0\n",
      "      11809 |   0.055502  |    0.031376     |   2\n",
      "      11810 |   0.185315  |    0.205120     |   1\n",
      "      11811 |   0.218867  |    0.144875     |   1\n",
      "      11812 |   0.194573  |    0.020736     |   0\n",
      "      11813 |   0.200195  |    0.051333     |   0\n",
      "      11814 |   0.062454  |    0.083727     |   2\n",
      "      11815 |   0.143602  |    0.144245     |   1\n",
      "      11816 |   0.180418  |    0.153876     |   1\n",
      "      11817 |   0.166166  |    0.140749     |   1\n",
      "      11818 |   0.174850  |    0.018238     |   0\n",
      "      11819 |   0.294548  |    0.197684     |   1\n",
      "      11820 |   0.183030  |    0.006619     |   0\n",
      "      11821 |   0.214529  |    0.052282     |   0\n",
      "      11822 |   0.175025  |    0.151912     |   1\n",
      "      11823 |   0.240249  |    0.144183     |   1\n",
      "      11824 |   0.218245  |    0.167851     |   1\n",
      "      11825 |   0.226956  |    0.020425     |   0\n",
      "      11826 |   0.248780  |    0.198092     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 11827: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      11827 |   0.059550  |    0.007023     |   2\n",
      "      11828 |   0.042954  |    0.075517     |   2\n",
      "      11829 |   0.158529  |    0.008226     |   0\n",
      "      11830 |   0.044687  |    0.072620     |   2\n",
      "      11831 |   0.058460  |    0.044116     |   2\n",
      "      11832 |   0.181687  |    0.047137     |   0\n",
      "      11833 |   0.030783  |    0.045991     |   2\n",
      "      11834 |   0.257198  |    0.042741     |   0\n",
      "      11835 |   0.219483  |    0.083181     |   0\n",
      "      11836 |   0.175875  |    0.153531     |   1\n",
      "      11837 |   0.045998  |    0.031916     |   2\n",
      "      11838 |   0.222808  |    0.092445     |   0\n",
      "      11839 |   0.244567  |    0.164980     |   1\n",
      "      11840 |   0.262424  |    0.147241     |   1\n",
      "      11841 |   0.152787  |    0.004720     |   0\n",
      "      11842 |   0.193186  |    0.046379     |   0\n",
      "      11843 |   0.204749  |    0.050802     |   0\n",
      "      11844 |   0.234830  |    0.073223     |   0\n",
      "      11845 |   0.239855  |    0.135247     |   1\n",
      "      11846 |   0.057836  |    0.077949     |   2\n",
      "      11847 |   0.060408  |    0.015464     |   2\n",
      "      11848 |   0.224378  |    0.072711     |   0\n",
      "      11849 |   0.151498  |    0.023133     |   0\n",
      "      11850 |   0.228591  |    0.221758     |   1\n",
      "      11851 |   0.053602  |    0.003160     |   2\n",
      "      11852 |   0.181693  |    0.156486     |   1\n",
      "      11853 |   0.182652  |    0.020474     |   0\n",
      "      11854 |   0.025693  |    0.078646     |   2\n",
      "      11855 |   0.205718  |    0.015565     |   0\n",
      "      11856 | \u001b[94m  0.000069\u001b[0m  |    0.084643     |   2\n",
      "      11857 |   0.007401  |    0.027515     |   2\n",
      "      11858 |   0.198164  |    0.208269     |   1\n",
      "      11859 |   0.083669  |    0.003029     |   2\n",
      "      11860 |   0.040545  |    0.015775     |   2\n",
      "      11861 |   0.069599  |    0.051537     |   2\n",
      "      11862 |   0.205196  |    0.078557     |   0\n",
      "      11863 |   0.145797  |    0.023299     |   0\n",
      "      11864 |   0.051873  |    0.073533     |   2\n",
      "      11865 |   0.022062  |    0.036868     |   2\n",
      "      11866 |   0.250726  |    0.166241     |   1\n",
      "      11867 |   0.044498  |    0.044542     |   2\n",
      "      11868 |   0.037161  |    0.064293     |   2\n",
      "      11869 |   0.198894  |    0.175920     |   1\n",
      "      11870 |   0.188111  |    0.150237     |   1\n",
      "      11871 |   0.000069  |    0.050516     |   2\n",
      "      11872 |   0.280138  |    0.162100     |   1\n",
      "      11873 |   0.185499  |    0.164543     |   1\n",
      "      11874 |   0.216868  |    0.153522     |   1\n",
      "      11875 |   0.158346  |    0.104317     |   1\n",
      "      11876 |   0.205582  |    0.183729     |   1\n",
      "      11877 |   0.172235  |    0.160049     |   1\n",
      "      11878 |   0.243673  |    0.198123     |   1\n",
      "      11879 |   0.197294  |    0.140735     |   1\n",
      "      11880 |   0.166215  |    0.065207     |   0\n",
      "      11881 |   0.229398  |    0.189754     |   1\n",
      "      11882 |   0.274493  |    0.025916     |   0\n",
      "      11883 |   0.210398  |    0.197606     |   1\n",
      "      11884 |   0.193749  |    0.196266     |   1\n",
      "      11885 |   0.230072  |    0.137425     |   1\n",
      "      11886 |   0.139149  |    0.195619     |   1\n",
      "      11887 |   0.241308  |    0.019170     |   0\n",
      "      11888 |   0.000070  |    0.049167     |   2\n",
      "      11889 |   0.191081  |    0.208055     |   1\n",
      "      11890 |   0.000070  |    0.009957     |   2\n",
      "      11891 |   0.000070  |    0.065963     |   2\n",
      "      11892 |   0.181319  |    0.162138     |   1\n",
      "      11893 |   0.223862  |    0.024675     |   0\n",
      "      11894 |   0.224401  |    0.208184     |   1\n",
      "      11895 | \u001b[94m  0.000069\u001b[0m  |    0.025525     |   2\n",
      "      11896 |   0.232250  |    0.199354     |   1\n",
      "      11897 | \u001b[94m  0.000069\u001b[0m  |    0.016147     |   2\n",
      "      11898 |   0.050817  |    0.081169     |   2\n",
      "      11899 |   0.183260  |    0.149836     |   1\n",
      "      11900 |   0.060657  |    0.046548     |   2\n",
      "      11901 |   0.329329  |    0.205718     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 11902: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      11902 |   0.169410  |    0.009331     |   0\n",
      "      11903 |   0.226625  |    0.105978     |   1\n",
      "      11904 |   0.150922  |    0.156189     |   1\n",
      "      11905 |   0.199069  |    0.014528     |   0\n",
      "      11906 |   0.055983  |    0.073051     |   2\n",
      "      11907 |   0.044253  |    0.023887     |   2\n",
      "      11908 |   0.044249  |    0.052675     |   2\n",
      "      11909 |   0.186446  |    0.074853     |   0\n",
      "      11910 |   0.053623  |    0.022803     |   2\n",
      "      11911 |   0.269677  |    0.049235     |   0\n",
      "      11912 |   0.236024  |    0.054262     |   0\n",
      "      11913 |   0.029394  |    0.041512     |   2\n",
      "      11914 |   0.195994  |    0.169511     |   1\n",
      "      11915 |   0.218292  |    0.157487     |   1\n",
      "      11916 |   0.049662  |    0.010809     |   2\n",
      "      11917 |   0.254290  |    0.078507     |   0\n",
      "      11918 |   0.054074  |    0.015860     |   2\n",
      "      11919 |   0.064115  |    0.053836     |   2\n",
      "      11920 |   0.056318  |    0.050669     |   2\n",
      "      11921 |   0.189342  |    0.202154     |   1\n",
      "      11922 |   0.026421  |    0.006747     |   2\n",
      "      11923 |   0.189939  |    0.089215     |   0\n",
      "      11924 | \u001b[94m  0.000067\u001b[0m  |    0.035248     |   2\n",
      "      11925 |   0.280723  |    0.196451     |   1\n",
      "      11926 |   0.007192  |    0.006038     |   2\n",
      "      11927 |   0.084935  |    0.051422     |   2\n",
      "      11928 |   0.193776  |    0.143961     |   1\n",
      "      11929 |   0.043247  |    0.051995     |   2\n",
      "      11930 |   0.170748  |    0.168560     |   1\n",
      "      11931 |   0.268767  |    0.154866     |   1\n",
      "      11932 |   0.064625  |    0.038684     |   2\n",
      "      11933 |   0.158250  |    0.055653     |   0\n",
      "      11934 |   0.208967  |    0.154378     |   1\n",
      "      11935 |   0.187959  |    0.144829     |   1\n",
      "      11936 |   0.259740  |    0.044981     |   0\n",
      "      11937 |   0.180587  |    0.042887     |   0\n",
      "      11938 |   0.047707  |    0.026677     |   2\n",
      "      11939 |   0.022216  |    0.046774     |   2\n",
      "      11940 |   0.212870  |    0.206734     |   1\n",
      "      11941 |   0.211392  |    0.141568     |   1\n",
      "      11942 |   0.183487  |    0.147781     |   1\n",
      "      11943 |   0.043423  |    0.009179     |   2\n",
      "      11944 |   0.315755  |    0.190528     |   1\n",
      "      11945 |   0.176725  |    0.005288     |   0\n",
      "      11946 |   0.035219  |    0.076208     |   2\n",
      "      11947 |   0.190745  |    0.167479     |   1\n",
      "      11948 |   0.205790  |    0.146018     |   1\n",
      "      11949 |   0.282114  |    0.134175     |   1\n",
      "      11950 |   0.205457  |    0.039495     |   0\n",
      "      11951 |   0.259836  |    0.075597     |   0\n",
      "      11952 |   0.154482  |    0.016620     |   0\n",
      "      11953 |   0.168507  |    0.079350     |   0\n",
      "      11954 | \u001b[94m  0.000067\u001b[0m  |    0.020196     |   2\n",
      "      11955 |   0.210684  |    0.039051     |   0\n",
      "      11956 |   0.163238  |    0.188798     |   1\n",
      "      11957 |   0.208093  |    0.134033     |   1\n",
      "      11958 |   0.233445  |    0.052128     |   0\n",
      "      11959 |   0.188706  |    0.165316     |   1\n",
      "      11960 | \u001b[94m  0.000067\u001b[0m  |    0.044339     |   2\n",
      "      11961 |   0.125932  |    0.149134     |   1\n",
      "      11962 |   0.206526  |    0.078637     |   0\n",
      "      11963 |   0.173493  |    0.012153     |   0\n",
      "      11964 | \u001b[94m  0.000066\u001b[0m  |    0.057544     |   2\n",
      "      11965 |   0.000067  |    0.057149     |   2\n",
      "      11966 | \u001b[94m  0.000066\u001b[0m  |    0.043755     |   2\n",
      "      11967 |   0.279431  |    0.149052     |   1\n",
      "      11968 |   0.205623  |    0.042564     |   0\n",
      "      11969 |   0.209138  |    0.043474     |   0\n",
      "      11970 |   0.177923  |    0.070481     |   0\n",
      "      11971 |   0.219675  |    0.007899     |   0\n",
      "      11972 | \u001b[94m  0.000066\u001b[0m  |    0.072054     |   2\n",
      "      11973 |   0.059893  |    0.015158     |   2\n",
      "      11974 |   0.061076  |    0.066833     |   2\n",
      "      11975 |   0.226623  |    0.165556     |   1\n",
      "      11976 |   0.236582  |    0.042605     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 11977: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      11977 |   0.062396  |    0.025767     |   2\n",
      "      11978 |   0.147094  |    0.216714     |   1\n",
      "      11979 |   0.223325  |    0.168514     |   1\n",
      "      11980 |   0.186360  |    0.170746     |   1\n",
      "      11981 |   0.250879  |    0.150313     |   1\n",
      "      11982 |   0.287568  |    0.148596     |   1\n",
      "      11983 |   0.291538  |    0.149224     |   1\n",
      "      11984 |   0.043633  |    0.040655     |   2\n",
      "      11985 |   0.045748  |    0.049409     |   2\n",
      "      11986 |   0.200986  |    0.134974     |   1\n",
      "      11987 |   0.214249  |    0.042738     |   0\n",
      "      11988 |   0.169405  |    0.073714     |   0\n",
      "      11989 |   0.056162  |    0.024383     |   2\n",
      "      11990 |   0.210757  |    0.211410     |   1\n",
      "      11991 |   0.192467  |    0.099587     |   1\n",
      "      11992 |   0.205258  |    0.164367     |   1\n",
      "      11993 |   0.029351  |    0.041770     |   2\n",
      "      11994 |   0.146406  |    0.198217     |   1\n",
      "      11995 |   0.223616  |    0.025942     |   0\n",
      "      11996 |   0.173843  |    0.193975     |   1\n",
      "      11997 |   0.048084  |    0.043011     |   2\n",
      "      11998 |   0.052500  |    0.072273     |   2\n",
      "      11999 |   0.234878  |    0.042968     |   0\n",
      "      12000 |   0.146903  |    0.047365     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 12000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 12000: Plotting estimates.\n",
      "Exception in thread neuralnilm-data-process:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 810, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/jack/workspace/python/neuralnilm/neuralnilm/data/datathread.py\", line 16, in run\n",
      "    batch = self.data_pipeline.get_batch(**self._get_batch_kwargs)\n",
      "  File \"/home/jack/workspace/python/neuralnilm/neuralnilm/data/datapipeline.py\", line 46, in get_batch\n",
      "    batch = self._source_iterators[source_id].next()\n",
      "ValueError: generator already executing\n",
      "\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      12001 |   0.129317  |    0.200947     |   1\n",
      "      12002 |   0.217588  |    0.149733     |   1\n",
      "      12003 |   0.195394  |    0.191610     |   1\n",
      "      12004 |   0.258939  |    0.014778     |   0\n",
      "      12005 |   0.177788  |    0.186339     |   1\n",
      "      12006 |   0.054189  |    0.008042     |   2\n",
      "      12007 |   0.208879  |    0.083352     |   0\n",
      "      12008 |   0.039492  |    0.041513     |   2\n",
      "      12009 |   0.044573  |    0.042372     |   2\n",
      "      12010 |   0.210069  |    0.051693     |   0\n",
      "      12011 |   0.218789  |    0.149350     |   1\n",
      "      12012 |   0.252071  |    0.132262     |   1\n",
      "      12013 |   0.053575  |    0.044336     |   2\n",
      "      12014 |   0.185427  |    0.051587     |   0\n",
      "      12015 |   0.268874  |    0.143448     |   1\n",
      "      12016 |   0.028929  |    0.031453     |   2\n",
      "      12017 |   0.049292  |    0.041299     |   2\n",
      "      12018 |   0.174370  |    0.081164     |   0\n",
      "      12019 |   0.180664  |    0.160210     |   1\n",
      "      12020 |   0.246185  |    0.146874     |   1\n",
      "      12021 |   0.235030  |    0.043196     |   0\n",
      "      12022 |   0.153305  |    0.151026     |   1\n",
      "      12023 |   0.194763  |    0.085768     |   0\n",
      "      12024 |   0.173667  |    0.135264     |   1\n",
      "      12025 |   0.197889  |    0.043428     |   0\n",
      "      12026 |   0.053969  |    0.075441     |   2\n",
      "      12027 |   0.212044  |    0.027008     |   0\n",
      "      12028 |   0.063058  |    0.079043     |   2\n",
      "      12029 |   0.228123  |    0.143210     |   1\n",
      "      12030 |   0.053114  |    0.039733     |   2\n",
      "      12031 |   0.026384  |    0.040137     |   2\n",
      "      12032 |   0.145212  |    0.049792     |   0\n",
      "      12033 |   0.187208  |    0.038276     |   0\n",
      "      12034 | \u001b[94m  0.000065\u001b[0m  |    0.054214     |   2\n",
      "      12035 |   0.006921  |    0.055985     |   2\n",
      "      12036 |   0.083669  |    0.038319     |   2\n",
      "      12037 |   0.167307  |    0.076431     |   0\n",
      "      12038 |   0.040949  |    0.013716     |   2\n",
      "      12039 |   0.064017  |    0.057370     |   2\n",
      "      12040 |   0.222010  |    0.152257     |   1\n",
      "      12041 |   0.184871  |    0.143108     |   1\n",
      "      12042 |   0.049834  |    0.072072     |   2\n",
      "      12043 |   0.020953  |    0.016327     |   2\n",
      "      12044 |   0.045471  |    0.076936     |   2\n",
      "      12045 |   0.036078  |    0.023118     |   2\n",
      "      12046 |   0.207207  |    0.042813     |   0\n",
      "      12047 | \u001b[94m  0.000065\u001b[0m  |    0.035697     |   2\n",
      "      12048 |   0.262843  |    0.202075     |   1\n",
      "      12049 |   0.000065  |    0.053795     |   2\n",
      "      12050 |   0.000066  |    0.027512     |   2\n",
      "      12051 |   0.000066  |    0.055219     |   2\n",
      "      12052 |   0.157281  |    0.192135     |   1\n",
      "      12053 |   0.171793  |    0.010957     |   0\n",
      "      12054 | \u001b[94m  0.000065\u001b[0m  |    0.075444     |   2\n",
      "      12055 |   0.169526  |    0.029261     |   0\n",
      "      12056 |   0.231391  |    0.083282     |   0\n",
      "      12057 |   0.239050  |    0.142630     |   1\n",
      "      12058 |   0.222697  |    0.048541     |   0\n",
      "      12059 |   0.189794  |    0.148891     |   1\n",
      "      12060 | \u001b[94m  0.000065\u001b[0m  |    0.050132     |   2\n",
      "      12061 |   0.217705  |    0.061468     |   0\n",
      "      12062 |   0.262921  |    0.142622     |   1\n",
      "      12063 |   0.273983  |    0.137336     |   1\n",
      "      12064 |   0.054919  |    0.006858     |   2\n",
      "      12065 |   0.061152  |    0.076126     |   2\n",
      "      12066 |   0.226831  |    0.019090     |   0\n",
      "      12067 |   0.166228  |    0.194278     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 12068: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      12068 |   0.054728  |    0.010181     |   2\n",
      "      12069 |   0.043005  |    0.079940     |   2\n",
      "      12070 |   0.044039  |    0.027673     |   2\n",
      "      12071 |   0.054534  |    0.085989     |   2\n",
      "      12072 |   0.258885  |    0.146836     |   1\n",
      "      12073 |   0.218518  |    0.013205     |   0\n",
      "      12074 |   0.173857  |    0.046512     |   0\n",
      "      12075 |   0.187752  |    0.207578     |   1\n",
      "      12076 |   0.115715  |    0.101498     |   1\n",
      "      12077 |   0.030209  |    0.038445     |   2\n",
      "      12078 |   0.205232  |    0.187766     |   1\n",
      "      12079 |   0.046253  |    0.013600     |   2\n",
      "      12080 |   0.052316  |    0.076993     |   2\n",
      "      12081 |   0.186510  |    0.011032     |   0\n",
      "      12082 |   0.232584  |    0.077512     |   0\n",
      "      12083 |   0.062007  |    0.021634     |   2\n",
      "      12084 |   0.219582  |    0.211520     |   1\n",
      "      12085 |   0.224024  |    0.152051     |   1\n",
      "      12086 |   0.052084  |    0.005055     |   2\n",
      "      12087 |   0.024818  |    0.038881     |   2\n",
      "      12088 |   0.208943  |    0.172069     |   1\n",
      "      12089 |   0.194280  |    0.012306     |   0\n",
      "      12090 | \u001b[94m  0.000064\u001b[0m  |    0.086212     |   2\n",
      "      12091 |   0.007763  |    0.010962     |   2\n",
      "      12092 |   0.180872  |    0.076570     |   0\n",
      "      12093 |   0.080770  |    0.026624     |   2\n",
      "      12094 |   0.172200  |    0.154940     |   1\n",
      "      12095 |   0.172382  |    0.166684     |   1\n",
      "      12096 |   0.259589  |    0.088611     |   1\n",
      "      12097 |   0.171006  |    0.043052     |   0\n",
      "      12098 |   0.040255  |    0.042332     |   2\n",
      "      12099 |   0.067516  |    0.061614     |   2\n",
      "      12100 |   0.251640  |    0.143609     |   1\n",
      "      12101 |   0.189403  |    0.018586     |   0\n",
      "      12102 |   0.169389  |    0.193058     |   1\n",
      "      12103 |   0.147048  |    0.014100     |   0\n",
      "      12104 |   0.230518  |    0.048856     |   0\n",
      "      12105 |   0.204753  |    0.206545     |   1\n",
      "      12106 |   0.167529  |    0.012865     |   0\n",
      "      12107 |   0.191491  |    0.207896     |   1\n",
      "      12108 |   0.204895  |    0.146363     |   1\n",
      "      12109 |   0.180545  |    0.003596     |   0\n",
      "      12110 |   0.051006  |    0.036967     |   2\n",
      "      12111 |   0.021895  |    0.042623     |   2\n",
      "      12112 |   0.187883  |    0.043122     |   0\n",
      "      12113 |   0.183812  |    0.180140     |   1\n",
      "      12114 |   0.182593  |    0.208460     |   1\n",
      "      12115 |   0.045219  |    0.011080     |   2\n",
      "      12116 |   0.035144  |    0.052209     |   2\n",
      "      12117 |   0.201650  |    0.163601     |   1\n",
      "      12118 | \u001b[94m  0.000064\u001b[0m  |    0.041958     |   2\n",
      "      12119 |   0.197707  |    0.090113     |   0\n",
      "      12120 |   0.228455  |    0.137561     |   1\n",
      "      12121 |   0.210050  |    0.026913     |   0\n",
      "      12122 |   0.000064  |    0.057754     |   2\n",
      "      12123 |   0.218477  |    0.078903     |   0\n",
      "      12124 |   0.282151  |    0.171616     |   1\n",
      "      12125 |   0.202933  |    0.049393     |   0\n",
      "      12126 |   0.158111  |    0.190919     |   1\n",
      "      12127 |   0.000064  |    0.005629     |   2\n",
      "      12128 |   0.199157  |    0.041434     |   0\n",
      "      12129 |   0.196705  |    0.153815     |   1\n",
      "      12130 |   0.279904  |    0.135787     |   1\n",
      "      12131 |   0.000064  |    0.016352     |   2\n",
      "      12132 |   0.225406  |    0.080460     |   0\n",
      "      12133 |   0.155712  |    0.029345     |   0\n",
      "      12134 |   0.218562  |    0.194338     |   1\n",
      "      12135 |   0.223610  |    0.129330     |   1\n",
      "      12136 |   0.197115  |    0.038735     |   0\n",
      "      12137 |   0.189647  |    0.051195     |   0\n",
      "      12138 |   0.213797  |    0.141019     |   1\n",
      "      12139 |   0.163309  |    0.043115     |   0\n",
      "      12140 | \u001b[94m  0.000064\u001b[0m  |    0.077885     |   2\n",
      "      12141 |   0.000064  |    0.025818     |   2\n",
      "      12142 |   0.159121  |    0.041658     |   0\n",
      "      12143 |   0.056858  |    0.074586     |   2\n",
      "      12144 |   0.060850  |    0.035752     |   2\n",
      "      12145 |   0.160110  |    0.214893     |   1\n",
      "      12146 |   0.230068  |    0.138375     |   1\n",
      "      12147 |   0.230668  |    0.040846     |   0\n",
      "      12148 |   0.182089  |    0.031574     |   0\n",
      "      12149 |   0.187649  |    0.048375     |   0\n",
      "      12150 |   0.156163  |    0.049258     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 12151: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      12151 |   0.174847  |    0.018118     |   0\n",
      "      12152 |   0.162583  |    0.068528     |   0\n",
      "      12153 |   0.202133  |    0.025342     |   0\n",
      "      12154 |   0.198646  |    0.042230     |   0\n",
      "      12155 |   0.199068  |    0.045145     |   0\n",
      "      12156 |   0.279927  |    0.151320     |   1\n",
      "      12157 |   0.058382  |    0.074562     |   2\n",
      "      12158 |   0.042988  |    0.018593     |   2\n",
      "      12159 |   0.223665  |    0.207865     |   1\n",
      "      12160 |   0.218229  |    0.012190     |   0\n",
      "      12161 |   0.044848  |    0.079465     |   2\n",
      "      12162 |   0.058241  |    0.023873     |   2\n",
      "      12163 |   0.030385  |    0.083268     |   2\n",
      "      12164 |   0.194999  |    0.129188     |   1\n",
      "      12165 |   0.170468  |    0.161909     |   1\n",
      "      12166 |   0.192607  |    0.154417     |   1\n",
      "      12167 |   0.047954  |    0.044569     |   2\n",
      "      12168 |   0.184945  |    0.044376     |   0\n",
      "      12169 |   0.055227  |    0.070937     |   2\n",
      "      12170 |   0.188899  |    0.008551     |   0\n",
      "      12171 |   0.198494  |    0.089121     |   0\n",
      "      12172 |   0.159228  |    0.144003     |   1\n",
      "      12173 |   0.269637  |    0.053018     |   0\n",
      "      12174 |   0.063222  |    0.042035     |   2\n",
      "      12175 |   0.055401  |    0.043125     |   2\n",
      "      12176 |   0.207257  |    0.075618     |   0\n",
      "      12177 |   0.171445  |    0.025607     |   0\n",
      "      12178 |   0.027654  |    0.089351     |   2\n",
      "      12179 |   0.194950  |    0.161303     |   1\n",
      "      12180 |   0.170688  |    0.144845     |   1\n",
      "      12181 |   0.182442  |    0.161639     |   1\n",
      "      12182 |   0.000064  |    0.042367     |   2\n",
      "      12183 |   0.284227  |    0.045087     |   0\n",
      "      12184 |   0.227087  |    0.189926     |   1\n",
      "      12185 |   0.220204  |    0.012373     |   0\n",
      "      12186 |   0.006831  |    0.079781     |   2\n",
      "      12187 |   0.083938  |    0.023347     |   2\n",
      "      12188 |   0.159147  |    0.071979     |   0\n",
      "      12189 |   0.042966  |    0.042587     |   2\n",
      "      12190 |   0.147499  |    0.045450     |   0\n",
      "      12191 |   0.220741  |    0.197359     |   1\n",
      "      12192 |   0.158941  |    0.008284     |   0\n",
      "      12193 |   0.281832  |    0.140929     |   1\n",
      "      12194 |   0.190046  |    0.041267     |   0\n",
      "      12195 |   0.213072  |    0.146856     |   1\n",
      "      12196 |   0.066070  |    0.044016     |   2\n",
      "      12197 |   0.049907  |    0.054474     |   2\n",
      "      12198 |   0.186803  |    0.048769     |   0\n",
      "      12199 |   0.237560  |    0.046438     |   0\n",
      "      12200 |   0.236324  |    0.203101     |   1\n",
      "      12201 |   0.021285  |    0.009135     |   2\n",
      "      12202 |   0.043593  |    0.074137     |   2\n",
      "      12203 |   0.191655  |    0.035580     |   0\n",
      "      12204 |   0.037227  |    0.040769     |   2\n",
      "      12205 |   0.214696  |    0.081429     |   0\n",
      "      12206 |   0.194552  |    0.013642     |   0\n",
      "      12207 |   0.222966  |    0.083618     |   0\n",
      "      12208 |   0.230822  |    0.029397     |   0\n",
      "      12209 |   0.256463  |    0.139264     |   1\n",
      "      12210 |   0.000064  |    0.040863     |   2\n",
      "      12211 |   0.173788  |    0.048083     |   0\n",
      "      12212 |   0.184032  |    0.208599     |   1\n",
      "      12213 |   0.233846  |    0.132012     |   1\n",
      "      12214 |   0.180078  |    0.010828     |   0\n",
      "      12215 |   0.219877  |    0.042319     |   0\n",
      "      12216 |   0.191564  |    0.180237     |   1\n",
      "      12217 |   0.000064  |    0.051065     |   2\n",
      "      12218 |   0.191046  |    0.145316     |   1\n",
      "      12219 |   0.000064  |    0.036828     |   2\n",
      "      12220 |   0.282282  |    0.170032     |   1\n",
      "      12221 |   0.000064  |    0.043254     |   2\n",
      "      12222 |   0.194441  |    0.079323     |   0\n",
      "      12223 |   0.223015  |    0.173409     |   1\n",
      "      12224 |   0.171919  |    0.172963     |   1\n",
      "      12225 |   0.244206  |    0.156744     |   1\n",
      "      12226 |   0.000064  |    0.003049     |   2\n",
      "      12227 |   0.195268  |    0.042650     |   0\n",
      "      12228 |   0.000064  |    0.042135     |   2\n",
      "      12229 |   0.056819  |    0.058316     |   2\n",
      "      12230 |   0.270086  |    0.133880     |   1\n",
      "      12231 |   0.156628  |    0.025484     |   0\n",
      "      12232 |   0.182499  |    0.043082     |   0\n",
      "      12233 |   0.224412  |    0.146349     |   1\n",
      "      12234 |   0.189124  |    0.045270     |   0\n",
      "      12235 |   0.239031  |    0.139881     |   1\n",
      "      12236 |   0.060777  |    0.038462     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 12237: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      12237 |   0.207632  |    0.045716     |   0\n",
      "      12238 |   0.055447  |    0.042258     |   2\n",
      "      12239 |   0.042272  |    0.055740     |   2\n",
      "      12240 |   0.224906  |    0.202909     |   1\n",
      "      12241 |   0.046664  |    0.013260     |   2\n",
      "      12242 |   0.056722  |    0.077532     |   2\n",
      "      12243 |   0.028719  |    0.027860     |   2\n",
      "      12244 |   0.048933  |    0.074248     |   2\n",
      "      12245 |   0.174968  |    0.018579     |   0\n",
      "      12246 |   0.047935  |    0.082810     |   2\n",
      "      12247 |   0.209717  |    0.155899     |   1\n",
      "      12248 |   0.171411  |    0.099110     |   1\n",
      "      12249 |   0.210580  |    0.199110     |   1\n",
      "      12250 |   0.216219  |    0.024556     |   0\n",
      "      12251 |   0.269516  |    0.156469     |   1\n",
      "      12252 |   0.168160  |    0.221756     |   1\n",
      "      12253 |   0.061527  |    0.022604     |   2\n",
      "      12254 |   0.215588  |    0.094210     |   0\n",
      "      12255 |   0.226675  |    0.166594     |   1\n",
      "      12256 |   0.054304  |    0.006935     |   2\n",
      "      12257 |   0.026808  |    0.065672     |   2\n",
      "      12258 |   0.176347  |    0.163471     |   1\n",
      "      12259 |   0.000064  |    0.082700     |   2\n",
      "      12260 |   0.006712  |    0.013168     |   2\n",
      "      12261 |   0.081144  |    0.077477     |   2\n",
      "      12262 |   0.191216  |    0.026683     |   0\n",
      "      12263 |   0.041679  |    0.048650     |   2\n",
      "      12264 |   0.063566  |    0.054654     |   2\n",
      "      12265 |   0.045427  |    0.030182     |   2\n",
      "      12266 |   0.181194  |    0.075545     |   0\n",
      "      12267 |   0.223362  |    0.023380     |   0\n",
      "      12268 |   0.235522  |    0.044363     |   0\n",
      "      12269 |   0.166939  |    0.043895     |   0\n",
      "      12270 |   0.019107  |    0.078874     |   2\n",
      "      12271 |   0.232793  |    0.028499     |   0\n",
      "      12272 |   0.179090  |    0.187310     |   1\n",
      "      12273 |   0.042646  |    0.003702     |   2\n",
      "      12274 |   0.204364  |    0.201213     |   1\n",
      "      12275 |   0.035984  |    0.005755     |   2\n",
      "      12276 |   0.230626  |    0.202814     |   1\n",
      "      12277 |   0.147785  |    0.170102     |   1\n",
      "      12278 |   0.187903  |    0.095325     |   1\n",
      "      12279 |   0.131905  |    0.044902     |   0\n",
      "      12280 |   0.192019  |    0.182073     |   1\n",
      "      12281 |   0.221058  |    0.026870     |   0\n",
      "      12282 |   0.199807  |    0.046004     |   0\n",
      "      12283 | \u001b[94m  0.000063\u001b[0m  |    0.074173     |   2\n",
      "      12284 |   0.174447  |    0.160380     |   1\n",
      "      12285 |   0.198381  |    0.137930     |   1\n",
      "      12286 |   0.160806  |    0.045528     |   0\n",
      "      12287 | \u001b[94m  0.000063\u001b[0m  |    0.043493     |   2\n",
      "      12288 |   0.172007  |    0.045261     |   0\n",
      "      12289 |   0.000063  |    0.053861     |   2\n",
      "      12290 |   0.230689  |    0.150360     |   1\n",
      "      12291 |   0.224180  |    0.042201     |   0\n",
      "      12292 |   0.000063  |    0.048635     |   2\n",
      "      12293 | \u001b[94m  0.000063\u001b[0m  |    0.045034     |   2\n",
      "      12294 |   0.188282  |    0.044993     |   0\n",
      "      12295 | \u001b[94m  0.000063\u001b[0m  |    0.076589     |   2\n",
      "      12296 |   0.212229  |    0.028183     |   0\n",
      "      12297 |   0.214891  |    0.149006     |   1\n",
      "      12298 |   0.154702  |    0.198308     |   1\n",
      "      12299 |   0.185676  |    0.133163     |   1\n",
      "      12300 |   0.053374  |    0.012323     |   2\n",
      "      12301 |   0.198795  |    0.076052     |   0\n",
      "      12302 |   0.059979  |    0.008760     |   2\n",
      "      12303 |   0.223994  |    0.197761     |   1\n",
      "      12304 |   0.202854  |    0.024136     |   0\n",
      "      12305 |   0.195295  |    0.072673     |   0\n",
      "      12306 |   0.149402  |    0.017663     |   0\n",
      "      12307 |   0.216762  |    0.196791     |   1\n",
      "      12308 |   0.166118  |    0.123213     |   1\n",
      "      12309 |   0.199089  |    0.050816     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 12310: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      12310 |   0.205970  |    0.192012     |   1\n",
      "      12311 |   0.193342  |    0.149036     |   1\n",
      "      12312 |   0.057301  |    0.042210     |   2\n",
      "      12313 |   0.041955  |    0.042875     |   2\n",
      "      12314 |   0.165171  |    0.071290     |   0\n",
      "      12315 |   0.046473  |    0.023249     |   2\n",
      "      12316 |   0.227207  |    0.077389     |   0\n",
      "      12317 |   0.221956  |    0.141935     |   1\n",
      "      12318 |   0.053737  |    0.075616     |   2\n",
      "      12319 |   0.030100  |    0.025736     |   2\n",
      "      12320 |   0.222680  |    0.156512     |   1\n",
      "      12321 |   0.185225  |    0.048109     |   0\n",
      "      12322 |   0.049982  |    0.074600     |   2\n",
      "      12323 |   0.197585  |    0.025581     |   0\n",
      "      12324 |   0.053289  |    0.043314     |   2\n",
      "      12325 |   0.059991  |    0.053888     |   2\n",
      "      12326 |   0.054666  |    0.042161     |   2\n",
      "      12327 |   0.023411  |    0.041735     |   2\n",
      "      12328 |   0.241405  |    0.194192     |   1\n",
      "      12329 |   0.000063  |    0.008765     |   2\n",
      "      12330 |   0.282497  |    0.185678     |   1\n",
      "      12331 |   0.006905  |    0.031883     |   2\n",
      "      12332 |   0.244575  |    0.137795     |   1\n",
      "      12333 |   0.196692  |    0.039777     |   0\n",
      "      12334 |   0.075907  |    0.076360     |   2\n",
      "      12335 |   0.225010  |    0.139605     |   1\n",
      "      12336 |   0.216439  |    0.043623     |   0\n",
      "      12337 |   0.039358  |    0.044911     |   2\n",
      "      12338 |   0.068399  |    0.079738     |   2\n",
      "      12339 |   0.046508  |    0.022020     |   2\n",
      "      12340 |   0.216785  |    0.174863     |   1\n",
      "      12341 |   0.222872  |    0.148023     |   1\n",
      "      12342 |   0.019867  |    0.025055     |   2\n",
      "      12343 |   0.226798  |    0.158846     |   1\n",
      "      12344 |   0.215495  |    0.077811     |   0\n",
      "      12345 |   0.042440  |    0.023602     |   2\n",
      "      12346 |   0.216905  |    0.195133     |   1\n",
      "      12347 |   0.034794  |    0.010159     |   2\n",
      "      12348 |   0.192414  |    0.075964     |   0\n",
      "      12349 |   0.000063  |    0.048078     |   2\n",
      "      12350 |   0.284544  |    0.049487     |   0\n",
      "      12351 |   0.244885  |    0.199389     |   1\n",
      "      12352 |   0.000063  |    0.003200     |   2\n",
      "      12353 |   0.189331  |    0.048691     |   0\n",
      "      12354 |   0.000063  |    0.041527     |   2\n",
      "      12355 |   0.220753  |    0.074539     |   0\n",
      "      12356 |   0.215878  |    0.039896     |   0\n",
      "      12357 |   0.195917  |    0.171692     |   1\n",
      "      12358 |   0.000063  |    0.012275     |   2\n",
      "      12359 |   0.191698  |    0.203673     |   1\n",
      "      12360 |   0.207441  |    0.143213     |   1\n",
      "      12361 |   0.207393  |    0.192289     |   1\n",
      "      12362 |   0.220523  |    0.150427     |   1\n",
      "      12363 | \u001b[94m  0.000062\u001b[0m  |    0.016859     |   2\n",
      "      12364 |   0.206210  |    0.081968     |   0\n",
      "      12365 | \u001b[94m  0.000062\u001b[0m  |    0.009612     |   2\n",
      "      12366 |   0.054392  |    0.078510     |   2\n",
      "      12367 |   0.059966  |    0.029769     |   2\n",
      "      12368 |   0.237827  |    0.081277     |   0\n",
      "      12369 |   0.162188  |    0.022735     |   0\n",
      "      12370 |   0.254604  |    0.190415     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 12371: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      12371 |   0.166449  |    0.027059     |   0\n",
      "      12372 |   0.057750  |    0.040477     |   2\n",
      "      12373 |   0.045931  |    0.047072     |   2\n",
      "      12374 |   0.044650  |    0.047762     |   2\n",
      "      12375 |   0.055053  |    0.055653     |   2\n",
      "      12376 |   0.275401  |    0.153676     |   1\n",
      "      12377 |   0.030383  |    0.030736     |   2\n",
      "      12378 |   0.246920  |    0.139053     |   1\n",
      "      12379 |   0.197250  |    0.046135     |   0\n",
      "      12380 |   0.046617  |    0.080588     |   2\n",
      "      12381 |   0.195562  |    0.056617     |   0\n",
      "      12382 |   0.203563  |    0.140918     |   1\n",
      "      12383 |   0.054248  |    0.044652     |   2\n",
      "      12384 |   0.219160  |    0.189049     |   1\n",
      "      12385 |   0.160633  |    0.010000     |   0\n",
      "      12386 |   0.060032  |    0.054392     |   2\n",
      "      12387 |   0.181012  |    0.044665     |   0\n",
      "      12388 |   0.051530  |    0.023763     |   2\n",
      "      12389 |   0.024324  |    0.081466     |   2\n",
      "      12390 |   0.174900  |    0.135068     |   1\n",
      "      12391 |   0.000062  |    0.043712     |   2\n",
      "      12392 |   0.160487  |    0.191055     |   1\n",
      "      12393 |   0.174832  |    0.145192     |   1\n",
      "      12394 |   0.006918  |    0.020593     |   2\n",
      "      12395 |   0.082142  |    0.084046     |   2\n",
      "      12396 |   0.160717  |    0.022420     |   0\n",
      "      12397 |   0.041460  |    0.084281     |   2\n",
      "      12398 |   0.065888  |    0.009786     |   2\n",
      "      12399 |   0.184049  |    0.082568     |   0\n",
      "      12400 |   0.197061  |    0.180416     |   1\n",
      "      12401 |   0.206835  |    0.141992     |   1\n",
      "      12402 |   0.238643  |    0.004876     |   0\n",
      "      12403 |   0.047956  |    0.070099     |   2\n",
      "      12404 |   0.264001  |    0.150120     |   1\n",
      "      12405 |   0.018916  |    0.045001     |   2\n",
      "      12406 |   0.044510  |    0.025235     |   2\n",
      "      12407 |   0.233239  |    0.202093     |   1\n",
      "      12408 |   0.221843  |    0.157348     |   1\n",
      "      12409 |   0.186913  |    0.142146     |   1\n",
      "      12410 |   0.207012  |    0.150961     |   1\n",
      "      12411 |   0.034010  |    0.016857     |   2\n",
      "      12412 |   0.169144  |    0.212258     |   1\n",
      "      12413 | \u001b[94m  0.000062\u001b[0m  |    0.008433     |   2\n",
      "      12414 |   0.204904  |    0.195428     |   1\n",
      "      12415 |   0.217711  |    0.028636     |   0\n",
      "      12416 |   0.230569  |    0.200873     |   1\n",
      "      12417 |   0.212061  |    0.161938     |   1\n",
      "      12418 |   0.214267  |    0.024972     |   0\n",
      "      12419 |   0.249029  |    0.191735     |   1\n",
      "      12420 |   0.245451  |    0.024483     |   0\n",
      "      12421 |   0.168613  |    0.049973     |   0\n",
      "      12422 | \u001b[94m  0.000062\u001b[0m  |    0.044483     |   2\n",
      "      12423 |   0.000062  |    0.070493     |   2\n",
      "      12424 |   0.164839  |    0.022463     |   0\n",
      "      12425 |   0.000062  |    0.076983     |   2\n",
      "      12426 |   0.200189  |    0.184949     |   1\n",
      "      12427 | \u001b[94m  0.000062\u001b[0m  |    0.007883     |   2\n",
      "      12428 | \u001b[94m  0.000061\u001b[0m  |    0.079058     |   2\n",
      "      12429 |   0.053324  |    0.042117     |   2\n",
      "      12430 |   0.058290  |    0.038473     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 12431: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      12431 |   0.178914  |    0.223747     |   1\n",
      "      12432 |   0.195051  |    0.146962     |   1\n",
      "      12433 |   0.246219  |    0.142416     |   1\n",
      "      12434 |   0.250178  |    0.004808     |   0\n",
      "      12435 |   0.232159  |    0.081370     |   0\n",
      "      12436 |   0.186483  |    0.157933     |   1\n",
      "      12437 |   0.055134  |    0.007580     |   2\n",
      "      12438 |   0.043398  |    0.077609     |   2\n",
      "      12439 |   0.043420  |    0.015070     |   2\n",
      "      12440 |   0.191315  |    0.204891     |   1\n",
      "      12441 |   0.052039  |    0.015463     |   2\n",
      "      12442 |   0.212091  |    0.205803     |   1\n",
      "      12443 |   0.030063  |    0.006873     |   2\n",
      "      12444 |   0.046124  |    0.094687     |   2\n",
      "      12445 |   0.053334  |    0.012789     |   2\n",
      "      12446 |   0.058096  |    0.077025     |   2\n",
      "      12447 |   0.195120  |    0.160550     |   1\n",
      "      12448 |   0.049970  |    0.048008     |   2\n",
      "      12449 |   0.234989  |    0.071472     |   0\n",
      "      12450 |   0.257926  |    0.143685     |   1\n",
      "      12451 |   0.191234  |    0.018106     |   0\n",
      "      12452 |   0.183986  |    0.192473     |   1\n",
      "      12453 |   0.024730  |    0.047682     |   2\n",
      "      12454 |   0.225000  |    0.159545     |   1\n",
      "      12455 |   0.222289  |    0.148204     |   1\n",
      "      12456 |   0.147931  |    0.057342     |   0\n",
      "      12457 |   0.225389  |    0.074192     |   0\n",
      "      12458 | \u001b[94m  0.000061\u001b[0m  |    0.024812     |   2\n",
      "      12459 |   0.006784  |    0.081519     |   2\n",
      "      12460 |   0.218814  |    0.133543     |   1\n",
      "      12461 |   0.192401  |    0.028997     |   0\n",
      "      12462 |   0.079647  |    0.077901     |   2\n",
      "      12463 |   0.040595  |    0.006048     |   2\n",
      "      12464 |   0.216627  |    0.185371     |   1\n",
      "      12465 |   0.203399  |    0.169571     |   1\n",
      "      12466 |   0.067382  |    0.006518     |   2\n",
      "      12467 |   0.047815  |    0.076841     |   2\n",
      "      12468 |   0.179416  |    0.147164     |   1\n",
      "      12469 |   0.186048  |    0.141449     |   1\n",
      "      12470 |   0.018827  |    0.076655     |   2\n",
      "      12471 |   0.180542  |    0.027873     |   0\n",
      "      12472 |   0.043718  |    0.050587     |   2\n",
      "      12473 |   0.035310  |    0.046246     |   2\n",
      "      12474 |   0.251787  |    0.187231     |   1\n",
      "      12475 | \u001b[94m  0.000061\u001b[0m  |    0.013208     |   2\n",
      "      12476 |   0.212008  |    0.197128     |   1\n",
      "      12477 | \u001b[94m  0.000061\u001b[0m  |    0.005070     |   2\n",
      "      12478 |   0.000061  |    0.073236     |   2\n",
      "      12479 |   0.180855  |    0.030525     |   0\n",
      "      12480 |   0.000061  |    0.042015     |   2\n",
      "      12481 |   0.199677  |    0.077379     |   0\n",
      "      12482 |   0.137583  |    0.016080     |   0\n",
      "      12483 |   0.165488  |    0.215883     |   1\n",
      "      12484 | \u001b[94m  0.000060\u001b[0m  |    0.009470     |   2\n",
      "      12485 |   0.217258  |    0.192475     |   1\n",
      "      12486 |   0.220108  |    0.159971     |   1\n",
      "      12487 |   0.244952  |    0.143394     |   1\n",
      "      12488 |   0.233328  |    0.018346     |   0\n",
      "      12489 | \u001b[94m  0.000060\u001b[0m  |    0.082251     |   2\n",
      "      12490 |   0.202825  |    0.149030     |   1\n",
      "      12491 |   0.051851  |    0.047539     |   2\n",
      "      12492 |   0.239497  |    0.155233     |   1\n",
      "      12493 |   0.267658  |    0.214070     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 12495: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      12494 |   0.058473  |    0.008526     |   2\n",
      "      12495 |   0.052617  |    0.107611     |   2\n",
      "      12496 |   0.169524  |    0.116306     |   1\n",
      "      12497 |   0.041142  |    0.083068     |   2\n",
      "      12498 |   0.169563  |    0.161261     |   1\n",
      "      12499 |   0.043812  |    0.054294     |   2\n",
      "      12500 |   0.216629  |    0.150111     |   1\n",
      "      12501 |   0.214839  |    0.080469     |   0\n",
      "      12502 |   0.206882  |    0.026844     |   0\n",
      "      12503 |   0.050586  |    0.078314     |   2\n",
      "      12504 |   0.197103  |    0.151050     |   1\n",
      "      12505 |   0.191971  |    0.165490     |   1\n",
      "      12506 |   0.153743  |    0.135993     |   1\n",
      "      12507 |   0.187831  |    0.080264     |   0\n",
      "      12508 |   0.039654  |    0.007290     |   2\n",
      "      12509 |   0.043135  |    0.077417     |   2\n",
      "      12510 |   0.263363  |    0.154192     |   1\n",
      "      12511 |   0.240631  |    0.135143     |   1\n",
      "      12512 |   0.297227  |    0.148506     |   1\n",
      "      12513 |   0.214054  |    0.014826     |   0\n",
      "      12514 |   0.053477  |    0.080785     |   2\n",
      "      12515 |   0.264587  |    0.041504     |   0\n",
      "      12516 |   0.215540  |    0.032502     |   0\n",
      "      12517 |   0.166227  |    0.050682     |   0\n",
      "      12518 |   0.251299  |    0.192497     |   1\n",
      "      12519 |   0.209493  |    0.147216     |   1\n",
      "      12520 |   0.236559  |    0.144672     |   1\n",
      "      12521 |   0.138603  |    0.172689     |   1\n",
      "      12522 |   0.029438  |    0.003557     |   2\n",
      "      12523 |   0.047463  |    0.058974     |   2\n",
      "      12524 |   0.194707  |    0.147896     |   1\n",
      "      12525 |   0.055334  |    0.048172     |   2\n",
      "      12526 |   0.217498  |    0.044786     |   0\n",
      "      12527 |   0.060904  |    0.046718     |   2\n",
      "      12528 |   0.053938  |    0.072322     |   2\n",
      "      12529 |   0.161626  |    0.032329     |   0\n",
      "      12530 |   0.207755  |    0.157055     |   1\n",
      "      12531 |   0.026753  |    0.007732     |   2\n",
      "      12532 |   0.147359  |    0.048027     |   0\n",
      "      12533 | \u001b[94m  0.000060\u001b[0m  |    0.044159     |   2\n",
      "      12534 |   0.194931  |    0.052485     |   0\n",
      "      12535 |   0.006676  |    0.043711     |   2\n",
      "      12536 |   0.080383  |    0.061384     |   2\n",
      "      12537 |   0.211948  |    0.044142     |   0\n",
      "      12538 |   0.138812  |    0.041194     |   0\n",
      "      12539 |   0.223390  |    0.199714     |   1\n",
      "      12540 |   0.197375  |    0.142061     |   1\n",
      "      12541 |   0.135882  |    0.019342     |   0\n",
      "      12542 |   0.216222  |    0.164262     |   1\n",
      "      12543 |   0.041582  |    0.072736     |   2\n",
      "      12544 |   0.067945  |    0.042827     |   2\n",
      "      12545 |   0.192111  |    0.191191     |   1\n",
      "      12546 |   0.223904  |    0.009719     |   0\n",
      "      12547 |   0.046355  |    0.074573     |   2\n",
      "      12548 |   0.136595  |    0.022665     |   0\n",
      "      12549 |   0.236721  |    0.202777     |   1\n",
      "      12550 |   0.225685  |    0.148057     |   1\n",
      "      12551 |   0.021571  |    0.023349     |   2\n",
      "      12552 |   0.205488  |    0.207997     |   1\n",
      "      12553 |   0.224329  |    0.045068     |   0\n",
      "      12554 |   0.046145  |    0.043483     |   2\n",
      "      12555 |   0.189356  |    0.040596     |   0\n",
      "      12556 |   0.033774  |    0.048276     |   2\n",
      "      12557 |   0.262954  |    0.206094     |   1\n",
      "      12558 |   0.173280  |    0.150865     |   1\n",
      "      12559 |   0.184454  |    0.028976     |   0\n",
      "      12560 |   0.229759  |    0.202711     |   1\n",
      "      12561 |   0.157147  |    0.157015     |   1\n",
      "      12562 |   0.192547  |    0.026699     |   0\n",
      "      12563 |   0.286884  |    0.151320     |   1\n",
      "      12564 |   0.000060  |    0.040560     |   2\n",
      "      12565 |   0.112457  |    0.209819     |   1\n",
      "      12566 |   0.212833  |    0.017919     |   0\n",
      "      12567 |   0.182723  |    0.077850     |   0\n",
      "      12568 |   0.000060  |    0.007919     |   2\n",
      "      12569 |   0.202022  |    0.193898     |   1\n",
      "      12570 |   0.176832  |    0.009612     |   0\n",
      "      12571 |   0.189070  |    0.079710     |   0\n",
      "      12572 |   0.163209  |    0.029735     |   0\n",
      "      12573 |   0.130763  |    0.047696     |   0\n",
      "      12574 |   0.200392  |    0.051096     |   0\n",
      "      12575 |   0.183597  |    0.041881     |   0\n",
      "      12576 |   0.161977  |    0.031067     |   0\n",
      "      12577 |   0.000060  |    0.053463     |   2\n",
      "      12578 |   0.165848  |    0.052930     |   0\n",
      "      12579 |   0.255584  |    0.148257     |   1\n",
      "      12580 |   0.249113  |    0.150579     |   1\n",
      "      12581 |   0.217585  |    0.134805     |   1\n",
      "      12582 |   0.000060  |    0.036140     |   2\n",
      "      12583 |   0.000060  |    0.045836     |   2\n",
      "      12584 |   0.000060  |    0.050103     |   2\n",
      "      12585 |   0.217973  |    0.212140     |   1\n",
      "      12586 |   0.190145  |    0.099987     |   1\n",
      "      12587 |   0.053382  |    0.025997     |   2\n",
      "      12588 |   0.057761  |    0.052267     |   2\n",
      "      12589 |   0.216615  |    0.040015     |   0\n",
      "      12590 |   0.199910  |    0.085729     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 12591: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      12591 |   0.185206  |    0.014932     |   0\n",
      "      12592 |   0.225807  |    0.210153     |   1\n",
      "      12593 |   0.178226  |    0.137258     |   1\n",
      "      12594 |   0.153190  |    0.045858     |   0\n",
      "      12595 |   0.192889  |    0.047349     |   0\n",
      "      12596 |   0.136826  |    0.168639     |   1\n",
      "      12597 |   0.222840  |    0.148879     |   1\n",
      "      12598 |   0.164578  |    0.034471     |   0\n",
      "      12599 |   0.198843  |    0.182268     |   1\n",
      "      12600 |   0.238718  |    0.021016     |   0\n",
      "      12601 |   0.181731  |    0.067289     |   0\n",
      "      12602 |   0.249300  |    0.143127     |   1\n",
      "      12603 |   0.168139  |    0.155660     |   1\n",
      "      12604 |   0.057487  |    0.047769     |   2\n",
      "      12605 |   0.153927  |    0.033244     |   0\n",
      "      12606 |   0.163068  |    0.048891     |   0\n",
      "      12607 |   0.044036  |    0.053223     |   2\n",
      "      12608 |   0.210205  |    0.192761     |   1\n",
      "      12609 |   0.044742  |    0.004904     |   2\n",
      "      12610 |   0.054266  |    0.080228     |   2\n",
      "      12611 |   0.211085  |    0.016991     |   0\n",
      "      12612 |   0.190800  |    0.193787     |   1\n",
      "      12613 |   0.247551  |    0.027766     |   0\n",
      "      12614 |   0.204963  |    0.191493     |   1\n",
      "      12615 |   0.327897  |    0.153340     |   1\n",
      "      12616 |   0.205935  |    0.017960     |   0\n",
      "      12617 |   0.030748  |    0.083145     |   2\n",
      "      12618 |   0.196928  |    0.205816     |   1\n",
      "      12619 |   0.243410  |    0.133569     |   1\n",
      "      12620 |   0.217672  |    0.007185     |   0\n",
      "      12621 |   0.202795  |    0.076787     |   0\n",
      "      12622 |   0.047783  |    0.015117     |   2\n",
      "      12623 |   0.161144  |    0.198867     |   1\n",
      "      12624 |   0.058015  |    0.009923     |   2\n",
      "      12625 |   0.059965  |    0.074196     |   2\n",
      "      12626 |   0.057772  |    0.019765     |   2\n",
      "      12627 |   0.026966  |    0.076958     |   2\n",
      "      12628 |   0.173002  |    0.157712     |   1\n",
      "      12629 | \u001b[94m  0.000059\u001b[0m  |    0.042945     |   2\n",
      "      12630 |   0.007937  |    0.081654     |   2\n",
      "      12631 |   0.303463  |    0.139020     |   1\n",
      "      12632 |   0.079598  |    0.045092     |   2\n",
      "      12633 |   0.202568  |    0.190912     |   1\n",
      "      12634 |   0.215082  |    0.128267     |   1\n",
      "      12635 |   0.275838  |    0.142558     |   1\n",
      "      12636 |   0.228354  |    0.166173     |   1\n",
      "      12637 |   0.212225  |    0.012880     |   0\n",
      "      12638 |   0.222572  |    0.082853     |   0\n",
      "      12639 |   0.201453  |    0.004976     |   0\n",
      "      12640 |   0.240293  |    0.084063     |   0\n",
      "      12641 |   0.194002  |    0.028583     |   0\n",
      "      12642 |   0.241688  |    0.054745     |   0\n",
      "      12643 |   0.224081  |    0.140149     |   1\n",
      "      12644 |   0.227396  |    0.202791     |   1\n",
      "      12645 |   0.304710  |    0.089072     |   1\n",
      "      12646 |   0.188511  |    0.215267     |   1\n",
      "      12647 |   0.286930  |    0.151678     |   1\n",
      "      12648 |   0.190061  |    0.145098     |   1\n",
      "      12649 |   0.178533  |    0.016891     |   0\n",
      "      12650 |   0.249558  |    0.191734     |   1\n",
      "      12651 |   0.042299  |    0.013827     |   2\n",
      "      12652 |   0.244765  |    0.077938     |   0\n",
      "      12653 |   0.066129  |    0.017729     |   2\n",
      "      12654 |   0.242267  |    0.146629     |   1\n",
      "      12655 |   0.045240  |    0.071590     |   2\n",
      "      12656 |   0.020558  |    0.041064     |   2\n",
      "      12657 |   0.043865  |    0.043111     |   2\n",
      "      12658 |   0.204842  |    0.041001     |   0\n",
      "      12659 |   0.034846  |    0.082609     |   2\n",
      "      12660 |   0.000060  |    0.018946     |   2\n",
      "      12661 |   0.212056  |    0.209179     |   1\n",
      "      12662 |   0.194343  |    0.155594     |   1\n",
      "      12663 |   0.000060  |    0.018627     |   2\n",
      "      12664 |   0.307606  |    0.200544     |   1\n",
      "      12665 |   0.154005  |    0.006478     |   0\n",
      "      12666 |   0.203326  |    0.080644     |   0\n",
      "      12667 |   0.227447  |    0.018967     |   0\n",
      "      12668 |   0.179758  |    0.214647     |   1\n",
      "      12669 |   0.178096  |    0.004889     |   0\n",
      "      12670 |   0.222268  |    0.072525     |   0\n",
      "      12671 |   0.195992  |    0.016136     |   0\n",
      "      12672 | \u001b[94m  0.000059\u001b[0m  |    0.069424     |   2\n",
      "      12673 |   0.155316  |    0.025571     |   0\n",
      "      12674 |   0.000059  |    0.082751     |   2\n",
      "      12675 | \u001b[94m  0.000059\u001b[0m  |    0.017957     |   2\n",
      "      12676 |   0.160073  |    0.072183     |   0\n",
      "      12677 | \u001b[94m  0.000059\u001b[0m  |    0.030048     |   2\n",
      "      12678 |   0.055572  |    0.044852     |   2\n",
      "      12679 |   0.193185  |    0.067089     |   0\n",
      "      12680 |   0.232488  |    0.141537     |   1\n",
      "      12681 |   0.255193  |    0.204109     |   1\n",
      "      12682 |   0.161992  |    0.159978     |   1\n",
      "      12683 |   0.178489  |    0.025129     |   0\n",
      "      12684 |   0.058719  |    0.073885     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 12685: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      12685 |   0.176478  |    0.003285     |   0\n",
      "      12686 |   0.148402  |    0.076772     |   0\n",
      "      12687 |   0.202786  |    0.149448     |   1\n",
      "      12688 |   0.056204  |    0.047352     |   2\n",
      "      12689 |   0.042124  |    0.044090     |   2\n",
      "      12690 |   0.198062  |    0.186171     |   1\n",
      "      12691 |   0.044827  |    0.004812     |   2\n",
      "      12692 |   0.191465  |    0.040624     |   0\n",
      "      12693 |   0.175089  |    0.074588     |   0\n",
      "      12694 |   0.054342  |    0.015249     |   2\n",
      "      12695 |   0.029107  |    0.051380     |   2\n",
      "      12696 |   0.046639  |    0.078553     |   2\n",
      "      12697 |   0.208527  |    0.148337     |   1\n",
      "      12698 |   0.217117  |    0.018617     |   0\n",
      "      12699 |   0.228543  |    0.201942     |   1\n",
      "      12700 |   0.059503  |    0.003653     |   2\n",
      "      12701 |   0.060681  |    0.041320     |   2\n",
      "      12702 |   0.143902  |    0.073217     |   0\n",
      "      12703 |   0.169815  |    0.036003     |   0\n",
      "      12704 |   0.167057  |    0.145916     |   1\n",
      "      12705 |   0.219838  |    0.138287     |   1\n",
      "      12706 |   0.250630  |    0.198807     |   1\n",
      "      12707 |   0.146189  |    0.006789     |   0\n",
      "      12708 |   0.053514  |    0.041251     |   2\n",
      "      12709 |   0.025703  |    0.043853     |   2\n",
      "      12710 | \u001b[94m  0.000059\u001b[0m  |    0.024174     |   2\n",
      "      12711 |   0.178037  |    0.203776     |   1\n",
      "      12712 |   0.006870  |    0.005134     |   2\n",
      "      12713 |   0.082785  |    0.075057     |   2\n",
      "      12714 |   0.214993  |    0.054255     |   0\n",
      "      12715 |   0.190429  |    0.143739     |   1\n",
      "      12716 |   0.219450  |    0.038057     |   0\n",
      "      12717 |   0.040182  |    0.078796     |   2\n",
      "      12718 |   0.214647  |    0.176813     |   1\n",
      "      12719 |   0.205615  |    0.131868     |   1\n",
      "      12720 |   0.207613  |    0.045949     |   0\n",
      "      12721 |   0.069962  |    0.041691     |   2\n",
      "      12722 |   0.207581  |    0.161794     |   1\n",
      "      12723 |   0.156936  |    0.154790     |   1\n",
      "      12724 |   0.049132  |    0.023117     |   2\n",
      "      12725 |   0.255039  |    0.074375     |   0\n",
      "      12726 |   0.218422  |    0.050894     |   0\n",
      "      12727 |   0.202316  |    0.192615     |   1\n",
      "      12728 |   0.020551  |    0.007762     |   2\n",
      "      12729 |   0.189682  |    0.080511     |   0\n",
      "      12730 |   0.045161  |    0.007795     |   2\n",
      "      12731 |   0.034576  |    0.083909     |   2\n",
      "      12732 |   0.000059  |    0.034017     |   2\n",
      "      12733 |   0.000059  |    0.060678     |   2\n",
      "      12734 |   0.000059  |    0.047280     |   2\n",
      "      12735 |   0.233121  |    0.049895     |   0\n",
      "      12736 |   0.000059  |    0.047041     |   2\n",
      "      12737 |   0.226231  |    0.192926     |   1\n",
      "      12738 |   0.226982  |    0.016022     |   0\n",
      "      12739 |   0.176740  |    0.075582     |   0\n",
      "      12740 |   0.206877  |    0.036192     |   0\n",
      "      12741 |   0.200502  |    0.051268     |   0\n",
      "      12742 |   0.158449  |    0.165522     |   1\n",
      "      12743 | \u001b[94m  0.000059\u001b[0m  |    0.011436     |   2\n",
      "      12744 |   0.000059  |    0.090159     |   2\n",
      "      12745 |   0.255251  |    0.143827     |   1\n",
      "      12746 |   0.055245  |    0.012903     |   2\n",
      "      12747 |   0.173828  |    0.224528     |   1\n",
      "      12748 |   0.189216  |    0.005344     |   0\n",
      "      12749 |   0.263911  |    0.144098     |   1\n",
      "      12750 |   0.058850  |    0.036202     |   2\n",
      "      12751 |   0.167516  |    0.060047     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 12752: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      12752 |   0.218072  |    0.143130     |   1\n",
      "      12753 |   0.057246  |    0.047674     |   2\n",
      "      12754 |   0.184471  |    0.169045     |   1\n",
      "      12755 |   0.227786  |    0.186085     |   1\n",
      "      12756 |   0.192176  |    0.029666     |   0\n",
      "      12757 |   0.042401  |    0.043881     |   2\n",
      "      12758 |   0.043556  |    0.052613     |   2\n",
      "      12759 |   0.207828  |    0.041567     |   0\n",
      "      12760 |   0.053008  |    0.029523     |   2\n",
      "      12761 |   0.198300  |    0.206690     |   1\n",
      "      12762 |   0.213198  |    0.022522     |   0\n",
      "      12763 |   0.199817  |    0.073761     |   0\n",
      "      12764 |   0.028811  |    0.024670     |   2\n",
      "      12765 |   0.190146  |    0.200610     |   1\n",
      "      12766 |   0.196462  |    0.029866     |   0\n",
      "      12767 |   0.045150  |    0.043649     |   2\n",
      "      12768 |   0.059601  |    0.068752     |   2\n",
      "      12769 |   0.216483  |    0.049080     |   0\n",
      "      12770 |   0.057858  |    0.040119     |   2\n",
      "      12771 |   0.205128  |    0.207646     |   1\n",
      "      12772 |   0.198054  |    0.148203     |   1\n",
      "      12773 |   0.051221  |    0.026134     |   2\n",
      "      12774 |   0.025213  |    0.080202     |   2\n",
      "      12775 |   0.154781  |    0.018641     |   0\n",
      "      12776 | \u001b[94m  0.000058\u001b[0m  |    0.074466     |   2\n",
      "      12777 |   0.006768  |    0.015142     |   2\n",
      "      12778 |   0.080607  |    0.058755     |   2\n",
      "      12779 |   0.204404  |    0.193454     |   1\n",
      "      12780 |   0.192123  |    0.150936     |   1\n",
      "      12781 |   0.196211  |    0.193659     |   1\n",
      "      12782 |   0.232007  |    0.004492     |   0\n",
      "      12783 |   0.039200  |    0.046604     |   2\n",
      "      12784 |   0.067679  |    0.043504     |   2\n",
      "      12785 |   0.154507  |    0.077348     |   0\n",
      "      12786 |   0.046571  |    0.019475     |   2\n",
      "      12787 |   0.193646  |    0.206034     |   1\n",
      "      12788 |   0.218856  |    0.134017     |   1\n",
      "      12789 |   0.180779  |    0.010145     |   0\n",
      "      12790 |   0.186228  |    0.152553     |   1\n",
      "      12791 |   0.021869  |    0.018292     |   2\n",
      "      12792 |   0.044124  |    0.057475     |   2\n",
      "      12793 |   0.209958  |    0.044982     |   0\n",
      "      12794 |   0.266195  |    0.139783     |   1\n",
      "      12795 |   0.035093  |    0.037947     |   2\n",
      "      12796 |   0.176802  |    0.169683     |   1\n",
      "      12797 |   0.233492  |    0.147221     |   1\n",
      "      12798 |   0.270786  |    0.147226     |   1\n",
      "      12799 |   0.205126  |    0.151963     |   1\n",
      "      12800 |   0.179841  |    0.148984     |   1\n",
      "      12801 |   0.214501  |    0.031704     |   0\n",
      "      12802 | \u001b[94m  0.000058\u001b[0m  |    0.051924     |   2\n",
      "      12803 |   0.237839  |    0.070158     |   0\n",
      "      12804 |   0.229883  |    0.135006     |   1\n",
      "      12805 |   0.170937  |    0.018961     |   0\n",
      "      12806 |   0.000058  |    0.049258     |   2\n",
      "      12807 |   0.000058  |    0.095832     |   2\n",
      "      12808 |   0.162260  |    0.140444     |   1\n",
      "      12809 |   0.186611  |    0.159683     |   1\n",
      "      12810 |   0.000058  |    0.040638     |   2\n",
      "      12811 |   0.179157  |    0.049108     |   0\n",
      "      12812 | \u001b[94m  0.000058\u001b[0m  |    0.047056     |   2\n",
      "      12813 |   0.166888  |    0.062532     |   0\n",
      "      12814 |   0.269744  |    0.111717     |   1\n",
      "      12815 |   0.261879  |    0.085402     |   0\n",
      "      12816 |   0.273456  |    0.134146     |   1\n",
      "      12817 | \u001b[94m  0.000058\u001b[0m  |    0.043585     |   2\n",
      "      12818 |   0.198011  |    0.043872     |   0\n",
      "      12819 |   0.241395  |    0.046292     |   0\n",
      "      12820 |   0.052025  |    0.048882     |   2\n",
      "      12821 |   0.058173  |    0.046571     |   2\n",
      "      12822 |   0.191613  |    0.090645     |   0\n",
      "      12823 |   0.225270  |    0.154054     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 12824: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      12824 |   0.173623  |    0.007700     |   0\n",
      "      12825 |   0.212512  |    0.147199     |   1\n",
      "      12826 |   0.204761  |    0.042438     |   0\n",
      "      12827 |   0.057893  |    0.043091     |   2\n",
      "      12828 |   0.253703  |    0.081384     |   0\n",
      "      12829 |   0.203916  |    0.040775     |   0\n",
      "      12830 |   0.164430  |    0.194855     |   1\n",
      "      12831 |   0.042850  |    0.014845     |   2\n",
      "      12832 |   0.043608  |    0.039173     |   2\n",
      "      12833 |   0.178980  |    0.089325     |   0\n",
      "      12834 |   0.203530  |    0.136726     |   1\n",
      "      12835 |   0.055132  |    0.036862     |   2\n",
      "      12836 |   0.184488  |    0.195707     |   1\n",
      "      12837 |   0.183599  |    0.146130     |   1\n",
      "      12838 |   0.160063  |    0.175248     |   1\n",
      "      12839 |   0.173771  |    0.179785     |   1\n",
      "      12840 |   0.029860  |    0.006771     |   2\n",
      "      12841 |   0.200768  |    0.093464     |   0\n",
      "      12842 |   0.271671  |    0.147456     |   1\n",
      "      12843 |   0.046648  |    0.013605     |   2\n",
      "      12844 |   0.199528  |    0.179106     |   1\n",
      "      12845 |   0.231715  |    0.148966     |   1\n",
      "      12846 |   0.201196  |    0.142615     |   1\n",
      "      12847 |   0.174411  |    0.044495     |   0\n",
      "      12848 |   0.057638  |    0.045584     |   2\n",
      "      12849 |   0.205139  |    0.194798     |   1\n",
      "      12850 |   0.201651  |    0.045533     |   0\n",
      "      12851 |   0.061744  |    0.048883     |   2\n",
      "      12852 |   0.228671  |    0.207095     |   1\n",
      "      12853 |   0.217725  |    0.006988     |   0\n",
      "      12854 |   0.050892  |    0.029850     |   2\n",
      "      12855 |   0.169368  |    0.038927     |   0\n",
      "      12856 |   0.208714  |    0.049615     |   0\n",
      "      12857 |   0.024289  |    0.079625     |   2\n",
      "      12858 | \u001b[94m  0.000057\u001b[0m  |    0.006596     |   2\n",
      "      12859 |   0.007064  |    0.044956     |   2\n",
      "      12860 |   0.181798  |    0.158272     |   1\n",
      "      12861 |   0.239355  |    0.167039     |   1\n",
      "      12862 |   0.145317  |    0.191150     |   1\n",
      "      12863 |   0.154961  |    0.164344     |   1\n",
      "      12864 |   0.083802  |    0.026442     |   2\n",
      "      12865 |   0.040795  |    0.049763     |   2\n",
      "      12866 |   0.067240  |    0.047878     |   2\n",
      "      12867 |   0.192951  |    0.041018     |   0\n",
      "      12868 |   0.195863  |    0.077229     |   0\n",
      "      12869 |   0.242939  |    0.138607     |   1\n",
      "      12870 |   0.046912  |    0.017518     |   2\n",
      "      12871 |   0.191956  |    0.046062     |   0\n",
      "      12872 |   0.020014  |    0.048560     |   2\n",
      "      12873 |   0.148566  |    0.202752     |   1\n",
      "      12874 |   0.045471  |    0.016418     |   2\n",
      "      12875 |   0.162906  |    0.056196     |   0\n",
      "      12876 |   0.170280  |    0.168002     |   1\n",
      "      12877 |   0.236667  |    0.156253     |   1\n",
      "      12878 |   0.149160  |    0.138941     |   1\n",
      "      12879 |   0.179215  |    0.040958     |   0\n",
      "      12880 |   0.037430  |    0.042302     |   2\n",
      "      12881 |   0.195415  |    0.039986     |   0\n",
      "      12882 |   0.157052  |    0.045387     |   0\n",
      "      12883 | \u001b[94m  0.000057\u001b[0m  |    0.038935     |   2\n",
      "      12884 | \u001b[94m  0.000057\u001b[0m  |    0.046359     |   2\n",
      "      12885 |   0.194542  |    0.208550     |   1\n",
      "      12886 |   0.191652  |    0.008912     |   0\n",
      "      12887 |   0.000057  |    0.049009     |   2\n",
      "      12888 |   0.000057  |    0.045385     |   2\n",
      "      12889 | \u001b[94m  0.000057\u001b[0m  |    0.038627     |   2\n",
      "      12890 |   0.226559  |    0.051045     |   0\n",
      "      12891 |   0.162284  |    0.047527     |   0\n",
      "      12892 |   0.212164  |    0.206198     |   1\n",
      "      12893 | \u001b[94m  0.000057\u001b[0m  |    0.011040     |   2\n",
      "      12894 |   0.054031  |    0.079704     |   2\n",
      "      12895 |   0.222688  |    0.137585     |   1\n",
      "      12896 |   0.059385  |    0.052805     |   2\n",
      "      12897 |   0.189933  |    0.046967     |   0\n",
      "      12898 |   0.232247  |    0.150714     |   1\n",
      "      12899 |   0.185358  |    0.195302     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 12900: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      12900 |   0.239748  |    0.077233     |   1\n",
      "      12901 |   0.221902  |    0.040900     |   0\n",
      "      12902 |   0.166415  |    0.042197     |   0\n",
      "      12903 |   0.054491  |    0.048210     |   2\n",
      "      12904 |   0.178488  |    0.185169     |   1\n",
      "      12905 |   0.182016  |    0.007268     |   0\n",
      "      12906 |   0.187096  |    0.070613     |   0\n",
      "      12907 |   0.156923  |    0.024207     |   0\n",
      "      12908 |   0.226472  |    0.081688     |   0\n",
      "      12909 |   0.185052  |    0.135558     |   1\n",
      "      12910 |   0.288875  |    0.137209     |   1\n",
      "      12911 |   0.175604  |    0.165138     |   1\n",
      "      12912 |   0.213369  |    0.096667     |   1\n",
      "      12913 |   0.208542  |    0.065249     |   0\n",
      "      12914 |   0.191039  |    0.146827     |   1\n",
      "      12915 |   0.042854  |    0.005229     |   2\n",
      "      12916 |   0.176502  |    0.207797     |   1\n",
      "      12917 |   0.172473  |    0.160028     |   1\n",
      "      12918 |   0.170718  |    0.136281     |   1\n",
      "      12919 |   0.200353  |    0.073809     |   0\n",
      "      12920 |   0.043948  |    0.009970     |   2\n",
      "      12921 |   0.166814  |    0.078019     |   0\n",
      "      12922 |   0.256607  |    0.140725     |   1\n",
      "      12923 |   0.053314  |    0.040916     |   2\n",
      "      12924 |   0.151734  |    0.160046     |   1\n",
      "      12925 |   0.235608  |    0.150091     |   1\n",
      "      12926 |   0.030232  |    0.028373     |   2\n",
      "      12927 |   0.047691  |    0.049257     |   2\n",
      "      12928 |   0.192510  |    0.071930     |   0\n",
      "      12929 |   0.054118  |    0.027622     |   2\n",
      "      12930 |   0.061217  |    0.048197     |   2\n",
      "      12931 |   0.193166  |    0.074558     |   0\n",
      "      12932 |   0.200160  |    0.117072     |   1\n",
      "      12933 |   0.050711  |    0.043470     |   2\n",
      "      12934 |   0.178518  |    0.190189     |   1\n",
      "      12935 |   0.211626  |    0.010204     |   0\n",
      "      12936 |   0.023566  |    0.046781     |   2\n",
      "      12937 |   0.213975  |    0.160201     |   1\n",
      "      12938 |   0.238262  |    0.193279     |   1\n",
      "      12939 | \u001b[94m  0.000056\u001b[0m  |    0.004339     |   2\n",
      "      12940 |   0.280753  |    0.133725     |   1\n",
      "      12941 |   0.208965  |    0.040640     |   0\n",
      "      12942 |   0.007191  |    0.043462     |   2\n",
      "      12943 |   0.080052  |    0.050027     |   2\n",
      "      12944 |   0.042182  |    0.070570     |   2\n",
      "      12945 |   0.066158  |    0.051890     |   2\n",
      "      12946 |   0.171822  |    0.187506     |   1\n",
      "      12947 |   0.049329  |    0.005590     |   2\n",
      "      12948 |   0.153636  |    0.075080     |   0\n",
      "      12949 |   0.021579  |    0.013835     |   2\n",
      "      12950 |   0.206816  |    0.083390     |   0\n",
      "      12951 |   0.227337  |    0.141467     |   1\n",
      "      12952 |   0.163979  |    0.077305     |   0\n",
      "      12953 |   0.233781  |    0.138716     |   1\n",
      "      12954 |   0.045828  |    0.017222     |   2\n",
      "      12955 |   0.193914  |    0.074077     |   0\n",
      "      12956 |   0.174279  |    0.011603     |   0\n",
      "      12957 |   0.032784  |    0.080414     |   2\n",
      "      12958 |   0.208412  |    0.018123     |   0\n",
      "      12959 | \u001b[94m  0.000056\u001b[0m  |    0.076879     |   2\n",
      "      12960 |   0.213262  |    0.024904     |   0\n",
      "      12961 |   0.193893  |    0.183607     |   1\n",
      "      12962 |   0.232706  |    0.031971     |   0\n",
      "      12963 | \u001b[94m  0.000056\u001b[0m  |    0.071811     |   2\n",
      "      12964 |   0.162353  |    0.025676     |   0\n",
      "      12965 |   0.215332  |    0.156279     |   1\n",
      "      12966 |   0.200853  |    0.213624     |   1\n",
      "      12967 |   0.259448  |    0.008346     |   0\n",
      "      12968 |   0.197425  |    0.153619     |   1\n",
      "      12969 |   0.234736  |    0.044739     |   0\n",
      "      12970 | \u001b[94m  0.000056\u001b[0m  |    0.071534     |   2\n",
      "      12971 |   0.185945  |    0.020519     |   0\n",
      "      12972 |   0.225483  |    0.079010     |   0\n",
      "      12973 |   0.190218  |    0.143247     |   1\n",
      "      12974 |   0.249222  |    0.160015     |   1\n",
      "      12975 |   0.202634  |    0.144815     |   1\n",
      "      12976 |   0.176174  |    0.042248     |   0\n",
      "      12977 |   0.166847  |    0.225589     |   1\n",
      "      12978 | \u001b[94m  0.000056\u001b[0m  |    0.003398     |   2\n",
      "      12979 | \u001b[94m  0.000056\u001b[0m  |    0.044395     |   2\n",
      "      12980 |   0.256720  |    0.157616     |   1\n",
      "      12981 |   0.156656  |    0.192155     |   1\n",
      "      12982 |   0.161659  |    0.014451     |   0\n",
      "      12983 | \u001b[94m  0.000056\u001b[0m  |    0.079928     |   2\n",
      "      12984 |   0.214545  |    0.043162     |   0\n",
      "      12985 |   0.058618  |    0.048100     |   2\n",
      "      12986 |   0.223483  |    0.162947     |   1\n",
      "      12987 |   0.196833  |    0.148982     |   1\n",
      "      12988 |   0.194820  |    0.130962     |   1\n",
      "      12989 |   0.207872  |    0.207932     |   1\n",
      "      12990 |   0.195919  |    0.006741     |   0\n",
      "      12991 |   0.058504  |    0.073911     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 12992: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      12992 |   0.059397  |    0.028520     |   2\n",
      "      12993 |   0.157946  |    0.079095     |   0\n",
      "      12994 |   0.222604  |    0.008662     |   0\n",
      "      12995 |   0.042853  |    0.065656     |   2\n",
      "      12996 |   0.210162  |    0.158489     |   1\n",
      "      12997 |   0.249540  |    0.147527     |   1\n",
      "      12998 |   0.155182  |    0.152240     |   1\n",
      "      12999 |   0.046425  |    0.044263     |   2\n",
      "      13000 |   0.051818  |    0.073538     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 13000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 13000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      13001 |   0.056106  |    0.080421     |   2\n",
      "      13002 |   0.167375  |    0.006134     |   0\n",
      "      13003 |   0.040441  |    0.083099     |   2\n",
      "      13004 |   0.233191  |    0.154988     |   1\n",
      "      13005 |   0.045537  |    0.072896     |   2\n",
      "      13006 |   0.050645  |    0.044082     |   2\n",
      "      13007 |   0.200272  |    0.075022     |   0\n",
      "      13008 |   0.180798  |    0.008852     |   0\n",
      "      13009 |   0.222651  |    0.080909     |   0\n",
      "      13010 |   0.194340  |    0.019048     |   0\n",
      "      13011 |   0.028743  |    0.074304     |   2\n",
      "      13012 |   0.173596  |    0.026036     |   0\n",
      "      13013 |   0.217838  |    0.194418     |   1\n",
      "      13014 |   0.218702  |    0.028816     |   0\n",
      "      13015 |   0.164390  |    0.074642     |   0\n",
      "      13016 |   0.185063  |    0.014441     |   0\n",
      "      13017 |   0.176360  |    0.075847     |   0\n",
      "      13018 |   0.173511  |    0.132094     |   1\n",
      "      13019 |   0.230957  |    0.192177     |   1\n",
      "      13020 |   0.176603  |    0.005418     |   0\n",
      "      13021 |   0.139487  |    0.082277     |   0\n",
      "      13022 |   0.044915  |    0.034659     |   2\n",
      "      13023 |   0.059501  |    0.049818     |   2\n",
      "      13024 |   0.222100  |    0.044351     |   0\n",
      "      13025 |   0.158905  |    0.040298     |   0\n",
      "      13026 |   0.060415  |    0.077249     |   2\n",
      "      13027 |   0.200451  |    0.025172     |   0\n",
      "      13028 |   0.256586  |    0.202060     |   1\n",
      "      13029 |   0.183018  |    0.011762     |   0\n",
      "      13030 |   0.157842  |    0.196864     |   1\n",
      "      13031 |   0.052835  |    0.005602     |   2\n",
      "      13032 |   0.025039  |    0.073045     |   2\n",
      "      13033 |   0.000056  |    0.045156     |   2\n",
      "      13034 |   0.151728  |    0.140061     |   1\n",
      "      13035 |   0.007222  |    0.042907     |   2\n",
      "      13036 |   0.225206  |    0.135628     |   1\n",
      "      13037 |   0.193932  |    0.024676     |   0\n",
      "      13038 |   0.080536  |    0.077636     |   2\n",
      "      13039 |   0.039404  |    0.006364     |   2\n",
      "      13040 |   0.200397  |    0.076284     |   0\n",
      "      13041 |   0.066916  |    0.041934     |   2\n",
      "      13042 |   0.048074  |    0.053385     |   2\n",
      "      13043 |   0.020493  |    0.044347     |   2\n",
      "      13044 |   0.221940  |    0.043061     |   0\n",
      "      13045 |   0.048215  |    0.045179     |   2\n",
      "      13046 |   0.253096  |    0.142031     |   1\n",
      "      13047 |   0.196803  |    0.191627     |   1\n",
      "      13048 |   0.034125  |    0.006581     |   2\n",
      "      13049 |   0.236974  |    0.192717     |   1\n",
      "      13050 |   0.000056  |    0.025428     |   2\n",
      "      13051 |   0.244140  |    0.201253     |   1\n",
      "      13052 |   0.172473  |    0.138881     |   1\n",
      "      13053 |   0.000056  |    0.042893     |   2\n",
      "      13054 |   0.199186  |    0.174273     |   1\n",
      "      13055 |   0.203250  |    0.043370     |   0\n",
      "      13056 |   0.000056  |    0.071791     |   2\n",
      "      13057 |   0.000056  |    0.026526     |   2\n",
      "      13058 |   0.000056  |    0.048912     |   2\n",
      "      13059 |   0.183730  |    0.042106     |   0\n",
      "      13060 |   0.229440  |    0.154562     |   1\n",
      "      13061 |   0.208984  |    0.141651     |   1\n",
      "      13062 |   0.000056  |    0.047511     |   2\n",
      "      13063 |   0.165495  |    0.207290     |   1\n",
      "      13064 |   0.183048  |    0.165104     |   1\n",
      "      13065 |   0.184660  |    0.018534     |   0\n",
      "      13066 |   0.050190  |    0.077858     |   2\n",
      "      13067 |   0.058225  |    0.020359     |   2\n",
      "      13068 |   0.167961  |    0.043227     |   0\n",
      "      13069 |   0.219758  |    0.183316     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 13070: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      13070 |   0.051083  |    0.025667     |   2\n",
      "      13071 |   0.224639  |    0.077698     |   0\n",
      "      13072 |   0.037215  |    0.024755     |   2\n",
      "      13073 |   0.195670  |    0.074994     |   0\n",
      "      13074 |   0.197500  |    0.011852     |   0\n",
      "      13075 |   0.218251  |    0.051118     |   0\n",
      "      13076 |   0.242015  |    0.063885     |   0\n",
      "      13077 |   0.157599  |    0.148996     |   1\n",
      "      13078 |   0.209321  |    0.143595     |   1\n",
      "      13079 |   0.261966  |    0.190616     |   1\n",
      "      13080 |   0.186894  |    0.139573     |   1\n",
      "      13081 |   0.201641  |    0.010184     |   0\n",
      "      13082 |   0.045308  |    0.046247     |   2\n",
      "      13083 |   0.198758  |    0.048952     |   0\n",
      "      13084 |   0.262199  |    0.154610     |   1\n",
      "      13085 |   0.189123  |    0.053081     |   0\n",
      "      13086 |   0.185158  |    0.085180     |   0\n",
      "      13087 |   0.220726  |    0.142583     |   1\n",
      "      13088 |   0.179527  |    0.036904     |   0\n",
      "      13089 |   0.163995  |    0.077321     |   0\n",
      "      13090 |   0.181119  |    0.027138     |   0\n",
      "      13091 |   0.199695  |    0.073068     |   0\n",
      "      13092 |   0.136703  |    0.161316     |   1\n",
      "      13093 |   0.054971  |    0.054849     |   2\n",
      "      13094 |   0.160042  |    0.204921     |   1\n",
      "      13095 |   0.250977  |    0.100291     |   1\n",
      "      13096 |   0.190967  |    0.156994     |   1\n",
      "      13097 |   0.193085  |    0.145258     |   1\n",
      "      13098 |   0.257470  |    0.008767     |   0\n",
      "      13099 |   0.231732  |    0.097167     |   0\n",
      "      13100 |   0.266318  |    0.140068     |   1\n",
      "      13101 |   0.030296  |    0.033956     |   2\n",
      "      13102 |   0.177117  |    0.074880     |   0\n",
      "      13103 |   0.178515  |    0.020932     |   0\n",
      "      13104 |   0.045020  |    0.053225     |   2\n",
      "      13105 |   0.060539  |    0.078045     |   2\n",
      "      13106 |   0.061391  |    0.018300     |   2\n",
      "      13107 |   0.228898  |    0.078435     |   0\n",
      "      13108 |   0.057441  |    0.016374     |   2\n",
      "      13109 |   0.028618  |    0.086119     |   2\n",
      "      13110 | \u001b[94m  0.000055\u001b[0m  |    0.005292     |   2\n",
      "      13111 |   0.198482  |    0.084004     |   0\n",
      "      13112 |   0.204531  |    0.160484     |   1\n",
      "      13113 |   0.006507  |    0.014042     |   2\n",
      "      13114 |   0.243882  |    0.073835     |   0\n",
      "      13115 |   0.231503  |    0.151600     |   1\n",
      "      13116 |   0.186323  |    0.196372     |   1\n",
      "      13117 |   0.260867  |    0.109601     |   1\n",
      "      13118 |   0.155034  |    0.192625     |   1\n",
      "      13119 |   0.223909  |    0.157656     |   1\n",
      "      13120 |   0.242721  |    0.152535     |   1\n",
      "      13121 |   0.079822  |    0.006149     |   2\n",
      "      13122 |   0.122379  |    0.216678     |   1\n",
      "      13123 |   0.200020  |    0.043810     |   0\n",
      "      13124 |   0.039230  |    0.030197     |   2\n",
      "      13125 |   0.212687  |    0.079941     |   0\n",
      "      13126 |   0.239964  |    0.134181     |   1\n",
      "      13127 |   0.186462  |    0.041014     |   0\n",
      "      13128 |   0.178393  |    0.044309     |   0\n",
      "      13129 |   0.227212  |    0.192507     |   1\n",
      "      13130 |   0.254225  |    0.010607     |   0\n",
      "      13131 |   0.198332  |    0.042757     |   0\n",
      "      13132 |   0.064434  |    0.078606     |   2\n",
      "      13133 |   0.285274  |    0.025037     |   0\n",
      "      13134 |   0.175798  |    0.047478     |   0\n",
      "      13135 |   0.247588  |    0.148852     |   1\n",
      "      13136 |   0.049409  |    0.032523     |   2\n",
      "      13137 |   0.018915  |    0.056525     |   2\n",
      "      13138 |   0.235356  |    0.154662     |   1\n",
      "      13139 |   0.040032  |    0.044155     |   2\n",
      "      13140 |   0.035979  |    0.051001     |   2\n",
      "      13141 |   0.196296  |    0.152210     |   1\n",
      "      13142 |   0.216989  |    0.019715     |   0\n",
      "      13143 |   0.145820  |    0.042619     |   0\n",
      "      13144 |   0.161024  |    0.048433     |   0\n",
      "      13145 |   0.135551  |    0.211146     |   1\n",
      "      13146 |   0.152542  |    0.010217     |   0\n",
      "      13147 |   0.000055  |    0.053679     |   2\n",
      "      13148 |   0.162463  |    0.039520     |   0\n",
      "      13149 |   0.193611  |    0.076665     |   0\n",
      "      13150 |   0.237295  |    0.028441     |   0\n",
      "      13151 |   0.200788  |    0.202920     |   1\n",
      "      13152 |   0.163319  |    0.004407     |   0\n",
      "      13153 |   0.207785  |    0.192207     |   1\n",
      "      13154 |   0.000055  |    0.007680     |   2\n",
      "      13155 |   0.000055  |    0.055164     |   2\n",
      "      13156 |   0.265617  |    0.139768     |   1\n",
      "      13157 |   0.000055  |    0.040441     |   2\n",
      "      13158 |   0.000055  |    0.041493     |   2\n",
      "      13159 |   0.160299  |    0.046084     |   0\n",
      "      13160 |   0.143577  |    0.150494     |   1\n",
      "      13161 |   0.000055  |    0.031169     |   2\n",
      "      13162 |   0.286661  |    0.201341     |   1\n",
      "      13163 |   0.054196  |    0.004137     |   2\n",
      "      13164 |   0.058269  |    0.041576     |   2\n",
      "      13165 |   0.202028  |    0.144815     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 13166: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      13166 |   0.192571  |    0.048141     |   0\n",
      "      13167 |   0.198451  |    0.029847     |   0\n",
      "      13168 |   0.196486  |    0.144292     |   1\n",
      "      13169 |   0.054148  |    0.040112     |   2\n",
      "      13170 |   0.220615  |    0.075343     |   0\n",
      "      13171 |   0.155273  |    0.013337     |   0\n",
      "      13172 |   0.037627  |    0.072915     |   2\n",
      "      13173 |   0.286367  |    0.146197     |   1\n",
      "      13174 |   0.211309  |    0.151203     |   1\n",
      "      13175 |   0.244210  |    0.144517     |   1\n",
      "      13176 |   0.210679  |    0.010601     |   0\n",
      "      13177 |   0.139384  |    0.072658     |   0\n",
      "      13178 |   0.222180  |    0.144480     |   1\n",
      "      13179 |   0.234491  |    0.152043     |   1\n",
      "      13180 |   0.044889  |    0.087202     |   2\n",
      "      13181 |   0.260715  |    0.158598     |   1\n",
      "      13182 |   0.222022  |    0.141977     |   1\n",
      "      13183 |   0.050309  |    0.017741     |   2\n",
      "      13184 |   0.028601  |    0.049502     |   2\n",
      "      13185 |   0.046146  |    0.046076     |   2\n",
      "      13186 |   0.054413  |    0.074383     |   2\n",
      "      13187 |   0.153532  |    0.010609     |   0\n",
      "      13188 |   0.259750  |    0.079794     |   0\n",
      "      13189 |   0.060120  |    0.027210     |   2\n",
      "      13190 |   0.055757  |    0.076952     |   2\n",
      "      13191 |   0.027729  |    0.026938     |   2\n",
      "      13192 |   0.197592  |    0.199601     |   1\n",
      "      13193 |   0.248165  |    0.025853     |   0\n",
      "      13194 |   0.235635  |    0.196216     |   1\n",
      "      13195 |   0.000055  |    0.013944     |   2\n",
      "      13196 |   0.192032  |    0.076683     |   0\n",
      "      13197 |   0.006816  |    0.010804     |   2\n",
      "      13198 |   0.078334  |    0.081917     |   2\n",
      "      13199 |   0.269924  |    0.145064     |   1\n",
      "      13200 |   0.222179  |    0.014705     |   0\n",
      "      13201 |   0.038772  |    0.076731     |   2\n",
      "      13202 |   0.189694  |    0.139179     |   1\n",
      "      13203 |   0.201671  |    0.046672     |   0\n",
      "      13204 |   0.063789  |    0.073314     |   2\n",
      "      13205 |   0.203653  |    0.005693     |   0\n",
      "      13206 |   0.047312  |    0.054642     |   2\n",
      "      13207 |   0.019709  |    0.049698     |   2\n",
      "      13208 |   0.209553  |    0.079368     |   0\n",
      "      13209 |   0.217869  |    0.166754     |   1\n",
      "      13210 |   0.223888  |    0.125969     |   1\n",
      "      13211 |   0.042746  |    0.041117     |   2\n",
      "      13212 |   0.219872  |    0.160801     |   1\n",
      "      13213 |   0.195882  |    0.191180     |   1\n",
      "      13214 |   0.226179  |    0.013050     |   0\n",
      "      13215 |   0.189952  |    0.208320     |   1\n",
      "      13216 |   0.135657  |    0.010166     |   0\n",
      "      13217 |   0.034588  |    0.029490     |   2\n",
      "      13218 |   0.192107  |    0.044485     |   0\n",
      "      13219 |   0.177756  |    0.147006     |   1\n",
      "      13220 |   0.186127  |    0.026959     |   0\n",
      "      13221 |   0.000055  |    0.073256     |   2\n",
      "      13222 |   0.000055  |    0.014623     |   2\n",
      "      13223 |   0.206845  |    0.200013     |   1\n",
      "      13224 |   0.210763  |    0.024403     |   0\n",
      "      13225 |   0.199141  |    0.080599     |   0\n",
      "      13226 |   0.201593  |    0.021808     |   0\n",
      "      13227 |   0.193823  |    0.207295     |   1\n",
      "      13228 |   0.166400  |    0.009260     |   0\n",
      "      13229 |   0.195485  |    0.077479     |   0\n",
      "      13230 |   0.199283  |    0.011769     |   0\n",
      "      13231 |   0.204942  |    0.047022     |   0\n",
      "      13232 |   0.190824  |    0.193955     |   1\n",
      "      13233 |   0.151055  |    0.024660     |   0\n",
      "      13234 |   0.151671  |    0.048924     |   0\n",
      "      13235 |   0.000055  |    0.042044     |   2\n",
      "      13236 |   0.000055  |    0.074533     |   2\n",
      "      13237 | \u001b[94m  0.000055\u001b[0m  |    0.040696     |   2\n",
      "      13238 |   0.152276  |    0.037339     |   0\n",
      "      13239 |   0.251498  |    0.197810     |   1\n",
      "      13240 |   0.188541  |    0.003762     |   0\n",
      "      13241 |   0.201473  |    0.196350     |   1\n",
      "      13242 |   0.000055  |    0.007755     |   2\n",
      "      13243 |   0.180204  |    0.075518     |   0\n",
      "      13244 |   0.201515  |    0.177002     |   1\n",
      "      13245 |   0.221849  |    0.161465     |   1\n",
      "      13246 |   0.208079  |    0.151624     |   1\n",
      "      13247 |   0.252641  |    0.147130     |   1\n",
      "      13248 |   0.183497  |    0.010361     |   0\n",
      "      13249 |   0.055582  |    0.078015     |   2\n",
      "      13250 |   0.219076  |    0.132963     |   1\n",
      "      13251 |   0.163526  |    0.071558     |   0\n",
      "      13252 |   0.232100  |    0.043387     |   0\n",
      "      13253 |   0.058552  |    0.039882     |   2\n",
      "      13254 |   0.185324  |    0.075508     |   0\n",
      "      13255 |   0.175274  |    0.156542     |   1\n",
      "      13256 |   0.192520  |    0.020308     |   0\n",
      "      13257 |   0.228090  |    0.075399     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 13259: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      13258 |   0.159630  |    0.024063     |   0\n",
      "      13259 |   0.257977  |    0.149831     |   1\n",
      "      13260 |   0.051166  |    0.044989     |   2\n",
      "      13261 |   0.186564  |    0.044426     |   0\n",
      "      13262 |   0.039222  |    0.045511     |   2\n",
      "      13263 |   0.043408  |    0.074359     |   2\n",
      "      13264 |   0.187209  |    0.017299     |   0\n",
      "      13265 |   0.051402  |    0.088730     |   2\n",
      "      13266 |   0.172764  |    0.165349     |   1\n",
      "      13267 |   0.176257  |    0.008107     |   0\n",
      "      13268 |   0.220187  |    0.073566     |   0\n",
      "      13269 |   0.029655  |    0.019262     |   2\n",
      "      13270 |   0.047020  |    0.076848     |   2\n",
      "      13271 |   0.055582  |    0.028680     |   2\n",
      "      13272 |   0.219579  |    0.204692     |   1\n",
      "      13273 |   0.196082  |    0.146642     |   1\n",
      "      13274 |   0.211680  |    0.149572     |   1\n",
      "      13275 |   0.060712  |    0.004362     |   2\n",
      "      13276 |   0.054485  |    0.076879     |   2\n",
      "      13277 |   0.184559  |    0.035763     |   0\n",
      "      13278 |   0.251576  |    0.206790     |   1\n",
      "      13279 |   0.209039  |    0.004183     |   0\n",
      "      13280 |   0.237277  |    0.046192     |   0\n",
      "      13281 |   0.201088  |    0.058893     |   0\n",
      "      13282 |   0.201836  |    0.171656     |   1\n",
      "      13283 |   0.240959  |    0.034171     |   0\n",
      "      13284 |   0.209854  |    0.079277     |   0\n",
      "      13285 |   0.024940  |    0.008706     |   2\n",
      "      13286 |   0.000055  |    0.076033     |   2\n",
      "      13287 |   0.006961  |    0.004702     |   2\n",
      "      13288 |   0.143208  |    0.198182     |   1\n",
      "      13289 |   0.220541  |    0.184742     |   1\n",
      "      13290 |   0.216562  |    0.163246     |   1\n",
      "      13291 |   0.180850  |    0.006744     |   0\n",
      "      13292 |   0.203755  |    0.075379     |   0\n",
      "      13293 |   0.080736  |    0.014100     |   2\n",
      "      13294 |   0.172186  |    0.089269     |   0\n",
      "      13295 |   0.280683  |    0.154842     |   1\n",
      "      13296 |   0.214373  |    0.163645     |   1\n",
      "      13297 |   0.177784  |    0.014978     |   0\n",
      "      13298 |   0.224293  |    0.155462     |   1\n",
      "      13299 |   0.174361  |    0.155201     |   1\n",
      "      13300 |   0.194809  |    0.153574     |   1\n",
      "      13301 |   0.181366  |    0.158850     |   1\n",
      "      13302 |   0.230689  |    0.186096     |   1\n",
      "      13303 |   0.166180  |    0.004096     |   0\n",
      "      13304 |   0.171166  |    0.047667     |   0\n",
      "      13305 |   0.185716  |    0.078043     |   0\n",
      "      13306 |   0.216606  |    0.159072     |   1\n",
      "      13307 |   0.041328  |    0.027898     |   2\n",
      "      13308 |   0.190223  |    0.074987     |   0\n",
      "      13309 |   0.224208  |    0.181329     |   1\n",
      "      13310 |   0.197769  |    0.006402     |   0\n",
      "      13311 |   0.156010  |    0.045751     |   0\n",
      "      13312 |   0.228462  |    0.156443     |   1\n",
      "      13313 |   0.216430  |    0.104520     |   1\n",
      "      13314 |   0.064402  |    0.046171     |   2\n",
      "      13315 |   0.191936  |    0.045620     |   0\n",
      "      13316 |   0.046610  |    0.074998     |   2\n",
      "      13317 |   0.250499  |    0.152776     |   1\n",
      "      13318 |   0.259861  |    0.182874     |   1\n",
      "      13319 |   0.231571  |    0.091505     |   1\n",
      "      13320 |   0.212842  |    0.195779     |   1\n",
      "      13321 |   0.019178  |    0.004334     |   2\n",
      "      13322 |   0.236778  |    0.195846     |   1\n",
      "      13323 |   0.235110  |    0.029650     |   0\n",
      "      13324 |   0.200441  |    0.082972     |   0\n",
      "      13325 |   0.165229  |    0.012552     |   0\n",
      "      13326 |   0.215890  |    0.072719     |   0\n",
      "      13327 |   0.227061  |    0.045249     |   0\n",
      "      13328 |   0.047304  |    0.071730     |   2\n",
      "      13329 |   0.033890  |    0.014306     |   2\n",
      "      13330 |   0.205068  |    0.051522     |   0\n",
      "      13331 |   0.152194  |    0.211731     |   1\n",
      "      13332 |   0.137832  |    0.139049     |   1\n",
      "      13333 | \u001b[94m  0.000054\u001b[0m  |    0.026535     |   2\n",
      "      13334 | \u001b[94m  0.000054\u001b[0m  |    0.043406     |   2\n",
      "      13335 |   0.149494  |    0.045111     |   0\n",
      "      13336 |   0.171844  |    0.211051     |   1\n",
      "      13337 |   0.086939  |    0.136885     |   1\n",
      "      13338 |   0.171705  |    0.042582     |   0\n",
      "      13339 |   0.182897  |    0.051058     |   0\n",
      "      13340 |   0.138569  |    0.044694     |   0\n",
      "      13341 | \u001b[94m  0.000054\u001b[0m  |    0.056097     |   2\n",
      "      13342 |   0.000054  |    0.027702     |   2\n",
      "      13343 |   0.241657  |    0.080244     |   0\n",
      "      13344 | \u001b[94m  0.000054\u001b[0m  |    0.038785     |   2\n",
      "      13345 |   0.146046  |    0.041163     |   0\n",
      "      13346 |   0.166121  |    0.042983     |   0\n",
      "      13347 |   0.216921  |    0.201268     |   1\n",
      "      13348 |   0.175963  |    0.151254     |   1\n",
      "      13349 |   0.000054  |    0.027024     |   2\n",
      "      13350 |   0.218443  |    0.075530     |   0\n",
      "      13351 |   0.235144  |    0.013779     |   0\n",
      "      13352 |   0.254485  |    0.200994     |   1\n",
      "      13353 |   0.177863  |    0.146879     |   1\n",
      "      13354 |   0.056815  |    0.048589     |   2\n",
      "      13355 |   0.150957  |    0.071542     |   0\n",
      "      13356 |   0.153215  |    0.021532     |   0\n",
      "      13357 |   0.059585  |    0.081527     |   2\n",
      "      13358 |   0.164136  |    0.020129     |   0\n",
      "      13359 |   0.209565  |    0.215871     |   1\n",
      "      13360 |   0.274422  |    0.140633     |   1\n",
      "      13361 |   0.277440  |    0.191873     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 13363: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      13362 |   0.246618  |    0.020061     |   0\n",
      "      13363 |   0.253165  |    0.142231     |   1\n",
      "      13364 |   0.164684  |    0.059817     |   0\n",
      "      13365 |   0.211555  |    0.136260     |   1\n",
      "      13366 |   0.054355  |    0.072109     |   2\n",
      "      13367 |   0.201274  |    0.019866     |   0\n",
      "      13368 |   0.226957  |    0.080115     |   0\n",
      "      13369 |   0.195664  |    0.029189     |   0\n",
      "      13370 |   0.176575  |    0.045395     |   0\n",
      "      13371 |   0.039771  |    0.040804     |   2\n",
      "      13372 |   0.214955  |    0.082425     |   0\n",
      "      13373 |   0.043822  |    0.026024     |   2\n",
      "      13374 |   0.052072  |    0.027425     |   2\n",
      "      13375 |   0.229975  |    0.069594     |   0\n",
      "      13376 |   0.168257  |    0.028824     |   0\n",
      "      13377 |   0.180203  |    0.199778     |   1\n",
      "      13378 |   0.155695  |    0.052118     |   0\n",
      "      13379 |   0.030306  |    0.041841     |   2\n",
      "      13380 |   0.044129  |    0.044851     |   2\n",
      "      13381 |   0.238764  |    0.075513     |   0\n",
      "      13382 |   0.056545  |    0.026380     |   2\n",
      "      13383 |   0.226341  |    0.210341     |   1\n",
      "      13384 |   0.157315  |    0.014592     |   0\n",
      "      13385 |   0.208739  |    0.073970     |   0\n",
      "      13386 |   0.064353  |    0.050602     |   2\n",
      "      13387 |   0.051840  |    0.046434     |   2\n",
      "      13388 |   0.193477  |    0.195474     |   1\n",
      "      13389 |   0.193088  |    0.014001     |   0\n",
      "      13390 |   0.158700  |    0.209471     |   1\n",
      "      13391 |   0.271442  |    0.128852     |   1\n",
      "      13392 |   0.163203  |    0.031072     |   0\n",
      "      13393 |   0.026502  |    0.046669     |   2\n",
      "      13394 |   0.212845  |    0.074028     |   0\n",
      "      13395 |   0.178971  |    0.166265     |   1\n",
      "      13396 |   0.213382  |    0.143331     |   1\n",
      "      13397 |   0.000055  |    0.055175     |   2\n",
      "      13398 |   0.148778  |    0.156133     |   1\n",
      "      13399 |   0.291659  |    0.059692     |   0\n",
      "      13400 |   0.251015  |    0.131657     |   1\n",
      "      13401 |   0.213567  |    0.186667     |   1\n",
      "      13402 |   0.006939  |    0.017056     |   2\n",
      "      13403 |   0.082351  |    0.072921     |   2\n",
      "      13404 |   0.039745  |    0.025996     |   2\n",
      "      13405 |   0.063648  |    0.081805     |   2\n",
      "      13406 |   0.147079  |    0.154765     |   1\n",
      "      13407 |   0.047261  |    0.025439     |   2\n",
      "      13408 |   0.019148  |    0.050211     |   2\n",
      "      13409 |   0.041339  |    0.044065     |   2\n",
      "      13410 |   0.036691  |    0.056842     |   2\n",
      "      13411 |   0.265180  |    0.146786     |   1\n",
      "      13412 |   0.202861  |    0.018211     |   0\n",
      "      13413 |   0.264442  |    0.188308     |   1\n",
      "      13414 |   0.166562  |    0.188176     |   1\n",
      "      13415 |   0.152153  |    0.005353     |   0\n",
      "      13416 |   0.000054  |    0.048009     |   2\n",
      "      13417 |   0.207432  |    0.079244     |   0\n",
      "      13418 |   0.158997  |    0.194700     |   1\n",
      "      13419 |   0.192555  |    0.016857     |   0\n",
      "      13420 | \u001b[94m  0.000054\u001b[0m  |    0.088036     |   2\n",
      "      13421 |   0.000054  |    0.005513     |   2\n",
      "      13422 |   0.000054  |    0.076162     |   2\n",
      "      13423 |   0.172532  |    0.150548     |   1\n",
      "      13424 | \u001b[94m  0.000054\u001b[0m  |    0.044115     |   2\n",
      "      13425 |   0.158994  |    0.143830     |   1\n",
      "      13426 |   0.199315  |    0.042432     |   0\n",
      "      13427 | \u001b[94m  0.000054\u001b[0m  |    0.047687     |   2\n",
      "      13428 |   0.054786  |    0.044421     |   2\n",
      "      13429 |   0.194155  |    0.150018     |   1\n",
      "      13430 |   0.208129  |    0.147818     |   1\n",
      "      13431 |   0.059399  |    0.043229     |   2\n",
      "      13432 |   0.156145  |    0.052945     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 13433: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      13433 |   0.196434  |    0.165036     |   1\n",
      "      13434 |   0.181571  |    0.154789     |   1\n",
      "      13435 |   0.208863  |    0.023237     |   0\n",
      "      13436 |   0.158492  |    0.197049     |   1\n",
      "      13437 |   0.052285  |    0.022490     |   2\n",
      "      13438 |   0.243810  |    0.055112     |   0\n",
      "      13439 |   0.204221  |    0.146759     |   1\n",
      "      13440 |   0.233599  |    0.074855     |   0\n",
      "      13441 |   0.040430  |    0.041784     |   2\n",
      "      13442 |   0.168662  |    0.046481     |   0\n",
      "      13443 |   0.164874  |    0.062398     |   0\n",
      "      13444 |   0.257593  |    0.164785     |   1\n",
      "      13445 |   0.171889  |    0.113319     |   1\n",
      "      13446 |   0.211118  |    0.045817     |   0\n",
      "      13447 |   0.046023  |    0.054035     |   2\n",
      "      13448 |   0.054110  |    0.044683     |   2\n",
      "      13449 |   0.226440  |    0.081124     |   0\n",
      "      13450 |   0.194881  |    0.010693     |   0\n",
      "      13451 |   0.228579  |    0.078491     |   0\n",
      "      13452 |   0.029081  |    0.017775     |   2\n",
      "      13453 |   0.045190  |    0.077669     |   2\n",
      "      13454 |   0.194764  |    0.015401     |   0\n",
      "      13455 |   0.209287  |    0.165414     |   1\n",
      "      13456 |   0.166930  |    0.051917     |   0\n",
      "      13457 |   0.292842  |    0.143277     |   1\n",
      "      13458 |   0.060017  |    0.014150     |   2\n",
      "      13459 |   0.060082  |    0.085545     |   2\n",
      "      13460 |   0.050920  |    0.014276     |   2\n",
      "      13461 |   0.206525  |    0.202702     |   1\n",
      "      13462 |   0.246675  |    0.155534     |   1\n",
      "      13463 |   0.026274  |    0.043851     |   2\n",
      "      13464 |   0.164483  |    0.040082     |   0\n",
      "      13465 | \u001b[94m  0.000053\u001b[0m  |    0.042554     |   2\n",
      "      13466 |   0.180326  |    0.076088     |   0\n",
      "      13467 |   0.195190  |    0.004458     |   0\n",
      "      13468 |   0.006760  |    0.058362     |   2\n",
      "      13469 |   0.201779  |    0.042251     |   0\n",
      "      13470 |   0.208160  |    0.041734     |   0\n",
      "      13471 |   0.211794  |    0.088562     |   0\n",
      "      13472 |   0.284640  |    0.154194     |   1\n",
      "      13473 |   0.185579  |    0.147061     |   1\n",
      "      13474 |   0.081957  |    0.031947     |   2\n",
      "      13475 |   0.228821  |    0.215551     |   1\n",
      "      13476 |   0.227640  |    0.151254     |   1\n",
      "      13477 |   0.195281  |    0.009391     |   0\n",
      "      13478 |   0.153902  |    0.043671     |   0\n",
      "      13479 |   0.192380  |    0.072758     |   0\n",
      "      13480 |   0.039200  |    0.027841     |   2\n",
      "      13481 |   0.219257  |    0.088559     |   0\n",
      "      13482 |   0.065795  |    0.017996     |   2\n",
      "      13483 |   0.173474  |    0.196796     |   1\n",
      "      13484 |   0.204386  |    0.053652     |   0\n",
      "      13485 |   0.194020  |    0.156703     |   1\n",
      "      13486 |   0.184580  |    0.047282     |   0\n",
      "      13487 |   0.120167  |    0.168292     |   1\n",
      "      13488 |   0.280791  |    0.162974     |   1\n",
      "      13489 |   0.048890  |    0.041187     |   2\n",
      "      13490 |   0.020109  |    0.055679     |   2\n",
      "      13491 |   0.229544  |    0.154301     |   1\n",
      "      13492 |   0.214311  |    0.007372     |   0\n",
      "      13493 |   0.042666  |    0.079237     |   2\n",
      "      13494 |   0.170607  |    0.024497     |   0\n",
      "      13495 |   0.174769  |    0.238285     |   1\n",
      "      13496 |   0.208043  |    0.126443     |   1\n",
      "      13497 |   0.162402  |    0.146127     |   1\n",
      "      13498 |   0.034576  |    0.010069     |   2\n",
      "      13499 |   0.000054  |    0.093634     |   2\n",
      "      13500 |   0.226628  |    0.148280     |   1\n",
      "      13501 |   0.157642  |    0.050895     |   0\n",
      "      13502 |   0.051818  |    0.073691     |   2\n",
      "      13503 |   0.157193  |    0.019120     |   0\n",
      "      13504 |   0.040296  |    0.079297     |   2\n",
      "      13505 |   0.186603  |    0.155267     |   1\n",
      "      13506 |   0.199895  |    0.157249     |   1\n",
      "      13507 |   0.173917  |    0.112859     |   1\n",
      "      13508 |   0.219681  |    0.160266     |   1\n",
      "      13509 |   0.044654  |    0.026297     |   2\n",
      "      13510 |   0.215665  |    0.074278     |   0\n",
      "      13511 |   0.051897  |    0.018591     |   2\n",
      "      13512 |   0.029140  |    0.079786     |   2\n",
      "      13513 |   0.218765  |    0.138152     |   1\n",
      "      13514 |   0.178761  |    0.147302     |   1\n",
      "      13515 |   0.044108  |    0.042448     |   2\n",
      "      13516 |   0.193901  |    0.055579     |   0\n",
      "      13517 |   0.223639  |    0.045280     |   0\n",
      "      13518 |   0.055598  |    0.048972     |   2\n",
      "      13519 |   0.215312  |    0.050956     |   0\n",
      "      13520 |   0.061815  |    0.042010     |   2\n",
      "      13521 |   0.051057  |    0.083199     |   2\n",
      "      13522 |   0.214448  |    0.023780     |   0\n",
      "      13523 |   0.203591  |    0.078870     |   0\n",
      "      13524 |   0.211121  |    0.015627     |   0\n",
      "      13525 |   0.250303  |    0.192516     |   1\n",
      "      13526 |   0.220199  |    0.030259     |   0\n",
      "      13527 |   0.157754  |    0.051328     |   0\n",
      "      13528 |   0.189178  |    0.193836     |   1\n",
      "      13529 |   0.171212  |    0.005244     |   0\n",
      "      13530 |   0.025593  |    0.046171     |   2\n",
      "      13531 |   0.199575  |    0.147842     |   1\n",
      "      13532 |   0.207710  |    0.027141     |   0\n",
      "      13533 |   0.231356  |    0.049215     |   0\n",
      "      13534 |   0.173707  |    0.173129     |   1\n",
      "      13535 |   0.233089  |    0.199331     |   1\n",
      "      13536 | \u001b[94m  0.000053\u001b[0m  |    0.041027     |   2\n",
      "      13537 |   0.007362  |    0.042929     |   2\n",
      "      13538 |   0.078656  |    0.054918     |   2\n",
      "      13539 |   0.309433  |    0.146210     |   1\n",
      "      13540 |   0.203427  |    0.051747     |   0\n",
      "      13541 |   0.039954  |    0.040823     |   2\n",
      "      13542 |   0.213859  |    0.206401     |   1\n",
      "      13543 |   0.225814  |    0.146827     |   1\n",
      "      13544 |   0.065672  |    0.010419     |   2\n",
      "      13545 |   0.047802  |    0.077075     |   2\n",
      "      13546 |   0.161035  |    0.022706     |   0\n",
      "      13547 |   0.291732  |    0.140546     |   1\n",
      "      13548 |   0.192531  |    0.071380     |   0\n",
      "      13549 |   0.158062  |    0.021209     |   0\n",
      "      13550 |   0.020294  |    0.074595     |   2\n",
      "      13551 |   0.210445  |    0.025277     |   0\n",
      "      13552 |   0.207883  |    0.196079     |   1\n",
      "      13553 |   0.206845  |    0.134336     |   1\n",
      "      13554 |   0.194554  |    0.015541     |   0\n",
      "      13555 |   0.043972  |    0.078448     |   2\n",
      "      13556 |   0.253304  |    0.042034     |   0\n",
      "      13557 |   0.214758  |    0.150067     |   1\n",
      "      13558 |   0.208313  |    0.071545     |   0\n",
      "      13559 |   0.037077  |    0.023397     |   2\n",
      "      13560 |   0.270526  |    0.077298     |   0\n",
      "      13561 | \u001b[94m  0.000053\u001b[0m  |    0.043557     |   2\n",
      "      13562 |   0.231063  |    0.045386     |   0\n",
      "      13563 | \u001b[94m  0.000053\u001b[0m  |    0.039534     |   2\n",
      "      13564 |   0.210426  |    0.201435     |   1\n",
      "      13565 |   0.161571  |    0.140776     |   1\n",
      "      13566 |   0.203620  |    0.046682     |   0\n",
      "      13567 |   0.181438  |    0.144302     |   1\n",
      "      13568 |   0.173298  |    0.078332     |   0\n",
      "      13569 | \u001b[94m  0.000053\u001b[0m  |    0.006296     |   2\n",
      "      13570 |   0.000053  |    0.071630     |   2\n",
      "      13571 | \u001b[94m  0.000053\u001b[0m  |    0.046478     |   2\n",
      "      13572 |   0.214887  |    0.075215     |   0\n",
      "      13573 | \u001b[94m  0.000053\u001b[0m  |    0.008148     |   2\n",
      "      13574 |   0.220840  |    0.051533     |   0\n",
      "      13575 |   0.058171  |    0.079442     |   2\n",
      "      13576 |   0.271381  |    0.134675     |   1\n",
      "      13577 |   0.201368  |    0.052661     |   0\n",
      "      13578 |   0.195954  |    0.151336     |   1\n",
      "      13579 |   0.060295  |    0.044606     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 13580: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      13580 |   0.057405  |    0.071128     |   2\n",
      "      13581 |   0.157261  |    0.017663     |   0\n",
      "      13582 |   0.213163  |    0.201626     |   1\n",
      "      13583 |   0.209915  |    0.161594     |   1\n",
      "      13584 |   0.276595  |    0.151690     |   1\n",
      "      13585 |   0.042013  |    0.039128     |   2\n",
      "      13586 |   0.045869  |    0.053107     |   2\n",
      "      13587 |   0.055676  |    0.049493     |   2\n",
      "      13588 |   0.165074  |    0.043853     |   0\n",
      "      13589 |   0.029138  |    0.082734     |   2\n",
      "      13590 |   0.206846  |    0.167774     |   1\n",
      "      13591 |   0.046284  |    0.007206     |   2\n",
      "      13592 |   0.052698  |    0.075803     |   2\n",
      "      13593 |   0.223765  |    0.180536     |   1\n",
      "      13594 |   0.223176  |    0.140634     |   1\n",
      "      13595 |   0.185390  |    0.156156     |   1\n",
      "      13596 |   0.061878  |    0.028762     |   2\n",
      "      13597 |   0.156922  |    0.043030     |   0\n",
      "      13598 |   0.055223  |    0.075520     |   2\n",
      "      13599 |   0.158177  |    0.030035     |   0\n",
      "      13600 |   0.159696  |    0.064513     |   0\n",
      "      13601 |   0.183256  |    0.155516     |   1\n",
      "      13602 |   0.202973  |    0.194149     |   1\n",
      "      13603 |   0.175542  |    0.021247     |   0\n",
      "      13604 |   0.236342  |    0.214204     |   1\n",
      "      13605 |   0.188606  |    0.009105     |   0\n",
      "      13606 |   0.201423  |    0.073531     |   0\n",
      "      13607 |   0.026867  |    0.039432     |   2\n",
      "      13608 |   0.000053  |    0.037900     |   2\n",
      "      13609 |   0.006689  |    0.052111     |   2\n",
      "      13610 |   0.148665  |    0.206767     |   1\n",
      "      13611 |   0.075447  |    0.006239     |   2\n",
      "      13612 |   0.171491  |    0.079790     |   0\n",
      "      13613 |   0.223383  |    0.137614     |   1\n",
      "      13614 |   0.194862  |    0.015535     |   0\n",
      "      13615 |   0.213819  |    0.076035     |   0\n",
      "      13616 |   0.036292  |    0.035588     |   2\n",
      "      13617 |   0.204802  |    0.210101     |   1\n",
      "      13618 |   0.158254  |    0.009842     |   0\n",
      "      13619 |   0.186223  |    0.042778     |   0\n",
      "      13620 |   0.063492  |    0.075115     |   2\n",
      "      13621 |   0.169806  |    0.142608     |   1\n",
      "      13622 |   0.045860  |    0.047275     |   2\n",
      "      13623 |   0.259532  |    0.149841     |   1\n",
      "      13624 |   0.018744  |    0.032701     |   2\n",
      "      13625 |   0.217441  |    0.193878     |   1\n",
      "      13626 |   0.131871  |    0.023886     |   0\n",
      "      13627 |   0.169682  |    0.079360     |   0\n",
      "      13628 |   0.184179  |    0.177547     |   1\n",
      "      13629 |   0.174820  |    0.156886     |   1\n",
      "      13630 |   0.154778  |    0.147648     |   1\n",
      "      13631 |   0.184827  |    0.008767     |   0\n",
      "      13632 |   0.188348  |    0.056530     |   0\n",
      "      13633 |   0.042536  |    0.077094     |   2\n",
      "      13634 |   0.275748  |    0.131826     |   1\n",
      "      13635 |   0.201655  |    0.052665     |   0\n",
      "      13636 |   0.187005  |    0.054038     |   0\n",
      "      13637 |   0.201290  |    0.078105     |   0\n",
      "      13638 |   0.236865  |    0.016928     |   0\n",
      "      13639 |   0.306607  |    0.193789     |   1\n",
      "      13640 |   0.179444  |    0.151690     |   1\n",
      "      13641 |   0.034000  |    0.014227     |   2\n",
      "      13642 | \u001b[94m  0.000052\u001b[0m  |    0.084883     |   2\n",
      "      13643 |   0.166544  |    0.017931     |   0\n",
      "      13644 |   0.208845  |    0.080184     |   0\n",
      "      13645 |   0.161490  |    0.019001     |   0\n",
      "      13646 |   0.224438  |    0.079527     |   0\n",
      "      13647 |   0.198019  |    0.144278     |   1\n",
      "      13648 |   0.190738  |    0.210825     |   1\n",
      "      13649 |   0.180323  |    0.164930     |   1\n",
      "      13650 | \u001b[94m  0.000051\u001b[0m  |    0.018582     |   2\n",
      "      13651 |   0.283793  |    0.142428     |   1\n",
      "      13652 |   0.161922  |    0.025245     |   0\n",
      "      13653 |   0.156061  |    0.048221     |   0\n",
      "      13654 |   0.267854  |    0.137528     |   1\n",
      "      13655 |   0.224487  |    0.052207     |   0\n",
      "      13656 |   0.260409  |    0.148289     |   1\n",
      "      13657 |   0.192613  |    0.042697     |   0\n",
      "      13658 |   0.208320  |    0.085157     |   0\n",
      "      13659 |   0.245668  |    0.151402     |   1\n",
      "      13660 |   0.213772  |    0.095787     |   1\n",
      "      13661 |   0.000052  |    0.046910     |   2\n",
      "      13662 |   0.188410  |    0.069988     |   0\n",
      "      13663 |   0.000052  |    0.044962     |   2\n",
      "      13664 |   0.247150  |    0.047139     |   0\n",
      "      13665 |   0.176242  |    0.050915     |   0\n",
      "      13666 |   0.000052  |    0.041076     |   2\n",
      "      13667 |   0.000052  |    0.061991     |   2\n",
      "      13668 |   0.159960  |    0.213279     |   1\n",
      "      13669 |   0.248964  |    0.136555     |   1\n",
      "      13670 |   0.184202  |    0.008599     |   0\n",
      "      13671 |   0.054868  |    0.059237     |   2\n",
      "      13672 |   0.239596  |    0.199535     |   1\n",
      "      13673 |   0.191752  |    0.155403     |   1\n",
      "      13674 |   0.283536  |    0.137290     |   1\n",
      "      13675 |   0.058501  |    0.071060     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 13676: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      13676 |   0.054150  |    0.025154     |   2\n",
      "      13677 |   0.148127  |    0.080492     |   0\n",
      "      13678 |   0.171087  |    0.038034     |   0\n",
      "      13679 |   0.194951  |    0.197756     |   1\n",
      "      13680 |   0.213305  |    0.010481     |   0\n",
      "      13681 |   0.235694  |    0.140763     |   1\n",
      "      13682 |   0.138096  |    0.029571     |   0\n",
      "      13683 |   0.208545  |    0.040861     |   0\n",
      "      13684 |   0.039346  |    0.047533     |   2\n",
      "      13685 |   0.218845  |    0.045981     |   0\n",
      "      13686 |   0.162812  |    0.199076     |   1\n",
      "      13687 |   0.174115  |    0.010094     |   0\n",
      "      13688 |   0.045414  |    0.050252     |   2\n",
      "      13689 |   0.051132  |    0.045385     |   2\n",
      "      13690 |   0.029356  |    0.043615     |   2\n",
      "      13691 |   0.194843  |    0.040913     |   0\n",
      "      13692 |   0.186844  |    0.070942     |   0\n",
      "      13693 |   0.157815  |    0.017773     |   0\n",
      "      13694 |   0.046172  |    0.074954     |   2\n",
      "      13695 |   0.151730  |    0.012333     |   0\n",
      "      13696 |   0.215757  |    0.184976     |   1\n",
      "      13697 |   0.138770  |    0.010926     |   0\n",
      "      13698 |   0.220427  |    0.202417     |   1\n",
      "      13699 |   0.192899  |    0.136493     |   1\n",
      "      13700 |   0.061421  |    0.024771     |   2\n",
      "      13701 |   0.215758  |    0.197935     |   1\n",
      "      13702 |   0.219439  |    0.133790     |   1\n",
      "      13703 |   0.063732  |    0.026836     |   2\n",
      "      13704 |   0.193597  |    0.060526     |   0\n",
      "      13705 |   0.048535  |    0.028425     |   2\n",
      "      13706 |   0.177952  |    0.051555     |   0\n",
      "      13707 |   0.204324  |    0.151673     |   1\n",
      "      13708 |   0.157186  |    0.071354     |   0\n",
      "      13709 |   0.024381  |    0.028124     |   2\n",
      "      13710 |   0.000051  |    0.080735     |   2\n",
      "      13711 |   0.204322  |    0.028810     |   0\n",
      "      13712 |   0.007013  |    0.071550     |   2\n",
      "      13713 |   0.266431  |    0.051285     |   0\n",
      "      13714 |   0.078813  |    0.021844     |   2\n",
      "      13715 |   0.206340  |    0.077465     |   0\n",
      "      13716 |   0.201485  |    0.034926     |   0\n",
      "      13717 |   0.039416  |    0.045249     |   2\n",
      "      13718 |   0.066771  |    0.073494     |   2\n",
      "      13719 |   0.225272  |    0.014735     |   0\n",
      "      13720 |   0.050578  |    0.072801     |   2\n",
      "      13721 |   0.136308  |    0.046452     |   0\n",
      "      13722 |   0.191935  |    0.158515     |   1\n",
      "      13723 |   0.237393  |    0.135828     |   1\n",
      "      13724 |   0.261650  |    0.130838     |   1\n",
      "      13725 |   0.240456  |    0.216685     |   1\n",
      "      13726 |   0.171481  |    0.149576     |   1\n",
      "      13727 |   0.195436  |    0.019466     |   0\n",
      "      13728 |   0.258453  |    0.185148     |   1\n",
      "      13729 |   0.156990  |    0.009310     |   0\n",
      "      13730 |   0.020181  |    0.088784     |   2\n",
      "      13731 |   0.046569  |    0.015327     |   2\n",
      "      13732 |   0.036555  |    0.078843     |   2\n",
      "      13733 |   0.000051  |    0.041333     |   2\n",
      "      13734 |   0.189673  |    0.029971     |   0\n",
      "      13735 |   0.000051  |    0.075009     |   2\n",
      "      13736 |   0.000051  |    0.016530     |   2\n",
      "      13737 |   0.196952  |    0.212471     |   1\n",
      "      13738 |   0.000052  |    0.003841     |   2\n",
      "      13739 |   0.218502  |    0.198671     |   1\n",
      "      13740 |   0.000051  |    0.006919     |   2\n",
      "      13741 |   0.166517  |    0.083038     |   0\n",
      "      13742 | \u001b[94m  0.000051\u001b[0m  |    0.004282     |   2\n",
      "      13743 |   0.051641  |    0.075150     |   2\n",
      "      13744 |   0.182046  |    0.051365     |   0\n",
      "      13745 |   0.248182  |    0.142884     |   1\n",
      "      13746 |   0.240120  |    0.068391     |   0\n",
      "      13747 |   0.059267  |    0.045212     |   2\n",
      "      13748 |   0.193932  |    0.138686     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 13749: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      13749 |   0.056105  |    0.050391     |   2\n",
      "      13750 |   0.241735  |    0.153868     |   1\n",
      "      13751 |   0.180160  |    0.166905     |   1\n",
      "      13752 |   0.231289  |    0.147080     |   1\n",
      "      13753 |   0.167950  |    0.004696     |   0\n",
      "      13754 |   0.041229  |    0.063017     |   2\n",
      "      13755 |   0.279495  |    0.164410     |   1\n",
      "      13756 |   0.045110  |    0.020599     |   2\n",
      "      13757 |   0.231066  |    0.076373     |   0\n",
      "      13758 |   0.053937  |    0.004824     |   2\n",
      "      13759 |   0.241356  |    0.077406     |   0\n",
      "      13760 |   0.221290  |    0.020450     |   0\n",
      "      13761 |   0.206378  |    0.194615     |   1\n",
      "      13762 |   0.160608  |    0.041725     |   0\n",
      "      13763 |   0.238366  |    0.075740     |   0\n",
      "      13764 |   0.218306  |    0.016109     |   0\n",
      "      13765 |   0.029195  |    0.051643     |   2\n",
      "      13766 |   0.043791  |    0.074617     |   2\n",
      "      13767 |   0.218398  |    0.142717     |   1\n",
      "      13768 |   0.185881  |    0.028269     |   0\n",
      "      13769 |   0.188509  |    0.080807     |   0\n",
      "      13770 |   0.218395  |    0.033071     |   0\n",
      "      13771 |   0.192362  |    0.051191     |   0\n",
      "      13772 |   0.188733  |    0.081281     |   0\n",
      "      13773 |   0.185540  |    0.025069     |   0\n",
      "      13774 |   0.227587  |    0.095226     |   0\n",
      "      13775 |   0.057130  |    0.012019     |   2\n",
      "      13776 |   0.284650  |    0.184429     |   1\n",
      "      13777 |   0.303904  |    0.146765     |   1\n",
      "      13778 |   0.062251  |    0.021327     |   2\n",
      "      13779 |   0.209716  |    0.101552     |   0\n",
      "      13780 |   0.216585  |    0.130266     |   1\n",
      "      13781 |   0.195118  |    0.044100     |   0\n",
      "      13782 |   0.220372  |    0.198003     |   1\n",
      "      13783 |   0.174521  |    0.006491     |   0\n",
      "      13784 |   0.051762  |    0.076965     |   2\n",
      "      13785 |   0.155568  |    0.016344     |   0\n",
      "      13786 |   0.026221  |    0.084632     |   2\n",
      "      13787 | \u001b[94m  0.000051\u001b[0m  |    0.028038     |   2\n",
      "      13788 |   0.006677  |    0.049095     |   2\n",
      "      13789 |   0.260736  |    0.182895     |   1\n",
      "      13790 |   0.174499  |    0.006029     |   0\n",
      "      13791 |   0.185120  |    0.045278     |   0\n",
      "      13792 |   0.074598  |    0.042159     |   2\n",
      "      13793 |   0.038537  |    0.037558     |   2\n",
      "      13794 |   0.166741  |    0.083450     |   0\n",
      "      13795 |   0.185465  |    0.029540     |   0\n",
      "      13796 |   0.277479  |    0.145043     |   1\n",
      "      13797 |   0.160986  |    0.205928     |   1\n",
      "      13798 |   0.067227  |    0.004582     |   2\n",
      "      13799 |   0.049981  |    0.082602     |   2\n",
      "      13800 |   0.226988  |    0.153260     |   1\n",
      "      13801 |   0.204785  |    0.160156     |   1\n",
      "      13802 |   0.217151  |    0.154010     |   1\n",
      "      13803 |   0.019248  |    0.033675     |   2\n",
      "      13804 |   0.277709  |    0.186082     |   1\n",
      "      13805 |   0.044466  |    0.015364     |   2\n",
      "      13806 |   0.150062  |    0.078338     |   0\n",
      "      13807 |   0.035257  |    0.032468     |   2\n",
      "      13808 | \u001b[94m  0.000051\u001b[0m  |    0.049596     |   2\n",
      "      13809 |   0.247592  |    0.189767     |   1\n",
      "      13810 |   0.000051  |    0.013472     |   2\n",
      "      13811 |   0.000051  |    0.054560     |   2\n",
      "      13812 |   0.000051  |    0.085627     |   2\n",
      "      13813 |   0.220069  |    0.155088     |   1\n",
      "      13814 |   0.238929  |    0.135430     |   1\n",
      "      13815 |   0.173910  |    0.008667     |   0\n",
      "      13816 |   0.142188  |    0.078494     |   0\n",
      "      13817 |   0.194813  |    0.044567     |   0\n",
      "      13818 |   0.194303  |    0.030176     |   0\n",
      "      13819 |   0.162665  |    0.205375     |   1\n",
      "      13820 |   0.171636  |    0.010948     |   0\n",
      "      13821 |   0.206040  |    0.227042     |   1\n",
      "      13822 |   0.199759  |    0.140947     |   1\n",
      "      13823 | \u001b[94m  0.000051\u001b[0m  |    0.007283     |   2\n",
      "      13824 | \u001b[94m  0.000051\u001b[0m  |    0.074980     |   2\n",
      "      13825 |   0.134472  |    0.159494     |   1\n",
      "      13826 |   0.202256  |    0.043186     |   0\n",
      "      13827 |   0.055545  |    0.069258     |   2\n",
      "      13828 |   0.059359  |    0.024099     |   2\n",
      "      13829 |   0.203193  |    0.081646     |   0\n",
      "      13830 |   0.188107  |    0.154385     |   1\n",
      "      13831 |   0.207679  |    0.164634     |   1\n",
      "      13832 |   0.177557  |    0.148732     |   1\n",
      "      13833 |   0.165442  |    0.151282     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 13834: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      13834 |   0.259196  |    0.144122     |   1\n",
      "      13835 |   0.197730  |    0.153124     |   1\n",
      "      13836 |   0.052858  |    0.059055     |   2\n",
      "      13837 |   0.198903  |    0.134552     |   1\n",
      "      13838 |   0.038401  |    0.070877     |   2\n",
      "      13839 |   0.044725  |    0.028551     |   2\n",
      "      13840 |   0.050335  |    0.074124     |   2\n",
      "      13841 |   0.028546  |    0.021671     |   2\n",
      "      13842 |   0.043025  |    0.078666     |   2\n",
      "      13843 |   0.054185  |    0.023137     |   2\n",
      "      13844 |   0.284769  |    0.208540     |   1\n",
      "      13845 |   0.205735  |    0.161481     |   1\n",
      "      13846 |   0.059670  |    0.004338     |   2\n",
      "      13847 |   0.233032  |    0.210600     |   1\n",
      "      13848 |   0.243286  |    0.044370     |   0\n",
      "      13849 |   0.244761  |    0.186654     |   1\n",
      "      13850 |   0.051037  |    0.031667     |   2\n",
      "      13851 |   0.277584  |    0.081562     |   0\n",
      "      13852 |   0.025037  |    0.005447     |   2\n",
      "      13853 | \u001b[94m  0.000051\u001b[0m  |    0.063015     |   2\n",
      "      13854 |   0.180946  |    0.047492     |   0\n",
      "      13855 |   0.179318  |    0.081142     |   0\n",
      "      13856 |   0.007019  |    0.086284     |   2\n",
      "      13857 |   0.247350  |    0.074693     |   0\n",
      "      13858 |   0.072662  |    0.080145     |   2\n",
      "      13859 |   0.226571  |    0.279205     |   1\n",
      "      13860 |   0.034997  |    0.003647     |   2\n",
      "      13861 |   0.229788  |    0.077245     |   0\n",
      "      13862 |   0.152806  |    0.048968     |   0\n",
      "      13863 |   0.063555  |    0.077197     |   2\n",
      "      13864 |   0.045982  |    0.041682     |   2\n",
      "      13865 |   0.178034  |    0.049563     |   0\n",
      "      13866 |   0.017913  |    0.056246     |   2\n",
      "      13867 |   0.170896  |    0.202706     |   1\n",
      "      13868 |   0.040750  |    0.006309     |   2\n",
      "      13869 |   0.031705  |    0.043594     |   2\n",
      "      13870 |   0.184162  |    0.078922     |   0\n",
      "      13871 |   0.203698  |    0.146724     |   1\n",
      "      13872 |   0.214464  |    0.052216     |   0\n",
      "      13873 |   0.192036  |    0.100538     |   0\n",
      "      13874 |   0.181705  |    0.159377     |   1\n",
      "      13875 |   0.232150  |    0.015619     |   0\n",
      "      13876 |   0.168065  |    0.077367     |   0\n",
      "      13877 | \u001b[94m  0.000050\u001b[0m  |    0.035458     |   2\n",
      "      13878 | \u001b[94m  0.000050\u001b[0m  |    0.078410     |   2\n",
      "      13879 | \u001b[94m  0.000049\u001b[0m  |    0.029725     |   2\n",
      "      13880 |   0.217589  |    0.200429     |   1\n",
      "      13881 |   0.189553  |    0.019843     |   0\n",
      "      13882 |   0.219404  |    0.059451     |   0\n",
      "      13883 |   0.211732  |    0.203417     |   1\n",
      "      13884 |   0.000050  |    0.024260     |   2\n",
      "      13885 |   0.184423  |    0.097842     |   0\n",
      "      13886 |   0.189837  |    0.113941     |   1\n",
      "      13887 |   0.227282  |    0.211243     |   1\n",
      "      13888 | \u001b[94m  0.000049\u001b[0m  |    0.007107     |   2\n",
      "      13889 |   0.148914  |    0.086067     |   0\n",
      "      13890 | \u001b[94m  0.000049\u001b[0m  |    0.023440     |   2\n",
      "      13891 |   0.060425  |    0.085290     |   2\n",
      "      13892 |   0.058864  |    0.045978     |   2\n",
      "      13893 |   0.198625  |    0.156088     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 13894: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      13894 |   0.176463  |    0.015588     |   0\n",
      "      13895 |   0.149000  |    0.045898     |   0\n",
      "      13896 |   0.216310  |    0.052486     |   0\n",
      "      13897 |   0.199540  |    0.078288     |   0\n",
      "      13898 |   0.205328  |    0.157668     |   1\n",
      "      13899 |   0.055245  |    0.039645     |   2\n",
      "      13900 |   0.041601  |    0.037998     |   2\n",
      "      13901 |   0.190296  |    0.203862     |   1\n",
      "      13902 |   0.044622  |    0.037381     |   2\n",
      "      13903 |   0.052035  |    0.048299     |   2\n",
      "      13904 |   0.029967  |    0.055082     |   2\n",
      "      13905 |   0.215926  |    0.059631     |   0\n",
      "      13906 |   0.205669  |    0.148504     |   1\n",
      "      13907 |   0.190692  |    0.039158     |   0\n",
      "      13908 |   0.241240  |    0.045843     |   0\n",
      "      13909 |   0.189458  |    0.047461     |   0\n",
      "      13910 |   0.043454  |    0.080613     |   2\n",
      "      13911 |   0.183054  |    0.026700     |   0\n",
      "      13912 |   0.056997  |    0.082242     |   2\n",
      "      13913 |   0.062099  |    0.040422     |   2\n",
      "      13914 |   0.179376  |    0.204688     |   1\n",
      "      13915 |   0.050410  |    0.024795     |   2\n",
      "      13916 |   0.023939  |    0.089291     |   2\n",
      "      13917 |   0.000049  |    0.021894     |   2\n",
      "      13918 |   0.260437  |    0.190574     |   1\n",
      "      13919 |   0.206738  |    0.041186     |   0\n",
      "      13920 |   0.180794  |    0.228544     |   1\n",
      "      13921 |   0.170725  |    0.005182     |   0\n",
      "      13922 |   0.007106  |    0.077012     |   2\n",
      "      13923 |   0.075793  |    0.023085     |   2\n",
      "      13924 |   0.039319  |    0.053880     |   2\n",
      "      13925 |   0.185281  |    0.144017     |   1\n",
      "      13926 |   0.065511  |    0.050798     |   2\n",
      "      13927 |   0.266934  |    0.192685     |   1\n",
      "      13928 |   0.047137  |    0.004610     |   2\n",
      "      13929 |   0.241043  |    0.077761     |   0\n",
      "      13930 |   0.219822  |    0.018696     |   0\n",
      "      13931 |   0.019210  |    0.087623     |   2\n",
      "      13932 |   0.143354  |    0.222704     |   1\n",
      "      13933 |   0.197432  |    0.095582     |   0\n",
      "      13934 |   0.242121  |    0.202051     |   1\n",
      "      13935 |   0.195824  |    0.029116     |   0\n",
      "      13936 |   0.181733  |    0.194376     |   1\n",
      "      13937 |   0.156268  |    0.019771     |   0\n",
      "      13938 |   0.266306  |    0.204932     |   1\n",
      "      13939 |   0.169647  |    0.191138     |   1\n",
      "      13940 |   0.150683  |    0.005461     |   0\n",
      "      13941 |   0.169346  |    0.085223     |   0\n",
      "      13942 |   0.213758  |    0.148618     |   1\n",
      "      13943 |   0.283175  |    0.146251     |   1\n",
      "      13944 |   0.205391  |    0.219814     |   1\n",
      "      13945 |   0.275754  |    0.087532     |   1\n",
      "      13946 |   0.203162  |    0.024074     |   0\n",
      "      13947 |   0.041803  |    0.070682     |   2\n",
      "      13948 |   0.035784  |    0.043633     |   2\n",
      "      13949 |   0.159179  |    0.026645     |   0\n",
      "      13950 |   0.000050  |    0.079964     |   2\n",
      "      13951 |   0.224398  |    0.026114     |   0\n",
      "      13952 |   0.215994  |    0.074863     |   0\n",
      "      13953 |   0.000050  |    0.027928     |   2\n",
      "      13954 |   0.210973  |    0.252766     |   1\n",
      "      13955 |   0.000050  |    0.004136     |   2\n",
      "      13956 |   0.000050  |    0.094236     |   2\n",
      "      13957 |   0.213787  |    0.299185     |   1\n",
      "      13958 |   0.218306  |    0.071476     |   0\n",
      "      13959 |   0.158921  |    0.217403     |   1\n",
      "      13960 |   0.180998  |    0.042127     |   0\n",
      "      13961 |   0.000050  |    0.073178     |   2\n",
      "      13962 |   0.000050  |    0.037537     |   2\n",
      "      13963 |   0.271869  |    0.084348     |   0\n",
      "      13964 |   0.056492  |    0.077709     |   2\n",
      "      13965 |   0.224255  |    0.023637     |   0\n",
      "      13966 |   0.196074  |    0.073395     |   0\n",
      "      13967 |   0.179241  |    0.141102     |   1\n",
      "      13968 |   0.197001  |    0.074951     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 13970: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      13969 |   0.057920  |    0.006489     |   2\n",
      "      13970 |   0.049963  |    0.077006     |   2\n",
      "      13971 |   0.038939  |    0.028319     |   2\n",
      "      13972 |   0.231223  |    0.192976     |   1\n",
      "      13973 |   0.185044  |    0.169928     |   1\n",
      "      13974 |   0.044111  |    0.009804     |   2\n",
      "      13975 |   0.234616  |    0.138229     |   1\n",
      "      13976 |   0.163367  |    0.202172     |   1\n",
      "      13977 |   0.233408  |    0.182169     |   1\n",
      "      13978 |   0.049994  |    0.004628     |   2\n",
      "      13979 |   0.190442  |    0.080270     |   0\n",
      "      13980 |   0.253551  |    0.207378     |   1\n",
      "      13981 |   0.218492  |    0.017878     |   0\n",
      "      13982 |   0.233334  |    0.153745     |   1\n",
      "      13983 |   0.212954  |    0.024190     |   0\n",
      "      13984 |   0.029512  |    0.096318     |   2\n",
      "      13985 |   0.225566  |    0.161996     |   1\n",
      "      13986 |   0.043031  |    0.016102     |   2\n",
      "      13987 |   0.057569  |    0.083764     |   2\n",
      "      13988 |   0.278699  |    0.200371     |   1\n",
      "      13989 |   0.059727  |    0.007116     |   2\n",
      "      13990 |   0.183788  |    0.186326     |   1\n",
      "      13991 |   0.048619  |    0.042282     |   2\n",
      "      13992 |   0.214968  |    0.193401     |   1\n",
      "      13993 |   0.178763  |    0.031028     |   0\n",
      "      13994 |   0.147860  |    0.080759     |   0\n",
      "      13995 |   0.025997  |    0.015193     |   2\n",
      "      13996 |   0.000050  |    0.086221     |   2\n",
      "      13997 |   0.252901  |    0.011608     |   0\n",
      "      13998 |   0.220415  |    0.081172     |   0\n",
      "      13999 |   0.006811  |    0.022955     |   2\n",
      "      14000 |   0.073363  |    0.077432     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 14000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 14000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      14001 |   0.192945  |    0.157963     |   1\n",
      "      14002 |   0.191611  |    0.068969     |   0\n",
      "      14003 |   0.153837  |    0.163910     |   1\n",
      "      14004 |   0.220765  |    0.170699     |   1\n",
      "      14005 |   0.229244  |    0.158118     |   1\n",
      "      14006 |   0.051696  |    0.008786     |   2\n",
      "      14007 |   0.037469  |    0.047914     |   2\n",
      "      14008 |   0.139064  |    0.058096     |   0\n",
      "      14009 |   0.180259  |    0.203778     |   1\n",
      "      14010 |   0.178316  |    0.155698     |   1\n",
      "      14011 |   0.211371  |    0.149572     |   1\n",
      "      14012 |   0.176295  |    0.044864     |   0\n",
      "      14013 |   0.162830  |    0.143195     |   1\n",
      "      14014 |   0.043875  |    0.051889     |   2\n",
      "      14015 |   0.181989  |    0.186410     |   1\n",
      "      14016 |   0.183667  |    0.138230     |   1\n",
      "      14017 |   0.048296  |    0.082540     |   2\n",
      "      14018 |   0.243751  |    0.146622     |   1\n",
      "      14019 |   0.212461  |    0.232489     |   1\n",
      "      14020 |   0.029061  |    0.055221     |   2\n",
      "      14021 |   0.043176  |    0.042794     |   2\n",
      "      14022 |   0.214748  |    0.197564     |   1\n",
      "      14023 |   0.228658  |    0.095740     |   1\n",
      "      14024 |   0.188593  |    0.071579     |   0\n",
      "      14025 |   0.204312  |    0.023024     |   0\n",
      "      14026 |   0.210611  |    0.059853     |   0\n",
      "      14027 |   0.182680  |    0.175351     |   1\n",
      "      14028 |   0.208723  |    0.034982     |   0\n",
      "      14029 |   0.052912  |    0.023403     |   2\n",
      "      14030 |   0.058437  |    0.071076     |   2\n",
      "      14031 |   0.136932  |    0.017844     |   0\n",
      "      14032 |   0.201442  |    0.168401     |   1\n",
      "      14033 |   0.156997  |    0.038844     |   0\n",
      "      14034 |   0.218967  |    0.041901     |   0\n",
      "      14035 |   0.195250  |    0.199934     |   1\n",
      "      14036 |   0.285572  |    0.148460     |   1\n",
      "      14037 |   0.174744  |    0.038422     |   0\n",
      "      14038 |   0.049239  |    0.053255     |   2\n",
      "      14039 |   0.168521  |    0.045535     |   0\n",
      "      14040 |   0.172945  |    0.195517     |   1\n",
      "      14041 |   0.185470  |    0.003935     |   0\n",
      "      14042 |   0.180826  |    0.147445     |   1\n",
      "      14043 |   0.163385  |    0.127496     |   1\n",
      "      14044 |   0.194210  |    0.038554     |   0\n",
      "      14045 |   0.176185  |    0.072365     |   0\n",
      "      14046 |   0.190164  |    0.015657     |   0\n",
      "      14047 |   0.025039  |    0.078357     |   2\n",
      "      14048 | \u001b[94m  0.000048\u001b[0m  |    0.021197     |   2\n",
      "      14049 |   0.192944  |    0.078230     |   0\n",
      "      14050 |   0.155821  |    0.026806     |   0\n",
      "      14051 |   0.201168  |    0.204785     |   1\n",
      "      14052 |   0.007442  |    0.010877     |   2\n",
      "      14053 |   0.172697  |    0.079327     |   0\n",
      "      14054 |   0.191104  |    0.025761     |   0\n",
      "      14055 |   0.073355  |    0.073457     |   2\n",
      "      14056 |   0.242134  |    0.159085     |   1\n",
      "      14057 |   0.205324  |    0.198312     |   1\n",
      "      14058 |   0.204951  |    0.146626     |   1\n",
      "      14059 |   0.161538  |    0.043972     |   0\n",
      "      14060 |   0.040948  |    0.027356     |   2\n",
      "      14061 |   0.220012  |    0.209845     |   1\n",
      "      14062 |   0.167677  |    0.011283     |   0\n",
      "      14063 |   0.192701  |    0.205217     |   1\n",
      "      14064 |   0.190867  |    0.198382     |   1\n",
      "      14065 |   0.066198  |    0.024573     |   2\n",
      "      14066 |   0.184777  |    0.082987     |   0\n",
      "      14067 |   0.155429  |    0.014327     |   0\n",
      "      14068 |   0.249443  |    0.203661     |   1\n",
      "      14069 |   0.047940  |    0.013632     |   2\n",
      "      14070 |   0.021486  |    0.079842     |   2\n",
      "      14071 |   0.049677  |    0.028232     |   2\n",
      "      14072 |   0.034084  |    0.081990     |   2\n",
      "      14073 |   0.205428  |    0.134327     |   1\n",
      "      14074 |   0.196515  |    0.184286     |   1\n",
      "      14075 |   0.000049  |    0.006900     |   2\n",
      "      14076 |   0.234964  |    0.044875     |   0\n",
      "      14077 |   0.156463  |    0.199803     |   1\n",
      "      14078 |   0.192339  |    0.153801     |   1\n",
      "      14079 |   0.000049  |    0.023381     |   2\n",
      "      14080 |   0.000049  |    0.073873     |   2\n",
      "      14081 |   0.236032  |    0.048201     |   0\n",
      "      14082 |   0.156112  |    0.041001     |   0\n",
      "      14083 |   0.178941  |    0.041911     |   0\n",
      "      14084 |   0.212907  |    0.188351     |   1\n",
      "      14085 |   0.171718  |    0.144820     |   1\n",
      "      14086 |   0.183754  |    0.018421     |   0\n",
      "      14087 |   0.000049  |    0.052950     |   2\n",
      "      14088 |   0.167858  |    0.188791     |   1\n",
      "      14089 |   0.000049  |    0.039127     |   2\n",
      "      14090 |   0.000049  |    0.074297     |   2\n",
      "      14091 |   0.052202  |    0.030943     |   2\n",
      "      14092 |   0.216159  |    0.174716     |   1\n",
      "      14093 |   0.272018  |    0.170525     |   1\n",
      "      14094 |   0.057554  |    0.025197     |   2\n",
      "      14095 |   0.207977  |    0.074199     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 14096: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      14096 |   0.050167  |    0.009340     |   2\n",
      "      14097 |   0.037917  |    0.077104     |   2\n",
      "      14098 |   0.198613  |    0.043427     |   0\n",
      "      14099 |   0.231544  |    0.078162     |   0\n",
      "      14100 |   0.171627  |    0.031981     |   0\n",
      "      14101 |   0.222451  |    0.074329     |   0\n",
      "      14102 |   0.204806  |    0.038483     |   0\n",
      "      14103 |   0.253142  |    0.145248     |   1\n",
      "      14104 |   0.213401  |    0.077183     |   0\n",
      "      14105 |   0.201660  |    0.052535     |   0\n",
      "      14106 |   0.241935  |    0.187230     |   1\n",
      "      14107 |   0.211822  |    0.004982     |   0\n",
      "      14108 |   0.226735  |    0.039327     |   0\n",
      "      14109 |   0.180617  |    0.071757     |   0\n",
      "      14110 |   0.189538  |    0.154774     |   1\n",
      "      14111 |   0.205767  |    0.039453     |   0\n",
      "      14112 |   0.174428  |    0.161750     |   1\n",
      "      14113 |   0.173944  |    0.205038     |   1\n",
      "      14114 |   0.043559  |    0.006016     |   2\n",
      "      14115 |   0.210187  |    0.086581     |   0\n",
      "      14116 |   0.191634  |    0.135581     |   1\n",
      "      14117 |   0.052462  |    0.050407     |   2\n",
      "      14118 |   0.213583  |    0.177008     |   1\n",
      "      14119 |   0.172006  |    0.015923     |   0\n",
      "      14120 |   0.121768  |    0.078760     |   0\n",
      "      14121 |   0.030308  |    0.044625     |   2\n",
      "      14122 |   0.307416  |    0.199159     |   1\n",
      "      14123 |   0.042690  |    0.004406     |   2\n",
      "      14124 |   0.250221  |    0.162349     |   1\n",
      "      14125 |   0.186379  |    0.022888     |   0\n",
      "      14126 |   0.059245  |    0.050682     |   2\n",
      "      14127 |   0.156133  |    0.054177     |   0\n",
      "      14128 |   0.205737  |    0.167233     |   1\n",
      "      14129 |   0.227522  |    0.156488     |   1\n",
      "      14130 |   0.060883  |    0.042879     |   2\n",
      "      14131 |   0.050633  |    0.077001     |   2\n",
      "      14132 |   0.025018  |    0.021031     |   2\n",
      "      14133 |   0.000049  |    0.075438     |   2\n",
      "      14134 |   0.218071  |    0.168377     |   1\n",
      "      14135 |   0.006271  |    0.025872     |   2\n",
      "      14136 |   0.190264  |    0.211206     |   1\n",
      "      14137 |   0.074199  |    0.023487     |   2\n",
      "      14138 |   0.038302  |    0.053821     |   2\n",
      "      14139 |   0.240664  |    0.163916     |   1\n",
      "      14140 |   0.182146  |    0.076168     |   0\n",
      "      14141 |   0.203025  |    0.166369     |   1\n",
      "      14142 |   0.226771  |    0.007438     |   0\n",
      "      14143 |   0.221166  |    0.076370     |   0\n",
      "      14144 |   0.169936  |    0.035522     |   0\n",
      "      14145 |   0.238100  |    0.149145     |   1\n",
      "      14146 |   0.064003  |    0.044435     |   2\n",
      "      14147 |   0.045808  |    0.052512     |   2\n",
      "      14148 |   0.230205  |    0.142764     |   1\n",
      "      14149 |   0.203766  |    0.045411     |   0\n",
      "      14150 |   0.191638  |    0.056547     |   0\n",
      "      14151 |   0.018418  |    0.041441     |   2\n",
      "      14152 |   0.237909  |    0.223462     |   1\n",
      "      14153 |   0.248248  |    0.144104     |   1\n",
      "      14154 |   0.253602  |    0.150023     |   1\n",
      "      14155 |   0.043148  |    0.010469     |   2\n",
      "      14156 |   0.186598  |    0.199903     |   1\n",
      "      14157 |   0.184561  |    0.010996     |   0\n",
      "      14158 |   0.237092  |    0.200817     |   1\n",
      "      14159 |   0.162061  |    0.143033     |   1\n",
      "      14160 |   0.190944  |    0.042326     |   0\n",
      "      14161 |   0.032884  |    0.045166     |   2\n",
      "      14162 |   0.155244  |    0.202956     |   1\n",
      "      14163 |   0.209073  |    0.150464     |   1\n",
      "      14164 |   0.000049  |    0.012028     |   2\n",
      "      14165 |   0.176567  |    0.205882     |   1\n",
      "      14166 |   0.168879  |    0.008129     |   0\n",
      "      14167 |   0.194520  |    0.071110     |   0\n",
      "      14168 |   0.217902  |    0.158599     |   1\n",
      "      14169 |   0.193039  |    0.163570     |   1\n",
      "      14170 |   0.148966  |    0.217920     |   1\n",
      "      14171 |   0.188202  |    0.031146     |   0\n",
      "      14172 |   0.000048  |    0.065404     |   2\n",
      "      14173 |   0.177648  |    0.040961     |   0\n",
      "      14174 |   0.177490  |    0.082751     |   0\n",
      "      14175 |   0.212343  |    0.147314     |   1\n",
      "      14176 | \u001b[94m  0.000048\u001b[0m  |    0.014588     |   2\n",
      "      14177 |   0.000048  |    0.050111     |   2\n",
      "      14178 | \u001b[94m  0.000048\u001b[0m  |    0.051388     |   2\n",
      "      14179 |   0.177822  |    0.049754     |   0\n",
      "      14180 |   0.178898  |    0.146701     |   1\n",
      "      14181 |   0.164613  |    0.049004     |   0\n",
      "      14182 | \u001b[94m  0.000048\u001b[0m  |    0.049250     |   2\n",
      "      14183 |   0.053068  |    0.075460     |   2\n",
      "      14184 |   0.057831  |    0.024940     |   2\n",
      "      14185 |   0.222411  |    0.090265     |   0\n",
      "      14186 |   0.165209  |    0.215543     |   1\n",
      "      14187 |   0.213220  |    0.143809     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 14189: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      14188 |   0.203457  |    0.038755     |   0\n",
      "      14189 |   0.200354  |    0.076692     |   0\n",
      "      14190 |   0.202620  |    0.036765     |   0\n",
      "      14191 |   0.054653  |    0.030144     |   2\n",
      "      14192 |   0.260342  |    0.259391     |   1\n",
      "      14193 |   0.188502  |    0.260410     |   1\n",
      "      14194 |   0.202266  |    0.013627     |   0\n",
      "      14195 |   0.043781  |    0.076569     |   2\n",
      "      14196 |   0.175061  |    0.025651     |   0\n",
      "      14197 |   0.250002  |    0.076656     |   0\n",
      "      14198 |   0.185293  |    0.021416     |   0\n",
      "      14199 |   0.043173  |    0.075495     |   2\n",
      "      14200 |   0.177283  |    0.010914     |   0\n",
      "      14201 |   0.169702  |    0.081817     |   0\n",
      "      14202 |   0.185377  |    0.152702     |   1\n",
      "      14203 |   0.235412  |    0.149354     |   1\n",
      "      14204 |   0.233551  |    0.115133     |   1\n",
      "      14205 |   0.241014  |    0.196567     |   1\n",
      "      14206 |   0.149204  |    0.131471     |   1\n",
      "      14207 |   0.051841  |    0.073214     |   2\n",
      "      14208 |   0.173356  |    0.028304     |   0\n",
      "      14209 |   0.244244  |    0.262383     |   1\n",
      "      14210 |   0.162338  |    0.205297     |   1\n",
      "      14211 |   0.166181  |    0.130973     |   1\n",
      "      14212 |   0.189854  |    0.200572     |   1\n",
      "      14213 |   0.237271  |    0.129023     |   1\n",
      "      14214 |   0.029223  |    0.012308     |   2\n",
      "      14215 |   0.045061  |    0.080629     |   2\n",
      "      14216 |   0.140352  |    0.020230     |   0\n",
      "      14217 |   0.056911  |    0.074685     |   2\n",
      "      14218 |   0.062210  |    0.027627     |   2\n",
      "      14219 |   0.148078  |    0.160670     |   1\n",
      "      14220 |   0.136933  |    0.202854     |   1\n",
      "      14221 |   0.172199  |    0.144722     |   1\n",
      "      14222 |   0.056131  |    0.010443     |   2\n",
      "      14223 |   0.171588  |    0.227044     |   1\n",
      "      14224 |   0.225254  |    0.147973     |   1\n",
      "      14225 |   0.262980  |    0.016589     |   0\n",
      "      14226 |   0.217619  |    0.071785     |   0\n",
      "      14227 |   0.182950  |    0.040573     |   0\n",
      "      14228 |   0.163458  |    0.031934     |   0\n",
      "      14229 |   0.025576  |    0.074988     |   2\n",
      "      14230 |   0.263637  |    0.149728     |   1\n",
      "      14231 |   0.000048  |    0.006349     |   2\n",
      "      14232 |   0.194245  |    0.083724     |   0\n",
      "      14233 |   0.154072  |    0.136643     |   1\n",
      "      14234 |   0.263048  |    0.142676     |   1\n",
      "      14235 |   0.178758  |    0.140219     |   1\n",
      "      14236 |   0.006739  |    0.080432     |   2\n",
      "      14237 |   0.075470  |    0.023081     |   2\n",
      "      14238 |   0.204869  |    0.209236     |   1\n",
      "      14239 |   0.177016  |    0.134435     |   1\n",
      "      14240 |   0.040197  |    0.042842     |   2\n",
      "      14241 |   0.234908  |    0.041454     |   0\n",
      "      14242 |   0.243147  |    0.073744     |   0\n",
      "      14243 |   0.220947  |    0.020000     |   0\n",
      "      14244 |   0.155940  |    0.047935     |   0\n",
      "      14245 |   0.312657  |    0.139759     |   1\n",
      "      14246 |   0.063510  |    0.003694     |   2\n",
      "      14247 |   0.181370  |    0.047367     |   0\n",
      "      14248 |   0.049939  |    0.071035     |   2\n",
      "      14249 |   0.198054  |    0.193384     |   1\n",
      "      14250 |   0.019446  |    0.006243     |   2\n",
      "      14251 |   0.044859  |    0.081377     |   2\n",
      "      14252 |   0.160053  |    0.028749     |   0\n",
      "      14253 |   0.244698  |    0.195299     |   1\n",
      "      14254 |   0.035730  |    0.005663     |   2\n",
      "      14255 | \u001b[94m  0.000047\u001b[0m  |    0.080783     |   2\n",
      "      14256 |   0.203576  |    0.130566     |   1\n",
      "      14257 | \u001b[94m  0.000047\u001b[0m  |    0.021441     |   2\n",
      "      14258 |   0.000047  |    0.082191     |   2\n",
      "      14259 |   0.154375  |    0.025511     |   0\n",
      "      14260 |   0.197845  |    0.045691     |   0\n",
      "      14261 |   0.000047  |    0.080404     |   2\n",
      "      14262 |   0.239637  |    0.138157     |   1\n",
      "      14263 | \u001b[94m  0.000047\u001b[0m  |    0.050099     |   2\n",
      "      14264 | \u001b[94m  0.000047\u001b[0m  |    0.037684     |   2\n",
      "      14265 |   0.055254  |    0.047458     |   2\n",
      "      14266 |   0.058178  |    0.061054     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 14267: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      14267 |   0.180210  |    0.184289     |   1\n",
      "      14268 |   0.049817  |    0.015054     |   2\n",
      "      14269 |   0.279220  |    0.199165     |   1\n",
      "      14270 |   0.036282  |    0.005690     |   2\n",
      "      14271 |   0.041848  |    0.081477     |   2\n",
      "      14272 |   0.051118  |    0.037954     |   2\n",
      "      14273 |   0.028821  |    0.039359     |   2\n",
      "      14274 |   0.165727  |    0.095037     |   0\n",
      "      14275 |   0.239955  |    0.144670     |   1\n",
      "      14276 |   0.043539  |    0.015419     |   2\n",
      "      14277 |   0.132810  |    0.216088     |   1\n",
      "      14278 |   0.253642  |    0.119866     |   1\n",
      "      14279 |   0.197708  |    0.042521     |   0\n",
      "      14280 |   0.207226  |    0.061537     |   0\n",
      "      14281 |   0.250696  |    0.141670     |   1\n",
      "      14282 |   0.163144  |    0.054064     |   0\n",
      "      14283 |   0.228766  |    0.202238     |   1\n",
      "      14284 |   0.220249  |    0.012298     |   0\n",
      "      14285 |   0.210588  |    0.149536     |   1\n",
      "      14286 |   0.186651  |    0.046523     |   0\n",
      "      14287 |   0.219817  |    0.025854     |   0\n",
      "      14288 |   0.053424  |    0.048726     |   2\n",
      "      14289 |   0.185488  |    0.207804     |   1\n",
      "      14290 |   0.220456  |    0.140977     |   1\n",
      "      14291 |   0.060807  |    0.006480     |   2\n",
      "      14292 |   0.051892  |    0.100108     |   2\n",
      "      14293 |   0.257815  |    0.145646     |   1\n",
      "      14294 |   0.194344  |    0.142410     |   1\n",
      "      14295 |   0.028089  |    0.024202     |   2\n",
      "      14296 | \u001b[94m  0.000047\u001b[0m  |    0.049039     |   2\n",
      "      14297 |   0.192928  |    0.194781     |   1\n",
      "      14298 |   0.170975  |    0.140186     |   1\n",
      "      14299 |   0.207645  |    0.041330     |   0\n",
      "      14300 |   0.162976  |    0.047293     |   0\n",
      "      14301 |   0.193926  |    0.155012     |   1\n",
      "      14302 |   0.235219  |    0.051138     |   0\n",
      "      14303 |   0.211088  |    0.048132     |   0\n",
      "      14304 |   0.006852  |    0.040473     |   2\n",
      "      14305 |   0.215522  |    0.084580     |   0\n",
      "      14306 |   0.075758  |    0.013854     |   2\n",
      "      14307 |   0.204442  |    0.221219     |   1\n",
      "      14308 |   0.205674  |    0.164121     |   1\n",
      "      14309 |   0.037198  |    0.005212     |   2\n",
      "      14310 |   0.061271  |    0.081726     |   2\n",
      "      14311 |   0.048579  |    0.015083     |   2\n",
      "      14312 |   0.224104  |    0.046645     |   0\n",
      "      14313 |   0.190985  |    0.080197     |   0\n",
      "      14314 |   0.016753  |    0.011782     |   2\n",
      "      14315 |   0.184718  |    0.172256     |   1\n",
      "      14316 |   0.204485  |    0.039404     |   0\n",
      "      14317 |   0.163350  |    0.168599     |   1\n",
      "      14318 |   0.144012  |    0.169331     |   1\n",
      "      14319 |   0.160480  |    0.157742     |   1\n",
      "      14320 |   0.228036  |    0.197038     |   1\n",
      "      14321 |   0.276847  |    0.142257     |   1\n",
      "      14322 |   0.042116  |    0.008407     |   2\n",
      "      14323 |   0.033272  |    0.083395     |   2\n",
      "      14324 |   0.243131  |    0.188017     |   1\n",
      "      14325 |   0.162223  |    0.154992     |   1\n",
      "      14326 |   0.199482  |    0.031748     |   0\n",
      "      14327 |   0.216940  |    0.201049     |   1\n",
      "      14328 | \u001b[94m  0.000046\u001b[0m  |    0.014748     |   2\n",
      "      14329 |   0.264801  |    0.070653     |   0\n",
      "      14330 | \u001b[94m  0.000046\u001b[0m  |    0.042179     |   2\n",
      "      14331 |   0.000046  |    0.044228     |   2\n",
      "      14332 |   0.000046  |    0.072545     |   2\n",
      "      14333 |   0.205609  |    0.160637     |   1\n",
      "      14334 |   0.154390  |    0.025497     |   0\n",
      "      14335 |   0.190291  |    0.080934     |   0\n",
      "      14336 | \u001b[94m  0.000046\u001b[0m  |    0.041553     |   2\n",
      "      14337 |   0.216207  |    0.166213     |   1\n",
      "      14338 |   0.251536  |    0.198090     |   1\n",
      "      14339 |   0.205640  |    0.056326     |   0\n",
      "      14340 | \u001b[94m  0.000046\u001b[0m  |    0.009909     |   2\n",
      "      14341 |   0.172072  |    0.075013     |   0\n",
      "      14342 |   0.250280  |    0.016273     |   0\n",
      "      14343 |   0.181180  |    0.085049     |   0\n",
      "      14344 |   0.209657  |    0.008108     |   0\n",
      "      14345 |   0.163603  |    0.075809     |   0\n",
      "      14346 |   0.053055  |    0.025286     |   2\n",
      "      14347 |   0.057203  |    0.048655     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 14348: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      14348 |   0.136680  |    0.044034     |   0\n",
      "      14349 |   0.174699  |    0.042945     |   0\n",
      "      14350 |   0.215374  |    0.078469     |   0\n",
      "      14351 |   0.052161  |    0.027709     |   2\n",
      "      14352 |   0.168707  |    0.190417     |   1\n",
      "      14353 |   0.039068  |    0.006349     |   2\n",
      "      14354 |   0.042897  |    0.074000     |   2\n",
      "      14355 |   0.048982  |    0.022136     |   2\n",
      "      14356 |   0.191646  |    0.211493     |   1\n",
      "      14357 |   0.214838  |    0.147756     |   1\n",
      "      14358 |   0.218145  |    0.053205     |   0\n",
      "      14359 |   0.269028  |    0.189604     |   1\n",
      "      14360 |   0.209216  |    0.031891     |   0\n",
      "      14361 |   0.186496  |    0.161459     |   1\n",
      "      14362 |   0.029657  |    0.047493     |   2\n",
      "      14363 |   0.163486  |    0.040540     |   0\n",
      "      14364 |   0.175405  |    0.210320     |   1\n",
      "      14365 |   0.184457  |    0.195453     |   1\n",
      "      14366 |   0.247180  |    0.131036     |   1\n",
      "      14367 |   0.217732  |    0.042293     |   0\n",
      "      14368 |   0.044045  |    0.042365     |   2\n",
      "      14369 |   0.057455  |    0.057062     |   2\n",
      "      14370 |   0.062386  |    0.041568     |   2\n",
      "      14371 |   0.277397  |    0.041949     |   0\n",
      "      14372 |   0.190552  |    0.043598     |   0\n",
      "      14373 |   0.200462  |    0.103811     |   0\n",
      "      14374 |   0.284245  |    0.169260     |   1\n",
      "      14375 |   0.175946  |    0.080541     |   0\n",
      "      14376 |   0.167451  |    0.044468     |   0\n",
      "      14377 |   0.162666  |    0.284288     |   1\n",
      "      14378 |   0.049138  |    0.071633     |   2\n",
      "      14379 |   0.025392  |    0.054167     |   2\n",
      "      14380 |   0.229357  |    0.058772     |   0\n",
      "      14381 | \u001b[94m  0.000046\u001b[0m  |    0.037243     |   2\n",
      "      14382 |   0.162738  |    0.091610     |   0\n",
      "      14383 |   0.178017  |    0.053782     |   0\n",
      "      14384 |   0.156727  |    0.274312     |   1\n",
      "      14385 |   0.006664  |    0.068917     |   2\n",
      "      14386 |   0.073248  |    0.078025     |   2\n",
      "      14387 |   0.204319  |    0.298677     |   1\n",
      "      14388 |   0.233214  |    0.270513     |   1\n",
      "      14389 |   0.037162  |    0.072463     |   2\n",
      "      14390 |   0.195430  |    0.070809     |   0\n",
      "      14391 |   0.249094  |    0.304849     |   1\n",
      "      14392 |   0.065905  |    0.072372     |   2\n",
      "      14393 |   0.051203  |    0.124725     |   2\n",
      "      14394 |   0.227417  |    0.296109     |   1\n",
      "      14395 |   0.217395  |    0.332297     |   1\n",
      "      14396 |   0.018203  |    0.037353     |   2\n",
      "      14397 |   0.174375  |    0.381586     |   1\n",
      "      14398 |   0.245272  |    0.223593     |   1\n",
      "      14399 |   0.174896  |    0.321947     |   1\n",
      "      14400 |   0.199858  |    0.132337     |   0\n",
      "      14401 |   0.197569  |    0.069238     |   0\n",
      "      14402 |   0.042126  |    0.121970     |   2\n",
      "      14403 |   0.221683  |    0.270559     |   1\n",
      "      14404 |   0.202972  |    0.283394     |   1\n",
      "      14405 |   0.184569  |    0.326802     |   1\n",
      "      14406 |   0.207802  |    0.083440     |   0\n",
      "      14407 |   0.212493  |    0.394937     |   1\n",
      "      14408 |   0.177034  |    0.326528     |   1\n",
      "      14409 |   0.199854  |    0.376596     |   1\n",
      "      14410 |   0.211981  |    0.322279     |   1\n",
      "      14411 |   0.031358  |    0.069264     |   2\n",
      "      14412 |   0.000046  |    0.123830     |   2\n",
      "      14413 |   0.230188  |    0.277299     |   1\n",
      "      14414 |   0.172045  |    0.072022     |   0\n",
      "      14415 |   0.163512  |    0.122885     |   0\n",
      "      14416 |   0.000046  |    0.037157     |   2\n",
      "      14417 |   0.000046  |    0.121724     |   2\n",
      "      14418 |   0.302103  |    0.274212     |   1\n",
      "      14419 |   0.219107  |    0.075668     |   0\n",
      "      14420 |   0.198784  |    0.073228     |   0\n",
      "      14421 |   0.269903  |    0.286084     |   1\n",
      "      14422 |   0.244651  |    0.120505     |   0\n",
      "      14423 |   0.223175  |    0.279747     |   1\n",
      "      14424 |   0.000046  |    0.036764     |   2\n",
      "      14425 | \u001b[94m  0.000046\u001b[0m  |    0.122479     |   2\n",
      "      14426 | \u001b[94m  0.000046\u001b[0m  |    0.070964     |   2\n",
      "      14427 |   0.053079  |    0.071350     |   2\n",
      "      14428 |   0.181405  |    0.074529     |   0\n",
      "      14429 |   0.215539  |    0.122959     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 14431: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      14430 |   0.057666  |    0.037428     |   2\n",
      "      14431 |   0.165545  |    0.325048     |   1\n",
      "      14432 |   0.053881  |    0.044311     |   2\n",
      "      14433 |   0.151014  |    0.326711     |   1\n",
      "      14434 |   0.160755  |    0.042068     |   0\n",
      "      14435 |   0.209872  |    0.120100     |   0\n",
      "      14436 |   0.208274  |    0.041776     |   0\n",
      "      14437 |   0.120300  |    0.070854     |   0\n",
      "      14438 |   0.185885  |    0.328870     |   1\n",
      "      14439 |   0.150077  |    0.322709     |   1\n",
      "      14440 |   0.160521  |    0.074314     |   0\n",
      "      14441 |   0.157267  |    0.327441     |   1\n",
      "      14442 |   0.196866  |    0.075975     |   0\n",
      "      14443 |   0.244628  |    0.338033     |   1\n",
      "      14444 |   0.040365  |    0.072702     |   2\n",
      "      14445 |   0.201581  |    0.137774     |   0\n",
      "      14446 |   0.202823  |    0.069125     |   0\n",
      "      14447 |   0.213453  |    0.137056     |   0\n",
      "      14448 |   0.171055  |    0.022324     |   0\n",
      "      14449 |   0.176923  |    0.071325     |   0\n",
      "      14450 |   0.044416  |    0.050694     |   2\n",
      "      14451 |   0.241377  |    0.259246     |   1\n",
      "      14452 |   0.233320  |    0.006729     |   0\n",
      "      14453 |   0.049578  |    0.074085     |   2\n",
      "      14454 |   0.029882  |    0.036412     |   2\n",
      "      14455 |   0.178493  |    0.219094     |   1\n",
      "      14456 |   0.187184  |    0.168405     |   1\n",
      "      14457 |   0.045848  |    0.042860     |   2\n",
      "      14458 |   0.056119  |    0.040619     |   2\n",
      "      14459 |   0.222659  |    0.180089     |   1\n",
      "      14460 |   0.200773  |    0.153503     |   1\n",
      "      14461 |   0.236766  |    0.065609     |   0\n",
      "      14462 |   0.061750  |    0.041231     |   2\n",
      "      14463 |   0.182954  |    0.093524     |   0\n",
      "      14464 |   0.197671  |    0.170849     |   1\n",
      "      14465 |   0.047578  |    0.121634     |   2\n",
      "      14466 |   0.147505  |    0.005272     |   0\n",
      "      14467 |   0.198021  |    0.108818     |   0\n",
      "      14468 |   0.165417  |    0.159722     |   1\n",
      "      14469 |   0.024404  |    0.035711     |   2\n",
      "      14470 | \u001b[94m  0.000045\u001b[0m  |    0.052589     |   2\n",
      "      14471 |   0.161886  |    0.045251     |   0\n",
      "      14472 |   0.173353  |    0.084362     |   0\n",
      "      14473 |   0.007072  |    0.011691     |   2\n",
      "      14474 |   0.140177  |    0.252952     |   1\n",
      "      14475 |   0.076160  |    0.011066     |   2\n",
      "      14476 |   0.218926  |    0.172955     |   1\n",
      "      14477 |   0.039291  |    0.040366     |   2\n",
      "      14478 |   0.209073  |    0.077056     |   0\n",
      "      14479 |   0.186576  |    0.030085     |   0\n",
      "      14480 |   0.230657  |    0.198538     |   1\n",
      "      14481 |   0.177307  |    0.004154     |   0\n",
      "      14482 |   0.217467  |    0.076428     |   0\n",
      "      14483 |   0.066993  |    0.035316     |   2\n",
      "      14484 |   0.049576  |    0.076582     |   2\n",
      "      14485 |   0.260504  |    0.165502     |   1\n",
      "      14486 |   0.238489  |    0.024135     |   0\n",
      "      14487 |   0.019216  |    0.078629     |   2\n",
      "      14488 |   0.045957  |    0.065439     |   2\n",
      "      14489 |   0.172542  |    0.030126     |   0\n",
      "      14490 |   0.033837  |    0.044485     |   2\n",
      "      14491 | \u001b[94m  0.000045\u001b[0m  |    0.069289     |   2\n",
      "      14492 |   0.186134  |    0.271316     |   1\n",
      "      14493 |   0.151762  |    0.229010     |   1\n",
      "      14494 |   0.163391  |    0.028603     |   0\n",
      "      14495 |   0.000045  |    0.084951     |   2\n",
      "      14496 |   0.141763  |    0.193138     |   1\n",
      "      14497 |   0.000045  |    0.075177     |   2\n",
      "      14498 |   0.185680  |    0.043635     |   0\n",
      "      14499 |   0.212682  |    0.164049     |   1\n",
      "      14500 |   0.000045  |    0.007567     |   2\n",
      "      14501 |   0.054022  |    0.120970     |   2\n",
      "      14502 |   0.040960  |    0.026067     |   2\n",
      "      14503 |   0.043525  |    0.069793     |   2\n",
      "      14504 |   0.049757  |    0.073819     |   2\n",
      "      14505 |   0.225584  |    0.122411     |   0\n",
      "      14506 |   0.269458  |    0.223098     |   1\n",
      "      14507 |   0.029468  |    0.071566     |   2\n",
      "      14508 |   0.042497  |    0.068764     |   2\n",
      "      14509 |   0.055191  |    0.069756     |   2\n",
      "      14510 |   0.060744  |    0.070606     |   2\n",
      "      14511 |   0.290015  |    0.228469     |   1\n",
      "      14512 |   0.281912  |    0.068882     |   0\n",
      "      14513 |   0.184215  |    0.272797     |   1\n",
      "      14514 |   0.279810  |    0.253033     |   1\n",
      "      14515 |   0.048999  |    0.009246     |   2\n",
      "      14516 |   0.196608  |    0.079035     |   0\n",
      "      14517 |   0.155115  |    0.082635     |   0\n",
      "      14518 |   0.172116  |    0.167774     |   1\n",
      "      14519 |   0.185091  |    0.045798     |   0\n",
      "      14520 |   0.186442  |    0.074816     |   0\n",
      "      14521 |   0.180631  |    0.157259     |   1\n",
      "      14522 |   0.208361  |    0.023586     |   0\n",
      "      14523 |   0.194984  |    0.230055     |   1\n",
      "      14524 |   0.023837  |    0.038656     |   2\n",
      "      14525 |   0.247588  |    0.065610     |   0\n",
      "      14526 |   0.208178  |    0.203015     |   1\n",
      "      14527 | \u001b[94m  0.000045\u001b[0m  |    0.028585     |   2\n",
      "      14528 |   0.006795  |    0.039434     |   2\n",
      "      14529 |   0.072843  |    0.097607     |   2\n",
      "      14530 |   0.152280  |    0.306264     |   1\n",
      "      14531 |   0.179035  |    0.025685     |   0\n",
      "      14532 |   0.169916  |    0.120000     |   0\n",
      "      14533 |   0.186575  |    0.069194     |   0\n",
      "      14534 |   0.163898  |    0.070716     |   0\n",
      "      14535 |   0.220299  |    0.122822     |   0\n",
      "      14536 |   0.191459  |    0.070244     |   0\n",
      "      14537 |   0.140857  |    0.071289     |   0\n",
      "      14538 |   0.184045  |    0.068979     |   0\n",
      "      14539 |   0.038903  |    0.068811     |   2\n",
      "      14540 |   0.219897  |    0.390179     |   1\n",
      "      14541 |   0.206121  |    0.277701     |   1\n",
      "      14542 |   0.064120  |    0.072388     |   2\n",
      "      14543 |   0.192745  |    0.089857     |   0\n",
      "      14544 |   0.047889  |    0.069574     |   2\n",
      "      14545 |   0.180049  |    0.073389     |   0\n",
      "      14546 |   0.020070  |    0.070320     |   2\n",
      "      14547 |   0.174034  |    0.131931     |   0\n",
      "      14548 |   0.241973  |    0.075359     |   0\n",
      "      14549 |   0.234844  |    0.122033     |   0\n",
      "      14550 |   0.189613  |    0.241118     |   1\n",
      "      14551 |   0.186283  |    0.138853     |   1\n",
      "      14552 |   0.157033  |    0.134190     |   1\n",
      "      14553 |   0.048685  |    0.040697     |   2\n",
      "      14554 |   0.193996  |    0.048008     |   0\n",
      "      14555 |   0.034587  |    0.073193     |   2\n",
      "      14556 |   0.223785  |    0.027441     |   0\n",
      "      14557 |   0.187112  |    0.182860     |   1\n",
      "      14558 | \u001b[94m  0.000045\u001b[0m  |    0.024366     |   2\n",
      "      14559 |   0.213392  |    0.076322     |   0\n",
      "      14560 |   0.224574  |    0.024402     |   0\n",
      "      14561 |   0.000045  |    0.053756     |   2\n",
      "      14562 |   0.186603  |    0.046601     |   0\n",
      "      14563 |   0.000045  |    0.045309     |   2\n",
      "      14564 |   0.163054  |    0.075665     |   0\n",
      "      14565 |   0.180048  |    0.026191     |   0\n",
      "      14566 |   0.000045  |    0.051730     |   2\n",
      "      14567 |   0.227386  |    0.149148     |   1\n",
      "      14568 |   0.000045  |    0.045913     |   2\n",
      "      14569 |   0.203764  |    0.148457     |   1\n",
      "      14570 |   0.198002  |    0.193294     |   1\n",
      "      14571 |   0.000045  |    0.012242     |   2\n",
      "      14572 |   0.204467  |    0.227403     |   1\n",
      "      14573 |   0.154251  |    0.157322     |   1\n",
      "      14574 |   0.244781  |    0.141206     |   1\n",
      "      14575 |   0.053927  |    0.008420     |   2\n",
      "      14576 |   0.058333  |    0.058039     |   2\n",
      "      14577 |   0.197691  |    0.154319     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 14579: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      14578 |   0.185413  |    0.024224     |   0\n",
      "      14579 |   0.156078  |    0.162922     |   1\n",
      "      14580 |   0.157052  |    0.041308     |   0\n",
      "      14581 |   0.179238  |    0.056378     |   0\n",
      "      14582 |   0.240220  |    0.186634     |   1\n",
      "      14583 |   0.053943  |    0.004471     |   2\n",
      "      14584 |   0.039633  |    0.094555     |   2\n",
      "      14585 |   0.274987  |    0.149347     |   1\n",
      "      14586 |   0.186943  |    0.019119     |   0\n",
      "      14587 |   0.177769  |    0.161949     |   1\n",
      "      14588 |   0.185824  |    0.016891     |   0\n",
      "      14589 |   0.044453  |    0.089820     |   2\n",
      "      14590 |   0.051346  |    0.008759     |   2\n",
      "      14591 |   0.209438  |    0.090914     |   0\n",
      "      14592 |   0.028664  |    0.016295     |   2\n",
      "      14593 |   0.166276  |    0.073234     |   0\n",
      "      14594 |   0.239169  |    0.166960     |   1\n",
      "      14595 |   0.163897  |    0.009919     |   0\n",
      "      14596 |   0.120559  |    0.044496     |   0\n",
      "      14597 |   0.042795  |    0.076973     |   2\n",
      "      14598 |   0.186489  |    0.014587     |   0\n",
      "      14599 |   0.055247  |    0.079532     |   2\n",
      "      14600 |   0.060540  |    0.019082     |   2\n",
      "      14601 |   0.234414  |    0.086938     |   0\n",
      "      14602 |   0.048858  |    0.022922     |   2\n",
      "      14603 |   0.159739  |    0.200651     |   1\n",
      "      14604 |   0.023161  |    0.015862     |   2\n",
      "      14605 |   0.216423  |    0.058868     |   0\n",
      "      14606 |   0.215518  |    0.147451     |   1\n",
      "      14607 |   0.168775  |    0.030545     |   0\n",
      "      14608 |   0.199295  |    0.085735     |   0\n",
      "      14609 |   0.188550  |    0.153790     |   1\n",
      "      14610 |   0.180617  |    0.004149     |   0\n",
      "      14611 |   0.174337  |    0.038052     |   0\n",
      "      14612 |   0.000045  |    0.048782     |   2\n",
      "      14613 |   0.171502  |    0.203372     |   1\n",
      "      14614 |   0.208624  |    0.004730     |   0\n",
      "      14615 |   0.178987  |    0.041058     |   0\n",
      "      14616 |   0.006128  |    0.043676     |   2\n",
      "      14617 |   0.174236  |    0.183489     |   1\n",
      "      14618 |   0.274877  |    0.152181     |   1\n",
      "      14619 |   0.072850  |    0.010136     |   2\n",
      "      14620 |   0.212331  |    0.228815     |   1\n",
      "      14621 |   0.212871  |    0.006802     |   0\n",
      "      14622 |   0.247659  |    0.170405     |   1\n",
      "      14623 |   0.173780  |    0.037368     |   0\n",
      "      14624 |   0.186404  |    0.208966     |   1\n",
      "      14625 |   0.147654  |    0.127790     |   1\n",
      "      14626 |   0.197741  |    0.041321     |   0\n",
      "      14627 |   0.038655  |    0.072215     |   2\n",
      "      14628 |   0.176938  |    0.026455     |   0\n",
      "      14629 |   0.176404  |    0.048229     |   0\n",
      "      14630 |   0.190678  |    0.040454     |   0\n",
      "      14631 |   0.200040  |    0.080328     |   0\n",
      "      14632 |   0.219363  |    0.126888     |   1\n",
      "      14633 |   0.064581  |    0.041159     |   2\n",
      "      14634 |   0.049855  |    0.050339     |   2\n",
      "      14635 |   0.020286  |    0.049322     |   2\n",
      "      14636 |   0.151126  |    0.042127     |   0\n",
      "      14637 |   0.045158  |    0.072079     |   2\n",
      "      14638 |   0.136460  |    0.020206     |   0\n",
      "      14639 |   0.033489  |    0.059995     |   2\n",
      "      14640 |   0.149943  |    0.150023     |   1\n",
      "      14641 |   0.203018  |    0.141967     |   1\n",
      "      14642 |   0.000045  |    0.012139     |   2\n",
      "      14643 |   0.233969  |    0.188448     |   1\n",
      "      14644 |   0.161273  |    0.166090     |   1\n",
      "      14645 |   0.242248  |    0.144242     |   1\n",
      "      14646 |   0.181767  |    0.119431     |   1\n",
      "      14647 |   0.226747  |    0.181428     |   1\n",
      "      14648 |   0.172058  |    0.144138     |   1\n",
      "      14649 |   0.171663  |    0.040025     |   0\n",
      "      14650 |   0.129209  |    0.081239     |   0\n",
      "      14651 |   0.211037  |    0.136518     |   1\n",
      "      14652 |   0.183586  |    0.016123     |   0\n",
      "      14653 |   0.186263  |    0.205486     |   1\n",
      "      14654 |   0.220412  |    0.171386     |   1\n",
      "      14655 |   0.186064  |    0.138716     |   1\n",
      "      14656 |   0.153377  |    0.009823     |   0\n",
      "      14657 |   0.000045  |    0.083880     |   2\n",
      "      14658 |   0.000045  |    0.024433     |   2\n",
      "      14659 |   0.137655  |    0.047378     |   0\n",
      "      14660 |   0.000046  |    0.077966     |   2\n",
      "      14661 |   0.248525  |    0.148938     |   1\n",
      "      14662 |   0.237075  |    0.042412     |   0\n",
      "      14663 |   0.000045  |    0.051330     |   2\n",
      "      14664 |   0.242646  |    0.156823     |   1\n",
      "      14665 |   0.174868  |    0.203844     |   1\n",
      "      14666 |   0.000046  |    0.014011     |   2\n",
      "      14667 |   0.255575  |    0.194337     |   1\n",
      "      14668 |   0.223301  |    0.026513     |   0\n",
      "      14669 |   0.181275  |    0.190183     |   1\n",
      "      14670 |   0.182630  |    0.188335     |   1\n",
      "      14671 |   0.189655  |    0.005004     |   0\n",
      "      14672 |   0.053680  |    0.078811     |   2\n",
      "      14673 |   0.202644  |    0.192165     |   1\n",
      "      14674 |   0.202905  |    0.020309     |   0\n",
      "      14675 |   0.184298  |    0.226174     |   1\n",
      "      14676 |   0.056408  |    0.015244     |   2\n",
      "      14677 |   0.197548  |    0.204019     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 14678: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      14678 |   0.213746  |    0.111985     |   1\n",
      "      14679 |   0.157913  |    0.148655     |   1\n",
      "      14680 |   0.158533  |    0.045154     |   0\n",
      "      14681 |   0.051613  |    0.053148     |   2\n",
      "      14682 |   0.181235  |    0.159658     |   1\n",
      "      14683 |   0.245641  |    0.156031     |   1\n",
      "      14684 |   0.160681  |    0.005096     |   0\n",
      "      14685 |   0.038786  |    0.076833     |   2\n",
      "      14686 |   0.136666  |    0.025394     |   0\n",
      "      14687 |   0.201263  |    0.076768     |   0\n",
      "      14688 |   0.233757  |    0.138173     |   1\n",
      "      14689 |   0.181390  |    0.016095     |   0\n",
      "      14690 |   0.177497  |    0.082175     |   0\n",
      "      14691 |   0.184716  |    0.034906     |   0\n",
      "      14692 |   0.201640  |    0.201668     |   1\n",
      "      14693 |   0.044829  |    0.012743     |   2\n",
      "      14694 |   0.247611  |    0.199739     |   1\n",
      "      14695 |   0.049477  |    0.003077     |   2\n",
      "      14696 |   0.028334  |    0.061987     |   2\n",
      "      14697 |   0.188075  |    0.143792     |   1\n",
      "      14698 |   0.043318  |    0.007130     |   2\n",
      "      14699 |   0.050924  |    0.078484     |   2\n",
      "      14700 |   0.169617  |    0.019776     |   0\n",
      "      14701 |   0.198809  |    0.212803     |   1\n",
      "      14702 |   0.058818  |    0.023756     |   2\n",
      "      14703 |   0.176064  |    0.196193     |   1\n",
      "      14704 |   0.050407  |    0.005690     |   2\n",
      "      14705 |   0.252322  |    0.087204     |   0\n",
      "      14706 |   0.197031  |    0.153122     |   1\n",
      "      14707 |   0.221995  |    0.155031     |   1\n",
      "      14708 |   0.196807  |    0.050636     |   0\n",
      "      14709 |   0.224225  |    0.148546     |   1\n",
      "      14710 |   0.025024  |    0.050968     |   2\n",
      "      14711 |   0.000045  |    0.044931     |   2\n",
      "      14712 |   0.207988  |    0.164724     |   1\n",
      "      14713 |   0.147212  |    0.052622     |   0\n",
      "      14714 |   0.007071  |    0.042485     |   2\n",
      "      14715 |   0.192407  |    0.048686     |   0\n",
      "      14716 |   0.068819  |    0.049083     |   2\n",
      "      14717 |   0.254582  |    0.149426     |   1\n",
      "      14718 |   0.035626  |    0.032375     |   2\n",
      "      14719 |   0.164720  |    0.079491     |   0\n",
      "      14720 |   0.152606  |    0.167593     |   1\n",
      "      14721 |   0.060556  |    0.005399     |   2\n",
      "      14722 |   0.217634  |    0.196906     |   1\n",
      "      14723 |   0.045425  |    0.030048     |   2\n",
      "      14724 |   0.162778  |    0.174994     |   1\n",
      "      14725 |   0.017890  |    0.076363     |   2\n",
      "      14726 |   0.212111  |    0.134719     |   1\n",
      "      14727 |   0.195450  |    0.042608     |   0\n",
      "      14728 |   0.263227  |    0.205114     |   1\n",
      "      14729 |   0.196973  |    0.110832     |   1\n",
      "      14730 |   0.205081  |    0.078022     |   0\n",
      "      14731 |   0.162365  |    0.149376     |   1\n",
      "      14732 |   0.238711  |    0.012706     |   0\n",
      "      14733 |   0.044684  |    0.077756     |   2\n",
      "      14734 |   0.030002  |    0.020636     |   2\n",
      "      14735 |   0.234892  |    0.192442     |   1\n",
      "      14736 |   0.000045  |    0.006818     |   2\n",
      "      14737 |   0.218677  |    0.077130     |   0\n",
      "      14738 |   0.195925  |    0.011526     |   0\n",
      "      14739 |   0.179756  |    0.138482     |   1\n",
      "      14740 |   0.000045  |    0.088175     |   2\n",
      "      14741 |   0.000045  |    0.009175     |   2\n",
      "      14742 |   0.210662  |    0.044941     |   0\n",
      "      14743 |   0.000045  |    0.050399     |   2\n",
      "      14744 |   0.000045  |    0.047486     |   2\n",
      "      14745 |   0.180692  |    0.195992     |   1\n",
      "      14746 |   0.160199  |    0.005678     |   0\n",
      "      14747 |   0.276110  |    0.043527     |   0\n",
      "      14748 |   0.000045  |    0.076402     |   2\n",
      "      14749 |   0.167017  |    0.045326     |   0\n",
      "      14750 |   0.051011  |    0.042303     |   2\n",
      "      14751 |   0.171063  |    0.047840     |   0\n",
      "      14752 |   0.193399  |    0.080290     |   0\n",
      "      14753 |   0.213878  |    0.157063     |   1\n",
      "      14754 |   0.055880  |    0.026274     |   2\n",
      "      14755 |   0.210550  |    0.199202     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 14757: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      14756 |   0.234039  |    0.003802     |   0\n",
      "      14757 |   0.186512  |    0.072052     |   0\n",
      "      14758 |   0.056674  |    0.006339     |   2\n",
      "      14759 |   0.219382  |    0.075886     |   0\n",
      "      14760 |   0.041192  |    0.024090     |   2\n",
      "      14761 |   0.172983  |    0.215343     |   1\n",
      "      14762 |   0.124814  |    0.141185     |   1\n",
      "      14763 |   0.191841  |    0.153434     |   1\n",
      "      14764 |   0.262991  |    0.134817     |   1\n",
      "      14765 |   0.043832  |    0.022073     |   2\n",
      "      14766 |   0.169091  |    0.082019     |   0\n",
      "      14767 |   0.199716  |    0.141037     |   1\n",
      "      14768 |   0.196304  |    0.139576     |   1\n",
      "      14769 |   0.211912  |    0.048090     |   0\n",
      "      14770 |   0.050257  |    0.041147     |   2\n",
      "      14771 |   0.163785  |    0.198765     |   1\n",
      "      14772 |   0.247568  |    0.104979     |   1\n",
      "      14773 |   0.203360  |    0.183943     |   1\n",
      "      14774 |   0.189468  |    0.006695     |   0\n",
      "      14775 |   0.187397  |    0.082413     |   0\n",
      "      14776 |   0.030323  |    0.018535     |   2\n",
      "      14777 |   0.044062  |    0.079773     |   2\n",
      "      14778 |   0.221276  |    0.147293     |   1\n",
      "      14779 |   0.055590  |    0.007144     |   2\n",
      "      14780 |   0.058018  |    0.080217     |   2\n",
      "      14781 |   0.273726  |    0.143045     |   1\n",
      "      14782 |   0.047342  |    0.027433     |   2\n",
      "      14783 |   0.224970  |    0.209195     |   1\n",
      "      14784 |   0.024756  |    0.010850     |   2\n",
      "      14785 |   0.188020  |    0.199930     |   1\n",
      "      14786 |   0.192317  |    0.029092     |   0\n",
      "      14787 |   0.241065  |    0.079553     |   0\n",
      "      14788 |   0.153783  |    0.151831     |   1\n",
      "      14789 |   0.298941  |    0.043259     |   0\n",
      "      14790 |   0.162147  |    0.156134     |   1\n",
      "      14791 | \u001b[94m  0.000044\u001b[0m  |    0.076474     |   2\n",
      "      14792 |   0.194802  |    0.017283     |   0\n",
      "      14793 |   0.242264  |    0.166940     |   1\n",
      "      14794 |   0.269135  |    0.144210     |   1\n",
      "      14795 |   0.215906  |    0.018580     |   0\n",
      "      14796 |   0.243774  |    0.074830     |   0\n",
      "      14797 |   0.239439  |    0.149856     |   1\n",
      "      14798 |   0.150509  |    0.162159     |   1\n",
      "      14799 |   0.198318  |    0.048232     |   0\n",
      "      14800 |   0.220729  |    0.147207     |   1\n",
      "      14801 |   0.194538  |    0.154823     |   1\n",
      "      14802 |   0.227537  |    0.141844     |   1\n",
      "      14803 |   0.207414  |    0.007783     |   0\n",
      "      14804 |   0.006288  |    0.071710     |   2\n",
      "      14805 |   0.118232  |    0.009018     |   0\n",
      "      14806 |   0.265234  |    0.076616     |   0\n",
      "      14807 |   0.075389  |    0.026565     |   2\n",
      "      14808 |   0.039300  |    0.027361     |   2\n",
      "      14809 |   0.204902  |    0.045673     |   0\n",
      "      14810 |   0.064402  |    0.037318     |   2\n",
      "      14811 |   0.191309  |    0.047426     |   0\n",
      "      14812 |   0.205671  |    0.190435     |   1\n",
      "      14813 |   0.193000  |    0.171233     |   1\n",
      "      14814 |   0.136031  |    0.010292     |   0\n",
      "      14815 |   0.252601  |    0.209372     |   1\n",
      "      14816 |   0.046008  |    0.007196     |   2\n",
      "      14817 |   0.018048  |    0.034395     |   2\n",
      "      14818 |   0.179109  |    0.088163     |   0\n",
      "      14819 |   0.048428  |    0.008916     |   2\n",
      "      14820 |   0.237190  |    0.197398     |   1\n",
      "      14821 |   0.204785  |    0.090079     |   1\n",
      "      14822 |   0.155623  |    0.041449     |   0\n",
      "      14823 |   0.216296  |    0.142931     |   1\n",
      "      14824 |   0.195827  |    0.157031     |   1\n",
      "      14825 |   0.179311  |    0.020855     |   0\n",
      "      14826 |   0.206516  |    0.212031     |   1\n",
      "      14827 |   0.246861  |    0.140820     |   1\n",
      "      14828 |   0.207022  |    0.153167     |   1\n",
      "      14829 |   0.034592  |    0.039839     |   2\n",
      "      14830 | \u001b[94m  0.000044\u001b[0m  |    0.051982     |   2\n",
      "      14831 |   0.228446  |    0.043723     |   0\n",
      "      14832 |   0.140504  |    0.194835     |   1\n",
      "      14833 |   0.217709  |    0.007074     |   0\n",
      "      14834 | \u001b[94m  0.000044\u001b[0m  |    0.074612     |   2\n",
      "      14835 |   0.194972  |    0.150134     |   1\n",
      "      14836 | \u001b[94m  0.000044\u001b[0m  |    0.045234     |   2\n",
      "      14837 |   0.169582  |    0.053932     |   0\n",
      "      14838 |   0.172938  |    0.160944     |   1\n",
      "      14839 |   0.000044  |    0.016103     |   2\n",
      "      14840 | \u001b[94m  0.000044\u001b[0m  |    0.072802     |   2\n",
      "      14841 |   0.198861  |    0.024779     |   0\n",
      "      14842 |   0.173712  |    0.061823     |   0\n",
      "      14843 |   0.147474  |    0.197179     |   1\n",
      "      14844 |   0.161578  |    0.155225     |   1\n",
      "      14845 |   0.160481  |    0.016495     |   0\n",
      "      14846 |   0.223771  |    0.147190     |   1\n",
      "      14847 |   0.147259  |    0.142238     |   1\n",
      "      14848 |   0.217595  |    0.073929     |   0\n",
      "      14849 |   0.144198  |    0.026971     |   0\n",
      "      14850 |   0.154612  |    0.044259     |   0\n",
      "      14851 |   0.219050  |    0.078296     |   0\n",
      "      14852 |   0.000044  |    0.014944     |   2\n",
      "      14853 |   0.055345  |    0.083053     |   2\n",
      "      14854 |   0.056580  |    0.020107     |   2\n",
      "      14855 |   0.259792  |    0.146743     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 14856: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      14856 |   0.146870  |    0.155127     |   1\n",
      "      14857 |   0.207172  |    0.050507     |   0\n",
      "      14858 |   0.164777  |    0.032607     |   0\n",
      "      14859 |   0.183370  |    0.135541     |   1\n",
      "      14860 |   0.232907  |    0.041689     |   0\n",
      "      14861 |   0.213042  |    0.166884     |   1\n",
      "      14862 |   0.053820  |    0.005917     |   2\n",
      "      14863 |   0.197563  |    0.080813     |   0\n",
      "      14864 |   0.189808  |    0.026779     |   0\n",
      "      14865 |   0.040875  |    0.052401     |   2\n",
      "      14866 |   0.190259  |    0.040389     |   0\n",
      "      14867 |   0.203346  |    0.201928     |   1\n",
      "      14868 |   0.043194  |    0.011796     |   2\n",
      "      14869 |   0.171452  |    0.196039     |   1\n",
      "      14870 |   0.206338  |    0.052760     |   0\n",
      "      14871 |   0.048917  |    0.047465     |   2\n",
      "      14872 |   0.175089  |    0.198365     |   1\n",
      "      14873 |   0.206790  |    0.014479     |   0\n",
      "      14874 |   0.181682  |    0.075479     |   0\n",
      "      14875 |   0.164955  |    0.036809     |   0\n",
      "      14876 |   0.205656  |    0.148657     |   1\n",
      "      14877 |   0.029584  |    0.070076     |   2\n",
      "      14878 |   0.184515  |    0.041790     |   0\n",
      "      14879 |   0.226608  |    0.046498     |   0\n",
      "      14880 |   0.196532  |    0.151616     |   1\n",
      "      14881 |   0.043214  |    0.030749     |   2\n",
      "      14882 |   0.056372  |    0.072999     |   2\n",
      "      14883 |   0.060505  |    0.020969     |   2\n",
      "      14884 |   0.170246  |    0.183550     |   1\n",
      "      14885 |   0.234232  |    0.159851     |   1\n",
      "      14886 |   0.260395  |    0.039881     |   0\n",
      "      14887 |   0.206740  |    0.167749     |   1\n",
      "      14888 |   0.257528  |    0.142271     |   1\n",
      "      14889 |   0.048949  |    0.016008     |   2\n",
      "      14890 |   0.174306  |    0.076725     |   0\n",
      "      14891 |   0.176016  |    0.142750     |   1\n",
      "      14892 |   0.023018  |    0.045224     |   2\n",
      "      14893 |   0.000044  |    0.048698     |   2\n",
      "      14894 |   0.181434  |    0.049169     |   0\n",
      "      14895 |   0.185229  |    0.197027     |   1\n",
      "      14896 |   0.180385  |    0.010698     |   0\n",
      "      14897 |   0.180456  |    0.087773     |   0\n",
      "      14898 |   0.231131  |    0.027324     |   0\n",
      "      14899 |   0.220282  |    0.150553     |   1\n",
      "      14900 |   0.006721  |    0.076251     |   2\n",
      "      14901 |   0.190488  |    0.038526     |   0\n",
      "      14902 |   0.186330  |    0.193373     |   1\n",
      "      14903 |   0.071208  |    0.006153     |   2\n",
      "      14904 |   0.180339  |    0.078834     |   0\n",
      "      14905 |   0.189659  |    0.041282     |   0\n",
      "      14906 |   0.229602  |    0.165371     |   1\n",
      "      14907 |   0.036528  |    0.041365     |   2\n",
      "      14908 |   0.220932  |    0.050979     |   0\n",
      "      14909 |   0.061450  |    0.051968     |   2\n",
      "      14910 |   0.236336  |    0.046338     |   0\n",
      "      14911 |   0.187236  |    0.226747     |   1\n",
      "      14912 |   0.142959  |    0.109883     |   1\n",
      "      14913 |   0.185772  |    0.159229     |   1\n",
      "      14914 |   0.257546  |    0.182659     |   1\n",
      "      14915 |   0.158514  |    0.218851     |   1\n",
      "      14916 |   0.194168  |    0.151991     |   1\n",
      "      14917 |   0.194698  |    0.005173     |   0\n",
      "      14918 |   0.194865  |    0.075191     |   0\n",
      "      14919 |   0.190294  |    0.014795     |   0\n",
      "      14920 |   0.156296  |    0.045671     |   0\n",
      "      14921 |   0.214253  |    0.052626     |   0\n",
      "      14922 |   0.205126  |    0.145091     |   1\n",
      "      14923 |   0.207480  |    0.018119     |   0\n",
      "      14924 |   0.236980  |    0.197206     |   1\n",
      "      14925 |   0.047849  |    0.020344     |   2\n",
      "      14926 |   0.202588  |    0.197391     |   1\n",
      "      14927 |   0.194881  |    0.023037     |   0\n",
      "      14928 |   0.237200  |    0.072827     |   0\n",
      "      14929 |   0.186114  |    0.141036     |   1\n",
      "      14930 |   0.184665  |    0.016658     |   0\n",
      "      14931 |   0.017256  |    0.076207     |   2\n",
      "      14932 |   0.184568  |    0.027090     |   0\n",
      "      14933 |   0.045663  |    0.078859     |   2\n",
      "      14934 |   0.033378  |    0.025864     |   2\n",
      "      14935 |   0.182435  |    0.079154     |   0\n",
      "      14936 |   0.188721  |    0.159534     |   1\n",
      "      14937 |   0.000044  |    0.043294     |   2\n",
      "      14938 |   0.175723  |    0.160842     |   1\n",
      "      14939 |   0.178555  |    0.052284     |   0\n",
      "      14940 |   0.205715  |    0.148286     |   1\n",
      "      14941 |   0.000044  |    0.036452     |   2\n",
      "      14942 |   0.232352  |    0.076218     |   0\n",
      "      14943 |   0.191145  |    0.026699     |   0\n",
      "      14944 |   0.150082  |    0.201938     |   1\n",
      "      14945 |   0.174377  |    0.189242     |   1\n",
      "      14946 |   0.170215  |    0.142895     |   1\n",
      "      14947 |   0.200598  |    0.003809     |   0\n",
      "      14948 |   0.234494  |    0.188267     |   1\n",
      "      14949 |   0.178208  |    0.013557     |   0\n",
      "      14950 |   0.000044  |    0.040682     |   2\n",
      "      14951 |   0.146806  |    0.188358     |   1\n",
      "      14952 |   0.000044  |    0.015336     |   2\n",
      "      14953 |   0.000044  |    0.047870     |   2\n",
      "      14954 |   0.000044  |    0.077850     |   2\n",
      "      14955 |   0.198970  |    0.133297     |   1\n",
      "      14956 |   0.223225  |    0.135491     |   1\n",
      "      14957 |   0.200529  |    0.214933     |   1\n",
      "      14958 |   0.201047  |    0.167715     |   1\n",
      "      14959 |   0.183226  |    0.006775     |   0\n",
      "      14960 |   0.173808  |    0.097965     |   0\n",
      "      14961 |   0.172645  |    0.150602     |   1\n",
      "      14962 |   0.053240  |    0.007555     |   2\n",
      "      14963 |   0.232252  |    0.084162     |   0\n",
      "      14964 |   0.056247  |    0.021622     |   2\n",
      "      14965 |   0.219312  |    0.146859     |   1\n",
      "      14966 |   0.213341  |    0.046328     |   0\n",
      "      14967 |   0.228262  |    0.142647     |   1\n",
      "      14968 |   0.188238  |    0.182316     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 14970: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      14969 |   0.196903  |    0.012776     |   0\n",
      "      14970 |   0.168735  |    0.054798     |   0\n",
      "      14971 |   0.183338  |    0.200766     |   1\n",
      "      14972 |   0.054767  |    0.003766     |   2\n",
      "      14973 |   0.040210  |    0.076922     |   2\n",
      "      14974 |   0.241662  |    0.031125     |   0\n",
      "      14975 |   0.196435  |    0.046369     |   0\n",
      "      14976 |   0.044983  |    0.085372     |   2\n",
      "      14977 |   0.182353  |    0.184652     |   1\n",
      "      14978 |   0.048692  |    0.004546     |   2\n",
      "      14979 |   0.203991  |    0.059715     |   0\n",
      "      14980 |   0.208608  |    0.161701     |   1\n",
      "      14981 |   0.029631  |    0.028505     |   2\n",
      "      14982 |   0.232800  |    0.044692     |   0\n",
      "      14983 |   0.046637  |    0.036875     |   2\n",
      "      14984 |   0.221757  |    0.145150     |   1\n",
      "      14985 |   0.158298  |    0.044022     |   0\n",
      "      14986 |   0.189149  |    0.150223     |   1\n",
      "      14987 |   0.236848  |    0.140568     |   1\n",
      "      14988 |   0.053589  |    0.056043     |   2\n",
      "      14989 |   0.205600  |    0.075018     |   0\n",
      "      14990 |   0.180956  |    0.144973     |   1\n",
      "      14991 |   0.150345  |    0.005138     |   0\n",
      "      14992 |   0.244733  |    0.140278     |   1\n",
      "      14993 |   0.144531  |    0.132544     |   1\n",
      "      14994 |   0.174720  |    0.044384     |   0\n",
      "      14995 |   0.059046  |    0.043936     |   2\n",
      "      14996 |   0.048703  |    0.077026     |   2\n",
      "      14997 |   0.159328  |    0.191589     |   1\n",
      "      14998 |   0.024711  |    0.003709     |   2\n",
      "      14999 | \u001b[94m  0.000043\u001b[0m  |    0.080510     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 15000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 15000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      15000 |   0.171022  |    0.023062     |   0\n",
      "      15001 |   0.201258  |    0.284129     |   1\n",
      "      15002 |   0.055194  |    0.024546     |   2\n",
      "      15003 |   0.042121  |    0.044082     |   2\n",
      "      15004 |   0.220177  |    0.131922     |   0\n",
      "      15005 |   0.190739  |    0.185978     |   1\n",
      "      15006 |   0.044955  |    0.008153     |   2\n",
      "      15007 |   0.172246  |    0.080933     |   0\n",
      "      15008 |   0.188150  |    0.015462     |   0\n",
      "      15009 |   0.223423  |    0.071678     |   0\n",
      "      15010 |   0.238659  |    0.027253     |   0\n",
      "      15011 |   0.048957  |    0.076494     |   2\n",
      "      15012 |   0.200241  |    0.025583     |   0\n",
      "      15013 |   0.167699  |    0.078492     |   0\n",
      "      15014 |   0.156015  |    0.009947     |   0\n",
      "      15015 |   0.245923  |    0.081341     |   0\n",
      "      15016 |   0.183465  |    0.030984     |   0\n",
      "      15017 |   0.178918  |    0.076818     |   0\n",
      "      15018 |   0.162380  |    0.014219     |   0\n",
      "      15019 |   0.195792  |    0.075387     |   0\n",
      "      15020 |   0.160230  |    0.024682     |   0\n",
      "      15021 |   0.182199  |    0.073028     |   0\n",
      "      15022 |   0.208673  |    0.025127     |   0\n",
      "      15023 |   0.243855  |    0.208716     |   1\n",
      "      15024 |   0.030785  |    0.006747     |   2\n",
      "      15025 |   0.044691  |    0.065782     |   2\n",
      "      15026 |   0.162726  |    0.202323     |   1\n",
      "      15027 |   0.171151  |    0.046567     |   0\n",
      "      15028 |   0.062189  |    0.045754     |   2\n",
      "      15029 |   0.062411  |    0.036401     |   2\n",
      "      15030 |   0.196177  |    0.082353     |   0\n",
      "      15031 |   0.196430  |    0.007191     |   0\n",
      "      15032 |   0.146385  |    0.040795     |   0\n",
      "      15033 |   0.049991  |    0.078550     |   2\n",
      "      15034 |   0.269602  |    0.133813     |   1\n",
      "      15035 |   0.163017  |    0.019996     |   0\n",
      "      15036 |   0.221110  |    0.198360     |   1\n",
      "      15037 |   0.024538  |    0.019795     |   2\n",
      "      15038 |   0.000043  |    0.072577     |   2\n",
      "      15039 |   0.169852  |    0.045305     |   0\n",
      "      15040 |   0.181597  |    0.080217     |   0\n",
      "      15041 |   0.006741  |    0.016234     |   2\n",
      "      15042 |   0.073630  |    0.075402     |   2\n",
      "      15043 |   0.042073  |    0.079333     |   2\n",
      "      15044 |   0.239140  |    0.068392     |   0\n",
      "      15045 |   0.214812  |    0.226264     |   1\n",
      "      15046 |   0.201089  |    0.216325     |   1\n",
      "      15047 |   0.063049  |    0.011329     |   2\n",
      "      15048 |   0.192940  |    0.148265     |   1\n",
      "      15049 |   0.184318  |    0.152059     |   1\n",
      "      15050 |   0.214164  |    0.149153     |   1\n",
      "      15051 |   0.050767  |    0.048354     |   2\n",
      "      15052 |   0.147990  |    0.183824     |   1\n",
      "      15053 |   0.193265  |    0.039495     |   0\n",
      "      15054 |   0.239691  |    0.155894     |   1\n",
      "      15055 |   0.018939  |    0.075762     |   2\n",
      "      15056 |   0.168872  |    0.005131     |   0\n",
      "      15057 |   0.222563  |    0.078528     |   0\n",
      "      15058 |   0.178751  |    0.020703     |   0\n",
      "      15059 |   0.201144  |    0.046623     |   0\n",
      "      15060 |   0.191976  |    0.145055     |   1\n",
      "      15061 |   0.045642  |    0.043672     |   2\n",
      "      15062 |   0.034674  |    0.051065     |   2\n",
      "      15063 |   0.000044  |    0.033306     |   2\n",
      "      15064 |   0.223653  |    0.149671     |   1\n",
      "      15065 |   0.238070  |    0.201292     |   1\n",
      "      15066 |   0.228657  |    0.030472     |   0\n",
      "      15067 |   0.201113  |    0.190123     |   1\n",
      "      15068 |   0.000044  |    0.010305     |   2\n",
      "      15069 |   0.000044  |    0.079330     |   2\n",
      "      15070 |   0.201190  |    0.131595     |   1\n",
      "      15071 |   0.193802  |    0.025445     |   0\n",
      "      15072 |   0.000044  |    0.046947     |   2\n",
      "      15073 |   0.200609  |    0.074207     |   0\n",
      "      15074 |   0.253639  |    0.025958     |   0\n",
      "      15075 |   0.000044  |    0.046143     |   2\n",
      "      15076 |   0.195929  |    0.052859     |   0\n",
      "      15077 |   0.228864  |    0.051457     |   0\n",
      "      15078 |   0.235093  |    0.151904     |   1\n",
      "      15079 |   0.132862  |    0.006957     |   0\n",
      "      15080 |   0.191735  |    0.201342     |   1\n",
      "      15081 |   0.000043  |    0.011983     |   2\n",
      "      15082 |   0.189173  |    0.197724     |   1\n",
      "      15083 |   0.221371  |    0.146399     |   1\n",
      "      15084 |   0.184914  |    0.192011     |   1\n",
      "      15085 |   0.210770  |    0.009465     |   0\n",
      "      15086 |   0.053548  |    0.079647     |   2\n",
      "      15087 |   0.056592  |    0.047972     |   2\n",
      "      15088 |   0.100219  |    0.199373     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 15089: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      15089 |   0.052564  |    0.014826     |   2\n",
      "      15090 |   0.194892  |    0.190422     |   1\n",
      "      15091 |   0.040786  |    0.045826     |   2\n",
      "      15092 |   0.042594  |    0.044866     |   2\n",
      "      15093 |   0.047974  |    0.072510     |   2\n",
      "      15094 |   0.197811  |    0.147474     |   1\n",
      "      15095 |   0.201828  |    0.042905     |   0\n",
      "      15096 |   0.274927  |    0.207402     |   1\n",
      "      15097 |   0.230910  |    0.138013     |   1\n",
      "      15098 |   0.177660  |    0.040137     |   0\n",
      "      15099 |   0.231924  |    0.041365     |   0\n",
      "      15100 |   0.215996  |    0.052581     |   0\n",
      "      15101 |   0.140656  |    0.042179     |   0\n",
      "      15102 |   0.029085  |    0.073639     |   2\n",
      "      15103 |   0.046112  |    0.029959     |   2\n",
      "      15104 |   0.242144  |    0.165413     |   1\n",
      "      15105 |   0.211303  |    0.049566     |   0\n",
      "      15106 |   0.195996  |    0.079373     |   0\n",
      "      15107 |   0.232719  |    0.132261     |   1\n",
      "      15108 |   0.054891  |    0.051624     |   2\n",
      "      15109 |   0.060202  |    0.039703     |   2\n",
      "      15110 |   0.247544  |    0.187956     |   1\n",
      "      15111 |   0.048965  |    0.032806     |   2\n",
      "      15112 |   0.024030  |    0.049553     |   2\n",
      "      15113 |   0.000044  |    0.059072     |   2\n",
      "      15114 |   0.255000  |    0.189465     |   1\n",
      "      15115 |   0.192490  |    0.003154     |   0\n",
      "      15116 |   0.190756  |    0.205994     |   1\n",
      "      15117 |   0.185459  |    0.146754     |   1\n",
      "      15118 |   0.217270  |    0.104006     |   1\n",
      "      15119 |   0.006944  |    0.052928     |   2\n",
      "      15120 |   0.180467  |    0.050595     |   0\n",
      "      15121 |   0.073281  |    0.064844     |   2\n",
      "      15122 |   0.198162  |    0.271480     |   1\n",
      "      15123 |   0.224308  |    0.012126     |   0\n",
      "      15124 |   0.171220  |    0.090692     |   0\n",
      "      15125 |   0.183350  |    0.135237     |   1\n",
      "      15126 |   0.205205  |    0.184146     |   1\n",
      "      15127 |   0.037889  |    0.005773     |   2\n",
      "      15128 |   0.063176  |    0.084384     |   2\n",
      "      15129 |   0.046780  |    0.011654     |   2\n",
      "      15130 |   0.018705  |    0.087581     |   2\n",
      "      15131 |   0.039129  |    0.028462     |   2\n",
      "      15132 |   0.149186  |    0.201058     |   1\n",
      "      15133 |   0.207789  |    0.224966     |   1\n",
      "      15134 |   0.205783  |    0.321598     |   1\n",
      "      15135 |   0.199902  |    0.185066     |   1\n",
      "      15136 |   0.176448  |    0.014198     |   0\n",
      "      15137 |   0.032413  |    0.098951     |   2\n",
      "      15138 |   0.177177  |    0.156732     |   1\n",
      "      15139 |   0.141431  |    0.124365     |   1\n",
      "      15140 |   0.221174  |    0.046945     |   0\n",
      "      15141 |   0.243606  |    0.221422     |   1\n",
      "      15142 | \u001b[94m  0.000043\u001b[0m  |    0.004683     |   2\n",
      "      15143 |   0.202064  |    0.174328     |   1\n",
      "      15144 | \u001b[94m  0.000043\u001b[0m  |    0.078097     |   2\n",
      "      15145 |   0.000043  |    0.044168     |   2\n",
      "      15146 |   0.000043  |    0.083811     |   2\n",
      "      15147 | \u001b[94m  0.000043\u001b[0m  |    0.021768     |   2\n",
      "      15148 |   0.181053  |    0.200104     |   1\n",
      "      15149 |   0.174522  |    0.006357     |   0\n",
      "      15150 | \u001b[94m  0.000043\u001b[0m  |    0.044327     |   2\n",
      "      15151 |   0.206177  |    0.078722     |   0\n",
      "      15152 |   0.205840  |    0.021663     |   0\n",
      "      15153 |   0.051263  |    0.078939     |   2\n",
      "      15154 |   0.242796  |    0.147558     |   1\n",
      "      15155 |   0.198013  |    0.188772     |   1\n",
      "      15156 |   0.055911  |    0.077003     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 15157: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      15157 |   0.053671  |    0.020712     |   2\n",
      "      15158 |   0.187249  |    0.320365     |   1\n",
      "      15159 |   0.227034  |    0.162415     |   1\n",
      "      15160 |   0.152121  |    0.148825     |   1\n",
      "      15161 |   0.208950  |    0.027586     |   0\n",
      "      15162 |   0.042943  |    0.043529     |   2\n",
      "      15163 |   0.044109  |    0.039215     |   2\n",
      "      15164 |   0.166764  |    0.080930     |   0\n",
      "      15165 |   0.158415  |    0.241660     |   1\n",
      "      15166 |   0.049823  |    0.013963     |   2\n",
      "      15167 |   0.203779  |    0.076294     |   0\n",
      "      15168 |   0.029254  |    0.022762     |   2\n",
      "      15169 |   0.233189  |    0.081140     |   0\n",
      "      15170 |   0.201085  |    0.146599     |   1\n",
      "      15171 |   0.220288  |    0.049243     |   0\n",
      "      15172 |   0.212169  |    0.195843     |   1\n",
      "      15173 |   0.162820  |    0.031287     |   0\n",
      "      15174 |   0.238474  |    0.162787     |   1\n",
      "      15175 |   0.233882  |    0.145441     |   1\n",
      "      15176 |   0.042315  |    0.005510     |   2\n",
      "      15177 |   0.053171  |    0.078107     |   2\n",
      "      15178 |   0.057800  |    0.075949     |   2\n",
      "      15179 |   0.201700  |    0.017766     |   0\n",
      "      15180 |   0.196455  |    0.290189     |   1\n",
      "      15181 |   0.047381  |    0.021200     |   2\n",
      "      15182 |   0.239788  |    0.227038     |   1\n",
      "      15183 |   0.024371  |    0.040637     |   2\n",
      "      15184 |   0.288049  |    0.172267     |   1\n",
      "      15185 |   0.218588  |    0.127243     |   1\n",
      "      15186 |   0.197511  |    0.067704     |   0\n",
      "      15187 |   0.211225  |    0.155213     |   1\n",
      "      15188 |   0.202422  |    0.160696     |   1\n",
      "      15189 |   0.205200  |    0.025516     |   0\n",
      "      15190 | \u001b[94m  0.000042\u001b[0m  |    0.073483     |   2\n",
      "      15191 |   0.006267  |    0.021330     |   2\n",
      "      15192 |   0.071682  |    0.076794     |   2\n",
      "      15193 |   0.192429  |    0.196968     |   1\n",
      "      15194 |   0.036476  |    0.003926     |   2\n",
      "      15195 |   0.182968  |    0.058719     |   0\n",
      "      15196 |   0.156685  |    0.057178     |   0\n",
      "      15197 |   0.228324  |    0.202499     |   1\n",
      "      15198 |   0.182085  |    0.185220     |   1\n",
      "      15199 |   0.169698  |    0.023421     |   0\n",
      "      15200 |   0.233451  |    0.205453     |   1\n",
      "      15201 |   0.160715  |    0.048369     |   0\n",
      "      15202 |   0.175084  |    0.214952     |   1\n",
      "      15203 |   0.184327  |    0.215534     |   1\n",
      "      15204 |   0.189161  |    0.023796     |   0\n",
      "      15205 |   0.203290  |    0.094601     |   0\n",
      "      15206 |   0.266501  |    0.083908     |   0\n",
      "      15207 |   0.161196  |    0.004931     |   0\n",
      "      15208 |   0.198936  |    0.048533     |   0\n",
      "      15209 |   0.060185  |    0.044343     |   2\n",
      "      15210 |   0.213893  |    0.074367     |   0\n",
      "      15211 |   0.179114  |    0.044995     |   0\n",
      "      15212 |   0.263289  |    0.135644     |   1\n",
      "      15213 |   0.250277  |    0.157975     |   1\n",
      "      15214 |   0.197628  |    0.037798     |   0\n",
      "      15215 |   0.189179  |    0.074791     |   0\n",
      "      15216 |   0.298616  |    0.152222     |   1\n",
      "      15217 |   0.159700  |    0.011479     |   0\n",
      "      15218 |   0.190894  |    0.049331     |   0\n",
      "      15219 |   0.227348  |    0.070744     |   0\n",
      "      15220 |   0.048688  |    0.013597     |   2\n",
      "      15221 |   0.198245  |    0.209415     |   1\n",
      "      15222 |   0.209621  |    0.171239     |   1\n",
      "      15223 |   0.020630  |    0.042487     |   2\n",
      "      15224 |   0.235052  |    0.073636     |   0\n",
      "      15225 |   0.207109  |    0.041061     |   0\n",
      "      15226 |   0.043224  |    0.046109     |   2\n",
      "      15227 |   0.206209  |    0.166455     |   1\n",
      "      15228 |   0.179330  |    0.085394     |   0\n",
      "      15229 |   0.236458  |    0.027650     |   0\n",
      "      15230 |   0.031748  |    0.079628     |   2\n",
      "      15231 |   0.220931  |    0.023715     |   0\n",
      "      15232 |   0.277994  |    0.196496     |   1\n",
      "      15233 |   0.199114  |    0.010413     |   0\n",
      "      15234 |   0.214559  |    0.080805     |   0\n",
      "      15235 |   0.159099  |    0.022956     |   0\n",
      "      15236 |   0.167567  |    0.170260     |   1\n",
      "      15237 |   0.222590  |    0.150279     |   1\n",
      "      15238 | \u001b[94m  0.000041\u001b[0m  |    0.042527     |   2\n",
      "      15239 | \u001b[94m  0.000041\u001b[0m  |    0.046110     |   2\n",
      "      15240 |   0.163722  |    0.234061     |   1\n",
      "      15241 |   0.000041  |    0.040942     |   2\n",
      "      15242 |   0.218607  |    0.196214     |   1\n",
      "      15243 |   0.212890  |    0.133328     |   1\n",
      "      15244 |   0.000042  |    0.021920     |   2\n",
      "      15245 |   0.242636  |    0.169410     |   1\n",
      "      15246 |   0.229764  |    0.211647     |   1\n",
      "      15247 |   0.214056  |    0.153145     |   1\n",
      "      15248 |   0.168730  |    0.022679     |   0\n",
      "      15249 |   0.177803  |    0.069895     |   0\n",
      "      15250 |   0.154017  |    0.153909     |   1\n",
      "      15251 |   0.214633  |    0.026426     |   0\n",
      "      15252 |   0.168728  |    0.084048     |   0\n",
      "      15253 |   0.201458  |    0.183529     |   1\n",
      "      15254 |   0.157882  |    0.008723     |   0\n",
      "      15255 |   0.138459  |    0.050869     |   0\n",
      "      15256 |   0.193622  |    0.044953     |   0\n",
      "      15257 |   0.000042  |    0.046375     |   2\n",
      "      15258 |   0.000042  |    0.046823     |   2\n",
      "      15259 |   0.154722  |    0.024523     |   0\n",
      "      15260 |   0.208505  |    0.197100     |   1\n",
      "      15261 |   0.139917  |    0.043720     |   0\n",
      "      15262 |   0.198077  |    0.038870     |   0\n",
      "      15263 |   0.054696  |    0.076210     |   2\n",
      "      15264 |   0.206214  |    0.021521     |   0\n",
      "      15265 |   0.056259  |    0.046640     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 15266: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      15266 |   0.209619  |    0.041069     |   0\n",
      "      15267 |   0.192073  |    0.153376     |   1\n",
      "      15268 |   0.162611  |    0.143075     |   1\n",
      "      15269 |   0.185499  |    0.028323     |   0\n",
      "      15270 |   0.276350  |    0.194618     |   1\n",
      "      15271 |   0.169503  |    0.012432     |   0\n",
      "      15272 |   0.135500  |    0.215583     |   1\n",
      "      15273 |   0.200082  |    0.160486     |   1\n",
      "      15274 |   0.055484  |    0.040211     |   2\n",
      "      15275 |   0.183106  |    0.049713     |   0\n",
      "      15276 |   0.041621  |    0.047185     |   2\n",
      "      15277 |   0.043294  |    0.048720     |   2\n",
      "      15278 |   0.172876  |    0.203954     |   1\n",
      "      15279 |   0.240611  |    0.147083     |   1\n",
      "      15280 |   0.231188  |    0.003956     |   0\n",
      "      15281 |   0.213271  |    0.140788     |   0\n",
      "      15282 |   0.195650  |    0.174718     |   1\n",
      "      15283 |   0.211944  |    0.164652     |   1\n",
      "      15284 |   0.252508  |    0.146561     |   1\n",
      "      15285 |   0.155261  |    0.041342     |   0\n",
      "      15286 |   0.179863  |    0.043861     |   0\n",
      "      15287 |   0.223866  |    0.040227     |   0\n",
      "      15288 |   0.155454  |    0.043031     |   0\n",
      "      15289 |   0.215409  |    0.209758     |   1\n",
      "      15290 |   0.222980  |    0.165570     |   1\n",
      "      15291 |   0.244209  |    0.085908     |   1\n",
      "      15292 |   0.206152  |    0.148480     |   1\n",
      "      15293 |   0.217272  |    0.156583     |   1\n",
      "      15294 |   0.224070  |    0.152779     |   1\n",
      "      15295 |   0.271483  |    0.145794     |   1\n",
      "      15296 |   0.210418  |    0.135795     |   1\n",
      "      15297 |   0.256510  |    0.192435     |   1\n",
      "      15298 |   0.175048  |    0.135162     |   1\n",
      "      15299 |   0.197276  |    0.012221     |   0\n",
      "      15300 |   0.049732  |    0.025948     |   2\n",
      "      15301 |   0.030269  |    0.077719     |   2\n",
      "      15302 |   0.045030  |    0.011652     |   2\n",
      "      15303 |   0.200042  |    0.079827     |   0\n",
      "      15304 |   0.234118  |    0.139305     |   1\n",
      "      15305 |   0.150816  |    0.148795     |   1\n",
      "      15306 |   0.170849  |    0.042681     |   0\n",
      "      15307 |   0.166368  |    0.082268     |   0\n",
      "      15308 |   0.051802  |    0.015141     |   2\n",
      "      15309 |   0.062649  |    0.083617     |   2\n",
      "      15310 |   0.052193  |    0.015774     |   2\n",
      "      15311 |   0.026169  |    0.077939     |   2\n",
      "      15312 |   0.000042  |    0.040630     |   2\n",
      "      15313 |   0.006616  |    0.051530     |   2\n",
      "      15314 |   0.073563  |    0.054054     |   2\n",
      "      15315 |   0.039278  |    0.042450     |   2\n",
      "      15316 |   0.187435  |    0.074973     |   0\n",
      "      15317 |   0.060847  |    0.011676     |   2\n",
      "      15318 |   0.047727  |    0.044308     |   2\n",
      "      15319 |   0.017134  |    0.055249     |   2\n",
      "      15320 |   0.208511  |    0.191987     |   1\n",
      "      15321 |   0.038609  |    0.003985     |   2\n",
      "      15322 |   0.031853  |    0.044200     |   2\n",
      "      15323 |   0.000042  |    0.043438     |   2\n",
      "      15324 |   0.188283  |    0.076837     |   0\n",
      "      15325 |   0.000042  |    0.028770     |   2\n",
      "      15326 |   0.000042  |    0.047512     |   2\n",
      "      15327 |   0.158978  |    0.152703     |   1\n",
      "      15328 |   0.177587  |    0.077454     |   0\n",
      "      15329 |   0.207740  |    0.153864     |   1\n",
      "      15330 |   0.182135  |    0.052652     |   0\n",
      "      15331 |   0.218788  |    0.026076     |   0\n",
      "      15332 |   0.182607  |    0.076452     |   0\n",
      "      15333 |   0.152320  |    0.007167     |   0\n",
      "      15334 |   0.000042  |    0.051427     |   2\n",
      "      15335 |   0.260228  |    0.082988     |   0\n",
      "      15336 |   0.000041  |    0.009608     |   2\n",
      "      15337 |   0.198041  |    0.178557     |   1\n",
      "      15338 |   0.202462  |    0.029240     |   0\n",
      "      15339 |   0.233796  |    0.201401     |   1\n",
      "      15340 |   0.173000  |    0.106942     |   1\n",
      "      15341 |   0.237976  |    0.194239     |   1\n",
      "      15342 |   0.186016  |    0.005986     |   0\n",
      "      15343 |   0.198664  |    0.037108     |   0\n",
      "      15344 | \u001b[94m  0.000041\u001b[0m  |    0.043356     |   2\n",
      "      15345 |   0.179113  |    0.196467     |   1\n",
      "      15346 |   0.146500  |    0.178877     |   1\n",
      "      15347 |   0.239324  |    0.153310     |   1\n",
      "      15348 |   0.056549  |    0.007079     |   2\n",
      "      15349 |   0.236152  |    0.083619     |   0\n",
      "      15350 |   0.181890  |    0.025532     |   0\n",
      "      15351 |   0.266964  |    0.200903     |   1\n",
      "      15352 |   0.260618  |    0.154556     |   1\n",
      "      15353 |   0.262534  |    0.135221     |   1\n",
      "      15354 |   0.055728  |    0.060797     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 15355: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      15355 |   0.053956  |    0.010443     |   2\n",
      "      15356 |   0.174237  |    0.098358     |   0\n",
      "      15357 |   0.229311  |    0.097791     |   1\n",
      "      15358 |   0.207985  |    0.025313     |   0\n",
      "      15359 |   0.174761  |    0.037551     |   0\n",
      "      15360 |   0.044582  |    0.073282     |   2\n",
      "      15361 |   0.226543  |    0.149362     |   1\n",
      "      15362 |   0.041313  |    0.044560     |   2\n",
      "      15363 |   0.181643  |    0.141253     |   1\n",
      "      15364 |   0.048208  |    0.069987     |   2\n",
      "      15365 |   0.173572  |    0.039487     |   0\n",
      "      15366 |   0.182519  |    0.183503     |   1\n",
      "      15367 |   0.213905  |    0.150181     |   1\n",
      "      15368 |   0.028777  |    0.011350     |   2\n",
      "      15369 |   0.234812  |    0.169117     |   1\n",
      "      15370 |   0.260456  |    0.141783     |   1\n",
      "      15371 |   0.196988  |    0.039187     |   0\n",
      "      15372 |   0.184650  |    0.074399     |   0\n",
      "      15373 |   0.239826  |    0.033287     |   0\n",
      "      15374 |   0.222236  |    0.186676     |   1\n",
      "      15375 |   0.043344  |    0.006177     |   2\n",
      "      15376 |   0.226713  |    0.075135     |   0\n",
      "      15377 |   0.057423  |    0.036657     |   2\n",
      "      15378 |   0.160850  |    0.207469     |   1\n",
      "      15379 |   0.220959  |    0.016552     |   0\n",
      "      15380 |   0.249345  |    0.156826     |   1\n",
      "      15381 |   0.057049  |    0.014821     |   2\n",
      "      15382 |   0.171056  |    0.076817     |   0\n",
      "      15383 |   0.239112  |    0.024128     |   0\n",
      "      15384 |   0.175318  |    0.081981     |   0\n",
      "      15385 |   0.166477  |    0.011301     |   0\n",
      "      15386 |   0.193984  |    0.081595     |   0\n",
      "      15387 |   0.235835  |    0.133392     |   1\n",
      "      15388 |   0.204557  |    0.145894     |   1\n",
      "      15389 |   0.184788  |    0.016799     |   0\n",
      "      15390 |   0.121287  |    0.197537     |   1\n",
      "      15391 |   0.049514  |    0.052945     |   2\n",
      "      15392 |   0.174230  |    0.045955     |   0\n",
      "      15393 |   0.026753  |    0.053756     |   2\n",
      "      15394 |   0.251445  |    0.158345     |   1\n",
      "      15395 |   0.219682  |    0.154624     |   1\n",
      "      15396 |   0.227659  |    0.040390     |   0\n",
      "      15397 |   0.215026  |    0.153243     |   1\n",
      "      15398 |   0.194570  |    0.080634     |   0\n",
      "      15399 |   0.185975  |    0.131522     |   1\n",
      "      15400 |   0.197904  |    0.049221     |   0\n",
      "      15401 |   0.214874  |    0.145173     |   1\n",
      "      15402 |   0.000041  |    0.029094     |   2\n",
      "      15403 |   0.218901  |    0.053928     |   0\n",
      "      15404 |   0.203488  |    0.042226     |   0\n",
      "      15405 |   0.166824  |    0.076460     |   0\n",
      "      15406 |   0.160382  |    0.147738     |   1\n",
      "      15407 |   0.194974  |    0.149548     |   1\n",
      "      15408 |   0.214202  |    0.080981     |   0\n",
      "      15409 |   0.164808  |    0.205615     |   1\n",
      "      15410 |   0.166576  |    0.005446     |   0\n",
      "      15411 |   0.134900  |    0.078243     |   0\n",
      "      15412 |   0.194438  |    0.027774     |   0\n",
      "      15413 |   0.006000  |    0.076101     |   2\n",
      "      15414 |   0.073782  |    0.023828     |   2\n",
      "      15415 |   0.169392  |    0.205023     |   1\n",
      "      15416 |   0.183503  |    0.008507     |   0\n",
      "      15417 |   0.039245  |    0.043727     |   2\n",
      "      15418 |   0.065856  |    0.039247     |   2\n",
      "      15419 |   0.203370  |    0.077849     |   0\n",
      "      15420 |   0.173897  |    0.027562     |   0\n",
      "      15421 |   0.146989  |    0.213251     |   1\n",
      "      15422 |   0.050471  |    0.010285     |   2\n",
      "      15423 |   0.173426  |    0.071540     |   0\n",
      "      15424 |   0.019660  |    0.027846     |   2\n",
      "      15425 |   0.200122  |    0.081530     |   0\n",
      "      15426 |   0.283345  |    0.141183     |   1\n",
      "      15427 |   0.046181  |    0.006063     |   2\n",
      "      15428 |   0.030688  |    0.079469     |   2\n",
      "      15429 |   0.173721  |    0.012111     |   0\n",
      "      15430 |   0.210961  |    0.048781     |   0\n",
      "      15431 |   0.218823  |    0.068714     |   0\n",
      "      15432 |   0.214348  |    0.183976     |   1\n",
      "      15433 |   0.190030  |    0.011284     |   0\n",
      "      15434 |   0.200293  |    0.205172     |   1\n",
      "      15435 |   0.150299  |    0.015737     |   0\n",
      "      15436 |   0.000042  |    0.079059     |   2\n",
      "      15437 |   0.000041  |    0.030765     |   2\n",
      "      15438 |   0.000042  |    0.063422     |   2\n",
      "      15439 |   0.211493  |    0.160822     |   1\n",
      "      15440 |   0.169491  |    0.053904     |   0\n",
      "      15441 |   0.162518  |    0.158603     |   1\n",
      "      15442 |   0.217132  |    0.051963     |   0\n",
      "      15443 |   0.187863  |    0.148689     |   1\n",
      "      15444 |   0.231555  |    0.148230     |   1\n",
      "      15445 |   0.257091  |    0.151181     |   1\n",
      "      15446 |   0.148097  |    0.192554     |   1\n",
      "      15447 |   0.224794  |    0.145553     |   1\n",
      "      15448 |   0.000042  |    0.028443     |   2\n",
      "      15449 |   0.211817  |    0.222443     |   1\n",
      "      15450 |   0.155549  |    0.009048     |   0\n",
      "      15451 |   0.218341  |    0.023027     |   0\n",
      "      15452 |   0.000042  |    0.078665     |   2\n",
      "      15453 |   0.193061  |    0.016518     |   0\n",
      "      15454 |   0.181450  |    0.074916     |   0\n",
      "      15455 |   0.298165  |    0.169119     |   1\n",
      "      15456 |   0.130853  |    0.150492     |   1\n",
      "      15457 |   0.000042  |    0.023616     |   2\n",
      "      15458 |   0.210912  |    0.075591     |   0\n",
      "      15459 |   0.050662  |    0.026480     |   2\n",
      "      15460 |   0.198430  |    0.199509     |   1\n",
      "      15461 |   0.055808  |    0.009895     |   2\n",
      "      15462 |   0.177959  |    0.078767     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 15463: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      15463 |   0.175394  |    0.148829     |   1\n",
      "      15464 |   0.181551  |    0.025612     |   0\n",
      "      15465 |   0.053755  |    0.081740     |   2\n",
      "      15466 |   0.205920  |    0.165955     |   1\n",
      "      15467 |   0.162514  |    0.008441     |   0\n",
      "      15468 |   0.170517  |    0.074049     |   0\n",
      "      15469 |   0.176004  |    0.049471     |   0\n",
      "      15470 |   0.039237  |    0.038089     |   2\n",
      "      15471 |   0.043710  |    0.045499     |   2\n",
      "      15472 |   0.050610  |    0.050958     |   2\n",
      "      15473 |   0.272534  |    0.152727     |   1\n",
      "      15474 |   0.161440  |    0.150384     |   1\n",
      "      15475 |   0.193821  |    0.042073     |   0\n",
      "      15476 |   0.191291  |    0.202795     |   1\n",
      "      15477 |   0.160603  |    0.022243     |   0\n",
      "      15478 |   0.244568  |    0.222502     |   1\n",
      "      15479 |   0.213145  |    0.087908     |   1\n",
      "      15480 |   0.028709  |    0.078518     |   2\n",
      "      15481 |   0.043432  |    0.013255     |   2\n",
      "      15482 |   0.174626  |    0.074123     |   0\n",
      "      15483 |   0.169172  |    0.014742     |   0\n",
      "      15484 |   0.204706  |    0.161741     |   1\n",
      "      15485 |   0.207763  |    0.181998     |   1\n",
      "      15486 |   0.227451  |    0.143176     |   1\n",
      "      15487 |   0.213953  |    0.033101     |   0\n",
      "      15488 |   0.056092  |    0.040878     |   2\n",
      "      15489 |   0.166017  |    0.049083     |   0\n",
      "      15490 |   0.215916  |    0.050682     |   0\n",
      "      15491 |   0.060105  |    0.074886     |   2\n",
      "      15492 |   0.048699  |    0.004659     |   2\n",
      "      15493 |   0.164288  |    0.082579     |   0\n",
      "      15494 |   0.024337  |    0.016859     |   2\n",
      "      15495 |   0.170582  |    0.075402     |   0\n",
      "      15496 |   0.000041  |    0.022494     |   2\n",
      "      15497 |   0.006337  |    0.078819     |   2\n",
      "      15498 |   0.215711  |    0.159326     |   1\n",
      "      15499 |   0.151088  |    0.153441     |   1\n",
      "      15500 |   0.185756  |    0.025576     |   0\n",
      "      15501 |   0.222172  |    0.203030     |   1\n",
      "      15502 |   0.053091  |    0.010224     |   2\n",
      "      15503 |   0.165312  |    0.050086     |   0\n",
      "      15504 |   0.165654  |    0.078846     |   0\n",
      "      15505 |   0.224122  |    0.138839     |   1\n",
      "      15506 |   0.038519  |    0.045268     |   2\n",
      "      15507 |   0.043639  |    0.041727     |   2\n",
      "      15508 |   0.185008  |    0.199136     |   1\n",
      "      15509 |   0.200534  |    0.137723     |   1\n",
      "      15510 |   0.167229  |    0.009148     |   0\n",
      "      15511 |   0.181092  |    0.074822     |   0\n",
      "      15512 |   0.210615  |    0.035602     |   0\n",
      "      15513 |   0.157584  |    0.217697     |   1\n",
      "      15514 |   0.210411  |    0.142589     |   1\n",
      "      15515 |   0.049787  |    0.024122     |   2\n",
      "      15516 |   0.163689  |    0.222944     |   1\n",
      "      15517 |   0.157198  |    0.139892     |   1\n",
      "      15518 |   0.207796  |    0.161459     |   1\n",
      "      15519 |   0.176728  |    0.156115     |   1\n",
      "      15520 |   0.141768  |    0.163553     |   1\n",
      "      15521 |   0.029305  |    0.043170     |   2\n",
      "      15522 |   0.044337  |    0.043545     |   2\n",
      "      15523 |   0.051906  |    0.051138     |   2\n",
      "      15524 |   0.059541  |    0.077846     |   2\n",
      "      15525 |   0.244938  |    0.012762     |   0\n",
      "      15526 |   0.047226  |    0.086326     |   2\n",
      "      15527 |   0.023221  |    0.025970     |   2\n",
      "      15528 |   0.162684  |    0.075375     |   0\n",
      "      15529 |   0.213199  |    0.016654     |   0\n",
      "      15530 |   0.188655  |    0.078290     |   0\n",
      "      15531 | \u001b[94m  0.000041\u001b[0m  |    0.005962     |   2\n",
      "      15532 |   0.168779  |    0.097655     |   0\n",
      "      15533 |   0.210280  |    0.166171     |   1\n",
      "      15534 |   0.247043  |    0.147398     |   1\n",
      "      15535 |   0.236652  |    0.021664     |   0\n",
      "      15536 |   0.006946  |    0.052890     |   2\n",
      "      15537 |   0.073950  |    0.046015     |   2\n",
      "      15538 |   0.039313  |    0.044120     |   2\n",
      "      15539 |   0.183044  |    0.051453     |   0\n",
      "      15540 |   0.197502  |    0.145983     |   1\n",
      "      15541 |   0.061952  |    0.038302     |   2\n",
      "      15542 |   0.046791  |    0.041914     |   2\n",
      "      15543 |   0.205154  |    0.196586     |   1\n",
      "      15544 |   0.222010  |    0.121555     |   1\n",
      "      15545 |   0.227719  |    0.141832     |   1\n",
      "      15546 |   0.021470  |    0.041474     |   2\n",
      "      15547 |   0.141025  |    0.049914     |   0\n",
      "      15548 |   0.204378  |    0.212843     |   1\n",
      "      15549 |   0.042631  |    0.005109     |   2\n",
      "      15550 |   0.032696  |    0.054772     |   2\n",
      "      15551 | \u001b[94m  0.000041\u001b[0m  |    0.053717     |   2\n",
      "      15552 | \u001b[94m  0.000041\u001b[0m  |    0.041040     |   2\n",
      "      15553 |   0.238753  |    0.088586     |   0\n",
      "      15554 |   0.166433  |    0.176957     |   1\n",
      "      15555 |   0.203915  |    0.153964     |   1\n",
      "      15556 |   0.195449  |    0.010004     |   0\n",
      "      15557 |   0.184584  |    0.075896     |   0\n",
      "      15558 |   0.209124  |    0.010454     |   0\n",
      "      15559 |   0.239096  |    0.211332     |   1\n",
      "      15560 |   0.189728  |    0.140172     |   1\n",
      "      15561 |   0.209036  |    0.043725     |   0\n",
      "      15562 |   0.193112  |    0.074256     |   0\n",
      "      15563 |   0.246481  |    0.146069     |   1\n",
      "      15564 |   0.198043  |    0.083756     |   0\n",
      "      15565 | \u001b[94m  0.000041\u001b[0m  |    0.010213     |   2\n",
      "      15566 |   0.000041  |    0.076312     |   2\n",
      "      15567 |   0.223056  |    0.046286     |   0\n",
      "      15568 |   0.187673  |    0.039196     |   0\n",
      "      15569 |   0.185645  |    0.078066     |   0\n",
      "      15570 | \u001b[94m  0.000041\u001b[0m  |    0.012592     |   2\n",
      "      15571 |   0.200863  |    0.215312     |   1\n",
      "      15572 |   0.180502  |    0.007887     |   0\n",
      "      15573 |   0.000041  |    0.046675     |   2\n",
      "      15574 |   0.056254  |    0.057832     |   2\n",
      "      15575 |   0.210615  |    0.210758     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 15577: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      15576 |   0.056729  |    0.010270     |   2\n",
      "      15577 |   0.206978  |    0.049680     |   0\n",
      "      15578 |   0.224776  |    0.146394     |   1\n",
      "      15579 |   0.148630  |    0.019633     |   0\n",
      "      15580 |   0.055920  |    0.076201     |   2\n",
      "      15581 |   0.173937  |    0.160297     |   1\n",
      "      15582 |   0.319452  |    0.144715     |   1\n",
      "      15583 |   0.042555  |    0.045974     |   2\n",
      "      15584 |   0.131722  |    0.171823     |   1\n",
      "      15585 |   0.177780  |    0.162714     |   1\n",
      "      15586 |   0.042001  |    0.039297     |   2\n",
      "      15587 |   0.049068  |    0.066558     |   2\n",
      "      15588 |   0.167961  |    0.189456     |   1\n",
      "      15589 |   0.028807  |    0.005884     |   2\n",
      "      15590 |   0.147841  |    0.044124     |   0\n",
      "      15591 |   0.199467  |    0.085683     |   0\n",
      "      15592 |   0.159712  |    0.150881     |   1\n",
      "      15593 |   0.189673  |    0.162727     |   1\n",
      "      15594 |   0.183317  |    0.151168     |   1\n",
      "      15595 |   0.225384  |    0.147966     |   1\n",
      "      15596 |   0.042710  |    0.011116     |   2\n",
      "      15597 |   0.051308  |    0.047067     |   2\n",
      "      15598 |   0.058314  |    0.043323     |   2\n",
      "      15599 |   0.240282  |    0.079882     |   0\n",
      "      15600 |   0.047675  |    0.022953     |   2\n",
      "      15601 |   0.190338  |    0.074104     |   0\n",
      "      15602 |   0.143410  |    0.004842     |   0\n",
      "      15603 |   0.023188  |    0.076728     |   2\n",
      "      15604 |   0.000041  |    0.003417     |   2\n",
      "      15605 |   0.182898  |    0.083468     |   0\n",
      "      15606 |   0.007116  |    0.021719     |   2\n",
      "      15607 |   0.073774  |    0.052075     |   2\n",
      "      15608 |   0.219742  |    0.159531     |   1\n",
      "      15609 |   0.170839  |    0.191230     |   1\n",
      "      15610 |   0.187738  |    0.005861     |   0\n",
      "      15611 |   0.219989  |    0.041322     |   0\n",
      "      15612 |   0.037346  |    0.051826     |   2\n",
      "      15613 |   0.177779  |    0.205129     |   1\n",
      "      15614 |   0.060208  |    0.014049     |   2\n",
      "      15615 |   0.245642  |    0.195445     |   1\n",
      "      15616 |   0.239772  |    0.005989     |   0\n",
      "      15617 |   0.046079  |    0.060721     |   2\n",
      "      15618 |   0.156360  |    0.141540     |   1\n",
      "      15619 |   0.195040  |    0.065667     |   0\n",
      "      15620 |   0.203121  |    0.141159     |   1\n",
      "      15621 |   0.020590  |    0.020184     |   2\n",
      "      15622 |   0.173563  |    0.199838     |   1\n",
      "      15623 |   0.197448  |    0.005722     |   0\n",
      "      15624 |   0.210948  |    0.049142     |   0\n",
      "      15625 |   0.165991  |    0.024903     |   0\n",
      "      15626 |   0.173963  |    0.044747     |   0\n",
      "      15627 |   0.042221  |    0.058006     |   2\n",
      "      15628 |   0.034249  |    0.041155     |   2\n",
      "      15629 |   0.181750  |    0.056330     |   0\n",
      "      15630 |   0.183387  |    0.153700     |   1\n",
      "      15631 |   0.234838  |    0.042894     |   0\n",
      "      15632 |   0.192756  |    0.150274     |   1\n",
      "      15633 |   0.183723  |    0.135036     |   1\n",
      "      15634 |   0.134650  |    0.042895     |   0\n",
      "      15635 |   0.205010  |    0.049933     |   0\n",
      "      15636 | \u001b[94m  0.000040\u001b[0m  |    0.046297     |   2\n",
      "      15637 | \u001b[94m  0.000040\u001b[0m  |    0.044896     |   2\n",
      "      15638 |   0.183347  |    0.076042     |   0\n",
      "      15639 | \u001b[94m  0.000040\u001b[0m  |    0.039377     |   2\n",
      "      15640 |   0.177337  |    0.194148     |   1\n",
      "      15641 |   0.239013  |    0.153059     |   1\n",
      "      15642 |   0.000040  |    0.044380     |   2\n",
      "      15643 | \u001b[94m  0.000040\u001b[0m  |    0.049075     |   2\n",
      "      15644 | \u001b[94m  0.000040\u001b[0m  |    0.049879     |   2\n",
      "      15645 |   0.052222  |    0.051056     |   2\n",
      "      15646 |   0.173144  |    0.031889     |   0\n",
      "      15647 |   0.055826  |    0.093454     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 15648: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      15648 |   0.164777  |    0.167510     |   1\n",
      "      15649 |   0.186078  |    0.008240     |   0\n",
      "      15650 |   0.053961  |    0.054645     |   2\n",
      "      15651 |   0.174282  |    0.149430     |   1\n",
      "      15652 |   0.251252  |    0.146983     |   1\n",
      "      15653 |   0.216141  |    0.098366     |   1\n",
      "      15654 |   0.169837  |    0.055181     |   0\n",
      "      15655 |   0.153037  |    0.043157     |   0\n",
      "      15656 |   0.038773  |    0.064488     |   2\n",
      "      15657 |   0.131823  |    0.151389     |   1\n",
      "      15658 |   0.278775  |    0.162578     |   1\n",
      "      15659 |   0.041958  |    0.005092     |   2\n",
      "      15660 |   0.199323  |    0.077853     |   0\n",
      "      15661 |   0.045208  |    0.025142     |   2\n",
      "      15662 |   0.195206  |    0.083849     |   0\n",
      "      15663 |   0.028469  |    0.025861     |   2\n",
      "      15664 |   0.146958  |    0.197195     |   1\n",
      "      15665 |   0.162445  |    0.005929     |   0\n",
      "      15666 |   0.043210  |    0.075667     |   2\n",
      "      15667 |   0.189713  |    0.024712     |   0\n",
      "      15668 |   0.052969  |    0.048325     |   2\n",
      "      15669 |   0.173139  |    0.052644     |   0\n",
      "      15670 |   0.221040  |    0.134006     |   1\n",
      "      15671 |   0.184236  |    0.061571     |   0\n",
      "      15672 |   0.173870  |    0.194236     |   1\n",
      "      15673 |   0.229043  |    0.144018     |   1\n",
      "      15674 |   0.208232  |    0.143153     |   1\n",
      "      15675 |   0.059648  |    0.054507     |   2\n",
      "      15676 |   0.142549  |    0.157294     |   1\n",
      "      15677 |   0.050486  |    0.041154     |   2\n",
      "      15678 |   0.221078  |    0.235325     |   1\n",
      "      15679 |   0.177941  |    0.152306     |   1\n",
      "      15680 |   0.023061  |    0.020748     |   2\n",
      "      15681 |   0.000040  |    0.058770     |   2\n",
      "      15682 |   0.219421  |    0.161755     |   1\n",
      "      15683 |   0.006167  |    0.051708     |   2\n",
      "      15684 |   0.074549  |    0.039870     |   2\n",
      "      15685 |   0.237985  |    0.148840     |   1\n",
      "      15686 |   0.037884  |    0.077495     |   2\n",
      "      15687 |   0.159976  |    0.011991     |   0\n",
      "      15688 |   0.185160  |    0.078117     |   0\n",
      "      15689 |   0.060959  |    0.010112     |   2\n",
      "      15690 |   0.172742  |    0.075852     |   0\n",
      "      15691 |   0.049938  |    0.042256     |   2\n",
      "      15692 |   0.184143  |    0.172281     |   1\n",
      "      15693 |   0.283729  |    0.167869     |   1\n",
      "      15694 |   0.192830  |    0.145783     |   1\n",
      "      15695 |   0.019803  |    0.021299     |   2\n",
      "      15696 |   0.185132  |    0.070540     |   0\n",
      "      15697 |   0.183518  |    0.021092     |   0\n",
      "      15698 |   0.039669  |    0.095093     |   2\n",
      "      15699 |   0.199408  |    0.156572     |   1\n",
      "      15700 |   0.034947  |    0.005853     |   2\n",
      "      15701 |   0.000040  |    0.075295     |   2\n",
      "      15702 |   0.167915  |    0.196078     |   1\n",
      "      15703 |   0.180034  |    0.005838     |   0\n",
      "      15704 |   0.154436  |    0.200621     |   1\n",
      "      15705 | \u001b[94m  0.000040\u001b[0m  |    0.020022     |   2\n",
      "      15706 |   0.200549  |    0.211441     |   1\n",
      "      15707 |   0.000040  |    0.021263     |   2\n",
      "      15708 |   0.193775  |    0.223122     |   1\n",
      "      15709 |   0.166153  |    0.143151     |   1\n",
      "      15710 |   0.150667  |    0.018128     |   0\n",
      "      15711 |   0.265753  |    0.198710     |   1\n",
      "      15712 |   0.000040  |    0.023504     |   2\n",
      "      15713 | \u001b[94m  0.000040\u001b[0m  |    0.078732     |   2\n",
      "      15714 |   0.230378  |    0.152799     |   1\n",
      "      15715 |   0.167127  |    0.190964     |   1\n",
      "      15716 | \u001b[94m  0.000040\u001b[0m  |    0.004514     |   2\n",
      "      15717 |   0.172486  |    0.040521     |   0\n",
      "      15718 |   0.247337  |    0.209349     |   1\n",
      "      15719 |   0.153665  |    0.006146     |   0\n",
      "      15720 |   0.048681  |    0.041801     |   2\n",
      "      15721 |   0.054041  |    0.076409     |   2\n",
      "      15722 |   0.201287  |    0.033627     |   0\n",
      "      15723 |   0.162368  |    0.200664     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 15725: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      15724 |   0.197062  |    0.008352     |   0\n",
      "      15725 |   0.052568  |    0.081679     |   2\n",
      "      15726 |   0.186118  |    0.160002     |   1\n",
      "      15727 |   0.178784  |    0.147567     |   1\n",
      "      15728 |   0.036968  |    0.046937     |   2\n",
      "      15729 |   0.178712  |    0.051386     |   0\n",
      "      15730 |   0.281564  |    0.154815     |   1\n",
      "      15731 |   0.044217  |    0.023116     |   2\n",
      "      15732 |   0.160986  |    0.084820     |   0\n",
      "      15733 |   0.151832  |    0.174788     |   1\n",
      "      15734 |   0.247109  |    0.193860     |   1\n",
      "      15735 |   0.048399  |    0.020302     |   2\n",
      "      15736 |   0.202387  |    0.077713     |   0\n",
      "      15737 |   0.028502  |    0.019033     |   2\n",
      "      15738 |   0.191719  |    0.081129     |   0\n",
      "      15739 |   0.043173  |    0.005950     |   2\n",
      "      15740 |   0.184793  |    0.062406     |   0\n",
      "      15741 |   0.288671  |    0.175267     |   1\n",
      "      15742 |   0.049209  |    0.003937     |   2\n",
      "      15743 |   0.159835  |    0.172015     |   1\n",
      "      15744 |   0.061510  |    0.040168     |   2\n",
      "      15745 |   0.170524  |    0.044899     |   0\n",
      "      15746 |   0.165794  |    0.043496     |   0\n",
      "      15747 |   0.199402  |    0.083761     |   0\n",
      "      15748 |   0.215552  |    0.022540     |   0\n",
      "      15749 |   0.202795  |    0.076134     |   0\n",
      "      15750 |   0.268940  |    0.041500     |   0\n",
      "      15751 |   0.050037  |    0.043243     |   2\n",
      "      15752 |   0.226009  |    0.164319     |   1\n",
      "      15753 |   0.024676  |    0.051581     |   2\n",
      "      15754 |   0.252364  |    0.201076     |   1\n",
      "      15755 |   0.175729  |    0.004294     |   0\n",
      "      15756 | \u001b[94m  0.000039\u001b[0m  |    0.080463     |   2\n",
      "      15757 |   0.191178  |    0.133381     |   1\n",
      "      15758 |   0.203252  |    0.023836     |   0\n",
      "      15759 |   0.006045  |    0.048783     |   2\n",
      "      15760 |   0.166414  |    0.199956     |   1\n",
      "      15761 |   0.196752  |    0.008492     |   0\n",
      "      15762 |   0.176824  |    0.063218     |   0\n",
      "      15763 |   0.196779  |    0.160937     |   1\n",
      "      15764 |   0.229868  |    0.141228     |   1\n",
      "      15765 |   0.074194  |    0.051802     |   2\n",
      "      15766 |   0.208450  |    0.191290     |   1\n",
      "      15767 |   0.038360  |    0.005816     |   2\n",
      "      15768 |   0.062514  |    0.077661     |   2\n",
      "      15769 |   0.047260  |    0.011734     |   2\n",
      "      15770 |   0.201915  |    0.189543     |   1\n",
      "      15771 |   0.142119  |    0.003536     |   0\n",
      "      15772 |   0.017605  |    0.070027     |   2\n",
      "      15773 |   0.037945  |    0.025589     |   2\n",
      "      15774 |   0.259858  |    0.200047     |   1\n",
      "      15775 |   0.190269  |    0.141458     |   1\n",
      "      15776 |   0.033066  |    0.025525     |   2\n",
      "      15777 |   0.203200  |    0.040582     |   0\n",
      "      15778 |   0.182837  |    0.049955     |   0\n",
      "      15779 |   0.161925  |    0.160497     |   1\n",
      "      15780 |   0.158356  |    0.154334     |   1\n",
      "      15781 |   0.214960  |    0.026701     |   0\n",
      "      15782 | \u001b[94m  0.000039\u001b[0m  |    0.052716     |   2\n",
      "      15783 |   0.137842  |    0.217301     |   1\n",
      "      15784 | \u001b[94m  0.000039\u001b[0m  |    0.003914     |   2\n",
      "      15785 |   0.000039  |    0.043324     |   2\n",
      "      15786 |   0.265888  |    0.156354     |   1\n",
      "      15787 |   0.170656  |    0.146980     |   1\n",
      "      15788 |   0.000039  |    0.057247     |   2\n",
      "      15789 |   0.201742  |    0.157641     |   1\n",
      "      15790 | \u001b[94m  0.000039\u001b[0m  |    0.014331     |   2\n",
      "      15791 |   0.288058  |    0.205687     |   1\n",
      "      15792 |   0.234107  |    0.004532     |   0\n",
      "      15793 | \u001b[94m  0.000039\u001b[0m  |    0.054792     |   2\n",
      "      15794 |   0.204404  |    0.041173     |   0\n",
      "      15795 |   0.214433  |    0.211052     |   1\n",
      "      15796 |   0.048323  |    0.010770     |   2\n",
      "      15797 |   0.054788  |    0.070557     |   2\n",
      "      15798 |   0.208258  |    0.152392     |   1\n",
      "      15799 |   0.177437  |    0.131436     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 15800: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      15800 |   0.215597  |    0.039631     |   0\n",
      "      15801 |   0.048815  |    0.044280     |   2\n",
      "      15802 |   0.036405  |    0.072365     |   2\n",
      "      15803 |   0.042611  |    0.019681     |   2\n",
      "      15804 |   0.227885  |    0.077232     |   0\n",
      "      15805 |   0.211439  |    0.028652     |   0\n",
      "      15806 |   0.047325  |    0.048353     |   2\n",
      "      15807 |   0.027520  |    0.052579     |   2\n",
      "      15808 |   0.161899  |    0.052510     |   0\n",
      "      15809 |   0.146344  |    0.163107     |   1\n",
      "      15810 |   0.041961  |    0.026408     |   2\n",
      "      15811 |   0.052150  |    0.082861     |   2\n",
      "      15812 |   0.061094  |    0.005676     |   2\n",
      "      15813 |   0.049009  |    0.077923     |   2\n",
      "      15814 |   0.024866  |    0.026874     |   2\n",
      "      15815 |   0.211903  |    0.215172     |   1\n",
      "      15816 |   0.251623  |    0.167326     |   1\n",
      "      15817 |   0.180304  |    0.153097     |   1\n",
      "      15818 |   0.190295  |    0.003928     |   0\n",
      "      15819 |   0.147242  |    0.170016     |   1\n",
      "      15820 |   0.172365  |    0.151723     |   1\n",
      "      15821 |   0.236828  |    0.146071     |   1\n",
      "      15822 | \u001b[94m  0.000038\u001b[0m  |    0.045878     |   2\n",
      "      15823 |   0.189011  |    0.167210     |   1\n",
      "      15824 |   0.217162  |    0.020447     |   0\n",
      "      15825 |   0.144120  |    0.198546     |   1\n",
      "      15826 |   0.005485  |    0.012031     |   2\n",
      "      15827 |   0.070763  |    0.079213     |   2\n",
      "      15828 |   0.177520  |    0.025380     |   0\n",
      "      15829 |   0.035829  |    0.088648     |   2\n",
      "      15830 |   0.228717  |    0.135725     |   1\n",
      "      15831 |   0.059973  |    0.025486     |   2\n",
      "      15832 |   0.045579  |    0.055681     |   2\n",
      "      15833 |   0.152173  |    0.042206     |   0\n",
      "      15834 |   0.020390  |    0.047913     |   2\n",
      "      15835 |   0.193374  |    0.213718     |   1\n",
      "      15836 |   0.208913  |    0.093280     |   1\n",
      "      15837 |   0.167838  |    0.201590     |   1\n",
      "      15838 |   0.208846  |    0.140733     |   1\n",
      "      15839 |   0.149928  |    0.032428     |   0\n",
      "      15840 |   0.196663  |    0.039725     |   0\n",
      "      15841 |   0.039956  |    0.048426     |   2\n",
      "      15842 |   0.256235  |    0.039841     |   0\n",
      "      15843 |   0.031304  |    0.079744     |   2\n",
      "      15844 |   0.161380  |    0.136934     |   1\n",
      "      15845 | \u001b[94m  0.000038\u001b[0m  |    0.041930     |   2\n",
      "      15846 |   0.207928  |    0.157656     |   1\n",
      "      15847 |   0.154601  |    0.175388     |   1\n",
      "      15848 | \u001b[94m  0.000038\u001b[0m  |    0.010231     |   2\n",
      "      15849 |   0.168296  |    0.083061     |   0\n",
      "      15850 |   0.165558  |    0.143961     |   1\n",
      "      15851 |   0.225457  |    0.025167     |   0\n",
      "      15852 | \u001b[94m  0.000038\u001b[0m  |    0.055028     |   2\n",
      "      15853 |   0.214940  |    0.042472     |   0\n",
      "      15854 |   0.227686  |    0.078010     |   0\n",
      "      15855 |   0.000038  |    0.010433     |   2\n",
      "      15856 |   0.225065  |    0.149533     |   1\n",
      "      15857 |   0.203151  |    0.196803     |   1\n",
      "      15858 |   0.248585  |    0.108902     |   1\n",
      "      15859 | \u001b[94m  0.000038\u001b[0m  |    0.048781     |   2\n",
      "      15860 | \u001b[94m  0.000038\u001b[0m  |    0.046113     |   2\n",
      "      15861 |   0.196350  |    0.042244     |   0\n",
      "      15862 |   0.225302  |    0.075888     |   0\n",
      "      15863 |   0.055842  |    0.018815     |   2\n",
      "      15864 |   0.255443  |    0.201835     |   1\n",
      "      15865 |   0.054088  |    0.003508     |   2\n",
      "      15866 |   0.207736  |    0.185389     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 15867: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      15867 |   0.243975  |    0.138962     |   1\n",
      "      15868 |   0.051533  |    0.028965     |   2\n",
      "      15869 |   0.037813  |    0.050332     |   2\n",
      "      15870 |   0.176691  |    0.160041     |   1\n",
      "      15871 |   0.041762  |    0.042380     |   2\n",
      "      15872 |   0.046452  |    0.049355     |   2\n",
      "      15873 |   0.028920  |    0.035111     |   2\n",
      "      15874 |   0.210232  |    0.202691     |   1\n",
      "      15875 |   0.175721  |    0.144020     |   1\n",
      "      15876 |   0.233159  |    0.105628     |   1\n",
      "      15877 |   0.041970  |    0.021414     |   2\n",
      "      15878 |   0.185627  |    0.217584     |   1\n",
      "      15879 |   0.233376  |    0.152180     |   1\n",
      "      15880 |   0.048811  |    0.009377     |   2\n",
      "      15881 |   0.057682  |    0.089808     |   2\n",
      "      15882 |   0.049127  |    0.024261     |   2\n",
      "      15883 |   0.237084  |    0.155792     |   1\n",
      "      15884 |   0.025308  |    0.080384     |   2\n",
      "      15885 |   0.212259  |    0.037962     |   0\n",
      "      15886 |   0.177317  |    0.157479     |   1\n",
      "      15887 |   0.000038  |    0.005653     |   2\n",
      "      15888 |   0.006137  |    0.071526     |   2\n",
      "      15889 |   0.204711  |    0.034072     |   0\n",
      "      15890 |   0.227648  |    0.138697     |   1\n",
      "      15891 |   0.149953  |    0.044585     |   0\n",
      "      15892 |   0.243170  |    0.084113     |   0\n",
      "      15893 |   0.192513  |    0.134450     |   1\n",
      "      15894 |   0.160310  |    0.194407     |   1\n",
      "      15895 |   0.173790  |    0.098628     |   1\n",
      "      15896 |   0.291334  |    0.044445     |   0\n",
      "      15897 |   0.071072  |    0.076021     |   2\n",
      "      15898 |   0.201127  |    0.145401     |   1\n",
      "      15899 |   0.167288  |    0.192651     |   1\n",
      "      15900 |   0.181334  |    0.158750     |   1\n",
      "      15901 |   0.208499  |    0.141764     |   1\n",
      "      15902 |   0.145933  |    0.161156     |   1\n",
      "      15903 |   0.036347  |    0.025859     |   2\n",
      "      15904 |   0.198683  |    0.220393     |   1\n",
      "      15905 |   0.192643  |    0.142750     |   1\n",
      "      15906 |   0.182059  |    0.018253     |   0\n",
      "      15907 |   0.059731  |    0.079094     |   2\n",
      "      15908 |   0.235107  |    0.032253     |   0\n",
      "      15909 |   0.182577  |    0.198863     |   1\n",
      "      15910 |   0.043577  |    0.013731     |   2\n",
      "      15911 |   0.215621  |    0.078727     |   0\n",
      "      15912 |   0.199632  |    0.013191     |   0\n",
      "      15913 |   0.178052  |    0.196253     |   1\n",
      "      15914 |   0.183433  |    0.158387     |   1\n",
      "      15915 |   0.020311  |    0.037760     |   2\n",
      "      15916 |   0.042903  |    0.041917     |   2\n",
      "      15917 |   0.137456  |    0.046287     |   0\n",
      "      15918 |   0.232552  |    0.045127     |   0\n",
      "      15919 |   0.173811  |    0.078506     |   0\n",
      "      15920 |   0.031197  |    0.032882     |   2\n",
      "      15921 |   0.220793  |    0.187566     |   1\n",
      "      15922 |   0.206243  |    0.147474     |   1\n",
      "      15923 | \u001b[94m  0.000037\u001b[0m  |    0.029180     |   2\n",
      "      15924 | \u001b[94m  0.000037\u001b[0m  |    0.072835     |   2\n",
      "      15925 |   0.204933  |    0.154114     |   1\n",
      "      15926 |   0.000037  |    0.019726     |   2\n",
      "      15927 |   0.203360  |    0.146964     |   1\n",
      "      15928 |   0.000037  |    0.028939     |   2\n",
      "      15929 |   0.180974  |    0.071134     |   0\n",
      "      15930 |   0.236232  |    0.152117     |   1\n",
      "      15931 |   0.184079  |    0.040542     |   0\n",
      "      15932 |   0.209862  |    0.041991     |   0\n",
      "      15933 |   0.157722  |    0.056311     |   0\n",
      "      15934 |   0.194277  |    0.175127     |   1\n",
      "      15935 |   0.177379  |    0.135436     |   1\n",
      "      15936 | \u001b[94m  0.000037\u001b[0m  |    0.080370     |   2\n",
      "      15937 |   0.270739  |    0.130077     |   1\n",
      "      15938 |   0.000037  |    0.050104     |   2\n",
      "      15939 |   0.187633  |    0.040384     |   0\n",
      "      15940 |   0.169529  |    0.197630     |   1\n",
      "      15941 |   0.053017  |    0.014087     |   2\n",
      "      15942 |   0.054340  |    0.076129     |   2\n",
      "      15943 |   0.253032  |    0.135180     |   1\n",
      "      15944 |   0.189514  |    0.048888     |   0\n",
      "      15945 |   0.227405  |    0.076773     |   0\n",
      "      15946 |   0.155753  |    0.021147     |   0\n",
      "      15947 |   0.257976  |    0.214443     |   1\n",
      "      15948 |   0.172923  |    0.132071     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 15949: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      15949 |   0.222985  |    0.132847     |   1\n",
      "      15950 |   0.165956  |    0.056940     |   0\n",
      "      15951 |   0.220700  |    0.152193     |   1\n",
      "      15952 |   0.177232  |    0.148248     |   1\n",
      "      15953 |   0.267866  |    0.128916     |   1\n",
      "      15954 |   0.214205  |    0.010630     |   0\n",
      "      15955 |   0.049834  |    0.064706     |   2\n",
      "      15956 |   0.036513  |    0.042898     |   2\n",
      "      15957 |   0.241838  |    0.078392     |   0\n",
      "      15958 |   0.234466  |    0.020915     |   0\n",
      "      15959 |   0.146608  |    0.083334     |   0\n",
      "      15960 |   0.042137  |    0.030136     |   2\n",
      "      15961 |   0.197940  |    0.200901     |   1\n",
      "      15962 |   0.203999  |    0.003393     |   0\n",
      "      15963 |   0.185538  |    0.170364     |   1\n",
      "      15964 |   0.145761  |    0.139184     |   1\n",
      "      15965 |   0.225385  |    0.041213     |   0\n",
      "      15966 |   0.170157  |    0.212808     |   1\n",
      "      15967 |   0.144978  |    0.009504     |   0\n",
      "      15968 |   0.203943  |    0.190716     |   1\n",
      "      15969 |   0.171914  |    0.017041     |   0\n",
      "      15970 |   0.257616  |    0.145276     |   1\n",
      "      15971 |   0.165396  |    0.039300     |   0\n",
      "      15972 |   0.218898  |    0.165304     |   1\n",
      "      15973 |   0.200329  |    0.153353     |   1\n",
      "      15974 |   0.226031  |    0.041493     |   0\n",
      "      15975 |   0.179565  |    0.042079     |   0\n",
      "      15976 |   0.240594  |    0.142882     |   1\n",
      "      15977 |   0.258053  |    0.137605     |   1\n",
      "      15978 |   0.217893  |    0.047742     |   0\n",
      "      15979 |   0.170094  |    0.058299     |   0\n",
      "      15980 |   0.224776  |    0.155574     |   1\n",
      "      15981 |   0.217673  |    0.044662     |   0\n",
      "      15982 |   0.221526  |    0.137225     |   1\n",
      "      15983 |   0.232396  |    0.049975     |   0\n",
      "      15984 |   0.207917  |    0.146045     |   1\n",
      "      15985 |   0.218375  |    0.141866     |   1\n",
      "      15986 |   0.047433  |    0.024411     |   2\n",
      "      15987 |   0.172456  |    0.215851     |   1\n",
      "      15988 |   0.225395  |    0.006359     |   0\n",
      "      15989 |   0.194154  |    0.080364     |   0\n",
      "      15990 |   0.202060  |    0.150679     |   1\n",
      "      15991 |   0.029660  |    0.020604     |   2\n",
      "      15992 |   0.203471  |    0.046922     |   0\n",
      "      15993 |   0.172881  |    0.045477     |   0\n",
      "      15994 |   0.209541  |    0.192119     |   1\n",
      "      15995 |   0.221209  |    0.139713     |   1\n",
      "      15996 |   0.043409  |    0.003849     |   2\n",
      "      15997 |   0.193923  |    0.183736     |   1\n",
      "      15998 |   0.169760  |    0.026116     |   0\n",
      "      15999 |   0.057324  |    0.076863     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 16000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 16000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      16000 |   0.148151  |    0.018668     |   0\n",
      "      16001 |   0.190953  |    0.078140     |   0\n",
      "      16002 |   0.052411  |    0.029758     |   2\n",
      "      16003 |   0.039972  |    0.077113     |   2\n",
      "      16004 |   0.212461  |    0.047110     |   0\n",
      "      16005 |   0.165004  |    0.046476     |   0\n",
      "      16006 |   0.043298  |    0.046145     |   2\n",
      "      16007 |   0.234865  |    0.152031     |   1\n",
      "      16008 |   0.229625  |    0.161170     |   1\n",
      "      16009 |   0.046324  |    0.040399     |   2\n",
      "      16010 |   0.028573  |    0.083128     |   2\n",
      "      16011 |   0.246538  |    0.195157     |   1\n",
      "      16012 |   0.272966  |    0.019480     |   0\n",
      "      16013 |   0.043486  |    0.081105     |   2\n",
      "      16014 |   0.163697  |    0.064076     |   0\n",
      "      16015 |   0.185219  |    0.180155     |   1\n",
      "      16016 |   0.163920  |    0.052266     |   0\n",
      "      16017 |   0.054199  |    0.085258     |   2\n",
      "      16018 |   0.222009  |    0.186328     |   1\n",
      "      16019 |   0.061011  |    0.005726     |   2\n",
      "      16020 |   0.181894  |    0.055676     |   0\n",
      "      16021 |   0.049872  |    0.042324     |   2\n",
      "      16022 |   0.181077  |    0.044717     |   0\n",
      "      16023 |   0.201296  |    0.189152     |   1\n",
      "      16024 |   0.238133  |    0.210229     |   1\n",
      "      16025 |   0.223283  |    0.131344     |   1\n",
      "      16026 |   0.024952  |    0.061503     |   2\n",
      "      16027 |   0.187891  |    0.196750     |   1\n",
      "      16028 |   0.141103  |    0.009253     |   0\n",
      "      16029 |   0.000037  |    0.052090     |   2\n",
      "      16030 |   0.006756  |    0.040657     |   2\n",
      "      16031 |   0.178315  |    0.043301     |   0\n",
      "      16032 |   0.173705  |    0.045344     |   0\n",
      "      16033 |   0.072970  |    0.087011     |   2\n",
      "      16034 |   0.168790  |    0.180402     |   1\n",
      "      16035 |   0.177151  |    0.195994     |   1\n",
      "      16036 |   0.234250  |    0.025633     |   0\n",
      "      16037 |   0.252306  |    0.087294     |   0\n",
      "      16038 |   0.037758  |    0.018784     |   2\n",
      "      16039 |   0.134420  |    0.247713     |   1\n",
      "      16040 |   0.062643  |    0.018428     |   2\n",
      "      16041 |   0.190155  |    0.049142     |   0\n",
      "      16042 |   0.182015  |    0.044818     |   0\n",
      "      16043 |   0.211883  |    0.170046     |   1\n",
      "      16044 |   0.183649  |    0.076251     |   0\n",
      "      16045 |   0.208409  |    0.019592     |   0\n",
      "      16046 |   0.250574  |    0.197244     |   1\n",
      "      16047 |   0.188568  |    0.139245     |   1\n",
      "      16048 |   0.201281  |    0.040126     |   0\n",
      "      16049 |   0.051053  |    0.049168     |   2\n",
      "      16050 |   0.020447  |    0.045128     |   2\n",
      "      16051 |   0.199413  |    0.043230     |   0\n",
      "      16052 |   0.221073  |    0.204249     |   1\n",
      "      16053 |   0.142073  |    0.023003     |   0\n",
      "      16054 |   0.223088  |    0.078945     |   0\n",
      "      16055 |   0.046222  |    0.017105     |   2\n",
      "      16056 |   0.150298  |    0.188099     |   1\n",
      "      16057 |   0.243421  |    0.135182     |   1\n",
      "      16058 |   0.227581  |    0.020910     |   0\n",
      "      16059 |   0.201567  |    0.209103     |   1\n",
      "      16060 |   0.030435  |    0.018002     |   2\n",
      "      16061 |   0.193811  |    0.211117     |   1\n",
      "      16062 |   0.209845  |    0.214164     |   1\n",
      "      16063 |   0.187563  |    0.204725     |   1\n",
      "      16064 |   0.117331  |    0.194727     |   1\n",
      "      16065 |   0.236920  |    0.139851     |   1\n",
      "      16066 |   0.000037  |    0.049443     |   2\n",
      "      16067 |   0.000037  |    0.049729     |   2\n",
      "      16068 |   0.131928  |    0.054069     |   0\n",
      "      16069 |   0.215564  |    0.189568     |   1\n",
      "      16070 |   0.208792  |    0.138959     |   1\n",
      "      16071 |   0.239587  |    0.105758     |   1\n",
      "      16072 |   0.206370  |    0.071327     |   0\n",
      "      16073 |   0.196464  |    0.047426     |   0\n",
      "      16074 |   0.000037  |    0.050659     |   2\n",
      "      16075 |   0.000038  |    0.076092     |   2\n",
      "      16076 |   0.136012  |    0.026061     |   0\n",
      "      16077 |   0.267145  |    0.211764     |   1\n",
      "      16078 |   0.185591  |    0.041786     |   0\n",
      "      16079 |   0.194513  |    0.095164     |   0\n",
      "      16080 |   0.158872  |    0.034722     |   0\n",
      "      16081 |   0.000037  |    0.039572     |   2\n",
      "      16082 |   0.000037  |    0.087950     |   2\n",
      "      16083 |   0.050371  |    0.012342     |   2\n",
      "      16084 |   0.187006  |    0.079699     |   0\n",
      "      16085 |   0.186561  |    0.026827     |   0\n",
      "      16086 |   0.198118  |    0.078996     |   0\n",
      "      16087 |   0.053696  |    0.075520     |   2\n",
      "      16088 |   0.182696  |    0.052574     |   0\n",
      "      16089 |   0.176409  |    0.063409     |   0\n",
      "      16090 |   0.203499  |    0.193305     |   1\n",
      "      16091 |   0.180371  |    0.142833     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 16092: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      16092 |   0.147767  |    0.200790     |   1\n",
      "      16093 |   0.185505  |    0.003688     |   0\n",
      "      16094 |   0.199131  |    0.075321     |   0\n",
      "      16095 |   0.252101  |    0.017818     |   0\n",
      "      16096 |   0.056121  |    0.079643     |   2\n",
      "      16097 |   0.195857  |    0.143281     |   1\n",
      "      16098 |   0.220724  |    0.044839     |   0\n",
      "      16099 |   0.225012  |    0.046683     |   0\n",
      "      16100 |   0.212481  |    0.216148     |   1\n",
      "      16101 |   0.179625  |    0.091076     |   1\n",
      "      16102 |   0.221340  |    0.038995     |   0\n",
      "      16103 |   0.199288  |    0.056035     |   0\n",
      "      16104 |   0.229097  |    0.151822     |   1\n",
      "      16105 |   0.042940  |    0.028411     |   2\n",
      "      16106 |   0.196105  |    0.188654     |   1\n",
      "      16107 |   0.045019  |    0.046715     |   2\n",
      "      16108 |   0.050272  |    0.051484     |   2\n",
      "      16109 |   0.028573  |    0.045368     |   2\n",
      "      16110 |   0.201742  |    0.154434     |   1\n",
      "      16111 |   0.215108  |    0.131768     |   1\n",
      "      16112 |   0.257270  |    0.073545     |   0\n",
      "      16113 |   0.044264  |    0.019443     |   2\n",
      "      16114 |   0.198215  |    0.157899     |   1\n",
      "      16115 |   0.055912  |    0.039617     |   2\n",
      "      16116 |   0.197088  |    0.082956     |   0\n",
      "      16117 |   0.062694  |    0.015437     |   2\n",
      "      16118 |   0.160802  |    0.086297     |   0\n",
      "      16119 |   0.203418  |    0.004142     |   0\n",
      "      16120 |   0.204334  |    0.078157     |   0\n",
      "      16121 |   0.171748  |    0.043801     |   0\n",
      "      16122 |   0.213361  |    0.160958     |   1\n",
      "      16123 |   0.189000  |    0.136993     |   1\n",
      "      16124 |   0.189148  |    0.027721     |   0\n",
      "      16125 |   0.221827  |    0.163516     |   1\n",
      "      16126 |   0.052357  |    0.043066     |   2\n",
      "      16127 |   0.022875  |    0.037959     |   2\n",
      "      16128 |   0.142519  |    0.048265     |   0\n",
      "      16129 |   0.183475  |    0.193445     |   1\n",
      "      16130 |   0.000038  |    0.013593     |   2\n",
      "      16131 |   0.191812  |    0.212013     |   1\n",
      "      16132 |   0.168301  |    0.005634     |   0\n",
      "      16133 |   0.006920  |    0.034096     |   2\n",
      "      16134 |   0.221844  |    0.145403     |   1\n",
      "      16135 |   0.130271  |    0.045517     |   0\n",
      "      16136 |   0.078170  |    0.046030     |   2\n",
      "      16137 |   0.201568  |    0.204367     |   1\n",
      "      16138 |   0.037447  |    0.040447     |   2\n",
      "      16139 |   0.245617  |    0.189613     |   1\n",
      "      16140 |   0.063892  |    0.005008     |   2\n",
      "      16141 |   0.210927  |    0.073308     |   0\n",
      "      16142 |   0.224557  |    0.025941     |   0\n",
      "      16143 |   0.051016  |    0.081004     |   2\n",
      "      16144 |   0.194391  |    0.149631     |   1\n",
      "      16145 |   0.218427  |    0.024160     |   0\n",
      "      16146 |   0.016774  |    0.083298     |   2\n",
      "      16147 |   0.041486  |    0.009482     |   2\n",
      "      16148 |   0.201537  |    0.192400     |   1\n",
      "      16149 |   0.032933  |    0.039280     |   2\n",
      "      16150 |   0.188292  |    0.198313     |   1\n",
      "      16151 |   0.000038  |    0.037811     |   2\n",
      "      16152 |   0.249238  |    0.143088     |   1\n",
      "      16153 |   0.193029  |    0.174320     |   1\n",
      "      16154 |   0.188594  |    0.033835     |   0\n",
      "      16155 |   0.151120  |    0.047607     |   0\n",
      "      16156 |   0.000037  |    0.038407     |   2\n",
      "      16157 |   0.197676  |    0.092624     |   0\n",
      "      16158 |   0.224480  |    0.135719     |   1\n",
      "      16159 |   0.191055  |    0.025721     |   0\n",
      "      16160 |   0.196821  |    0.189206     |   1\n",
      "      16161 |   0.164726  |    0.014942     |   0\n",
      "      16162 |   0.217121  |    0.089526     |   0\n",
      "      16163 |   0.160541  |    0.136860     |   1\n",
      "      16164 |   0.221688  |    0.144276     |   1\n",
      "      16165 |   0.205548  |    0.170523     |   1\n",
      "      16166 |   0.181666  |    0.131475     |   1\n",
      "      16167 |   0.000037  |    0.079290     |   2\n",
      "      16168 |   0.156150  |    0.008642     |   0\n",
      "      16169 |   0.000037  |    0.085893     |   2\n",
      "      16170 |   0.229044  |    0.106615     |   1\n",
      "      16171 |   0.176527  |    0.180682     |   1\n",
      "      16172 |   0.185111  |    0.137456     |   1\n",
      "      16173 |   0.146246  |    0.036439     |   0\n",
      "      16174 |   0.201413  |    0.161655     |   1\n",
      "      16175 |   0.262708  |    0.161732     |   1\n",
      "      16176 |   0.000037  |    0.014875     |   2\n",
      "      16177 |   0.000037  |    0.088119     |   2\n",
      "      16178 |   0.229175  |    0.153998     |   1\n",
      "      16179 |   0.272314  |    0.101028     |   1\n",
      "      16180 |   0.190389  |    0.019457     |   0\n",
      "      16181 |   0.172103  |    0.093379     |   0\n",
      "      16182 |   0.163766  |    0.125286     |   1\n",
      "      16183 |   0.049250  |    0.017155     |   2\n",
      "      16184 |   0.054294  |    0.074417     |   2\n",
      "      16185 |   0.221158  |    0.018200     |   0\n",
      "      16186 |   0.224890  |    0.081523     |   0\n",
      "      16187 |   0.212464  |    0.131020     |   1\n",
      "      16188 |   0.216393  |    0.191616     |   1\n",
      "      16189 |   0.156464  |    0.008614     |   0\n",
      "      16190 |   0.190607  |    0.173277     |   1\n",
      "      16191 |   0.203281  |    0.026847     |   0\n",
      "      16192 |   0.201500  |    0.231589     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 16193: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      16193 |   0.223531  |    0.094298     |   1\n",
      "      16194 |   0.231906  |    0.045613     |   0\n",
      "      16195 |   0.208498  |    0.039384     |   0\n",
      "      16196 |   0.200875  |    0.079434     |   0\n",
      "      16197 |   0.054366  |    0.013935     |   2\n",
      "      16198 |   0.202233  |    0.213510     |   1\n",
      "      16199 |   0.173453  |    0.145309     |   1\n",
      "      16200 |   0.042348  |    0.040638     |   2\n",
      "      16201 |   0.044245  |    0.047110     |   2\n",
      "      16202 |   0.149088  |    0.209757     |   1\n",
      "      16203 |   0.048847  |    0.006768     |   2\n",
      "      16204 |   0.170052  |    0.077810     |   0\n",
      "      16205 |   0.204520  |    0.168909     |   1\n",
      "      16206 |   0.253386  |    0.135635     |   1\n",
      "      16207 |   0.029108  |    0.037625     |   2\n",
      "      16208 |   0.196452  |    0.044576     |   0\n",
      "      16209 |   0.041740  |    0.077419     |   2\n",
      "      16210 |   0.230249  |    0.139928     |   1\n",
      "      16211 |   0.155144  |    0.030969     |   0\n",
      "      16212 |   0.051219  |    0.044137     |   2\n",
      "      16213 |   0.059570  |    0.040731     |   2\n",
      "      16214 |   0.050973  |    0.078577     |   2\n",
      "      16215 |   0.243289  |    0.008936     |   0\n",
      "      16216 |   0.135102  |    0.047735     |   0\n",
      "      16217 |   0.260682  |    0.144903     |   1\n",
      "      16218 |   0.024983  |    0.048918     |   2\n",
      "      16219 |   0.000037  |    0.046364     |   2\n",
      "      16220 |   0.007004  |    0.035909     |   2\n",
      "      16221 |   0.192766  |    0.072383     |   0\n",
      "      16222 |   0.195817  |    0.018255     |   0\n",
      "      16223 |   0.073301  |    0.049204     |   2\n",
      "      16224 |   0.036506  |    0.074418     |   2\n",
      "      16225 |   0.212005  |    0.160120     |   1\n",
      "      16226 |   0.063067  |    0.006973     |   2\n",
      "      16227 |   0.169635  |    0.053152     |   0\n",
      "      16228 |   0.188796  |    0.078077     |   0\n",
      "      16229 |   0.046480  |    0.008546     |   2\n",
      "      16230 |   0.167533  |    0.084980     |   0\n",
      "      16231 |   0.216233  |    0.151754     |   1\n",
      "      16232 |   0.017722  |    0.021264     |   2\n",
      "      16233 |   0.165043  |    0.169448     |   1\n",
      "      16234 |   0.177182  |    0.047718     |   0\n",
      "      16235 |   0.181432  |    0.046896     |   0\n",
      "      16236 |   0.205671  |    0.041729     |   0\n",
      "      16237 |   0.219590  |    0.076827     |   0\n",
      "      16238 |   0.218196  |    0.144022     |   1\n",
      "      16239 |   0.042274  |    0.037680     |   2\n",
      "      16240 |   0.192059  |    0.166036     |   1\n",
      "      16241 |   0.180454  |    0.159153     |   1\n",
      "      16242 |   0.248045  |    0.198409     |   1\n",
      "      16243 |   0.032127  |    0.006651     |   2\n",
      "      16244 |   0.000037  |    0.087966     |   2\n",
      "      16245 |   0.205821  |    0.146991     |   1\n",
      "      16246 |   0.000037  |    0.037546     |   2\n",
      "      16247 |   0.000037  |    0.051623     |   2\n",
      "      16248 |   0.000038  |    0.044810     |   2\n",
      "      16249 |   0.000037  |    0.053145     |   2\n",
      "      16250 |   0.000037  |    0.034603     |   2\n",
      "      16251 |   0.051273  |    0.041332     |   2\n",
      "      16252 |   0.160654  |    0.050237     |   0\n",
      "      16253 |   0.231573  |    0.205325     |   1\n",
      "      16254 |   0.054309  |    0.005312     |   2\n",
      "      16255 |   0.231851  |    0.216631     |   1\n",
      "      16256 |   0.186664  |    0.109032     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 16257: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      16257 |   0.224991  |    0.155667     |   1\n",
      "      16258 |   0.226168  |    0.191565     |   1\n",
      "      16259 |   0.183266  |    0.167666     |   1\n",
      "      16260 |   0.244514  |    0.164434     |   1\n",
      "      16261 |   0.167387  |    0.156364     |   1\n",
      "      16262 |   0.048004  |    0.045048     |   2\n",
      "      16263 |   0.194271  |    0.034894     |   0\n",
      "      16264 |   0.195447  |    0.141017     |   1\n",
      "      16265 |   0.202138  |    0.043019     |   0\n",
      "      16266 |   0.142405  |    0.190665     |   1\n",
      "      16267 |   0.037939  |    0.025984     |   2\n",
      "      16268 |   0.220070  |    0.074583     |   0\n",
      "      16269 |   0.041172  |    0.034082     |   2\n",
      "      16270 |   0.151993  |    0.052607     |   0\n",
      "      16271 |   0.223803  |    0.146390     |   1\n",
      "      16272 |   0.287914  |    0.158586     |   1\n",
      "      16273 |   0.215900  |    0.159116     |   1\n",
      "      16274 |   0.244952  |    0.204971     |   1\n",
      "      16275 |   0.158328  |    0.019481     |   0\n",
      "      16276 |   0.047998  |    0.075701     |   2\n",
      "      16277 |   0.243349  |    0.149192     |   1\n",
      "      16278 |   0.217981  |    0.195264     |   1\n",
      "      16279 |   0.155534  |    0.201079     |   1\n",
      "      16280 |   0.028813  |    0.041930     |   2\n",
      "      16281 |   0.168611  |    0.048347     |   0\n",
      "      16282 |   0.219846  |    0.188556     |   1\n",
      "      16283 |   0.162740  |    0.004804     |   0\n",
      "      16284 |   0.273756  |    0.079512     |   0\n",
      "      16285 |   0.185742  |    0.153618     |   1\n",
      "      16286 |   0.199663  |    0.254727     |   1\n",
      "      16287 |   0.039592  |    0.082276     |   2\n",
      "      16288 |   0.211997  |    0.079152     |   0\n",
      "      16289 |   0.174383  |    0.266292     |   1\n",
      "      16290 |   0.170637  |    0.077369     |   0\n",
      "      16291 |   0.217576  |    0.047006     |   0\n",
      "      16292 |   0.200416  |    0.073484     |   0\n",
      "      16293 |   0.051952  |    0.003181     |   2\n",
      "      16294 |   0.202623  |    0.078917     |   0\n",
      "      16295 |   0.208626  |    0.230629     |   1\n",
      "      16296 |   0.224663  |    0.035367     |   0\n",
      "      16297 |   0.246414  |    0.174030     |   1\n",
      "      16298 |   0.161002  |    0.045650     |   0\n",
      "      16299 |   0.060939  |    0.042496     |   2\n",
      "      16300 |   0.051062  |    0.089489     |   2\n",
      "      16301 |   0.023749  |    0.029348     |   2\n",
      "      16302 |   0.202262  |    0.077111     |   0\n",
      "      16303 |   0.197372  |    0.202820     |   1\n",
      "      16304 |   0.196482  |    0.160644     |   1\n",
      "      16305 |   0.199403  |    0.021805     |   0\n",
      "      16306 |   0.138595  |    0.287254     |   1\n",
      "      16307 | \u001b[94m  0.000037\u001b[0m  |    0.037383     |   2\n",
      "      16308 |   0.183910  |    0.079413     |   0\n",
      "      16309 |   0.006923  |    0.091156     |   2\n",
      "      16310 |   0.194012  |    0.014593     |   0\n",
      "      16311 |   0.071477  |    0.095440     |   2\n",
      "      16312 |   0.174057  |    0.020465     |   0\n",
      "      16313 |   0.161520  |    0.081094     |   0\n",
      "      16314 |   0.201960  |    0.087787     |   0\n",
      "      16315 |   0.038526  |    0.076124     |   2\n",
      "      16316 |   0.175953  |    0.080590     |   0\n",
      "      16317 |   0.362463  |    0.236943     |   1\n",
      "      16318 |   0.217308  |    0.269056     |   1\n",
      "      16319 |   0.249573  |    0.189145     |   1\n",
      "      16320 |   0.060704  |    0.044658     |   2\n",
      "      16321 |   0.047616  |    0.082885     |   2\n",
      "      16322 |   0.211275  |    0.076560     |   0\n",
      "      16323 |   0.017598  |    0.085636     |   2\n",
      "      16324 |   0.041841  |    0.040443     |   2\n",
      "      16325 |   0.198597  |    0.083394     |   0\n",
      "      16326 |   0.196319  |    0.072557     |   0\n",
      "      16327 |   0.033548  |    0.037587     |   2\n",
      "      16328 |   0.000037  |    0.080117     |   2\n",
      "      16329 |   0.182002  |    0.052904     |   0\n",
      "      16330 |   0.164394  |    0.087384     |   0\n",
      "      16331 |   0.000037  |    0.074270     |   2\n",
      "      16332 |   0.183981  |    0.076106     |   0\n",
      "      16333 |   0.000037  |    0.091852     |   2\n",
      "      16334 |   0.157058  |    0.140143     |   0\n",
      "      16335 |   0.223696  |    0.243240     |   1\n",
      "      16336 |   0.222366  |    0.064326     |   0\n",
      "      16337 |   0.245544  |    0.250442     |   1\n",
      "      16338 |   0.000037  |    0.058361     |   2\n",
      "      16339 |   0.235854  |    0.215217     |   1\n",
      "      16340 |   0.272910  |    0.224018     |   1\n",
      "      16341 |   0.185221  |    0.206330     |   1\n",
      "      16342 |   0.216450  |    0.201969     |   1\n",
      "      16343 |   0.193292  |    0.025900     |   0\n",
      "      16344 |   0.196884  |    0.202794     |   1\n",
      "      16345 |   0.156586  |    0.197052     |   1\n",
      "      16346 |   0.174006  |    0.023281     |   0\n",
      "      16347 |   0.218992  |    0.078962     |   0\n",
      "      16348 |   0.182215  |    0.043924     |   0\n",
      "      16349 |   0.247703  |    0.252051     |   1\n",
      "      16350 |   0.171835  |    0.018471     |   0\n",
      "      16351 |   0.201069  |    0.079225     |   0\n",
      "      16352 |   0.221827  |    0.081140     |   0\n",
      "      16353 |   0.197187  |    0.043970     |   0\n",
      "      16354 | \u001b[94m  0.000037\u001b[0m  |    0.076729     |   2\n",
      "      16355 |   0.239582  |    0.025931     |   0\n",
      "      16356 |   0.182437  |    0.168227     |   1\n",
      "      16357 | \u001b[94m  0.000037\u001b[0m  |    0.040835     |   2\n",
      "      16358 |   0.251053  |    0.043941     |   0\n",
      "      16359 |   0.160139  |    0.074322     |   0\n",
      "      16360 |   0.152743  |    0.058504     |   0\n",
      "      16361 |   0.259885  |    0.150638     |   1\n",
      "      16362 |   0.211366  |    0.193655     |   1\n",
      "      16363 |   0.231121  |    0.007526     |   0\n",
      "      16364 |   0.169752  |    0.075195     |   0\n",
      "      16365 |   0.055179  |    0.076407     |   2\n",
      "      16366 |   0.222254  |    0.158414     |   1\n",
      "      16367 |   0.161713  |    0.008262     |   0\n",
      "      16368 |   0.235324  |    0.199435     |   1\n",
      "      16369 |   0.175591  |    0.008273     |   0\n",
      "      16370 |   0.178171  |    0.060557     |   0\n",
      "      16371 |   0.141066  |    0.204533     |   1\n",
      "      16372 |   0.213856  |    0.276348     |   1\n",
      "      16373 |   0.204578  |    0.007460     |   0\n",
      "      16374 |   0.055306  |    0.125694     |   2\n",
      "      16375 |   0.213624  |    0.027954     |   0\n",
      "      16376 |   0.193957  |    0.209696     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 16377: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      16377 |   0.229527  |    0.195427     |   1\n",
      "      16378 |   0.053521  |    0.029627     |   2\n",
      "      16379 |   0.163479  |    0.224955     |   1\n",
      "      16380 |   0.255775  |    0.150421     |   1\n",
      "      16381 |   0.142928  |    0.049164     |   0\n",
      "      16382 |   0.202141  |    0.206653     |   1\n",
      "      16383 |   0.184954  |    0.138741     |   1\n",
      "      16384 |   0.160584  |    0.014785     |   0\n",
      "      16385 |   0.036930  |    0.078144     |   2\n",
      "      16386 |   0.043873  |    0.013690     |   2\n",
      "      16387 |   0.172167  |    0.078712     |   0\n",
      "      16388 |   0.049860  |    0.045015     |   2\n",
      "      16389 |   0.207550  |    0.049783     |   0\n",
      "      16390 |   0.116445  |    0.046613     |   0\n",
      "      16391 |   0.161037  |    0.207872     |   1\n",
      "      16392 |   0.028474  |    0.040047     |   2\n",
      "      16393 |   0.040274  |    0.072170     |   2\n",
      "      16394 |   0.207928  |    0.042300     |   0\n",
      "      16395 |   0.270443  |    0.055999     |   0\n",
      "      16396 |   0.053674  |    0.046737     |   2\n",
      "      16397 |   0.057399  |    0.062620     |   2\n",
      "      16398 |   0.206418  |    0.164543     |   1\n",
      "      16399 |   0.230445  |    0.152172     |   1\n",
      "      16400 |   0.192799  |    0.005983     |   0\n",
      "      16401 |   0.211706  |    0.079831     |   0\n",
      "      16402 |   0.230517  |    0.186330     |   1\n",
      "      16403 |   0.216449  |    0.257613     |   1\n",
      "      16404 |   0.187849  |    0.160028     |   1\n",
      "      16405 |   0.209730  |    0.151204     |   1\n",
      "      16406 |   0.048093  |    0.043106     |   2\n",
      "      16407 |   0.209888  |    0.048486     |   0\n",
      "      16408 |   0.023709  |    0.048018     |   2\n",
      "      16409 |   0.172064  |    0.194463     |   1\n",
      "      16410 |   0.000038  |    0.032886     |   2\n",
      "      16411 |   0.006491  |    0.047165     |   2\n",
      "      16412 |   0.201299  |    0.050677     |   0\n",
      "      16413 |   0.203664  |    0.193538     |   1\n",
      "      16414 |   0.172822  |    0.074802     |   0\n",
      "      16415 |   0.071652  |    0.026303     |   2\n",
      "      16416 |   0.217561  |    0.218932     |   1\n",
      "      16417 |   0.179226  |    0.137508     |   1\n",
      "      16418 |   0.034952  |    0.029779     |   2\n",
      "      16419 |   0.060262  |    0.081270     |   2\n",
      "      16420 |   0.181627  |    0.007354     |   0\n",
      "      16421 |   0.045931  |    0.079375     |   2\n",
      "      16422 |   0.191573  |    0.189709     |   1\n",
      "      16423 |   0.159890  |    0.007957     |   0\n",
      "      16424 |   0.178695  |    0.074492     |   0\n",
      "      16425 |   0.179708  |    0.204776     |   1\n",
      "      16426 |   0.222363  |    0.152917     |   1\n",
      "      16427 |   0.229131  |    0.025198     |   0\n",
      "      16428 |   0.018434  |    0.077333     |   2\n",
      "      16429 |   0.215173  |    0.187063     |   1\n",
      "      16430 |   0.212818  |    0.005419     |   0\n",
      "      16431 |   0.236709  |    0.070954     |   0\n",
      "      16432 |   0.042516  |    0.049866     |   2\n",
      "      16433 |   0.190722  |    0.098256     |   0\n",
      "      16434 |   0.031848  |    0.017062     |   2\n",
      "      16435 |   0.179654  |    0.221935     |   1\n",
      "      16436 |   0.161020  |    0.006633     |   0\n",
      "      16437 |   0.000037  |    0.059910     |   2\n",
      "      16438 |   0.204476  |    0.073658     |   0\n",
      "      16439 |   0.000037  |    0.013471     |   2\n",
      "      16440 |   0.000037  |    0.080432     |   2\n",
      "      16441 |   0.198886  |    0.030484     |   0\n",
      "      16442 |   0.000037  |    0.027531     |   2\n",
      "      16443 |   0.171411  |    0.074784     |   0\n",
      "      16444 |   0.000037  |    0.025096     |   2\n",
      "      16445 |   0.000037  |    0.083517     |   2\n",
      "      16446 |   0.209876  |    0.200212     |   1\n",
      "      16447 |   0.049952  |    0.035235     |   2\n",
      "      16448 |   0.053782  |    0.089217     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 16449: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      16449 |   0.047813  |    0.054407     |   2\n",
      "      16450 |   0.196541  |    0.043462     |   0\n",
      "      16451 |   0.036554  |    0.047617     |   2\n",
      "      16452 |   0.159924  |    0.076699     |   0\n",
      "      16453 |   0.042811  |    0.039486     |   2\n",
      "      16454 |   0.196999  |    0.184398     |   1\n",
      "      16455 |   0.049308  |    0.083570     |   2\n",
      "      16456 |   0.028965  |    0.052809     |   2\n",
      "      16457 |   0.188632  |    0.100595     |   0\n",
      "      16458 |   0.041661  |    0.046442     |   2\n",
      "      16459 |   0.245832  |    0.198367     |   1\n",
      "      16460 |   0.211719  |    0.018491     |   0\n",
      "      16461 |   0.196461  |    0.073409     |   0\n",
      "      16462 |   0.200997  |    0.029714     |   0\n",
      "      16463 |   0.192371  |    0.200385     |   1\n",
      "      16464 |   0.210039  |    0.155575     |   1\n",
      "      16465 |   0.176471  |    0.026128     |   0\n",
      "      16466 |   0.054348  |    0.087363     |   2\n",
      "      16467 |   0.060042  |    0.017557     |   2\n",
      "      16468 |   0.187867  |    0.160051     |   1\n",
      "      16469 |   0.190425  |    0.104333     |   0\n",
      "      16470 |   0.164630  |    0.157163     |   1\n",
      "      16471 |   0.190973  |    0.191947     |   1\n",
      "      16472 |   0.200384  |    0.005240     |   0\n",
      "      16473 |   0.186432  |    0.079186     |   0\n",
      "      16474 |   0.248376  |    0.031367     |   0\n",
      "      16475 |   0.173599  |    0.208736     |   1\n",
      "      16476 |   0.227804  |    0.134016     |   1\n",
      "      16477 |   0.185445  |    0.060863     |   0\n",
      "      16478 |   0.175062  |    0.005086     |   0\n",
      "      16479 |   0.048452  |    0.038079     |   2\n",
      "      16480 |   0.183711  |    0.080184     |   0\n",
      "      16481 |   0.142971  |    0.011395     |   0\n",
      "      16482 |   0.023988  |    0.079254     |   2\n",
      "      16483 |   0.190968  |    0.155249     |   1\n",
      "      16484 | \u001b[94m  0.000037\u001b[0m  |    0.090143     |   2\n",
      "      16485 |   0.246402  |    0.144736     |   1\n",
      "      16486 |   0.006585  |    0.048483     |   2\n",
      "      16487 |   0.072595  |    0.042319     |   2\n",
      "      16488 |   0.041468  |    0.045317     |   2\n",
      "      16489 |   0.251681  |    0.210285     |   1\n",
      "      16490 |   0.163364  |    0.004783     |   0\n",
      "      16491 |   0.064243  |    0.073679     |   2\n",
      "      16492 |   0.169430  |    0.027389     |   0\n",
      "      16493 |   0.178108  |    0.046511     |   0\n",
      "      16494 |   0.203313  |    0.194861     |   1\n",
      "      16495 |   0.211689  |    0.135870     |   1\n",
      "      16496 |   0.049009  |    0.050822     |   2\n",
      "      16497 |   0.203749  |    0.058688     |   0\n",
      "      16498 |   0.162590  |    0.205014     |   1\n",
      "      16499 |   0.181872  |    0.196872     |   1\n",
      "      16500 |   0.170182  |    0.151061     |   1\n",
      "      16501 |   0.048220  |    0.075541     |   2\n",
      "      16502 |   0.036848  |    0.038530     |   2\n",
      "      16503 |   0.043185  |    0.048212     |   2\n",
      "      16504 |   0.194279  |    0.236200     |   1\n",
      "      16505 |   0.168577  |    0.147127     |   1\n",
      "      16506 |   0.047726  |    0.025889     |   2\n",
      "      16507 |   0.204620  |    0.236576     |   1\n",
      "      16508 |   0.239678  |    0.153368     |   1\n",
      "      16509 |   0.155511  |    0.005683     |   0\n",
      "      16510 |   0.202291  |    0.086646     |   0\n",
      "      16511 |   0.231486  |    0.136199     |   1\n",
      "      16512 |   0.194141  |    0.081749     |   0\n",
      "      16513 |   0.028566  |    0.021510     |   2\n",
      "      16514 |   0.040529  |    0.077608     |   2\n",
      "      16515 |   0.172873  |    0.029384     |   0\n",
      "      16516 |   0.213487  |    0.080125     |   0\n",
      "      16517 |   0.218631  |    0.036609     |   0\n",
      "      16518 |   0.214795  |    0.195052     |   1\n",
      "      16519 |   0.133312  |    0.028419     |   0\n",
      "      16520 |   0.198112  |    0.203909     |   1\n",
      "      16521 |   0.200135  |    0.042634     |   0\n",
      "      16522 |   0.051062  |    0.051370     |   2\n",
      "      16523 |   0.212633  |    0.073984     |   0\n",
      "      16524 |   0.187826  |    0.142865     |   1\n",
      "      16525 |   0.217130  |    0.198087     |   1\n",
      "      16526 |   0.167450  |    0.042979     |   0\n",
      "      16527 |   0.158279  |    0.221119     |   1\n",
      "      16528 |   0.190013  |    0.156484     |   1\n",
      "      16529 |   0.198768  |    0.143325     |   1\n",
      "      16530 |   0.222764  |    0.157917     |   1\n",
      "      16531 |   0.178981  |    0.046688     |   0\n",
      "      16532 |   0.057211  |    0.044345     |   2\n",
      "      16533 |   0.049595  |    0.068857     |   2\n",
      "      16534 |   0.197874  |    0.027103     |   0\n",
      "      16535 |   0.210921  |    0.079828     |   0\n",
      "      16536 |   0.026359  |    0.029467     |   2\n",
      "      16537 |   0.111778  |    0.057658     |   0\n",
      "      16538 |   0.195879  |    0.080461     |   0\n",
      "      16539 |   0.000037  |    0.030003     |   2\n",
      "      16540 |   0.253303  |    0.213114     |   1\n",
      "      16541 |   0.173615  |    0.226510     |   1\n",
      "      16542 |   0.180240  |    0.147162     |   1\n",
      "      16543 |   0.154535  |    0.142019     |   1\n",
      "      16544 |   0.006508  |    0.048128     |   2\n",
      "      16545 |   0.067655  |    0.070464     |   2\n",
      "      16546 |   0.143005  |    0.025542     |   0\n",
      "      16547 |   0.186587  |    0.206455     |   1\n",
      "      16548 |   0.037925  |    0.052380     |   2\n",
      "      16549 |   0.187603  |    0.205048     |   1\n",
      "      16550 |   0.167540  |    0.138897     |   1\n",
      "      16551 |   0.063651  |    0.083958     |   2\n",
      "      16552 |   0.230237  |    0.047714     |   0\n",
      "      16553 |   0.152970  |    0.210812     |   1\n",
      "      16554 |   0.180339  |    0.157152     |   1\n",
      "      16555 |   0.047123  |    0.029486     |   2\n",
      "      16556 |   0.232463  |    0.085708     |   0\n",
      "      16557 |   0.293127  |    0.155153     |   1\n",
      "      16558 |   0.019143  |    0.042876     |   2\n",
      "      16559 |   0.200676  |    0.201617     |   1\n",
      "      16560 |   0.267217  |    0.130875     |   1\n",
      "      16561 |   0.198112  |    0.042224     |   0\n",
      "      16562 |   0.042884  |    0.078313     |   2\n",
      "      16563 |   0.228571  |    0.142061     |   1\n",
      "      16564 |   0.230604  |    0.080913     |   0\n",
      "      16565 |   0.170825  |    0.006464     |   0\n",
      "      16566 |   0.184763  |    0.076608     |   0\n",
      "      16567 |   0.033077  |    0.021603     |   2\n",
      "      16568 |   0.223944  |    0.078868     |   0\n",
      "      16569 |   0.170706  |    0.042800     |   0\n",
      "      16570 |   0.198923  |    0.212467     |   1\n",
      "      16571 |   0.000038  |    0.003684     |   2\n",
      "      16572 |   0.205798  |    0.195363     |   1\n",
      "      16573 |   0.210344  |    0.045734     |   0\n",
      "      16574 |   0.173949  |    0.072324     |   0\n",
      "      16575 |   0.232340  |    0.200232     |   1\n",
      "      16576 |   0.169638  |    0.008267     |   0\n",
      "      16577 |   0.000038  |    0.077943     |   2\n",
      "      16578 |   0.000038  |    0.057842     |   2\n",
      "      16579 |   0.000038  |    0.046421     |   2\n",
      "      16580 |   0.000037  |    0.044145     |   2\n",
      "      16581 |   0.000037  |    0.044210     |   2\n",
      "      16582 |   0.222447  |    0.202092     |   1\n",
      "      16583 |   0.210040  |    0.141998     |   1\n",
      "      16584 |   0.157595  |    0.190384     |   1\n",
      "      16585 |   0.209197  |    0.196994     |   1\n",
      "      16586 |   0.057909  |    0.015404     |   2\n",
      "      16587 |   0.158536  |    0.092285     |   0\n",
      "      16588 |   0.055226  |    0.013730     |   2\n",
      "      16589 |   0.167577  |    0.195737     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 16590: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      16590 |   0.168822  |    0.027023     |   0\n",
      "      16591 |   0.185777  |    0.075758     |   0\n",
      "      16592 |   0.180933  |    0.034562     |   0\n",
      "      16593 |   0.155801  |    0.048580     |   0\n",
      "      16594 |   0.191807  |    0.186604     |   1\n",
      "      16595 |   0.229702  |    0.037612     |   0\n",
      "      16596 |   0.204136  |    0.046505     |   0\n",
      "      16597 |   0.051409  |    0.078503     |   2\n",
      "      16598 |   0.236815  |    0.045508     |   0\n",
      "      16599 |   0.199481  |    0.196309     |   1\n",
      "      16600 |   0.038777  |    0.047560     |   2\n",
      "      16601 |   0.226828  |    0.049847     |   0\n",
      "      16602 |   0.165106  |    0.047106     |   0\n",
      "      16603 |   0.043329  |    0.083491     |   2\n",
      "      16604 |   0.235080  |    0.191192     |   1\n",
      "      16605 |   0.046108  |    0.003100     |   2\n",
      "      16606 |   0.028536  |    0.080426     |   2\n",
      "      16607 |   0.204885  |    0.218009     |   1\n",
      "      16608 |   0.043286  |    0.005623     |   2\n",
      "      16609 |   0.052596  |    0.086277     |   2\n",
      "      16610 |   0.057528  |    0.006332     |   2\n",
      "      16611 |   0.199956  |    0.201513     |   1\n",
      "      16612 |   0.198687  |    0.055869     |   0\n",
      "      16613 |   0.189582  |    0.155639     |   1\n",
      "      16614 |   0.046233  |    0.044612     |   2\n",
      "      16615 |   0.205096  |    0.079233     |   0\n",
      "      16616 |   0.168786  |    0.032861     |   0\n",
      "      16617 |   0.024468  |    0.079086     |   2\n",
      "      16618 |   0.206762  |    0.156169     |   1\n",
      "      16619 |   0.000038  |    0.080725     |   2\n",
      "      16620 |   0.006698  |    0.017704     |   2\n",
      "      16621 |   0.212025  |    0.202165     |   1\n",
      "      16622 |   0.069825  |    0.018063     |   2\n",
      "      16623 |   0.037563  |    0.093103     |   2\n",
      "      16624 |   0.184595  |    0.157759     |   1\n",
      "      16625 |   0.250793  |    0.039550     |   0\n",
      "      16626 |   0.060905  |    0.076873     |   2\n",
      "      16627 |   0.043388  |    0.041053     |   2\n",
      "      16628 |   0.162922  |    0.039947     |   0\n",
      "      16629 |   0.018794  |    0.061905     |   2\n",
      "      16630 |   0.200114  |    0.193570     |   1\n",
      "      16631 |   0.131686  |    0.156262     |   1\n",
      "      16632 |   0.216276  |    0.195974     |   1\n",
      "      16633 |   0.042304  |    0.009393     |   2\n",
      "      16634 |   0.150709  |    0.194829     |   1\n",
      "      16635 |   0.177648  |    0.049270     |   0\n",
      "      16636 |   0.190940  |    0.044521     |   0\n",
      "      16637 |   0.030455  |    0.046076     |   2\n",
      "      16638 |   0.179375  |    0.065234     |   0\n",
      "      16639 |   0.286923  |    0.185479     |   1\n",
      "      16640 |   0.189552  |    0.149035     |   1\n",
      "      16641 |   0.246609  |    0.206749     |   1\n",
      "      16642 |   0.196442  |    0.161702     |   1\n",
      "      16643 |   0.217428  |    0.050238     |   0\n",
      "      16644 |   0.150187  |    0.202080     |   1\n",
      "      16645 |   0.000037  |    0.025860     |   2\n",
      "      16646 |   0.211683  |    0.080547     |   0\n",
      "      16647 |   0.164297  |    0.186376     |   1\n",
      "      16648 |   0.169765  |    0.012160     |   0\n",
      "      16649 |   0.195892  |    0.214091     |   1\n",
      "      16650 |   0.182281  |    0.046185     |   0\n",
      "      16651 |   0.000037  |    0.043892     |   2\n",
      "      16652 |   0.176839  |    0.076173     |   0\n",
      "      16653 |   0.000037  |    0.025281     |   2\n",
      "      16654 |   0.169887  |    0.044841     |   0\n",
      "      16655 |   0.198964  |    0.044641     |   0\n",
      "      16656 |   0.174603  |    0.041673     |   0\n",
      "      16657 |   0.167040  |    0.044961     |   0\n",
      "      16658 |   0.000037  |    0.073972     |   2\n",
      "      16659 |   0.155372  |    0.034791     |   0\n",
      "      16660 |   0.222962  |    0.221100     |   1\n",
      "      16661 |   0.210634  |    0.161848     |   1\n",
      "      16662 |   0.000037  |    0.010628     |   2\n",
      "      16663 |   0.000037  |    0.067776     |   2\n",
      "      16664 |   0.157121  |    0.043185     |   0\n",
      "      16665 |   0.240289  |    0.226611     |   1\n",
      "      16666 |   0.247502  |    0.138768     |   1\n",
      "      16667 |   0.052486  |    0.041545     |   2\n",
      "      16668 |   0.199092  |    0.056782     |   0\n",
      "      16669 |   0.145373  |    0.200630     |   1\n",
      "      16670 |   0.129925  |    0.207380     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 16672: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      16671 |   0.054344  |    0.007514     |   2\n",
      "      16672 |   0.190362  |    0.198510     |   1\n",
      "      16673 |   0.045963  |    0.047953     |   2\n",
      "      16674 |   0.188619  |    0.236841     |   1\n",
      "      16675 |   0.036680  |    0.009102     |   2\n",
      "      16676 |   0.185895  |    0.077366     |   0\n",
      "      16677 |   0.041632  |    0.021215     |   2\n",
      "      16678 |   0.047434  |    0.098733     |   2\n",
      "      16679 |   0.214172  |    0.016958     |   0\n",
      "      16680 |   0.027864  |    0.047010     |   2\n",
      "      16681 |   0.213490  |    0.121884     |   0\n",
      "      16682 |   0.198481  |    0.142834     |   1\n",
      "      16683 |   0.250277  |    0.129465     |   1\n",
      "      16684 |   0.142635  |    0.074877     |   0\n",
      "      16685 |   0.151646  |    0.185996     |   1\n",
      "      16686 |   0.161930  |    0.155297     |   1\n",
      "      16687 |   0.042148  |    0.027391     |   2\n",
      "      16688 |   0.050431  |    0.051921     |   2\n",
      "      16689 |   0.057025  |    0.041674     |   2\n",
      "      16690 |   0.166205  |    0.083567     |   0\n",
      "      16691 |   0.045793  |    0.023012     |   2\n",
      "      16692 |   0.023736  |    0.086706     |   2\n",
      "      16693 |   0.000037  |    0.022521     |   2\n",
      "      16694 |   0.199715  |    0.083563     |   0\n",
      "      16695 |   0.005906  |    0.026652     |   2\n",
      "      16696 |   0.253748  |    0.048777     |   0\n",
      "      16697 |   0.070770  |    0.074810     |   2\n",
      "      16698 |   0.037686  |    0.044938     |   2\n",
      "      16699 |   0.178069  |    0.189372     |   1\n",
      "      16700 |   0.060538  |    0.042959     |   2\n",
      "      16701 |   0.197426  |    0.081043     |   0\n",
      "      16702 |   0.242680  |    0.155504     |   1\n",
      "      16703 |   0.132904  |    0.207757     |   1\n",
      "      16704 |   0.204700  |    0.026657     |   0\n",
      "      16705 |   0.045410  |    0.078634     |   2\n",
      "      16706 |   0.161307  |    0.041383     |   0\n",
      "      16707 |   0.018788  |    0.052046     |   2\n",
      "      16708 |   0.042397  |    0.069687     |   2\n",
      "      16709 |   0.033713  |    0.030106     |   2\n",
      "      16710 |   0.151880  |    0.208974     |   1\n",
      "      16711 | \u001b[94m  0.000037\u001b[0m  |    0.017164     |   2\n",
      "      16712 |   0.207031  |    0.191044     |   1\n",
      "      16713 | \u001b[94m  0.000037\u001b[0m  |    0.045957     |   2\n",
      "      16714 |   0.216578  |    0.158918     |   1\n",
      "      16715 |   0.187212  |    0.154093     |   1\n",
      "      16716 |   0.197386  |    0.198134     |   1\n",
      "      16717 |   0.208568  |    0.005739     |   0\n",
      "      16718 |   0.221737  |    0.079563     |   0\n",
      "      16719 |   0.211764  |    0.035226     |   0\n",
      "      16720 |   0.257792  |    0.202176     |   1\n",
      "      16721 |   0.208305  |    0.003808     |   0\n",
      "      16722 |   0.240356  |    0.183073     |   1\n",
      "      16723 | \u001b[94m  0.000036\u001b[0m  |    0.074149     |   2\n",
      "      16724 |   0.170737  |    0.017202     |   0\n",
      "      16725 |   0.000037  |    0.083191     |   2\n",
      "      16726 |   0.213881  |    0.051718     |   0\n",
      "      16727 |   0.169532  |    0.198801     |   1\n",
      "      16728 |   0.166624  |    0.027237     |   0\n",
      "      16729 |   0.182093  |    0.204903     |   1\n",
      "      16730 |   0.212836  |    0.055185     |   0\n",
      "      16731 |   0.180081  |    0.190955     |   1\n",
      "      16732 | \u001b[94m  0.000036\u001b[0m  |    0.003700     |   2\n",
      "      16733 |   0.193458  |    0.053238     |   0\n",
      "      16734 |   0.146538  |    0.258113     |   1\n",
      "      16735 |   0.218204  |    0.010596     |   0\n",
      "      16736 | \u001b[94m  0.000036\u001b[0m  |    0.080502     |   2\n",
      "      16737 |   0.202014  |    0.040658     |   0\n",
      "      16738 |   0.237269  |    0.188479     |   1\n",
      "      16739 |   0.054603  |    0.004236     |   2\n",
      "      16740 |   0.177276  |    0.042777     |   0\n",
      "      16741 |   0.169631  |    0.049011     |   0\n",
      "      16742 |   0.170518  |    0.234648     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 16744: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      16743 |   0.054805  |    0.008199     |   2\n",
      "      16744 |   0.247931  |    0.051437     |   0\n",
      "      16745 |   0.047070  |    0.073997     |   2\n",
      "      16746 |   0.038458  |    0.031589     |   2\n",
      "      16747 |   0.227842  |    0.152146     |   1\n",
      "      16748 |   0.167221  |    0.195682     |   1\n",
      "      16749 |   0.233705  |    0.162103     |   1\n",
      "      16750 |   0.166770  |    0.077584     |   0\n",
      "      16751 |   0.041170  |    0.031669     |   2\n",
      "      16752 |   0.049124  |    0.042939     |   2\n",
      "      16753 |   0.028105  |    0.082287     |   2\n",
      "      16754 |   0.040660  |    0.042865     |   2\n",
      "      16755 |   0.232951  |    0.048796     |   0\n",
      "      16756 |   0.191097  |    0.041940     |   0\n",
      "      16757 |   0.191210  |    0.044627     |   0\n",
      "      16758 |   0.143176  |    0.077337     |   0\n",
      "      16759 |   0.171745  |    0.035044     |   0\n",
      "      16760 |   0.050605  |    0.091752     |   2\n",
      "      16761 |   0.193853  |    0.151392     |   1\n",
      "      16762 |   0.057373  |    0.020484     |   2\n",
      "      16763 |   0.163408  |    0.073238     |   0\n",
      "      16764 |   0.194434  |    0.143601     |   1\n",
      "      16765 |   0.204169  |    0.078579     |   0\n",
      "      16766 |   0.243144  |    0.163621     |   1\n",
      "      16767 |   0.170570  |    0.187093     |   1\n",
      "      16768 |   0.253876  |    0.225940     |   1\n",
      "      16769 |   0.160545  |    0.165032     |   1\n",
      "      16770 |   0.273955  |    0.156115     |   1\n",
      "      16771 |   0.045914  |    0.047416     |   2\n",
      "      16772 |   0.176163  |    0.046698     |   0\n",
      "      16773 |   0.163583  |    0.086013     |   0\n",
      "      16774 |   0.211383  |    0.024842     |   0\n",
      "      16775 |   0.198224  |    0.157547     |   1\n",
      "      16776 |   0.023602  |    0.042945     |   2\n",
      "      16777 |   0.000036  |    0.042484     |   2\n",
      "      16778 |   0.006319  |    0.049005     |   2\n",
      "      16779 |   0.070852  |    0.055900     |   2\n",
      "      16780 |   0.177040  |    0.210736     |   1\n",
      "      16781 |   0.218964  |    0.147318     |   1\n",
      "      16782 |   0.035483  |    0.051785     |   2\n",
      "      16783 |   0.150626  |    0.170672     |   1\n",
      "      16784 |   0.159457  |    0.046560     |   0\n",
      "      16785 |   0.058669  |    0.077245     |   2\n",
      "      16786 |   0.043042  |    0.034235     |   2\n",
      "      16787 |   0.153852  |    0.044331     |   0\n",
      "      16788 |   0.018118  |    0.093791     |   2\n",
      "      16789 |   0.038215  |    0.022751     |   2\n",
      "      16790 |   0.178462  |    0.084001     |   0\n",
      "      16791 |   0.162412  |    0.217479     |   1\n",
      "      16792 |   0.178689  |    0.161638     |   1\n",
      "      16793 |   0.271237  |    0.165784     |   1\n",
      "      16794 |   0.169865  |    0.142950     |   1\n",
      "      16795 |   0.030664  |    0.061972     |   2\n",
      "      16796 |   0.151316  |    0.222431     |   1\n",
      "      16797 |   0.161662  |    0.012372     |   0\n",
      "      16798 | \u001b[94m  0.000036\u001b[0m  |    0.045144     |   2\n",
      "      16799 |   0.193115  |    0.075950     |   0\n",
      "      16800 | \u001b[94m  0.000036\u001b[0m  |    0.019689     |   2\n",
      "      16801 |   0.000036  |    0.075951     |   2\n",
      "      16802 |   0.000036  |    0.049751     |   2\n",
      "      16803 |   0.174896  |    0.191153     |   1\n",
      "      16804 | \u001b[94m  0.000036\u001b[0m  |    0.021460     |   2\n",
      "      16805 |   0.159686  |    0.219847     |   1\n",
      "      16806 | \u001b[94m  0.000036\u001b[0m  |    0.075705     |   2\n",
      "      16807 |   0.152154  |    0.085674     |   0\n",
      "      16808 |   0.050262  |    0.088623     |   2\n",
      "      16809 |   0.176081  |    0.205829     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 16811: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      16810 |   0.053421  |    0.006454     |   2\n",
      "      16811 |   0.047573  |    0.098305     |   2\n",
      "      16812 |   0.189943  |    0.151519     |   1\n",
      "      16813 |   0.126791  |    0.191523     |   1\n",
      "      16814 |   0.164868  |    0.138694     |   1\n",
      "      16815 |   0.036164  |    0.045527     |   2\n",
      "      16816 |   0.041086  |    0.084106     |   2\n",
      "      16817 |   0.235514  |    0.149228     |   1\n",
      "      16818 |   0.198415  |    0.044841     |   0\n",
      "      16819 |   0.171120  |    0.087303     |   0\n",
      "      16820 |   0.185217  |    0.225568     |   1\n",
      "      16821 |   0.045758  |    0.005128     |   2\n",
      "      16822 |   0.027437  |    0.085037     |   2\n",
      "      16823 |   0.222581  |    0.156276     |   1\n",
      "      16824 |   0.171642  |    0.217633     |   1\n",
      "      16825 |   0.206409  |    0.198025     |   1\n",
      "      16826 |   0.181516  |    0.143486     |   1\n",
      "      16827 |   0.176826  |    0.144089     |   1\n",
      "      16828 |   0.199248  |    0.042741     |   0\n",
      "      16829 |   0.041028  |    0.044869     |   2\n",
      "      16830 |   0.214296  |    0.251764     |   1\n",
      "      16831 |   0.048101  |    0.019304     |   2\n",
      "      16832 |   0.185036  |    0.210155     |   1\n",
      "      16833 |   0.231349  |    0.152331     |   1\n",
      "      16834 |   0.232112  |    0.082360     |   0\n",
      "      16835 |   0.186954  |    0.024480     |   0\n",
      "      16836 |   0.187775  |    0.076108     |   0\n",
      "      16837 |   0.057917  |    0.040766     |   2\n",
      "      16838 |   0.162216  |    0.040081     |   0\n",
      "      16839 |   0.047664  |    0.052992     |   2\n",
      "      16840 |   0.237305  |    0.208094     |   1\n",
      "      16841 |   0.198772  |    0.017688     |   0\n",
      "      16842 |   0.206763  |    0.220456     |   1\n",
      "      16843 |   0.168071  |    0.195612     |   1\n",
      "      16844 |   0.022929  |    0.004565     |   2\n",
      "      16845 |   0.249501  |    0.081741     |   0\n",
      "      16846 |   0.201858  |    0.030102     |   0\n",
      "      16847 | \u001b[94m  0.000035\u001b[0m  |    0.079817     |   2\n",
      "      16848 |   0.223454  |    0.039307     |   0\n",
      "      16849 |   0.191367  |    0.210041     |   1\n",
      "      16850 |   0.221570  |    0.152948     |   1\n",
      "      16851 |   0.007003  |    0.005882     |   2\n",
      "      16852 |   0.247488  |    0.219871     |   1\n",
      "      16853 |   0.201777  |    0.022586     |   0\n",
      "      16854 |   0.211179  |    0.074163     |   0\n",
      "      16855 |   0.073562  |    0.039986     |   2\n",
      "      16856 |   0.184443  |    0.227213     |   1\n",
      "      16857 |   0.038194  |    0.027840     |   2\n",
      "      16858 |   0.061987  |    0.043604     |   2\n",
      "      16859 |   0.194406  |    0.042703     |   0\n",
      "      16860 |   0.150970  |    0.081803     |   0\n",
      "      16861 |   0.041766  |    0.014288     |   2\n",
      "      16862 |   0.018661  |    0.076572     |   2\n",
      "      16863 |   0.201456  |    0.041095     |   0\n",
      "      16864 |   0.221501  |    0.180318     |   1\n",
      "      16865 |   0.043016  |    0.071267     |   2\n",
      "      16866 |   0.187193  |    0.045734     |   0\n",
      "      16867 |   0.030494  |    0.040861     |   2\n",
      "      16868 | \u001b[94m  0.000035\u001b[0m  |    0.086180     |   2\n",
      "      16869 |   0.216727  |    0.017714     |   0\n",
      "      16870 |   0.211496  |    0.072508     |   0\n",
      "      16871 |   0.175774  |    0.133049     |   1\n",
      "      16872 |   0.161497  |    0.075908     |   0\n",
      "      16873 |   0.159096  |    0.222232     |   1\n",
      "      16874 |   0.222635  |    0.103644     |   1\n",
      "      16875 |   0.226512  |    0.046279     |   0\n",
      "      16876 |   0.144404  |    0.044310     |   0\n",
      "      16877 |   0.185122  |    0.240720     |   1\n",
      "      16878 | \u001b[94m  0.000035\u001b[0m  |    0.015711     |   2\n",
      "      16879 |   0.195989  |    0.081148     |   0\n",
      "      16880 |   0.227943  |    0.182696     |   1\n",
      "      16881 |   0.145952  |    0.004938     |   0\n",
      "      16882 |   0.000035  |    0.085094     |   2\n",
      "      16883 |   0.231756  |    0.143018     |   1\n",
      "      16884 |   0.000035  |    0.031926     |   2\n",
      "      16885 |   0.178735  |    0.074496     |   0\n",
      "      16886 |   0.198071  |    0.009818     |   0\n",
      "      16887 |   0.157183  |    0.044220     |   0\n",
      "      16888 |   0.224632  |    0.047374     |   0\n",
      "      16889 |   0.181345  |    0.199174     |   1\n",
      "      16890 |   0.201270  |    0.200660     |   1\n",
      "      16891 |   0.000035  |    0.004694     |   2\n",
      "      16892 |   0.246855  |    0.188883     |   1\n",
      "      16893 |   0.000035  |    0.021527     |   2\n",
      "      16894 |   0.198523  |    0.075962     |   0\n",
      "      16895 |   0.161364  |    0.031179     |   0\n",
      "      16896 |   0.220225  |    0.187115     |   1\n",
      "      16897 |   0.215225  |    0.205251     |   1\n",
      "      16898 |   0.188607  |    0.154604     |   1\n",
      "      16899 |   0.223280  |    0.106805     |   0\n",
      "      16900 |   0.218131  |    0.192941     |   1\n",
      "      16901 |   0.232286  |    0.003591     |   0\n",
      "      16902 |   0.051937  |    0.050261     |   2\n",
      "      16903 |   0.218336  |    0.046413     |   0\n",
      "      16904 |   0.199076  |    0.078472     |   0\n",
      "      16905 |   0.188918  |    0.142541     |   1\n",
      "      16906 |   0.169142  |    0.080273     |   0\n",
      "      16907 |   0.239357  |    0.155536     |   1\n",
      "      16908 |   0.192383  |    0.052000     |   0\n",
      "      16909 |   0.184589  |    0.141866     |   1\n",
      "      16910 |   0.240879  |    0.210583     |   1\n",
      "      16911 |   0.151218  |    0.028234     |   0\n",
      "      16912 |   0.164008  |    0.049212     |   0\n",
      "      16913 |   0.153938  |    0.057651     |   0\n",
      "      16914 |   0.216653  |    0.144930     |   1\n",
      "      16915 |   0.054103  |    0.035778     |   2\n",
      "      16916 |   0.178987  |    0.071593     |   0\n",
      "      16917 |   0.204111  |    0.148578     |   1\n",
      "      16918 |   0.180023  |    0.197633     |   1\n",
      "      16919 |   0.274653  |    0.029821     |   0\n",
      "      16920 |   0.159339  |    0.155977     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 16921: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      16921 |   0.215089  |    0.150947     |   1\n",
      "      16922 |   0.054317  |    0.041869     |   2\n",
      "      16923 |   0.207576  |    0.079265     |   0\n",
      "      16924 |   0.037730  |    0.039902     |   2\n",
      "      16925 |   0.246206  |    0.188051     |   1\n",
      "      16926 |   0.045199  |    0.015530     |   2\n",
      "      16927 |   0.260600  |    0.196727     |   1\n",
      "      16928 |   0.234554  |    0.215018     |   1\n",
      "      16929 |   0.182298  |    0.007281     |   0\n",
      "      16930 |   0.192957  |    0.076447     |   0\n",
      "      16931 |   0.188367  |    0.026959     |   0\n",
      "      16932 |   0.046496  |    0.080681     |   2\n",
      "      16933 |   0.252735  |    0.061315     |   0\n",
      "      16934 |   0.027344  |    0.083056     |   2\n",
      "      16935 |   0.043313  |    0.018131     |   2\n",
      "      16936 |   0.195316  |    0.182783     |   1\n",
      "      16937 |   0.052088  |    0.039414     |   2\n",
      "      16938 |   0.144143  |    0.079759     |   0\n",
      "      16939 |   0.057489  |    0.005498     |   2\n",
      "      16940 |   0.147131  |    0.093667     |   0\n",
      "      16941 |   0.179524  |    0.158321     |   1\n",
      "      16942 |   0.211196  |    0.041082     |   0\n",
      "      16943 |   0.191038  |    0.046125     |   0\n",
      "      16944 |   0.049916  |    0.076508     |   2\n",
      "      16945 |   0.024563  |    0.048463     |   2\n",
      "      16946 |   0.188511  |    0.214978     |   1\n",
      "      16947 |   0.184337  |    0.004411     |   0\n",
      "      16948 |   0.175551  |    0.039841     |   0\n",
      "      16949 |   0.187512  |    0.050304     |   0\n",
      "      16950 |   0.000035  |    0.092533     |   2\n",
      "      16951 |   0.227967  |    0.192552     |   1\n",
      "      16952 |   0.178138  |    0.003839     |   0\n",
      "      16953 |   0.224659  |    0.050512     |   0\n",
      "      16954 |   0.178067  |    0.204431     |   1\n",
      "      16955 |   0.006099  |    0.006654     |   2\n",
      "      16956 |   0.108378  |    0.081743     |   0\n",
      "      16957 |   0.071134  |    0.027412     |   2\n",
      "      16958 |   0.038280  |    0.085121     |   2\n",
      "      16959 |   0.060356  |    0.016007     |   2\n",
      "      16960 |   0.230878  |    0.088205     |   0\n",
      "      16961 |   0.162472  |    0.027290     |   0\n",
      "      16962 |   0.225345  |    0.209875     |   1\n",
      "      16963 |   0.152158  |    0.015284     |   0\n",
      "      16964 |   0.149873  |    0.048563     |   0\n",
      "      16965 |   0.047464  |    0.051808     |   2\n",
      "      16966 |   0.019264  |    0.070098     |   2\n",
      "      16967 |   0.042390  |    0.039174     |   2\n",
      "      16968 |   0.182540  |    0.147971     |   1\n",
      "      16969 |   0.210361  |    0.072102     |   0\n",
      "      16970 |   0.206862  |    0.016927     |   0\n",
      "      16971 |   0.207517  |    0.079118     |   0\n",
      "      16972 |   0.158141  |    0.168518     |   1\n",
      "      16973 |   0.173806  |    0.101853     |   0\n",
      "      16974 |   0.204876  |    0.168886     |   1\n",
      "      16975 |   0.204217  |    0.148674     |   1\n",
      "      16976 |   0.204728  |    0.042936     |   0\n",
      "      16977 |   0.030812  |    0.076927     |   2\n",
      "      16978 |   0.140920  |    0.023009     |   0\n",
      "      16979 |   0.000035  |    0.055105     |   2\n",
      "      16980 |   0.191940  |    0.207049     |   1\n",
      "      16981 |   0.149946  |    0.049106     |   0\n",
      "      16982 |   0.205786  |    0.206385     |   1\n",
      "      16983 |   0.126318  |    0.006975     |   0\n",
      "      16984 | \u001b[94m  0.000035\u001b[0m  |    0.098580     |   2\n",
      "      16985 |   0.259649  |    0.149530     |   1\n",
      "      16986 |   0.169036  |    0.188896     |   1\n",
      "      16987 |   0.164432  |    0.027773     |   0\n",
      "      16988 |   0.000035  |    0.057549     |   2\n",
      "      16989 |   0.147805  |    0.077456     |   0\n",
      "      16990 |   0.178539  |    0.026126     |   0\n",
      "      16991 |   0.234305  |    0.214622     |   1\n",
      "      16992 |   0.166404  |    0.007344     |   0\n",
      "      16993 |   0.137192  |    0.075279     |   0\n",
      "      16994 |   0.167534  |    0.038700     |   0\n",
      "      16995 |   0.249691  |    0.184312     |   1\n",
      "      16996 |   0.146098  |    0.063677     |   0\n",
      "      16997 |   0.203065  |    0.138081     |   1\n",
      "      16998 |   0.222963  |    0.225516     |   1\n",
      "      16999 |   0.000036  |    0.047290     |   2\n",
      "      17000 |   0.163881  |    0.077864     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 17000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 17000: Plotting estimates.\n",
      "Exception in thread neuralnilm-data-process:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 810, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/jack/workspace/python/neuralnilm/neuralnilm/data/datathread.py\", line 16, in run\n",
      "    batch = self.data_pipeline.get_batch(**self._get_batch_kwargs)\n",
      "  File \"/home/jack/workspace/python/neuralnilm/neuralnilm/data/datapipeline.py\", line 46, in get_batch\n",
      "    batch = self._source_iterators[source_id].next()\n",
      "ValueError: generator already executing\n",
      "\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      17001 |   0.168667  |    0.087465     |   0\n",
      "      17002 |   0.212568  |    0.197340     |   1\n",
      "      17003 |   0.164009  |    0.007888     |   0\n",
      "      17004 |   0.202511  |    0.045841     |   0\n",
      "      17005 |   0.050542  |    0.047402     |   2\n",
      "      17006 |   0.174779  |    0.058773     |   0\n",
      "      17007 |   0.038136  |    0.050256     |   2\n",
      "      17008 |   0.252746  |    0.150144     |   1\n",
      "      17009 |   0.157596  |    0.006552     |   0\n",
      "      17010 |   0.167572  |    0.042335     |   0\n",
      "      17011 |   0.043642  |    0.052757     |   2\n",
      "      17012 |   0.191633  |    0.149657     |   1\n",
      "      17013 |   0.049209  |    0.047575     |   2\n",
      "      17014 |   0.228889  |    0.196325     |   1\n",
      "      17015 |   0.178636  |    0.006403     |   0\n",
      "      17016 |   0.028114  |    0.044635     |   2\n",
      "      17017 |   0.192016  |    0.201175     |   1\n",
      "      17018 |   0.186658  |    0.158492     |   1\n",
      "      17019 |   0.251427  |    0.008021     |   0\n",
      "      17020 |   0.043581  |    0.026413     |   2\n",
      "      17021 |   0.054311  |    0.078029     |   2\n",
      "      17022 |   0.056848  |    0.018802     |   2\n",
      "      17023 |   0.198553  |    0.073451     |   0\n",
      "      17024 |   0.049304  |    0.027800     |   2\n",
      "      17025 |   0.204739  |    0.045455     |   0\n",
      "      17026 |   0.024499  |    0.039204     |   2\n",
      "      17027 |   0.000036  |    0.086885     |   2\n",
      "      17028 |   0.171485  |    0.015201     |   0\n",
      "      17029 |   0.188033  |    0.083143     |   0\n",
      "      17030 |   0.006126  |    0.024471     |   2\n",
      "      17031 |   0.247011  |    0.074795     |   0\n",
      "      17032 |   0.193832  |    0.020665     |   0\n",
      "      17033 |   0.186303  |    0.051397     |   0\n",
      "      17034 |   0.245007  |    0.205041     |   1\n",
      "      17035 |   0.068377  |    0.029498     |   2\n",
      "      17036 |   0.037107  |    0.045924     |   2\n",
      "      17037 |   0.137723  |    0.042951     |   0\n",
      "      17038 |   0.165914  |    0.190298     |   1\n",
      "      17039 |   0.062557  |    0.031442     |   2\n",
      "      17040 |   0.045215  |    0.078233     |   2\n",
      "      17041 |   0.179320  |    0.026247     |   0\n",
      "      17042 |   0.159193  |    0.203390     |   1\n",
      "      17043 |   0.261463  |    0.135796     |   1\n",
      "      17044 |   0.180479  |    0.076522     |   0\n",
      "      17045 |   0.180645  |    0.019400     |   0\n",
      "      17046 |   0.018798  |    0.082778     |   2\n",
      "      17047 |   0.219433  |    0.058161     |   0\n",
      "      17048 |   0.163410  |    0.164742     |   1\n",
      "      17049 |   0.041615  |    0.007901     |   2\n",
      "      17050 |   0.147617  |    0.075600     |   0\n",
      "      17051 |   0.032587  |    0.024490     |   2\n",
      "      17052 |   0.227315  |    0.190456     |   1\n",
      "      17053 |   0.200238  |    0.004850     |   0\n",
      "      17054 |   0.228207  |    0.212040     |   1\n",
      "      17055 |   0.000036  |    0.023765     |   2\n",
      "      17056 |   0.000036  |    0.077334     |   2\n",
      "      17057 |   0.156476  |    0.046085     |   0\n",
      "      17058 |   0.218954  |    0.026729     |   0\n",
      "      17059 |   0.190264  |    0.207794     |   1\n",
      "      17060 |   0.215775  |    0.129498     |   1\n",
      "      17061 |   0.000036  |    0.044012     |   2\n",
      "      17062 |   0.000036  |    0.043753     |   2\n",
      "      17063 |   0.000036  |    0.089739     |   2\n",
      "      17064 |   0.148355  |    0.196850     |   1\n",
      "      17065 |   0.223511  |    0.145286     |   1\n",
      "      17066 |   0.204534  |    0.041098     |   0\n",
      "      17067 |   0.174761  |    0.071991     |   0\n",
      "      17068 |   0.217822  |    0.138824     |   1\n",
      "      17069 |   0.208927  |    0.172634     |   1\n",
      "      17070 |   0.199041  |    0.133912     |   1\n",
      "      17071 |   0.164247  |    0.157763     |   1\n",
      "      17072 |   0.207013  |    0.038956     |   0\n",
      "      17073 |   0.159855  |    0.043936     |   0\n",
      "      17074 |   0.205517  |    0.042694     |   0\n",
      "      17075 |   0.255037  |    0.077199     |   0\n",
      "      17076 |   0.000036  |    0.007913     |   2\n",
      "      17077 |   0.051354  |    0.078957     |   2\n",
      "      17078 |   0.190398  |    0.050159     |   0\n",
      "      17079 |   0.256957  |    0.161105     |   1\n",
      "      17080 |   0.205822  |    0.028003     |   0\n",
      "      17081 |   0.054847  |    0.077152     |   2\n",
      "      17082 |   0.183340  |    0.194863     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 17083: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      17083 |   0.172733  |    0.007511     |   0\n",
      "      17084 |   0.208124  |    0.080024     |   0\n",
      "      17085 |   0.048720  |    0.025907     |   2\n",
      "      17086 |   0.236772  |    0.199994     |   1\n",
      "      17087 |   0.240409  |    0.057395     |   0\n",
      "      17088 |   0.202131  |    0.155221     |   1\n",
      "      17089 |   0.198505  |    0.052841     |   0\n",
      "      17090 |   0.192188  |    0.159071     |   1\n",
      "      17091 |   0.203618  |    0.084383     |   0\n",
      "      17092 |   0.180831  |    0.145299     |   1\n",
      "      17093 |   0.123984  |    0.188858     |   1\n",
      "      17094 |   0.036251  |    0.023530     |   2\n",
      "      17095 |   0.185147  |    0.081044     |   0\n",
      "      17096 |   0.042035  |    0.025935     |   2\n",
      "      17097 |   0.187114  |    0.079637     |   0\n",
      "      17098 |   0.158975  |    0.038793     |   0\n",
      "      17099 |   0.204228  |    0.216037     |   1\n",
      "      17100 |   0.049438  |    0.007876     |   2\n",
      "      17101 |   0.137378  |    0.076227     |   0\n",
      "      17102 |   0.188070  |    0.017320     |   0\n",
      "      17103 |   0.209698  |    0.079679     |   0\n",
      "      17104 |   0.172862  |    0.032866     |   0\n",
      "      17105 |   0.197756  |    0.149102     |   1\n",
      "      17106 |   0.190439  |    0.151804     |   1\n",
      "      17107 |   0.197469  |    0.167259     |   1\n",
      "      17108 |   0.028721  |    0.020821     |   2\n",
      "      17109 |   0.168726  |    0.044037     |   0\n",
      "      17110 |   0.179098  |    0.044374     |   0\n",
      "      17111 |   0.182927  |    0.079967     |   0\n",
      "      17112 |   0.042796  |    0.026442     |   2\n",
      "      17113 |   0.222758  |    0.193754     |   1\n",
      "      17114 |   0.250383  |    0.155167     |   1\n",
      "      17115 |   0.168187  |    0.026001     |   0\n",
      "      17116 |   0.206890  |    0.214421     |   1\n",
      "      17117 |   0.140917  |    0.006635     |   0\n",
      "      17118 |   0.159332  |    0.071221     |   0\n",
      "      17119 |   0.053950  |    0.024305     |   2\n",
      "      17120 |   0.059714  |    0.081408     |   2\n",
      "      17121 |   0.047233  |    0.047479     |   2\n",
      "      17122 |   0.228833  |    0.157229     |   1\n",
      "      17123 |   0.178037  |    0.045428     |   0\n",
      "      17124 |   0.252814  |    0.209834     |   1\n",
      "      17125 |   0.166493  |    0.006311     |   0\n",
      "      17126 |   0.198039  |    0.046081     |   0\n",
      "      17127 |   0.022941  |    0.074584     |   2\n",
      "      17128 |   0.000036  |    0.042642     |   2\n",
      "      17129 |   0.005517  |    0.055807     |   2\n",
      "      17130 |   0.231766  |    0.200387     |   1\n",
      "      17131 |   0.189656  |    0.156531     |   1\n",
      "      17132 |   0.181582  |    0.012119     |   0\n",
      "      17133 |   0.072242  |    0.087777     |   2\n",
      "      17134 |   0.181393  |    0.135475     |   1\n",
      "      17135 |   0.182640  |    0.051258     |   0\n",
      "      17136 |   0.328433  |    0.146222     |   1\n",
      "      17137 |   0.158440  |    0.041686     |   0\n",
      "      17138 |   0.173643  |    0.199181     |   1\n",
      "      17139 |   0.180519  |    0.006484     |   0\n",
      "      17140 |   0.250340  |    0.162939     |   1\n",
      "      17141 |   0.173429  |    0.078223     |   0\n",
      "      17142 |   0.165639  |    0.136835     |   1\n",
      "      17143 |   0.170604  |    0.195360     |   1\n",
      "      17144 |   0.037602  |    0.008244     |   2\n",
      "      17145 |   0.060863  |    0.078721     |   2\n",
      "      17146 |   0.201440  |    0.039778     |   0\n",
      "      17147 |   0.180587  |    0.042551     |   0\n",
      "      17148 |   0.043961  |    0.043426     |   2\n",
      "      17149 |   0.017068  |    0.044145     |   2\n",
      "      17150 |   0.168362  |    0.059691     |   0\n",
      "      17151 |   0.255924  |    0.148580     |   1\n",
      "      17152 |   0.194488  |    0.230905     |   1\n",
      "      17153 |   0.267489  |    0.088333     |   1\n",
      "      17154 |   0.040801  |    0.052458     |   2\n",
      "      17155 |   0.031308  |    0.076907     |   2\n",
      "      17156 |   0.228615  |    0.028903     |   0\n",
      "      17157 |   0.217114  |    0.198641     |   1\n",
      "      17158 |   0.202727  |    0.011221     |   0\n",
      "      17159 |   0.222973  |    0.201416     |   1\n",
      "      17160 |   0.244149  |    0.195198     |   1\n",
      "      17161 |   0.229793  |    0.145002     |   1\n",
      "      17162 |   0.128165  |    0.208975     |   1\n",
      "      17163 |   0.186475  |    0.168062     |   1\n",
      "      17164 |   0.000036  |    0.007121     |   2\n",
      "      17165 |   0.200473  |    0.200015     |   1\n",
      "      17166 |   0.000036  |    0.032611     |   2\n",
      "      17167 |   0.151708  |    0.200890     |   1\n",
      "      17168 |   0.185837  |    0.013572     |   0\n",
      "      17169 |   0.206637  |    0.077924     |   0\n",
      "      17170 |   0.200696  |    0.148143     |   1\n",
      "      17171 |   0.000036  |    0.011135     |   2\n",
      "      17172 |   0.210926  |    0.085812     |   0\n",
      "      17173 |   0.173924  |    0.149477     |   1\n",
      "      17174 |   0.189879  |    0.170860     |   1\n",
      "      17175 |   0.195814  |    0.138633     |   1\n",
      "      17176 |   0.174629  |    0.204607     |   1\n",
      "      17177 |   0.172765  |    0.107105     |   1\n",
      "      17178 |   0.000036  |    0.046667     |   2\n",
      "      17179 |   0.152059  |    0.052914     |   0\n",
      "      17180 |   0.163705  |    0.206765     |   1\n",
      "      17181 |   0.000035  |    0.013058     |   2\n",
      "      17182 |   0.196624  |    0.187925     |   1\n",
      "      17183 |   0.000035  |    0.027508     |   2\n",
      "      17184 |   0.176048  |    0.229104     |   1\n",
      "      17185 |   0.182352  |    0.027601     |   0\n",
      "      17186 |   0.186538  |    0.229078     |   1\n",
      "      17187 |   0.045737  |    0.016457     |   2\n",
      "      17188 |   0.052650  |    0.085294     |   2\n",
      "      17189 |   0.229395  |    0.185371     |   1\n",
      "      17190 |   0.201221  |    0.005953     |   0\n",
      "      17191 |   0.136137  |    0.078341     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 17192: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      17192 |   0.181928  |    0.031575     |   0\n",
      "      17193 |   0.048426  |    0.052824     |   2\n",
      "      17194 |   0.175921  |    0.146540     |   1\n",
      "      17195 |   0.090426  |    0.216913     |   1\n",
      "      17196 |   0.212791  |    0.142068     |   1\n",
      "      17197 |   0.036827  |    0.029160     |   2\n",
      "      17198 |   0.207697  |    0.148532     |   1\n",
      "      17199 |   0.207583  |    0.138941     |   1\n",
      "      17200 |   0.042393  |    0.040921     |   2\n",
      "      17201 |   0.248106  |    0.200003     |   1\n",
      "      17202 |   0.198080  |    0.010106     |   0\n",
      "      17203 |   0.190179  |    0.194710     |   1\n",
      "      17204 |   0.045720  |    0.074681     |   2\n",
      "      17205 |   0.104355  |    0.019056     |   0\n",
      "      17206 |   0.158053  |    0.231739     |   1\n",
      "      17207 |   0.028080  |    0.009004     |   2\n",
      "      17208 |   0.248349  |    0.212806     |   1\n",
      "      17209 |   0.232220  |    0.143432     |   1\n",
      "      17210 |   0.164220  |    0.024888     |   0\n",
      "      17211 |   0.231729  |    0.157067     |   1\n",
      "      17212 |   0.188873  |    0.164441     |   1\n",
      "      17213 |   0.042334  |    0.048667     |   2\n",
      "      17214 |   0.211309  |    0.184627     |   1\n",
      "      17215 |   0.222902  |    0.150729     |   1\n",
      "      17216 |   0.182821  |    0.142329     |   1\n",
      "      17217 |   0.170526  |    0.151908     |   1\n",
      "      17218 |   0.046926  |    0.090613     |   2\n",
      "      17219 |   0.176321  |    0.153370     |   1\n",
      "      17220 |   0.199892  |    0.022512     |   0\n",
      "      17221 |   0.203787  |    0.195852     |   1\n",
      "      17222 |   0.180921  |    0.026288     |   0\n",
      "      17223 |   0.182316  |    0.202678     |   1\n",
      "      17224 |   0.054516  |    0.029381     |   2\n",
      "      17225 |   0.050518  |    0.086125     |   2\n",
      "      17226 |   0.195570  |    0.174137     |   1\n",
      "      17227 |   0.165521  |    0.182476     |   1\n",
      "      17228 |   0.182178  |    0.047242     |   0\n",
      "      17229 |   0.232334  |    0.147977     |   1\n",
      "      17230 |   0.166617  |    0.209409     |   1\n",
      "      17231 |   0.216308  |    0.130654     |   1\n",
      "      17232 |   0.172295  |    0.024881     |   0\n",
      "      17233 |   0.026067  |    0.076910     |   2\n",
      "      17234 | \u001b[94m  0.000035\u001b[0m  |    0.027168     |   2\n",
      "      17235 |   0.007035  |    0.077661     |   2\n",
      "      17236 |   0.184456  |    0.024545     |   0\n",
      "      17237 |   0.070812  |    0.065516     |   2\n",
      "      17238 |   0.035974  |    0.043647     |   2\n",
      "      17239 |   0.203631  |    0.211699     |   1\n",
      "      17240 |   0.201388  |    0.007043     |   0\n",
      "      17241 |   0.061490  |    0.051804     |   2\n",
      "      17242 |   0.193014  |    0.145527     |   1\n",
      "      17243 |   0.167039  |    0.188338     |   1\n",
      "      17244 |   0.174873  |    0.173943     |   1\n",
      "      17245 |   0.157779  |    0.005000     |   0\n",
      "      17246 |   0.157984  |    0.152776     |   1\n",
      "      17247 |   0.183127  |    0.040555     |   0\n",
      "      17248 |   0.232033  |    0.156953     |   1\n",
      "      17249 |   0.201458  |    0.171517     |   1\n",
      "      17250 |   0.207294  |    0.031883     |   0\n",
      "      17251 |   0.047523  |    0.088470     |   2\n",
      "      17252 |   0.218434  |    0.164005     |   1\n",
      "      17253 |   0.175968  |    0.004472     |   0\n",
      "      17254 |   0.212926  |    0.212878     |   1\n",
      "      17255 |   0.203115  |    0.044833     |   0\n",
      "      17256 |   0.227201  |    0.077857     |   0\n",
      "      17257 |   0.149767  |    0.131061     |   1\n",
      "      17258 |   0.015921  |    0.081563     |   2\n",
      "      17259 |   0.201465  |    0.026125     |   0\n",
      "      17260 |   0.041084  |    0.061523     |   2\n",
      "      17261 |   0.198011  |    0.193461     |   1\n",
      "      17262 |   0.029990  |    0.006487     |   2\n",
      "      17263 |   0.203860  |    0.076277     |   0\n",
      "      17264 |   0.171224  |    0.045994     |   0\n",
      "      17265 |   0.000035  |    0.045787     |   2\n",
      "      17266 |   0.166719  |    0.165330     |   1\n",
      "      17267 |   0.201822  |    0.149894     |   1\n",
      "      17268 |   0.000035  |    0.039614     |   2\n",
      "      17269 |   0.201756  |    0.189342     |   1\n",
      "      17270 |   0.235370  |    0.005568     |   0\n",
      "      17271 |   0.188698  |    0.077564     |   0\n",
      "      17272 |   0.229335  |    0.051873     |   0\n",
      "      17273 |   0.183451  |    0.145725     |   1\n",
      "      17274 |   0.228696  |    0.040631     |   0\n",
      "      17275 |   0.221303  |    0.079440     |   0\n",
      "      17276 |   0.000035  |    0.016381     |   2\n",
      "      17277 |   0.000035  |    0.078531     |   2\n",
      "      17278 | \u001b[94m  0.000034\u001b[0m  |    0.022602     |   2\n",
      "      17279 |   0.150217  |    0.073626     |   0\n",
      "      17280 | \u001b[94m  0.000034\u001b[0m  |    0.011848     |   2\n",
      "      17281 |   0.150405  |    0.043158     |   0\n",
      "      17282 |   0.054789  |    0.080585     |   2\n",
      "      17283 |   0.172405  |    0.154280     |   1\n",
      "      17284 |   0.189951  |    0.076360     |   0\n",
      "      17285 |   0.196495  |    0.032091     |   0\n",
      "      17286 |   0.054731  |    0.082213     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 17287: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      17287 |   0.155680  |    0.162561     |   1\n",
      "      17288 |   0.053763  |    0.030144     |   2\n",
      "      17289 |   0.038882  |    0.078264     |   2\n",
      "      17290 |   0.159977  |    0.023000     |   0\n",
      "      17291 |   0.166303  |    0.090729     |   0\n",
      "      17292 |   0.185854  |    0.139166     |   1\n",
      "      17293 |   0.043758  |    0.037875     |   2\n",
      "      17294 |   0.224286  |    0.086245     |   0\n",
      "      17295 |   0.045892  |    0.026910     |   2\n",
      "      17296 |   0.128889  |    0.043208     |   0\n",
      "      17297 |   0.029506  |    0.081702     |   2\n",
      "      17298 |   0.231210  |    0.101830     |   1\n",
      "      17299 |   0.219506  |    0.025378     |   0\n",
      "      17300 |   0.206482  |    0.077512     |   0\n",
      "      17301 |   0.043779  |    0.018992     |   2\n",
      "      17302 |   0.052079  |    0.085259     |   2\n",
      "      17303 |   0.230008  |    0.137573     |   1\n",
      "      17304 |   0.059662  |    0.029662     |   2\n",
      "      17305 |   0.218585  |    0.193237     |   1\n",
      "      17306 |   0.179685  |    0.026501     |   0\n",
      "      17307 |   0.201787  |    0.202975     |   1\n",
      "      17308 |   0.048278  |    0.022389     |   2\n",
      "      17309 |   0.185341  |    0.089812     |   0\n",
      "      17310 |   0.159342  |    0.148600     |   1\n",
      "      17311 |   0.195902  |    0.138254     |   1\n",
      "      17312 |   0.169047  |    0.040129     |   0\n",
      "      17313 |   0.022402  |    0.077587     |   2\n",
      "      17314 |   0.165693  |    0.144408     |   1\n",
      "      17315 |   0.173240  |    0.190106     |   1\n",
      "      17316 |   0.167494  |    0.253686     |   1\n",
      "      17317 |   0.000035  |    0.043945     |   2\n",
      "      17318 |   0.213539  |    0.199980     |   1\n",
      "      17319 |   0.215865  |    0.007071     |   0\n",
      "      17320 |   0.006159  |    0.069992     |   2\n",
      "      17321 |   0.068436  |    0.043736     |   2\n",
      "      17322 |   0.248223  |    0.288261     |   1\n",
      "      17323 |   0.036256  |    0.044115     |   2\n",
      "      17324 |   0.210281  |    0.270786     |   1\n",
      "      17325 |   0.207584  |    0.209906     |   1\n",
      "      17326 |   0.187997  |    0.016744     |   0\n",
      "      17327 |   0.057768  |    0.088180     |   2\n",
      "      17328 |   0.217260  |    0.193779     |   1\n",
      "      17329 |   0.181191  |    0.154533     |   1\n",
      "      17330 |   0.204178  |    0.052191     |   0\n",
      "      17331 |   0.044561  |    0.046203     |   2\n",
      "      17332 |   0.216046  |    0.046054     |   0\n",
      "      17333 |   0.015382  |    0.040229     |   2\n",
      "      17334 |   0.200354  |    0.078850     |   0\n",
      "      17335 |   0.146278  |    0.165164     |   1\n",
      "      17336 |   0.040444  |    0.042994     |   2\n",
      "      17337 |   0.181474  |    0.169774     |   1\n",
      "      17338 |   0.185525  |    0.027836     |   0\n",
      "      17339 |   0.196206  |    0.206620     |   1\n",
      "      17340 |   0.139692  |    0.201485     |   1\n",
      "      17341 |   0.218519  |    0.148647     |   1\n",
      "      17342 |   0.175754  |    0.050509     |   0\n",
      "      17343 |   0.205971  |    0.153091     |   1\n",
      "      17344 |   0.031837  |    0.047922     |   2\n",
      "      17345 |   0.000034  |    0.075744     |   2\n",
      "      17346 |   0.165939  |    0.048860     |   0\n",
      "      17347 |   0.169049  |    0.152147     |   1\n",
      "      17348 |   0.290784  |    0.143469     |   1\n",
      "      17349 | \u001b[94m  0.000034\u001b[0m  |    0.050460     |   2\n",
      "      17350 |   0.197845  |    0.047031     |   0\n",
      "      17351 | \u001b[94m  0.000034\u001b[0m  |    0.050203     |   2\n",
      "      17352 |   0.000034  |    0.034845     |   2\n",
      "      17353 | \u001b[94m  0.000034\u001b[0m  |    0.092121     |   2\n",
      "      17354 |   0.203682  |    0.151982     |   1\n",
      "      17355 |   0.187861  |    0.027601     |   0\n",
      "      17356 |   0.209007  |    0.040759     |   0\n",
      "      17357 | \u001b[94m  0.000034\u001b[0m  |    0.079755     |   2\n",
      "      17358 |   0.145098  |    0.012396     |   0\n",
      "      17359 |   0.173432  |    0.079934     |   0\n",
      "      17360 |   0.050565  |    0.018210     |   2\n",
      "      17361 |   0.149526  |    0.198518     |   1\n",
      "      17362 |   0.197626  |    0.081918     |   0\n",
      "      17363 |   0.244460  |    0.142694     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 17365: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      17364 |   0.054453  |    0.018460     |   2\n",
      "      17365 |   0.166162  |    0.060563     |   0\n",
      "      17366 |   0.226576  |    0.134160     |   1\n",
      "      17367 |   0.150078  |    0.037285     |   0\n",
      "      17368 |   0.193380  |    0.189866     |   1\n",
      "      17369 |   0.161632  |    0.030798     |   0\n",
      "      17370 |   0.185259  |    0.190951     |   1\n",
      "      17371 |   0.049094  |    0.022689     |   2\n",
      "      17372 |   0.034608  |    0.079267     |   2\n",
      "      17373 |   0.041117  |    0.015521     |   2\n",
      "      17374 |   0.211252  |    0.212036     |   1\n",
      "      17375 |   0.046173  |    0.005059     |   2\n",
      "      17376 |   0.231188  |    0.075629     |   0\n",
      "      17377 |   0.160174  |    0.020753     |   0\n",
      "      17378 |   0.268363  |    0.189385     |   1\n",
      "      17379 |   0.251946  |    0.154744     |   1\n",
      "      17380 |   0.191841  |    0.046599     |   0\n",
      "      17381 |   0.027529  |    0.033395     |   2\n",
      "      17382 |   0.156504  |    0.074329     |   0\n",
      "      17383 |   0.164222  |    0.029143     |   0\n",
      "      17384 |   0.042966  |    0.082646     |   2\n",
      "      17385 |   0.197626  |    0.015872     |   0\n",
      "      17386 |   0.051713  |    0.076962     |   2\n",
      "      17387 |   0.057654  |    0.031803     |   2\n",
      "      17388 |   0.047036  |    0.046856     |   2\n",
      "      17389 |   0.159581  |    0.188681     |   1\n",
      "      17390 |   0.022888  |    0.013090     |   2\n",
      "      17391 | \u001b[94m  0.000034\u001b[0m  |    0.076434     |   2\n",
      "      17392 |   0.006028  |    0.053235     |   2\n",
      "      17393 |   0.218771  |    0.124549     |   1\n",
      "      17394 |   0.196699  |    0.043859     |   0\n",
      "      17395 |   0.070158  |    0.073903     |   2\n",
      "      17396 |   0.037527  |    0.034472     |   2\n",
      "      17397 |   0.217835  |    0.047361     |   0\n",
      "      17398 |   0.058575  |    0.052677     |   2\n",
      "      17399 |   0.208691  |    0.029707     |   0\n",
      "      17400 |   0.195054  |    0.064318     |   0\n",
      "      17401 |   0.173415  |    0.167073     |   1\n",
      "      17402 |   0.164731  |    0.043272     |   0\n",
      "      17403 |   0.208575  |    0.199733     |   1\n",
      "      17404 |   0.045432  |    0.011477     |   2\n",
      "      17405 |   0.194317  |    0.204305     |   1\n",
      "      17406 |   0.017430  |    0.005863     |   2\n",
      "      17407 |   0.040139  |    0.094466     |   2\n",
      "      17408 |   0.173353  |    0.009939     |   0\n",
      "      17409 |   0.029303  |    0.077753     |   2\n",
      "      17410 |   0.172357  |    0.035761     |   0\n",
      "      17411 |   0.182806  |    0.198640     |   1\n",
      "      17412 |   0.000034  |    0.007933     |   2\n",
      "      17413 | \u001b[94m  0.000034\u001b[0m  |    0.090978     |   2\n",
      "      17414 |   0.186121  |    0.159394     |   1\n",
      "      17415 |   0.251601  |    0.150988     |   1\n",
      "      17416 |   0.000034  |    0.040439     |   2\n",
      "      17417 |   0.165513  |    0.079927     |   0\n",
      "      17418 |   0.193795  |    0.155771     |   1\n",
      "      17419 |   0.000034  |    0.030054     |   2\n",
      "      17420 |   0.195229  |    0.241802     |   1\n",
      "      17421 |   0.000034  |    0.006283     |   2\n",
      "      17422 |   0.161524  |    0.071707     |   0\n",
      "      17423 |   0.151215  |    0.047470     |   0\n",
      "      17424 |   0.000034  |    0.036460     |   2\n",
      "      17425 |   0.213121  |    0.076898     |   0\n",
      "      17426 |   0.147081  |    0.183898     |   1\n",
      "      17427 |   0.173468  |    0.197617     |   1\n",
      "      17428 |   0.130233  |    0.147850     |   1\n",
      "      17429 |   0.182597  |    0.184172     |   1\n",
      "      17430 |   0.199049  |    0.044745     |   0\n",
      "      17431 |   0.181213  |    0.153139     |   1\n",
      "      17432 |   0.209748  |    0.165234     |   1\n",
      "      17433 |   0.052545  |    0.045148     |   2\n",
      "      17434 |   0.206869  |    0.080052     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 17436: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      17435 |   0.053849  |    0.027228     |   2\n",
      "      17436 |   0.050545  |    0.052591     |   2\n",
      "      17437 |   0.176321  |    0.176051     |   1\n",
      "      17438 |   0.034701  |    0.030131     |   2\n",
      "      17439 |   0.195802  |    0.089284     |   0\n",
      "      17440 |   0.248912  |    0.184275     |   1\n",
      "      17441 |   0.041848  |    0.054100     |   2\n",
      "      17442 |   0.045654  |    0.075818     |   2\n",
      "      17443 |   0.183943  |    0.160965     |   1\n",
      "      17444 |   0.027095  |    0.008025     |   2\n",
      "      17445 |   0.041587  |    0.058900     |   2\n",
      "      17446 |   0.164048  |    0.128994     |   1\n",
      "      17447 |   0.209946  |    0.201084     |   1\n",
      "      17448 |   0.050129  |    0.012755     |   2\n",
      "      17449 |   0.055677  |    0.082961     |   2\n",
      "      17450 |   0.047308  |    0.010143     |   2\n",
      "      17451 |   0.166345  |    0.203020     |   1\n",
      "      17452 |   0.206460  |    0.149473     |   1\n",
      "      17453 |   0.023622  |    0.032989     |   2\n",
      "      17454 |   0.224449  |    0.208669     |   1\n",
      "      17455 |   0.213684  |    0.147358     |   1\n",
      "      17456 |   0.193263  |    0.041354     |   0\n",
      "      17457 |   0.206400  |    0.048833     |   0\n",
      "      17458 |   0.217852  |    0.041139     |   0\n",
      "      17459 |   0.189577  |    0.074989     |   0\n",
      "      17460 | \u001b[94m  0.000034\u001b[0m  |    0.015993     |   2\n",
      "      17461 |   0.186114  |    0.208506     |   1\n",
      "      17462 |   0.177096  |    0.147872     |   1\n",
      "      17463 |   0.215096  |    0.209880     |   1\n",
      "      17464 |   0.181736  |    0.007560     |   0\n",
      "      17465 |   0.006534  |    0.073612     |   2\n",
      "      17466 |   0.069540  |    0.040558     |   2\n",
      "      17467 |   0.203134  |    0.078502     |   0\n",
      "      17468 |   0.179203  |    0.158135     |   1\n",
      "      17469 |   0.036149  |    0.047069     |   2\n",
      "      17470 |   0.215325  |    0.144743     |   1\n",
      "      17471 |   0.061016  |    0.047404     |   2\n",
      "      17472 |   0.237441  |    0.159360     |   1\n",
      "      17473 |   0.044434  |    0.044619     |   2\n",
      "      17474 |   0.197087  |    0.041421     |   0\n",
      "      17475 |   0.016841  |    0.075071     |   2\n",
      "      17476 |   0.039937  |    0.025432     |   2\n",
      "      17477 |   0.208860  |    0.206651     |   1\n",
      "      17478 |   0.104675  |    0.143998     |   1\n",
      "      17479 |   0.191762  |    0.010010     |   0\n",
      "      17480 |   0.028999  |    0.076744     |   2\n",
      "      17481 |   0.193542  |    0.026088     |   0\n",
      "      17482 |   0.000034  |    0.039058     |   2\n",
      "      17483 |   0.187358  |    0.079969     |   0\n",
      "      17484 |   0.000034  |    0.030289     |   2\n",
      "      17485 |   0.161937  |    0.203988     |   1\n",
      "      17486 |   0.191580  |    0.007701     |   0\n",
      "      17487 |   0.183983  |    0.040645     |   0\n",
      "      17488 |   0.151241  |    0.159069     |   1\n",
      "      17489 |   0.212420  |    0.146496     |   1\n",
      "      17490 |   0.178138  |    0.187338     |   1\n",
      "      17491 |   0.156255  |    0.131870     |   1\n",
      "      17492 |   0.189034  |    0.078749     |   0\n",
      "      17493 |   0.173067  |    0.154249     |   1\n",
      "      17494 |   0.000034  |    0.045956     |   2\n",
      "      17495 |   0.000034  |    0.039692     |   2\n",
      "      17496 |   0.000034  |    0.077350     |   2\n",
      "      17497 |   0.000034  |    0.022826     |   2\n",
      "      17498 |   0.050513  |    0.086491     |   2\n",
      "      17499 |   0.243862  |    0.165673     |   1\n",
      "      17500 |   0.216844  |    0.166551     |   1\n",
      "      17501 |   0.227015  |    0.199941     |   1\n",
      "      17502 |   0.046795  |    0.018406     |   2\n",
      "      17503 |   0.183627  |    0.079450     |   0\n",
      "      17504 |   0.153451  |    0.046657     |   0\n",
      "      17505 |   0.283384  |    0.139888     |   1\n",
      "      17506 |   0.033772  |    0.049901     |   2\n",
      "      17507 |   0.041478  |    0.076011     |   2\n",
      "      17508 |   0.194599  |    0.015489     |   0\n",
      "      17509 |   0.045591  |    0.085224     |   2\n",
      "      17510 |   0.255335  |    0.172151     |   1\n",
      "      17511 |   0.226534  |    0.095389     |   1\n",
      "      17512 |   0.026943  |    0.043732     |   2\n",
      "      17513 |   0.197194  |    0.046750     |   0\n",
      "      17514 |   0.192170  |    0.039486     |   0\n",
      "      17515 |   0.215789  |    0.071019     |   0\n",
      "      17516 |   0.167919  |    0.038957     |   0\n",
      "      17517 |   0.251677  |    0.079324     |   0\n",
      "      17518 |   0.150797  |    0.191212     |   1\n",
      "      17519 |   0.209552  |    0.141308     |   1\n",
      "      17520 |   0.178674  |    0.041086     |   0\n",
      "      17521 |   0.041529  |    0.083918     |   2\n",
      "      17522 |   0.217460  |    0.139417     |   1\n",
      "      17523 |   0.050839  |    0.075358     |   2\n",
      "      17524 |   0.152560  |    0.138470     |   1\n",
      "      17525 |   0.197943  |    0.181025     |   1\n",
      "      17526 |   0.178922  |    0.022436     |   0\n",
      "      17527 |   0.168939  |    0.059694     |   0\n",
      "      17528 |   0.058428  |    0.050510     |   2\n",
      "      17529 |   0.197007  |    0.083866     |   0\n",
      "      17530 |   0.048002  |    0.023632     |   2\n",
      "      17531 |   0.157861  |    0.193838     |   1\n",
      "      17532 |   0.232585  |    0.076598     |   0\n",
      "      17533 |   0.023957  |    0.015300     |   2\n",
      "      17534 | \u001b[94m  0.000033\u001b[0m  |    0.077854     |   2\n",
      "      17535 |   0.161246  |    0.025140     |   0\n",
      "      17536 |   0.171634  |    0.214970     |   1\n",
      "      17537 |   0.208753  |    0.146134     |   1\n",
      "      17538 |   0.006220  |    0.073107     |   2\n",
      "      17539 |   0.144674  |    0.027602     |   0\n",
      "      17540 |   0.069582  |    0.070609     |   2\n",
      "      17541 |   0.037933  |    0.041244     |   2\n",
      "      17542 |   0.165671  |    0.042122     |   0\n",
      "      17543 |   0.061276  |    0.074207     |   2\n",
      "      17544 |   0.242410  |    0.040766     |   0\n",
      "      17545 |   0.182280  |    0.056297     |   0\n",
      "      17546 |   0.243470  |    0.153995     |   1\n",
      "      17547 |   0.210165  |    0.156650     |   1\n",
      "      17548 |   0.221791  |    0.128431     |   1\n",
      "      17549 |   0.046438  |    0.037026     |   2\n",
      "      17550 |   0.188101  |    0.049209     |   0\n",
      "      17551 |   0.209046  |    0.043730     |   0\n",
      "      17552 |   0.017526  |    0.078899     |   2\n",
      "      17553 |   0.043012  |    0.007299     |   2\n",
      "      17554 |   0.178924  |    0.055069     |   0\n",
      "      17555 |   0.193004  |    0.193284     |   1\n",
      "      17556 |   0.205000  |    0.144213     |   1\n",
      "      17557 |   0.028945  |    0.026162     |   2\n",
      "      17558 |   0.178308  |    0.186486     |   1\n",
      "      17559 |   0.169242  |    0.031677     |   0\n",
      "      17560 | \u001b[94m  0.000033\u001b[0m  |    0.074732     |   2\n",
      "      17561 | \u001b[94m  0.000033\u001b[0m  |    0.041076     |   2\n",
      "      17562 |   0.225853  |    0.136735     |   1\n",
      "      17563 |   0.158247  |    0.073075     |   0\n",
      "      17564 |   0.200685  |    0.017617     |   0\n",
      "      17565 |   0.000033  |    0.078298     |   2\n",
      "      17566 |   0.184943  |    0.024328     |   0\n",
      "      17567 |   0.000034  |    0.061748     |   2\n",
      "      17568 |   0.000033  |    0.076148     |   2\n",
      "      17569 |   0.184079  |    0.039153     |   0\n",
      "      17570 |   0.191777  |    0.048529     |   0\n",
      "      17571 |   0.000033  |    0.037909     |   2\n",
      "      17572 |   0.056377  |    0.049309     |   2\n",
      "      17573 |   0.055004  |    0.092576     |   2\n",
      "      17574 |   0.224636  |    0.142816     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 17575: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      17575 |   0.051784  |    0.008537     |   2\n",
      "      17576 |   0.183967  |    0.043716     |   0\n",
      "      17577 |   0.189799  |    0.111888     |   0\n",
      "      17578 |   0.180695  |    0.136883     |   1\n",
      "      17579 |   0.036862  |    0.014564     |   2\n",
      "      17580 |   0.209177  |    0.186957     |   1\n",
      "      17581 |   0.041050  |    0.027528     |   2\n",
      "      17582 |   0.045360  |    0.075417     |   2\n",
      "      17583 |   0.028227  |    0.042346     |   2\n",
      "      17584 |   0.186300  |    0.045132     |   0\n",
      "      17585 |   0.179843  |    0.195220     |   1\n",
      "      17586 |   0.206237  |    0.083245     |   1\n",
      "      17587 |   0.040978  |    0.073001     |   2\n",
      "      17588 |   0.196716  |    0.149425     |   1\n",
      "      17589 |   0.177381  |    0.042019     |   0\n",
      "      17590 |   0.050593  |    0.056256     |   2\n",
      "      17591 |   0.152946  |    0.160325     |   1\n",
      "      17592 |   0.055663  |    0.042777     |   2\n",
      "      17593 |   0.048243  |    0.071170     |   2\n",
      "      17594 |   0.185161  |    0.043586     |   0\n",
      "      17595 |   0.166650  |    0.073607     |   0\n",
      "      17596 |   0.021936  |    0.029211     |   2\n",
      "      17597 |   0.156706  |    0.098618     |   0\n",
      "      17598 |   0.277911  |    0.084877     |   1\n",
      "      17599 |   0.170707  |    0.047617     |   0\n",
      "      17600 |   0.183269  |    0.162366     |   1\n",
      "      17601 |   0.207866  |    0.070927     |   0\n",
      "      17602 |   0.214050  |    0.036289     |   0\n",
      "      17603 |   0.213284  |    0.075934     |   0\n",
      "      17604 |   0.000033  |    0.079811     |   2\n",
      "      17605 |   0.190049  |    0.047299     |   0\n",
      "      17606 |   0.160410  |    0.040049     |   0\n",
      "      17607 |   0.205252  |    0.080536     |   0\n",
      "      17608 |   0.005865  |    0.051180     |   2\n",
      "      17609 |   0.206457  |    0.189105     |   1\n",
      "      17610 |   0.171104  |    0.015316     |   0\n",
      "      17611 |   0.069233  |    0.076358     |   2\n",
      "      17612 |   0.037410  |    0.032526     |   2\n",
      "      17613 |   0.062384  |    0.079169     |   2\n",
      "      17614 |   0.146823  |    0.020747     |   0\n",
      "      17615 |   0.213942  |    0.245320     |   1\n",
      "      17616 |   0.181844  |    0.156981     |   1\n",
      "      17617 |   0.152669  |    0.195011     |   1\n",
      "      17618 |   0.194254  |    0.030457     |   0\n",
      "      17619 |   0.045481  |    0.082565     |   2\n",
      "      17620 |   0.016948  |    0.053317     |   2\n",
      "      17621 |   0.236551  |    0.210523     |   1\n",
      "      17622 |   0.225445  |    0.199755     |   1\n",
      "      17623 |   0.040825  |    0.037910     |   2\n",
      "      17624 |   0.240042  |    0.187590     |   1\n",
      "      17625 |   0.219195  |    0.138718     |   1\n",
      "      17626 |   0.243563  |    0.042281     |   0\n",
      "      17627 |   0.215371  |    0.083395     |   0\n",
      "      17628 |   0.030096  |    0.028728     |   2\n",
      "      17629 |   0.151411  |    0.083380     |   0\n",
      "      17630 |   0.163752  |    0.165332     |   1\n",
      "      17631 |   0.224608  |    0.005788     |   0\n",
      "      17632 |   0.000034  |    0.084857     |   2\n",
      "      17633 |   0.178811  |    0.132000     |   1\n",
      "      17634 |   0.180479  |    0.148059     |   1\n",
      "      17635 |   0.184166  |    0.077492     |   0\n",
      "      17636 |   0.000034  |    0.041060     |   2\n",
      "      17637 |   0.190329  |    0.072957     |   0\n",
      "      17638 |   0.135243  |    0.057819     |   0\n",
      "      17639 |   0.000034  |    0.120469     |   2\n",
      "      17640 |   0.167922  |    0.005223     |   0\n",
      "      17641 |   0.173188  |    0.077486     |   0\n",
      "      17642 |   0.000034  |    0.040827     |   2\n",
      "      17643 |   0.000034  |    0.082578     |   2\n",
      "      17644 |   0.180818  |    0.149572     |   1\n",
      "      17645 |   0.000034  |    0.044658     |   2\n",
      "      17646 |   0.054124  |    0.078074     |   2\n",
      "      17647 |   0.228267  |    0.145530     |   1\n",
      "      17648 |   0.184116  |    0.199247     |   1\n",
      "      17649 |   0.054411  |    0.005497     |   2\n",
      "      17650 |   0.199414  |    0.197184     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 17651: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      17651 |   0.144403  |    0.185254     |   1\n",
      "      17652 |   0.049215  |    0.008504     |   2\n",
      "      17653 |   0.039255  |    0.086037     |   2\n",
      "      17654 |   0.196905  |    0.013823     |   0\n",
      "      17655 |   0.189806  |    0.091784     |   0\n",
      "      17656 |   0.211082  |    0.139687     |   1\n",
      "      17657 |   0.178598  |    0.022078     |   0\n",
      "      17658 |   0.164417  |    0.079681     |   0\n",
      "      17659 |   0.041628  |    0.024743     |   2\n",
      "      17660 |   0.046667  |    0.073992     |   2\n",
      "      17661 |   0.027786  |    0.028010     |   2\n",
      "      17662 |   0.293458  |    0.195536     |   1\n",
      "      17663 |   0.038651  |    0.035945     |   2\n",
      "      17664 |   0.152410  |    0.152822     |   1\n",
      "      17665 |   0.134211  |    0.216783     |   1\n",
      "      17666 |   0.177193  |    0.145020     |   1\n",
      "      17667 |   0.246330  |    0.078166     |   0\n",
      "      17668 |   0.148498  |    0.040724     |   0\n",
      "      17669 |   0.195088  |    0.068933     |   0\n",
      "      17670 |   0.054485  |    0.027859     |   2\n",
      "      17671 |   0.056555  |    0.087370     |   2\n",
      "      17672 |   0.047864  |    0.036666     |   2\n",
      "      17673 |   0.022261  |    0.035817     |   2\n",
      "      17674 | \u001b[94m  0.000033\u001b[0m  |    0.072511     |   2\n",
      "      17675 |   0.193938  |    0.019205     |   0\n",
      "      17676 |   0.200617  |    0.079071     |   0\n",
      "      17677 |   0.167413  |    0.147218     |   1\n",
      "      17678 |   0.222083  |    0.074395     |   0\n",
      "      17679 |   0.005577  |    0.041630     |   2\n",
      "      17680 |   0.072059  |    0.079181     |   2\n",
      "      17681 |   0.181134  |    0.164907     |   1\n",
      "      17682 |   0.183676  |    0.009880     |   0\n",
      "      17683 |   0.135135  |    0.253233     |   1\n",
      "      17684 |   0.135068  |    0.016320     |   0\n",
      "      17685 |   0.036449  |    0.050954     |   2\n",
      "      17686 |   0.062669  |    0.030175     |   2\n",
      "      17687 |   0.208990  |    0.079277     |   0\n",
      "      17688 |   0.198081  |    0.195424     |   1\n",
      "      17689 |   0.046513  |    0.012034     |   2\n",
      "      17690 |   0.018119  |    0.076309     |   2\n",
      "      17691 |   0.169053  |    0.131813     |   1\n",
      "      17692 |   0.041492  |    0.054494     |   2\n",
      "      17693 |   0.266466  |    0.191816     |   1\n",
      "      17694 |   0.196761  |    0.105087     |   1\n",
      "      17695 |   0.028758  |    0.073602     |   2\n",
      "      17696 |   0.191494  |    0.027464     |   0\n",
      "      17697 |   0.000033  |    0.082712     |   2\n",
      "      17698 |   0.000033  |    0.011915     |   2\n",
      "      17699 |   0.168638  |    0.213916     |   1\n",
      "      17700 |   0.209693  |    0.005395     |   0\n",
      "      17701 |   0.190049  |    0.166636     |   1\n",
      "      17702 |   0.195392  |    0.143335     |   1\n",
      "      17703 |   0.239438  |    0.006260     |   0\n",
      "      17704 |   0.177313  |    0.072068     |   0\n",
      "      17705 |   0.224755  |    0.166305     |   1\n",
      "      17706 |   0.143733  |    0.238651     |   1\n",
      "      17707 |   0.130534  |    0.258503     |   1\n",
      "      17708 |   0.000033  |    0.005360     |   2\n",
      "      17709 |   0.228588  |    0.074186     |   0\n",
      "      17710 |   0.178640  |    0.053715     |   0\n",
      "      17711 |   0.000033  |    0.033532     |   2\n",
      "      17712 |   0.195271  |    0.052295     |   0\n",
      "      17713 | \u001b[94m  0.000033\u001b[0m  |    0.040688     |   2\n",
      "      17714 |   0.186620  |    0.040954     |   0\n",
      "      17715 | \u001b[94m  0.000033\u001b[0m  |    0.039465     |   2\n",
      "      17716 |   0.232984  |    0.213742     |   1\n",
      "      17717 |   0.050839  |    0.014461     |   2\n",
      "      17718 |   0.053060  |    0.078075     |   2\n",
      "      17719 |   0.112368  |    0.019061     |   0\n",
      "      17720 |   0.210509  |    0.149214     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 17721: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      17721 |   0.194039  |    0.061478     |   0\n",
      "      17722 |   0.156033  |    0.154562     |   1\n",
      "      17723 |   0.053230  |    0.044829     |   2\n",
      "      17724 |   0.247258  |    0.188583     |   1\n",
      "      17725 |   0.037444  |    0.004581     |   2\n",
      "      17726 |   0.139545  |    0.072809     |   0\n",
      "      17727 |   0.043457  |    0.022125     |   2\n",
      "      17728 |   0.186459  |    0.051419     |   0\n",
      "      17729 |   0.187709  |    0.042389     |   0\n",
      "      17730 |   0.044108  |    0.033029     |   2\n",
      "      17731 |   0.027578  |    0.058952     |   2\n",
      "      17732 |   0.128534  |    0.208052     |   1\n",
      "      17733 |   0.191162  |    0.146180     |   1\n",
      "      17734 |   0.317508  |    0.146281     |   1\n",
      "      17735 |   0.204242  |    0.079825     |   0\n",
      "      17736 |   0.040925  |    0.031917     |   2\n",
      "      17737 |   0.183833  |    0.183440     |   1\n",
      "      17738 |   0.051208  |    0.029310     |   2\n",
      "      17739 |   0.058590  |    0.052832     |   2\n",
      "      17740 |   0.168717  |    0.202728     |   1\n",
      "      17741 |   0.198815  |    0.007090     |   0\n",
      "      17742 |   0.197959  |    0.193979     |   1\n",
      "      17743 |   0.152146  |    0.018175     |   0\n",
      "      17744 |   0.142033  |    0.200176     |   1\n",
      "      17745 |   0.166418  |    0.056916     |   0\n",
      "      17746 |   0.211320  |    0.150180     |   1\n",
      "      17747 |   0.049954  |    0.045540     |   2\n",
      "      17748 |   0.183808  |    0.050907     |   0\n",
      "      17749 |   0.024216  |    0.033554     |   2\n",
      "      17750 |   0.193609  |    0.052352     |   0\n",
      "      17751 |   0.181073  |    0.039733     |   0\n",
      "      17752 |   0.183707  |    0.075590     |   0\n",
      "      17753 |   0.000033  |    0.024551     |   2\n",
      "      17754 |   0.130919  |    0.197013     |   1\n",
      "      17755 |   0.165657  |    0.022144     |   0\n",
      "      17756 |   0.005540  |    0.074209     |   2\n",
      "      17757 |   0.160174  |    0.036600     |   0\n",
      "      17758 |   0.193263  |    0.193623     |   1\n",
      "      17759 |   0.193797  |    0.025657     |   0\n",
      "      17760 |   0.208092  |    0.038428     |   0\n",
      "      17761 |   0.065929  |    0.047763     |   2\n",
      "      17762 |   0.176903  |    0.193685     |   1\n",
      "      17763 |   0.254939  |    0.132927     |   1\n",
      "      17764 |   0.036916  |    0.051480     |   2\n",
      "      17765 |   0.190819  |    0.210968     |   1\n",
      "      17766 |   0.243413  |    0.012223     |   0\n",
      "      17767 |   0.062401  |    0.078436     |   2\n",
      "      17768 |   0.045426  |    0.047813     |   2\n",
      "      17769 |   0.017339  |    0.027460     |   2\n",
      "      17770 |   0.170504  |    0.074076     |   0\n",
      "      17771 |   0.178785  |    0.131584     |   1\n",
      "      17772 |   0.041895  |    0.024766     |   2\n",
      "      17773 |   0.181687  |    0.049160     |   0\n",
      "      17774 |   0.028980  |    0.052169     |   2\n",
      "      17775 |   0.210675  |    0.043559     |   0\n",
      "      17776 |   0.190455  |    0.046104     |   0\n",
      "      17777 |   0.000033  |    0.078565     |   2\n",
      "      17778 |   0.000033  |    0.004887     |   2\n",
      "      17779 |   0.192606  |    0.076303     |   0\n",
      "      17780 |   0.187780  |    0.025818     |   0\n",
      "      17781 |   0.172576  |    0.073843     |   0\n",
      "      17782 |   0.000033  |    0.029770     |   2\n",
      "      17783 |   0.176243  |    0.047187     |   0\n",
      "      17784 |   0.193315  |    0.040522     |   0\n",
      "      17785 |   0.000033  |    0.078250     |   2\n",
      "      17786 |   0.000033  |    0.013404     |   2\n",
      "      17787 |   0.151965  |    0.048281     |   0\n",
      "      17788 |   0.000033  |    0.074556     |   2\n",
      "      17789 |   0.220709  |    0.051311     |   0\n",
      "      17790 |   0.147006  |    0.138116     |   1\n",
      "      17791 |   0.222009  |    0.132419     |   1\n",
      "      17792 |   0.133518  |    0.202729     |   1\n",
      "      17793 |   0.170636  |    0.007284     |   0\n",
      "      17794 |   0.052800  |    0.091821     |   2\n",
      "      17795 |   0.174770  |    0.019830     |   0\n",
      "      17796 |   0.220891  |    0.082621     |   0\n",
      "      17797 |   0.054007  |    0.025508     |   2\n",
      "      17798 |   0.178086  |    0.077704     |   0\n",
      "      17799 |   0.165125  |    0.189606     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 17800: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      17800 |   0.198497  |    0.091093     |   1\n",
      "      17801 |   0.133646  |    0.058269     |   0\n",
      "      17802 |   0.193173  |    0.198746     |   1\n",
      "      17803 |   0.051179  |    0.004847     |   2\n",
      "      17804 |   0.037901  |    0.086683     |   2\n",
      "      17805 |   0.219298  |    0.148908     |   1\n",
      "      17806 |   0.042353  |    0.050684     |   2\n",
      "      17807 |   0.043998  |    0.040155     |   2\n",
      "      17808 |   0.151860  |    0.071335     |   0\n",
      "      17809 |   0.186673  |    0.020996     |   0\n",
      "      17810 |   0.027525  |    0.070134     |   2\n",
      "      17811 |   0.184455  |    0.192963     |   1\n",
      "      17812 |   0.041205  |    0.020249     |   2\n",
      "      17813 |   0.207032  |    0.186557     |   1\n",
      "      17814 |   0.051902  |    0.041162     |   2\n",
      "      17815 |   0.194614  |    0.074924     |   0\n",
      "      17816 |   0.183253  |    0.023389     |   0\n",
      "      17817 |   0.197861  |    0.074144     |   0\n",
      "      17818 |   0.057793  |    0.024512     |   2\n",
      "      17819 |   0.190795  |    0.192535     |   1\n",
      "      17820 |   0.047532  |    0.008271     |   2\n",
      "      17821 |   0.213687  |    0.082280     |   0\n",
      "      17822 |   0.177878  |    0.197902     |   1\n",
      "      17823 |   0.144002  |    0.008837     |   0\n",
      "      17824 |   0.021249  |    0.075395     |   2\n",
      "      17825 |   0.207795  |    0.033134     |   0\n",
      "      17826 |   0.000034  |    0.039772     |   2\n",
      "      17827 |   0.256614  |    0.184896     |   1\n",
      "      17828 |   0.005357  |    0.022161     |   2\n",
      "      17829 |   0.183072  |    0.214482     |   1\n",
      "      17830 |   0.199977  |    0.011674     |   0\n",
      "      17831 |   0.068298  |    0.077024     |   2\n",
      "      17832 |   0.231589  |    0.137009     |   1\n",
      "      17833 |   0.036016  |    0.027518     |   2\n",
      "      17834 |   0.162575  |    0.049337     |   0\n",
      "      17835 |   0.060403  |    0.054100     |   2\n",
      "      17836 |   0.204704  |    0.149264     |   1\n",
      "      17837 |   0.161886  |    0.079292     |   0\n",
      "      17838 |   0.043992  |    0.018332     |   2\n",
      "      17839 |   0.164718  |    0.080457     |   0\n",
      "      17840 |   0.191576  |    0.153344     |   1\n",
      "      17841 |   0.016022  |    0.042477     |   2\n",
      "      17842 |   0.040519  |    0.044401     |   2\n",
      "      17843 |   0.170102  |    0.071212     |   0\n",
      "      17844 |   0.028602  |    0.018144     |   2\n",
      "      17845 |   0.231351  |    0.211613     |   1\n",
      "      17846 |   0.210442  |    0.007564     |   0\n",
      "      17847 |   0.189280  |    0.078920     |   0\n",
      "      17848 |   0.200187  |    0.043232     |   0\n",
      "      17849 |   0.000034  |    0.033972     |   2\n",
      "      17850 |   0.152981  |    0.142745     |   1\n",
      "      17851 |   0.186991  |    0.151701     |   1\n",
      "      17852 |   0.307304  |    0.198158     |   1\n",
      "      17853 |   0.000034  |    0.007056     |   2\n",
      "      17854 |   0.000034  |    0.082674     |   2\n",
      "      17855 |   0.157666  |    0.018762     |   0\n",
      "      17856 |   0.173330  |    0.082029     |   0\n",
      "      17857 |   0.183874  |    0.131909     |   1\n",
      "      17858 |   0.129184  |    0.198864     |   1\n",
      "      17859 |   0.160966  |    0.138167     |   1\n",
      "      17860 |   0.000034  |    0.026054     |   2\n",
      "      17861 |   0.000033  |    0.082986     |   2\n",
      "      17862 |   0.168772  |    0.012971     |   0\n",
      "      17863 |   0.206871  |    0.076320     |   0\n",
      "      17864 |   0.000033  |    0.022268     |   2\n",
      "      17865 |   0.205346  |    0.048780     |   0\n",
      "      17866 |   0.204121  |    0.087099     |   0\n",
      "      17867 |   0.201644  |    0.161493     |   1\n",
      "      17868 |   0.170869  |    0.146486     |   1\n",
      "      17869 |   0.053131  |    0.039804     |   2\n",
      "      17870 |   0.210330  |    0.197100     |   1\n",
      "      17871 |   0.162414  |    0.041038     |   0\n",
      "      17872 |   0.243622  |    0.145242     |   1\n",
      "      17873 |   0.055013  |    0.041027     |   2\n",
      "      17874 |   0.171411  |    0.047875     |   0\n",
      "      17875 |   0.160417  |    0.042366     |   0\n",
      "      17876 |   0.176734  |    0.188192     |   1\n",
      "      17877 |   0.255455  |    0.149919     |   1\n",
      "      17878 |   0.184642  |    0.026264     |   0\n",
      "      17879 |   0.167622  |    0.076985     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 17880: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      17880 |   0.049750  |    0.025606     |   2\n",
      "      17881 |   0.223010  |    0.222934     |   1\n",
      "      17882 |   0.147556  |    0.005560     |   0\n",
      "      17883 |   0.188512  |    0.067875     |   0\n",
      "      17884 |   0.192151  |    0.268405     |   1\n",
      "      17885 |   0.196845  |    0.162263     |   1\n",
      "      17886 |   0.216094  |    0.087107     |   0\n",
      "      17887 |   0.038369  |    0.044260     |   2\n",
      "      17888 |   0.040137  |    0.040273     |   2\n",
      "      17889 |   0.220063  |    0.085906     |   0\n",
      "      17890 |   0.213779  |    0.049062     |   0\n",
      "      17891 |   0.194902  |    0.159318     |   1\n",
      "      17892 |   0.044314  |    0.012801     |   2\n",
      "      17893 |   0.027708  |    0.086969     |   2\n",
      "      17894 |   0.040603  |    0.025164     |   2\n",
      "      17895 |   0.139242  |    0.078981     |   0\n",
      "      17896 |   0.170854  |    0.190594     |   1\n",
      "      17897 |   0.217000  |    0.152991     |   1\n",
      "      17898 |   0.053178  |    0.030386     |   2\n",
      "      17899 |   0.055911  |    0.048358     |   2\n",
      "      17900 |   0.216816  |    0.187311     |   1\n",
      "      17901 |   0.046551  |    0.042334     |   2\n",
      "      17902 |   0.166015  |    0.047983     |   0\n",
      "      17903 |   0.021511  |    0.072879     |   2\n",
      "      17904 |   0.000033  |    0.058037     |   2\n",
      "      17905 |   0.006035  |    0.092781     |   2\n",
      "      17906 |   0.215554  |    0.144351     |   1\n",
      "      17907 |   0.203133  |    0.189790     |   1\n",
      "      17908 |   0.067279  |    0.005617     |   2\n",
      "      17909 |   0.035342  |    0.080837     |   2\n",
      "      17910 |   0.061319  |    0.022039     |   2\n",
      "      17911 |   0.217824  |    0.177912     |   1\n",
      "      17912 |   0.176228  |    0.025901     |   0\n",
      "      17913 |   0.170716  |    0.208877     |   1\n",
      "      17914 |   0.195917  |    0.197867     |   1\n",
      "      17915 |   0.195457  |    0.041099     |   0\n",
      "      17916 |   0.139121  |    0.056066     |   0\n",
      "      17917 |   0.043070  |    0.050101     |   2\n",
      "      17918 |   0.243849  |    0.191786     |   1\n",
      "      17919 |   0.191387  |    0.148223     |   1\n",
      "      17920 |   0.252031  |    0.152924     |   1\n",
      "      17921 |   0.175110  |    0.210321     |   1\n",
      "      17922 |   0.191027  |    0.044887     |   0\n",
      "      17923 |   0.192208  |    0.039081     |   0\n",
      "      17924 |   0.167293  |    0.050631     |   0\n",
      "      17925 |   0.015306  |    0.047664     |   2\n",
      "      17926 |   0.188269  |    0.074591     |   0\n",
      "      17927 |   0.219312  |    0.022824     |   0\n",
      "      17928 |   0.040722  |    0.075975     |   2\n",
      "      17929 |   0.146729  |    0.026807     |   0\n",
      "      17930 |   0.173444  |    0.083052     |   0\n",
      "      17931 |   0.207966  |    0.163905     |   1\n",
      "      17932 |   0.128331  |    0.188616     |   1\n",
      "      17933 |   0.165268  |    0.008306     |   0\n",
      "      17934 |   0.029888  |    0.070504     |   2\n",
      "      17935 |   0.194353  |    0.158963     |   1\n",
      "      17936 |   0.226630  |    0.148790     |   1\n",
      "      17937 |   0.230303  |    0.127371     |   1\n",
      "      17938 |   0.000033  |    0.043160     |   2\n",
      "      17939 |   0.171975  |    0.064557     |   0\n",
      "      17940 |   0.198688  |    0.176520     |   1\n",
      "      17941 |   0.149938  |    0.050921     |   0\n",
      "      17942 |   0.155254  |    0.196161     |   1\n",
      "      17943 |   0.229769  |    0.137205     |   1\n",
      "      17944 | \u001b[94m  0.000033\u001b[0m  |    0.021969     |   2\n",
      "      17945 |   0.000033  |    0.078391     |   2\n",
      "      17946 |   0.199634  |    0.038861     |   0\n",
      "      17947 |   0.167473  |    0.055470     |   0\n",
      "      17948 |   0.216346  |    0.202726     |   1\n",
      "      17949 |   0.000033  |    0.013300     |   2\n",
      "      17950 |   0.177318  |    0.228700     |   1\n",
      "      17951 |   0.311185  |    0.139786     |   1\n",
      "      17952 |   0.174803  |    0.017537     |   0\n",
      "      17953 |   0.266681  |    0.224010     |   1\n",
      "      17954 |   0.216892  |    0.174370     |   1\n",
      "      17955 |   0.000033  |    0.024347     |   2\n",
      "      17956 |   0.217929  |    0.078967     |   0\n",
      "      17957 |   0.000033  |    0.042877     |   2\n",
      "      17958 |   0.135263  |    0.044634     |   0\n",
      "      17959 |   0.234468  |    0.150815     |   1\n",
      "      17960 |   0.202943  |    0.078736     |   0\n",
      "      17961 |   0.169718  |    0.027122     |   0\n",
      "      17962 |   0.045739  |    0.045491     |   2\n",
      "      17963 |   0.235770  |    0.080401     |   0\n",
      "      17964 |   0.223774  |    0.147841     |   1\n",
      "      17965 |   0.255949  |    0.082269     |   0\n",
      "      17966 |   0.161008  |    0.152209     |   1\n",
      "      17967 |   0.213826  |    0.138443     |   1\n",
      "      17968 |   0.054145  |    0.085893     |   2\n",
      "      17969 |   0.184981  |    0.025387     |   0\n",
      "      17970 |   0.188142  |    0.044721     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 17971: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      17971 |   0.049512  |    0.074730     |   2\n",
      "      17972 |   0.209808  |    0.146169     |   1\n",
      "      17973 |   0.243104  |    0.194594     |   1\n",
      "      17974 |   0.035022  |    0.019645     |   2\n",
      "      17975 |   0.228153  |    0.139055     |   1\n",
      "      17976 |   0.042157  |    0.045037     |   2\n",
      "      17977 |   0.172572  |    0.076546     |   0\n",
      "      17978 |   0.043828  |    0.020378     |   2\n",
      "      17979 |   0.027396  |    0.053654     |   2\n",
      "      17980 |   0.227316  |    0.210221     |   1\n",
      "      17981 |   0.038338  |    0.005069     |   2\n",
      "      17982 |   0.153273  |    0.196235     |   1\n",
      "      17983 |   0.170877  |    0.003887     |   0\n",
      "      17984 |   0.050323  |    0.041763     |   2\n",
      "      17985 |   0.235375  |    0.073446     |   0\n",
      "      17986 |   0.056704  |    0.022548     |   2\n",
      "      17987 |   0.188001  |    0.085272     |   0\n",
      "      17988 |   0.206502  |    0.014572     |   0\n",
      "      17989 |   0.046974  |    0.083437     |   2\n",
      "      17990 |   0.022381  |    0.041298     |   2\n",
      "      17991 |   0.151243  |    0.218141     |   1\n",
      "      17992 |   0.203822  |    0.139240     |   1\n",
      "      17993 |   0.250985  |    0.153925     |   1\n",
      "      17994 |   0.226360  |    0.022213     |   0\n",
      "      17995 |   0.163323  |    0.075673     |   0\n",
      "      17996 |   0.200634  |    0.028062     |   0\n",
      "      17997 | \u001b[94m  0.000033\u001b[0m  |    0.044339     |   2\n",
      "      17998 |   0.005756  |    0.079805     |   2\n",
      "      17999 |   0.217517  |    0.152420     |   1\n",
      "      18000 |   0.069194  |    0.043801     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 18000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 18000: Plotting estimates.\n",
      "Exception in thread neuralnilm-data-process:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 810, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/jack/workspace/python/neuralnilm/neuralnilm/data/datathread.py\", line 16, in run\n",
      "    batch = self.data_pipeline.get_batch(**self._get_batch_kwargs)\n",
      "  File \"/home/jack/workspace/python/neuralnilm/neuralnilm/data/datapipeline.py\", line 46, in get_batch\n",
      "    batch = self._source_iterators[source_id].next()\n",
      "ValueError: generator already executing\n",
      "\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      18001 |   0.049272  |    0.078479     |   2\n",
      "      18002 |   0.034465  |    0.020993     |   2\n",
      "      18003 |   0.227690  |    0.082908     |   0\n",
      "      18004 |   0.042548  |    0.009349     |   2\n",
      "      18005 |   0.279690  |    0.171354     |   1\n",
      "      18006 |   0.043703  |    0.056110     |   2\n",
      "      18007 |   0.188434  |    0.151991     |   1\n",
      "      18008 |   0.027153  |    0.081618     |   2\n",
      "      18009 |   0.182529  |    0.022199     |   0\n",
      "      18010 |   0.201798  |    0.077504     |   0\n",
      "      18011 |   0.253209  |    0.154366     |   1\n",
      "      18012 |   0.236527  |    0.143740     |   1\n",
      "      18013 |   0.039151  |    0.018791     |   2\n",
      "      18014 |   0.050853  |    0.076564     |   2\n",
      "      18015 |   0.058071  |    0.014525     |   2\n",
      "      18016 |   0.230121  |    0.073656     |   0\n",
      "      18017 |   0.045609  |    0.032348     |   2\n",
      "      18018 |   0.153084  |    0.077948     |   0\n",
      "      18019 |   0.131975  |    0.019997     |   0\n",
      "      18020 |   0.021820  |    0.076183     |   2\n",
      "      18021 |   0.199511  |    0.190703     |   1\n",
      "      18022 |   0.130335  |    0.137047     |   1\n",
      "      18023 |   0.208907  |    0.135562     |   1\n",
      "      18024 |   0.231419  |    0.229446     |   1\n",
      "      18025 |   0.185968  |    0.072141     |   0\n",
      "      18026 |   0.196654  |    0.294504     |   1\n",
      "      18027 |   0.190575  |    0.120684     |   0\n",
      "      18028 |   0.151038  |    0.324803     |   1\n",
      "      18029 |   0.169269  |    0.331001     |   1\n",
      "      18030 |   0.243285  |    0.632077     |   1\n",
      "      18031 |   0.175984  |    0.043571     |   0\n",
      "      18032 |   0.173860  |    0.086186     |   0\n",
      "      18033 |   0.177537  |    0.075642     |   0\n",
      "      18034 |   0.199616  |    0.322131     |   1\n",
      "      18035 | \u001b[94m  0.000032\u001b[0m  |    0.093336     |   2\n",
      "      18036 |   0.005090  |    0.119802     |   2\n",
      "      18037 |   0.066848  |    0.064867     |   2\n",
      "      18038 |   0.035241  |    0.073643     |   2\n",
      "      18039 |   0.169795  |    0.027466     |   0\n",
      "      18040 |   0.201892  |    0.207929     |   1\n",
      "      18041 |   0.210399  |    0.165061     |   1\n",
      "      18042 |   0.061588  |    0.044631     |   2\n",
      "      18043 |   0.171545  |    0.094438     |   0\n",
      "      18044 |   0.045374  |    0.046485     |   2\n",
      "      18045 |   0.183584  |    0.218631     |   1\n",
      "      18046 |   0.017810  |    0.015894     |   2\n",
      "      18047 |   0.198189  |    0.182019     |   1\n",
      "      18048 |   0.039595  |    0.036339     |   2\n",
      "      18049 |   0.151149  |    0.198577     |   1\n",
      "      18050 |   0.163483  |    0.039893     |   0\n",
      "      18051 |   0.028400  |    0.043697     |   2\n",
      "      18052 |   0.000032  |    0.094848     |   2\n",
      "      18053 |   0.151541  |    0.163668     |   1\n",
      "      18054 |   0.000032  |    0.007573     |   2\n",
      "      18055 |   0.000032  |    0.086438     |   2\n",
      "      18056 |   0.228272  |    0.034733     |   0\n",
      "      18057 |   0.209264  |    0.206230     |   1\n",
      "      18058 |   0.000033  |    0.043157     |   2\n",
      "      18059 |   0.175026  |    0.201455     |   1\n",
      "      18060 |   0.000032  |    0.024375     |   2\n",
      "      18061 |   0.242748  |    0.207456     |   1\n",
      "      18062 |   0.000032  |    0.005778     |   2\n",
      "      18063 |   0.219744  |    0.091250     |   0\n",
      "      18064 |   0.210629  |    0.028188     |   0\n",
      "      18065 |   0.182688  |    0.073308     |   0\n",
      "      18066 |   0.187181  |    0.017192     |   0\n",
      "      18067 |   0.214187  |    0.189897     |   1\n",
      "      18068 |   0.209113  |    0.014983     |   0\n",
      "      18069 |   0.190713  |    0.071712     |   0\n",
      "      18070 |   0.210194  |    0.036336     |   0\n",
      "      18071 |   0.227794  |    0.205858     |   1\n",
      "      18072 |   0.052559  |    0.003605     |   2\n",
      "      18073 |   0.184535  |    0.190683     |   1\n",
      "      18074 |   0.184502  |    0.008133     |   0\n",
      "      18075 |   0.239542  |    0.186083     |   1\n",
      "      18076 |   0.054638  |    0.028517     |   2\n",
      "      18077 |   0.184944  |    0.089993     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 18078: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      18078 |   0.256631  |    0.138366     |   1\n",
      "      18079 |   0.051258  |    0.022235     |   2\n",
      "      18080 |   0.038447  |    0.087463     |   2\n",
      "      18081 |   0.205486  |    0.140998     |   1\n",
      "      18082 |   0.156523  |    0.046676     |   0\n",
      "      18083 |   0.190229  |    0.045101     |   0\n",
      "      18084 |   0.200866  |    0.052730     |   0\n",
      "      18085 |   0.040177  |    0.041556     |   2\n",
      "      18086 |   0.042572  |    0.081584     |   2\n",
      "      18087 |   0.211318  |    0.139525     |   1\n",
      "      18088 |   0.189658  |    0.039208     |   0\n",
      "      18089 |   0.028200  |    0.051876     |   2\n",
      "      18090 |   0.185221  |    0.150832     |   1\n",
      "      18091 |   0.229774  |    0.154971     |   1\n",
      "      18092 |   0.219369  |    0.146586     |   1\n",
      "      18093 |   0.038429  |    0.007647     |   2\n",
      "      18094 |   0.168232  |    0.215450     |   1\n",
      "      18095 |   0.205391  |    0.008305     |   0\n",
      "      18096 |   0.184632  |    0.078679     |   0\n",
      "      18097 |   0.049449  |    0.029484     |   2\n",
      "      18098 |   0.266475  |    0.143813     |   1\n",
      "      18099 |   0.059230  |    0.024162     |   2\n",
      "      18100 |   0.045655  |    0.079622     |   2\n",
      "      18101 |   0.215179  |    0.169609     |   1\n",
      "      18102 |   0.209975  |    0.019225     |   0\n",
      "      18103 |   0.204678  |    0.211789     |   1\n",
      "      18104 |   0.021260  |    0.003865     |   2\n",
      "      18105 |   0.147810  |    0.074861     |   0\n",
      "      18106 | \u001b[94m  0.000032\u001b[0m  |    0.014733     |   2\n",
      "      18107 |   0.005311  |    0.075694     |   2\n",
      "      18108 |   0.067131  |    0.017161     |   2\n",
      "      18109 |   0.185060  |    0.199430     |   1\n",
      "      18110 |   0.036151  |    0.043354     |   2\n",
      "      18111 |   0.188634  |    0.042434     |   0\n",
      "      18112 |   0.249393  |    0.173022     |   1\n",
      "      18113 |   0.191165  |    0.076570     |   0\n",
      "      18114 |   0.156023  |    0.021985     |   0\n",
      "      18115 |   0.059415  |    0.081475     |   2\n",
      "      18116 |   0.044178  |    0.042265     |   2\n",
      "      18117 |   0.189286  |    0.045110     |   0\n",
      "      18118 |   0.017144  |    0.042830     |   2\n",
      "      18119 |   0.178960  |    0.048209     |   0\n",
      "      18120 |   0.039325  |    0.046204     |   2\n",
      "      18121 |   0.165973  |    0.045223     |   0\n",
      "      18122 |   0.200485  |    0.202090     |   1\n",
      "      18123 |   0.151363  |    0.027191     |   0\n",
      "      18124 |   0.241240  |    0.202489     |   1\n",
      "      18125 |   0.028530  |    0.023206     |   2\n",
      "      18126 | \u001b[94m  0.000032\u001b[0m  |    0.074781     |   2\n",
      "      18127 |   0.195048  |    0.129840     |   1\n",
      "      18128 |   0.183113  |    0.046223     |   0\n",
      "      18129 |   0.184411  |    0.076702     |   0\n",
      "      18130 |   0.000032  |    0.028182     |   2\n",
      "      18131 |   0.233895  |    0.201071     |   1\n",
      "      18132 |   0.239072  |    0.007006     |   0\n",
      "      18133 |   0.000032  |    0.072749     |   2\n",
      "      18134 |   0.224679  |    0.154260     |   1\n",
      "      18135 |   0.164933  |    0.151838     |   1\n",
      "      18136 |   0.155532  |    0.218679     |   1\n",
      "      18137 |   0.000032  |    0.023594     |   2\n",
      "      18138 |   0.181166  |    0.205700     |   1\n",
      "      18139 |   0.000032  |    0.007415     |   2\n",
      "      18140 |   0.000032  |    0.081074     |   2\n",
      "      18141 |   0.186997  |    0.040853     |   0\n",
      "      18142 |   0.163631  |    0.175842     |   1\n",
      "      18143 |   0.051352  |    0.045242     |   2\n",
      "      18144 |   0.052671  |    0.056147     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 18145: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      18145 |   0.230767  |    0.143165     |   1\n",
      "      18146 |   0.133561  |    0.025300     |   0\n",
      "      18147 |   0.150021  |    0.078438     |   0\n",
      "      18148 |   0.180561  |    0.211823     |   1\n",
      "      18149 |   0.160690  |    0.008280     |   0\n",
      "      18150 |   0.208055  |    0.192632     |   1\n",
      "      18151 |   0.171264  |    0.020985     |   0\n",
      "      18152 |   0.172695  |    0.208815     |   1\n",
      "      18153 |   0.192597  |    0.147746     |   1\n",
      "      18154 |   0.050111  |    0.010067     |   2\n",
      "      18155 |   0.034256  |    0.050816     |   2\n",
      "      18156 |   0.041622  |    0.046915     |   2\n",
      "      18157 |   0.219330  |    0.085826     |   0\n",
      "      18158 |   0.209379  |    0.138486     |   1\n",
      "      18159 |   0.192490  |    0.047598     |   0\n",
      "      18160 |   0.164051  |    0.162359     |   1\n",
      "      18161 |   0.196215  |    0.039820     |   0\n",
      "      18162 |   0.041739  |    0.036202     |   2\n",
      "      18163 |   0.027848  |    0.040235     |   2\n",
      "      18164 |   0.138428  |    0.074261     |   0\n",
      "      18165 |   0.176470  |    0.209093     |   1\n",
      "      18166 |   0.173505  |    0.005055     |   0\n",
      "      18167 |   0.230368  |    0.139720     |   1\n",
      "      18168 |   0.194244  |    0.143473     |   1\n",
      "      18169 |   0.038535  |    0.040748     |   2\n",
      "      18170 |   0.200032  |    0.079103     |   0\n",
      "      18171 |   0.049998  |    0.032009     |   2\n",
      "      18172 |   0.056070  |    0.082333     |   2\n",
      "      18173 |   0.046047  |    0.007235     |   2\n",
      "      18174 |   0.192205  |    0.072880     |   0\n",
      "      18175 |   0.225679  |    0.058717     |   0\n",
      "      18176 |   0.209022  |    0.202929     |   1\n",
      "      18177 |   0.169015  |    0.168215     |   1\n",
      "      18178 |   0.163387  |    0.114661     |   1\n",
      "      18179 |   0.184949  |    0.164805     |   1\n",
      "      18180 |   0.226425  |    0.151025     |   1\n",
      "      18181 |   0.022244  |    0.048433     |   2\n",
      "      18182 |   0.000032  |    0.048142     |   2\n",
      "      18183 |   0.192509  |    0.156005     |   1\n",
      "      18184 |   0.005687  |    0.044829     |   2\n",
      "      18185 |   0.161759  |    0.041340     |   0\n",
      "      18186 |   0.184880  |    0.046108     |   0\n",
      "      18187 |   0.181120  |    0.044877     |   0\n",
      "      18188 |   0.066195  |    0.041762     |   2\n",
      "      18189 |   0.121810  |    0.042363     |   0\n",
      "      18190 |   0.035903  |    0.041464     |   2\n",
      "      18191 |   0.058865  |    0.053397     |   2\n",
      "      18192 |   0.194739  |    0.220814     |   1\n",
      "      18193 |   0.044258  |    0.079092     |   2\n",
      "      18194 |   0.190454  |    0.076590     |   0\n",
      "      18195 |   0.173713  |    0.205726     |   1\n",
      "      18196 |   0.220803  |    0.175839     |   1\n",
      "      18197 |   0.141562  |    0.159130     |   1\n",
      "      18198 |   0.185076  |    0.155137     |   1\n",
      "      18199 |   0.015232  |    0.054072     |   2\n",
      "      18200 |   0.208110  |    0.188784     |   1\n",
      "      18201 |   0.210593  |    0.008212     |   0\n",
      "      18202 |   0.173282  |    0.095352     |   0\n",
      "      18203 |   0.231569  |    0.221463     |   1\n",
      "      18204 |   0.163135  |    0.183608     |   1\n",
      "      18205 |   0.139821  |    0.172264     |   1\n",
      "      18206 |   0.263939  |    0.140733     |   1\n",
      "      18207 |   0.156811  |    0.162621     |   1\n",
      "      18208 |   0.192099  |    0.054242     |   0\n",
      "      18209 |   0.222956  |    0.196052     |   1\n",
      "      18210 |   0.036610  |    0.020979     |   2\n",
      "      18211 |   0.151729  |    0.051736     |   0\n",
      "      18212 |   0.167962  |    0.075014     |   0\n",
      "      18213 |   0.242149  |    0.010180     |   0\n",
      "      18214 |   0.028442  |    0.050199     |   2\n",
      "      18215 |   0.000032  |    0.045496     |   2\n",
      "      18216 |   0.000032  |    0.076261     |   2\n",
      "      18217 |   0.000032  |    0.026791     |   2\n",
      "      18218 |   0.000033  |    0.047569     |   2\n",
      "      18219 |   0.202083  |    0.208285     |   1\n",
      "      18220 |   0.178175  |    0.014314     |   0\n",
      "      18221 |   0.159014  |    0.046920     |   0\n",
      "      18222 |   0.179835  |    0.075736     |   0\n",
      "      18223 |   0.216128  |    0.041515     |   0\n",
      "      18224 |   0.168214  |    0.048863     |   0\n",
      "      18225 |   0.163841  |    0.187602     |   1\n",
      "      18226 |   0.157266  |    0.004849     |   0\n",
      "      18227 |   0.134431  |    0.196737     |   1\n",
      "      18228 |   0.000032  |    0.053385     |   2\n",
      "      18229 |   0.142195  |    0.202027     |   1\n",
      "      18230 |   0.000032  |    0.004620     |   2\n",
      "      18231 |   0.168810  |    0.092524     |   0\n",
      "      18232 |   0.208721  |    0.139932     |   1\n",
      "      18233 |   0.208258  |    0.136705     |   1\n",
      "      18234 |   0.202535  |    0.142054     |   1\n",
      "      18235 |   0.220875  |    0.026399     |   0\n",
      "      18236 |   0.050253  |    0.077886     |   2\n",
      "      18237 |   0.053173  |    0.036504     |   2\n",
      "      18238 |   0.193456  |    0.189955     |   1\n",
      "      18239 |   0.188254  |    0.139812     |   1\n",
      "      18240 |   0.167583  |    0.093028     |   0\n",
      "      18241 |   0.156378  |    0.173700     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 18242: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      18242 |   0.210678  |    0.014491     |   0\n",
      "      18243 |   0.186583  |    0.210694     |   1\n",
      "      18244 |   0.244203  |    0.145925     |   1\n",
      "      18245 |   0.047698  |    0.012945     |   2\n",
      "      18246 |   0.131700  |    0.062968     |   0\n",
      "      18247 |   0.235138  |    0.150996     |   1\n",
      "      18248 |   0.033466  |    0.037853     |   2\n",
      "      18249 |   0.301923  |    0.189421     |   1\n",
      "      18250 |   0.186709  |    0.015405     |   0\n",
      "      18251 |   0.212605  |    0.185700     |   1\n",
      "      18252 |   0.271863  |    0.043354     |   0\n",
      "      18253 |   0.188452  |    0.052721     |   0\n",
      "      18254 |   0.129419  |    0.143013     |   1\n",
      "      18255 |   0.194680  |    0.203869     |   1\n",
      "      18256 |   0.195338  |    0.023253     |   0\n",
      "      18257 |   0.218236  |    0.207830     |   1\n",
      "      18258 |   0.228517  |    0.006203     |   0\n",
      "      18259 |   0.166517  |    0.052443     |   0\n",
      "      18260 |   0.200202  |    0.057525     |   0\n",
      "      18261 |   0.212923  |    0.131264     |   1\n",
      "      18262 |   0.041364  |    0.075762     |   2\n",
      "      18263 |   0.188251  |    0.047672     |   0\n",
      "      18264 |   0.143973  |    0.030407     |   0\n",
      "      18265 |   0.154440  |    0.164272     |   1\n",
      "      18266 |   0.045597  |    0.051114     |   2\n",
      "      18267 |   0.204198  |    0.200591     |   1\n",
      "      18268 |   0.028210  |    0.011360     |   2\n",
      "      18269 |   0.212755  |    0.075437     |   0\n",
      "      18270 |   0.039664  |    0.029037     |   2\n",
      "      18271 |   0.051477  |    0.081946     |   2\n",
      "      18272 |   0.054194  |    0.010995     |   2\n",
      "      18273 |   0.048736  |    0.073416     |   2\n",
      "      18274 |   0.176493  |    0.028002     |   0\n",
      "      18275 |   0.024767  |    0.086877     |   2\n",
      "      18276 | \u001b[94m  0.000032\u001b[0m  |    0.079840     |   2\n",
      "      18277 |   0.219175  |    0.171409     |   1\n",
      "      18278 |   0.149484  |    0.047156     |   0\n",
      "      18279 |   0.212165  |    0.197356     |   1\n",
      "      18280 |   0.180600  |    0.144736     |   1\n",
      "      18281 |   0.196364  |    0.204244     |   1\n",
      "      18282 |   0.005807  |    0.051731     |   2\n",
      "      18283 |   0.152082  |    0.200191     |   1\n",
      "      18284 |   0.161574  |    0.162961     |   1\n",
      "      18285 |   0.066259  |    0.017988     |   2\n",
      "      18286 |   0.199465  |    0.214096     |   1\n",
      "      18287 |   0.224273  |    0.151403     |   1\n",
      "      18288 |   0.180540  |    0.034739     |   0\n",
      "      18289 |   0.190518  |    0.229117     |   1\n",
      "      18290 |   0.206524  |    0.025393     |   0\n",
      "      18291 |   0.309149  |    0.197149     |   1\n",
      "      18292 |   0.163128  |    0.140928     |   1\n",
      "      18293 |   0.182759  |    0.080586     |   0\n",
      "      18294 |   0.033811  |    0.027334     |   2\n",
      "      18295 |   0.058372  |    0.087096     |   2\n",
      "      18296 |   0.157530  |    0.032457     |   0\n",
      "      18297 |   0.169769  |    0.047728     |   0\n",
      "      18298 |   0.041682  |    0.046528     |   2\n",
      "      18299 |   0.017214  |    0.079721     |   2\n",
      "      18300 |   0.147185  |    0.173345     |   1\n",
      "      18301 |   0.194769  |    0.198318     |   1\n",
      "      18302 |   0.161073  |    0.026840     |   0\n",
      "      18303 |   0.205139  |    0.075171     |   0\n",
      "      18304 |   0.039209  |    0.028028     |   2\n",
      "      18305 |   0.198154  |    0.204429     |   1\n",
      "      18306 |   0.226394  |    0.013512     |   0\n",
      "      18307 |   0.197873  |    0.159850     |   1\n",
      "      18308 |   0.164315  |    0.177644     |   1\n",
      "      18309 |   0.242215  |    0.015859     |   0\n",
      "      18310 |   0.201320  |    0.076851     |   0\n",
      "      18311 |   0.027951  |    0.018993     |   2\n",
      "      18312 | \u001b[94m  0.000031\u001b[0m  |    0.083604     |   2\n",
      "      18313 |   0.203650  |    0.158344     |   1\n",
      "      18314 |   0.174841  |    0.145173     |   1\n",
      "      18315 |   0.190921  |    0.046127     |   0\n",
      "      18316 |   0.178899  |    0.078187     |   0\n",
      "      18317 |   0.178018  |    0.027171     |   0\n",
      "      18318 |   0.158247  |    0.237303     |   1\n",
      "      18319 |   0.199631  |    0.159846     |   1\n",
      "      18320 |   0.154139  |    0.026990     |   0\n",
      "      18321 | \u001b[94m  0.000031\u001b[0m  |    0.048494     |   2\n",
      "      18322 |   0.179537  |    0.072685     |   0\n",
      "      18323 |   0.167390  |    0.023487     |   0\n",
      "      18324 |   0.000031  |    0.074191     |   2\n",
      "      18325 |   0.260964  |    0.136478     |   1\n",
      "      18326 |   0.000031  |    0.070067     |   2\n",
      "      18327 |   0.172804  |    0.101034     |   1\n",
      "      18328 |   0.267403  |    0.182178     |   1\n",
      "      18329 |   0.231766  |    0.146245     |   1\n",
      "      18330 |   0.202326  |    0.015534     |   0\n",
      "      18331 |   0.192117  |    0.078112     |   0\n",
      "      18332 |   0.000031  |    0.027589     |   2\n",
      "      18333 |   0.234266  |    0.085898     |   0\n",
      "      18334 |   0.000031  |    0.017942     |   2\n",
      "      18335 |   0.049102  |    0.072930     |   2\n",
      "      18336 |   0.052049  |    0.029667     |   2\n",
      "      18337 |   0.241468  |    0.208653     |   1\n",
      "      18338 |   0.169360  |    0.091412     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 18339: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      18339 |   0.216636  |    0.139652     |   1\n",
      "      18340 |   0.195819  |    0.037656     |   0\n",
      "      18341 |   0.047456  |    0.080244     |   2\n",
      "      18342 |   0.200202  |    0.030066     |   0\n",
      "      18343 |   0.266986  |    0.203464     |   1\n",
      "      18344 |   0.192891  |    0.012705     |   0\n",
      "      18345 |   0.034086  |    0.079625     |   2\n",
      "      18346 |   0.152085  |    0.017476     |   0\n",
      "      18347 |   0.236402  |    0.078965     |   0\n",
      "      18348 |   0.040063  |    0.030970     |   2\n",
      "      18349 |   0.175820  |    0.081391     |   0\n",
      "      18350 |   0.218815  |    0.189728     |   1\n",
      "      18351 |   0.192432  |    0.017962     |   0\n",
      "      18352 |   0.206107  |    0.177001     |   1\n",
      "      18353 |   0.224975  |    0.040737     |   0\n",
      "      18354 |   0.218599  |    0.212944     |   1\n",
      "      18355 |   0.172952  |    0.007568     |   0\n",
      "      18356 |   0.043585  |    0.075772     |   2\n",
      "      18357 |   0.161548  |    0.028747     |   0\n",
      "      18358 |   0.235139  |    0.198673     |   1\n",
      "      18359 |   0.028082  |    0.004071     |   2\n",
      "      18360 |   0.039456  |    0.055142     |   2\n",
      "      18361 |   0.246491  |    0.135445     |   1\n",
      "      18362 |   0.193069  |    0.187763     |   1\n",
      "      18363 |   0.187815  |    0.144485     |   1\n",
      "      18364 |   0.212142  |    0.040216     |   0\n",
      "      18365 |   0.054320  |    0.092052     |   2\n",
      "      18366 |   0.246867  |    0.129422     |   1\n",
      "      18367 |   0.194797  |    0.026871     |   0\n",
      "      18368 |   0.056316  |    0.084925     |   2\n",
      "      18369 |   0.229644  |    0.186963     |   1\n",
      "      18370 |   0.172290  |    0.009541     |   0\n",
      "      18371 |   0.046214  |    0.085591     |   2\n",
      "      18372 |   0.023142  |    0.020892     |   2\n",
      "      18373 |   0.000031  |    0.063160     |   2\n",
      "      18374 |   0.137804  |    0.053121     |   0\n",
      "      18375 |   0.005916  |    0.030704     |   2\n",
      "      18376 |   0.184118  |    0.080571     |   0\n",
      "      18377 |   0.194380  |    0.146825     |   1\n",
      "      18378 |   0.165562  |    0.041872     |   0\n",
      "      18379 |   0.187270  |    0.043513     |   0\n",
      "      18380 |   0.206932  |    0.047611     |   0\n",
      "      18381 |   0.176540  |    0.059775     |   0\n",
      "      18382 |   0.066368  |    0.045310     |   2\n",
      "      18383 |   0.035455  |    0.029483     |   2\n",
      "      18384 |   0.176213  |    0.210120     |   1\n",
      "      18385 |   0.133895  |    0.149235     |   1\n",
      "      18386 |   0.059501  |    0.076730     |   2\n",
      "      18387 |   0.044528  |    0.026561     |   2\n",
      "      18388 |   0.206017  |    0.207951     |   1\n",
      "      18389 |   0.194543  |    0.007828     |   0\n",
      "      18390 |   0.141191  |    0.046076     |   0\n",
      "      18391 |   0.017590  |    0.044794     |   2\n",
      "      18392 |   0.202927  |    0.198211     |   1\n",
      "      18393 |   0.176758  |    0.005349     |   0\n",
      "      18394 |   0.196503  |    0.047519     |   0\n",
      "      18395 |   0.038501  |    0.043484     |   2\n",
      "      18396 |   0.195574  |    0.199928     |   1\n",
      "      18397 |   0.029281  |    0.016144     |   2\n",
      "      18398 |   0.182354  |    0.055172     |   0\n",
      "      18399 |   0.000031  |    0.074352     |   2\n",
      "      18400 |   0.000031  |    0.007772     |   2\n",
      "      18401 |   0.180604  |    0.074185     |   0\n",
      "      18402 |   0.209834  |    0.197973     |   1\n",
      "      18403 |   0.000031  |    0.018414     |   2\n",
      "      18404 |   0.179538  |    0.182014     |   1\n",
      "      18405 |   0.000031  |    0.011303     |   2\n",
      "      18406 |   0.000031  |    0.080323     |   2\n",
      "      18407 |   0.161621  |    0.211662     |   1\n",
      "      18408 |   0.000031  |    0.012558     |   2\n",
      "      18409 |   0.208345  |    0.084563     |   0\n",
      "      18410 |   0.047926  |    0.015268     |   2\n",
      "      18411 |   0.243704  |    0.214567     |   1\n",
      "      18412 |   0.194763  |    0.157070     |   1\n",
      "      18413 |   0.275335  |    0.138115     |   1\n",
      "      18414 |   0.261025  |    0.193473     |   1\n",
      "      18415 |   0.232470  |    0.026688     |   0\n",
      "      18416 |   0.199920  |    0.075726     |   0\n",
      "      18417 |   0.051651  |    0.052643     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 18418: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      18418 |   0.169469  |    0.139735     |   1\n",
      "      18419 |   0.167317  |    0.062584     |   0\n",
      "      18420 |   0.200462  |    0.173674     |   1\n",
      "      18421 |   0.186531  |    0.032755     |   0\n",
      "      18422 |   0.042080  |    0.079760     |   2\n",
      "      18423 |   0.246445  |    0.040001     |   0\n",
      "      18424 |   0.162565  |    0.044034     |   0\n",
      "      18425 |   0.187504  |    0.075786     |   0\n",
      "      18426 |   0.230460  |    0.038086     |   0\n",
      "      18427 |   0.236192  |    0.193957     |   1\n",
      "      18428 |   0.198477  |    0.004955     |   0\n",
      "      18429 |   0.034681  |    0.046563     |   2\n",
      "      18430 |   0.041423  |    0.046945     |   2\n",
      "      18431 |   0.045389  |    0.046878     |   2\n",
      "      18432 |   0.161623  |    0.041259     |   0\n",
      "      18433 |   0.217943  |    0.041040     |   0\n",
      "      18434 |   0.028027  |    0.043642     |   2\n",
      "      18435 |   0.041381  |    0.049334     |   2\n",
      "      18436 |   0.251262  |    0.045536     |   0\n",
      "      18437 |   0.180563  |    0.049085     |   0\n",
      "      18438 |   0.158992  |    0.198747     |   1\n",
      "      18439 |   0.207088  |    0.033544     |   0\n",
      "      18440 |   0.157135  |    0.189377     |   1\n",
      "      18441 |   0.128064  |    0.049595     |   0\n",
      "      18442 |   0.190452  |    0.204730     |   1\n",
      "      18443 |   0.199446  |    0.109198     |   1\n",
      "      18444 |   0.054306  |    0.052109     |   2\n",
      "      18445 |   0.169432  |    0.048042     |   0\n",
      "      18446 |   0.057576  |    0.025683     |   2\n",
      "      18447 |   0.048338  |    0.088746     |   2\n",
      "      18448 |   0.191614  |    0.202228     |   1\n",
      "      18449 |   0.181554  |    0.158019     |   1\n",
      "      18450 |   0.023720  |    0.007119     |   2\n",
      "      18451 |   0.168002  |    0.074871     |   0\n",
      "      18452 |   0.180773  |    0.049476     |   0\n",
      "      18453 |   0.000031  |    0.033849     |   2\n",
      "      18454 |   0.192223  |    0.193968     |   1\n",
      "      18455 |   0.006330  |    0.085687     |   2\n",
      "      18456 |   0.067853  |    0.019870     |   2\n",
      "      18457 |   0.187112  |    0.258134     |   1\n",
      "      18458 |   0.235108  |    0.141806     |   1\n",
      "      18459 |   0.180236  |    0.217640     |   1\n",
      "      18460 |   0.214940  |    0.143975     |   1\n",
      "      18461 |   0.185421  |    0.077482     |   0\n",
      "      18462 |   0.036062  |    0.040254     |   2\n",
      "      18463 |   0.210228  |    0.233743     |   1\n",
      "      18464 |   0.059953  |    0.027839     |   2\n",
      "      18465 |   0.223083  |    0.194349     |   1\n",
      "      18466 |   0.044624  |    0.007193     |   2\n",
      "      18467 |   0.017306  |    0.086145     |   2\n",
      "      18468 |   0.038356  |    0.040567     |   2\n",
      "      18469 |   0.028329  |    0.052650     |   2\n",
      "      18470 |   0.156021  |    0.044398     |   0\n",
      "      18471 |   0.180521  |    0.049340     |   0\n",
      "      18472 |   0.000031  |    0.059243     |   2\n",
      "      18473 |   0.212117  |    0.246183     |   1\n",
      "      18474 |   0.291098  |    0.075330     |   0\n",
      "      18475 |   0.174379  |    0.309978     |   1\n",
      "      18476 |   0.207613  |    0.268545     |   1\n",
      "      18477 |   0.190905  |    0.201997     |   1\n",
      "      18478 |   0.000031  |    0.072712     |   2\n",
      "      18479 |   0.176844  |    0.079084     |   0\n",
      "      18480 |   0.161959  |    0.075265     |   0\n",
      "      18481 |   0.174361  |    0.033498     |   0\n",
      "      18482 |   0.155142  |    0.198658     |   1\n",
      "      18483 |   0.193412  |    0.073082     |   0\n",
      "      18484 |   0.184092  |    0.286761     |   1\n",
      "      18485 |   0.000031  |    0.040210     |   2\n",
      "      18486 |   0.000031  |    0.085121     |   2\n",
      "      18487 |   0.180630  |    0.311473     |   1\n",
      "      18488 |   0.213733  |    0.149039     |   1\n",
      "      18489 |   0.217158  |    0.287894     |   1\n",
      "      18490 |   0.163970  |    0.042402     |   0\n",
      "      18491 |   0.154646  |    0.322402     |   1\n",
      "      18492 |   0.000031  |    0.075566     |   2\n",
      "      18493 |   0.201436  |    0.134312     |   0\n",
      "      18494 |   0.212407  |    0.288367     |   1\n",
      "      18495 |   0.000031  |    0.042150     |   2\n",
      "      18496 |   0.048139  |    0.084715     |   2\n",
      "      18497 |   0.176673  |    0.048288     |   0\n",
      "      18498 |   0.051300  |    0.009577     |   2\n",
      "      18499 |   0.217396  |    0.084112     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 18500: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      18500 |   0.048433  |    0.037610     |   2\n",
      "      18501 |   0.211892  |    0.281446     |   1\n",
      "      18502 |   0.176083  |    0.036956     |   0\n",
      "      18503 |   0.125726  |    0.295927     |   1\n",
      "      18504 |   0.137667  |    0.240914     |   1\n",
      "      18505 |   0.160216  |    0.026656     |   0\n",
      "      18506 |   0.187110  |    0.199250     |   1\n",
      "      18507 |   0.181639  |    0.147559     |   1\n",
      "      18508 |   0.242967  |    0.147816     |   1\n",
      "      18509 |   0.214528  |    0.048054     |   0\n",
      "      18510 |   0.181951  |    0.043513     |   0\n",
      "      18511 |   0.048424  |    0.047313     |   2\n",
      "      18512 |   0.205646  |    0.039898     |   0\n",
      "      18513 |   0.141279  |    0.046777     |   0\n",
      "      18514 |   0.204838  |    0.045882     |   0\n",
      "      18515 |   0.150364  |    0.044361     |   0\n",
      "      18516 |   0.179365  |    0.039632     |   0\n",
      "      18517 |   0.040390  |    0.048990     |   2\n",
      "      18518 |   0.188469  |    0.052544     |   0\n",
      "      18519 |   0.207106  |    0.163557     |   1\n",
      "      18520 |   0.174632  |    0.044007     |   0\n",
      "      18521 |   0.219170  |    0.045635     |   0\n",
      "      18522 |   0.170550  |    0.046250     |   0\n",
      "      18523 |   0.202906  |    0.182155     |   1\n",
      "      18524 |   0.042519  |    0.072790     |   2\n",
      "      18525 |   0.043888  |    0.021759     |   2\n",
      "      18526 |   0.030241  |    0.057690     |   2\n",
      "      18527 |   0.041576  |    0.054952     |   2\n",
      "      18528 |   0.240574  |    0.166344     |   1\n",
      "      18529 |   0.184174  |    0.137600     |   1\n",
      "      18530 |   0.163377  |    0.040799     |   0\n",
      "      18531 |   0.057018  |    0.042619     |   2\n",
      "      18532 |   0.227189  |    0.054133     |   0\n",
      "      18533 |   0.275744  |    0.136008     |   1\n",
      "      18534 |   0.272936  |    0.134740     |   1\n",
      "      18535 |   0.227716  |    0.144325     |   1\n",
      "      18536 |   0.186092  |    0.006096     |   0\n",
      "      18537 |   0.055921  |    0.075106     |   2\n",
      "      18538 |   0.171265  |    0.041238     |   0\n",
      "      18539 |   0.179672  |    0.044065     |   0\n",
      "      18540 |   0.216007  |    0.047008     |   0\n",
      "      18541 |   0.046715  |    0.041131     |   2\n",
      "      18542 |   0.210548  |    0.198785     |   1\n",
      "      18543 |   0.022671  |    0.005287     |   2\n",
      "      18544 |   0.180090  |    0.076569     |   0\n",
      "      18545 |   0.000031  |    0.039005     |   2\n",
      "      18546 |   0.185237  |    0.146071     |   1\n",
      "      18547 |   0.005781  |    0.023538     |   2\n",
      "      18548 |   0.069071  |    0.058038     |   2\n",
      "      18549 |   0.190245  |    0.053133     |   0\n",
      "      18550 |   0.180937  |    0.044914     |   0\n",
      "      18551 |   0.235655  |    0.026655     |   0\n",
      "      18552 |   0.179724  |    0.076300     |   0\n",
      "      18553 |   0.157576  |    0.040369     |   0\n",
      "      18554 |   0.035531  |    0.070062     |   2\n",
      "      18555 |   0.165543  |    0.205196     |   1\n",
      "      18556 |   0.244003  |    0.144735     |   1\n",
      "      18557 |   0.207888  |    0.162507     |   1\n",
      "      18558 |   0.061085  |    0.018588     |   2\n",
      "      18559 |   0.203496  |    0.230298     |   1\n",
      "      18560 |   0.145717  |    0.092012     |   1\n",
      "      18561 |   0.212543  |    0.193202     |   1\n",
      "      18562 |   0.171706  |    0.005523     |   0\n",
      "      18563 |   0.045016  |    0.056464     |   2\n",
      "      18564 |   0.228812  |    0.043423     |   0\n",
      "      18565 |   0.017529  |    0.080835     |   2\n",
      "      18566 |   0.185418  |    0.022633     |   0\n",
      "      18567 |   0.188464  |    0.198354     |   1\n",
      "      18568 |   0.035343  |    0.071487     |   2\n",
      "      18569 |   0.032259  |    0.028611     |   2\n",
      "      18570 |   0.157199  |    0.081596     |   0\n",
      "      18571 |   0.207464  |    0.024343     |   0\n",
      "      18572 |   0.000031  |    0.079961     |   2\n",
      "      18573 |   0.217743  |    0.020693     |   0\n",
      "      18574 |   0.205003  |    0.189838     |   1\n",
      "      18575 |   0.000031  |    0.042511     |   2\n",
      "      18576 |   0.000031  |    0.051896     |   2\n",
      "      18577 |   0.116007  |    0.160778     |   1\n",
      "      18578 |   0.000031  |    0.021381     |   2\n",
      "      18579 |   0.177839  |    0.075264     |   0\n",
      "      18580 |   0.169892  |    0.026350     |   0\n",
      "      18581 |   0.000031  |    0.076739     |   2\n",
      "      18582 |   0.000031  |    0.023133     |   2\n",
      "      18583 |   0.166987  |    0.057366     |   0\n",
      "      18584 |   0.188182  |    0.045230     |   0\n",
      "      18585 |   0.165163  |    0.023939     |   0\n",
      "      18586 |   0.155649  |    0.081162     |   0\n",
      "      18587 |   0.054791  |    0.014416     |   2\n",
      "      18588 |   0.176253  |    0.080663     |   0\n",
      "      18589 |   0.201624  |    0.007707     |   0\n",
      "      18590 |   0.195781  |    0.075532     |   0\n",
      "      18591 |   0.184365  |    0.045740     |   0\n",
      "      18592 |   0.196844  |    0.152632     |   1\n",
      "      18593 |   0.223385  |    0.150402     |   1\n",
      "      18594 |   0.053295  |    0.044825     |   2\n",
      "      18595 |   0.234658  |    0.077512     |   0\n",
      "      18596 |   0.165835  |    0.149949     |   1\n",
      "      18597 |   0.280764  |    0.142422     |   1\n",
      "      18598 |   0.198100  |    0.197164     |   1\n",
      "      18599 |   0.156489  |    0.014087     |   0\n",
      "      18600 |   0.205887  |    0.073999     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 18602: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      18601 |   0.201495  |    0.024683     |   0\n",
      "      18602 |   0.159863  |    0.045399     |   0\n",
      "      18603 |   0.164623  |    0.069185     |   0\n",
      "      18604 |   0.122072  |    0.024431     |   0\n",
      "      18605 |   0.049300  |    0.087665     |   2\n",
      "      18606 |   0.039232  |    0.005352     |   2\n",
      "      18607 |   0.205082  |    0.218952     |   1\n",
      "      18608 |   0.185558  |    0.149854     |   1\n",
      "      18609 |   0.216739  |    0.202951     |   1\n",
      "      18610 |   0.213761  |    0.148634     |   1\n",
      "      18611 |   0.196280  |    0.151635     |   1\n",
      "      18612 |   0.042286  |    0.050075     |   2\n",
      "      18613 |   0.218784  |    0.143990     |   1\n",
      "      18614 |   0.044870  |    0.074455     |   2\n",
      "      18615 |   0.200001  |    0.021027     |   0\n",
      "      18616 |   0.173039  |    0.190389     |   1\n",
      "      18617 |   0.027241  |    0.009275     |   2\n",
      "      18618 |   0.192035  |    0.087577     |   0\n",
      "      18619 |   0.178929  |    0.151015     |   1\n",
      "      18620 |   0.038667  |    0.077559     |   2\n",
      "      18621 |   0.188291  |    0.025335     |   0\n",
      "      18622 |   0.189818  |    0.056912     |   0\n",
      "      18623 |   0.218922  |    0.195250     |   1\n",
      "      18624 |   0.048000  |    0.004824     |   2\n",
      "      18625 |   0.192805  |    0.144284     |   1\n",
      "      18626 |   0.267994  |    0.045875     |   0\n",
      "      18627 |   0.230306  |    0.077175     |   0\n",
      "      18628 |   0.053548  |    0.030148     |   2\n",
      "      18629 |   0.151913  |    0.242197     |   1\n",
      "      18630 |   0.210183  |    0.140883     |   1\n",
      "      18631 |   0.178376  |    0.113401     |   1\n",
      "      18632 |   0.212598  |    0.076048     |   0\n",
      "      18633 |   0.047551  |    0.007017     |   2\n",
      "      18634 |   0.151151  |    0.078907     |   0\n",
      "      18635 |   0.177140  |    0.140900     |   1\n",
      "      18636 |   0.023744  |    0.056408     |   2\n",
      "      18637 |   0.121543  |    0.195986     |   1\n",
      "      18638 |   0.136854  |    0.006097     |   0\n",
      "      18639 |   0.200593  |    0.158709     |   1\n",
      "      18640 |   0.000032  |    0.039673     |   2\n",
      "      18641 |   0.005836  |    0.044525     |   2\n",
      "      18642 |   0.065549  |    0.049754     |   2\n",
      "      18643 |   0.175117  |    0.176167     |   1\n",
      "      18644 |   0.034756  |    0.043550     |   2\n",
      "      18645 |   0.200745  |    0.072853     |   0\n",
      "      18646 |   0.059800  |    0.031435     |   2\n",
      "      18647 |   0.193758  |    0.206673     |   1\n",
      "      18648 |   0.216482  |    0.146177     |   1\n",
      "      18649 |   0.121660  |    0.022061     |   0\n",
      "      18650 |   0.203205  |    0.198272     |   1\n",
      "      18651 |   0.042385  |    0.007623     |   2\n",
      "      18652 |   0.157691  |    0.081354     |   0\n",
      "      18653 |   0.171298  |    0.169094     |   1\n",
      "      18654 |   0.165867  |    0.192792     |   1\n",
      "      18655 |   0.017725  |    0.003904     |   2\n",
      "      18656 |   0.199021  |    0.084049     |   0\n",
      "      18657 |   0.038092  |    0.016587     |   2\n",
      "      18658 |   0.029624  |    0.074808     |   2\n",
      "      18659 |   0.306839  |    0.129768     |   1\n",
      "      18660 |   0.000031  |    0.069798     |   2\n",
      "      18661 |   0.000031  |    0.068811     |   2\n",
      "      18662 |   0.163985  |    0.280122     |   1\n",
      "      18663 |   0.173975  |    0.033165     |   0\n",
      "      18664 |   0.170011  |    0.070859     |   0\n",
      "      18665 |   0.000031  |    0.078601     |   2\n",
      "      18666 |   0.154539  |    0.069601     |   0\n",
      "      18667 |   0.216940  |    0.068758     |   0\n",
      "      18668 |   0.227667  |    0.069194     |   0\n",
      "      18669 |   0.232030  |    0.038015     |   0\n",
      "      18670 |   0.195260  |    0.316543     |   1\n",
      "      18671 |   0.000031  |    0.039258     |   2\n",
      "      18672 |   0.000031  |    0.071449     |   2\n",
      "      18673 |   0.000031  |    0.094955     |   2\n",
      "      18674 |   0.191188  |    0.072825     |   0\n",
      "      18675 |   0.047216  |    0.038712     |   2\n",
      "      18676 |   0.051056  |    0.066889     |   2\n",
      "      18677 |   0.214903  |    0.238298     |   1\n",
      "      18678 |   0.177345  |    0.280784     |   1\n",
      "      18679 |   0.164752  |    0.277037     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 18680: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      18680 |   0.242314  |    0.152866     |   1\n",
      "      18681 |   0.219629  |    0.220119     |   1\n",
      "      18682 |   0.164119  |    0.007680     |   0\n",
      "      18683 |   0.048685  |    0.048893     |   2\n",
      "      18684 |   0.036089  |    0.074185     |   2\n",
      "      18685 |   0.166470  |    0.073039     |   0\n",
      "      18686 |   0.256628  |    0.260259     |   1\n",
      "      18687 |   0.196698  |    0.056919     |   0\n",
      "      18688 |   0.129251  |    0.279353     |   1\n",
      "      18689 |   0.207429  |    0.069668     |   0\n",
      "      18690 |   0.214063  |    0.096736     |   0\n",
      "      18691 |   0.262162  |    0.229185     |   1\n",
      "      18692 |   0.040556  |    0.073226     |   2\n",
      "      18693 |   0.178092  |    0.031280     |   0\n",
      "      18694 |   0.166598  |    0.206218     |   1\n",
      "      18695 |   0.163652  |    0.004689     |   0\n",
      "      18696 |   0.043034  |    0.080582     |   2\n",
      "      18697 |   0.188076  |    0.192256     |   1\n",
      "      18698 |   0.256242  |    0.161446     |   1\n",
      "      18699 |   0.028394  |    0.045063     |   2\n",
      "      18700 |   0.176983  |    0.051974     |   0\n",
      "      18701 |   0.041903  |    0.028145     |   2\n",
      "      18702 |   0.172908  |    0.038990     |   0\n",
      "      18703 |   0.192087  |    0.051433     |   0\n",
      "      18704 |   0.215247  |    0.161245     |   1\n",
      "      18705 |   0.153776  |    0.046230     |   0\n",
      "      18706 |   0.147864  |    0.046958     |   0\n",
      "      18707 |   0.194307  |    0.048747     |   0\n",
      "      18708 |   0.048629  |    0.073297     |   2\n",
      "      18709 |   0.054759  |    0.020029     |   2\n",
      "      18710 |   0.171037  |    0.203982     |   1\n",
      "      18711 |   0.046227  |    0.027309     |   2\n",
      "      18712 |   0.249488  |    0.046342     |   0\n",
      "      18713 |   0.190924  |    0.043801     |   0\n",
      "      18714 |   0.021620  |    0.070854     |   2\n",
      "      18715 |   0.193203  |    0.014123     |   0\n",
      "      18716 |   0.000031  |    0.074503     |   2\n",
      "      18717 |   0.217250  |    0.165859     |   1\n",
      "      18718 |   0.190105  |    0.096714     |   1\n",
      "      18719 |   0.180486  |    0.080097     |   0\n",
      "      18720 |   0.005643  |    0.009441     |   2\n",
      "      18721 |   0.194170  |    0.212396     |   1\n",
      "      18722 |   0.184506  |    0.008443     |   0\n",
      "      18723 |   0.175760  |    0.073586     |   0\n",
      "      18724 |   0.066927  |    0.029430     |   2\n",
      "      18725 |   0.206690  |    0.211849     |   1\n",
      "      18726 |   0.190318  |    0.161217     |   1\n",
      "      18727 |   0.035960  |    0.010956     |   2\n",
      "      18728 |   0.173116  |    0.079809     |   0\n",
      "      18729 |   0.064354  |    0.021405     |   2\n",
      "      18730 |   0.184207  |    0.076511     |   0\n",
      "      18731 |   0.243750  |    0.143815     |   1\n",
      "      18732 |   0.187875  |    0.152330     |   1\n",
      "      18733 |   0.214775  |    0.164246     |   1\n",
      "      18734 |   0.223648  |    0.031520     |   0\n",
      "      18735 |   0.230001  |    0.185235     |   1\n",
      "      18736 |   0.041139  |    0.010005     |   2\n",
      "      18737 |   0.185358  |    0.203731     |   1\n",
      "      18738 |   0.016578  |    0.025934     |   2\n",
      "      18739 |   0.039475  |    0.047077     |   2\n",
      "      18740 |   0.158729  |    0.078662     |   0\n",
      "      18741 |   0.214696  |    0.162046     |   1\n",
      "      18742 |   0.029404  |    0.023816     |   2\n",
      "      18743 |   0.226085  |    0.191932     |   1\n",
      "      18744 |   0.204480  |    0.137217     |   1\n",
      "      18745 |   0.151282  |    0.043429     |   0\n",
      "      18746 |   0.172358  |    0.148497     |   1\n",
      "      18747 |   0.000031  |    0.015486     |   2\n",
      "      18748 |   0.195332  |    0.082644     |   0\n",
      "      18749 |   0.000031  |    0.041577     |   2\n",
      "      18750 |   0.250869  |    0.200500     |   1\n",
      "      18751 |   0.197186  |    0.012502     |   0\n",
      "      18752 |   0.137827  |    0.191648     |   1\n",
      "      18753 |   0.000031  |    0.037195     |   2\n",
      "      18754 |   0.176347  |    0.073884     |   0\n",
      "      18755 |   0.173350  |    0.021918     |   0\n",
      "      18756 |   0.168923  |    0.199265     |   1\n",
      "      18757 |   0.000031  |    0.010844     |   2\n",
      "      18758 |   0.000031  |    0.084937     |   2\n",
      "      18759 |   0.237430  |    0.015866     |   0\n",
      "      18760 |   0.153072  |    0.053277     |   0\n",
      "      18761 |   0.163192  |    0.214550     |   1\n",
      "      18762 |   0.172496  |    0.005358     |   0\n",
      "      18763 | \u001b[94m  0.000031\u001b[0m  |    0.075326     |   2\n",
      "      18764 |   0.185639  |    0.051926     |   0\n",
      "      18765 |   0.206406  |    0.194700     |   1\n",
      "      18766 |   0.176511  |    0.132578     |   1\n",
      "      18767 |   0.171629  |    0.030647     |   0\n",
      "      18768 |   0.180447  |    0.201133     |   1\n",
      "      18769 |   0.050440  |    0.005795     |   2\n",
      "      18770 |   0.203783  |    0.078157     |   0\n",
      "      18771 |   0.052047  |    0.012763     |   2\n",
      "      18772 |   0.159208  |    0.205352     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 18773: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      18773 |   0.206326  |    0.195541     |   1\n",
      "      18774 |   0.213764  |    0.009768     |   0\n",
      "      18775 |   0.048572  |    0.074493     |   2\n",
      "      18776 |   0.036809  |    0.041948     |   2\n",
      "      18777 |   0.041370  |    0.077226     |   2\n",
      "      18778 |   0.043340  |    0.023829     |   2\n",
      "      18779 |   0.028627  |    0.081224     |   2\n",
      "      18780 |   0.187472  |    0.141903     |   1\n",
      "      18781 |   0.039599  |    0.041097     |   2\n",
      "      18782 |   0.172261  |    0.209432     |   1\n",
      "      18783 |   0.049848  |    0.038415     |   2\n",
      "      18784 |   0.209839  |    0.118782     |   0\n",
      "      18785 |   0.054883  |    0.070141     |   2\n",
      "      18786 |   0.171787  |    0.323751     |   1\n",
      "      18787 |   0.046509  |    0.095306     |   2\n",
      "      18788 |   0.251011  |    0.323291     |   1\n",
      "      18789 |   0.172311  |    0.298093     |   1\n",
      "      18790 |   0.212048  |    0.118543     |   0\n",
      "      18791 |   0.177775  |    0.069990     |   0\n",
      "      18792 |   0.022045  |    0.073089     |   2\n",
      "      18793 |   0.247596  |    0.071709     |   0\n",
      "      18794 |   0.178582  |    0.371760     |   1\n",
      "      18795 |   0.201068  |    0.320173     |   1\n",
      "      18796 |   0.000031  |    0.119223     |   2\n",
      "      18797 |   0.155184  |    0.037685     |   0\n",
      "      18798 |   0.005791  |    0.118915     |   2\n",
      "      18799 |   0.216371  |    0.039507     |   0\n",
      "      18800 |   0.150415  |    0.371582     |   1\n",
      "      18801 |   0.065941  |    0.070543     |   2\n",
      "      18802 |   0.187606  |    0.375963     |   1\n",
      "      18803 |   0.032644  |    0.037227     |   2\n",
      "      18804 |   0.153078  |    0.071069     |   0\n",
      "      18805 |   0.163793  |    0.120075     |   0\n",
      "      18806 |   0.178247  |    0.071512     |   0\n",
      "      18807 |   0.213357  |    0.330299     |   1\n",
      "      18808 |   0.160116  |    0.128260     |   0\n",
      "      18809 |   0.185414  |    0.026221     |   0\n",
      "      18810 |   0.182665  |    0.320024     |   1\n",
      "      18811 |   0.059949  |    0.136216     |   2\n",
      "      18812 |   0.215279  |    0.022092     |   0\n",
      "      18813 |   0.148291  |    0.280576     |   1\n",
      "      18814 |   0.044814  |    0.098782     |   2\n",
      "      18815 |   0.016607  |    0.045389     |   2\n",
      "      18816 |   0.198104  |    0.414057     |   1\n",
      "      18817 |   0.191096  |    0.311315     |   1\n",
      "      18818 |   0.207420  |    0.091679     |   0\n",
      "      18819 |   0.163578  |    0.083677     |   0\n",
      "      18820 |   0.176695  |    0.220354     |   1\n",
      "      18821 |   0.163523  |    0.041591     |   0\n",
      "      18822 |   0.038816  |    0.073380     |   2\n",
      "      18823 |   0.233013  |    0.079820     |   0\n",
      "      18824 |   0.030914  |    0.127402     |   2\n",
      "      18825 | \u001b[94m  0.000030\u001b[0m  |    0.073950     |   2\n",
      "      18826 | \u001b[94m  0.000030\u001b[0m  |    0.076617     |   2\n",
      "      18827 |   0.187587  |    0.142717     |   0\n",
      "      18828 |   0.153856  |    0.039804     |   0\n",
      "      18829 |   0.218984  |    0.133583     |   0\n",
      "      18830 | \u001b[94m  0.000030\u001b[0m  |    0.022838     |   2\n",
      "      18831 |   0.000030  |    0.129844     |   2\n",
      "      18832 |   0.155751  |    0.037944     |   0\n",
      "      18833 |   0.194793  |    0.070691     |   0\n",
      "      18834 | \u001b[94m  0.000030\u001b[0m  |    0.114770     |   2\n",
      "      18835 |   0.172502  |    0.069524     |   0\n",
      "      18836 | \u001b[94m  0.000030\u001b[0m  |    0.097747     |   2\n",
      "      18837 |   0.195136  |    0.299772     |   1\n",
      "      18838 |   0.152153  |    0.322124     |   1\n",
      "      18839 |   0.189262  |    0.038382     |   0\n",
      "      18840 |   0.189871  |    0.300336     |   1\n",
      "      18841 |   0.054266  |    0.068944     |   2\n",
      "      18842 |   0.179492  |    0.300026     |   1\n",
      "      18843 |   0.209433  |    0.344552     |   1\n",
      "      18844 |   0.177656  |    0.015116     |   0\n",
      "      18845 |   0.153748  |    0.281056     |   1\n",
      "      18846 |   0.052572  |    0.165945     |   2\n",
      "      18847 |   0.158619  |    0.013587     |   0\n",
      "      18848 |   0.170940  |    0.065384     |   0\n",
      "      18849 |   0.192468  |    0.303832     |   1\n",
      "      18850 |   0.174570  |    0.073703     |   0\n",
      "      18851 |   0.159078  |    0.060693     |   0\n",
      "      18852 |   0.221858  |    0.376469     |   1\n",
      "      18853 |   0.163180  |    0.068669     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 18854: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      18854 |   0.157948  |    0.337672     |   1\n",
      "      18855 |   0.192400  |    0.021173     |   0\n",
      "      18856 |   0.217393  |    0.118455     |   0\n",
      "      18857 |   0.232174  |    0.286420     |   1\n",
      "      18858 |   0.208094  |    0.081291     |   0\n",
      "      18859 |   0.048736  |    0.067012     |   2\n",
      "      18860 |   0.196424  |    0.298949     |   1\n",
      "      18861 |   0.187906  |    0.382469     |   1\n",
      "      18862 |   0.039476  |    0.120792     |   2\n",
      "      18863 |   0.228741  |    0.291090     |   1\n",
      "      18864 |   0.245776  |    0.336264     |   1\n",
      "      18865 |   0.039991  |    0.092424     |   2\n",
      "      18866 |   0.043625  |    0.072214     |   2\n",
      "      18867 |   0.028597  |    0.144125     |   2\n",
      "      18868 |   0.180823  |    0.069380     |   0\n",
      "      18869 |   0.038716  |    0.090060     |   2\n",
      "      18870 |   0.051874  |    0.086637     |   2\n",
      "      18871 |   0.137766  |    0.380926     |   1\n",
      "      18872 |   0.139860  |    0.058331     |   0\n",
      "      18873 |   0.250430  |    0.358952     |   1\n",
      "      18874 |   0.151914  |    0.082673     |   0\n",
      "      18875 |   0.188843  |    0.304778     |   1\n",
      "      18876 |   0.055132  |    0.146418     |   2\n",
      "      18877 |   0.045253  |    0.037347     |   2\n",
      "      18878 |   0.196559  |    0.094744     |   0\n",
      "      18879 |   0.021914  |    0.141203     |   2\n",
      "      18880 |   0.178800  |    0.024601     |   0\n",
      "      18881 |   0.173898  |    0.074759     |   0\n",
      "      18882 |   0.189439  |    0.352780     |   1\n",
      "      18883 |   0.214176  |    0.073655     |   0\n",
      "      18884 |   0.000031  |    0.092473     |   2\n",
      "      18885 |   0.006190  |    0.095579     |   2\n",
      "      18886 |   0.198101  |    0.166736     |   0\n",
      "      18887 |   0.194402  |    0.020661     |   0\n",
      "      18888 |   0.182078  |    0.071495     |   0\n",
      "      18889 |   0.172085  |    0.091244     |   0\n",
      "      18890 |   0.068099  |    0.068748     |   2\n",
      "      18891 |   0.222219  |    0.399371     |   1\n",
      "      18892 |   0.034267  |    0.067716     |   2\n",
      "      18893 |   0.060414  |    0.145863     |   2\n",
      "      18894 |   0.182641  |    0.118817     |   0\n",
      "      18895 |   0.195786  |    0.343889     |   1\n",
      "      18896 |   0.225842  |    0.442521     |   1\n",
      "      18897 |   0.043827  |    0.092309     |   2\n",
      "      18898 |   0.017660  |    0.073647     |   2\n",
      "      18899 |   0.040638  |    0.101008     |   2\n",
      "      18900 |   0.209982  |    0.337511     |   1\n",
      "      18901 |   0.299245  |    0.470522     |   1\n",
      "      18902 |   0.180881  |    0.048122     |   0\n",
      "      18903 |   0.187610  |    0.142822     |   0\n",
      "      18904 |   0.173028  |    0.018482     |   0\n",
      "      18905 |   0.030917  |    0.141631     |   2\n",
      "      18906 |   0.227961  |    0.330994     |   1\n",
      "      18907 |   0.000030  |    0.075881     |   2\n",
      "      18908 |   0.155213  |    0.472819     |   1\n",
      "      18909 |   0.208343  |    0.271797     |   1\n",
      "      18910 |   0.198354  |    0.080398     |   0\n",
      "      18911 |   0.124792  |    0.330724     |   1\n",
      "      18912 |   0.160205  |    0.285610     |   1\n",
      "      18913 |   0.232414  |    0.138535     |   0\n",
      "      18914 |   0.000030  |    0.091025     |   2\n",
      "      18915 |   0.129297  |    0.362020     |   1\n",
      "      18916 |   0.175797  |    0.037503     |   0\n",
      "      18917 |   0.162375  |    0.113836     |   0\n",
      "      18918 |   0.000030  |    0.070723     |   2\n",
      "      18919 |   0.216823  |    0.287202     |   1\n",
      "      18920 |   0.177417  |    0.039732     |   0\n",
      "      18921 |   0.222743  |    0.328094     |   1\n",
      "      18922 |   0.000030  |    0.036530     |   2\n",
      "      18923 |   0.174088  |    0.129981     |   0\n",
      "      18924 |   0.000030  |    0.062022     |   2\n",
      "      18925 |   0.000030  |    0.065448     |   2\n",
      "      18926 |   0.047021  |    0.151770     |   2\n",
      "      18927 |   0.192133  |    0.249429     |   1\n",
      "      18928 |   0.207804  |    0.359461     |   1\n",
      "      18929 |   0.052192  |    0.067964     |   2\n",
      "      18930 |   0.196489  |    0.254924     |   1\n",
      "      18931 |   0.166581  |    0.400136     |   1\n",
      "      18932 |   0.217285  |    0.004633     |   0\n",
      "      18933 |   0.152398  |    0.327866     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 18934: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      18934 |   0.045564  |    0.069092     |   2\n",
      "      18935 |   0.036099  |    0.090477     |   2\n",
      "      18936 |   0.232678  |    0.271896     |   1\n",
      "      18937 |   0.184784  |    0.528226     |   1\n",
      "      18938 |   0.150100  |    0.010818     |   0\n",
      "      18939 |   0.184980  |    0.187166     |   0\n",
      "      18940 |   0.040536  |    0.143940     |   2\n",
      "      18941 |   0.226609  |    0.281658     |   1\n",
      "      18942 |   0.167821  |    0.131593     |   0\n",
      "      18943 |   0.045801  |    0.141029     |   2\n",
      "      18944 |   0.153607  |    0.084005     |   0\n",
      "      18945 |   0.144181  |    0.081308     |   0\n",
      "      18946 |   0.216906  |    0.093835     |   0\n",
      "      18947 |   0.027297  |    0.107183     |   2\n",
      "      18948 |   0.175524  |    0.149773     |   0\n",
      "      18949 |   0.160519  |    0.098256     |   0\n",
      "      18950 |   0.190620  |    0.399327     |   1\n",
      "      18951 |   0.037198  |    0.148265     |   2\n",
      "      18952 |   0.051202  |    0.155053     |   2\n",
      "      18953 |   0.146431  |    0.213657     |   0\n",
      "      18954 |   0.053664  |    0.132119     |   2\n",
      "      18955 |   0.220476  |    0.096090     |   0\n",
      "      18956 |   0.042902  |    0.094782     |   2\n",
      "      18957 |   0.127267  |    0.180259     |   0\n",
      "      18958 |   0.144384  |    0.360574     |   1\n",
      "      18959 |   0.215544  |    0.360400     |   1\n",
      "      18960 |   0.022534  |    0.066638     |   2\n",
      "      18961 |   0.194649  |    0.067248     |   0\n",
      "      18962 |   0.169306  |    0.094145     |   0\n",
      "      18963 | \u001b[94m  0.000030\u001b[0m  |    0.041741     |   2\n",
      "      18964 |   0.246852  |    0.348491     |   1\n",
      "      18965 |   0.156400  |    0.112233     |   0\n",
      "      18966 |   0.179709  |    0.299160     |   1\n",
      "      18967 |   0.161629  |    0.007276     |   0\n",
      "      18968 |   0.179743  |    0.146345     |   0\n",
      "      18969 |   0.173692  |    0.403152     |   1\n",
      "      18970 |   0.005448  |    0.103216     |   2\n",
      "      18971 |   0.154623  |    0.109278     |   0\n",
      "      18972 |   0.175304  |    0.060249     |   0\n",
      "      18973 |   0.066361  |    0.068627     |   2\n",
      "      18974 |   0.184268  |    0.302685     |   1\n",
      "      18975 |   0.231455  |    0.157727     |   1\n",
      "      18976 |   0.196818  |    0.042453     |   0\n",
      "      18977 |   0.165499  |    0.093703     |   0\n",
      "      18978 |   0.107338  |    0.268453     |   1\n",
      "      18979 |   0.033851  |    0.061623     |   2\n",
      "      18980 |   0.227855  |    0.264349     |   1\n",
      "      18981 |   0.138465  |    0.022876     |   0\n",
      "      18982 |   0.060125  |    0.065288     |   2\n",
      "      18983 |   0.042940  |    0.079870     |   2\n",
      "      18984 |   0.198563  |    0.073169     |   0\n",
      "      18985 |   0.183043  |    0.237921     |   1\n",
      "      18986 |   0.194075  |    0.072041     |   0\n",
      "      18987 |   0.225317  |    0.233729     |   1\n",
      "      18988 |   0.017106  |    0.018374     |   2\n",
      "      18989 |   0.147790  |    0.254650     |   1\n",
      "      18990 |   0.184148  |    0.096712     |   0\n",
      "      18991 |   0.149225  |    0.306561     |   1\n",
      "      18992 |   0.036336  |    0.068402     |   2\n",
      "      18993 |   0.153737  |    0.060988     |   0\n",
      "      18994 |   0.200121  |    0.127320     |   0\n",
      "      18995 |   0.239653  |    0.038336     |   0\n",
      "      18996 |   0.151668  |    0.089983     |   0\n",
      "      18997 |   0.320988  |    0.295361     |   1\n",
      "      18998 |   0.028349  |    0.092353     |   2\n",
      "      18999 |   0.000030  |    0.147352     |   2\n",
      "      19000 |   0.170825  |    0.378564     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 19000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 19000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      19001 |   0.182987  |    0.196265     |   1\n",
      "      19002 |   0.192567  |    0.048454     |   0\n",
      "      19003 |   0.047396  |    0.029533     |   2\n",
      "      19004 |   0.186737  |    0.071984     |   0\n",
      "      19005 |   0.164205  |    0.022880     |   0\n",
      "      19006 |   0.184027  |    0.075273     |   0\n",
      "      19007 |   0.036560  |    0.028327     |   2\n",
      "      19008 |   0.152296  |    0.042816     |   0\n",
      "      19009 |   0.235156  |    0.048228     |   0\n",
      "      19010 |   0.039700  |    0.036540     |   2\n",
      "      19011 |   0.209656  |    0.195039     |   1\n",
      "      19012 |   0.187744  |    0.006655     |   0\n",
      "      19013 |   0.168862  |    0.078105     |   0\n",
      "      19014 |   0.173374  |    0.021095     |   0\n",
      "      19015 |   0.043013  |    0.053220     |   2\n",
      "      19016 |   0.203702  |    0.139891     |   1\n",
      "      19017 |   0.151980  |    0.076336     |   0\n",
      "      19018 |   0.027628  |    0.022471     |   2\n",
      "      19019 |   0.040194  |    0.077154     |   2\n",
      "      19020 |   0.177589  |    0.023307     |   0\n",
      "      19021 |   0.057453  |    0.052072     |   2\n",
      "      19022 |   0.196814  |    0.175458     |   1\n",
      "      19023 |   0.211908  |    0.022469     |   0\n",
      "      19024 |   0.214240  |    0.215244     |   1\n",
      "      19025 |   0.253471  |    0.011438     |   0\n",
      "      19026 |   0.156703  |    0.078540     |   0\n",
      "      19027 |   0.224365  |    0.165610     |   1\n",
      "      19028 |   0.199127  |    0.047340     |   0\n",
      "      19029 |   0.237097  |    0.142033     |   1\n",
      "      19030 |   0.177764  |    0.212486     |   1\n",
      "      19031 |   0.175890  |    0.040215     |   0\n",
      "      19032 |   0.141178  |    0.050465     |   0\n",
      "      19033 |   0.057236  |    0.062429     |   2\n",
      "      19034 |   0.203209  |    0.186332     |   1\n",
      "      19035 |   0.043054  |    0.021856     |   2\n",
      "      19036 |   0.176547  |    0.053982     |   0\n",
      "      19037 |   0.020500  |    0.080257     |   2\n",
      "      19038 |   0.000030  |    0.008127     |   2\n",
      "      19039 |   0.005400  |    0.069323     |   2\n",
      "      19040 |   0.067053  |    0.031394     |   2\n",
      "      19041 |   0.034956  |    0.075933     |   2\n",
      "      19042 |   0.284822  |    0.040714     |   0\n",
      "      19043 |   0.057352  |    0.039915     |   2\n",
      "      19044 |   0.039108  |    0.049546     |   2\n",
      "      19045 |   0.217717  |    0.048106     |   0\n",
      "      19046 |   0.129837  |    0.171007     |   1\n",
      "      19047 |   0.217105  |    0.141765     |   1\n",
      "      19048 |   0.196156  |    0.025632     |   0\n",
      "      19049 |   0.016428  |    0.047844     |   2\n",
      "      19050 |   0.170333  |    0.044465     |   0\n",
      "      19051 |   0.037166  |    0.041890     |   2\n",
      "      19052 |   0.030050  |    0.078883     |   2\n",
      "      19053 |   0.000030  |    0.045069     |   2\n",
      "      19054 |   0.000030  |    0.054320     |   2\n",
      "      19055 |   0.213668  |    0.220632     |   1\n",
      "      19056 |   0.000030  |    0.016900     |   2\n",
      "      19057 |   0.200576  |    0.223768     |   1\n",
      "      19058 |   0.249105  |    0.157218     |   1\n",
      "      19059 |   0.147254  |    0.006146     |   0\n",
      "      19060 |   0.000030  |    0.036300     |   2\n",
      "      19061 |   0.194606  |    0.080274     |   0\n",
      "      19062 |   0.205029  |    0.153001     |   1\n",
      "      19063 |   0.240713  |    0.049861     |   0\n",
      "      19064 |   0.000030  |    0.045490     |   2\n",
      "      19065 |   0.000030  |    0.043165     |   2\n",
      "      19066 |   0.220563  |    0.222602     |   1\n",
      "      19067 |   0.218067  |    0.204854     |   1\n",
      "      19068 |   0.216461  |    0.026046     |   0\n",
      "      19069 |   0.206311  |    0.080085     |   0\n",
      "      19070 |   0.048052  |    0.044907     |   2\n",
      "      19071 |   0.175671  |    0.054926     |   0\n",
      "      19072 |   0.155757  |    0.146227     |   1\n",
      "      19073 |   0.052800  |    0.049956     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 19074: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      19074 |   0.045470  |    0.051446     |   2\n",
      "      19075 |   0.183664  |    0.039356     |   0\n",
      "      19076 |   0.173602  |    0.076223     |   0\n",
      "      19077 |   0.036221  |    0.048814     |   2\n",
      "      19078 |   0.175518  |    0.057591     |   0\n",
      "      19079 |   0.158414  |    0.204965     |   1\n",
      "      19080 |   0.040067  |    0.010957     |   2\n",
      "      19081 |   0.257123  |    0.209843     |   1\n",
      "      19082 |   0.209250  |    0.134784     |   1\n",
      "      19083 |   0.145653  |    0.144884     |   1\n",
      "      19084 |   0.166671  |    0.304604     |   1\n",
      "      19085 |   0.179472  |    0.027767     |   0\n",
      "      19086 |   0.171012  |    0.076829     |   0\n",
      "      19087 |   0.161673  |    0.259441     |   1\n",
      "      19088 |   0.196086  |    0.273025     |   1\n",
      "      19089 |   0.041733  |    0.035581     |   2\n",
      "      19090 |   0.129337  |    0.075003     |   0\n",
      "      19091 |   0.187602  |    0.189077     |   1\n",
      "      19092 |   0.027836  |    0.041601     |   2\n",
      "      19093 |   0.169525  |    0.239979     |   1\n",
      "      19094 |   0.189835  |    0.044221     |   0\n",
      "      19095 |   0.041198  |    0.073080     |   2\n",
      "      19096 |   0.184455  |    0.126235     |   0\n",
      "      19097 |   0.051035  |    0.025274     |   2\n",
      "      19098 |   0.161553  |    0.293297     |   1\n",
      "      19099 |   0.056458  |    0.079236     |   2\n",
      "      19100 |   0.212468  |    0.255922     |   1\n",
      "      19101 |   0.262965  |    0.157580     |   1\n",
      "      19102 |   0.188538  |    0.074888     |   0\n",
      "      19103 |   0.142773  |    0.195585     |   1\n",
      "      19104 |   0.206990  |    0.133271     |   1\n",
      "      19105 |   0.186942  |    0.055837     |   0\n",
      "      19106 |   0.220280  |    0.324108     |   1\n",
      "      19107 |   0.046020  |    0.056378     |   2\n",
      "      19108 |   0.185360  |    0.194400     |   1\n",
      "      19109 |   0.022417  |    0.026701     |   2\n",
      "      19110 | \u001b[94m  0.000030\u001b[0m  |    0.138656     |   2\n",
      "      19111 |   0.189848  |    0.150333     |   1\n",
      "      19112 |   0.005597  |    0.073504     |   2\n",
      "      19113 |   0.206015  |    0.073119     |   0\n",
      "      19114 |   0.067003  |    0.009921     |   2\n",
      "      19115 |   0.036345  |    0.048420     |   2\n",
      "      19116 |   0.058167  |    0.077634     |   2\n",
      "      19117 |   0.040067  |    0.074462     |   2\n",
      "      19118 |   0.015630  |    0.069665     |   2\n",
      "      19119 |   0.034843  |    0.072783     |   2\n",
      "      19120 |   0.028199  |    0.046243     |   2\n",
      "      19121 |   0.000030  |    0.053801     |   2\n",
      "      19122 |   0.208707  |    0.203407     |   1\n",
      "      19123 |   0.166458  |    0.043274     |   0\n",
      "      19124 |   0.207032  |    0.222238     |   1\n",
      "      19125 |   0.198549  |    0.219506     |   1\n",
      "      19126 |   0.135150  |    0.031185     |   0\n",
      "      19127 |   0.206580  |    0.263029     |   1\n",
      "      19128 | \u001b[94m  0.000030\u001b[0m  |    0.026943     |   2\n",
      "      19129 |   0.189058  |    0.119012     |   0\n",
      "      19130 | \u001b[94m  0.000030\u001b[0m  |    0.036764     |   2\n",
      "      19131 |   0.157403  |    0.069404     |   0\n",
      "      19132 |   0.140572  |    0.123305     |   0\n",
      "      19133 |   0.230813  |    0.272601     |   1\n",
      "      19134 |   0.000030  |    0.070972     |   2\n",
      "      19135 |   0.135618  |    0.069054     |   0\n",
      "      19136 |   0.190187  |    0.321346     |   1\n",
      "      19137 |   0.251507  |    0.075748     |   0\n",
      "      19138 |   0.181672  |    0.071898     |   0\n",
      "      19139 | \u001b[94m  0.000029\u001b[0m  |    0.071798     |   2\n",
      "      19140 | \u001b[94m  0.000029\u001b[0m  |    0.076730     |   2\n",
      "      19141 |   0.245562  |    0.287946     |   1\n",
      "      19142 |   0.047282  |    0.041905     |   2\n",
      "      19143 |   0.240239  |    0.077422     |   0\n",
      "      19144 |   0.189353  |    0.026621     |   0\n",
      "      19145 |   0.051771  |    0.076554     |   2\n",
      "      19146 |   0.197123  |    0.018049     |   0\n",
      "      19147 |   0.222042  |    0.195094     |   1\n",
      "      19148 |   0.257604  |    0.140107     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 19150: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      19149 |   0.175535  |    0.007197     |   0\n",
      "      19150 |   0.213679  |    0.079003     |   0\n",
      "      19151 |   0.177802  |    0.017009     |   0\n",
      "      19152 |   0.186672  |    0.076795     |   0\n",
      "      19153 |   0.184908  |    0.006470     |   0\n",
      "      19154 |   0.211309  |    0.139754     |   1\n",
      "      19155 |   0.166638  |    0.076963     |   0\n",
      "      19156 |   0.248694  |    0.023906     |   0\n",
      "      19157 |   0.048028  |    0.080032     |   2\n",
      "      19158 |   0.036871  |    0.022062     |   2\n",
      "      19159 |   0.149614  |    0.073394     |   0\n",
      "      19160 |   0.194144  |    0.183530     |   1\n",
      "      19161 |   0.040120  |    0.022056     |   2\n",
      "      19162 |   0.215400  |    0.197200     |   1\n",
      "      19163 |   0.195916  |    0.023587     |   0\n",
      "      19164 |   0.194291  |    0.046610     |   0\n",
      "      19165 |   0.042466  |    0.046898     |   2\n",
      "      19166 |   0.269583  |    0.079292     |   0\n",
      "      19167 |   0.027681  |    0.025938     |   2\n",
      "      19168 |   0.230749  |    0.202744     |   1\n",
      "      19169 |   0.172846  |    0.137245     |   1\n",
      "      19170 |   0.039691  |    0.010004     |   2\n",
      "      19171 |   0.219848  |    0.073792     |   0\n",
      "      19172 |   0.201794  |    0.142261     |   1\n",
      "      19173 |   0.175801  |    0.024663     |   0\n",
      "      19174 |   0.228746  |    0.188819     |   1\n",
      "      19175 |   0.187786  |    0.007547     |   0\n",
      "      19176 |   0.051402  |    0.094192     |   2\n",
      "      19177 |   0.171183  |    0.157598     |   1\n",
      "      19178 |   0.242619  |    0.138641     |   1\n",
      "      19179 |   0.058694  |    0.028302     |   2\n",
      "      19180 |   0.043802  |    0.073684     |   2\n",
      "      19181 |   0.233043  |    0.163652     |   1\n",
      "      19182 |   0.021147  |    0.007465     |   2\n",
      "      19183 |   0.000029  |    0.097247     |   2\n",
      "      19184 |   0.166221  |    0.016179     |   0\n",
      "      19185 |   0.167021  |    0.205075     |   1\n",
      "      19186 |   0.191463  |    0.009214     |   0\n",
      "      19187 |   0.184782  |    0.077411     |   0\n",
      "      19188 |   0.223468  |    0.150305     |   1\n",
      "      19189 |   0.290938  |    0.144265     |   1\n",
      "      19190 |   0.005783  |    0.046280     |   2\n",
      "      19191 |   0.163954  |    0.042447     |   0\n",
      "      19192 |   0.199208  |    0.044544     |   0\n",
      "      19193 |   0.205396  |    0.083170     |   0\n",
      "      19194 |   0.184899  |    0.191756     |   1\n",
      "      19195 |   0.182301  |    0.023843     |   0\n",
      "      19196 |   0.194195  |    0.259898     |   1\n",
      "      19197 |   0.065908  |    0.008136     |   2\n",
      "      19198 |   0.231100  |    0.206818     |   1\n",
      "      19199 |   0.233904  |    0.144911     |   1\n",
      "      19200 |   0.035723  |    0.123980     |   2\n",
      "      19201 |   0.133808  |    0.041797     |   0\n",
      "      19202 |   0.189989  |    0.074504     |   0\n",
      "      19203 |   0.187408  |    0.272680     |   1\n",
      "      19204 |   0.216674  |    0.037117     |   0\n",
      "      19205 |   0.055749  |    0.068811     |   2\n",
      "      19206 |   0.170373  |    0.069978     |   0\n",
      "      19207 |   0.201491  |    0.272518     |   1\n",
      "      19208 |   0.040776  |    0.039056     |   2\n",
      "      19209 |   0.229734  |    0.271692     |   1\n",
      "      19210 |   0.017233  |    0.038916     |   2\n",
      "      19211 |   0.202837  |    0.120597     |   0\n",
      "      19212 |   0.037376  |    0.082441     |   2\n",
      "      19213 |   0.029784  |    0.071565     |   2\n",
      "      19214 | \u001b[94m  0.000029\u001b[0m  |    0.036999     |   2\n",
      "      19215 |   0.222346  |    0.079286     |   0\n",
      "      19216 | \u001b[94m  0.000029\u001b[0m  |    0.026373     |   2\n",
      "      19217 |   0.000029  |    0.068901     |   2\n",
      "      19218 |   0.160877  |    0.072973     |   0\n",
      "      19219 |   0.246048  |    0.287920     |   1\n",
      "      19220 |   0.000029  |    0.074888     |   2\n",
      "      19221 |   0.202774  |    0.069289     |   0\n",
      "      19222 | \u001b[94m  0.000029\u001b[0m  |    0.069573     |   2\n",
      "      19223 |   0.177506  |    0.069580     |   0\n",
      "      19224 |   0.160291  |    0.071405     |   0\n",
      "      19225 |   0.242075  |    0.226212     |   1\n",
      "      19226 | \u001b[94m  0.000029\u001b[0m  |    0.072366     |   2\n",
      "      19227 |   0.280065  |    0.278263     |   1\n",
      "      19228 |   0.047306  |    0.037094     |   2\n",
      "      19229 |   0.050863  |    0.070061     |   2\n",
      "      19230 |   0.230511  |    0.269867     |   1\n",
      "      19231 |   0.159690  |    0.224229     |   1\n",
      "      19232 |   0.169122  |    0.071559     |   0\n",
      "      19233 |   0.157938  |    0.069048     |   0\n",
      "      19234 |   0.256347  |    0.272992     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 19235: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      19235 |   0.153696  |    0.012318     |   0\n",
      "      19236 |   0.301534  |    0.250864     |   1\n",
      "      19237 |   0.202210  |    0.074382     |   0\n",
      "      19238 |   0.170607  |    0.073706     |   0\n",
      "      19239 |   0.224137  |    0.030712     |   0\n",
      "      19240 |   0.219775  |    0.206187     |   1\n",
      "      19241 |   0.043703  |    0.006289     |   2\n",
      "      19242 |   0.200346  |    0.100406     |   0\n",
      "      19243 |   0.234297  |    0.163360     |   1\n",
      "      19244 |   0.032148  |    0.089473     |   2\n",
      "      19245 |   0.164167  |    0.010062     |   0\n",
      "      19246 |   0.203275  |    0.089535     |   0\n",
      "      19247 |   0.039950  |    0.040923     |   2\n",
      "      19248 |   0.215018  |    0.192127     |   1\n",
      "      19249 |   0.165463  |    0.003648     |   0\n",
      "      19250 |   0.174982  |    0.098486     |   0\n",
      "      19251 |   0.042983  |    0.047704     |   2\n",
      "      19252 |   0.027082  |    0.044520     |   2\n",
      "      19253 |   0.202001  |    0.049713     |   0\n",
      "      19254 |   0.039177  |    0.054312     |   2\n",
      "      19255 |   0.053534  |    0.048715     |   2\n",
      "      19256 |   0.175674  |    0.085887     |   0\n",
      "      19257 |   0.060479  |    0.037009     |   2\n",
      "      19258 |   0.190454  |    0.192860     |   1\n",
      "      19259 |   0.221306  |    0.045604     |   0\n",
      "      19260 |   0.176497  |    0.058253     |   0\n",
      "      19261 |   0.219865  |    0.188445     |   1\n",
      "      19262 |   0.042850  |    0.022032     |   2\n",
      "      19263 |   0.023744  |    0.091886     |   2\n",
      "      19264 |   0.221951  |    0.161746     |   1\n",
      "      19265 |   0.140966  |    0.041617     |   0\n",
      "      19266 |   0.157116  |    0.043867     |   0\n",
      "      19267 | \u001b[94m  0.000029\u001b[0m  |    0.049064     |   2\n",
      "      19268 |   0.144140  |    0.144518     |   1\n",
      "      19269 |   0.194582  |    0.084640     |   0\n",
      "      19270 |   0.191518  |    0.157516     |   1\n",
      "      19271 |   0.204703  |    0.142774     |   1\n",
      "      19272 |   0.191926  |    0.045187     |   0\n",
      "      19273 |   0.005708  |    0.044555     |   2\n",
      "      19274 |   0.068076  |    0.037035     |   2\n",
      "      19275 |   0.190661  |    0.078662     |   0\n",
      "      19276 |   0.201578  |    0.166999     |   1\n",
      "      19277 |   0.206915  |    0.047717     |   0\n",
      "      19278 |   0.037804  |    0.043031     |   2\n",
      "      19279 |   0.152414  |    0.199559     |   1\n",
      "      19280 |   0.220582  |    0.141115     |   1\n",
      "      19281 |   0.189727  |    0.013487     |   0\n",
      "      19282 |   0.146345  |    0.208653     |   1\n",
      "      19283 |   0.224572  |    0.053419     |   0\n",
      "      19284 |   0.173408  |    0.195738     |   1\n",
      "      19285 |   0.057997  |    0.007314     |   2\n",
      "      19286 |   0.152725  |    0.044219     |   0\n",
      "      19287 |   0.162639  |    0.043426     |   0\n",
      "      19288 |   0.232460  |    0.166626     |   1\n",
      "      19289 |   0.043718  |    0.053889     |   2\n",
      "      19290 |   0.187031  |    0.232542     |   1\n",
      "      19291 |   0.189548  |    0.085571     |   0\n",
      "      19292 |   0.017528  |    0.043247     |   2\n",
      "      19293 |   0.235350  |    0.073921     |   0\n",
      "      19294 |   0.191041  |    0.283859     |   1\n",
      "      19295 |   0.169569  |    0.230685     |   1\n",
      "      19296 |   0.038763  |    0.040594     |   2\n",
      "      19297 |   0.229083  |    0.272527     |   1\n",
      "      19298 |   0.165656  |    0.039663     |   0\n",
      "      19299 |   0.028461  |    0.071524     |   2\n",
      "      19300 |   0.244654  |    0.270366     |   1\n",
      "      19301 |   0.163174  |    0.074780     |   0\n",
      "      19302 |   0.132712  |    0.304841     |   1\n",
      "      19303 |   0.206046  |    0.221524     |   1\n",
      "      19304 |   0.000029  |    0.069528     |   2\n",
      "      19305 |   0.000029  |    0.117413     |   2\n",
      "      19306 |   0.000029  |    0.071114     |   2\n",
      "      19307 |   0.179107  |    0.101029     |   0\n",
      "      19308 |   0.204777  |    0.343077     |   1\n",
      "      19309 |   0.156328  |    0.333990     |   1\n",
      "      19310 |   0.204499  |    0.039858     |   0\n",
      "      19311 |   0.135742  |    0.339674     |   1\n",
      "      19312 |   0.000029  |    0.065910     |   2\n",
      "      19313 |   0.167431  |    0.069918     |   0\n",
      "      19314 |   0.000029  |    0.069486     |   2\n",
      "      19315 |   0.168276  |    0.093549     |   0\n",
      "      19316 |   0.197162  |    0.285988     |   1\n",
      "      19317 |   0.178349  |    0.241248     |   1\n",
      "      19318 |   0.162005  |    0.070084     |   0\n",
      "      19319 |   0.000029  |    0.071706     |   2\n",
      "      19320 |   0.175422  |    0.043108     |   0\n",
      "      19321 |   0.179261  |    0.237809     |   1\n",
      "      19322 |   0.144748  |    0.313220     |   1\n",
      "      19323 |   0.144998  |    0.040218     |   0\n",
      "      19324 |   0.166711  |    0.077768     |   0\n",
      "      19325 |   0.049886  |    0.038372     |   2\n",
      "      19326 |   0.050311  |    0.068985     |   2\n",
      "      19327 |   0.193682  |    0.070947     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 19328: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      19328 |   0.207389  |    0.295168     |   1\n",
      "      19329 |   0.192044  |    0.245475     |   1\n",
      "      19330 |   0.049121  |    0.025629     |   2\n",
      "      19331 |   0.037298  |    0.068493     |   2\n",
      "      19332 |   0.290833  |    0.069100     |   0\n",
      "      19333 |   0.038614  |    0.129946     |   2\n",
      "      19334 |   0.174500  |    0.039694     |   0\n",
      "      19335 |   0.042822  |    0.069339     |   2\n",
      "      19336 |   0.159803  |    0.078962     |   0\n",
      "      19337 |   0.188435  |    0.196786     |   1\n",
      "      19338 |   0.188679  |    0.269638     |   1\n",
      "      19339 |   0.166058  |    0.074260     |   0\n",
      "      19340 |   0.179911  |    0.063696     |   0\n",
      "      19341 |   0.027177  |    0.070605     |   2\n",
      "      19342 |   0.214551  |    0.270476     |   1\n",
      "      19343 |   0.220907  |    0.023721     |   0\n",
      "      19344 |   0.190198  |    0.099643     |   0\n",
      "      19345 |   0.161066  |    0.075019     |   0\n",
      "      19346 |   0.308602  |    0.278217     |   1\n",
      "      19347 |   0.039801  |    0.025005     |   2\n",
      "      19348 |   0.054390  |    0.077147     |   2\n",
      "      19349 |   0.138786  |    0.306378     |   1\n",
      "      19350 |   0.056718  |    0.088427     |   2\n",
      "      19351 |   0.259266  |    0.252579     |   1\n",
      "      19352 |   0.045180  |    0.036533     |   2\n",
      "      19353 |   0.023377  |    0.074038     |   2\n",
      "      19354 |   0.279485  |    0.307414     |   1\n",
      "      19355 |   0.165284  |    0.046186     |   0\n",
      "      19356 |   0.194587  |    0.275328     |   1\n",
      "      19357 |   0.194915  |    0.126050     |   0\n",
      "      19358 |   0.000029  |    0.064313     |   2\n",
      "      19359 |   0.005723  |    0.095402     |   2\n",
      "      19360 |   0.191773  |    0.094064     |   0\n",
      "      19361 |   0.227758  |    0.358827     |   1\n",
      "      19362 |   0.163447  |    0.155950     |   0\n",
      "      19363 |   0.065877  |    0.041796     |   2\n",
      "      19364 |   0.035914  |    0.118324     |   2\n",
      "      19365 |   0.159748  |    0.086186     |   0\n",
      "      19366 |   0.176707  |    0.274061     |   1\n",
      "      19367 |   0.059322  |    0.070915     |   2\n",
      "      19368 |   0.256196  |    0.358732     |   1\n",
      "      19369 |   0.179046  |    0.220233     |   1\n",
      "      19370 |   0.137489  |    0.036716     |   0\n",
      "      19371 |   0.045372  |    0.117220     |   2\n",
      "      19372 |   0.129198  |    0.322206     |   1\n",
      "      19373 |   0.189213  |    0.355879     |   1\n",
      "      19374 |   0.017213  |    0.074932     |   2\n",
      "      19375 |   0.148255  |    0.288737     |   1\n",
      "      19376 |   0.182617  |    0.155255     |   0\n",
      "      19377 |   0.186108  |    0.037965     |   0\n",
      "      19378 |   0.038144  |    0.066495     |   2\n",
      "      19379 |   0.196156  |    0.279561     |   1\n",
      "      19380 |   0.161297  |    0.293447     |   1\n",
      "      19381 |   0.182353  |    0.036760     |   0\n",
      "      19382 |   0.174290  |    0.427673     |   1\n",
      "      19383 |   0.143455  |    0.041082     |   0\n",
      "      19384 |   0.228899  |    0.290252     |   1\n",
      "      19385 |   0.197923  |    0.367697     |   1\n",
      "      19386 |   0.181617  |    0.271281     |   1\n",
      "      19387 |   0.184225  |    0.065111     |   0\n",
      "      19388 |   0.153803  |    0.123181     |   0\n",
      "      19389 |   0.028387  |    0.019245     |   2\n",
      "      19390 |   0.172052  |    0.121380     |   0\n",
      "      19391 |   0.204792  |    0.327350     |   1\n",
      "      19392 | \u001b[94m  0.000028\u001b[0m  |    0.123888     |   2\n",
      "      19393 |   0.207164  |    0.074059     |   0\n",
      "      19394 | \u001b[94m  0.000028\u001b[0m  |    0.148352     |   2\n",
      "      19395 |   0.154124  |    0.037017     |   0\n",
      "      19396 |   0.000028  |    0.111302     |   2\n",
      "      19397 |   0.207519  |    0.284522     |   1\n",
      "      19398 |   0.194812  |    0.039141     |   0\n",
      "      19399 |   0.000028  |    0.094573     |   2\n",
      "      19400 |   0.160949  |    0.088846     |   0\n",
      "      19401 | \u001b[94m  0.000028\u001b[0m  |    0.073092     |   2\n",
      "      19402 |   0.000028  |    0.038520     |   2\n",
      "      19403 |   0.051685  |    0.136362     |   2\n",
      "      19404 |   0.182305  |    0.359543     |   1\n",
      "      19405 |   0.191944  |    0.080039     |   0\n",
      "      19406 |   0.170974  |    0.146406     |   0\n",
      "      19407 |   0.171106  |    0.308923     |   1\n",
      "      19408 |   0.158793  |    0.013155     |   0\n",
      "      19409 |   0.051008  |    0.134596     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 19410: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      19410 |   0.217118  |    0.039976     |   0\n",
      "      19411 |   0.187837  |    0.311274     |   1\n",
      "      19412 |   0.052104  |    0.038908     |   2\n",
      "      19413 |   0.204733  |    0.287166     |   1\n",
      "      19414 |   0.175693  |    0.081510     |   0\n",
      "      19415 |   0.177091  |    0.343099     |   1\n",
      "      19416 |   0.213890  |    0.284592     |   1\n",
      "      19417 |   0.041144  |    0.084301     |   2\n",
      "      19418 |   0.039742  |    0.145665     |   2\n",
      "      19419 |   0.042515  |    0.039210     |   2\n",
      "      19420 |   0.027998  |    0.072559     |   2\n",
      "      19421 |   0.174745  |    0.305364     |   1\n",
      "      19422 |   0.039204  |    0.088092     |   2\n",
      "      19423 |   0.171520  |    0.114410     |   0\n",
      "      19424 |   0.196344  |    0.106491     |   0\n",
      "      19425 |   0.224612  |    0.082264     |   0\n",
      "      19426 |   0.051030  |    0.088009     |   2\n",
      "      19427 |   0.187720  |    0.115778     |   0\n",
      "      19428 |   0.203949  |    0.121502     |   0\n",
      "      19429 |   0.056585  |    0.091415     |   2\n",
      "      19430 |   0.169025  |    0.149286     |   0\n",
      "      19431 |   0.047443  |    0.144817     |   2\n",
      "      19432 |   0.225548  |    0.621306     |   1\n",
      "      19433 |   0.165181  |    0.190323     |   0\n",
      "      19434 |   0.168196  |    0.482485     |   1\n",
      "      19435 |   0.178620  |    0.133969     |   0\n",
      "      19436 |   0.125845  |    0.142894     |   0\n",
      "      19437 |   0.213881  |    0.339280     |   1\n",
      "      19438 |   0.024837  |    0.149773     |   2\n",
      "      19439 |   0.000029  |    0.055939     |   2\n",
      "      19440 |   0.172657  |    0.095950     |   0\n",
      "      19441 |   0.217000  |    0.091582     |   0\n",
      "      19442 |   0.153187  |    0.074965     |   0\n",
      "      19443 |   0.208763  |    0.345942     |   1\n",
      "      19444 |   0.193824  |    0.345521     |   1\n",
      "      19445 |   0.187991  |    0.079101     |   0\n",
      "      19446 |   0.139997  |    0.037601     |   0\n",
      "      19447 |   0.005058  |    0.150871     |   2\n",
      "      19448 |   0.067103  |    0.063663     |   2\n",
      "      19449 |   0.159079  |    0.092716     |   0\n",
      "      19450 |   0.154828  |    0.351627     |   1\n",
      "      19451 |   0.037247  |    0.122799     |   2\n",
      "      19452 |   0.206422  |    0.080246     |   0\n",
      "      19453 |   0.060396  |    0.138530     |   2\n",
      "      19454 |   0.045611  |    0.010444     |   2\n",
      "      19455 |   0.015544  |    0.170179     |   2\n",
      "      19456 |   0.203596  |    0.401459     |   1\n",
      "      19457 |   0.038714  |    0.039773     |   2\n",
      "      19458 |   0.164831  |    0.117884     |   0\n",
      "      19459 |   0.030651  |    0.103768     |   2\n",
      "      19460 |   0.203988  |    0.091456     |   0\n",
      "      19461 |   0.205905  |    0.125796     |   0\n",
      "      19462 |   0.178326  |    0.061194     |   0\n",
      "      19463 |   0.184409  |    0.116911     |   0\n",
      "      19464 |   0.164063  |    0.475452     |   1\n",
      "      19465 |   0.206062  |    0.087211     |   0\n",
      "      19466 |   0.160484  |    0.077401     |   0\n",
      "      19467 |   0.000029  |    0.142286     |   2\n",
      "      19468 |   0.000029  |    0.129471     |   2\n",
      "      19469 |   0.205057  |    0.344243     |   1\n",
      "      19470 |   0.000029  |    0.020302     |   2\n",
      "      19471 |   0.217304  |    0.358796     |   1\n",
      "      19472 |   0.000029  |    0.141788     |   2\n",
      "      19473 |   0.000029  |    0.037334     |   2\n",
      "      19474 |   0.176517  |    0.115422     |   0\n",
      "      19475 |   0.000029  |    0.146725     |   2\n",
      "      19476 |   0.191718  |    0.285262     |   1\n",
      "      19477 |   0.185083  |    0.314844     |   1\n",
      "      19478 |   0.198783  |    0.094890     |   0\n",
      "      19479 |   0.166253  |    0.059533     |   0\n",
      "      19480 |   0.203771  |    0.266358     |   1\n",
      "      19481 |   0.048915  |    0.014198     |   2\n",
      "      19482 |   0.186423  |    0.088672     |   0\n",
      "      19483 |   0.199406  |    0.237601     |   1\n",
      "      19484 |   0.160547  |    0.215758     |   1\n",
      "      19485 |   0.184429  |    0.074434     |   0\n",
      "      19486 |   0.051753  |    0.091897     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 19487: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      19487 |   0.205850  |    0.046205     |   0\n",
      "      19488 |   0.188296  |    0.223723     |   1\n",
      "      19489 |   0.234057  |    0.231687     |   1\n",
      "      19490 |   0.048951  |    0.004020     |   2\n",
      "      19491 |   0.242086  |    0.184269     |   1\n",
      "      19492 |   0.168954  |    0.186482     |   1\n",
      "      19493 |   0.231165  |    0.152454     |   1\n",
      "      19494 |   0.205608  |    0.029509     |   0\n",
      "      19495 |   0.147162  |    0.257807     |   1\n",
      "      19496 |   0.137249  |    0.008257     |   0\n",
      "      19497 |   0.035503  |    0.102452     |   2\n",
      "      19498 |   0.039453  |    0.051986     |   2\n",
      "      19499 |   0.044140  |    0.036264     |   2\n",
      "      19500 |   0.218348  |    0.046306     |   0\n",
      "      19501 |   0.045945  |    0.080147     |   2\n",
      "      19502 |   0.203752  |    0.021895     |   0\n",
      "      19503 |   0.034394  |    0.080445     |   2\n",
      "      19504 |   0.246751  |    0.013121     |   0\n",
      "      19505 |   0.154781  |    0.086704     |   0\n",
      "      19506 |   0.038818  |    0.020696     |   2\n",
      "      19507 |   0.207181  |    0.212046     |   1\n",
      "      19508 |   0.042091  |    0.004285     |   2\n",
      "      19509 |   0.183583  |    0.205187     |   1\n",
      "      19510 |   0.026893  |    0.003895     |   2\n",
      "      19511 |   0.038566  |    0.078186     |   2\n",
      "      19512 |   0.198963  |    0.193450     |   1\n",
      "      19513 |   0.182900  |    0.149369     |   1\n",
      "      19514 |   0.052123  |    0.010907     |   2\n",
      "      19515 |   0.238745  |    0.084539     |   0\n",
      "      19516 |   0.134889  |    0.025881     |   0\n",
      "      19517 |   0.182542  |    0.079850     |   0\n",
      "      19518 |   0.202760  |    0.039547     |   0\n",
      "      19519 |   0.057139  |    0.051675     |   2\n",
      "      19520 |   0.046476  |    0.045727     |   2\n",
      "      19521 |   0.178981  |    0.206921     |   1\n",
      "      19522 |   0.174252  |    0.007436     |   0\n",
      "      19523 |   0.022907  |    0.081145     |   2\n",
      "      19524 |   0.138436  |    0.144235     |   1\n",
      "      19525 |   0.000028  |    0.046860     |   2\n",
      "      19526 |   0.203304  |    0.087032     |   0\n",
      "      19527 |   0.186693  |    0.141216     |   1\n",
      "      19528 |   0.154791  |    0.032358     |   0\n",
      "      19529 |   0.156283  |    0.213963     |   1\n",
      "      19530 |   0.255420  |    0.130660     |   1\n",
      "      19531 |   0.005286  |    0.040070     |   2\n",
      "      19532 |   0.067051  |    0.050568     |   2\n",
      "      19533 |   0.193584  |    0.080444     |   0\n",
      "      19534 |   0.182808  |    0.135358     |   1\n",
      "      19535 |   0.139362  |    0.080155     |   0\n",
      "      19536 |   0.171701  |    0.011784     |   0\n",
      "      19537 |   0.216509  |    0.191806     |   1\n",
      "      19538 |   0.037064  |    0.043791     |   2\n",
      "      19539 |   0.258099  |    0.147015     |   1\n",
      "      19540 |   0.195328  |    0.044467     |   0\n",
      "      19541 |   0.180180  |    0.227864     |   1\n",
      "      19542 |   0.059485  |    0.004499     |   2\n",
      "      19543 |   0.180276  |    0.047596     |   0\n",
      "      19544 |   0.178767  |    0.043843     |   0\n",
      "      19545 |   0.151413  |    0.041130     |   0\n",
      "      19546 |   0.134601  |    0.047245     |   0\n",
      "      19547 |   0.044055  |    0.083363     |   2\n",
      "      19548 |   0.107681  |    0.160299     |   1\n",
      "      19549 |   0.017316  |    0.006800     |   2\n",
      "      19550 |   0.145661  |    0.152714     |   1\n",
      "      19551 |   0.173485  |    0.169594     |   1\n",
      "      19552 |   0.152888  |    0.005605     |   0\n",
      "      19553 |   0.040094  |    0.104886     |   2\n",
      "      19554 |   0.151113  |    0.146677     |   1\n",
      "      19555 |   0.028999  |    0.062241     |   2\n",
      "      19556 |   0.223892  |    0.133509     |   1\n",
      "      19557 |   0.000028  |    0.045414     |   2\n",
      "      19558 |   0.210586  |    0.176518     |   1\n",
      "      19559 |   0.165065  |    0.048993     |   0\n",
      "      19560 |   0.211048  |    0.186740     |   1\n",
      "      19561 |   0.000028  |    0.018279     |   2\n",
      "      19562 |   0.208014  |    0.203747     |   1\n",
      "      19563 |   0.214471  |    0.039937     |   0\n",
      "      19564 |   0.000028  |    0.031658     |   2\n",
      "      19565 |   0.000029  |    0.048066     |   2\n",
      "      19566 |   0.140140  |    0.205778     |   1\n",
      "      19567 |   0.161369  |    0.153287     |   1\n",
      "      19568 |   0.195646  |    0.156373     |   1\n",
      "      19569 |   0.162812  |    0.007902     |   0\n",
      "      19570 |   0.187025  |    0.168473     |   1\n",
      "      19571 |   0.182418  |    0.128972     |   1\n",
      "      19572 |   0.000028  |    0.004043     |   2\n",
      "      19573 |   0.000028  |    0.075202     |   2\n",
      "      19574 |   0.197415  |    0.046940     |   0\n",
      "      19575 |   0.044120  |    0.045742     |   2\n",
      "      19576 |   0.049531  |    0.044406     |   2\n",
      "      19577 |   0.223716  |    0.196551     |   1\n",
      "      19578 |   0.200425  |    0.150987     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 19580: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      19579 |   0.188342  |    0.005963     |   0\n",
      "      19580 |   0.197150  |    0.145429     |   1\n",
      "      19581 |   0.047980  |    0.026947     |   2\n",
      "      19582 |   0.035348  |    0.089972     |   2\n",
      "      19583 |   0.220509  |    0.153318     |   1\n",
      "      19584 |   0.202698  |    0.009395     |   0\n",
      "      19585 |   0.040013  |    0.077835     |   2\n",
      "      19586 |   0.041482  |    0.050593     |   2\n",
      "      19587 |   0.176905  |    0.195280     |   1\n",
      "      19588 |   0.026499  |    0.011389     |   2\n",
      "      19589 |   0.175570  |    0.246288     |   1\n",
      "      19590 |   0.203387  |    0.006457     |   0\n",
      "      19591 |   0.195837  |    0.082868     |   0\n",
      "      19592 |   0.038110  |    0.038619     |   2\n",
      "      19593 |   0.203627  |    0.205825     |   1\n",
      "      19594 |   0.166239  |    0.014084     |   0\n",
      "      19595 |   0.204786  |    0.091770     |   0\n",
      "      19596 |   0.046870  |    0.011147     |   2\n",
      "      19597 |   0.169482  |    0.074150     |   0\n",
      "      19598 |   0.058979  |    0.030356     |   2\n",
      "      19599 |   0.200499  |    0.053407     |   0\n",
      "      19600 |   0.044779  |    0.054467     |   2\n",
      "      19601 |   0.205393  |    0.075000     |   0\n",
      "      19602 |   0.024549  |    0.019525     |   2\n",
      "      19603 |   0.193651  |    0.072219     |   0\n",
      "      19604 | \u001b[94m  0.000028\u001b[0m  |    0.048895     |   2\n",
      "      19605 |   0.210166  |    0.043478     |   0\n",
      "      19606 |   0.176475  |    0.197692     |   1\n",
      "      19607 |   0.005485  |    0.011050     |   2\n",
      "      19608 |   0.218908  |    0.080751     |   0\n",
      "      19609 |   0.065957  |    0.005379     |   2\n",
      "      19610 |   0.173793  |    0.208696     |   1\n",
      "      19611 |   0.184844  |    0.152091     |   1\n",
      "      19612 |   0.037665  |    0.044084     |   2\n",
      "      19613 |   0.179563  |    0.080422     |   0\n",
      "      19614 |   0.178319  |    0.136581     |   1\n",
      "      19615 |   0.228127  |    0.072597     |   0\n",
      "      19616 |   0.163269  |    0.034888     |   0\n",
      "      19617 |   0.239254  |    0.193332     |   1\n",
      "      19618 |   0.190528  |    0.013219     |   0\n",
      "      19619 |   0.215820  |    0.181049     |   1\n",
      "      19620 |   0.061221  |    0.013782     |   2\n",
      "      19621 |   0.209542  |    0.197705     |   1\n",
      "      19622 |   0.043493  |    0.019263     |   2\n",
      "      19623 |   0.224579  |    0.208049     |   1\n",
      "      19624 |   0.174433  |    0.006976     |   0\n",
      "      19625 |   0.019563  |    0.077631     |   2\n",
      "      19626 |   0.251768  |    0.197695     |   1\n",
      "      19627 |   0.190106  |    0.148378     |   1\n",
      "      19628 |   0.128628  |    0.028729     |   0\n",
      "      19629 |   0.199677  |    0.217264     |   1\n",
      "      19630 |   0.038097  |    0.007872     |   2\n",
      "      19631 |   0.030761  |    0.075396     |   2\n",
      "      19632 |   0.215350  |    0.045374     |   0\n",
      "      19633 | \u001b[94m  0.000027\u001b[0m  |    0.040151     |   2\n",
      "      19634 | \u001b[94m  0.000027\u001b[0m  |    0.085456     |   2\n",
      "      19635 |   0.224606  |    0.157721     |   1\n",
      "      19636 |   0.228739  |    0.157591     |   1\n",
      "      19637 |   0.000027  |    0.009635     |   2\n",
      "      19638 |   0.166631  |    0.075373     |   0\n",
      "      19639 |   0.234195  |    0.139234     |   1\n",
      "      19640 |   0.000028  |    0.044480     |   2\n",
      "      19641 |   0.154517  |    0.030864     |   0\n",
      "      19642 |   0.154112  |    0.187669     |   1\n",
      "      19643 |   0.193970  |    0.014184     |   0\n",
      "      19644 |   0.189166  |    0.195691     |   1\n",
      "      19645 |   0.192315  |    0.027869     |   0\n",
      "      19646 |   0.157979  |    0.226906     |   1\n",
      "      19647 | \u001b[94m  0.000027\u001b[0m  |    0.005709     |   2\n",
      "      19648 |   0.180298  |    0.087132     |   0\n",
      "      19649 |   0.151270  |    0.167835     |   1\n",
      "      19650 |   0.153385  |    0.136988     |   1\n",
      "      19651 |   0.183081  |    0.175788     |   1\n",
      "      19652 |   0.179314  |    0.018904     |   0\n",
      "      19653 |   0.190289  |    0.072569     |   0\n",
      "      19654 |   0.211725  |    0.148504     |   1\n",
      "      19655 | \u001b[94m  0.000027\u001b[0m  |    0.022110     |   2\n",
      "      19656 |   0.224383  |    0.206455     |   1\n",
      "      19657 |   0.188030  |    0.142666     |   1\n",
      "      19658 |   0.048713  |    0.013810     |   2\n",
      "      19659 |   0.171189  |    0.075975     |   0\n",
      "      19660 |   0.124796  |    0.020256     |   0\n",
      "      19661 |   0.049344  |    0.043886     |   2\n",
      "      19662 |   0.200709  |    0.074960     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 19663: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      19663 |   0.048230  |    0.025430     |   2\n",
      "      19664 |   0.035212  |    0.078664     |   2\n",
      "      19665 |   0.037796  |    0.021991     |   2\n",
      "      19666 |   0.230663  |    0.192862     |   1\n",
      "      19667 |   0.241661  |    0.137593     |   1\n",
      "      19668 |   0.255182  |    0.021143     |   0\n",
      "      19669 |   0.201146  |    0.044827     |   0\n",
      "      19670 |   0.218751  |    0.092040     |   0\n",
      "      19671 |   0.210833  |    0.140552     |   1\n",
      "      19672 |   0.042308  |    0.038804     |   2\n",
      "      19673 |   0.190627  |    0.043489     |   0\n",
      "      19674 |   0.026851  |    0.047491     |   2\n",
      "      19675 |   0.037735  |    0.043092     |   2\n",
      "      19676 |   0.048188  |    0.074999     |   2\n",
      "      19677 |   0.052343  |    0.039310     |   2\n",
      "      19678 |   0.141691  |    0.186246     |   1\n",
      "      19679 |   0.044840  |    0.016652     |   2\n",
      "      19680 |   0.170395  |    0.191552     |   1\n",
      "      19681 |   0.172557  |    0.015529     |   0\n",
      "      19682 |   0.024394  |    0.046770     |   2\n",
      "      19683 |   0.000027  |    0.047620     |   2\n",
      "      19684 |   0.213087  |    0.192391     |   1\n",
      "      19685 |   0.201005  |    0.054131     |   0\n",
      "      19686 |   0.197795  |    0.136601     |   1\n",
      "      19687 |   0.212500  |    0.018747     |   0\n",
      "      19688 |   0.199233  |    0.201458     |   1\n",
      "      19689 |   0.238062  |    0.164037     |   1\n",
      "      19690 |   0.193054  |    0.014784     |   0\n",
      "      19691 |   0.192213  |    0.072445     |   0\n",
      "      19692 |   0.173493  |    0.042348     |   0\n",
      "      19693 |   0.005625  |    0.041282     |   2\n",
      "      19694 |   0.164455  |    0.043995     |   0\n",
      "      19695 |   0.066748  |    0.072933     |   2\n",
      "      19696 |   0.034872  |    0.031456     |   2\n",
      "      19697 |   0.233198  |    0.162413     |   1\n",
      "      19698 |   0.180822  |    0.191151     |   1\n",
      "      19699 |   0.060987  |    0.007819     |   2\n",
      "      19700 |   0.041534  |    0.075985     |   2\n",
      "      19701 |   0.017077  |    0.043318     |   2\n",
      "      19702 |   0.038060  |    0.047040     |   2\n",
      "      19703 |   0.163110  |    0.045272     |   0\n",
      "      19704 |   0.027126  |    0.040938     |   2\n",
      "      19705 |   0.185446  |    0.217627     |   1\n",
      "      19706 |   0.205879  |    0.140358     |   1\n",
      "      19707 |   0.157829  |    0.156614     |   1\n",
      "      19708 |   0.226471  |    0.039933     |   0\n",
      "      19709 |   0.000027  |    0.045298     |   2\n",
      "      19710 |   0.225283  |    0.065333     |   0\n",
      "      19711 |   0.260235  |    0.191884     |   1\n",
      "      19712 |   0.181707  |    0.052345     |   0\n",
      "      19713 |   0.230710  |    0.188143     |   1\n",
      "      19714 |   0.000027  |    0.006969     |   2\n",
      "      19715 |   0.158360  |    0.073705     |   0\n",
      "      19716 |   0.174065  |    0.025205     |   0\n",
      "      19717 |   0.161959  |    0.202231     |   1\n",
      "      19718 |   0.208188  |    0.142679     |   1\n",
      "      19719 |   0.000027  |    0.028375     |   2\n",
      "      19720 |   0.117226  |    0.210381     |   1\n",
      "      19721 |   0.000028  |    0.006168     |   2\n",
      "      19722 |   0.000027  |    0.072452     |   2\n",
      "      19723 |   0.000027  |    0.042874     |   2\n",
      "      19724 |   0.211709  |    0.058059     |   0\n",
      "      19725 |   0.224380  |    0.148564     |   1\n",
      "      19726 |   0.195584  |    0.198604     |   1\n",
      "      19727 |   0.043225  |    0.031728     |   2\n",
      "      19728 |   0.141661  |    0.199485     |   1\n",
      "      19729 |   0.049100  |    0.041382     |   2\n",
      "      19730 |   0.202455  |    0.194592     |   1\n",
      "      19731 |   0.258381  |    0.143936     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 19732: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      19732 |   0.235596  |    0.011182     |   0\n",
      "      19733 |   0.167377  |    0.039454     |   0\n",
      "      19734 |   0.221013  |    0.182594     |   1\n",
      "      19735 |   0.181543  |    0.138698     |   1\n",
      "      19736 |   0.227081  |    0.149099     |   1\n",
      "      19737 |   0.273448  |    0.015213     |   0\n",
      "      19738 |   0.185270  |    0.080049     |   0\n",
      "      19739 |   0.045329  |    0.024810     |   2\n",
      "      19740 |   0.033537  |    0.093721     |   2\n",
      "      19741 |   0.039569  |    0.008532     |   2\n",
      "      19742 |   0.143163  |    0.071948     |   0\n",
      "      19743 |   0.042491  |    0.035248     |   2\n",
      "      19744 |   0.169113  |    0.197879     |   1\n",
      "      19745 |   0.183219  |    0.026643     |   0\n",
      "      19746 |   0.026919  |    0.086403     |   2\n",
      "      19747 |   0.154593  |    0.137995     |   1\n",
      "      19748 |   0.037632  |    0.048558     |   2\n",
      "      19749 |   0.248101  |    0.198893     |   1\n",
      "      19750 |   0.051689  |    0.018650     |   2\n",
      "      19751 |   0.219078  |    0.205655     |   1\n",
      "      19752 |   0.171281  |    0.147549     |   1\n",
      "      19753 |   0.188587  |    0.143986     |   1\n",
      "      19754 |   0.187557  |    0.046170     |   0\n",
      "      19755 |   0.196161  |    0.073838     |   0\n",
      "      19756 |   0.191978  |    0.012973     |   0\n",
      "      19757 |   0.154205  |    0.074900     |   0\n",
      "      19758 |   0.191441  |    0.142042     |   1\n",
      "      19759 |   0.215922  |    0.042687     |   0\n",
      "      19760 |   0.053627  |    0.039955     |   2\n",
      "      19761 |   0.262025  |    0.190036     |   1\n",
      "      19762 |   0.184579  |    0.152515     |   1\n",
      "      19763 |   0.189304  |    0.150047     |   1\n",
      "      19764 |   0.190059  |    0.008194     |   0\n",
      "      19765 |   0.224359  |    0.079826     |   0\n",
      "      19766 |   0.234619  |    0.023818     |   0\n",
      "      19767 |   0.045399  |    0.084705     |   2\n",
      "      19768 |   0.201791  |    0.190952     |   1\n",
      "      19769 |   0.176403  |    0.007074     |   0\n",
      "      19770 |   0.021967  |    0.053191     |   2\n",
      "      19771 |   0.169404  |    0.052909     |   0\n",
      "      19772 |   0.185163  |    0.197334     |   1\n",
      "      19773 |   0.184565  |    0.153507     |   1\n",
      "      19774 |   0.142078  |    0.097522     |   1\n",
      "      19775 |   0.234779  |    0.040480     |   0\n",
      "      19776 |   0.202849  |    0.043371     |   0\n",
      "      19777 |   0.190967  |    0.074257     |   0\n",
      "      19778 |   0.222331  |    0.024797     |   0\n",
      "      19779 |   0.193911  |    0.108868     |   0\n",
      "      19780 |   0.208689  |    0.157426     |   1\n",
      "      19781 |   0.148630  |    0.016109     |   0\n",
      "      19782 |   0.238052  |    0.199701     |   1\n",
      "      19783 |   0.157289  |    0.004203     |   0\n",
      "      19784 | \u001b[94m  0.000026\u001b[0m  |    0.044800     |   2\n",
      "      19785 |   0.005444  |    0.052243     |   2\n",
      "      19786 |   0.227568  |    0.209535     |   1\n",
      "      19787 |   0.171854  |    0.150500     |   1\n",
      "      19788 |   0.177625  |    0.158446     |   1\n",
      "      19789 |   0.067238  |    0.025241     |   2\n",
      "      19790 |   0.036427  |    0.077399     |   2\n",
      "      19791 |   0.238479  |    0.136774     |   1\n",
      "      19792 |   0.168198  |    0.049382     |   0\n",
      "      19793 |   0.060869  |    0.074658     |   2\n",
      "      19794 |   0.042938  |    0.016424     |   2\n",
      "      19795 |   0.191713  |    0.197384     |   1\n",
      "      19796 |   0.226708  |    0.012222     |   0\n",
      "      19797 |   0.185148  |    0.073577     |   0\n",
      "      19798 |   0.235272  |    0.044499     |   0\n",
      "      19799 |   0.190427  |    0.050366     |   0\n",
      "      19800 |   0.209492  |    0.149281     |   1\n",
      "      19801 |   0.197347  |    0.210249     |   1\n",
      "      19802 |   0.016733  |    0.004410     |   2\n",
      "      19803 |   0.183009  |    0.071510     |   0\n",
      "      19804 |   0.036375  |    0.016743     |   2\n",
      "      19805 |   0.029737  |    0.081471     |   2\n",
      "      19806 |   0.160805  |    0.036685     |   0\n",
      "      19807 |   0.000026  |    0.043525     |   2\n",
      "      19808 |   0.000026  |    0.084929     |   2\n",
      "      19809 |   0.000026  |    0.014789     |   2\n",
      "      19810 |   0.133437  |    0.048144     |   0\n",
      "      19811 |   0.000027  |    0.051392     |   2\n",
      "      19812 |   0.164517  |    0.155801     |   1\n",
      "      19813 |   0.158959  |    0.024001     |   0\n",
      "      19814 |   0.178225  |    0.180966     |   1\n",
      "      19815 |   0.000026  |    0.074789     |   2\n",
      "      19816 |   0.000026  |    0.025733     |   2\n",
      "      19817 |   0.159833  |    0.082852     |   0\n",
      "      19818 |   0.047769  |    0.010676     |   2\n",
      "      19819 |   0.196435  |    0.077004     |   0\n",
      "      19820 |   0.175494  |    0.026758     |   0\n",
      "      19821 |   0.114593  |    0.200175     |   1\n",
      "      19822 |   0.251909  |    0.192564     |   1\n",
      "      19823 |   0.053085  |    0.009361     |   2\n",
      "      19824 |   0.228524  |    0.202034     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 19825: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      19825 |   0.179654  |    0.051462     |   0\n",
      "      19826 |   0.046285  |    0.038491     |   2\n",
      "      19827 |   0.185741  |    0.081645     |   0\n",
      "      19828 |   0.034215  |    0.024250     |   2\n",
      "      19829 |   0.154576  |    0.048578     |   0\n",
      "      19830 |   0.039642  |    0.056112     |   2\n",
      "      19831 |   0.189923  |    0.138293     |   1\n",
      "      19832 |   0.181498  |    0.201320     |   1\n",
      "      19833 |   0.159677  |    0.012758     |   0\n",
      "      19834 |   0.042325  |    0.077338     |   2\n",
      "      19835 |   0.027240  |    0.017604     |   2\n",
      "      19836 |   0.099915  |    0.207191     |   1\n",
      "      19837 |   0.037516  |    0.013864     |   2\n",
      "      19838 |   0.184092  |    0.213213     |   1\n",
      "      19839 |   0.213878  |    0.008383     |   0\n",
      "      19840 |   0.160126  |    0.185840     |   1\n",
      "      19841 |   0.177424  |    0.044281     |   0\n",
      "      19842 |   0.164045  |    0.046865     |   0\n",
      "      19843 |   0.186691  |    0.074385     |   0\n",
      "      19844 |   0.165734  |    0.021590     |   0\n",
      "      19845 |   0.190246  |    0.091897     |   0\n",
      "      19846 |   0.052463  |    0.007994     |   2\n",
      "      19847 |   0.053073  |    0.077934     |   2\n",
      "      19848 |   0.042751  |    0.031408     |   2\n",
      "      19849 |   0.020687  |    0.046222     |   2\n",
      "      19850 | \u001b[94m  0.000026\u001b[0m  |    0.043392     |   2\n",
      "      19851 |   0.197801  |    0.073104     |   0\n",
      "      19852 |   0.197002  |    0.027847     |   0\n",
      "      19853 |   0.237808  |    0.213488     |   1\n",
      "      19854 |   0.232677  |    0.150334     |   1\n",
      "      19855 |   0.204401  |    0.167573     |   1\n",
      "      19856 |   0.231005  |    0.119720     |   1\n",
      "      19857 |   0.210061  |    0.142994     |   1\n",
      "      19858 |   0.226508  |    0.169371     |   1\n",
      "      19859 |   0.194925  |    0.044354     |   0\n",
      "      19860 |   0.005078  |    0.050816     |   2\n",
      "      19861 |   0.249766  |    0.197589     |   1\n",
      "      19862 |   0.221247  |    0.005196     |   0\n",
      "      19863 |   0.066619  |    0.082443     |   2\n",
      "      19864 |   0.215716  |    0.027965     |   0\n",
      "      19865 |   0.223463  |    0.215439     |   1\n",
      "      19866 |   0.150566  |    0.136551     |   1\n",
      "      19867 |   0.237418  |    0.052221     |   0\n",
      "      19868 |   0.032622  |    0.047554     |   2\n",
      "      19869 |   0.264668  |    0.148228     |   1\n",
      "      19870 |   0.057750  |    0.036210     |   2\n",
      "      19871 |   0.216347  |    0.194561     |   1\n",
      "      19872 |   0.222610  |    0.152110     |   1\n",
      "      19873 |   0.200030  |    0.010119     |   0\n",
      "      19874 |   0.137241  |    0.072560     |   0\n",
      "      19875 |   0.194968  |    0.040454     |   0\n",
      "      19876 |   0.040683  |    0.063272     |   2\n",
      "      19877 |   0.169066  |    0.203645     |   1\n",
      "      19878 |   0.015631  |    0.004574     |   2\n",
      "      19879 |   0.170801  |    0.052626     |   0\n",
      "      19880 |   0.034197  |    0.037594     |   2\n",
      "      19881 |   0.196819  |    0.162946     |   1\n",
      "      19882 |   0.160909  |    0.075717     |   0\n",
      "      19883 |   0.030445  |    0.046085     |   2\n",
      "      19884 |   0.207972  |    0.173479     |   1\n",
      "      19885 | \u001b[94m  0.000026\u001b[0m  |    0.017081     |   2\n",
      "      19886 |   0.170147  |    0.090970     |   0\n",
      "      19887 |   0.168839  |    0.139083     |   1\n",
      "      19888 |   0.152970  |    0.065377     |   0\n",
      "      19889 |   0.135171  |    0.211904     |   1\n",
      "      19890 |   0.169753  |    0.137946     |   1\n",
      "      19891 |   0.169237  |    0.042780     |   0\n",
      "      19892 |   0.218095  |    0.196099     |   1\n",
      "      19893 |   0.153867  |    0.149593     |   1\n",
      "      19894 |   0.131206  |    0.018336     |   0\n",
      "      19895 | \u001b[94m  0.000026\u001b[0m  |    0.081277     |   2\n",
      "      19896 |   0.000026  |    0.029789     |   2\n",
      "      19897 |   0.000026  |    0.076039     |   2\n",
      "      19898 | \u001b[94m  0.000026\u001b[0m  |    0.027030     |   2\n",
      "      19899 |   0.193149  |    0.090636     |   0\n",
      "      19900 |   0.163829  |    0.153562     |   1\n",
      "      19901 |   0.229192  |    0.166011     |   1\n",
      "      19902 |   0.147759  |    0.155091     |   1\n",
      "      19903 |   0.205284  |    0.148271     |   1\n",
      "      19904 |   0.201134  |    0.145152     |   1\n",
      "      19905 | \u001b[94m  0.000026\u001b[0m  |    0.034907     |   2\n",
      "      19906 |   0.194608  |    0.086600     |   0\n",
      "      19907 |   0.046233  |    0.021075     |   2\n",
      "      19908 |   0.190619  |    0.192225     |   1\n",
      "      19909 |   0.052085  |    0.036292     |   2\n",
      "      19910 |   0.246254  |    0.198350     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 19911: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      19911 |   0.166876  |    0.035672     |   0\n",
      "      19912 |   0.168560  |    0.160837     |   1\n",
      "      19913 |   0.218133  |    0.040218     |   0\n",
      "      19914 |   0.201687  |    0.181338     |   1\n",
      "      19915 |   0.152643  |    0.028992     |   0\n",
      "      19916 |   0.208345  |    0.157021     |   1\n",
      "      19917 |   0.045349  |    0.052674     |   2\n",
      "      19918 |   0.032760  |    0.075659     |   2\n",
      "      19919 |   0.244234  |    0.133139     |   1\n",
      "      19920 |   0.188845  |    0.018659     |   0\n",
      "      19921 |   0.186852  |    0.078504     |   0\n",
      "      19922 |   0.168411  |    0.147473     |   1\n",
      "      19923 |   0.038619  |    0.039122     |   2\n",
      "      19924 |   0.166015  |    0.089625     |   0\n",
      "      19925 |   0.235985  |    0.168098     |   1\n",
      "      19926 |   0.164868  |    0.140578     |   1\n",
      "      19927 |   0.168651  |    0.045594     |   0\n",
      "      19928 |   0.238963  |    0.190894     |   1\n",
      "      19929 |   0.042062  |    0.003920     |   2\n",
      "      19930 |   0.026605  |    0.041286     |   2\n",
      "      19931 |   0.175911  |    0.187892     |   1\n",
      "      19932 |   0.140119  |    0.163911     |   1\n",
      "      19933 |   0.174734  |    0.219035     |   1\n",
      "      19934 |   0.160657  |    0.005869     |   0\n",
      "      19935 |   0.154618  |    0.035803     |   0\n",
      "      19936 |   0.176635  |    0.198603     |   1\n",
      "      19937 |   0.038923  |    0.006316     |   2\n",
      "      19938 |   0.049364  |    0.080654     |   2\n",
      "      19939 |   0.052614  |    0.020411     |   2\n",
      "      19940 |   0.197295  |    0.195916     |   1\n",
      "      19941 |   0.200917  |    0.012223     |   0\n",
      "      19942 |   0.044680  |    0.078696     |   2\n",
      "      19943 |   0.021319  |    0.013684     |   2\n",
      "      19944 |   0.179501  |    0.057768     |   0\n",
      "      19945 | \u001b[94m  0.000026\u001b[0m  |    0.045684     |   2\n",
      "      19946 |   0.005456  |    0.054633     |   2\n",
      "      19947 |   0.208996  |    0.203203     |   1\n",
      "      19948 |   0.213874  |    0.012575     |   0\n",
      "      19949 |   0.200798  |    0.080534     |   0\n",
      "      19950 |   0.203381  |    0.032735     |   0\n",
      "      19951 |   0.065241  |    0.086055     |   2\n",
      "      19952 |   0.172474  |    0.150669     |   1\n",
      "      19953 |   0.194748  |    0.079440     |   0\n",
      "      19954 |   0.256144  |    0.143733     |   1\n",
      "      19955 |   0.217400  |    0.028758     |   0\n",
      "      19956 |   0.164968  |    0.158320     |   1\n",
      "      19957 |   0.035440  |    0.058903     |   2\n",
      "      19958 |   0.200375  |    0.045073     |   0\n",
      "      19959 |   0.056417  |    0.016705     |   2\n",
      "      19960 |   0.158456  |    0.079252     |   0\n",
      "      19961 |   0.228376  |    0.138953     |   1\n",
      "      19962 |   0.132943  |    0.041833     |   0\n",
      "      19963 |   0.040276  |    0.046777     |   2\n",
      "      19964 |   0.171895  |    0.168657     |   1\n",
      "      19965 |   0.135146  |    0.204215     |   1\n",
      "      19966 |   0.195971  |    0.016967     |   0\n",
      "      19967 |   0.183205  |    0.191840     |   1\n",
      "      19968 |   0.210478  |    0.143769     |   1\n",
      "      19969 |   0.216587  |    0.006693     |   0\n",
      "      19970 |   0.145765  |    0.049184     |   0\n",
      "      19971 |   0.187139  |    0.194473     |   1\n",
      "      19972 |   0.016666  |    0.005085     |   2\n",
      "      19973 |   0.037877  |    0.085606     |   2\n",
      "      19974 |   0.149629  |    0.155145     |   1\n",
      "      19975 |   0.193311  |    0.042856     |   0\n",
      "      19976 |   0.189403  |    0.042390     |   0\n",
      "      19977 |   0.028458  |    0.041496     |   2\n",
      "      19978 |   0.000026  |    0.076911     |   2\n",
      "      19979 |   0.146693  |    0.025389     |   0\n",
      "      19980 |   0.180683  |    0.041252     |   0\n",
      "      19981 |   0.000026  |    0.044818     |   2\n",
      "      19982 |   0.000026  |    0.073434     |   2\n",
      "      19983 |   0.000026  |    0.022646     |   2\n",
      "      19984 |   0.000026  |    0.084371     |   2\n",
      "      19985 |   0.201342  |    0.044097     |   0\n",
      "      19986 |   0.207787  |    0.202569     |   1\n",
      "      19987 |   0.177512  |    0.003968     |   0\n",
      "      19988 |   0.213719  |    0.201218     |   1\n",
      "      19989 | \u001b[94m  0.000026\u001b[0m  |    0.005937     |   2\n",
      "      19990 |   0.048840  |    0.080286     |   2\n",
      "      19991 |   0.172927  |    0.025787     |   0\n",
      "      19992 |   0.204191  |    0.081929     |   0\n",
      "      19993 |   0.197474  |    0.034635     |   0\n",
      "      19994 |   0.186130  |    0.073122     |   0\n",
      "      19995 |   0.171432  |    0.027094     |   0\n",
      "      19996 |   0.051289  |    0.088408     |   2\n",
      "      19997 |   0.201051  |    0.134034     |   1\n",
      "      19998 |   0.187535  |    0.064965     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 19999: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      19999 |   0.153818  |    0.162648     |   1\n",
      "      20000 |   0.177383  |    0.130833     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 20000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 20000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      20001 |   0.175992  |    0.201834     |   1\n",
      "      20002 |   0.196080  |    0.039217     |   0\n",
      "      20003 |   0.188955  |    0.081243     |   0\n",
      "      20004 |   0.046347  |    0.025084     |   2\n",
      "      20005 |   0.232378  |    0.213483     |   1\n",
      "      20006 |   0.159018  |    0.039628     |   0\n",
      "      20007 |   0.173529  |    0.237894     |   1\n",
      "      20008 |   0.034687  |    0.007997     |   2\n",
      "      20009 |   0.039610  |    0.079639     |   2\n",
      "      20010 |   0.156566  |    0.043469     |   0\n",
      "      20011 |   0.043283  |    0.045806     |   2\n",
      "      20012 |   0.188827  |    0.047925     |   0\n",
      "      20013 |   0.027520  |    0.045569     |   2\n",
      "      20014 |   0.170881  |    0.045514     |   0\n",
      "      20015 |   0.035875  |    0.052197     |   2\n",
      "      20016 |   0.051837  |    0.071813     |   2\n",
      "      20017 |   0.054509  |    0.049416     |   2\n",
      "      20018 |   0.045007  |    0.044280     |   2\n",
      "      20019 |   0.170432  |    0.142224     |   1\n",
      "      20020 |   0.171613  |    0.042750     |   0\n",
      "      20021 |   0.163302  |    0.045787     |   0\n",
      "      20022 |   0.169196  |    0.043241     |   0\n",
      "      20023 |   0.120794  |    0.072833     |   0\n",
      "      20024 |   0.197751  |    0.022704     |   0\n",
      "      20025 |   0.227299  |    0.049655     |   0\n",
      "      20026 |   0.150156  |    0.074879     |   0\n",
      "      20027 |   0.021280  |    0.042488     |   2\n",
      "      20028 | \u001b[94m  0.000025\u001b[0m  |    0.039520     |   2\n",
      "      20029 |   0.135363  |    0.200969     |   1\n",
      "      20030 |   0.122180  |    0.023964     |   0\n",
      "      20031 |   0.181999  |    0.051807     |   0\n",
      "      20032 |   0.162815  |    0.041008     |   0\n",
      "      20033 |   0.188304  |    0.057169     |   0\n",
      "      20034 |   0.213625  |    0.153167     |   1\n",
      "      20035 |   0.005438  |    0.055584     |   2\n",
      "      20036 |   0.170256  |    0.134132     |   1\n",
      "      20037 |   0.168228  |    0.041712     |   0\n",
      "      20038 |   0.166113  |    0.050996     |   0\n",
      "      20039 |   0.066670  |    0.043878     |   2\n",
      "      20040 |   0.035425  |    0.046070     |   2\n",
      "      20041 |   0.143194  |    0.041339     |   0\n",
      "      20042 |   0.059422  |    0.025757     |   2\n",
      "      20043 |   0.167497  |    0.219901     |   1\n",
      "      20044 |   0.158948  |    0.211215     |   1\n",
      "      20045 |   0.195467  |    0.163683     |   1\n",
      "      20046 |   0.238685  |    0.140317     |   1\n",
      "      20047 |   0.182180  |    0.074404     |   0\n",
      "      20048 |   0.191820  |    0.038190     |   0\n",
      "      20049 |   0.143873  |    0.213093     |   1\n",
      "      20050 |   0.043168  |    0.023386     |   2\n",
      "      20051 |   0.018035  |    0.079899     |   2\n",
      "      20052 |   0.041295  |    0.016519     |   2\n",
      "      20053 |   0.030182  |    0.078804     |   2\n",
      "      20054 |   0.000026  |    0.028516     |   2\n",
      "      20055 |   0.160809  |    0.077881     |   0\n",
      "      20056 |   0.166036  |    0.004505     |   0\n",
      "      20057 |   0.209568  |    0.191015     |   1\n",
      "      20058 |   0.000026  |    0.044237     |   2\n",
      "      20059 |   0.180377  |    0.195118     |   1\n",
      "      20060 |   0.188708  |    0.043169     |   0\n",
      "      20061 |   0.188023  |    0.180836     |   1\n",
      "      20062 |   0.148230  |    0.047889     |   0\n",
      "      20063 |   0.229709  |    0.202660     |   1\n",
      "      20064 |   0.163819  |    0.164662     |   1\n",
      "      20065 |   0.000026  |    0.013772     |   2\n",
      "      20066 |   0.169730  |    0.187863     |   1\n",
      "      20067 |   0.191017  |    0.165802     |   1\n",
      "      20068 |   0.000026  |    0.073408     |   2\n",
      "      20069 |   0.194957  |    0.160910     |   1\n",
      "      20070 |   0.000026  |    0.041259     |   2\n",
      "      20071 |   0.210047  |    0.152791     |   1\n",
      "      20072 |   0.231184  |    0.146744     |   1\n",
      "      20073 |   0.000026  |    0.051340     |   2\n",
      "      20074 |   0.146353  |    0.041625     |   0\n",
      "      20075 |   0.044168  |    0.031527     |   2\n",
      "      20076 |   0.050813  |    0.056258     |   2\n",
      "      20077 |   0.159900  |    0.028086     |   0\n",
      "      20078 |   0.156535  |    0.074979     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 20079: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      20079 |   0.158557  |    0.010456     |   0\n",
      "      20080 |   0.043869  |    0.087166     |   2\n",
      "      20081 |   0.033110  |    0.032194     |   2\n",
      "      20082 |   0.039926  |    0.054556     |   2\n",
      "      20083 |   0.145630  |    0.193432     |   1\n",
      "      20084 |   0.042775  |    0.008673     |   2\n",
      "      20085 |   0.162665  |    0.185533     |   1\n",
      "      20086 |   0.026463  |    0.085876     |   2\n",
      "      20087 |   0.187560  |    0.188010     |   1\n",
      "      20088 |   0.036739  |    0.032787     |   2\n",
      "      20089 |   0.191134  |    0.192180     |   1\n",
      "      20090 |   0.193432  |    0.007841     |   0\n",
      "      20091 |   0.166629  |    0.041313     |   0\n",
      "      20092 |   0.051798  |    0.077865     |   2\n",
      "      20093 |   0.054284  |    0.020935     |   2\n",
      "      20094 |   0.048002  |    0.080090     |   2\n",
      "      20095 |   0.179186  |    0.028381     |   0\n",
      "      20096 |   0.222976  |    0.051312     |   0\n",
      "      20097 |   0.150613  |    0.250558     |   1\n",
      "      20098 |   0.022776  |    0.006792     |   2\n",
      "      20099 |   0.000026  |    0.080111     |   2\n",
      "      20100 |   0.156515  |    0.045175     |   0\n",
      "      20101 |   0.168465  |    0.047645     |   0\n",
      "      20102 |   0.005016  |    0.075853     |   2\n",
      "      20103 |   0.213088  |    0.012126     |   0\n",
      "      20104 |   0.186141  |    0.082305     |   0\n",
      "      20105 |   0.204394  |    0.150898     |   1\n",
      "      20106 |   0.165152  |    0.072097     |   0\n",
      "      20107 |   0.179750  |    0.018304     |   0\n",
      "      20108 |   0.159682  |    0.077615     |   0\n",
      "      20109 |   0.205595  |    0.031653     |   0\n",
      "      20110 |   0.061356  |    0.041180     |   2\n",
      "      20111 |   0.200383  |    0.076935     |   0\n",
      "      20112 |   0.036202  |    0.046721     |   2\n",
      "      20113 |   0.060859  |    0.041794     |   2\n",
      "      20114 |   0.177814  |    0.051843     |   0\n",
      "      20115 |   0.043113  |    0.043957     |   2\n",
      "      20116 |   0.253368  |    0.044690     |   0\n",
      "      20117 |   0.180715  |    0.050522     |   0\n",
      "      20118 |   0.165179  |    0.039491     |   0\n",
      "      20119 |   0.167976  |    0.074069     |   0\n",
      "      20120 |   0.196002  |    0.029002     |   0\n",
      "      20121 |   0.159551  |    0.051109     |   0\n",
      "      20122 |   0.181141  |    0.047038     |   0\n",
      "      20123 |   0.168121  |    0.082774     |   0\n",
      "      20124 |   0.180489  |    0.131361     |   1\n",
      "      20125 |   0.184403  |    0.076611     |   0\n",
      "      20126 |   0.018804  |    0.025099     |   2\n",
      "      20127 |   0.184087  |    0.225326     |   1\n",
      "      20128 |   0.183247  |    0.006260     |   0\n",
      "      20129 |   0.185309  |    0.087772     |   0\n",
      "      20130 |   0.190752  |    0.055996     |   0\n",
      "      20131 |   0.191352  |    0.173222     |   1\n",
      "      20132 |   0.043833  |    0.014493     |   2\n",
      "      20133 |   0.192158  |    0.199384     |   1\n",
      "      20134 |   0.228420  |    0.025456     |   0\n",
      "      20135 |   0.029927  |    0.081499     |   2\n",
      "      20136 |   0.192870  |    0.152308     |   1\n",
      "      20137 |   0.188504  |    0.075397     |   0\n",
      "      20138 |   0.188584  |    0.020903     |   0\n",
      "      20139 |   0.207525  |    0.081921     |   0\n",
      "      20140 |   0.237809  |    0.149953     |   1\n",
      "      20141 |   0.156624  |    0.250621     |   1\n",
      "      20142 |   0.000026  |    0.054332     |   2\n",
      "      20143 |   0.202321  |    0.153397     |   1\n",
      "      20144 |   0.169452  |    0.025370     |   0\n",
      "      20145 |   0.194880  |    0.072942     |   0\n",
      "      20146 |   0.169875  |    0.041477     |   0\n",
      "      20147 |   0.152831  |    0.203078     |   1\n",
      "      20148 |   0.165890  |    0.161267     |   1\n",
      "      20149 |   0.000026  |    0.037116     |   2\n",
      "      20150 |   0.202245  |    0.188630     |   1\n",
      "      20151 |   0.200671  |    0.044493     |   0\n",
      "      20152 |   0.209945  |    0.056054     |   0\n",
      "      20153 |   0.187278  |    0.191872     |   1\n",
      "      20154 |   0.000026  |    0.010218     |   2\n",
      "      20155 |   0.000027  |    0.118950     |   2\n",
      "      20156 |   0.199954  |    0.158323     |   1\n",
      "      20157 |   0.127205  |    0.040116     |   0\n",
      "      20158 |   0.000026  |    0.072827     |   2\n",
      "      20159 |   0.133610  |    0.015348     |   0\n",
      "      20160 |   0.184702  |    0.209910     |   1\n",
      "      20161 |   0.149056  |    0.023894     |   0\n",
      "      20162 |   0.176344  |    0.076798     |   0\n",
      "      20163 |   0.179694  |    0.204502     |   1\n",
      "      20164 |   0.159402  |    0.022510     |   0\n",
      "      20165 |   0.184001  |    0.078652     |   0\n",
      "      20166 |   0.200060  |    0.235921     |   1\n",
      "      20167 |   0.000026  |    0.006934     |   2\n",
      "      20168 |   0.190503  |    0.078436     |   0\n",
      "      20169 |   0.051281  |    0.040314     |   2\n",
      "      20170 |   0.228884  |    0.065615     |   0\n",
      "      20171 |   0.153012  |    0.212980     |   1\n",
      "      20172 |   0.150322  |    0.256018     |   1\n",
      "      20173 |   0.051439  |    0.081843     |   2\n",
      "      20174 |   0.197576  |    0.159340     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 20175: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      20175 |   0.176844  |    0.216432     |   1\n",
      "      20176 |   0.131691  |    0.205530     |   1\n",
      "      20177 |   0.146993  |    0.249642     |   1\n",
      "      20178 |   0.046589  |    0.048095     |   2\n",
      "      20179 |   0.169974  |    0.193192     |   1\n",
      "      20180 |   0.189776  |    0.030434     |   0\n",
      "      20181 |   0.035012  |    0.049757     |   2\n",
      "      20182 |   0.171208  |    0.038024     |   0\n",
      "      20183 |   0.185308  |    0.209881     |   1\n",
      "      20184 |   0.038749  |    0.078403     |   2\n",
      "      20185 |   0.044343  |    0.072291     |   2\n",
      "      20186 |   0.028272  |    0.075553     |   2\n",
      "      20187 |   0.185958  |    0.208644     |   1\n",
      "      20188 |   0.151033  |    0.225514     |   1\n",
      "      20189 |   0.216336  |    0.195091     |   1\n",
      "      20190 |   0.039467  |    0.045288     |   2\n",
      "      20191 |   0.052901  |    0.072151     |   2\n",
      "      20192 |   0.185773  |    0.025233     |   0\n",
      "      20193 |   0.054297  |    0.081435     |   2\n",
      "      20194 |   0.044689  |    0.039717     |   2\n",
      "      20195 |   0.141707  |    0.079006     |   0\n",
      "      20196 |   0.210525  |    0.261456     |   1\n",
      "      20197 |   0.130197  |    0.075032     |   0\n",
      "      20198 |   0.191744  |    0.071175     |   0\n",
      "      20199 |   0.021783  |    0.043488     |   2\n",
      "      20200 |   0.206889  |    0.194545     |   1\n",
      "      20201 |   0.190005  |    0.008733     |   0\n",
      "      20202 |   0.000026  |    0.078320     |   2\n",
      "      20203 |   0.181015  |    0.214708     |   1\n",
      "      20204 |   0.005455  |    0.071500     |   2\n",
      "      20205 |   0.154098  |    0.069329     |   0\n",
      "      20206 |   0.175971  |    0.223830     |   1\n",
      "      20207 |   0.065256  |    0.039561     |   2\n",
      "      20208 |   0.195721  |    0.073374     |   0\n",
      "      20209 |   0.188897  |    0.082659     |   0\n",
      "      20210 |   0.197033  |    0.336727     |   1\n",
      "      20211 |   0.038062  |    0.075262     |   2\n",
      "      20212 |   0.131993  |    0.307772     |   1\n",
      "      20213 |   0.057299  |    0.071749     |   2\n",
      "      20214 |   0.202296  |    0.071547     |   0\n",
      "      20215 |   0.207085  |    0.086495     |   0\n",
      "      20216 |   0.209611  |    0.119788     |   0\n",
      "      20217 |   0.250329  |    0.222778     |   1\n",
      "      20218 |   0.043325  |    0.037865     |   2\n",
      "      20219 |   0.017214  |    0.139766     |   2\n",
      "      20220 |   0.037565  |    0.042860     |   2\n",
      "      20221 |   0.167587  |    0.065380     |   0\n",
      "      20222 |   0.030492  |    0.090458     |   2\n",
      "      20223 |   0.198632  |    0.137298     |   1\n",
      "      20224 |   0.000026  |    0.080092     |   2\n",
      "      20225 |   0.156132  |    0.158955     |   1\n",
      "      20226 |   0.146198  |    0.047452     |   0\n",
      "      20227 |   0.187915  |    0.053160     |   0\n",
      "      20228 |   0.000026  |    0.051945     |   2\n",
      "      20229 |   0.000026  |    0.059912     |   2\n",
      "      20230 |   0.242734  |    0.154091     |   1\n",
      "      20231 |   0.215493  |    0.159460     |   1\n",
      "      20232 |   0.000026  |    0.037183     |   2\n",
      "      20233 |   0.208330  |    0.189022     |   1\n",
      "      20234 |   0.000026  |    0.042537     |   2\n",
      "      20235 |   0.210978  |    0.040655     |   0\n",
      "      20236 |   0.223663  |    0.060528     |   0\n",
      "      20237 |   0.000026  |    0.071241     |   2\n",
      "      20238 |   0.138870  |    0.014862     |   0\n",
      "      20239 |   0.188577  |    0.080181     |   0\n",
      "      20240 |   0.048755  |    0.020088     |   2\n",
      "      20241 |   0.161895  |    0.202429     |   1\n",
      "      20242 |   0.218512  |    0.078868     |   0\n",
      "      20243 |   0.050942  |    0.020100     |   2\n",
      "      20244 |   0.204905  |    0.186902     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 20245: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      20245 |   0.165557  |    0.119168     |   1\n",
      "      20246 |   0.051761  |    0.048568     |   2\n",
      "      20247 |   0.189345  |    0.185422     |   1\n",
      "      20248 |   0.157836  |    0.007854     |   0\n",
      "      20249 |   0.176587  |    0.082597     |   0\n",
      "      20250 |   0.036307  |    0.028145     |   2\n",
      "      20251 |   0.041471  |    0.047475     |   2\n",
      "      20252 |   0.156005  |    0.045003     |   0\n",
      "      20253 |   0.201030  |    0.058244     |   0\n",
      "      20254 |   0.183523  |    0.032569     |   0\n",
      "      20255 |   0.042016  |    0.097002     |   2\n",
      "      20256 |   0.199225  |    0.156772     |   1\n",
      "      20257 |   0.142260  |    0.028291     |   0\n",
      "      20258 |   0.179926  |    0.042940     |   0\n",
      "      20259 |   0.149459  |    0.046439     |   0\n",
      "      20260 |   0.145482  |    0.046466     |   0\n",
      "      20261 |   0.026826  |    0.121645     |   2\n",
      "      20262 |   0.165504  |    0.040541     |   0\n",
      "      20263 |   0.040328  |    0.080794     |   2\n",
      "      20264 |   0.182578  |    0.048109     |   0\n",
      "      20265 |   0.175456  |    0.278520     |   1\n",
      "      20266 |   0.047588  |    0.036494     |   2\n",
      "      20267 |   0.054714  |    0.122146     |   2\n",
      "      20268 |   0.185474  |    0.039376     |   0\n",
      "      20269 |   0.190848  |    0.382396     |   1\n",
      "      20270 |   0.214018  |    0.323652     |   1\n",
      "      20271 |   0.198616  |    0.121543     |   0\n",
      "      20272 |   0.047838  |    0.072002     |   2\n",
      "      20273 |   0.185297  |    0.080850     |   0\n",
      "      20274 |   0.204739  |    0.328745     |   1\n",
      "      20275 |   0.180253  |    0.247389     |   1\n",
      "      20276 |   0.022253  |    0.068695     |   2\n",
      "      20277 |   0.240048  |    0.296501     |   1\n",
      "      20278 |   0.000026  |    0.070808     |   2\n",
      "      20279 |   0.166892  |    0.272017     |   1\n",
      "      20280 |   0.168916  |    0.265989     |   1\n",
      "      20281 |   0.005425  |    0.088843     |   2\n",
      "      20282 |   0.156134  |    0.074492     |   0\n",
      "      20283 |   0.253386  |    0.270705     |   1\n",
      "      20284 |   0.169901  |    0.343353     |   1\n",
      "      20285 |   0.196953  |    0.038105     |   0\n",
      "      20286 |   0.185825  |    0.302400     |   1\n",
      "      20287 |   0.250318  |    0.046304     |   0\n",
      "      20288 |   0.205339  |    0.074096     |   0\n",
      "      20289 |   0.185871  |    0.056171     |   0\n",
      "      20290 |   0.186695  |    0.168768     |   1\n",
      "      20291 |   0.225359  |    0.072133     |   0\n",
      "      20292 |   0.168865  |    0.091514     |   0\n",
      "      20293 |   0.064838  |    0.015355     |   2\n",
      "      20294 |   0.038300  |    0.046347     |   2\n",
      "      20295 |   0.169458  |    0.088526     |   0\n",
      "      20296 |   0.171916  |    0.063229     |   0\n",
      "      20297 |   0.226601  |    0.202047     |   1\n",
      "      20298 |   0.159049  |    0.007996     |   0\n",
      "      20299 |   0.060891  |    0.039685     |   2\n",
      "      20300 |   0.254850  |    0.196564     |   1\n",
      "      20301 |   0.208881  |    0.029204     |   0\n",
      "      20302 |   0.044094  |    0.088162     |   2\n",
      "      20303 |   0.195618  |    0.027720     |   0\n",
      "      20304 |   0.206778  |    0.210265     |   1\n",
      "      20305 |   0.121090  |    0.157872     |   1\n",
      "      20306 |   0.156022  |    0.011504     |   0\n",
      "      20307 |   0.183926  |    0.219284     |   1\n",
      "      20308 |   0.195935  |    0.148187     |   1\n",
      "      20309 |   0.015681  |    0.004757     |   2\n",
      "      20310 |   0.035528  |    0.075976     |   2\n",
      "      20311 |   0.227239  |    0.156876     |   1\n",
      "      20312 |   0.174621  |    0.050840     |   0\n",
      "      20313 |   0.028695  |    0.037850     |   2\n",
      "      20314 |   0.166372  |    0.079206     |   0\n",
      "      20315 |   0.165291  |    0.015908     |   0\n",
      "      20316 |   0.210565  |    0.078060     |   0\n",
      "      20317 |   0.271294  |    0.143730     |   1\n",
      "      20318 |   0.000026  |    0.044046     |   2\n",
      "      20319 |   0.137481  |    0.208099     |   1\n",
      "      20320 |   0.197397  |    0.164939     |   1\n",
      "      20321 |   0.000026  |    0.020580     |   2\n",
      "      20322 |   0.180997  |    0.149685     |   1\n",
      "      20323 |   0.221740  |    0.187003     |   1\n",
      "      20324 |   0.185804  |    0.022309     |   0\n",
      "      20325 |   0.000026  |    0.070639     |   2\n",
      "      20326 |   0.198996  |    0.026641     |   0\n",
      "      20327 |   0.158362  |    0.072148     |   0\n",
      "      20328 |   0.000027  |    0.023780     |   2\n",
      "      20329 |   0.139173  |    0.196955     |   1\n",
      "      20330 |   0.000026  |    0.043790     |   2\n",
      "      20331 |   0.000026  |    0.038315     |   2\n",
      "      20332 |   0.046730  |    0.040377     |   2\n",
      "      20333 |   0.178362  |    0.179782     |   1\n",
      "      20334 |   0.183621  |    0.042784     |   0\n",
      "      20335 |   0.177728  |    0.045671     |   0\n",
      "      20336 |   0.280618  |    0.146155     |   1\n",
      "      20337 |   0.174509  |    0.080108     |   0\n",
      "      20338 |   0.194895  |    0.006927     |   0\n",
      "      20339 |   0.185687  |    0.082819     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 20341: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      20340 |   0.049686  |    0.026254     |   2\n",
      "      20341 |   0.049477  |    0.057778     |   2\n",
      "      20342 |   0.186383  |    0.160362     |   1\n",
      "      20343 |   0.033817  |    0.086442     |   2\n",
      "      20344 |   0.041458  |    0.008250     |   2\n",
      "      20345 |   0.159400  |    0.079792     |   0\n",
      "      20346 |   0.150788  |    0.194018     |   1\n",
      "      20347 |   0.041744  |    0.009465     |   2\n",
      "      20348 |   0.232832  |    0.189327     |   1\n",
      "      20349 |   0.142468  |    0.028282     |   0\n",
      "      20350 |   0.161580  |    0.074301     |   0\n",
      "      20351 |   0.165710  |    0.020666     |   0\n",
      "      20352 |   0.027078  |    0.050466     |   2\n",
      "      20353 |   0.155279  |    0.188420     |   1\n",
      "      20354 |   0.255281  |    0.142192     |   1\n",
      "      20355 |   0.039528  |    0.025689     |   2\n",
      "      20356 |   0.213547  |    0.070507     |   0\n",
      "      20357 |   0.164163  |    0.209194     |   1\n",
      "      20358 |   0.175229  |    0.140958     |   1\n",
      "      20359 |   0.048948  |    0.045152     |   2\n",
      "      20360 |   0.172597  |    0.196561     |   1\n",
      "      20361 |   0.204833  |    0.155871     |   1\n",
      "      20362 |   0.191972  |    0.270771     |   1\n",
      "      20363 |   0.215239  |    0.037832     |   0\n",
      "      20364 |   0.175616  |    0.076121     |   0\n",
      "      20365 |   0.227660  |    0.272473     |   1\n",
      "      20366 |   0.149407  |    0.075060     |   0\n",
      "      20367 |   0.132496  |    0.294557     |   1\n",
      "      20368 |   0.056426  |    0.071059     |   2\n",
      "      20369 |   0.219692  |    0.068107     |   0\n",
      "      20370 |   0.045321  |    0.074782     |   2\n",
      "      20371 |   0.197519  |    0.072052     |   0\n",
      "      20372 |   0.220956  |    0.074961     |   0\n",
      "      20373 |   0.019166  |    0.074302     |   2\n",
      "      20374 |   0.000026  |    0.082723     |   2\n",
      "      20375 |   0.165741  |    0.364128     |   1\n",
      "      20376 |   0.223276  |    0.071300     |   0\n",
      "      20377 |   0.005749  |    0.097108     |   2\n",
      "      20378 |   0.167934  |    0.263432     |   1\n",
      "      20379 |   0.242423  |    0.238518     |   1\n",
      "      20380 |   0.236489  |    0.293670     |   1\n",
      "      20381 |   0.181576  |    0.086855     |   0\n",
      "      20382 |   0.229954  |    0.373784     |   1\n",
      "      20383 |   0.183889  |    0.273688     |   1\n",
      "      20384 |   0.066214  |    0.073576     |   2\n",
      "      20385 |   0.038031  |    0.085413     |   2\n",
      "      20386 |   0.059092  |    0.118353     |   2\n",
      "      20387 |   0.257921  |    0.280449     |   1\n",
      "      20388 |   0.042155  |    0.039486     |   2\n",
      "      20389 |   0.194881  |    0.084318     |   0\n",
      "      20390 |   0.144658  |    0.342946     |   1\n",
      "      20391 |   0.152054  |    0.391938     |   1\n",
      "      20392 |   0.184006  |    0.038685     |   0\n",
      "      20393 |   0.015298  |    0.124299     |   2\n",
      "      20394 |   0.038800  |    0.077087     |   2\n",
      "      20395 |   0.200552  |    0.343538     |   1\n",
      "      20396 |   0.223774  |    0.044373     |   0\n",
      "      20397 |   0.262932  |    0.270633     |   1\n",
      "      20398 |   0.027711  |    0.068153     |   2\n",
      "      20399 |   0.175724  |    0.128720     |   0\n",
      "      20400 |   0.000026  |    0.069992     |   2\n",
      "      20401 |   0.144147  |    0.374122     |   1\n",
      "      20402 |   0.000026  |    0.037393     |   2\n",
      "      20403 |   0.000026  |    0.119486     |   2\n",
      "      20404 |   0.000027  |    0.058583     |   2\n",
      "      20405 |   0.000026  |    0.123360     |   2\n",
      "      20406 |   0.202546  |    0.293150     |   1\n",
      "      20407 |   0.167534  |    0.318985     |   1\n",
      "      20408 |   0.000026  |    0.044645     |   2\n",
      "      20409 |   0.184630  |    0.335414     |   1\n",
      "      20410 |   0.043916  |    0.069400     |   2\n",
      "      20411 |   0.187089  |    0.373293     |   1\n",
      "      20412 |   0.160493  |    0.301217     |   1\n",
      "      20413 |   0.048886  |    0.021288     |   2\n",
      "      20414 |   0.178901  |    0.072260     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 20416: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      20415 |   0.173842  |    0.031719     |   0\n",
      "      20416 |   0.046607  |    0.075517     |   2\n",
      "      20417 |   0.180950  |    0.142378     |   1\n",
      "      20418 |   0.241279  |    0.190323     |   1\n",
      "      20419 |   0.032665  |    0.024832     |   2\n",
      "      20420 |   0.039042  |    0.079815     |   2\n",
      "      20421 |   0.039268  |    0.023846     |   2\n",
      "      20422 |   0.229676  |    0.055913     |   0\n",
      "      20423 |   0.265872  |    0.047742     |   0\n",
      "      20424 |   0.202351  |    0.194869     |   1\n",
      "      20425 |   0.228679  |    0.020470     |   0\n",
      "      20426 |   0.026850  |    0.041144     |   2\n",
      "      20427 |   0.200572  |    0.039873     |   0\n",
      "      20428 |   0.038695  |    0.069930     |   2\n",
      "      20429 |   0.048458  |    0.040711     |   2\n",
      "      20430 |   0.054552  |    0.053090     |   2\n",
      "      20431 |   0.045005  |    0.045202     |   2\n",
      "      20432 |   0.021000  |    0.026722     |   2\n",
      "      20433 |   0.219491  |    0.206831     |   1\n",
      "      20434 |   0.194381  |    0.147245     |   1\n",
      "      20435 |   0.000026  |    0.019791     |   2\n",
      "      20436 |   0.153254  |    0.224852     |   1\n",
      "      20437 |   0.146253  |    0.158502     |   1\n",
      "      20438 |   0.005968  |    0.005411     |   2\n",
      "      20439 |   0.111490  |    0.044235     |   0\n",
      "      20440 |   0.062594  |    0.073652     |   2\n",
      "      20441 |   0.033974  |    0.024837     |   2\n",
      "      20442 |   0.057860  |    0.072544     |   2\n",
      "      20443 |   0.163828  |    0.049291     |   0\n",
      "      20444 |   0.041630  |    0.040592     |   2\n",
      "      20445 |   0.217239  |    0.197890     |   1\n",
      "      20446 |   0.198462  |    0.083277     |   1\n",
      "      20447 |   0.015447  |    0.041075     |   2\n",
      "      20448 |   0.190078  |    0.169332     |   1\n",
      "      20449 |   0.264040  |    0.133495     |   1\n",
      "      20450 |   0.034250  |    0.043000     |   2\n",
      "      20451 |   0.028189  |    0.074542     |   2\n",
      "      20452 |   0.189887  |    0.141889     |   1\n",
      "      20453 |   0.000026  |    0.044829     |   2\n",
      "      20454 |   0.163031  |    0.191614     |   1\n",
      "      20455 |   0.200962  |    0.148011     |   1\n",
      "      20456 |   0.000026  |    0.045257     |   2\n",
      "      20457 |   0.153688  |    0.150664     |   1\n",
      "      20458 |   0.208188  |    0.204859     |   1\n",
      "      20459 |   0.244578  |    0.135678     |   1\n",
      "      20460 |   0.000026  |    0.021050     |   2\n",
      "      20461 |   0.000026  |    0.077874     |   2\n",
      "      20462 |   0.190939  |    0.131876     |   1\n",
      "      20463 |   0.211677  |    0.006241     |   0\n",
      "      20464 |   0.191497  |    0.045611     |   0\n",
      "      20465 |   0.188459  |    0.091031     |   0\n",
      "      20466 |   0.227675  |    0.156315     |   1\n",
      "      20467 |   0.248085  |    0.141177     |   1\n",
      "      20468 |   0.201109  |    0.144682     |   1\n",
      "      20469 |   0.181558  |    0.138413     |   1\n",
      "      20470 |   0.162627  |    0.079788     |   0\n",
      "      20471 |   0.000026  |    0.022540     |   2\n",
      "      20472 |   0.165558  |    0.071153     |   0\n",
      "      20473 |   0.155474  |    0.025683     |   0\n",
      "      20474 |   0.151768  |    0.195931     |   1\n",
      "      20475 |   0.189892  |    0.052779     |   0\n",
      "      20476 |   0.000026  |    0.054365     |   2\n",
      "      20477 |   0.156379  |    0.152573     |   1\n",
      "      20478 |   0.043165  |    0.022123     |   2\n",
      "      20479 |   0.203758  |    0.078581     |   0\n",
      "      20480 |   0.178022  |    0.153370     |   1\n",
      "      20481 |   0.172847  |    0.074881     |   0\n",
      "      20482 |   0.205222  |    0.155695     |   1\n",
      "      20483 |   0.277286  |    0.099850     |   0\n",
      "      20484 |   0.205306  |    0.149546     |   1\n",
      "      20485 |   0.197020  |    0.008260     |   0\n",
      "      20486 |   0.218062  |    0.076319     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 20488: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      20487 |   0.048559  |    0.022344     |   2\n",
      "      20488 |   0.047595  |    0.070701     |   2\n",
      "      20489 |   0.034842  |    0.035912     |   2\n",
      "      20490 |   0.038489  |    0.051117     |   2\n",
      "      20491 |   0.180716  |    0.044024     |   0\n",
      "      20492 |   0.209093  |    0.080101     |   0\n",
      "      20493 |   0.153478  |    0.027355     |   0\n",
      "      20494 |   0.187869  |    0.217090     |   1\n",
      "      20495 |   0.041248  |    0.018357     |   2\n",
      "      20496 |   0.192721  |    0.187653     |   1\n",
      "      20497 |   0.177660  |    0.042674     |   0\n",
      "      20498 |   0.027067  |    0.083710     |   2\n",
      "      20499 |   0.177794  |    0.162618     |   1\n",
      "      20500 |   0.216899  |    0.045681     |   0\n",
      "      20501 |   0.046864  |    0.081565     |   2\n",
      "      20502 |   0.167062  |    0.153592     |   1\n",
      "      20503 |   0.034470  |    0.019095     |   2\n",
      "      20504 |   0.038409  |    0.080246     |   2\n",
      "      20505 |   0.176055  |    0.131979     |   1\n",
      "      20506 |   0.244245  |    0.150100     |   1\n",
      "      20507 |   0.177530  |    0.141367     |   1\n",
      "      20508 |   0.234691  |    0.157242     |   1\n",
      "      20509 |   0.040505  |    0.052240     |   2\n",
      "      20510 |   0.148014  |    0.047538     |   0\n",
      "      20511 |   0.026698  |    0.038306     |   2\n",
      "      20512 |   0.038235  |    0.074710     |   2\n",
      "      20513 |   0.240719  |    0.021982     |   0\n",
      "      20514 |   0.049469  |    0.046104     |   2\n",
      "      20515 |   0.185806  |    0.074336     |   0\n",
      "      20516 |   0.173142  |    0.043075     |   0\n",
      "      20517 |   0.052823  |    0.053452     |   2\n",
      "      20518 |   0.180872  |    0.135307     |   1\n",
      "      20519 |   0.184415  |    0.041822     |   0\n",
      "      20520 |   0.214454  |    0.074106     |   0\n",
      "      20521 |   0.041930  |    0.027167     |   2\n",
      "      20522 |   0.213951  |    0.072076     |   0\n",
      "      20523 |   0.019065  |    0.054548     |   2\n",
      "      20524 |   0.215135  |    0.204352     |   1\n",
      "      20525 |   0.000026  |    0.005623     |   2\n",
      "      20526 |   0.213885  |    0.076250     |   0\n",
      "      20527 |   0.274785  |    0.045335     |   0\n",
      "      20528 |   0.005515  |    0.072663     |   2\n",
      "      20529 |   0.068215  |    0.039094     |   2\n",
      "      20530 |   0.159829  |    0.074522     |   0\n",
      "      20531 |   0.033976  |    0.011940     |   2\n",
      "      20532 |   0.215894  |    0.212807     |   1\n",
      "      20533 |   0.188628  |    0.090339     |   1\n",
      "      20534 |   0.056292  |    0.073097     |   2\n",
      "      20535 |   0.164053  |    0.012743     |   0\n",
      "      20536 |   0.145769  |    0.209432     |   1\n",
      "      20537 |   0.187218  |    0.132963     |   1\n",
      "      20538 |   0.202590  |    0.108235     |   1\n",
      "      20539 |   0.183407  |    0.041674     |   0\n",
      "      20540 |   0.225163  |    0.148869     |   1\n",
      "      20541 |   0.041571  |    0.022591     |   2\n",
      "      20542 |   0.154515  |    0.191263     |   1\n",
      "      20543 |   0.016267  |    0.023892     |   2\n",
      "      20544 |   0.172647  |    0.201568     |   1\n",
      "      20545 |   0.149558  |    0.016419     |   0\n",
      "      20546 |   0.199705  |    0.073670     |   0\n",
      "      20547 |   0.213316  |    0.105383     |   1\n",
      "      20548 |   0.034711  |    0.041689     |   2\n",
      "      20549 |   0.028269  |    0.046275     |   2\n",
      "      20550 |   0.161301  |    0.205519     |   1\n",
      "      20551 |   0.000026  |    0.004120     |   2\n",
      "      20552 |   0.000026  |    0.025784     |   2\n",
      "      20553 |   0.000026  |    0.084367     |   2\n",
      "      20554 |   0.000026  |    0.023851     |   2\n",
      "      20555 |   0.000026  |    0.072757     |   2\n",
      "      20556 |   0.228107  |    0.042389     |   0\n",
      "      20557 |   0.182380  |    0.044850     |   0\n",
      "      20558 |   0.204318  |    0.175436     |   1\n",
      "      20559 |   0.193496  |    0.148532     |   1\n",
      "      20560 |   0.000026  |    0.042891     |   2\n",
      "      20561 |   0.146192  |    0.048342     |   0\n",
      "      20562 |   0.135240  |    0.169806     |   1\n",
      "      20563 |   0.135421  |    0.211973     |   1\n",
      "      20564 |   0.046416  |    0.029248     |   2\n",
      "      20565 |   0.048982  |    0.052851     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 20566: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      20566 |   0.190395  |    0.215508     |   1\n",
      "      20567 |   0.043435  |    0.011817     |   2\n",
      "      20568 |   0.161499  |    0.208557     |   1\n",
      "      20569 |   0.032943  |    0.055601     |   2\n",
      "      20570 |   0.037837  |    0.041345     |   2\n",
      "      20571 |   0.204655  |    0.138789     |   1\n",
      "      20572 |   0.142221  |    0.198640     |   1\n",
      "      20573 |   0.217186  |    0.004977     |   0\n",
      "      20574 |   0.182261  |    0.072459     |   0\n",
      "      20575 |   0.041647  |    0.042193     |   2\n",
      "      20576 |   0.027090  |    0.029383     |   2\n",
      "      20577 |   0.177672  |    0.072594     |   0\n",
      "      20578 |   0.231523  |    0.166457     |   1\n",
      "      20579 |   0.228109  |    0.142390     |   1\n",
      "      20580 |   0.159343  |    0.004590     |   0\n",
      "      20581 |   0.187299  |    0.076815     |   0\n",
      "      20582 |   0.202275  |    0.021605     |   0\n",
      "      20583 |   0.037894  |    0.073363     |   2\n",
      "      20584 |   0.149744  |    0.191488     |   1\n",
      "      20585 |   0.187088  |    0.022607     |   0\n",
      "      20586 |   0.048837  |    0.078493     |   2\n",
      "      20587 |   0.052866  |    0.044673     |   2\n",
      "      20588 |   0.253334  |    0.223008     |   1\n",
      "      20589 |   0.199460  |    0.159764     |   1\n",
      "      20590 |   0.180181  |    0.151265     |   1\n",
      "      20591 |   0.162440  |    0.006089     |   0\n",
      "      20592 |   0.155919  |    0.024704     |   0\n",
      "      20593 |   0.173760  |    0.074825     |   0\n",
      "      20594 |   0.175795  |    0.014367     |   0\n",
      "      20595 |   0.045561  |    0.077142     |   2\n",
      "      20596 |   0.235215  |    0.038553     |   0\n",
      "      20597 |   0.195387  |    0.145112     |   1\n",
      "      20598 |   0.020147  |    0.021806     |   2\n",
      "      20599 | \u001b[94m  0.000025\u001b[0m  |    0.044913     |   2\n",
      "      20600 |   0.005633  |    0.041051     |   2\n",
      "      20601 |   0.062708  |    0.085267     |   2\n",
      "      20602 |   0.157335  |    0.013468     |   0\n",
      "      20603 |   0.172692  |    0.056236     |   0\n",
      "      20604 |   0.203029  |    0.187972     |   1\n",
      "      20605 |   0.197298  |    0.009936     |   0\n",
      "      20606 |   0.035340  |    0.070746     |   2\n",
      "      20607 |   0.174727  |    0.031338     |   0\n",
      "      20608 |   0.200739  |    0.071927     |   0\n",
      "      20609 |   0.165045  |    0.042026     |   0\n",
      "      20610 |   0.058939  |    0.075252     |   2\n",
      "      20611 |   0.292292  |    0.127523     |   1\n",
      "      20612 |   0.040907  |    0.045789     |   2\n",
      "      20613 |   0.017225  |    0.044572     |   2\n",
      "      20614 |   0.260673  |    0.206078     |   1\n",
      "      20615 |   0.040431  |    0.003136     |   2\n",
      "      20616 |   0.031093  |    0.077464     |   2\n",
      "      20617 |   0.186345  |    0.149023     |   1\n",
      "      20618 | \u001b[94m  0.000025\u001b[0m  |    0.074109     |   2\n",
      "      20619 |   0.185761  |    0.045924     |   0\n",
      "      20620 | \u001b[94m  0.000025\u001b[0m  |    0.042753     |   2\n",
      "      20621 |   0.000025  |    0.076555     |   2\n",
      "      20622 |   0.000026  |    0.055330     |   2\n",
      "      20623 |   0.221943  |    0.170390     |   1\n",
      "      20624 |   0.181300  |    0.162088     |   1\n",
      "      20625 |   0.000025  |    0.027248     |   2\n",
      "      20626 |   0.196437  |    0.075640     |   0\n",
      "      20627 |   0.000025  |    0.027491     |   2\n",
      "      20628 |   0.172028  |    0.080982     |   0\n",
      "      20629 |   0.252441  |    0.142455     |   1\n",
      "      20630 |   0.044852  |    0.034307     |   2\n",
      "      20631 |   0.282362  |    0.207207     |   1\n",
      "      20632 |   0.196380  |    0.011241     |   0\n",
      "      20633 |   0.049307  |    0.087647     |   2\n",
      "      20634 |   0.304484  |    0.140043     |   1\n",
      "      20635 |   0.165284  |    0.200773     |   1\n",
      "      20636 |   0.217635  |    0.011540     |   0\n",
      "      20637 |   0.170426  |    0.073092     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 20639: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      20638 |   0.191178  |    0.034218     |   0\n",
      "      20639 |   0.158829  |    0.189148     |   1\n",
      "      20640 |   0.187131  |    0.158064     |   1\n",
      "      20641 |   0.181365  |    0.170286     |   1\n",
      "      20642 |   0.156033  |    0.276001     |   1\n",
      "      20643 |   0.166644  |    0.041393     |   0\n",
      "      20644 |   0.160323  |    0.075157     |   0\n",
      "      20645 |   0.200152  |    0.040990     |   0\n",
      "      20646 |   0.183718  |    0.086565     |   0\n",
      "      20647 |   0.042784  |    0.076353     |   2\n",
      "      20648 |   0.151788  |    0.246636     |   1\n",
      "      20649 |   0.152468  |    0.135769     |   1\n",
      "      20650 |   0.173781  |    0.045785     |   0\n",
      "      20651 |   0.180417  |    0.048568     |   0\n",
      "      20652 |   0.194559  |    0.025252     |   0\n",
      "      20653 |   0.195572  |    0.074182     |   0\n",
      "      20654 |   0.163327  |    0.031200     |   0\n",
      "      20655 |   0.222621  |    0.047013     |   0\n",
      "      20656 |   0.182377  |    0.046571     |   0\n",
      "      20657 |   0.152370  |    0.045712     |   0\n",
      "      20658 |   0.176571  |    0.051152     |   0\n",
      "      20659 |   0.144847  |    0.041232     |   0\n",
      "      20660 |   0.211682  |    0.076599     |   0\n",
      "      20661 |   0.036834  |    0.033919     |   2\n",
      "      20662 |   0.223443  |    0.152809     |   1\n",
      "      20663 |   0.167762  |    0.042733     |   0\n",
      "      20664 |   0.177882  |    0.081878     |   0\n",
      "      20665 |   0.184733  |    0.141091     |   1\n",
      "      20666 |   0.180001  |    0.163545     |   1\n",
      "      20667 |   0.037617  |    0.034111     |   2\n",
      "      20668 |   0.158104  |    0.075316     |   0\n",
      "      20669 |   0.208509  |    0.158542     |   1\n",
      "      20670 |   0.041059  |    0.032635     |   2\n",
      "      20671 |   0.170721  |    0.206250     |   1\n",
      "      20672 |   0.027240  |    0.023381     |   2\n",
      "      20673 |   0.174113  |    0.201525     |   1\n",
      "      20674 |   0.037841  |    0.066067     |   2\n",
      "      20675 |   0.205771  |    0.048518     |   0\n",
      "      20676 |   0.053442  |    0.041587     |   2\n",
      "      20677 |   0.056163  |    0.063570     |   2\n",
      "      20678 |   0.247691  |    0.185898     |   1\n",
      "      20679 |   0.044542  |    0.015447     |   2\n",
      "      20680 |   0.256280  |    0.193009     |   1\n",
      "      20681 |   0.194112  |    0.144997     |   1\n",
      "      20682 |   0.200872  |    0.194494     |   1\n",
      "      20683 |   0.201932  |    0.011358     |   0\n",
      "      20684 |   0.221898  |    0.080960     |   0\n",
      "      20685 |   0.225684  |    0.045056     |   0\n",
      "      20686 |   0.019524  |    0.037704     |   2\n",
      "      20687 | \u001b[94m  0.000025\u001b[0m  |    0.075827     |   2\n",
      "      20688 |   0.153412  |    0.215239     |   1\n",
      "      20689 |   0.193270  |    0.009071     |   0\n",
      "      20690 |   0.146122  |    0.085587     |   0\n",
      "      20691 |   0.006442  |    0.021885     |   2\n",
      "      20692 |   0.062656  |    0.072514     |   2\n",
      "      20693 |   0.037473  |    0.019113     |   2\n",
      "      20694 |   0.174363  |    0.090329     |   0\n",
      "      20695 |   0.153318  |    0.222686     |   1\n",
      "      20696 |   0.054515  |    0.054810     |   2\n",
      "      20697 |   0.197920  |    0.203620     |   1\n",
      "      20698 |   0.161667  |    0.156958     |   1\n",
      "      20699 |   0.159697  |    0.040219     |   0\n",
      "      20700 |   0.039394  |    0.073643     |   2\n",
      "      20701 |   0.135202  |    0.212125     |   1\n",
      "      20702 |   0.164390  |    0.159801     |   1\n",
      "      20703 |   0.182076  |    0.032436     |   0\n",
      "      20704 |   0.188913  |    0.072442     |   0\n",
      "      20705 |   0.180708  |    0.020596     |   0\n",
      "      20706 |   0.187941  |    0.086402     |   0\n",
      "      20707 |   0.205924  |    0.150792     |   1\n",
      "      20708 |   0.164326  |    0.231484     |   1\n",
      "      20709 |   0.158666  |    0.129129     |   1\n",
      "      20710 |   0.183942  |    0.105773     |   1\n",
      "      20711 |   0.188274  |    0.046801     |   0\n",
      "      20712 |   0.172677  |    0.085966     |   0\n",
      "      20713 |   0.171829  |    0.009863     |   0\n",
      "      20714 |   0.016021  |    0.063732     |   2\n",
      "      20715 |   0.037642  |    0.041884     |   2\n",
      "      20716 |   0.157061  |    0.070538     |   0\n",
      "      20717 |   0.192319  |    0.059317     |   0\n",
      "      20718 |   0.170911  |    0.200682     |   1\n",
      "      20719 |   0.028138  |    0.027848     |   2\n",
      "      20720 |   0.198659  |    0.074133     |   0\n",
      "      20721 | \u001b[94m  0.000025\u001b[0m  |    0.016304     |   2\n",
      "      20722 | \u001b[94m  0.000025\u001b[0m  |    0.122272     |   2\n",
      "      20723 |   0.000025  |    0.020925     |   2\n",
      "      20724 |   0.135527  |    0.094747     |   0\n",
      "      20725 |   0.179327  |    0.285849     |   1\n",
      "      20726 |   0.173483  |    0.079004     |   0\n",
      "      20727 |   0.000025  |    0.075461     |   2\n",
      "      20728 | \u001b[94m  0.000025\u001b[0m  |    0.074249     |   2\n",
      "      20729 | \u001b[94m  0.000025\u001b[0m  |    0.039503     |   2\n",
      "      20730 |   0.047072  |    0.072905     |   2\n",
      "      20731 |   0.165429  |    0.046657     |   0\n",
      "      20732 |   0.049719  |    0.042311     |   2\n",
      "      20733 |   0.171430  |    0.247614     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 20734: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      20734 |   0.052115  |    0.008448     |   2\n",
      "      20735 |   0.036543  |    0.136538     |   2\n",
      "      20736 |   0.207317  |    0.273611     |   1\n",
      "      20737 |   0.197919  |    0.046000     |   0\n",
      "      20738 |   0.173517  |    0.252535     |   1\n",
      "      20739 |   0.322940  |    0.250206     |   1\n",
      "      20740 |   0.181198  |    0.076908     |   0\n",
      "      20741 |   0.038255  |    0.072661     |   2\n",
      "      20742 |   0.204477  |    0.041562     |   0\n",
      "      20743 |   0.237504  |    0.281311     |   1\n",
      "      20744 |   0.189809  |    0.185350     |   1\n",
      "      20745 |   0.142191  |    0.071569     |   0\n",
      "      20746 |   0.039592  |    0.046352     |   2\n",
      "      20747 |   0.187157  |    0.073741     |   0\n",
      "      20748 |   0.027045  |    0.043178     |   2\n",
      "      20749 |   0.152267  |    0.056882     |   0\n",
      "      20750 |   0.177417  |    0.023679     |   0\n",
      "      20751 |   0.190528  |    0.081629     |   0\n",
      "      20752 |   0.164068  |    0.010631     |   0\n",
      "      20753 |   0.191370  |    0.080140     |   0\n",
      "      20754 |   0.250370  |    0.076650     |   0\n",
      "      20755 |   0.037606  |    0.056570     |   2\n",
      "      20756 |   0.206560  |    0.214117     |   1\n",
      "      20757 |   0.161053  |    0.152700     |   1\n",
      "      20758 |   0.163173  |    0.075156     |   0\n",
      "      20759 |   0.171214  |    0.048054     |   0\n",
      "      20760 |   0.182990  |    0.073165     |   0\n",
      "      20761 |   0.209366  |    0.271214     |   1\n",
      "      20762 |   0.172300  |    0.226156     |   1\n",
      "      20763 |   0.050626  |    0.072287     |   2\n",
      "      20764 |   0.183705  |    0.119123     |   0\n",
      "      20765 |   0.162802  |    0.272869     |   1\n",
      "      20766 |   0.055725  |    0.045322     |   2\n",
      "      20767 |   0.181600  |    0.044116     |   0\n",
      "      20768 |   0.205406  |    0.319513     |   1\n",
      "      20769 |   0.173797  |    0.046577     |   0\n",
      "      20770 |   0.220455  |    0.269873     |   1\n",
      "      20771 |   0.148188  |    0.220868     |   1\n",
      "      20772 |   0.229646  |    0.241113     |   1\n",
      "      20773 |   0.047121  |    0.068666     |   2\n",
      "      20774 |   0.198990  |    0.119259     |   0\n",
      "      20775 |   0.156942  |    0.076809     |   0\n",
      "      20776 |   0.189639  |    0.014244     |   0\n",
      "      20777 |   0.022933  |    0.084757     |   2\n",
      "      20778 |   0.209026  |    0.192468     |   1\n",
      "      20779 |   0.000025  |    0.026469     |   2\n",
      "      20780 |   0.005163  |    0.050775     |   2\n",
      "      20781 |   0.177783  |    0.044064     |   0\n",
      "      20782 |   0.233303  |    0.079606     |   0\n",
      "      20783 |   0.169362  |    0.212112     |   1\n",
      "      20784 |   0.065098  |    0.003743     |   2\n",
      "      20785 |   0.035289  |    0.048674     |   2\n",
      "      20786 |   0.057780  |    0.063400     |   2\n",
      "      20787 |   0.170640  |    0.074504     |   0\n",
      "      20788 |   0.122810  |    0.009206     |   0\n",
      "      20789 |   0.191323  |    0.100739     |   0\n",
      "      20790 |   0.258910  |    0.137119     |   1\n",
      "      20791 |   0.184061  |    0.191436     |   1\n",
      "      20792 |   0.039637  |    0.004933     |   2\n",
      "      20793 |   0.242340  |    0.188989     |   1\n",
      "      20794 |   0.178277  |    0.088576     |   0\n",
      "      20795 |   0.210512  |    0.213594     |   1\n",
      "      20796 |   0.015197  |    0.040655     |   2\n",
      "      20797 |   0.178130  |    0.299413     |   1\n",
      "      20798 |   0.035978  |    0.022198     |   2\n",
      "      20799 |   0.176267  |    0.120827     |   0\n",
      "      20800 |   0.029504  |    0.038641     |   2\n",
      "      20801 |   0.237677  |    0.369081     |   1\n",
      "      20802 |   0.190775  |    0.069580     |   0\n",
      "      20803 |   0.212995  |    0.421003     |   1\n",
      "      20804 |   0.205106  |    0.334655     |   1\n",
      "      20805 |   0.000025  |    0.068485     |   2\n",
      "      20806 |   0.228666  |    0.269684     |   1\n",
      "      20807 |   0.000025  |    0.078579     |   2\n",
      "      20808 |   0.000025  |    0.068090     |   2\n",
      "      20809 |   0.000025  |    0.075594     |   2\n",
      "      20810 |   0.000025  |    0.073096     |   2\n",
      "      20811 |   0.195887  |    0.073522     |   0\n",
      "      20812 |   0.182790  |    0.068356     |   0\n",
      "      20813 |   0.222978  |    0.322835     |   1\n",
      "      20814 |   0.000025  |    0.071227     |   2\n",
      "      20815 |   0.045148  |    0.080366     |   2\n",
      "      20816 |   0.051269  |    0.069832     |   2\n",
      "      20817 |   0.191342  |    0.322711     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 20818: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      20818 |   0.222947  |    0.319502     |   1\n",
      "      20819 |   0.217981  |    0.071111     |   0\n",
      "      20820 |   0.178625  |    0.320052     |   1\n",
      "      20821 |   0.045451  |    0.068525     |   2\n",
      "      20822 |   0.179980  |    0.073495     |   0\n",
      "      20823 |   0.034086  |    0.071880     |   2\n",
      "      20824 |   0.038840  |    0.120147     |   2\n",
      "      20825 |   0.149902  |    0.020039     |   0\n",
      "      20826 |   0.141165  |    0.353573     |   1\n",
      "      20827 |   0.194223  |    0.133249     |   1\n",
      "      20828 |   0.242061  |    0.026309     |   0\n",
      "      20829 |   0.191480  |    0.078516     |   0\n",
      "      20830 |   0.039074  |    0.009573     |   2\n",
      "      20831 |   0.026269  |    0.091973     |   2\n",
      "      20832 |   0.038271  |    0.034653     |   2\n",
      "      20833 |   0.188843  |    0.203338     |   1\n",
      "      20834 |   0.191039  |    0.130820     |   1\n",
      "      20835 |   0.155584  |    0.040299     |   0\n",
      "      20836 |   0.175413  |    0.073023     |   0\n",
      "      20837 |   0.052049  |    0.037454     |   2\n",
      "      20838 |   0.197005  |    0.042690     |   0\n",
      "      20839 |   0.142493  |    0.045318     |   0\n",
      "      20840 |   0.174449  |    0.154033     |   1\n",
      "      20841 |   0.055097  |    0.043710     |   2\n",
      "      20842 |   0.219468  |    0.175610     |   1\n",
      "      20843 |   0.044779  |    0.011854     |   2\n",
      "      20844 |   0.187033  |    0.211385     |   1\n",
      "      20845 |   0.208430  |    0.142523     |   1\n",
      "      20846 |   0.192775  |    0.072900     |   0\n",
      "      20847 |   0.172743  |    0.016680     |   0\n",
      "      20848 |   0.136687  |    0.235565     |   1\n",
      "      20849 |   0.192137  |    0.105775     |   1\n",
      "      20850 |   0.183701  |    0.072526     |   0\n",
      "      20851 |   0.021595  |    0.020495     |   2\n",
      "      20852 |   0.255949  |    0.211984     |   1\n",
      "      20853 |   0.205859  |    0.187139     |   1\n",
      "      20854 | \u001b[94m  0.000025\u001b[0m  |    0.004635     |   2\n",
      "      20855 |   0.249916  |    0.259316     |   1\n",
      "      20856 |   0.160052  |    0.237524     |   1\n",
      "      20857 |   0.166358  |    0.072775     |   0\n",
      "      20858 |   0.201300  |    0.290812     |   1\n",
      "      20859 |   0.005457  |    0.070732     |   2\n",
      "      20860 |   0.059097  |    0.070007     |   2\n",
      "      20861 |   0.162194  |    0.068793     |   0\n",
      "      20862 |   0.235030  |    0.279157     |   1\n",
      "      20863 |   0.205510  |    0.073873     |   0\n",
      "      20864 |   0.179307  |    0.076782     |   0\n",
      "      20865 |   0.162884  |    0.297495     |   1\n",
      "      20866 |   0.217912  |    0.294010     |   1\n",
      "      20867 |   0.034134  |    0.073008     |   2\n",
      "      20868 |   0.054849  |    0.099236     |   2\n",
      "      20869 |   0.162043  |    0.069193     |   0\n",
      "      20870 |   0.204753  |    0.375272     |   1\n",
      "      20871 |   0.145216  |    0.276644     |   1\n",
      "      20872 |   0.189228  |    0.122557     |   0\n",
      "      20873 |   0.174208  |    0.320568     |   1\n",
      "      20874 |   0.209683  |    0.289482     |   1\n",
      "      20875 |   0.230919  |    0.269080     |   1\n",
      "      20876 |   0.176282  |    0.074018     |   0\n",
      "      20877 |   0.200836  |    0.346328     |   1\n",
      "      20878 |   0.215349  |    0.074110     |   0\n",
      "      20879 |   0.191155  |    0.084673     |   0\n",
      "      20880 |   0.152668  |    0.347257     |   1\n",
      "      20881 |   0.042851  |    0.089265     |   2\n",
      "      20882 |   0.238382  |    0.334317     |   1\n",
      "      20883 |   0.181081  |    0.079942     |   0\n",
      "      20884 |   0.180553  |    0.153681     |   1\n",
      "      20885 |   0.016333  |    0.040942     |   2\n",
      "      20886 |   0.141046  |    0.206446     |   1\n",
      "      20887 |   0.201101  |    0.044270     |   0\n",
      "      20888 |   0.193409  |    0.088463     |   0\n",
      "      20889 |   0.209960  |    0.030071     |   0\n",
      "      20890 |   0.202130  |    0.215651     |   1\n",
      "      20891 |   0.034962  |    0.043906     |   2\n",
      "      20892 |   0.027430  |    0.081350     |   2\n",
      "      20893 |   0.182477  |    0.170403     |   1\n",
      "      20894 |   0.250456  |    0.160087     |   1\n",
      "      20895 |   0.144719  |    0.012816     |   0\n",
      "      20896 |   0.196341  |    0.231199     |   1\n",
      "      20897 |   0.209270  |    0.010625     |   0\n",
      "      20898 |   0.207835  |    0.163580     |   1\n",
      "      20899 |   0.162291  |    0.153081     |   1\n",
      "      20900 | \u001b[94m  0.000025\u001b[0m  |    0.004233     |   2\n",
      "      20901 | \u001b[94m  0.000025\u001b[0m  |    0.048277     |   2\n",
      "      20902 |   0.179146  |    0.041070     |   0\n",
      "      20903 |   0.213467  |    0.198831     |   1\n",
      "      20904 |   0.181645  |    0.214306     |   1\n",
      "      20905 |   0.168216  |    0.109768     |   1\n",
      "      20906 |   0.000025  |    0.009029     |   2\n",
      "      20907 |   0.000025  |    0.080413     |   2\n",
      "      20908 |   0.200973  |    0.186878     |   1\n",
      "      20909 |   0.223571  |    0.006890     |   0\n",
      "      20910 |   0.000025  |    0.071922     |   2\n",
      "      20911 |   0.166043  |    0.016297     |   0\n",
      "      20912 |   0.204064  |    0.080381     |   0\n",
      "      20913 |   0.190586  |    0.205684     |   1\n",
      "      20914 |   0.218948  |    0.141311     |   1\n",
      "      20915 |   0.138930  |    0.006185     |   0\n",
      "      20916 |   0.222930  |    0.183683     |   1\n",
      "      20917 |   0.172538  |    0.078914     |   0\n",
      "      20918 |   0.175147  |    0.029056     |   0\n",
      "      20919 |   0.186169  |    0.075480     |   0\n",
      "      20920 | \u001b[94m  0.000024\u001b[0m  |    0.045189     |   2\n",
      "      20921 |   0.046678  |    0.037518     |   2\n",
      "      20922 |   0.178785  |    0.038970     |   0\n",
      "      20923 |   0.049073  |    0.047452     |   2\n",
      "      20924 |   0.207203  |    0.091114     |   0\n",
      "      20925 |   0.205722  |    0.158129     |   1\n",
      "      20926 |   0.215986  |    0.007271     |   0\n",
      "      20927 |   0.206665  |    0.077726     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 20928: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      20928 |   0.177613  |    0.031742     |   0\n",
      "      20929 |   0.045054  |    0.041206     |   2\n",
      "      20930 |   0.183703  |    0.195597     |   1\n",
      "      20931 |   0.187243  |    0.024766     |   0\n",
      "      20932 |   0.165862  |    0.182290     |   1\n",
      "      20933 |   0.172864  |    0.013232     |   0\n",
      "      20934 |   0.189707  |    0.087596     |   0\n",
      "      20935 |   0.167903  |    0.021056     |   0\n",
      "      20936 |   0.034314  |    0.077895     |   2\n",
      "      20937 |   0.039797  |    0.017020     |   2\n",
      "      20938 |   0.041682  |    0.046343     |   2\n",
      "      20939 |   0.180783  |    0.188429     |   1\n",
      "      20940 |   0.026602  |    0.007889     |   2\n",
      "      20941 |   0.039829  |    0.086814     |   2\n",
      "      20942 |   0.051094  |    0.027318     |   2\n",
      "      20943 |   0.055396  |    0.074918     |   2\n",
      "      20944 |   0.167806  |    0.016656     |   0\n",
      "      20945 |   0.043687  |    0.076135     |   2\n",
      "      20946 |   0.146122  |    0.025698     |   0\n",
      "      20947 |   0.161538  |    0.206013     |   1\n",
      "      20948 |   0.020827  |    0.042179     |   2\n",
      "      20949 |   0.208940  |    0.050171     |   0\n",
      "      20950 |   0.159647  |    0.179290     |   1\n",
      "      20951 |   0.223068  |    0.038666     |   0\n",
      "      20952 |   0.000024  |    0.046274     |   2\n",
      "      20953 |   0.005339  |    0.039630     |   2\n",
      "      20954 |   0.064092  |    0.054070     |   2\n",
      "      20955 |   0.037435  |    0.051586     |   2\n",
      "      20956 |   0.055958  |    0.050971     |   2\n",
      "      20957 |   0.205715  |    0.193496     |   1\n",
      "      20958 |   0.149712  |    0.009092     |   0\n",
      "      20959 |   0.170477  |    0.071084     |   0\n",
      "      20960 |   0.178621  |    0.024834     |   0\n",
      "      20961 |   0.041338  |    0.082397     |   2\n",
      "      20962 |   0.018117  |    0.029488     |   2\n",
      "      20963 |   0.183709  |    0.204778     |   1\n",
      "      20964 |   0.035187  |    0.014573     |   2\n",
      "      20965 |   0.031039  |    0.080049     |   2\n",
      "      20966 |   0.208026  |    0.137979     |   1\n",
      "      20967 |   0.000024  |    0.029158     |   2\n",
      "      20968 |   0.000024  |    0.080654     |   2\n",
      "      20969 |   0.000024  |    0.023602     |   2\n",
      "      20970 |   0.198361  |    0.156179     |   1\n",
      "      20971 |   0.207256  |    0.147494     |   1\n",
      "      20972 |   0.000025  |    0.041031     |   2\n",
      "      20973 |   0.172634  |    0.082260     |   0\n",
      "      20974 |   0.000024  |    0.008698     |   2\n",
      "      20975 |   0.156649  |    0.197029     |   1\n",
      "      20976 |   0.246641  |    0.142161     |   1\n",
      "      20977 |   0.165055  |    0.040827     |   0\n",
      "      20978 |   0.000024  |    0.073437     |   2\n",
      "      20979 |   0.202026  |    0.021631     |   0\n",
      "      20980 |   0.043901  |    0.083294     |   2\n",
      "      20981 |   0.200174  |    0.138144     |   1\n",
      "      20982 |   0.048563  |    0.048465     |   2\n",
      "      20983 |   0.182185  |    0.076350     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 20984: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      20984 |   0.042754  |    0.007877     |   2\n",
      "      20985 |   0.221310  |    0.203533     |   1\n",
      "      20986 |   0.199004  |    0.049890     |   0\n",
      "      20987 |   0.211321  |    0.155729     |   1\n",
      "      20988 |   0.171218  |    0.012162     |   0\n",
      "      20989 |   0.178772  |    0.079624     |   0\n",
      "      20990 |   0.032817  |    0.014936     |   2\n",
      "      20991 |   0.198224  |    0.186420     |   1\n",
      "      20992 |   0.232002  |    0.019384     |   0\n",
      "      20993 |   0.189679  |    0.076918     |   0\n",
      "      20994 |   0.038512  |    0.038743     |   2\n",
      "      20995 |   0.040710  |    0.049818     |   2\n",
      "      20996 |   0.026223  |    0.050935     |   2\n",
      "      20997 |   0.204064  |    0.153857     |   1\n",
      "      20998 |   0.199404  |    0.194639     |   1\n",
      "      20999 |   0.179366  |    0.167421     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 21000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 21000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      21000 |   0.191694  |    0.028777     |   0\n",
      "      21001 |   0.043124  |    0.079380     |   2\n",
      "      21002 |   0.198768  |    0.141819     |   1\n",
      "      21003 |   0.179602  |    0.076681     |   0\n",
      "      21004 |   0.032196  |    0.018293     |   2\n",
      "      21005 |   0.167879  |    0.076238     |   0\n",
      "      21006 |   0.037895  |    0.024609     |   2\n",
      "      21007 |   0.194151  |    0.074463     |   0\n",
      "      21008 |   0.175133  |    0.022326     |   0\n",
      "      21009 |   0.156085  |    0.217763     |   1\n",
      "      21010 |   0.193257  |    0.146741     |   1\n",
      "      21011 |   0.204016  |    0.144270     |   1\n",
      "      21012 |   0.179880  |    0.145080     |   1\n",
      "      21013 |   0.249168  |    0.075768     |   0\n",
      "      21014 |   0.263944  |    0.033869     |   0\n",
      "      21015 |   0.231258  |    0.079268     |   0\n",
      "      21016 |   0.197709  |    0.100942     |   1\n",
      "      21017 |   0.040037  |    0.049481     |   2\n",
      "      21018 |   0.244649  |    0.146576     |   1\n",
      "      21019 |   0.182509  |    0.039204     |   0\n",
      "      21020 |   0.131532  |    0.049297     |   0\n",
      "      21021 |   0.026543  |    0.035018     |   2\n",
      "      21022 |   0.147708  |    0.051098     |   0\n",
      "      21023 |   0.182441  |    0.044874     |   0\n",
      "      21024 |   0.039013  |    0.049246     |   2\n",
      "      21025 |   0.131804  |    0.045100     |   0\n",
      "      21026 |   0.050103  |    0.083915     |   2\n",
      "      21027 |   0.255074  |    0.153597     |   1\n",
      "      21028 |   0.056514  |    0.007440     |   2\n",
      "      21029 |   0.043579  |    0.083003     |   2\n",
      "      21030 |   0.021448  |    0.030619     |   2\n",
      "      21031 |   0.207509  |    0.040248     |   0\n",
      "      21032 |   0.149024  |    0.080855     |   0\n",
      "      21033 |   0.173229  |    0.012874     |   0\n",
      "      21034 | \u001b[94m  0.000024\u001b[0m  |    0.080805     |   2\n",
      "      21035 |   0.005356  |    0.007997     |   2\n",
      "      21036 |   0.060575  |    0.081961     |   2\n",
      "      21037 |   0.035900  |    0.024942     |   2\n",
      "      21038 |   0.234657  |    0.193246     |   1\n",
      "      21039 |   0.058395  |    0.029760     |   2\n",
      "      21040 |   0.261827  |    0.175592     |   1\n",
      "      21041 |   0.123970  |    0.148399     |   1\n",
      "      21042 |   0.042083  |    0.039996     |   2\n",
      "      21043 |   0.141713  |    0.044428     |   0\n",
      "      21044 |   0.018027  |    0.095273     |   2\n",
      "      21045 |   0.145522  |    0.138556     |   1\n",
      "      21046 |   0.175859  |    0.152502     |   1\n",
      "      21047 |   0.033387  |    0.071863     |   2\n",
      "      21048 |   0.154019  |    0.179284     |   1\n",
      "      21049 |   0.149872  |    0.145106     |   1\n",
      "      21050 |   0.171572  |    0.150572     |   1\n",
      "      21051 |   0.029460  |    0.044741     |   2\n",
      "      21052 |   0.000024  |    0.071401     |   2\n",
      "      21053 |   0.197093  |    0.142860     |   1\n",
      "      21054 |   0.000024  |    0.050598     |   2\n",
      "      21055 |   0.206101  |    0.044071     |   0\n",
      "      21056 |   0.197754  |    0.078715     |   0\n",
      "      21057 |   0.000024  |    0.031521     |   2\n",
      "      21058 |   0.000025  |    0.048625     |   2\n",
      "      21059 |   0.000024  |    0.042836     |   2\n",
      "      21060 |   0.000024  |    0.039995     |   2\n",
      "      21061 |   0.160605  |    0.048517     |   0\n",
      "      21062 |   0.146058  |    0.179035     |   1\n",
      "      21063 |   0.046190  |    0.007508     |   2\n",
      "      21064 |   0.200221  |    0.073324     |   0\n",
      "      21065 |   0.217119  |    0.044719     |   0\n",
      "      21066 |   0.161776  |    0.047142     |   0\n",
      "      21067 |   0.200560  |    0.192789     |   1\n",
      "      21068 |   0.155082  |    0.078951     |   0\n",
      "      21069 |   0.181282  |    0.030245     |   0\n",
      "      21070 |   0.159440  |    0.162028     |   1\n",
      "      21071 |   0.050446  |    0.043083     |   2\n",
      "      21072 |   0.218291  |    0.186748     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 21073: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      21073 |   0.141297  |    0.013089     |   0\n",
      "      21074 |   0.160997  |    0.076800     |   0\n",
      "      21075 |   0.199873  |    0.022863     |   0\n",
      "      21076 |   0.152059  |    0.058811     |   0\n",
      "      21077 |   0.046878  |    0.046292     |   2\n",
      "      21078 |   0.033285  |    0.049429     |   2\n",
      "      21079 |   0.172369  |    0.184728     |   1\n",
      "      21080 |   0.147598  |    0.004882     |   0\n",
      "      21081 |   0.162369  |    0.205874     |   1\n",
      "      21082 |   0.158666  |    0.010537     |   0\n",
      "      21083 |   0.196183  |    0.082831     |   0\n",
      "      21084 |   0.164565  |    0.027806     |   0\n",
      "      21085 |   0.038806  |    0.064459     |   2\n",
      "      21086 |   0.147506  |    0.035626     |   0\n",
      "      21087 |   0.180618  |    0.046118     |   0\n",
      "      21088 |   0.209878  |    0.188217     |   1\n",
      "      21089 |   0.042582  |    0.027204     |   2\n",
      "      21090 |   0.027254  |    0.043678     |   2\n",
      "      21091 |   0.039599  |    0.039300     |   2\n",
      "      21092 |   0.052242  |    0.078496     |   2\n",
      "      21093 |   0.237589  |    0.136500     |   1\n",
      "      21094 |   0.204100  |    0.011167     |   0\n",
      "      21095 |   0.053185  |    0.099484     |   2\n",
      "      21096 |   0.218274  |    0.146037     |   1\n",
      "      21097 |   0.166451  |    0.031114     |   0\n",
      "      21098 |   0.231281  |    0.197893     |   1\n",
      "      21099 |   0.044957  |    0.005250     |   2\n",
      "      21100 |   0.141118  |    0.046579     |   0\n",
      "      21101 |   0.178893  |    0.144732     |   1\n",
      "      21102 |   0.174776  |    0.075370     |   0\n",
      "      21103 |   0.021493  |    0.022751     |   2\n",
      "      21104 |   0.197165  |    0.194687     |   1\n",
      "      21105 |   0.000024  |    0.010702     |   2\n",
      "      21106 |   0.110208  |    0.075308     |   0\n",
      "      21107 |   0.193791  |    0.038357     |   0\n",
      "      21108 |   0.005282  |    0.041899     |   2\n",
      "      21109 |   0.061322  |    0.040180     |   2\n",
      "      21110 |   0.152507  |    0.079667     |   0\n",
      "      21111 |   0.034198  |    0.028342     |   2\n",
      "      21112 |   0.056159  |    0.060639     |   2\n",
      "      21113 |   0.039483  |    0.037915     |   2\n",
      "      21114 |   0.186845  |    0.052503     |   0\n",
      "      21115 |   0.192060  |    0.196588     |   1\n",
      "      21116 |   0.016317  |    0.009302     |   2\n",
      "      21117 |   0.034465  |    0.083687     |   2\n",
      "      21118 |   0.296383  |    0.155983     |   1\n",
      "      21119 |   0.154624  |    0.043787     |   0\n",
      "      21120 |   0.173198  |    0.074968     |   0\n",
      "      21121 |   0.260875  |    0.153670     |   1\n",
      "      21122 |   0.028440  |    0.005189     |   2\n",
      "      21123 |   0.207825  |    0.047112     |   0\n",
      "      21124 |   0.196189  |    0.225371     |   1\n",
      "      21125 |   0.212507  |    0.005309     |   0\n",
      "      21126 |   0.211445  |    0.154269     |   1\n",
      "      21127 |   0.000024  |    0.051894     |   2\n",
      "      21128 |   0.000024  |    0.043032     |   2\n",
      "      21129 |   0.176583  |    0.046758     |   0\n",
      "      21130 |   0.000024  |    0.045116     |   2\n",
      "      21131 |   0.000024  |    0.046612     |   2\n",
      "      21132 |   0.000024  |    0.042266     |   2\n",
      "      21133 |   0.189943  |    0.049135     |   0\n",
      "      21134 |   0.191145  |    0.056649     |   0\n",
      "      21135 |   0.250606  |    0.158855     |   1\n",
      "      21136 |   0.000024  |    0.031682     |   2\n",
      "      21137 |   0.235352  |    0.151092     |   1\n",
      "      21138 |   0.197480  |    0.196843     |   1\n",
      "      21139 |   0.044048  |    0.011408     |   2\n",
      "      21140 |   0.200914  |    0.082994     |   0\n",
      "      21141 |   0.267329  |    0.142951     |   1\n",
      "      21142 |   0.211147  |    0.143363     |   1\n",
      "      21143 |   0.048814  |    0.036896     |   2\n",
      "      21144 |   0.192456  |    0.078442     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 21145: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      21145 |   0.041574  |    0.014576     |   2\n",
      "      21146 |   0.145335  |    0.213952     |   1\n",
      "      21147 |   0.032039  |    0.005670     |   2\n",
      "      21148 |   0.175334  |    0.074852     |   0\n",
      "      21149 |   0.036006  |    0.025689     |   2\n",
      "      21150 |   0.037593  |    0.076448     |   2\n",
      "      21151 |   0.233877  |    0.021578     |   0\n",
      "      21152 |   0.186823  |    0.045552     |   0\n",
      "      21153 |   0.026764  |    0.076285     |   2\n",
      "      21154 |   0.153089  |    0.151402     |   1\n",
      "      21155 |   0.201028  |    0.022754     |   0\n",
      "      21156 |   0.190736  |    0.082362     |   0\n",
      "      21157 |   0.200145  |    0.151719     |   1\n",
      "      21158 |   0.161200  |    0.153699     |   1\n",
      "      21159 |   0.257091  |    0.142836     |   1\n",
      "      21160 |   0.039694  |    0.047806     |   2\n",
      "      21161 |   0.167187  |    0.144809     |   1\n",
      "      21162 |   0.054101  |    0.030385     |   2\n",
      "      21163 |   0.238816  |    0.202080     |   1\n",
      "      21164 |   0.184557  |    0.149446     |   1\n",
      "      21165 |   0.234254  |    0.055637     |   0\n",
      "      21166 |   0.225305  |    0.140115     |   1\n",
      "      21167 |   0.163084  |    0.021826     |   0\n",
      "      21168 |   0.238721  |    0.204582     |   1\n",
      "      21169 |   0.161423  |    0.106250     |   1\n",
      "      21170 |   0.050969  |    0.077244     |   2\n",
      "      21171 |   0.041801  |    0.030145     |   2\n",
      "      21172 |   0.170822  |    0.045681     |   0\n",
      "      21173 |   0.223184  |    0.190170     |   1\n",
      "      21174 |   0.021347  |    0.008859     |   2\n",
      "      21175 |   0.160365  |    0.191443     |   1\n",
      "      21176 | \u001b[94m  0.000023\u001b[0m  |    0.015541     |   2\n",
      "      21177 |   0.219257  |    0.074386     |   0\n",
      "      21178 |   0.191449  |    0.026769     |   0\n",
      "      21179 |   0.192621  |    0.194905     |   1\n",
      "      21180 |   0.197551  |    0.029062     |   0\n",
      "      21181 |   0.201409  |    0.221314     |   1\n",
      "      21182 |   0.190582  |    0.147337     |   1\n",
      "      21183 |   0.191394  |    0.012635     |   0\n",
      "      21184 |   0.201554  |    0.206781     |   1\n",
      "      21185 |   0.185022  |    0.015013     |   0\n",
      "      21186 |   0.178276  |    0.162692     |   1\n",
      "      21187 |   0.005673  |    0.083490     |   2\n",
      "      21188 |   0.061711  |    0.004838     |   2\n",
      "      21189 |   0.157289  |    0.093531     |   0\n",
      "      21190 |   0.129696  |    0.143683     |   1\n",
      "      21191 |   0.161256  |    0.063426     |   0\n",
      "      21192 |   0.227467  |    0.138752     |   1\n",
      "      21193 |   0.178928  |    0.044173     |   0\n",
      "      21194 |   0.033869  |    0.041755     |   2\n",
      "      21195 |   0.162037  |    0.039739     |   0\n",
      "      21196 |   0.057235  |    0.070961     |   2\n",
      "      21197 |   0.042686  |    0.049135     |   2\n",
      "      21198 |   0.181229  |    0.202344     |   1\n",
      "      21199 |   0.168906  |    0.145584     |   1\n",
      "      21200 |   0.179224  |    0.184076     |   1\n",
      "      21201 |   0.016228  |    0.025821     |   2\n",
      "      21202 |   0.201718  |    0.209984     |   1\n",
      "      21203 |   0.161522  |    0.130441     |   1\n",
      "      21204 |   0.034803  |    0.007333     |   2\n",
      "      21205 |   0.163207  |    0.215452     |   1\n",
      "      21206 |   0.155582  |    0.133463     |   1\n",
      "      21207 |   0.026545  |    0.016003     |   2\n",
      "      21208 |   0.181738  |    0.204270     |   1\n",
      "      21209 |   0.162304  |    0.155869     |   1\n",
      "      21210 |   0.000024  |    0.071676     |   2\n",
      "      21211 | \u001b[94m  0.000023\u001b[0m  |    0.026657     |   2\n",
      "      21212 |   0.000024  |    0.046187     |   2\n",
      "      21213 |   0.000024  |    0.043356     |   2\n",
      "      21214 |   0.186607  |    0.055291     |   0\n",
      "      21215 |   0.000024  |    0.039130     |   2\n",
      "      21216 |   0.185790  |    0.075601     |   0\n",
      "      21217 |   0.190508  |    0.031307     |   0\n",
      "      21218 |   0.154911  |    0.218247     |   1\n",
      "      21219 |   0.241191  |    0.008091     |   0\n",
      "      21220 |   0.222213  |    0.079663     |   0\n",
      "      21221 | \u001b[94m  0.000023\u001b[0m  |    0.040846     |   2\n",
      "      21222 |   0.172891  |    0.041303     |   0\n",
      "      21223 |   0.044732  |    0.055521     |   2\n",
      "      21224 |   0.163584  |    0.201527     |   1\n",
      "      21225 |   0.171943  |    0.153736     |   1\n",
      "      21226 |   0.191085  |    0.036932     |   0\n",
      "      21227 |   0.048112  |    0.024061     |   2\n",
      "      21228 |   0.244883  |    0.205295     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 21230: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      21229 |   0.198427  |    0.008794     |   0\n",
      "      21230 |   0.195148  |    0.160371     |   1\n",
      "      21231 |   0.154009  |    0.023243     |   0\n",
      "      21232 |   0.186401  |    0.079633     |   0\n",
      "      21233 |   0.045600  |    0.027078     |   2\n",
      "      21234 |   0.032457  |    0.045032     |   2\n",
      "      21235 |   0.204851  |    0.149896     |   1\n",
      "      21236 |   0.190544  |    0.202701     |   1\n",
      "      21237 |   0.186027  |    0.132714     |   1\n",
      "      21238 |   0.226016  |    0.213523     |   1\n",
      "      21239 |   0.108770  |    0.015579     |   0\n",
      "      21240 |   0.194630  |    0.160667     |   1\n",
      "      21241 |   0.039396  |    0.021392     |   2\n",
      "      21242 |   0.187395  |    0.093473     |   0\n",
      "      21243 |   0.181688  |    0.142514     |   1\n",
      "      21244 |   0.163571  |    0.194969     |   1\n",
      "      21245 |   0.249265  |    0.147601     |   1\n",
      "      21246 |   0.040090  |    0.022910     |   2\n",
      "      21247 |   0.185763  |    0.078604     |   0\n",
      "      21248 |   0.026637  |    0.026705     |   2\n",
      "      21249 |   0.037186  |    0.064826     |   2\n",
      "      21250 |   0.144299  |    0.208333     |   1\n",
      "      21251 |   0.219752  |    0.136344     |   1\n",
      "      21252 |   0.056129  |    0.026006     |   2\n",
      "      21253 |   0.053524  |    0.078855     |   2\n",
      "      21254 |   0.187950  |    0.050676     |   0\n",
      "      21255 |   0.041826  |    0.045287     |   2\n",
      "      21256 |   0.206921  |    0.045662     |   0\n",
      "      21257 |   0.021779  |    0.076131     |   2\n",
      "      21258 |   0.206910  |    0.030704     |   0\n",
      "      21259 |   0.165285  |    0.040759     |   0\n",
      "      21260 |   0.000023  |    0.046510     |   2\n",
      "      21261 |   0.179436  |    0.049563     |   0\n",
      "      21262 |   0.171389  |    0.049596     |   0\n",
      "      21263 |   0.229990  |    0.164467     |   1\n",
      "      21264 |   0.005604  |    0.003985     |   2\n",
      "      21265 |   0.205144  |    0.076595     |   0\n",
      "      21266 |   0.247264  |    0.161304     |   1\n",
      "      21267 |   0.166475  |    0.164369     |   1\n",
      "      21268 |   0.063903  |    0.028659     |   2\n",
      "      21269 |   0.198086  |    0.209010     |   1\n",
      "      21270 |   0.205004  |    0.147348     |   1\n",
      "      21271 |   0.183987  |    0.004590     |   0\n",
      "      21272 |   0.198375  |    0.045323     |   0\n",
      "      21273 |   0.210673  |    0.191325     |   1\n",
      "      21274 |   0.167946  |    0.133788     |   1\n",
      "      21275 |   0.034213  |    0.042456     |   2\n",
      "      21276 |   0.287497  |    0.194390     |   1\n",
      "      21277 |   0.139390  |    0.140097     |   1\n",
      "      21278 |   0.057160  |    0.047989     |   2\n",
      "      21279 |   0.043573  |    0.074989     |   2\n",
      "      21280 |   0.186517  |    0.030033     |   0\n",
      "      21281 |   0.270518  |    0.165951     |   1\n",
      "      21282 |   0.176769  |    0.030762     |   0\n",
      "      21283 |   0.193455  |    0.157509     |   1\n",
      "      21284 |   0.210157  |    0.141757     |   1\n",
      "      21285 |   0.015786  |    0.043136     |   2\n",
      "      21286 |   0.193037  |    0.073630     |   0\n",
      "      21287 |   0.216179  |    0.190144     |   1\n",
      "      21288 |   0.034449  |    0.007977     |   2\n",
      "      21289 |   0.171933  |    0.092022     |   0\n",
      "      21290 |   0.241736  |    0.141519     |   1\n",
      "      21291 |   0.027328  |    0.013554     |   2\n",
      "      21292 |   0.212962  |    0.201952     |   1\n",
      "      21293 |   0.208361  |    0.030921     |   0\n",
      "      21294 |   0.130397  |    0.220043     |   1\n",
      "      21295 |   0.164864  |    0.005989     |   0\n",
      "      21296 | \u001b[94m  0.000023\u001b[0m  |    0.076128     |   2\n",
      "      21297 |   0.181495  |    0.035584     |   0\n",
      "      21298 |   0.214943  |    0.209096     |   1\n",
      "      21299 |   0.202315  |    0.139666     |   1\n",
      "      21300 |   0.138234  |    0.023237     |   0\n",
      "      21301 | \u001b[94m  0.000023\u001b[0m  |    0.081992     |   2\n",
      "      21302 |   0.232328  |    0.022735     |   0\n",
      "      21303 |   0.184618  |    0.082756     |   0\n",
      "      21304 | \u001b[94m  0.000023\u001b[0m  |    0.008999     |   2\n",
      "      21305 |   0.000023  |    0.074837     |   2\n",
      "      21306 | \u001b[94m  0.000023\u001b[0m  |    0.034973     |   2\n",
      "      21307 |   0.206450  |    0.142480     |   1\n",
      "      21308 | \u001b[94m  0.000023\u001b[0m  |    0.043452     |   2\n",
      "      21309 |   0.045203  |    0.091268     |   2\n",
      "      21310 |   0.186025  |    0.149669     |   1\n",
      "      21311 |   0.046930  |    0.041168     |   2\n",
      "      21312 |   0.167612  |    0.075986     |   0\n",
      "      21313 |   0.208038  |    0.028632     |   0\n",
      "      21314 |   0.254628  |    0.083658     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 21315: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      21315 |   0.175740  |    0.181856     |   1\n",
      "      21316 |   0.177148  |    0.138159     |   1\n",
      "      21317 |   0.176135  |    0.022894     |   0\n",
      "      21318 |   0.157782  |    0.077230     |   0\n",
      "      21319 |   0.045660  |    0.015607     |   2\n",
      "      21320 |   0.032684  |    0.075134     |   2\n",
      "      21321 |   0.184900  |    0.155149     |   1\n",
      "      21322 |   0.039106  |    0.051149     |   2\n",
      "      21323 |   0.039601  |    0.056598     |   2\n",
      "      21324 |   0.198461  |    0.152866     |   1\n",
      "      21325 |   0.179208  |    0.150212     |   1\n",
      "      21326 |   0.027119  |    0.023247     |   2\n",
      "      21327 |   0.038482  |    0.076281     |   2\n",
      "      21328 |   0.205332  |    0.191216     |   1\n",
      "      21329 |   0.052779  |    0.005959     |   2\n",
      "      21330 |   0.052338  |    0.082588     |   2\n",
      "      21331 |   0.041126  |    0.014739     |   2\n",
      "      21332 |   0.194456  |    0.201221     |   1\n",
      "      21333 |   0.141688  |    0.148875     |   1\n",
      "      21334 |   0.171201  |    0.025761     |   0\n",
      "      21335 |   0.232985  |    0.078746     |   0\n",
      "      21336 |   0.021821  |    0.020885     |   2\n",
      "      21337 |   0.130446  |    0.051596     |   0\n",
      "      21338 |   0.197019  |    0.038609     |   0\n",
      "      21339 |   0.159279  |    0.081228     |   0\n",
      "      21340 | \u001b[94m  0.000023\u001b[0m  |    0.027688     |   2\n",
      "      21341 |   0.137200  |    0.186457     |   1\n",
      "      21342 |   0.175224  |    0.004024     |   0\n",
      "      21343 |   0.005411  |    0.086015     |   2\n",
      "      21344 |   0.062837  |    0.028153     |   2\n",
      "      21345 |   0.036275  |    0.081131     |   2\n",
      "      21346 |   0.151416  |    0.206114     |   1\n",
      "      21347 |   0.156691  |    0.142483     |   1\n",
      "      21348 |   0.141623  |    0.007697     |   0\n",
      "      21349 |   0.185076  |    0.198474     |   1\n",
      "      21350 |   0.190846  |    0.199175     |   1\n",
      "      21351 |   0.156555  |    0.100626     |   1\n",
      "      21352 |   0.173481  |    0.048503     |   0\n",
      "      21353 |   0.057086  |    0.078956     |   2\n",
      "      21354 |   0.176510  |    0.149588     |   1\n",
      "      21355 |   0.040910  |    0.043570     |   2\n",
      "      21356 |   0.014777  |    0.042142     |   2\n",
      "      21357 |   0.157524  |    0.052364     |   0\n",
      "      21358 |   0.201865  |    0.147478     |   1\n",
      "      21359 |   0.158577  |    0.041899     |   0\n",
      "      21360 |   0.198860  |    0.044007     |   0\n",
      "      21361 |   0.033404  |    0.058432     |   2\n",
      "      21362 |   0.207343  |    0.051537     |   0\n",
      "      21363 |   0.213966  |    0.141224     |   1\n",
      "      21364 |   0.229425  |    0.046347     |   0\n",
      "      21365 |   0.202421  |    0.180171     |   1\n",
      "      21366 |   0.028600  |    0.079049     |   2\n",
      "      21367 |   0.144817  |    0.007152     |   0\n",
      "      21368 |   0.153011  |    0.075997     |   0\n",
      "      21369 |   0.000023  |    0.030034     |   2\n",
      "      21370 |   0.141257  |    0.190145     |   1\n",
      "      21371 |   0.189894  |    0.187769     |   1\n",
      "      21372 |   0.187107  |    0.140151     |   1\n",
      "      21373 | \u001b[94m  0.000023\u001b[0m  |    0.048236     |   2\n",
      "      21374 |   0.194052  |    0.041277     |   0\n",
      "      21375 |   0.166944  |    0.048281     |   0\n",
      "      21376 |   0.205851  |    0.206371     |   1\n",
      "      21377 |   0.169185  |    0.151026     |   1\n",
      "      21378 |   0.000023  |    0.007876     |   2\n",
      "      21379 |   0.184139  |    0.082774     |   0\n",
      "      21380 |   0.000023  |    0.008556     |   2\n",
      "      21381 |   0.000023  |    0.079274     |   2\n",
      "      21382 |   0.229094  |    0.186564     |   1\n",
      "      21383 |   0.193532  |    0.146392     |   1\n",
      "      21384 |   0.000023  |    0.043113     |   2\n",
      "      21385 |   0.203840  |    0.042805     |   0\n",
      "      21386 |   0.046392  |    0.048483     |   2\n",
      "      21387 |   0.048695  |    0.048970     |   2\n",
      "      21388 |   0.210704  |    0.147872     |   1\n",
      "      21389 |   0.246027  |    0.136068     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 21390: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      21390 |   0.210113  |    0.030433     |   0\n",
      "      21391 |   0.148431  |    0.046812     |   0\n",
      "      21392 |   0.204719  |    0.213580     |   1\n",
      "      21393 |   0.044403  |    0.005435     |   2\n",
      "      21394 |   0.197001  |    0.179793     |   1\n",
      "      21395 |   0.199707  |    0.046867     |   0\n",
      "      21396 |   0.143477  |    0.028747     |   0\n",
      "      21397 |   0.131169  |    0.075480     |   0\n",
      "      21398 |   0.129560  |    0.016116     |   0\n",
      "      21399 |   0.139374  |    0.178836     |   1\n",
      "      21400 |   0.155145  |    0.152946     |   1\n",
      "      21401 |   0.183874  |    0.150991     |   1\n",
      "      21402 |   0.032817  |    0.038530     |   2\n",
      "      21403 |   0.133864  |    0.077996     |   0\n",
      "      21404 |   0.133810  |    0.157789     |   1\n",
      "      21405 |   0.038137  |    0.009447     |   2\n",
      "      21406 |   0.187731  |    0.075457     |   0\n",
      "      21407 |   0.039229  |    0.007014     |   2\n",
      "      21408 |   0.144202  |    0.071294     |   0\n",
      "      21409 |   0.188810  |    0.042580     |   0\n",
      "      21410 |   0.026643  |    0.040642     |   2\n",
      "      21411 |   0.181912  |    0.167434     |   1\n",
      "      21412 |   0.152393  |    0.042075     |   0\n",
      "      21413 |   0.192189  |    0.045153     |   0\n",
      "      21414 |   0.148335  |    0.145502     |   1\n",
      "      21415 |   0.038964  |    0.043244     |   2\n",
      "      21416 |   0.049180  |    0.052753     |   2\n",
      "      21417 |   0.195912  |    0.039030     |   0\n",
      "      21418 |   0.166929  |    0.180637     |   1\n",
      "      21419 |   0.156929  |    0.043153     |   0\n",
      "      21420 |   0.157509  |    0.043559     |   0\n",
      "      21421 |   0.160354  |    0.047021     |   0\n",
      "      21422 |   0.054142  |    0.078852     |   2\n",
      "      21423 |   0.166271  |    0.021730     |   0\n",
      "      21424 |   0.147594  |    0.080322     |   0\n",
      "      21425 |   0.208575  |    0.191478     |   1\n",
      "      21426 |   0.226364  |    0.154882     |   1\n",
      "      21427 |   0.134232  |    0.154978     |   1\n",
      "      21428 |   0.187925  |    0.018639     |   0\n",
      "      21429 |   0.042833  |    0.079955     |   2\n",
      "      21430 |   0.185524  |    0.156005     |   1\n",
      "      21431 |   0.160745  |    0.164845     |   1\n",
      "      21432 |   0.154919  |    0.040781     |   0\n",
      "      21433 |   0.018812  |    0.049458     |   2\n",
      "      21434 |   0.179343  |    0.043454     |   0\n",
      "      21435 |   0.205369  |    0.077061     |   0\n",
      "      21436 |   0.215553  |    0.143553     |   1\n",
      "      21437 |   0.000023  |    0.021726     |   2\n",
      "      21438 |   0.177438  |    0.076546     |   0\n",
      "      21439 |   0.005517  |    0.046069     |   2\n",
      "      21440 |   0.062086  |    0.043129     |   2\n",
      "      21441 |   0.150304  |    0.043483     |   0\n",
      "      21442 |   0.222882  |    0.212432     |   1\n",
      "      21443 |   0.038068  |    0.008578     |   2\n",
      "      21444 |   0.059078  |    0.091518     |   2\n",
      "      21445 |   0.156161  |    0.018286     |   0\n",
      "      21446 |   0.209990  |    0.197041     |   1\n",
      "      21447 |   0.040084  |    0.041055     |   2\n",
      "      21448 |   0.250343  |    0.071302     |   0\n",
      "      21449 |   0.186895  |    0.031740     |   0\n",
      "      21450 |   0.197683  |    0.211177     |   1\n",
      "      21451 |   0.188566  |    0.026370     |   0\n",
      "      21452 |   0.015411  |    0.053604     |   2\n",
      "      21453 |   0.172357  |    0.139559     |   1\n",
      "      21454 |   0.198489  |    0.074739     |   0\n",
      "      21455 |   0.034324  |    0.040062     |   2\n",
      "      21456 |   0.178103  |    0.157524     |   1\n",
      "      21457 |   0.126803  |    0.152622     |   1\n",
      "      21458 |   0.173644  |    0.201256     |   1\n",
      "      21459 |   0.029243  |    0.011631     |   2\n",
      "      21460 |   0.137277  |    0.080446     |   0\n",
      "      21461 |   0.168927  |    0.014148     |   0\n",
      "      21462 |   0.000023  |    0.070624     |   2\n",
      "      21463 |   0.000023  |    0.079548     |   2\n",
      "      21464 |   0.170979  |    0.127674     |   1\n",
      "      21465 |   0.176204  |    0.075237     |   0\n",
      "      21466 |   0.166569  |    0.152007     |   1\n",
      "      21467 |   0.227167  |    0.047622     |   0\n",
      "      21468 |   0.000023  |    0.023464     |   2\n",
      "      21469 |   0.000023  |    0.080829     |   2\n",
      "      21470 |   0.000023  |    0.033557     |   2\n",
      "      21471 |   0.203720  |    0.202898     |   1\n",
      "      21472 |   0.201987  |    0.004295     |   0\n",
      "      21473 |   0.000023  |    0.059674     |   2\n",
      "      21474 |   0.192420  |    0.042994     |   0\n",
      "      21475 |   0.053518  |    0.047617     |   2\n",
      "      21476 |   0.224251  |    0.198829     |   1\n",
      "      21477 |   0.050082  |    0.004504     |   2\n",
      "      21478 |   0.205935  |    0.051056     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 21479: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      21479 |   0.167023  |    0.045102     |   0\n",
      "      21480 |   0.043097  |    0.037242     |   2\n",
      "      21481 |   0.030461  |    0.058368     |   2\n",
      "      21482 |   0.149892  |    0.048042     |   0\n",
      "      21483 |   0.038136  |    0.047381     |   2\n",
      "      21484 |   0.203753  |    0.164527     |   1\n",
      "      21485 |   0.208515  |    0.195191     |   1\n",
      "      21486 |   0.185552  |    0.024306     |   0\n",
      "      21487 |   0.040115  |    0.081166     |   2\n",
      "      21488 |   0.182477  |    0.027327     |   0\n",
      "      21489 |   0.204135  |    0.075740     |   0\n",
      "      21490 |   0.165215  |    0.026325     |   0\n",
      "      21491 |   0.026385  |    0.073812     |   2\n",
      "      21492 |   0.040302  |    0.045007     |   2\n",
      "      21493 |   0.048719  |    0.039092     |   2\n",
      "      21494 |   0.145944  |    0.106643     |   0\n",
      "      21495 |   0.189220  |    0.150814     |   1\n",
      "      21496 |   0.269562  |    0.048902     |   0\n",
      "      21497 |   0.166496  |    0.143300     |   1\n",
      "      21498 |   0.225511  |    0.207868     |   1\n",
      "      21499 |   0.178539  |    0.014077     |   0\n",
      "      21500 |   0.202739  |    0.221781     |   1\n",
      "      21501 |   0.219165  |    0.270981     |   1\n",
      "      21502 |   0.199399  |    0.276678     |   1\n",
      "      21503 |   0.284146  |    0.240325     |   1\n",
      "      21504 |   0.173339  |    0.064980     |   0\n",
      "      21505 |   0.157464  |    0.269884     |   1\n",
      "      21506 |   0.132564  |    0.291589     |   1\n",
      "      21507 |   0.116063  |    0.128670     |   0\n",
      "      21508 |   0.042886  |    0.047246     |   2\n",
      "      21509 |   0.141832  |    0.044508     |   0\n",
      "      21510 |   0.031643  |    0.032485     |   2\n",
      "      21511 |   0.158392  |    0.227929     |   1\n",
      "      21512 |   0.158137  |    0.023905     |   0\n",
      "      21513 |   0.036875  |    0.100903     |   2\n",
      "      21514 |   0.038745  |    0.043420     |   2\n",
      "      21515 |   0.181226  |    0.080737     |   0\n",
      "      21516 |   0.234888  |    0.147346     |   1\n",
      "      21517 |   0.164629  |    0.206583     |   1\n",
      "      21518 |   0.025919  |    0.003758     |   2\n",
      "      21519 |   0.038260  |    0.077718     |   2\n",
      "      21520 |   0.185157  |    0.036827     |   0\n",
      "      21521 |   0.045951  |    0.095870     |   2\n",
      "      21522 |   0.152389  |    0.159783     |   1\n",
      "      21523 |   0.153971  |    0.024561     |   0\n",
      "      21524 |   0.052645  |    0.080447     |   2\n",
      "      21525 |   0.139283  |    0.046623     |   0\n",
      "      21526 |   0.152472  |    0.188146     |   1\n",
      "      21527 |   0.205339  |    0.154633     |   1\n",
      "      21528 |   0.042194  |    0.007465     |   2\n",
      "      21529 |   0.183741  |    0.072344     |   0\n",
      "      21530 |   0.019862  |    0.027728     |   2\n",
      "      21531 |   0.171076  |    0.198211     |   1\n",
      "      21532 | \u001b[94m  0.000023\u001b[0m  |    0.007722     |   2\n",
      "      21533 |   0.172453  |    0.202988     |   1\n",
      "      21534 |   0.216062  |    0.079763     |   0\n",
      "      21535 |   0.005271  |    0.014626     |   2\n",
      "      21536 |   0.169140  |    0.079535     |   0\n",
      "      21537 |   0.062663  |    0.029009     |   2\n",
      "      21538 |   0.259812  |    0.070818     |   0\n",
      "      21539 |   0.179708  |    0.022967     |   0\n",
      "      21540 |   0.148121  |    0.085685     |   0\n",
      "      21541 |   0.217604  |    0.150743     |   1\n",
      "      21542 |   0.197431  |    0.152725     |   1\n",
      "      21543 |   0.156932  |    0.137243     |   1\n",
      "      21544 |   0.034203  |    0.020191     |   2\n",
      "      21545 |   0.190245  |    0.205900     |   1\n",
      "      21546 |   0.057779  |    0.011643     |   2\n",
      "      21547 |   0.222598  |    0.082319     |   0\n",
      "      21548 |   0.188692  |    0.025882     |   0\n",
      "      21549 |   0.199812  |    0.181951     |   1\n",
      "      21550 |   0.041342  |    0.029702     |   2\n",
      "      21551 |   0.155840  |    0.198457     |   1\n",
      "      21552 |   0.177974  |    0.038925     |   0\n",
      "      21553 |   0.018160  |    0.046202     |   2\n",
      "      21554 |   0.179009  |    0.074961     |   0\n",
      "      21555 |   0.035529  |    0.029329     |   2\n",
      "      21556 |   0.148353  |    0.072243     |   0\n",
      "      21557 |   0.028638  |    0.021486     |   2\n",
      "      21558 |   0.178687  |    0.079324     |   0\n",
      "      21559 | \u001b[94m  0.000022\u001b[0m  |    0.010509     |   2\n",
      "      21560 |   0.163070  |    0.094891     |   0\n",
      "      21561 |   0.206051  |    0.146747     |   1\n",
      "      21562 |   0.187234  |    0.159073     |   1\n",
      "      21563 |   0.152437  |    0.134827     |   1\n",
      "      21564 |   0.000022  |    0.069590     |   2\n",
      "      21565 |   0.192003  |    0.023544     |   0\n",
      "      21566 |   0.201968  |    0.189278     |   1\n",
      "      21567 |   0.000022  |    0.039637     |   2\n",
      "      21568 |   0.273286  |    0.191778     |   1\n",
      "      21569 |   0.165801  |    0.037503     |   0\n",
      "      21570 |   0.224226  |    0.040782     |   0\n",
      "      21571 |   0.000023  |    0.074226     |   2\n",
      "      21572 |   0.226474  |    0.127525     |   1\n",
      "      21573 |   0.196132  |    0.045601     |   0\n",
      "      21574 |   0.178478  |    0.145596     |   1\n",
      "      21575 |   0.174218  |    0.045227     |   0\n",
      "      21576 |   0.218903  |    0.048769     |   0\n",
      "      21577 |   0.251986  |    0.150608     |   1\n",
      "      21578 |   0.197690  |    0.210489     |   1\n",
      "      21579 |   0.000022  |    0.003351     |   2\n",
      "      21580 |   0.177920  |    0.205100     |   1\n",
      "      21581 |   0.158647  |    0.003090     |   0\n",
      "      21582 |   0.143151  |    0.059710     |   0\n",
      "      21583 |   0.199407  |    0.201698     |   1\n",
      "      21584 |   0.099255  |    0.134304     |   1\n",
      "      21585 |   0.000022  |    0.084408     |   2\n",
      "      21586 |   0.052773  |    0.028808     |   2\n",
      "      21587 |   0.158563  |    0.247463     |   1\n",
      "      21588 |   0.212773  |    0.046718     |   0\n",
      "      21589 |   0.195590  |    0.069489     |   0\n",
      "      21590 |   0.161897  |    0.270910     |   1\n",
      "      21591 |   0.160769  |    0.070404     |   0\n",
      "      21592 |   0.190803  |    0.071330     |   0\n",
      "      21593 |   0.147777  |    0.277851     |   1\n",
      "      21594 |   0.204875  |    0.068898     |   0\n",
      "      21595 |   0.196288  |    0.271168     |   1\n",
      "      21596 |   0.144899  |    0.044103     |   0\n",
      "      21597 |   0.200294  |    0.120476     |   0\n",
      "      21598 |   0.222145  |    0.221887     |   1\n",
      "      21599 |   0.308625  |    0.257208     |   1\n",
      "      21600 |   0.050283  |    0.022087     |   2\n",
      "      21601 |   0.241656  |    0.290183     |   1\n",
      "      21602 |   0.194355  |    0.258765     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 21603: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      21603 |   0.175998  |    0.271600     |   1\n",
      "      21604 |   0.164614  |    0.090447     |   0\n",
      "      21605 |   0.208233  |    0.071702     |   0\n",
      "      21606 |   0.159687  |    0.277120     |   1\n",
      "      21607 |   0.183948  |    0.080587     |   0\n",
      "      21608 |   0.155576  |    0.283903     |   1\n",
      "      21609 |   0.043271  |    0.071584     |   2\n",
      "      21610 |   0.253215  |    0.270799     |   1\n",
      "      21611 |   0.032254  |    0.102068     |   2\n",
      "      21612 |   0.174700  |    0.259921     |   1\n",
      "      21613 |   0.170093  |    0.121886     |   1\n",
      "      21614 |   0.203258  |    0.188759     |   1\n",
      "      21615 |   0.037286  |    0.024148     |   2\n",
      "      21616 |   0.039846  |    0.074383     |   2\n",
      "      21617 |   0.160342  |    0.019257     |   0\n",
      "      21618 |   0.180807  |    0.089480     |   0\n",
      "      21619 |   0.124286  |    0.200730     |   1\n",
      "      21620 |   0.160265  |    0.013680     |   0\n",
      "      21621 |   0.025601  |    0.091770     |   2\n",
      "      21622 |   0.277826  |    0.131063     |   1\n",
      "      21623 |   0.035584  |    0.032541     |   2\n",
      "      21624 |   0.162276  |    0.195715     |   1\n",
      "      21625 |   0.252314  |    0.048612     |   0\n",
      "      21626 |   0.157744  |    0.205216     |   1\n",
      "      21627 |   0.176618  |    0.146736     |   1\n",
      "      21628 |   0.047255  |    0.054668     |   2\n",
      "      21629 |   0.241059  |    0.144603     |   1\n",
      "      21630 |   0.052035  |    0.036235     |   2\n",
      "      21631 |   0.152362  |    0.213433     |   1\n",
      "      21632 |   0.203322  |    0.010077     |   0\n",
      "      21633 |   0.132771  |    0.033194     |   0\n",
      "      21634 |   0.146405  |    0.044988     |   0\n",
      "      21635 |   0.184314  |    0.050960     |   0\n",
      "      21636 |   0.190814  |    0.149621     |   1\n",
      "      21637 |   0.224396  |    0.150334     |   1\n",
      "      21638 |   0.179957  |    0.171461     |   1\n",
      "      21639 |   0.044199  |    0.005632     |   2\n",
      "      21640 |   0.022348  |    0.038574     |   2\n",
      "      21641 |   0.202493  |    0.073610     |   0\n",
      "      21642 |   0.236976  |    0.191864     |   1\n",
      "      21643 |   0.143684  |    0.154561     |   1\n",
      "      21644 |   0.183706  |    0.150168     |   1\n",
      "      21645 | \u001b[94m  0.000022\u001b[0m  |    0.021924     |   2\n",
      "      21646 |   0.198330  |    0.082538     |   0\n",
      "      21647 |   0.233595  |    0.029876     |   0\n",
      "      21648 |   0.261996  |    0.079299     |   0\n",
      "      21649 |   0.220133  |    0.172671     |   1\n",
      "      21650 |   0.233255  |    0.152605     |   1\n",
      "      21651 |   0.196887  |    0.076659     |   0\n",
      "      21652 |   0.157771  |    0.012976     |   0\n",
      "      21653 |   0.004878  |    0.074325     |   2\n",
      "      21654 |   0.208459  |    0.030282     |   0\n",
      "      21655 |   0.064003  |    0.076103     |   2\n",
      "      21656 |   0.204572  |    0.212434     |   1\n",
      "      21657 |   0.189511  |    0.108898     |   1\n",
      "      21658 |   0.166640  |    0.043097     |   0\n",
      "      21659 |   0.033843  |    0.043629     |   2\n",
      "      21660 |   0.132591  |    0.047501     |   0\n",
      "      21661 |   0.206905  |    0.148888     |   1\n",
      "      21662 |   0.056035  |    0.074644     |   2\n",
      "      21663 |   0.040640  |    0.078962     |   2\n",
      "      21664 |   0.149770  |    0.039396     |   0\n",
      "      21665 |   0.183932  |    0.077815     |   0\n",
      "      21666 |   0.015688  |    0.075252     |   2\n",
      "      21667 |   0.271791  |    0.227185     |   1\n",
      "      21668 |   0.252711  |    0.223947     |   1\n",
      "      21669 |   0.187289  |    0.071073     |   0\n",
      "      21670 |   0.176620  |    0.269473     |   1\n",
      "      21671 |   0.224913  |    0.180187     |   1\n",
      "      21672 |   0.192718  |    0.022478     |   0\n",
      "      21673 |   0.174829  |    0.050586     |   0\n",
      "      21674 |   0.229944  |    0.191565     |   1\n",
      "      21675 |   0.192915  |    0.004731     |   0\n",
      "      21676 |   0.189962  |    0.058995     |   0\n",
      "      21677 |   0.037374  |    0.042031     |   2\n",
      "      21678 |   0.232901  |    0.182055     |   1\n",
      "      21679 |   0.178393  |    0.043496     |   0\n",
      "      21680 |   0.223079  |    0.052105     |   0\n",
      "      21681 |   0.192302  |    0.199140     |   1\n",
      "      21682 |   0.028745  |    0.014994     |   2\n",
      "      21683 |   0.220271  |    0.079452     |   0\n",
      "      21684 | \u001b[94m  0.000022\u001b[0m  |    0.041999     |   2\n",
      "      21685 |   0.175315  |    0.196932     |   1\n",
      "      21686 | \u001b[94m  0.000022\u001b[0m  |    0.005946     |   2\n",
      "      21687 |   0.000022  |    0.073139     |   2\n",
      "      21688 |   0.000022  |    0.041334     |   2\n",
      "      21689 |   0.177251  |    0.044488     |   0\n",
      "      21690 |   0.175718  |    0.074222     |   0\n",
      "      21691 | \u001b[94m  0.000022\u001b[0m  |    0.017081     |   2\n",
      "      21692 | \u001b[94m  0.000022\u001b[0m  |    0.048922     |   2\n",
      "      21693 |   0.047761  |    0.079032     |   2\n",
      "      21694 |   0.181160  |    0.279217     |   1\n",
      "      21695 |   0.170326  |    0.011310     |   0\n",
      "      21696 |   0.158002  |    0.071178     |   0\n",
      "      21697 |   0.187070  |    0.074992     |   0\n",
      "      21698 |   0.049982  |    0.076271     |   2\n",
      "      21699 |   0.195992  |    0.271685     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 21700: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      21700 |   0.048295  |    0.069242     |   2\n",
      "      21701 |   0.199349  |    0.071046     |   0\n",
      "      21702 |   0.165025  |    0.073340     |   0\n",
      "      21703 |   0.206401  |    0.280814     |   1\n",
      "      21704 |   0.032421  |    0.069417     |   2\n",
      "      21705 |   0.140369  |    0.273918     |   1\n",
      "      21706 |   0.228053  |    0.069697     |   0\n",
      "      21707 |   0.192828  |    0.072191     |   0\n",
      "      21708 |   0.038398  |    0.068674     |   2\n",
      "      21709 |   0.041078  |    0.075825     |   2\n",
      "      21710 |   0.203000  |    0.284928     |   1\n",
      "      21711 |   0.174920  |    0.036652     |   0\n",
      "      21712 |   0.025460  |    0.069374     |   2\n",
      "      21713 |   0.038977  |    0.074628     |   2\n",
      "      21714 |   0.047343  |    0.074946     |   2\n",
      "      21715 |   0.053732  |    0.071514     |   2\n",
      "      21716 |   0.151769  |    0.072474     |   0\n",
      "      21717 |   0.215739  |    0.328915     |   1\n",
      "      21718 |   0.187306  |    0.226347     |   1\n",
      "      21719 |   0.042367  |    0.036528     |   2\n",
      "      21720 |   0.133071  |    0.322790     |   1\n",
      "      21721 |   0.178220  |    0.037116     |   0\n",
      "      21722 |   0.236603  |    0.275347     |   1\n",
      "      21723 |   0.022451  |    0.045465     |   2\n",
      "      21724 |   0.223202  |    0.136535     |   0\n",
      "      21725 |   0.000022  |    0.074143     |   2\n",
      "      21726 |   0.005365  |    0.144136     |   2\n",
      "      21727 |   0.060215  |    0.072576     |   2\n",
      "      21728 |   0.226342  |    0.346603     |   1\n",
      "      21729 |   0.264414  |    0.270620     |   1\n",
      "      21730 |   0.033301  |    0.072404     |   2\n",
      "      21731 |   0.171412  |    0.037267     |   0\n",
      "      21732 |   0.204326  |    0.099417     |   0\n",
      "      21733 |   0.270207  |    0.271666     |   1\n",
      "      21734 |   0.195166  |    0.236812     |   1\n",
      "      21735 |   0.152929  |    0.036664     |   0\n",
      "      21736 |   0.171388  |    0.079863     |   0\n",
      "      21737 |   0.055335  |    0.072094     |   2\n",
      "      21738 |   0.038303  |    0.071393     |   2\n",
      "      21739 |   0.014572  |    0.070939     |   2\n",
      "      21740 |   0.032274  |    0.072727     |   2\n",
      "      21741 |   0.134460  |    0.059355     |   0\n",
      "      21742 |   0.029451  |    0.119555     |   2\n",
      "      21743 |   0.000022  |    0.024212     |   2\n",
      "      21744 |   0.216100  |    0.307475     |   1\n",
      "      21745 |   0.143852  |    0.068681     |   0\n",
      "      21746 |   0.000022  |    0.070999     |   2\n",
      "      21747 |   0.179359  |    0.088053     |   0\n",
      "      21748 |   0.235288  |    0.068863     |   0\n",
      "      21749 |   0.203872  |    0.037967     |   0\n",
      "      21750 | \u001b[94m  0.000022\u001b[0m  |    0.120976     |   2\n",
      "      21751 |   0.178798  |    0.247733     |   1\n",
      "      21752 |   0.193174  |    0.304497     |   1\n",
      "      21753 |   0.000022  |    0.144918     |   2\n",
      "      21754 | \u001b[94m  0.000021\u001b[0m  |    0.065218     |   2\n",
      "      21755 |   0.199546  |    0.156609     |   0\n",
      "      21756 |   0.159853  |    0.102973     |   0\n",
      "      21757 |   0.243220  |    0.065158     |   0\n",
      "      21758 |   0.220348  |    0.030971     |   0\n",
      "      21759 |   0.156625  |    0.232656     |   1\n",
      "      21760 |   0.172750  |    0.041793     |   0\n",
      "      21761 | \u001b[94m  0.000021\u001b[0m  |    0.046396     |   2\n",
      "      21762 |   0.166715  |    0.245333     |   1\n",
      "      21763 |   0.255917  |    0.237730     |   1\n",
      "      21764 |   0.200054  |    0.252580     |   1\n",
      "      21765 |   0.220347  |    0.150419     |   1\n",
      "      21766 |   0.048307  |    0.094555     |   2\n",
      "      21767 |   0.183940  |    0.231819     |   1\n",
      "      21768 |   0.172817  |    0.076685     |   0\n",
      "      21769 |   0.188951  |    0.063244     |   0\n",
      "      21770 |   0.174663  |    0.114406     |   0\n",
      "      21771 |   0.146280  |    0.217656     |   1\n",
      "      21772 |   0.135403  |    0.046890     |   0\n",
      "      21773 |   0.049587  |    0.063221     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 21774: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      21774 |   0.049906  |    0.090042     |   2\n",
      "      21775 |   0.036791  |    0.050270     |   2\n",
      "      21776 |   0.187642  |    0.282952     |   1\n",
      "      21777 |   0.170315  |    0.024132     |   0\n",
      "      21778 |   0.256899  |    0.095958     |   0\n",
      "      21779 |   0.172828  |    0.047238     |   0\n",
      "      21780 |   0.135552  |    0.154562     |   1\n",
      "      21781 |   0.158407  |    0.057752     |   0\n",
      "      21782 |   0.038027  |    0.043561     |   2\n",
      "      21783 |   0.041276  |    0.073834     |   2\n",
      "      21784 |   0.026246  |    0.029204     |   2\n",
      "      21785 |   0.175637  |    0.101357     |   0\n",
      "      21786 |   0.168061  |    0.048443     |   0\n",
      "      21787 |   0.224361  |    0.189432     |   1\n",
      "      21788 |   0.038815  |    0.004173     |   2\n",
      "      21789 |   0.048302  |    0.046948     |   2\n",
      "      21790 |   0.198483  |    0.106383     |   0\n",
      "      21791 |   0.153140  |    0.206756     |   1\n",
      "      21792 |   0.054186  |    0.004610     |   2\n",
      "      21793 |   0.138351  |    0.072018     |   0\n",
      "      21794 |   0.045820  |    0.045491     |   2\n",
      "      21795 |   0.023203  |    0.042856     |   2\n",
      "      21796 |   0.000022  |    0.041294     |   2\n",
      "      21797 |   0.171703  |    0.218922     |   1\n",
      "      21798 |   0.005064  |    0.045862     |   2\n",
      "      21799 |   0.197094  |    0.205945     |   1\n",
      "      21800 |   0.220509  |    0.235044     |   1\n",
      "      21801 |   0.259299  |    0.191211     |   1\n",
      "      21802 |   0.199367  |    0.241865     |   1\n",
      "      21803 |   0.149291  |    0.023762     |   0\n",
      "      21804 |   0.183337  |    0.262633     |   1\n",
      "      21805 |   0.154482  |    0.004891     |   0\n",
      "      21806 |   0.157428  |    0.202854     |   1\n",
      "      21807 |   0.207206  |    0.211229     |   1\n",
      "      21808 |   0.189978  |    0.033991     |   0\n",
      "      21809 |   0.060638  |    0.069375     |   2\n",
      "      21810 |   0.199990  |    0.209569     |   1\n",
      "      21811 |   0.221226  |    0.051096     |   0\n",
      "      21812 |   0.142081  |    0.016245     |   0\n",
      "      21813 |   0.157847  |    0.078803     |   0\n",
      "      21814 |   0.033306  |    0.064252     |   2\n",
      "      21815 |   0.057186  |    0.083577     |   2\n",
      "      21816 |   0.244938  |    0.143860     |   1\n",
      "      21817 |   0.163017  |    0.043023     |   0\n",
      "      21818 |   0.150915  |    0.225292     |   1\n",
      "      21819 |   0.224590  |    0.009942     |   0\n",
      "      21820 |   0.213904  |    0.069427     |   0\n",
      "      21821 |   0.193238  |    0.144868     |   1\n",
      "      21822 |   0.192698  |    0.071187     |   0\n",
      "      21823 |   0.040899  |    0.051467     |   2\n",
      "      21824 |   0.014672  |    0.045179     |   2\n",
      "      21825 |   0.035230  |    0.021867     |   2\n",
      "      21826 |   0.195608  |    0.082529     |   0\n",
      "      21827 |   0.203952  |    0.221736     |   1\n",
      "      21828 |   0.027135  |    0.004521     |   2\n",
      "      21829 |   0.000022  |    0.104862     |   2\n",
      "      21830 |   0.203364  |    0.163050     |   1\n",
      "      21831 |   0.163447  |    0.014523     |   0\n",
      "      21832 |   0.210457  |    0.155160     |   1\n",
      "      21833 |   0.199759  |    0.198673     |   1\n",
      "      21834 |   0.145302  |    0.041810     |   0\n",
      "      21835 |   0.200959  |    0.188377     |   1\n",
      "      21836 |   0.246775  |    0.058042     |   0\n",
      "      21837 |   0.193532  |    0.065997     |   0\n",
      "      21838 |   0.168582  |    0.059485     |   0\n",
      "      21839 |   0.197484  |    0.224592     |   1\n",
      "      21840 |   0.188427  |    0.169644     |   1\n",
      "      21841 |   0.192626  |    0.140926     |   1\n",
      "      21842 |   0.000022  |    0.084812     |   2\n",
      "      21843 |   0.186386  |    0.043827     |   0\n",
      "      21844 |   0.221936  |    0.156710     |   1\n",
      "      21845 |   0.181704  |    0.191052     |   1\n",
      "      21846 |   0.164433  |    0.170441     |   1\n",
      "      21847 |   0.111985  |    0.003465     |   0\n",
      "      21848 |   0.191532  |    0.038893     |   0\n",
      "      21849 |   0.198875  |    0.169002     |   1\n",
      "      21850 |   0.000021  |    0.059778     |   2\n",
      "      21851 |   0.151349  |    0.139496     |   1\n",
      "      21852 |   0.221778  |    0.185151     |   1\n",
      "      21853 |   0.235318  |    0.188699     |   1\n",
      "      21854 |   0.184054  |    0.006916     |   0\n",
      "      21855 |   0.000022  |    0.081160     |   2\n",
      "      21856 |   0.000021  |    0.009272     |   2\n",
      "      21857 |   0.145718  |    0.057741     |   0\n",
      "      21858 |   0.000021  |    0.040732     |   2\n",
      "      21859 |   0.211560  |    0.151853     |   1\n",
      "      21860 |   0.212844  |    0.138480     |   1\n",
      "      21861 |   0.155030  |    0.186954     |   1\n",
      "      21862 |   0.193167  |    0.038886     |   0\n",
      "      21863 |   0.146263  |    0.051148     |   0\n",
      "      21864 |   0.044952  |    0.055209     |   2\n",
      "      21865 |   0.182453  |    0.196555     |   1\n",
      "      21866 |   0.183670  |    0.026298     |   0\n",
      "      21867 |   0.048217  |    0.048587     |   2\n",
      "      21868 |   0.210002  |    0.187307     |   1\n",
      "      21869 |   0.147483  |    0.007659     |   0\n",
      "      21870 |   0.168363  |    0.092611     |   0\n",
      "      21871 |   0.161955  |    0.163396     |   1\n",
      "      21872 |   0.183338  |    0.141001     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 21873: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      21873 |   0.217731  |    0.092296     |   0\n",
      "      21874 |   0.166105  |    0.187113     |   1\n",
      "      21875 |   0.177115  |    0.194881     |   1\n",
      "      21876 |   0.044602  |    0.042142     |   2\n",
      "      21877 |   0.032804  |    0.075821     |   2\n",
      "      21878 |   0.204388  |    0.030219     |   0\n",
      "      21879 |   0.272215  |    0.197710     |   1\n",
      "      21880 |   0.176715  |    0.007839     |   0\n",
      "      21881 |   0.038161  |    0.056991     |   2\n",
      "      21882 |   0.185955  |    0.140519     |   1\n",
      "      21883 |   0.040287  |    0.079847     |   2\n",
      "      21884 |   0.026350  |    0.041883     |   2\n",
      "      21885 |   0.100948  |    0.072623     |   0\n",
      "      21886 |   0.198924  |    0.038853     |   0\n",
      "      21887 |   0.187733  |    0.209381     |   1\n",
      "      21888 |   0.174149  |    0.042612     |   0\n",
      "      21889 |   0.194363  |    0.181589     |   1\n",
      "      21890 |   0.037463  |    0.010053     |   2\n",
      "      21891 |   0.224072  |    0.191278     |   1\n",
      "      21892 |   0.224173  |    0.130184     |   1\n",
      "      21893 |   0.045469  |    0.090977     |   2\n",
      "      21894 |   0.154999  |    0.164534     |   1\n",
      "      21895 |   0.230926  |    0.133534     |   1\n",
      "      21896 |   0.212242  |    0.027808     |   0\n",
      "      21897 |   0.169150  |    0.079073     |   0\n",
      "      21898 |   0.214465  |    0.029114     |   0\n",
      "      21899 |   0.162363  |    0.080922     |   0\n",
      "      21900 |   0.055073  |    0.053255     |   2\n",
      "      21901 |   0.258006  |    0.149775     |   1\n",
      "      21902 |   0.253914  |    0.149974     |   1\n",
      "      21903 |   0.041039  |    0.056995     |   2\n",
      "      21904 |   0.206410  |    0.196475     |   1\n",
      "      21905 |   0.127847  |    0.023819     |   0\n",
      "      21906 |   0.197906  |    0.203873     |   1\n",
      "      21907 |   0.020160  |    0.022796     |   2\n",
      "      21908 |   0.177162  |    0.077879     |   0\n",
      "      21909 |   0.000022  |    0.039649     |   2\n",
      "      21910 |   0.177831  |    0.138419     |   1\n",
      "      21911 |   0.188328  |    0.052292     |   0\n",
      "      21912 |   0.005097  |    0.044866     |   2\n",
      "      21913 |   0.240686  |    0.204001     |   1\n",
      "      21914 |   0.060525  |    0.003990     |   2\n",
      "      21915 |   0.035164  |    0.041425     |   2\n",
      "      21916 |   0.055409  |    0.079387     |   2\n",
      "      21917 |   0.039585  |    0.029814     |   2\n",
      "      21918 |   0.178975  |    0.211028     |   1\n",
      "      21919 |   0.195091  |    0.026778     |   0\n",
      "      21920 |   0.161457  |    0.217329     |   1\n",
      "      21921 |   0.016485  |    0.023268     |   2\n",
      "      21922 |   0.210105  |    0.157897     |   1\n",
      "      21923 |   0.037823  |    0.076985     |   2\n",
      "      21924 |   0.149461  |    0.149184     |   1\n",
      "      21925 |   0.153110  |    0.034909     |   0\n",
      "      21926 |   0.028490  |    0.079196     |   2\n",
      "      21927 | \u001b[94m  0.000021\u001b[0m  |    0.016183     |   2\n",
      "      21928 | \u001b[94m  0.000021\u001b[0m  |    0.083366     |   2\n",
      "      21929 |   0.000021  |    0.022711     |   2\n",
      "      21930 |   0.158326  |    0.203422     |   1\n",
      "      21931 |   0.151499  |    0.005787     |   0\n",
      "      21932 |   0.000021  |    0.049882     |   2\n",
      "      21933 |   0.231502  |    0.214090     |   1\n",
      "      21934 | \u001b[94m  0.000021\u001b[0m  |    0.006680     |   2\n",
      "      21935 |   0.156433  |    0.192888     |   1\n",
      "      21936 |   0.205814  |    0.141081     |   1\n",
      "      21937 |   0.142287  |    0.186515     |   1\n",
      "      21938 |   0.264311  |    0.142818     |   1\n",
      "      21939 |   0.000021  |    0.039948     |   2\n",
      "      21940 |   0.196908  |    0.077178     |   0\n",
      "      21941 |   0.195525  |    0.012945     |   0\n",
      "      21942 |   0.151296  |    0.194054     |   1\n",
      "      21943 |   0.041698  |    0.058141     |   2\n",
      "      21944 |   0.145193  |    0.039420     |   0\n",
      "      21945 |   0.205888  |    0.080864     |   0\n",
      "      21946 |   0.170627  |    0.029994     |   0\n",
      "      21947 |   0.160987  |    0.215459     |   1\n",
      "      21948 |   0.048660  |    0.005989     |   2\n",
      "      21949 |   0.112690  |    0.072017     |   0\n",
      "      21950 |   0.135527  |    0.011634     |   0\n",
      "      21951 |   0.193574  |    0.080378     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 21952: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      21952 |   0.193943  |    0.152112     |   1\n",
      "      21953 |   0.044995  |    0.032860     |   2\n",
      "      21954 |   0.168191  |    0.198595     |   1\n",
      "      21955 |   0.033510  |    0.006783     |   2\n",
      "      21956 |   0.038661  |    0.075551     |   2\n",
      "      21957 |   0.165502  |    0.189005     |   1\n",
      "      21958 |   0.113503  |    0.007396     |   0\n",
      "      21959 |   0.039770  |    0.080736     |   2\n",
      "      21960 |   0.215511  |    0.169403     |   1\n",
      "      21961 |   0.192924  |    0.153512     |   1\n",
      "      21962 |   0.173346  |    0.030138     |   0\n",
      "      21963 |   0.026142  |    0.076125     |   2\n",
      "      21964 |   0.037302  |    0.012740     |   2\n",
      "      21965 |   0.047858  |    0.088841     |   2\n",
      "      21966 |   0.155233  |    0.192530     |   1\n",
      "      21967 |   0.195474  |    0.133789     |   1\n",
      "      21968 |   0.053468  |    0.026516     |   2\n",
      "      21969 |   0.191820  |    0.214692     |   1\n",
      "      21970 |   0.194218  |    0.163853     |   1\n",
      "      21971 |   0.220467  |    0.142880     |   1\n",
      "      21972 |   0.174829  |    0.134248     |   1\n",
      "      21973 |   0.043232  |    0.047629     |   2\n",
      "      21974 |   0.021349  |    0.052274     |   2\n",
      "      21975 |   0.000021  |    0.049161     |   2\n",
      "      21976 |   0.004953  |    0.046424     |   2\n",
      "      21977 |   0.200881  |    0.248469     |   1\n",
      "      21978 |   0.142894  |    0.003940     |   0\n",
      "      21979 |   0.154392  |    0.083493     |   0\n",
      "      21980 |   0.190030  |    0.152581     |   1\n",
      "      21981 |   0.182718  |    0.083686     |   0\n",
      "      21982 |   0.161177  |    0.029159     |   0\n",
      "      21983 |   0.129525  |    0.075805     |   0\n",
      "      21984 |   0.192190  |    0.263801     |   1\n",
      "      21985 |   0.188166  |    0.212503     |   1\n",
      "      21986 |   0.215610  |    0.238744     |   1\n",
      "      21987 |   0.186386  |    0.245495     |   1\n",
      "      21988 |   0.059179  |    0.076955     |   2\n",
      "      21989 |   0.032802  |    0.075962     |   2\n",
      "      21990 |   0.220256  |    0.045311     |   0\n",
      "      21991 |   0.177624  |    0.050776     |   0\n",
      "      21992 |   0.055992  |    0.074369     |   2\n",
      "      21993 |   0.039876  |    0.040780     |   2\n",
      "      21994 |   0.013409  |    0.125009     |   2\n",
      "      21995 |   0.256807  |    0.047985     |   0\n",
      "      21996 |   0.197735  |    0.051560     |   0\n",
      "      21997 |   0.032688  |    0.077963     |   2\n",
      "      21998 |   0.168715  |    0.330121     |   1\n",
      "      21999 |   0.244432  |    0.024542     |   0\n",
      "      22000 |   0.186672  |    0.319884     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 22000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 22000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      22001 |   0.187977  |    0.086559     |   0\n",
      "      22002 |   0.041500  |    0.003767     |   2\n",
      "      22003 |   0.209357  |    0.210585     |   1\n",
      "      22004 |   0.177725  |    0.018761     |   0\n",
      "      22005 |   0.203404  |    0.084363     |   0\n",
      "      22006 |   0.284021  |    0.134457     |   1\n",
      "      22007 |   0.164747  |    0.033188     |   0\n",
      "      22008 |   0.206358  |    0.083134     |   0\n",
      "      22009 |   0.030115  |    0.004789     |   2\n",
      "      22010 |   0.220106  |    0.157430     |   1\n",
      "      22011 |   0.039413  |    0.043294     |   2\n",
      "      22012 |   0.042376  |    0.060028     |   2\n",
      "      22013 |   0.143236  |    0.189293     |   1\n",
      "      22014 |   0.177362  |    0.162641     |   1\n",
      "      22015 |   0.025939  |    0.004457     |   2\n",
      "      22016 |   0.036983  |    0.039507     |   2\n",
      "      22017 |   0.046782  |    0.047352     |   2\n",
      "      22018 |   0.052786  |    0.057516     |   2\n",
      "      22019 |   0.196870  |    0.043236     |   0\n",
      "      22020 |   0.191614  |    0.183021     |   1\n",
      "      22021 |   0.149317  |    0.008695     |   0\n",
      "      22022 |   0.045031  |    0.078750     |   2\n",
      "      22023 |   0.170713  |    0.034574     |   0\n",
      "      22024 |   0.260776  |    0.205910     |   1\n",
      "      22025 |   0.146884  |    0.006200     |   0\n",
      "      22026 |   0.217270  |    0.185085     |   1\n",
      "      22027 |   0.021301  |    0.006223     |   2\n",
      "      22028 | \u001b[94m  0.000021\u001b[0m  |    0.080837     |   2\n",
      "      22029 |   0.151581  |    0.029902     |   0\n",
      "      22030 |   0.211867  |    0.201268     |   1\n",
      "      22031 |   0.194458  |    0.029362     |   0\n",
      "      22032 |   0.179187  |    0.202274     |   1\n",
      "      22033 |   0.192011  |    0.041820     |   0\n",
      "      22034 |   0.187137  |    0.164198     |   1\n",
      "      22035 |   0.005283  |    0.045025     |   2\n",
      "      22036 |   0.191882  |    0.043223     |   0\n",
      "      22037 |   0.180723  |    0.039384     |   0\n",
      "      22038 |   0.059992  |    0.072503     |   2\n",
      "      22039 |   0.170790  |    0.155537     |   1\n",
      "      22040 |   0.190518  |    0.037647     |   0\n",
      "      22041 |   0.148414  |    0.074923     |   0\n",
      "      22042 |   0.198662  |    0.027590     |   0\n",
      "      22043 |   0.183556  |    0.058333     |   0\n",
      "      22044 |   0.220830  |    0.140395     |   1\n",
      "      22045 |   0.033695  |    0.043488     |   2\n",
      "      22046 |   0.176937  |    0.080191     |   0\n",
      "      22047 |   0.054356  |    0.030829     |   2\n",
      "      22048 |   0.185387  |    0.196307     |   1\n",
      "      22049 |   0.197311  |    0.006310     |   0\n",
      "      22050 |   0.187811  |    0.080209     |   0\n",
      "      22051 |   0.153760  |    0.028123     |   0\n",
      "      22052 |   0.157608  |    0.044161     |   0\n",
      "      22053 |   0.150027  |    0.038676     |   0\n",
      "      22054 |   0.161832  |    0.039991     |   0\n",
      "      22055 |   0.039692  |    0.082819     |   2\n",
      "      22056 |   0.141130  |    0.198378     |   1\n",
      "      22057 |   0.016047  |    0.005353     |   2\n",
      "      22058 |   0.206886  |    0.173186     |   1\n",
      "      22059 |   0.039063  |    0.004134     |   2\n",
      "      22060 |   0.155731  |    0.052222     |   0\n",
      "      22061 |   0.179920  |    0.148923     |   1\n",
      "      22062 |   0.026485  |    0.086459     |   2\n",
      "      22063 | \u001b[94m  0.000021\u001b[0m  |    0.021044     |   2\n",
      "      22064 |   0.120138  |    0.172527     |   1\n",
      "      22065 |   0.187813  |    0.198963     |   1\n",
      "      22066 |   0.170021  |    0.007716     |   0\n",
      "      22067 |   0.199577  |    0.190467     |   1\n",
      "      22068 | \u001b[94m  0.000021\u001b[0m  |    0.044307     |   2\n",
      "      22069 |   0.000021  |    0.047830     |   2\n",
      "      22070 |   0.000021  |    0.042775     |   2\n",
      "      22071 |   0.000021  |    0.041143     |   2\n",
      "      22072 |   0.217941  |    0.040627     |   0\n",
      "      22073 |   0.000021  |    0.041249     |   2\n",
      "      22074 |   0.051245  |    0.077993     |   2\n",
      "      22075 |   0.218528  |    0.016519     |   0\n",
      "      22076 |   0.204197  |    0.199231     |   1\n",
      "      22077 |   0.049011  |    0.006254     |   2\n",
      "      22078 |   0.126962  |    0.082493     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 22079: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      22079 |   0.047220  |    0.039867     |   2\n",
      "      22080 |   0.186733  |    0.228757     |   1\n",
      "      22081 |   0.211326  |    0.147872     |   1\n",
      "      22082 |   0.146168  |    0.019738     |   0\n",
      "      22083 |   0.180473  |    0.167463     |   1\n",
      "      22084 |   0.031884  |    0.043589     |   2\n",
      "      22085 |   0.247158  |    0.081229     |   0\n",
      "      22086 |   0.213085  |    0.149417     |   1\n",
      "      22087 |   0.181934  |    0.197761     |   1\n",
      "      22088 |   0.200015  |    0.003532     |   0\n",
      "      22089 |   0.186946  |    0.043292     |   0\n",
      "      22090 |   0.167902  |    0.046490     |   0\n",
      "      22091 |   0.037378  |    0.048990     |   2\n",
      "      22092 |   0.039182  |    0.025493     |   2\n",
      "      22093 |   0.025336  |    0.081169     |   2\n",
      "      22094 |   0.036702  |    0.024043     |   2\n",
      "      22095 |   0.168848  |    0.199147     |   1\n",
      "      22096 |   0.049276  |    0.011346     |   2\n",
      "      22097 |   0.189534  |    0.046652     |   0\n",
      "      22098 |   0.204002  |    0.044356     |   0\n",
      "      22099 |   0.050878  |    0.046007     |   2\n",
      "      22100 |   0.133781  |    0.042221     |   0\n",
      "      22101 |   0.212545  |    0.175330     |   1\n",
      "      22102 |   0.154797  |    0.004944     |   0\n",
      "      22103 |   0.173548  |    0.074401     |   0\n",
      "      22104 |   0.043552  |    0.044012     |   2\n",
      "      22105 |   0.022210  |    0.037439     |   2\n",
      "      22106 |   0.187657  |    0.042322     |   0\n",
      "      22107 |   0.000021  |    0.044067     |   2\n",
      "      22108 |   0.005007  |    0.036495     |   2\n",
      "      22109 |   0.185976  |    0.045928     |   0\n",
      "      22110 |   0.215733  |    0.169010     |   1\n",
      "      22111 |   0.198354  |    0.138580     |   1\n",
      "      22112 |   0.202971  |    0.038455     |   0\n",
      "      22113 |   0.059924  |    0.046718     |   2\n",
      "      22114 |   0.032277  |    0.055843     |   2\n",
      "      22115 |   0.168502  |    0.046936     |   0\n",
      "      22116 |   0.187587  |    0.028796     |   0\n",
      "      22117 |   0.161332  |    0.071436     |   0\n",
      "      22118 |   0.055626  |    0.042739     |   2\n",
      "      22119 |   0.150105  |    0.051026     |   0\n",
      "      22120 |   0.039640  |    0.047896     |   2\n",
      "      22121 |   0.170516  |    0.042981     |   0\n",
      "      22122 |   0.015790  |    0.045239     |   2\n",
      "      22123 |   0.172256  |    0.204597     |   1\n",
      "      22124 |   0.153237  |    0.146299     |   1\n",
      "      22125 |   0.036932  |    0.122086     |   2\n",
      "      22126 |   0.026967  |    0.040408     |   2\n",
      "      22127 |   0.195543  |    0.070129     |   0\n",
      "      22128 |   0.143024  |    0.072999     |   0\n",
      "      22129 |   0.193610  |    0.069695     |   0\n",
      "      22130 |   0.196703  |    0.324676     |   1\n",
      "      22131 |   0.000021  |    0.039705     |   2\n",
      "      22132 |   0.000021  |    0.071221     |   2\n",
      "      22133 |   0.186926  |    0.272979     |   1\n",
      "      22134 |   0.216463  |    0.072536     |   0\n",
      "      22135 |   0.000021  |    0.071760     |   2\n",
      "      22136 |   0.000021  |    0.070500     |   2\n",
      "      22137 |   0.228050  |    0.274105     |   1\n",
      "      22138 |   0.231723  |    0.324349     |   1\n",
      "      22139 |   0.205559  |    0.270092     |   1\n",
      "      22140 |   0.190414  |    0.072912     |   0\n",
      "      22141 |   0.000021  |    0.097261     |   2\n",
      "      22142 |   0.243094  |    0.282279     |   1\n",
      "      22143 |   0.000021  |    0.073163     |   2\n",
      "      22144 |   0.203612  |    0.076242     |   0\n",
      "      22145 |   0.044497  |    0.122895     |   2\n",
      "      22146 |   0.166359  |    0.017321     |   0\n",
      "      22147 |   0.183551  |    0.092904     |   0\n",
      "      22148 |   0.236473  |    0.276710     |   1\n",
      "      22149 |   0.196086  |    0.071351     |   0\n",
      "      22150 |   0.200583  |    0.039618     |   0\n",
      "      22151 |   0.212662  |    0.272643     |   1\n",
      "      22152 |   0.167023  |    0.094370     |   0\n",
      "      22153 |   0.049402  |    0.069627     |   2\n",
      "      22154 |   0.142552  |    0.095005     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 22155: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      22155 |   0.216323  |    0.234108     |   1\n",
      "      22156 |   0.043455  |    0.038410     |   2\n",
      "      22157 |   0.173617  |    0.071822     |   0\n",
      "      22158 |   0.143715  |    0.390428     |   1\n",
      "      22159 |   0.030571  |    0.119590     |   2\n",
      "      22160 |   0.134282  |    0.060501     |   0\n",
      "      22161 |   0.039299  |    0.123694     |   2\n",
      "      22162 |   0.185785  |    0.039960     |   0\n",
      "      22163 |   0.040964  |    0.131567     |   2\n",
      "      22164 |   0.131462  |    0.388351     |   1\n",
      "      22165 |   0.157753  |    0.069097     |   0\n",
      "      22166 |   0.196046  |    0.340187     |   1\n",
      "      22167 |   0.179539  |    0.064978     |   0\n",
      "      22168 |   0.026025  |    0.096038     |   2\n",
      "      22169 |   0.038005  |    0.003555     |   2\n",
      "      22170 |   0.048778  |    0.108949     |   2\n",
      "      22171 |   0.275257  |    0.223938     |   1\n",
      "      22172 |   0.055117  |    0.005428     |   2\n",
      "      22173 |   0.217035  |    0.082515     |   0\n",
      "      22174 |   0.190822  |    0.047754     |   0\n",
      "      22175 |   0.222425  |    0.228326     |   1\n",
      "      22176 |   0.188474  |    0.225473     |   1\n",
      "      22177 |   0.044481  |    0.013501     |   2\n",
      "      22178 |   0.020490  |    0.111784     |   2\n",
      "      22179 |   0.000021  |    0.030203     |   2\n",
      "      22180 |   0.005214  |    0.117605     |   2\n",
      "      22181 |   0.058361  |    0.065214     |   2\n",
      "      22182 |   0.031986  |    0.047896     |   2\n",
      "      22183 |   0.053693  |    0.048786     |   2\n",
      "      22184 |   0.037646  |    0.043097     |   2\n",
      "      22185 |   0.172834  |    0.066150     |   0\n",
      "      22186 |   0.013323  |    0.042900     |   2\n",
      "      22187 |   0.033345  |    0.118047     |   2\n",
      "      22188 |   0.027311  |    0.069564     |   2\n",
      "      22189 |   0.195073  |    0.240076     |   1\n",
      "      22190 |   0.165468  |    0.221777     |   1\n",
      "      22191 |   0.000021  |    0.018832     |   2\n",
      "      22192 |   0.222084  |    0.272726     |   1\n",
      "      22193 |   0.000021  |    0.021126     |   2\n",
      "      22194 |   0.165585  |    0.268214     |   1\n",
      "      22195 |   0.134044  |    0.231908     |   1\n",
      "      22196 |   0.000021  |    0.027023     |   2\n",
      "      22197 |   0.182273  |    0.089782     |   0\n",
      "      22198 |   0.225849  |    0.174888     |   1\n",
      "      22199 |   0.233997  |    0.027071     |   0\n",
      "      22200 |   0.178711  |    0.095037     |   0\n",
      "      22201 |   0.000021  |    0.041348     |   2\n",
      "      22202 |   0.000021  |    0.074130     |   2\n",
      "      22203 |   0.284378  |    0.279372     |   1\n",
      "      22204 |   0.180264  |    0.084284     |   1\n",
      "      22205 |   0.140491  |    0.041475     |   0\n",
      "      22206 |   0.194108  |    0.296929     |   1\n",
      "      22207 |   0.181469  |    0.144486     |   1\n",
      "      22208 |   0.150767  |    0.047959     |   0\n",
      "      22209 |   0.000021  |    0.041516     |   2\n",
      "      22210 |   0.167551  |    0.039950     |   0\n",
      "      22211 |   0.043604  |    0.091290     |   2\n",
      "      22212 |   0.047743  |    0.029578     |   2\n",
      "      22213 |   0.205340  |    0.077893     |   0\n",
      "      22214 |   0.205885  |    0.077988     |   0\n",
      "      22215 |   0.239836  |    0.216637     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 22216: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      22216 |   0.177369  |    0.042732     |   0\n",
      "      22217 |   0.172871  |    0.013121     |   0\n",
      "      22218 |   0.044042  |    0.075968     |   2\n",
      "      22219 |   0.168431  |    0.025337     |   0\n",
      "      22220 |   0.148097  |    0.077733     |   0\n",
      "      22221 |   0.033339  |    0.041787     |   2\n",
      "      22222 |   0.038403  |    0.067744     |   2\n",
      "      22223 |   0.199633  |    0.045467     |   0\n",
      "      22224 |   0.039536  |    0.098848     |   2\n",
      "      22225 |   0.240704  |    0.039553     |   0\n",
      "      22226 |   0.026677  |    0.074715     |   2\n",
      "      22227 |   0.216083  |    0.030646     |   0\n",
      "      22228 |   0.036924  |    0.092873     |   2\n",
      "      22229 |   0.225614  |    0.192857     |   1\n",
      "      22230 |   0.208493  |    0.177347     |   1\n",
      "      22231 |   0.196658  |    0.013631     |   0\n",
      "      22232 |   0.054926  |    0.112213     |   2\n",
      "      22233 |   0.225685  |    0.180300     |   1\n",
      "      22234 |   0.053617  |    0.030611     |   2\n",
      "      22235 |   0.042959  |    0.041603     |   2\n",
      "      22236 |   0.210676  |    0.079982     |   0\n",
      "      22237 |   0.211286  |    0.163682     |   1\n",
      "      22238 |   0.217889  |    0.219543     |   1\n",
      "      22239 |   0.021600  |    0.004562     |   2\n",
      "      22240 |   0.232167  |    0.065705     |   0\n",
      "      22241 |   0.195848  |    0.046966     |   0\n",
      "      22242 |   0.212816  |    0.192121     |   1\n",
      "      22243 |   0.202615  |    0.047133     |   0\n",
      "      22244 |   0.153522  |    0.191167     |   1\n",
      "      22245 |   0.000021  |    0.018312     |   2\n",
      "      22246 |   0.147500  |    0.208847     |   1\n",
      "      22247 |   0.150270  |    0.196211     |   1\n",
      "      22248 |   0.189120  |    0.024330     |   0\n",
      "      22249 |   0.005074  |    0.084914     |   2\n",
      "      22250 |   0.232512  |    0.216911     |   1\n",
      "      22251 |   0.175775  |    0.025735     |   0\n",
      "      22252 |   0.177098  |    0.261629     |   1\n",
      "      22253 |   0.191775  |    0.009176     |   0\n",
      "      22254 |   0.063133  |    0.052324     |   2\n",
      "      22255 |   0.033709  |    0.088105     |   2\n",
      "      22256 |   0.211896  |    0.010394     |   0\n",
      "      22257 |   0.187905  |    0.053690     |   0\n",
      "      22258 |   0.171393  |    0.077657     |   0\n",
      "      22259 |   0.188887  |    0.140858     |   1\n",
      "      22260 |   0.145274  |    0.038943     |   0\n",
      "      22261 |   0.194193  |    0.241188     |   1\n",
      "      22262 |   0.241868  |    0.166229     |   1\n",
      "      22263 |   0.197736  |    0.165813     |   1\n",
      "      22264 |   0.054940  |    0.038545     |   2\n",
      "      22265 |   0.162782  |    0.045157     |   0\n",
      "      22266 |   0.187767  |    0.011927     |   0\n",
      "      22267 |   0.039018  |    0.078947     |   2\n",
      "      22268 |   0.156682  |    0.034694     |   0\n",
      "      22269 |   0.172330  |    0.197259     |   1\n",
      "      22270 |   0.014818  |    0.019584     |   2\n",
      "      22271 |   0.191219  |    0.199967     |   1\n",
      "      22272 |   0.035614  |    0.021091     |   2\n",
      "      22273 |   0.026656  |    0.080653     |   2\n",
      "      22274 |   0.000021  |    0.042668     |   2\n",
      "      22275 |   0.181323  |    0.043959     |   0\n",
      "      22276 |   0.164242  |    0.137144     |   1\n",
      "      22277 |   0.158996  |    0.037841     |   0\n",
      "      22278 | \u001b[94m  0.000021\u001b[0m  |    0.077492     |   2\n",
      "      22279 |   0.129975  |    0.035711     |   0\n",
      "      22280 |   0.000021  |    0.038811     |   2\n",
      "      22281 |   0.162387  |    0.048798     |   0\n",
      "      22282 |   0.000021  |    0.076111     |   2\n",
      "      22283 |   0.190794  |    0.151264     |   1\n",
      "      22284 |   0.198465  |    0.021088     |   0\n",
      "      22285 | \u001b[94m  0.000021\u001b[0m  |    0.046952     |   2\n",
      "      22286 |   0.195766  |    0.047867     |   0\n",
      "      22287 | \u001b[94m  0.000021\u001b[0m  |    0.061911     |   2\n",
      "      22288 |   0.043292  |    0.042247     |   2\n",
      "      22289 |   0.268485  |    0.201891     |   1\n",
      "      22290 |   0.047443  |    0.004125     |   2\n",
      "      22291 |   0.187859  |    0.076279     |   0\n",
      "      22292 |   0.153808  |    0.026509     |   0\n",
      "      22293 |   0.164292  |    0.053824     |   0\n",
      "      22294 |   0.164758  |    0.200205     |   1\n",
      "      22295 |   0.196584  |    0.009381     |   0\n",
      "      22296 |   0.164180  |    0.207275     |   1\n",
      "      22297 |   0.194931  |    0.026352     |   0\n",
      "      22298 |   0.246393  |    0.075849     |   0\n",
      "      22299 |   0.156227  |    0.025205     |   0\n",
      "      22300 |   0.195943  |    0.147292     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 22301: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      22301 |   0.186265  |    0.148007     |   1\n",
      "      22302 |   0.047014  |    0.044198     |   2\n",
      "      22303 |   0.219592  |    0.188819     |   1\n",
      "      22304 |   0.034684  |    0.015267     |   2\n",
      "      22305 |   0.193541  |    0.140850     |   1\n",
      "      22306 |   0.130493  |    0.042480     |   0\n",
      "      22307 |   0.179865  |    0.042884     |   0\n",
      "      22308 |   0.191220  |    0.208778     |   1\n",
      "      22309 |   0.155203  |    0.145644     |   1\n",
      "      22310 |   0.037431  |    0.025105     |   2\n",
      "      22311 |   0.194304  |    0.196047     |   1\n",
      "      22312 |   0.209402  |    0.042666     |   0\n",
      "      22313 |   0.305880  |    0.140269     |   1\n",
      "      22314 |   0.193093  |    0.041560     |   0\n",
      "      22315 |   0.159527  |    0.191165     |   1\n",
      "      22316 |   0.039864  |    0.041356     |   2\n",
      "      22317 |   0.194140  |    0.044619     |   0\n",
      "      22318 |   0.185126  |    0.043863     |   0\n",
      "      22319 |   0.234174  |    0.076736     |   0\n",
      "      22320 |   0.210049  |    0.155623     |   1\n",
      "      22321 |   0.194877  |    0.142174     |   1\n",
      "      22322 |   0.025553  |    0.007753     |   2\n",
      "      22323 |   0.157072  |    0.076239     |   0\n",
      "      22324 |   0.035979  |    0.030088     |   2\n",
      "      22325 |   0.050114  |    0.057738     |   2\n",
      "      22326 |   0.174292  |    0.048674     |   0\n",
      "      22327 |   0.050422  |    0.075101     |   2\n",
      "      22328 |   0.126735  |    0.024654     |   0\n",
      "      22329 |   0.159651  |    0.207350     |   1\n",
      "      22330 |   0.165850  |    0.006795     |   0\n",
      "      22331 |   0.162213  |    0.076234     |   0\n",
      "      22332 |   0.040434  |    0.021483     |   2\n",
      "      22333 |   0.020236  |    0.092137     |   2\n",
      "      22334 |   0.171771  |    0.154443     |   1\n",
      "      22335 |   0.246105  |    0.142841     |   1\n",
      "      22336 |   0.000021  |    0.053745     |   2\n",
      "      22337 |   0.004921  |    0.051839     |   2\n",
      "      22338 |   0.061037  |    0.041917     |   2\n",
      "      22339 |   0.035319  |    0.086619     |   2\n",
      "      22340 |   0.145799  |    0.017705     |   0\n",
      "      22341 |   0.056026  |    0.077902     |   2\n",
      "      22342 |   0.038705  |    0.028491     |   2\n",
      "      22343 |   0.174996  |    0.041509     |   0\n",
      "      22344 |   0.164683  |    0.077636     |   0\n",
      "      22345 |   0.014526  |    0.008413     |   2\n",
      "      22346 |   0.035421  |    0.090239     |   2\n",
      "      22347 |   0.196417  |    0.020613     |   0\n",
      "      22348 |   0.029583  |    0.046605     |   2\n",
      "      22349 |   0.000021  |    0.085157     |   2\n",
      "      22350 |   0.000021  |    0.025183     |   2\n",
      "      22351 |   0.153837  |    0.041744     |   0\n",
      "      22352 |   0.147499  |    0.046420     |   0\n",
      "      22353 |   0.240783  |    0.208804     |   1\n",
      "      22354 |   0.186940  |    0.140877     |   1\n",
      "      22355 | \u001b[94m  0.000021\u001b[0m  |    0.029523     |   2\n",
      "      22356 |   0.000021  |    0.054083     |   2\n",
      "      22357 | \u001b[94m  0.000021\u001b[0m  |    0.050377     |   2\n",
      "      22358 |   0.157625  |    0.184995     |   1\n",
      "      22359 |   0.167674  |    0.208052     |   1\n",
      "      22360 |   0.192859  |    0.140304     |   1\n",
      "      22361 |   0.170162  |    0.140549     |   1\n",
      "      22362 |   0.258874  |    0.149895     |   1\n",
      "      22363 | \u001b[94m  0.000021\u001b[0m  |    0.071379     |   2\n",
      "      22364 |   0.228052  |    0.032412     |   0\n",
      "      22365 |   0.222864  |    0.165693     |   1\n",
      "      22366 |   0.180554  |    0.062505     |   0\n",
      "      22367 |   0.222107  |    0.200359     |   1\n",
      "      22368 |   0.156891  |    0.166082     |   1\n",
      "      22369 |   0.217186  |    0.138821     |   1\n",
      "      22370 |   0.211799  |    0.185558     |   1\n",
      "      22371 |   0.150551  |    0.135437     |   1\n",
      "      22372 |   0.185197  |    0.135991     |   1\n",
      "      22373 |   0.203379  |    0.165923     |   1\n",
      "      22374 |   0.193552  |    0.033256     |   0\n",
      "      22375 |   0.222507  |    0.147804     |   1\n",
      "      22376 |   0.044555  |    0.083170     |   2\n",
      "      22377 |   0.191735  |    0.146845     |   1\n",
      "      22378 |   0.046813  |    0.034770     |   2\n",
      "      22379 |   0.158445  |    0.202272     |   1\n",
      "      22380 |   0.164972  |    0.016369     |   0\n",
      "      22381 |   0.185775  |    0.157440     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 22382: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      22382 |   0.041685  |    0.011077     |   2\n",
      "      22383 |   0.030461  |    0.107985     |   2\n",
      "      22384 |   0.196953  |    0.145735     |   1\n",
      "      22385 |   0.266109  |    0.072840     |   0\n",
      "      22386 |   0.220018  |    0.025976     |   0\n",
      "      22387 |   0.036852  |    0.079161     |   2\n",
      "      22388 |   0.132235  |    0.013277     |   0\n",
      "      22389 |   0.197339  |    0.076112     |   0\n",
      "      22390 |   0.039682  |    0.035755     |   2\n",
      "      22391 |   0.184276  |    0.203587     |   1\n",
      "      22392 |   0.025610  |    0.003560     |   2\n",
      "      22393 |   0.173483  |    0.040991     |   0\n",
      "      22394 |   0.198194  |    0.076300     |   0\n",
      "      22395 |   0.036487  |    0.037305     |   2\n",
      "      22396 |   0.202521  |    0.154029     |   1\n",
      "      22397 |   0.217030  |    0.046246     |   0\n",
      "      22398 |   0.051129  |    0.050137     |   2\n",
      "      22399 |   0.049843  |    0.075079     |   2\n",
      "      22400 |   0.041088  |    0.020264     |   2\n",
      "      22401 |   0.215092  |    0.200336     |   1\n",
      "      22402 |   0.206628  |    0.143297     |   1\n",
      "      22403 |   0.169940  |    0.027922     |   0\n",
      "      22404 |   0.021171  |    0.048593     |   2\n",
      "      22405 | \u001b[94m  0.000020\u001b[0m  |    0.049359     |   2\n",
      "      22406 |   0.165590  |    0.038799     |   0\n",
      "      22407 |   0.145157  |    0.209014     |   1\n",
      "      22408 |   0.187031  |    0.037592     |   0\n",
      "      22409 |   0.197692  |    0.077745     |   0\n",
      "      22410 |   0.006325  |    0.028920     |   2\n",
      "      22411 |   0.141166  |    0.051627     |   0\n",
      "      22412 |   0.227650  |    0.078108     |   0\n",
      "      22413 |   0.060767  |    0.013481     |   2\n",
      "      22414 |   0.203823  |    0.083320     |   0\n",
      "      22415 |   0.033877  |    0.036262     |   2\n",
      "      22416 |   0.194566  |    0.146629     |   1\n",
      "      22417 |   0.255259  |    0.048240     |   0\n",
      "      22418 |   0.186321  |    0.189944     |   1\n",
      "      22419 |   0.061200  |    0.006317     |   2\n",
      "      22420 |   0.169271  |    0.072574     |   0\n",
      "      22421 |   0.176836  |    0.042936     |   0\n",
      "      22422 |   0.043700  |    0.051640     |   2\n",
      "      22423 |   0.015140  |    0.041964     |   2\n",
      "      22424 |   0.203674  |    0.053056     |   0\n",
      "      22425 |   0.269704  |    0.197948     |   1\n",
      "      22426 |   0.193238  |    0.005194     |   0\n",
      "      22427 |   0.185349  |    0.089636     |   0\n",
      "      22428 |   0.036726  |    0.015919     |   2\n",
      "      22429 |   0.194356  |    0.072904     |   0\n",
      "      22430 |   0.204106  |    0.140243     |   1\n",
      "      22431 |   0.201199  |    0.025698     |   0\n",
      "      22432 |   0.025303  |    0.058104     |   2\n",
      "      22433 |   0.000020  |    0.099897     |   2\n",
      "      22434 |   0.177541  |    0.150036     |   1\n",
      "      22435 |   0.211369  |    0.050508     |   0\n",
      "      22436 |   0.185599  |    0.183204     |   1\n",
      "      22437 |   0.142272  |    0.147633     |   1\n",
      "      22438 |   0.180675  |    0.165584     |   1\n",
      "      22439 |   0.163468  |    0.025146     |   0\n",
      "      22440 |   0.000021  |    0.078838     |   2\n",
      "      22441 |   0.187050  |    0.055172     |   0\n",
      "      22442 |   0.188063  |    0.152894     |   1\n",
      "      22443 |   0.000021  |    0.028110     |   2\n",
      "      22444 |   0.183875  |    0.052568     |   0\n",
      "      22445 |   0.162337  |    0.210227     |   1\n",
      "      22446 |   0.226595  |    0.022444     |   0\n",
      "      22447 |   0.273245  |    0.212889     |   1\n",
      "      22448 |   0.171301  |    0.141210     |   1\n",
      "      22449 |   0.161382  |    0.006517     |   0\n",
      "      22450 |   0.000021  |    0.088779     |   2\n",
      "      22451 |   0.165879  |    0.139122     |   1\n",
      "      22452 |   0.000021  |    0.051696     |   2\n",
      "      22453 |   0.200106  |    0.150459     |   1\n",
      "      22454 |   0.000021  |    0.049416     |   2\n",
      "      22455 |   0.136824  |    0.214821     |   1\n",
      "      22456 |   0.233471  |    0.096953     |   1\n",
      "      22457 |   0.207113  |    0.198053     |   1\n",
      "      22458 |   0.195289  |    0.052005     |   0\n",
      "      22459 |   0.041701  |    0.043686     |   2\n",
      "      22460 |   0.141157  |    0.046264     |   0\n",
      "      22461 |   0.160698  |    0.046334     |   0\n",
      "      22462 |   0.190261  |    0.075982     |   0\n",
      "      22463 |   0.179660  |    0.030636     |   0\n",
      "      22464 |   0.169775  |    0.210864     |   1\n",
      "      22465 |   0.235118  |    0.093299     |   1\n",
      "      22466 |   0.199180  |    0.071254     |   0\n",
      "      22467 |   0.163066  |    0.163569     |   1\n",
      "      22468 |   0.182769  |    0.009925     |   0\n",
      "      22469 |   0.047670  |    0.083734     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 22471: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      22470 |   0.162952  |    0.014046     |   0\n",
      "      22471 |   0.248057  |    0.186637     |   1\n",
      "      22472 |   0.229386  |    0.141214     |   1\n",
      "      22473 |   0.243659  |    0.032896     |   0\n",
      "      22474 |   0.165568  |    0.185724     |   1\n",
      "      22475 |   0.179910  |    0.073844     |   0\n",
      "      22476 |   0.047809  |    0.023278     |   2\n",
      "      22477 |   0.033875  |    0.043736     |   2\n",
      "      22478 |   0.122950  |    0.041129     |   0\n",
      "      22479 |   0.180983  |    0.072869     |   0\n",
      "      22480 |   0.038041  |    0.014398     |   2\n",
      "      22481 |   0.039485  |    0.074790     |   2\n",
      "      22482 |   0.026317  |    0.023451     |   2\n",
      "      22483 |   0.159906  |    0.049909     |   0\n",
      "      22484 |   0.231293  |    0.053534     |   0\n",
      "      22485 |   0.229481  |    0.158991     |   1\n",
      "      22486 |   0.225191  |    0.195949     |   1\n",
      "      22487 |   0.036425  |    0.012946     |   2\n",
      "      22488 |   0.179213  |    0.153853     |   1\n",
      "      22489 |   0.049338  |    0.080420     |   2\n",
      "      22490 |   0.050269  |    0.008943     |   2\n",
      "      22491 |   0.042303  |    0.083522     |   2\n",
      "      22492 |   0.189483  |    0.030719     |   0\n",
      "      22493 |   0.022975  |    0.073533     |   2\n",
      "      22494 |   0.169305  |    0.148102     |   1\n",
      "      22495 |   0.160768  |    0.048356     |   0\n",
      "      22496 |   0.000021  |    0.045660     |   2\n",
      "      22497 |   0.166040  |    0.046241     |   0\n",
      "      22498 |   0.005732  |    0.051498     |   2\n",
      "      22499 |   0.061517  |    0.047393     |   2\n",
      "      22500 |   0.188221  |    0.132430     |   1\n",
      "      22501 |   0.197701  |    0.078709     |   0\n",
      "      22502 |   0.045567  |    0.024190     |   2\n",
      "      22503 |   0.141688  |    0.075957     |   0\n",
      "      22504 |   0.034253  |    0.009091     |   2\n",
      "      22505 |   0.037526  |    0.076990     |   2\n",
      "      22506 |   0.215516  |    0.070692     |   0\n",
      "      22507 |   0.037536  |    0.022764     |   2\n",
      "      22508 |   0.184377  |    0.077148     |   0\n",
      "      22509 |   0.026098  |    0.018912     |   2\n",
      "      22510 |   0.197797  |    0.071664     |   0\n",
      "      22511 |   0.189875  |    0.042020     |   0\n",
      "      22512 |   0.146701  |    0.022351     |   0\n",
      "      22513 |   0.034887  |    0.079268     |   2\n",
      "      22514 |   0.207120  |    0.162029     |   1\n",
      "      22515 |   0.179878  |    0.185401     |   1\n",
      "      22516 |   0.047057  |    0.008981     |   2\n",
      "      22517 |   0.169992  |    0.165368     |   1\n",
      "      22518 |   0.234646  |    0.044773     |   0\n",
      "      22519 |   0.152512  |    0.042129     |   0\n",
      "      22520 |   0.148937  |    0.044686     |   0\n",
      "      22521 |   0.198081  |    0.064721     |   0\n",
      "      22522 |   0.224468  |    0.228518     |   1\n",
      "      22523 |   0.135300  |    0.147433     |   1\n",
      "      22524 |   0.129620  |    0.017918     |   0\n",
      "      22525 |   0.160404  |    0.206227     |   1\n",
      "      22526 |   0.177617  |    0.147098     |   1\n",
      "      22527 |   0.163722  |    0.147514     |   1\n",
      "      22528 |   0.200121  |    0.191337     |   1\n",
      "      22529 |   0.243387  |    0.146804     |   1\n",
      "      22530 |   0.209852  |    0.048449     |   0\n",
      "      22531 |   0.142133  |    0.284680     |   1\n",
      "      22532 |   0.188561  |    0.041247     |   0\n",
      "      22533 |   0.050572  |    0.080513     |   2\n",
      "      22534 |   0.196966  |    0.255801     |   1\n",
      "      22535 |   0.231953  |    0.201285     |   1\n",
      "      22536 |   0.044269  |    0.044598     |   2\n",
      "      22537 |   0.212599  |    0.264777     |   1\n",
      "      22538 |   0.223079  |    0.240184     |   1\n",
      "      22539 |   0.153661  |    0.144418     |   1\n",
      "      22540 |   0.021393  |    0.010904     |   2\n",
      "      22541 |   0.189354  |    0.258255     |   1\n",
      "      22542 |   0.161426  |    0.239042     |   1\n",
      "      22543 |   0.000021  |    0.071975     |   2\n",
      "      22544 |   0.175508  |    0.078307     |   0\n",
      "      22545 |   0.227949  |    0.086885     |   0\n",
      "      22546 |   0.171426  |    0.266334     |   1\n",
      "      22547 |   0.217581  |    0.079566     |   0\n",
      "      22548 |   0.155129  |    0.189103     |   1\n",
      "      22549 |   0.183683  |    0.059037     |   0\n",
      "      22550 |   0.230376  |    0.254494     |   1\n",
      "      22551 |   0.005850  |    0.077526     |   2\n",
      "      22552 |   0.061439  |    0.047767     |   2\n",
      "      22553 |   0.035641  |    0.086213     |   2\n",
      "      22554 |   0.195087  |    0.153797     |   1\n",
      "      22555 |   0.178282  |    0.245119     |   1\n",
      "      22556 |   0.175079  |    0.044209     |   0\n",
      "      22557 |   0.057582  |    0.073694     |   2\n",
      "      22558 |   0.150719  |    0.081063     |   0\n",
      "      22559 |   0.224215  |    0.330289     |   1\n",
      "      22560 |   0.195803  |    0.159910     |   1\n",
      "      22561 |   0.037433  |    0.042253     |   2\n",
      "      22562 |   0.160103  |    0.292654     |   1\n",
      "      22563 |   0.015128  |    0.068333     |   2\n",
      "      22564 |   0.203945  |    0.075872     |   0\n",
      "      22565 |   0.033951  |    0.068680     |   2\n",
      "      22566 |   0.212032  |    0.070816     |   0\n",
      "      22567 |   0.131676  |    0.320971     |   1\n",
      "      22568 |   0.025265  |    0.072354     |   2\n",
      "      22569 |   0.000021  |    0.072244     |   2\n",
      "      22570 |   0.000021  |    0.078042     |   2\n",
      "      22571 |   0.000021  |    0.069451     |   2\n",
      "      22572 |   0.174981  |    0.076346     |   0\n",
      "      22573 |   0.167720  |    0.048851     |   0\n",
      "      22574 |   0.000021  |    0.070545     |   2\n",
      "      22575 |   0.207526  |    0.230507     |   1\n",
      "      22576 |   0.225249  |    0.324494     |   1\n",
      "      22577 |   0.210300  |    0.042688     |   0\n",
      "      22578 |   0.159631  |    0.084342     |   0\n",
      "      22579 |   0.189524  |    0.297656     |   1\n",
      "      22580 |   0.141630  |    0.091873     |   0\n",
      "      22581 |   0.143746  |    0.071328     |   0\n",
      "      22582 |   0.175591  |    0.039949     |   0\n",
      "      22583 |   0.162423  |    0.064247     |   0\n",
      "      22584 |   0.176725  |    0.267103     |   1\n",
      "      22585 |   0.000020  |    0.004735     |   2\n",
      "      22586 |   0.233942  |    0.070670     |   0\n",
      "      22587 |   0.204646  |    0.014849     |   0\n",
      "      22588 |   0.191205  |    0.195577     |   1\n",
      "      22589 |   0.149479  |    0.182751     |   1\n",
      "      22590 |   0.000020  |    0.016995     |   2\n",
      "      22591 |   0.186642  |    0.199287     |   1\n",
      "      22592 |   0.044967  |    0.013810     |   2\n",
      "      22593 |   0.188027  |    0.189513     |   1\n",
      "      22594 |   0.198582  |    0.147924     |   1\n",
      "      22595 |   0.182880  |    0.070792     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 22597: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      22596 |   0.048553  |    0.041033     |   2\n",
      "      22597 |   0.193421  |    0.082772     |   0\n",
      "      22598 |   0.226072  |    0.137403     |   1\n",
      "      22599 |   0.046286  |    0.060986     |   2\n",
      "      22600 |   0.220470  |    0.179144     |   1\n",
      "      22601 |   0.183178  |    0.190055     |   1\n",
      "      22602 |   0.033291  |    0.044707     |   2\n",
      "      22603 |   0.172763  |    0.024792     |   0\n",
      "      22604 |   0.037987  |    0.051895     |   2\n",
      "      22605 |   0.216806  |    0.214443     |   1\n",
      "      22606 |   0.038849  |    0.027910     |   2\n",
      "      22607 |   0.211247  |    0.078027     |   0\n",
      "      22608 |   0.025826  |    0.041709     |   2\n",
      "      22609 |   0.035617  |    0.076062     |   2\n",
      "      22610 |   0.206008  |    0.151549     |   1\n",
      "      22611 |   0.144749  |    0.135228     |   1\n",
      "      22612 |   0.182757  |    0.033254     |   0\n",
      "      22613 |   0.168199  |    0.079807     |   0\n",
      "      22614 |   0.309201  |    0.139713     |   1\n",
      "      22615 |   0.144051  |    0.077185     |   0\n",
      "      22616 |   0.184754  |    0.148422     |   1\n",
      "      22617 |   0.163676  |    0.152732     |   1\n",
      "      22618 |   0.119224  |    0.148714     |   1\n",
      "      22619 |   0.164322  |    0.081261     |   0\n",
      "      22620 |   0.187883  |    0.023754     |   0\n",
      "      22621 |   0.181056  |    0.074319     |   0\n",
      "      22622 |   0.184494  |    0.015865     |   0\n",
      "      22623 |   0.190622  |    0.207681     |   1\n",
      "      22624 |   0.045479  |    0.015971     |   2\n",
      "      22625 |   0.174531  |    0.076376     |   0\n",
      "      22626 |   0.177966  |    0.190965     |   1\n",
      "      22627 |   0.052949  |    0.005228     |   2\n",
      "      22628 |   0.043865  |    0.079510     |   2\n",
      "      22629 |   0.245162  |    0.168850     |   1\n",
      "      22630 |   0.218412  |    0.042677     |   0\n",
      "      22631 |   0.147491  |    0.188952     |   1\n",
      "      22632 |   0.019870  |    0.039304     |   2\n",
      "      22633 |   0.000021  |    0.050060     |   2\n",
      "      22634 |   0.164986  |    0.156230     |   1\n",
      "      22635 |   0.137209  |    0.216481     |   1\n",
      "      22636 |   0.199839  |    0.156459     |   1\n",
      "      22637 |   0.005519  |    0.009164     |   2\n",
      "      22638 |   0.161329  |    0.085039     |   0\n",
      "      22639 |   0.184830  |    0.203559     |   1\n",
      "      22640 |   0.200373  |    0.019785     |   0\n",
      "      22641 |   0.225686  |    0.234275     |   1\n",
      "      22642 |   0.157711  |    0.103072     |   1\n",
      "      22643 |   0.059216  |    0.026848     |   2\n",
      "      22644 |   0.192198  |    0.296206     |   1\n",
      "      22645 |   0.243819  |    0.037804     |   0\n",
      "      22646 |   0.179034  |    0.250395     |   1\n",
      "      22647 |   0.031612  |    0.087334     |   2\n",
      "      22648 |   0.059842  |    0.039493     |   2\n",
      "      22649 |   0.038525  |    0.073573     |   2\n",
      "      22650 |   0.014731  |    0.071587     |   2\n",
      "      22651 |   0.180266  |    0.072884     |   0\n",
      "      22652 |   0.032191  |    0.073404     |   2\n",
      "      22653 |   0.026202  |    0.069055     |   2\n",
      "      22654 |   0.208442  |    0.272838     |   1\n",
      "      22655 |   0.181588  |    0.073001     |   0\n",
      "      22656 |   0.181405  |    0.077433     |   0\n",
      "      22657 |   0.000021  |    0.072127     |   2\n",
      "      22658 |   0.000021  |    0.079526     |   2\n",
      "      22659 |   0.203414  |    0.024744     |   0\n",
      "      22660 |   0.000021  |    0.083578     |   2\n",
      "      22661 |   0.169567  |    0.036483     |   0\n",
      "      22662 |   0.196613  |    0.069606     |   0\n",
      "      22663 |   0.157083  |    0.076541     |   0\n",
      "      22664 |   0.156320  |    0.277979     |   1\n",
      "      22665 |   0.177488  |    0.070232     |   0\n",
      "      22666 |   0.000021  |    0.074245     |   2\n",
      "      22667 |   0.228972  |    0.326562     |   1\n",
      "      22668 |   0.000021  |    0.036264     |   2\n",
      "      22669 |   0.196006  |    0.341243     |   1\n",
      "      22670 |   0.234082  |    0.222383     |   1\n",
      "      22671 |   0.192258  |    0.229644     |   1\n",
      "      22672 |   0.000020  |    0.072438     |   2\n",
      "      22673 |   0.046947  |    0.120275     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 22675: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      22674 |   0.048733  |    0.012210     |   2\n",
      "      22675 |   0.041430  |    0.127979     |   2\n",
      "      22676 |   0.164065  |    0.157374     |   1\n",
      "      22677 |   0.200196  |    0.043937     |   0\n",
      "      22678 |   0.133480  |    0.202215     |   1\n",
      "      22679 |   0.208960  |    0.164358     |   1\n",
      "      22680 |   0.153154  |    0.151674     |   1\n",
      "      22681 |   0.197951  |    0.134112     |   1\n",
      "      22682 |   0.032847  |    0.067272     |   2\n",
      "      22683 |   0.181206  |    0.236234     |   1\n",
      "      22684 |   0.037274  |    0.007492     |   2\n",
      "      22685 |   0.208233  |    0.164972     |   1\n",
      "      22686 |   0.041742  |    0.035663     |   2\n",
      "      22687 |   0.025442  |    0.028388     |   2\n",
      "      22688 |   0.167616  |    0.236417     |   1\n",
      "      22689 |   0.033371  |    0.009921     |   2\n",
      "      22690 |   0.041367  |    0.104055     |   2\n",
      "      22691 |   0.164424  |    0.166178     |   1\n",
      "      22692 |   0.151349  |    0.223886     |   1\n",
      "      22693 |   0.049243  |    0.028410     |   2\n",
      "      22694 |   0.171580  |    0.192961     |   1\n",
      "      22695 |   0.041683  |    0.026106     |   2\n",
      "      22696 |   0.230257  |    0.219457     |   1\n",
      "      22697 |   0.021909  |    0.014239     |   2\n",
      "      22698 |   0.175735  |    0.202443     |   1\n",
      "      22699 |   0.000020  |    0.040795     |   2\n",
      "      22700 |   0.190875  |    0.059954     |   0\n",
      "      22701 |   0.197474  |    0.041708     |   0\n",
      "      22702 |   0.247356  |    0.077458     |   0\n",
      "      22703 |   0.005519  |    0.074490     |   2\n",
      "      22704 |   0.211860  |    0.156654     |   1\n",
      "      22705 |   0.161740  |    0.045414     |   0\n",
      "      22706 |   0.202429  |    0.150533     |   1\n",
      "      22707 |   0.213519  |    0.075296     |   0\n",
      "      22708 |   0.058674  |    0.019518     |   2\n",
      "      22709 |   0.193874  |    0.198552     |   1\n",
      "      22710 |   0.179015  |    0.048740     |   0\n",
      "      22711 |   0.031246  |    0.045748     |   2\n",
      "      22712 |   0.254567  |    0.190427     |   1\n",
      "      22713 |   0.058235  |    0.004171     |   2\n",
      "      22714 |   0.163927  |    0.079674     |   0\n",
      "      22715 |   0.187022  |    0.159635     |   1\n",
      "      22716 |   0.038118  |    0.024733     |   2\n",
      "      22717 |   0.205458  |    0.199142     |   1\n",
      "      22718 |   0.014156  |    0.006137     |   2\n",
      "      22719 |   0.220811  |    0.078319     |   0\n",
      "      22720 |   0.251094  |    0.043850     |   0\n",
      "      22721 |   0.031919  |    0.040325     |   2\n",
      "      22722 |   0.141722  |    0.075451     |   0\n",
      "      22723 |   0.028534  |    0.026792     |   2\n",
      "      22724 | \u001b[94m  0.000020\u001b[0m  |    0.053232     |   2\n",
      "      22725 |   0.224709  |    0.204694     |   1\n",
      "      22726 |   0.170626  |    0.192027     |   1\n",
      "      22727 |   0.151415  |    0.016774     |   0\n",
      "      22728 |   0.157166  |    0.200795     |   1\n",
      "      22729 | \u001b[94m  0.000020\u001b[0m  |    0.011558     |   2\n",
      "      22730 | \u001b[94m  0.000020\u001b[0m  |    0.050483     |   2\n",
      "      22731 |   0.000020  |    0.045272     |   2\n",
      "      22732 |   0.224208  |    0.052643     |   0\n",
      "      22733 |   0.210123  |    0.167259     |   1\n",
      "      22734 |   0.189623  |    0.045609     |   0\n",
      "      22735 |   0.190052  |    0.186558     |   1\n",
      "      22736 |   0.191802  |    0.017028     |   0\n",
      "      22737 | \u001b[94m  0.000020\u001b[0m  |    0.025144     |   2\n",
      "      22738 | \u001b[94m  0.000020\u001b[0m  |    0.044236     |   2\n",
      "      22739 |   0.151076  |    0.075532     |   0\n",
      "      22740 |   0.047539  |    0.047625     |   2\n",
      "      22741 |   0.187269  |    0.190124     |   1\n",
      "      22742 |   0.153482  |    0.006758     |   0\n",
      "      22743 |   0.048452  |    0.087652     |   2\n",
      "      22744 |   0.152647  |    0.018406     |   0\n",
      "      22745 |   0.220019  |    0.186968     |   1\n",
      "      22746 |   0.176962  |    0.022859     |   0\n",
      "      22747 |   0.221334  |    0.207717     |   1\n",
      "      22748 |   0.236195  |    0.157227     |   1\n",
      "      22749 |   0.196372  |    0.142688     |   1\n",
      "      22750 |   0.229348  |    0.132380     |   1\n",
      "      22751 |   0.153770  |    0.009312     |   0\n",
      "      22752 |   0.222560  |    0.203368     |   1\n",
      "      22753 |   0.187813  |    0.187007     |   1\n",
      "      22754 |   0.190453  |    0.005342     |   0\n",
      "      22755 |   0.191147  |    0.071700     |   0\n",
      "      22756 |   0.194210  |    0.145470     |   1\n",
      "      22757 |   0.160553  |    0.143142     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 22758: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      22758 |   0.148839  |    0.029253     |   0\n",
      "      22759 |   0.043193  |    0.072282     |   2\n",
      "      22760 |   0.032642  |    0.023839     |   2\n",
      "      22761 |   0.219914  |    0.075139     |   0\n",
      "      22762 |   0.174389  |    0.187129     |   1\n",
      "      22763 |   0.189602  |    0.007559     |   0\n",
      "      22764 |   0.209890  |    0.044481     |   0\n",
      "      22765 |   0.037808  |    0.024654     |   2\n",
      "      22766 |   0.042057  |    0.080214     |   2\n",
      "      22767 |   0.026881  |    0.030134     |   2\n",
      "      22768 |   0.227198  |    0.154262     |   1\n",
      "      22769 |   0.165908  |    0.039292     |   0\n",
      "      22770 |   0.034605  |    0.089280     |   2\n",
      "      22771 |   0.163155  |    0.149601     |   1\n",
      "      22772 |   0.193709  |    0.133076     |   1\n",
      "      22773 |   0.178308  |    0.052453     |   0\n",
      "      22774 |   0.165000  |    0.145604     |   1\n",
      "      22775 |   0.206675  |    0.043683     |   0\n",
      "      22776 |   0.250798  |    0.196767     |   1\n",
      "      22777 |   0.196804  |    0.159562     |   1\n",
      "      22778 |   0.190945  |    0.162582     |   1\n",
      "      22779 |   0.192786  |    0.130453     |   1\n",
      "      22780 |   0.043495  |    0.041509     |   2\n",
      "      22781 |   0.209574  |    0.163517     |   1\n",
      "      22782 |   0.051837  |    0.016547     |   2\n",
      "      22783 |   0.124687  |    0.207406     |   1\n",
      "      22784 |   0.043299  |    0.013247     |   2\n",
      "      22785 |   0.020795  |    0.072037     |   2\n",
      "      22786 |   0.000020  |    0.033275     |   2\n",
      "      22787 |   0.163268  |    0.185079     |   1\n",
      "      22788 |   0.005596  |    0.012641     |   2\n",
      "      22789 |   0.156729  |    0.195282     |   1\n",
      "      22790 |   0.185954  |    0.042637     |   0\n",
      "      22791 |   0.061205  |    0.051947     |   2\n",
      "      22792 |   0.173123  |    0.202719     |   1\n",
      "      22793 |   0.033187  |    0.003932     |   2\n",
      "      22794 |   0.057259  |    0.072894     |   2\n",
      "      22795 |   0.038565  |    0.029800     |   2\n",
      "      22796 |   0.013375  |    0.057144     |   2\n",
      "      22797 |   0.148494  |    0.051219     |   0\n",
      "      22798 |   0.033283  |    0.039767     |   2\n",
      "      22799 |   0.153987  |    0.046552     |   0\n",
      "      22800 |   0.208796  |    0.191300     |   1\n",
      "      22801 |   0.027055  |    0.006759     |   2\n",
      "      22802 |   0.000020  |    0.078707     |   2\n",
      "      22803 |   0.000020  |    0.039382     |   2\n",
      "      22804 |   0.000020  |    0.040106     |   2\n",
      "      22805 |   0.161668  |    0.080333     |   0\n",
      "      22806 |   0.186592  |    0.147146     |   1\n",
      "      22807 |   0.240035  |    0.163269     |   1\n",
      "      22808 |   0.164735  |    0.148647     |   1\n",
      "      22809 |   0.000020  |    0.006076     |   2\n",
      "      22810 |   0.255271  |    0.078541     |   0\n",
      "      22811 |   0.000020  |    0.010858     |   2\n",
      "      22812 |   0.184827  |    0.185050     |   1\n",
      "      22813 |   0.000020  |    0.041394     |   2\n",
      "      22814 |   0.043034  |    0.041259     |   2\n",
      "      22815 |   0.047683  |    0.050416     |   2\n",
      "      22816 |   0.210211  |    0.223423     |   1\n",
      "      22817 |   0.262069  |    0.142057     |   1\n",
      "      22818 |   0.173731  |    0.147037     |   1\n",
      "      22819 |   0.240583  |    0.058782     |   0\n",
      "      22820 |   0.151816  |    0.038224     |   0\n",
      "      22821 |   0.143171  |    0.045971     |   0\n",
      "      22822 |   0.169626  |    0.076540     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 22823: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      22823 |   0.170701  |    0.023782     |   0\n",
      "      22824 |   0.159367  |    0.079761     |   0\n",
      "      22825 |   0.179569  |    0.014251     |   0\n",
      "      22826 |   0.041697  |    0.073817     |   2\n",
      "      22827 |   0.182245  |    0.143431     |   1\n",
      "      22828 |   0.197304  |    0.073487     |   0\n",
      "      22829 |   0.031836  |    0.013850     |   2\n",
      "      22830 |   0.214884  |    0.081316     |   0\n",
      "      22831 |   0.193714  |    0.157574     |   1\n",
      "      22832 |   0.183316  |    0.044949     |   0\n",
      "      22833 |   0.171759  |    0.196303     |   1\n",
      "      22834 |   0.037744  |    0.007960     |   2\n",
      "      22835 |   0.195775  |    0.184707     |   1\n",
      "      22836 |   0.039468  |    0.039654     |   2\n",
      "      22837 |   0.228321  |    0.080124     |   0\n",
      "      22838 |   0.133745  |    0.048036     |   0\n",
      "      22839 |   0.025975  |    0.038136     |   2\n",
      "      22840 |   0.148061  |    0.192849     |   1\n",
      "      22841 |   0.203772  |    0.164447     |   1\n",
      "      22842 |   0.148799  |    0.153819     |   1\n",
      "      22843 |   0.210484  |    0.070154     |   0\n",
      "      22844 |   0.170670  |    0.068433     |   0\n",
      "      22845 |   0.193213  |    0.119341     |   0\n",
      "      22846 |   0.227569  |    0.274267     |   1\n",
      "      22847 |   0.225306  |    0.321521     |   1\n",
      "      22848 |   0.191329  |    0.387823     |   1\n",
      "      22849 |   0.179231  |    0.069735     |   0\n",
      "      22850 |   0.166413  |    0.401440     |   1\n",
      "      22851 |   0.146614  |    0.283092     |   1\n",
      "      22852 |   0.220487  |    0.375375     |   1\n",
      "      22853 |   0.035257  |    0.077715     |   2\n",
      "      22854 |   0.160019  |    0.120672     |   0\n",
      "      22855 |   0.045047  |    0.068154     |   2\n",
      "      22856 |   0.188788  |    0.081572     |   0\n",
      "      22857 |   0.182685  |    0.118364     |   0\n",
      "      22858 |   0.186533  |    0.070026     |   0\n",
      "      22859 |   0.049481  |    0.100427     |   2\n",
      "      22860 |   0.191718  |    0.076494     |   0\n",
      "      22861 |   0.167654  |    0.337739     |   1\n",
      "      22862 |   0.142223  |    0.074032     |   0\n",
      "      22863 |   0.043403  |    0.050693     |   2\n",
      "      22864 |   0.149268  |    0.215672     |   1\n",
      "      22865 |   0.151650  |    0.181065     |   1\n",
      "      22866 |   0.240248  |    0.214809     |   1\n",
      "      22867 |   0.020305  |    0.017139     |   2\n",
      "      22868 |   0.237221  |    0.261546     |   1\n",
      "      22869 |   0.000020  |    0.008146     |   2\n",
      "      22870 |   0.167866  |    0.069864     |   0\n",
      "      22871 |   0.004901  |    0.024484     |   2\n",
      "      22872 |   0.058867  |    0.045808     |   2\n",
      "      22873 |   0.193494  |    0.062149     |   0\n",
      "      22874 |   0.282764  |    0.077371     |   0\n",
      "      22875 |   0.218913  |    0.032230     |   0\n",
      "      22876 |   0.167898  |    0.189510     |   1\n",
      "      22877 |   0.034164  |    0.041755     |   2\n",
      "      22878 |   0.170757  |    0.142110     |   1\n",
      "      22879 |   0.057121  |    0.043724     |   2\n",
      "      22880 |   0.041050  |    0.037886     |   2\n",
      "      22881 |   0.014945  |    0.078381     |   2\n",
      "      22882 |   0.032832  |    0.025270     |   2\n",
      "      22883 |   0.189185  |    0.210869     |   1\n",
      "      22884 |   0.173114  |    0.014715     |   0\n",
      "      22885 |   0.027198  |    0.083121     |   2\n",
      "      22886 |   0.000020  |    0.015219     |   2\n",
      "      22887 |   0.000020  |    0.076369     |   2\n",
      "      22888 |   0.000020  |    0.027482     |   2\n",
      "      22889 |   0.153698  |    0.080060     |   0\n",
      "      22890 |   0.167745  |    0.185410     |   1\n",
      "      22891 |   0.140431  |    0.040280     |   0\n",
      "      22892 |   0.000020  |    0.074588     |   2\n",
      "      22893 |   0.000020  |    0.032143     |   2\n",
      "      22894 |   0.171951  |    0.073591     |   0\n",
      "      22895 |   0.165310  |    0.032012     |   0\n",
      "      22896 |   0.173098  |    0.201178     |   1\n",
      "      22897 |   0.231813  |    0.096123     |   1\n",
      "      22898 |   0.181284  |    0.078398     |   0\n",
      "      22899 |   0.158188  |    0.021148     |   0\n",
      "      22900 |   0.182986  |    0.075521     |   0\n",
      "      22901 |   0.119487  |    0.186198     |   1\n",
      "      22902 | \u001b[94m  0.000020\u001b[0m  |    0.036347     |   2\n",
      "      22903 |   0.159673  |    0.230640     |   1\n",
      "      22904 |   0.162691  |    0.145136     |   1\n",
      "      22905 |   0.150978  |    0.143204     |   1\n",
      "      22906 |   0.048148  |    0.041869     |   2\n",
      "      22907 |   0.194160  |    0.056882     |   0\n",
      "      22908 |   0.113882  |    0.195124     |   1\n",
      "      22909 |   0.159951  |    0.270380     |   1\n",
      "      22910 |   0.048225  |    0.124952     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 22911: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      22911 |   0.044597  |    0.076228     |   2\n",
      "      22912 |   0.147645  |    0.073606     |   0\n",
      "      22913 |   0.197701  |    0.408683     |   1\n",
      "      22914 |   0.195368  |    0.269559     |   1\n",
      "      22915 |   0.033321  |    0.087050     |   2\n",
      "      22916 |   0.157767  |    0.358166     |   1\n",
      "      22917 |   0.182833  |    0.291174     |   1\n",
      "      22918 |   0.036614  |    0.078731     |   2\n",
      "      22919 |   0.172226  |    0.040549     |   0\n",
      "      22920 |   0.163626  |    0.088252     |   0\n",
      "      22921 |   0.038956  |    0.081360     |   2\n",
      "      22922 |   0.026085  |    0.071570     |   2\n",
      "      22923 |   0.035305  |    0.070756     |   2\n",
      "      22924 |   0.203719  |    0.271811     |   1\n",
      "      22925 |   0.044744  |    0.071480     |   2\n",
      "      22926 |   0.172875  |    0.283911     |   1\n",
      "      22927 |   0.203422  |    0.182846     |   1\n",
      "      22928 |   0.145327  |    0.335490     |   1\n",
      "      22929 |   0.170701  |    0.017499     |   0\n",
      "      22930 |   0.189106  |    0.246631     |   1\n",
      "      22931 |   0.165753  |    0.271523     |   1\n",
      "      22932 |   0.050251  |    0.060989     |   2\n",
      "      22933 |   0.180358  |    0.145692     |   0\n",
      "      22934 |   0.170113  |    0.281619     |   1\n",
      "      22935 |   0.205600  |    0.260285     |   1\n",
      "      22936 |   0.178770  |    0.034783     |   0\n",
      "      22937 |   0.043408  |    0.130398     |   2\n",
      "      22938 |   0.202684  |    0.037870     |   0\n",
      "      22939 |   0.020321  |    0.094178     |   2\n",
      "      22940 |   0.206800  |    0.089375     |   0\n",
      "      22941 |   0.213556  |    0.119963     |   0\n",
      "      22942 |   0.000020  |    0.080166     |   2\n",
      "      22943 |   0.165915  |    0.037346     |   0\n",
      "      22944 |   0.004994  |    0.148260     |   2\n",
      "      22945 |   0.060219  |    0.042138     |   2\n",
      "      22946 |   0.194491  |    0.069148     |   0\n",
      "      22947 |   0.261410  |    0.319991     |   1\n",
      "      22948 |   0.033190  |    0.036847     |   2\n",
      "      22949 |   0.056775  |    0.071418     |   2\n",
      "      22950 |   0.038739  |    0.110655     |   2\n",
      "      22951 |   0.221036  |    0.077927     |   0\n",
      "      22952 |   0.199372  |    0.090316     |   0\n",
      "      22953 |   0.203940  |    0.066331     |   0\n",
      "      22954 |   0.204332  |    0.071516     |   0\n",
      "      22955 |   0.138576  |    0.113927     |   0\n",
      "      22956 |   0.158168  |    0.071973     |   0\n",
      "      22957 |   0.191999  |    0.075440     |   0\n",
      "      22958 |   0.208247  |    0.128918     |   0\n",
      "      22959 |   0.156511  |    0.018879     |   0\n",
      "      22960 |   0.201172  |    0.130876     |   0\n",
      "      22961 |   0.015881  |    0.020314     |   2\n",
      "      22962 |   0.037616  |    0.091456     |   2\n",
      "      22963 |   0.169463  |    0.340032     |   1\n",
      "      22964 |   0.183245  |    0.080544     |   0\n",
      "      22965 |   0.211744  |    0.310173     |   1\n",
      "      22966 |   0.024758  |    0.074147     |   2\n",
      "      22967 |   0.121626  |    0.388245     |   1\n",
      "      22968 |   0.184444  |    0.050246     |   0\n",
      "      22969 |   0.193058  |    0.047328     |   0\n",
      "      22970 | \u001b[94m  0.000020\u001b[0m  |    0.038088     |   2\n",
      "      22971 |   0.000020  |    0.053221     |   2\n",
      "      22972 |   0.168490  |    0.081132     |   0\n",
      "      22973 |   0.200756  |    0.260939     |   1\n",
      "      22974 |   0.194329  |    0.164452     |   1\n",
      "      22975 |   0.000020  |    0.079137     |   2\n",
      "      22976 |   0.184249  |    0.195264     |   1\n",
      "      22977 |   0.146238  |    0.293368     |   1\n",
      "      22978 |   0.207446  |    0.298017     |   1\n",
      "      22979 |   0.000020  |    0.049370     |   2\n",
      "      22980 |   0.218500  |    0.217732     |   1\n",
      "      22981 |   0.258426  |    0.223359     |   1\n",
      "      22982 |   0.182091  |    0.068868     |   0\n",
      "      22983 |   0.166499  |    0.233716     |   1\n",
      "      22984 |   0.000020  |    0.007097     |   2\n",
      "      22985 |   0.157587  |    0.078723     |   0\n",
      "      22986 |   0.223156  |    0.281102     |   1\n",
      "      22987 |   0.000020  |    0.004363     |   2\n",
      "      22988 |   0.175093  |    0.191634     |   1\n",
      "      22989 |   0.227961  |    0.279608     |   1\n",
      "      22990 |   0.208832  |    0.116227     |   1\n",
      "      22991 |   0.194484  |    0.039806     |   0\n",
      "      22992 |   0.047526  |    0.101355     |   2\n",
      "      22993 |   0.179761  |    0.053030     |   0\n",
      "      22994 |   0.047309  |    0.067576     |   2\n",
      "      22995 |   0.193319  |    0.216192     |   1\n",
      "      22996 |   0.264093  |    0.050872     |   0\n",
      "      22997 |   0.221513  |    0.072970     |   0\n",
      "      22998 |   0.282964  |    0.097864     |   0\n",
      "      22999 |   0.165621  |    0.239543     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 23000: Finished training epoch\n",
      "INFO:neuralnilm.trainer:Iteration 23000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 23000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      23000 |   0.045880  |    0.006271     |   2\n",
      "      23001 |   0.248706  |    0.274131     |   1\n",
      "      23002 |   0.045462  |    0.052047     |   2\n",
      "      23003 |   0.033914  |    0.039089     |   2\n",
      "      23004 |   0.185360  |    0.231205     |   1\n",
      "      23005 |   0.036926  |    0.061299     |   2\n",
      "      23006 |   0.040381  |    0.074538     |   2\n",
      "      23007 |   0.027007  |    0.038391     |   2\n",
      "      23008 |   0.149785  |    0.290159     |   1\n",
      "      23009 |   0.200856  |    0.197069     |   1\n",
      "      23010 |   0.181936  |    0.156651     |   1\n",
      "      23011 |   0.034706  |    0.040948     |   2\n",
      "      23012 |   0.163141  |    0.074868     |   0\n",
      "      23013 |   0.190364  |    0.053186     |   0\n",
      "      23014 |   0.046874  |    0.088777     |   2\n",
      "      23015 |   0.049829  |    0.041700     |   2\n",
      "      23016 |   0.165377  |    0.240993     |   1\n",
      "      23017 |   0.245932  |    0.223273     |   1\n",
      "      23018 |   0.041642  |    0.025716     |   2\n",
      "      23019 |   0.188630  |    0.208914     |   1\n",
      "      23020 |   0.205740  |    0.079445     |   0\n",
      "      23021 |   0.020399  |    0.025044     |   2\n",
      "      23022 |   0.143144  |    0.110746     |   0\n",
      "      23023 |   0.199244  |    0.049471     |   0\n",
      "      23024 |   0.188321  |    0.071995     |   0\n",
      "      23025 |   0.000020  |    0.028305     |   2\n",
      "      23026 |   0.005521  |    0.064610     |   2\n",
      "      23027 |   0.061146  |    0.109186     |   2\n",
      "      23028 |   0.205026  |    0.231973     |   1\n",
      "      23029 |   0.229374  |    0.292222     |   1\n",
      "      23030 |   0.197156  |    0.034054     |   0\n",
      "      23031 |   0.139269  |    0.209866     |   1\n",
      "      23032 |   0.033488  |    0.016294     |   2\n",
      "      23033 |   0.202671  |    0.284156     |   1\n",
      "      23034 |   0.220189  |    0.162270     |   1\n",
      "      23035 |   0.058156  |    0.056805     |   2\n",
      "      23036 |   0.202471  |    0.428789     |   1\n",
      "      23037 |   0.038790  |    0.158090     |   2\n",
      "      23038 |   0.169960  |    0.036448     |   0\n",
      "      23039 |   0.204581  |    0.070655     |   0\n",
      "      23040 |   0.012754  |    0.078022     |   2\n",
      "      23041 |   0.189008  |    0.075535     |   0\n",
      "      23042 |   0.182992  |    0.089980     |   0\n",
      "      23043 |   0.232642  |    0.322040     |   1\n",
      "      23044 |   0.139998  |    0.109880     |   0\n",
      "      23045 |   0.160427  |    0.294787     |   1\n",
      "      23046 |   0.214432  |    0.233878     |   1\n",
      "      23047 |   0.227282  |    0.314669     |   1\n",
      "      23048 |   0.165842  |    0.375927     |   1\n",
      "      23049 |   0.193376  |    0.048074     |   0\n",
      "      23050 |   0.032148  |    0.094427     |   2\n",
      "      23051 |   0.215647  |    0.270331     |   1\n",
      "      23052 |   0.193369  |    0.239719     |   1\n",
      "      23053 |   0.231810  |    0.120968     |   0\n",
      "      23054 |   0.024541  |    0.071095     |   2\n",
      "      23055 |   0.000020  |    0.120663     |   2\n",
      "      23056 |   0.180108  |    0.013385     |   0\n",
      "      23057 |   0.161393  |    0.090577     |   0\n",
      "      23058 |   0.000020  |    0.110481     |   2\n",
      "      23059 |   0.203129  |    0.243559     |   1\n",
      "      23060 |   0.000020  |    0.071822     |   2\n",
      "      23061 |   0.000020  |    0.131781     |   2\n",
      "      23062 |   0.184668  |    0.317504     |   1\n",
      "      23063 |   0.000020  |    0.125517     |   2\n",
      "      23064 |   0.171874  |    0.060359     |   0\n",
      "      23065 |   0.000020  |    0.069840     |   2\n",
      "      23066 |   0.158030  |    0.132933     |   0\n",
      "      23067 |   0.245198  |    0.278893     |   1\n",
      "      23068 |   0.156245  |    0.100233     |   0\n",
      "      23069 |   0.157545  |    0.378560     |   1\n",
      "      23070 |   0.228767  |    0.036788     |   0\n",
      "      23071 |   0.044209  |    0.158581     |   2\n",
      "      23072 |   0.243900  |    0.312267     |   1\n",
      "      23073 |   0.047488  |    0.077177     |   2\n",
      "      23074 |   0.175586  |    0.072422     |   0\n",
      "      23075 |   0.174389  |    0.071833     |   0\n",
      "      23076 |   0.204610  |    0.123074     |   0\n",
      "      23077 |   0.136474  |    0.225498     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 23078: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      23078 |   0.215824  |    0.126915     |   0\n",
      "      23079 |   0.245049  |    0.240425     |   1\n",
      "      23080 |   0.151719  |    0.040024     |   0\n",
      "      23081 |   0.261689  |    0.294028     |   1\n",
      "      23082 |   0.231258  |    0.288013     |   1\n",
      "      23083 |   0.046436  |    0.076340     |   2\n",
      "      23084 |   0.206928  |    0.288292     |   1\n",
      "      23085 |   0.198905  |    0.289746     |   1\n",
      "      23086 |   0.161893  |    0.007579     |   0\n",
      "      23087 |   0.032837  |    0.078203     |   2\n",
      "      23088 |   0.037766  |    0.064207     |   2\n",
      "      23089 |   0.038653  |    0.073313     |   2\n",
      "      23090 |   0.240605  |    0.185693     |   1\n",
      "      23091 |   0.192403  |    0.050301     |   0\n",
      "      23092 |   0.255140  |    0.233596     |   1\n",
      "      23093 |   0.126578  |    0.282309     |   1\n",
      "      23094 |   0.025212  |    0.022924     |   2\n",
      "      23095 |   0.230230  |    0.239090     |   1\n",
      "      23096 |   0.191545  |    0.226687     |   1\n",
      "      23097 |   0.033674  |    0.029382     |   2\n",
      "      23098 |   0.209550  |    0.107866     |   0\n",
      "      23099 |   0.155270  |    0.058680     |   0\n",
      "      23100 |   0.156554  |    0.025900     |   0\n",
      "      23101 |   0.176897  |    0.079501     |   0\n",
      "      23102 |   0.046407  |    0.043664     |   2\n",
      "      23103 |   0.051631  |    0.073689     |   2\n",
      "      23104 |   0.185848  |    0.219835     |   1\n",
      "      23105 |   0.039021  |    0.044635     |   2\n",
      "      23106 |   0.196289  |    0.235162     |   1\n",
      "      23107 |   0.198207  |    0.046505     |   0\n",
      "      23108 |   0.265582  |    0.261979     |   1\n",
      "      23109 |   0.193915  |    0.235778     |   1\n",
      "      23110 |   0.021364  |    0.073958     |   2\n",
      "      23111 |   0.276081  |    0.232086     |   1\n",
      "      23112 |   0.000020  |    0.016699     |   2\n",
      "      23113 |   0.205531  |    0.101143     |   0\n",
      "      23114 |   0.189096  |    0.217173     |   1\n",
      "      23115 |   0.005787  |    0.014516     |   2\n",
      "      23116 |   0.206365  |    0.079561     |   0\n",
      "      23117 |   0.163221  |    0.039008     |   0\n",
      "      23118 |   0.060749  |    0.043900     |   2\n",
      "      23119 |   0.147263  |    0.094671     |   0\n",
      "      23120 |   0.159802  |    0.185523     |   1\n",
      "      23121 |   0.031695  |    0.085764     |   2\n",
      "      23122 |   0.252788  |    0.204239     |   1\n",
      "      23123 |   0.057148  |    0.007283     |   2\n",
      "      23124 |   0.038581  |    0.089115     |   2\n",
      "      23125 |   0.013911  |    0.073956     |   2\n",
      "      23126 |   0.171214  |    0.059628     |   0\n",
      "      23127 |   0.183296  |    0.042034     |   0\n",
      "      23128 |   0.203909  |    0.219451     |   1\n",
      "      23129 |   0.162610  |    0.098792     |   0\n",
      "      23130 |   0.143789  |    0.213708     |   1\n",
      "      23131 |   0.171539  |    0.280962     |   1\n",
      "      23132 |   0.175463  |    0.219858     |   1\n",
      "      23133 |   0.121377  |    0.253362     |   1\n",
      "      23134 |   0.035611  |    0.013757     |   2\n",
      "      23135 |   0.025516  |    0.119355     |   2\n",
      "      23136 |   0.193110  |    0.299325     |   1\n",
      "      23137 |   0.150735  |    0.005883     |   0\n",
      "      23138 |   0.206714  |    0.236308     |   1\n",
      "      23139 |   0.233528  |    0.033103     |   0\n",
      "      23140 |   0.206976  |    0.243952     |   1\n",
      "      23141 |   0.214283  |    0.060687     |   0\n",
      "      23142 |   0.158108  |    0.076880     |   0\n",
      "      23143 |   0.153430  |    0.023835     |   0\n",
      "      23144 |   0.186723  |    0.119437     |   0\n",
      "      23145 |   0.151757  |    0.288763     |   1\n",
      "      23146 | \u001b[94m  0.000019\u001b[0m  |    0.005943     |   2\n",
      "      23147 | \u001b[94m  0.000019\u001b[0m  |    0.097619     |   2\n",
      "      23148 |   0.146039  |    0.027579     |   0\n",
      "      23149 |   0.178244  |    0.306350     |   1\n",
      "      23150 |   0.229252  |    0.197890     |   1\n",
      "      23151 |   0.194632  |    0.043103     |   0\n",
      "      23152 | \u001b[94m  0.000019\u001b[0m  |    0.083848     |   2\n",
      "      23153 |   0.229614  |    0.227578     |   1\n",
      "      23154 |   0.000019  |    0.006354     |   2\n",
      "      23155 |   0.236930  |    0.106748     |   0\n",
      "      23156 | \u001b[94m  0.000019\u001b[0m  |    0.022278     |   2\n",
      "      23157 | \u001b[94m  0.000019\u001b[0m  |    0.082716     |   2\n",
      "      23158 |   0.191719  |    0.033666     |   0\n",
      "      23159 |   0.042304  |    0.119139     |   2\n",
      "      23160 |   0.047847  |    0.043173     |   2\n",
      "      23161 |   0.154013  |    0.257668     |   1\n",
      "      23162 |   0.148899  |    0.206518     |   1\n",
      "      23163 |   0.178255  |    0.220104     |   1\n",
      "      23164 |   0.131233  |    0.046615     |   0\n",
      "      23165 |   0.255587  |    0.081238     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 23166: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      23166 |   0.181514  |    0.045605     |   0\n",
      "      23167 |   0.188616  |    0.039571     |   0\n",
      "      23168 |   0.151874  |    0.112969     |   0\n",
      "      23169 |   0.045366  |    0.029216     |   2\n",
      "      23170 |   0.146891  |    0.286628     |   1\n",
      "      23171 |   0.116582  |    0.189323     |   1\n",
      "      23172 |   0.147582  |    0.026079     |   0\n",
      "      23173 |   0.032900  |    0.084012     |   2\n",
      "      23174 |   0.038709  |    0.122212     |   2\n",
      "      23175 |   0.209165  |    0.194741     |   1\n",
      "      23176 |   0.037467  |    0.054084     |   2\n",
      "      23177 |   0.026012  |    0.052587     |   2\n",
      "      23178 |   0.232937  |    0.307687     |   1\n",
      "      23179 |   0.183869  |    0.007393     |   0\n",
      "      23180 |   0.037487  |    0.134854     |   2\n",
      "      23181 |   0.193260  |    0.222458     |   1\n",
      "      23182 |   0.174484  |    0.197666     |   1\n",
      "      23183 |   0.046403  |    0.044711     |   2\n",
      "      23184 |   0.153343  |    0.044895     |   0\n",
      "      23185 |   0.203195  |    0.079608     |   0\n",
      "      23186 |   0.217753  |    0.066929     |   0\n",
      "      23187 |   0.147955  |    0.232471     |   1\n",
      "      23188 |   0.200531  |    0.215455     |   1\n",
      "      23189 |   0.131889  |    0.018196     |   0\n",
      "      23190 |   0.180136  |    0.262382     |   1\n",
      "      23191 |   0.145259  |    0.301739     |   1\n",
      "      23192 |   0.181319  |    0.189878     |   1\n",
      "      23193 |   0.214149  |    0.019623     |   0\n",
      "      23194 |   0.245083  |    0.280216     |   1\n",
      "      23195 |   0.181577  |    0.042703     |   0\n",
      "      23196 |   0.149392  |    0.179263     |   1\n",
      "      23197 |   0.180977  |    0.234999     |   1\n",
      "      23198 |   0.048719  |    0.110483     |   2\n",
      "      23199 |   0.042262  |    0.013902     |   2\n",
      "      23200 |   0.287910  |    0.113324     |   0\n",
      "      23201 |   0.022084  |    0.008309     |   2\n",
      "      23202 |   0.000019  |    0.121142     |   2\n",
      "      23203 |   0.005371  |    0.095388     |   2\n",
      "      23204 |   0.183507  |    0.292137     |   1\n",
      "      23205 |   0.060803  |    0.009620     |   2\n",
      "      23206 |   0.147510  |    0.084304     |   0\n",
      "      23207 |   0.159339  |    0.187181     |   1\n",
      "      23208 |   0.201932  |    0.039132     |   0\n",
      "      23209 |   0.032938  |    0.067947     |   2\n",
      "      23210 |   0.236914  |    0.253371     |   1\n",
      "      23211 |   0.188482  |    0.228810     |   1\n",
      "      23212 |   0.060024  |    0.038682     |   2\n",
      "      23213 |   0.042554  |    0.132824     |   2\n",
      "      23214 |   0.164861  |    0.187701     |   1\n",
      "      23215 |   0.228094  |    0.053641     |   0\n",
      "      23216 |   0.014109  |    0.066302     |   2\n",
      "      23217 |   0.209232  |    0.211284     |   1\n",
      "      23218 |   0.035292  |    0.064032     |   2\n",
      "      23219 |   0.211668  |    0.196234     |   1\n",
      "      23220 |   0.161574  |    0.133014     |   0\n",
      "      23221 |   0.027431  |    0.003197     |   2\n",
      "      23222 |   0.000019  |    0.080129     |   2\n",
      "      23223 |   0.000019  |    0.107588     |   2\n",
      "      23224 |   0.195083  |    0.191493     |   1\n",
      "      23225 |   0.188061  |    0.009024     |   0\n",
      "      23226 |   0.000019  |    0.081518     |   2\n",
      "      23227 |   0.187663  |    0.260265     |   1\n",
      "      23228 |   0.210146  |    0.040280     |   0\n",
      "      23229 |   0.000019  |    0.041089     |   2\n",
      "      23230 |   0.162508  |    0.078838     |   0\n",
      "      23231 |   0.000019  |    0.008716     |   2\n",
      "      23232 |   0.203700  |    0.105318     |   0\n",
      "      23233 |   0.143101  |    0.261883     |   1\n",
      "      23234 | \u001b[94m  0.000019\u001b[0m  |    0.028831     |   2\n",
      "      23235 |   0.192212  |    0.219401     |   1\n",
      "      23236 |   0.042737  |    0.021330     |   2\n",
      "      23237 |   0.179045  |    0.091938     |   0\n",
      "      23238 |   0.047396  |    0.013069     |   2\n",
      "      23239 |   0.163642  |    0.093028     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 23240: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      23240 |   0.187727  |    0.195758     |   1\n",
      "      23241 |   0.176480  |    0.167814     |   1\n",
      "      23242 |   0.192163  |    0.075896     |   0\n",
      "      23243 |   0.044550  |    0.045305     |   2\n",
      "      23244 |   0.201846  |    0.085631     |   0\n",
      "      23245 |   0.173705  |    0.202176     |   1\n",
      "      23246 |   0.157505  |    0.006886     |   0\n",
      "      23247 |   0.157296  |    0.150118     |   0\n",
      "      23248 |   0.234498  |    0.162734     |   1\n",
      "      23249 |   0.034551  |    0.029829     |   2\n",
      "      23250 |   0.174719  |    0.241297     |   1\n",
      "      23251 |   0.172752  |    0.219517     |   1\n",
      "      23252 |   0.167564  |    0.242740     |   1\n",
      "      23253 |   0.181416  |    0.261954     |   1\n",
      "      23254 |   0.182182  |    0.010367     |   0\n",
      "      23255 |   0.164879  |    0.226911     |   1\n",
      "      23256 |   0.036614  |    0.022162     |   2\n",
      "      23257 |   0.152560  |    0.268556     |   1\n",
      "      23258 |   0.180823  |    0.022065     |   0\n",
      "      23259 |   0.202173  |    0.114653     |   0\n",
      "      23260 |   0.038186  |    0.009229     |   2\n",
      "      23261 |   0.026783  |    0.110370     |   2\n",
      "      23262 |   0.150361  |    0.037973     |   0\n",
      "      23263 |   0.171984  |    0.256933     |   1\n",
      "      23264 |   0.035803  |    0.043074     |   2\n",
      "      23265 |   0.216913  |    0.243742     |   1\n",
      "      23266 |   0.048620  |    0.025478     |   2\n",
      "      23267 |   0.165271  |    0.111441     |   0\n",
      "      23268 |   0.196061  |    0.206513     |   1\n",
      "      23269 |   0.129022  |    0.230786     |   1\n",
      "      23270 |   0.149004  |    0.037072     |   0\n",
      "      23271 |   0.048635  |    0.109975     |   2\n",
      "      23272 |   0.182375  |    0.255698     |   1\n",
      "      23273 |   0.043758  |    0.013988     |   2\n",
      "      23274 |   0.201400  |    0.219871     |   1\n",
      "      23275 |   0.210738  |    0.223820     |   1\n",
      "      23276 |   0.021005  |    0.023029     |   2\n",
      "      23277 | \u001b[94m  0.000019\u001b[0m  |    0.111141     |   2\n",
      "      23278 |   0.004965  |    0.012488     |   2\n",
      "      23279 |   0.153407  |    0.271899     |   1\n",
      "      23280 |   0.189772  |    0.029054     |   0\n",
      "      23281 |   0.161982  |    0.258580     |   1\n",
      "      23282 |   0.061117  |    0.028353     |   2\n",
      "      23283 |   0.160299  |    0.074263     |   0\n",
      "      23284 |   0.194309  |    0.072649     |   0\n",
      "      23285 |   0.156082  |    0.176126     |   1\n",
      "      23286 |   0.034099  |    0.021274     |   2\n",
      "      23287 |   0.142377  |    0.109763     |   0\n",
      "      23288 |   0.059010  |    0.003499     |   2\n",
      "      23289 |   0.041167  |    0.105619     |   2\n",
      "      23290 |   0.153719  |    0.025069     |   0\n",
      "      23291 |   0.013757  |    0.051507     |   2\n",
      "      23292 |   0.159252  |    0.286536     |   1\n",
      "      23293 |   0.158903  |    0.151348     |   1\n",
      "      23294 |   0.205827  |    0.049492     |   0\n",
      "      23295 |   0.188990  |    0.247331     |   1\n",
      "      23296 |   0.198549  |    0.213020     |   1\n",
      "      23297 |   0.035194  |    0.011680     |   2\n",
      "      23298 |   0.024020  |    0.071657     |   2\n",
      "      23299 |   0.126609  |    0.247035     |   1\n",
      "      23300 |   0.169498  |    0.059844     |   0\n",
      "      23301 |   0.186760  |    0.066116     |   0\n",
      "      23302 |   0.162475  |    0.216926     |   1\n",
      "      23303 |   0.168959  |    0.030856     |   0\n",
      "      23304 |   0.130327  |    0.064192     |   0\n",
      "      23305 |   0.203424  |    0.040032     |   0\n",
      "      23306 |   0.000019  |    0.069512     |   2\n",
      "      23307 |   0.174746  |    0.239869     |   1\n",
      "      23308 |   0.232719  |    0.202881     |   1\n",
      "      23309 |   0.159849  |    0.027495     |   0\n",
      "      23310 |   0.183977  |    0.335211     |   1\n",
      "      23311 |   0.223251  |    0.192779     |   1\n",
      "      23312 |   0.000019  |    0.040158     |   2\n",
      "      23313 |   0.182993  |    0.086527     |   0\n",
      "      23314 |   0.136922  |    0.068361     |   0\n",
      "      23315 |   0.203283  |    0.067771     |   0\n",
      "      23316 |   0.177961  |    0.249357     |   1\n",
      "      23317 |   0.222413  |    0.231174     |   1\n",
      "      23318 |   0.000019  |    0.027000     |   2\n",
      "      23319 |   0.000019  |    0.073904     |   2\n",
      "      23320 |   0.000019  |    0.021840     |   2\n",
      "      23321 |   0.000019  |    0.122047     |   2\n",
      "      23322 |   0.169220  |    0.214446     |   1\n",
      "      23323 |   0.046356  |    0.040141     |   2\n",
      "      23324 |   0.185107  |    0.044636     |   0\n",
      "      23325 |   0.235074  |    0.238444     |   1\n",
      "      23326 |   0.232414  |    0.226524     |   1\n",
      "      23327 |   0.180275  |    0.201812     |   1\n",
      "      23328 |   0.153822  |    0.286866     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 23330: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      23329 |   0.047934  |    0.006405     |   2\n",
      "      23330 |   0.188619  |    0.171574     |   1\n",
      "      23331 |   0.237303  |    0.197817     |   1\n",
      "      23332 |   0.159594  |    0.067829     |   0\n",
      "      23333 |   0.133403  |    0.063625     |   0\n",
      "      23334 |   0.043329  |    0.097634     |   2\n",
      "      23335 |   0.033033  |    0.034702     |   2\n",
      "      23336 |   0.165937  |    0.229986     |   1\n",
      "      23337 |   0.214058  |    0.245170     |   1\n",
      "      23338 |   0.169879  |    0.010249     |   0\n",
      "      23339 |   0.037472  |    0.082306     |   2\n",
      "      23340 |   0.184974  |    0.257190     |   1\n",
      "      23341 |   0.172528  |    0.071247     |   0\n",
      "      23342 |   0.037294  |    0.065340     |   2\n",
      "      23343 |   0.181488  |    0.223436     |   1\n",
      "      23344 |   0.025301  |    0.004259     |   2\n",
      "      23345 |   0.164047  |    0.067334     |   0\n",
      "      23346 |   0.155055  |    0.081991     |   0\n",
      "      23347 |   0.034556  |    0.028526     |   2\n",
      "      23348 |   0.183237  |    0.234193     |   1\n",
      "      23349 |   0.171762  |    0.226713     |   1\n",
      "      23350 |   0.173984  |    0.064357     |   0\n",
      "      23351 |   0.149882  |    0.208321     |   1\n",
      "      23352 |   0.135217  |    0.081267     |   0\n",
      "      23353 |   0.218129  |    0.209523     |   1\n",
      "      23354 |   0.044317  |    0.014154     |   2\n",
      "      23355 |   0.050994  |    0.122217     |   2\n",
      "      23356 |   0.167578  |    0.003371     |   0\n",
      "      23357 |   0.041469  |    0.100932     |   2\n",
      "      23358 |   0.020366  |    0.044482     |   2\n",
      "      23359 |   0.187799  |    0.077159     |   0\n",
      "      23360 |   0.149785  |    0.213204     |   1\n",
      "      23361 |   0.151528  |    0.064245     |   0\n",
      "      23362 | \u001b[94m  0.000019\u001b[0m  |    0.068300     |   2\n",
      "      23363 |   0.005154  |    0.041573     |   2\n",
      "      23364 |   0.205795  |    0.265260     |   1\n",
      "      23365 |   0.184378  |    0.041289     |   0\n",
      "      23366 |   0.059723  |    0.067625     |   2\n",
      "      23367 |   0.151199  |    0.209388     |   1\n",
      "      23368 |   0.254782  |    0.223824     |   1\n",
      "      23369 |   0.032637  |    0.004243     |   2\n",
      "      23370 |   0.055791  |    0.070097     |   2\n",
      "      23371 |   0.042554  |    0.069632     |   2\n",
      "      23372 |   0.185683  |    0.063370     |   0\n",
      "      23373 |   0.017584  |    0.077206     |   2\n",
      "      23374 |   0.181947  |    0.261223     |   1\n",
      "      23375 |   0.170198  |    0.024137     |   0\n",
      "      23376 |   0.033246  |    0.081295     |   2\n",
      "      23377 |   0.196200  |    0.068288     |   0\n",
      "      23378 |   0.218169  |    0.227019     |   1\n",
      "      23379 |   0.173322  |    0.006861     |   0\n",
      "      23380 |   0.208140  |    0.152615     |   0\n",
      "      23381 |   0.264201  |    0.008522     |   0\n",
      "      23382 |   0.026970  |    0.092308     |   2\n",
      "      23383 | \u001b[94m  0.000019\u001b[0m  |    0.048273     |   2\n",
      "      23384 |   0.195532  |    0.081836     |   0\n",
      "      23385 |   0.183439  |    0.053126     |   0\n",
      "      23386 |   0.150531  |    0.244168     |   1\n",
      "      23387 |   0.204634  |    0.258182     |   1\n",
      "      23388 |   0.234084  |    0.211521     |   1\n",
      "      23389 |   0.261659  |    0.226183     |   1\n",
      "      23390 |   0.220395  |    0.222952     |   1\n",
      "      23391 |   0.170208  |    0.163901     |   1\n",
      "      23392 |   0.160899  |    0.023934     |   0\n",
      "      23393 |   0.148633  |    0.128764     |   0\n",
      "      23394 |   0.208459  |    0.215988     |   1\n",
      "      23395 | \u001b[94m  0.000019\u001b[0m  |    0.061989     |   2\n",
      "      23396 |   0.000019  |    0.010115     |   2\n",
      "      23397 |   0.179397  |    0.271689     |   1\n",
      "      23398 |   0.189529  |    0.268122     |   1\n",
      "      23399 |   0.000019  |    0.003703     |   2\n",
      "      23400 |   0.166499  |    0.070572     |   0\n",
      "      23401 | \u001b[94m  0.000019\u001b[0m  |    0.076092     |   2\n",
      "      23402 |   0.193578  |    0.274355     |   1\n",
      "      23403 |   0.170395  |    0.168365     |   1\n",
      "      23404 |   0.191775  |    0.113711     |   0\n",
      "      23405 |   0.169303  |    0.024635     |   0\n",
      "      23406 |   0.140435  |    0.066351     |   0\n",
      "      23407 |   0.228159  |    0.120673     |   0\n",
      "      23408 |   0.129292  |    0.024644     |   0\n",
      "      23409 |   0.157301  |    0.069937     |   0\n",
      "      23410 | \u001b[94m  0.000019\u001b[0m  |    0.115693     |   2\n",
      "      23411 |   0.042744  |    0.046043     |   2\n",
      "      23412 |   0.153416  |    0.162664     |   0\n",
      "      23413 |   0.046521  |    0.003196     |   2\n",
      "      23414 |   0.156026  |    0.305986     |   1\n",
      "      23415 |   0.148084  |    0.235458     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 23416: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      23416 |   0.176606  |    0.288847     |   1\n",
      "      23417 |   0.046405  |    0.050369     |   2\n",
      "      23418 |   0.138471  |    0.292876     |   1\n",
      "      23419 |   0.174944  |    0.109606     |   0\n",
      "      23420 |   0.211562  |    0.028803     |   0\n",
      "      23421 |   0.152987  |    0.062844     |   0\n",
      "      23422 |   0.163911  |    0.088868     |   0\n",
      "      23423 |   0.192587  |    0.039338     |   0\n",
      "      23424 |   0.185847  |    0.114042     |   0\n",
      "      23425 |   0.142388  |    0.237744     |   1\n",
      "      23426 |   0.030991  |    0.009665     |   2\n",
      "      23427 |   0.038380  |    0.085814     |   2\n",
      "      23428 |   0.142279  |    0.215776     |   1\n",
      "      23429 |   0.226080  |    0.248829     |   1\n",
      "      23430 |   0.040037  |    0.127444     |   2\n",
      "      23431 |   0.026084  |    0.018249     |   2\n",
      "      23432 |   0.161381  |    0.326541     |   1\n",
      "      23433 |   0.195121  |    0.066272     |   0\n",
      "      23434 |   0.034166  |    0.077631     |   2\n",
      "      23435 |   0.165592  |    0.143645     |   0\n",
      "      23436 |   0.176591  |    0.280356     |   1\n",
      "      23437 |   0.157699  |    0.206979     |   1\n",
      "      23438 |   0.048231  |    0.152328     |   2\n",
      "      23439 |   0.048736  |    0.003597     |   2\n",
      "      23440 |   0.240633  |    0.337934     |   1\n",
      "      23441 |   0.042337  |    0.003265     |   2\n",
      "      23442 |   0.020659  |    0.011148     |   2\n",
      "      23443 |   0.147851  |    0.357144     |   1\n",
      "      23444 |   0.000019  |    0.026409     |   2\n",
      "      23445 |   0.191836  |    0.139667     |   0\n",
      "      23446 |   0.005005  |    0.027568     |   2\n",
      "      23447 |   0.194629  |    0.067275     |   0\n",
      "      23448 |   0.205681  |    0.093474     |   0\n",
      "      23449 |   0.197985  |    0.264241     |   1\n",
      "      23450 |   0.141391  |    0.214948     |   1\n",
      "      23451 |   0.058968  |    0.072482     |   2\n",
      "      23452 |   0.032269  |    0.079705     |   2\n",
      "      23453 |   0.276031  |    0.129637     |   0\n",
      "      23454 |   0.055793  |    0.012253     |   2\n",
      "      23455 |   0.174450  |    0.325691     |   1\n",
      "      23456 |   0.039264  |    0.022318     |   2\n",
      "      23457 |   0.139913  |    0.042805     |   0\n",
      "      23458 |   0.016735  |    0.168055     |   2\n",
      "      23459 |   0.237882  |    0.180300     |   1\n",
      "      23460 |   0.219968  |    0.136220     |   1\n",
      "      23461 |   0.033117  |    0.096954     |   2\n",
      "      23462 |   0.023707  |    0.041534     |   2\n",
      "      23463 |   0.207513  |    0.093032     |   0\n",
      "      23464 |   0.174788  |    0.293029     |   1\n",
      "      23465 |   0.000019  |    0.049662     |   2\n",
      "      23466 |   0.000019  |    0.144198     |   2\n",
      "      23467 |   0.000019  |    0.019775     |   2\n",
      "      23468 |   0.000019  |    0.186033     |   2\n",
      "      23469 |   0.265541  |    0.014533     |   0\n",
      "      23470 |   0.166663  |    0.316173     |   1\n",
      "      23471 |   0.218409  |    0.219461     |   1\n",
      "      23472 |   0.174775  |    0.300301     |   1\n",
      "      23473 |   0.000019  |    0.074076     |   2\n",
      "      23474 |   0.178204  |    0.143337     |   0\n",
      "      23475 |   0.264233  |    0.280548     |   1\n",
      "      23476 |   0.000019  |    0.021672     |   2\n",
      "      23477 |   0.154749  |    0.332678     |   1\n",
      "      23478 |   0.185369  |    0.320791     |   1\n",
      "      23479 |   0.229237  |    0.070676     |   0\n",
      "      23480 |   0.226652  |    0.355833     |   1\n",
      "      23481 |   0.187411  |    0.061483     |   0\n",
      "      23482 |   0.160905  |    0.148233     |   0\n",
      "      23483 |   0.155334  |    0.010224     |   0\n",
      "      23484 |   0.208325  |    0.373197     |   1\n",
      "      23485 |   0.041571  |    0.068138     |   2\n",
      "      23486 |   0.221255  |    0.095042     |   0\n",
      "      23487 |   0.292609  |    0.136011     |   0\n",
      "      23488 |   0.168252  |    0.408067     |   1\n",
      "      23489 |   0.182505  |    0.123228     |   0\n",
      "      23490 |   0.046560  |    0.040193     |   2\n",
      "      23491 |   0.197682  |    0.220227     |   1\n",
      "      23492 |   0.142590  |    0.072229     |   0\n",
      "      23493 |   0.190752  |    0.240260     |   1\n",
      "      23494 |   0.187171  |    0.204483     |   1\n",
      "      23495 |   0.233144  |    0.098405     |   0\n",
      "      23496 |   0.226918  |    0.201901     |   1\n",
      "      23497 |   0.186548  |    0.188403     |   1\n",
      "      23498 |   0.119968  |    0.275782     |   1\n",
      "      23499 |   0.200151  |    0.064324     |   0\n",
      "      23500 |   0.181500  |    0.067569     |   0\n",
      "      23501 |   0.208585  |    0.228958     |   1\n",
      "      23502 |   0.046259  |    0.069107     |   2\n",
      "      23503 |   0.220665  |    0.215574     |   1\n",
      "      23504 |   0.161887  |    0.100232     |   0\n",
      "      23505 |   0.031370  |    0.012793     |   2\n",
      "      23506 |   0.150380  |    0.096852     |   0\n",
      "      23507 |   0.224760  |    0.323740     |   1\n",
      "      23508 |   0.202532  |    0.387123     |   1\n",
      "      23509 |   0.037941  |    0.060929     |   2\n",
      "      23510 |   0.195332  |    0.393175     |   1\n",
      "      23511 |   0.040080  |    0.058429     |   2\n",
      "      23512 |   0.027163  |    0.099055     |   2\n",
      "      23513 |   0.034123  |    0.077362     |   2\n",
      "      23514 |   0.155540  |    0.356792     |   1\n",
      "      23515 |   0.193260  |    0.281540     |   1\n",
      "      23516 |   0.196270  |    0.310695     |   1\n",
      "      23517 |   0.049373  |    0.068425     |   2\n",
      "      23518 |   0.220746  |    0.383940     |   1\n",
      "      23519 |   0.149666  |    0.087687     |   0\n",
      "      23520 |   0.198933  |    0.037937     |   0\n",
      "      23521 |   0.189994  |    0.387681     |   1\n",
      "      23522 |   0.049792  |    0.024839     |   2\n",
      "      23523 |   0.207502  |    0.141593     |   0\n",
      "      23524 |   0.144108  |    0.117762     |   0\n",
      "      23525 |   0.191215  |    0.143096     |   0\n",
      "      23526 |   0.203811  |    0.027350     |   0\n",
      "      23527 |   0.150567  |    0.112414     |   0\n",
      "      23528 |   0.042407  |    0.086787     |   2\n",
      "      23529 |   0.020145  |    0.084588     |   2\n",
      "      23530 |   0.000019  |    0.100126     |   2\n",
      "      23531 |   0.005233  |    0.112536     |   2\n",
      "      23532 |   0.059205  |    0.078748     |   2\n",
      "      23533 |   0.185344  |    0.385550     |   1\n",
      "      23534 |   0.195955  |    0.022600     |   0\n",
      "      23535 |   0.208430  |    0.146785     |   0\n",
      "      23536 |   0.138256  |    0.286343     |   1\n",
      "      23537 |   0.192452  |    0.020874     |   0\n",
      "      23538 |   0.144010  |    0.176652     |   0\n",
      "      23539 |   0.178606  |    0.264935     |   1\n",
      "      23540 |   0.163941  |    0.004548     |   0\n",
      "      23541 |   0.034938  |    0.110960     |   2\n",
      "      23542 |   0.244212  |    0.280184     |   1\n",
      "      23543 |   0.181244  |    0.012080     |   0\n",
      "      23544 |   0.058324  |    0.079301     |   2\n",
      "      23545 |   0.038316  |    0.084664     |   2\n",
      "      23546 |   0.202815  |    0.166486     |   1\n",
      "      23547 |   0.018081  |    0.034161     |   2\n",
      "      23548 |   0.038761  |    0.072827     |   2\n",
      "      23549 |   0.157853  |    0.239733     |   1\n",
      "      23550 |   0.161927  |    0.052537     |   0\n",
      "      23551 |   0.166077  |    0.231427     |   1\n",
      "      23552 |   0.223532  |    0.241299     |   1\n",
      "      23553 |   0.174206  |    0.004246     |   0\n",
      "      23554 |   0.207074  |    0.246351     |   1\n",
      "      23555 |   0.200487  |    0.158444     |   1\n",
      "      23556 |   0.185020  |    0.060419     |   0\n",
      "      23557 |   0.026245  |    0.075494     |   2\n",
      "      23558 |   0.194600  |    0.229393     |   1\n",
      "      23559 |   0.175376  |    0.062483     |   0\n",
      "      23560 |   0.218901  |    0.066557     |   0\n",
      "      23561 |   0.000019  |    0.077538     |   2\n",
      "      23562 |   0.000019  |    0.044045     |   2\n",
      "      23563 |   0.139873  |    0.098398     |   0\n",
      "      23564 |   0.000019  |    0.013994     |   2\n",
      "      23565 |   0.154061  |    0.268507     |   1\n",
      "      23566 |   0.000019  |    0.028782     |   2\n",
      "      23567 |   0.155553  |    0.228649     |   1\n",
      "      23568 |   0.000019  |    0.011893     |   2\n",
      "      23569 |   0.183682  |    0.095211     |   0\n",
      "      23570 |   0.181913  |    0.039594     |   0\n",
      "      23571 |   0.187476  |    0.310048     |   1\n",
      "      23572 |   0.175699  |    0.023081     |   0\n",
      "      23573 |   0.000019  |    0.080020     |   2\n",
      "      23574 |   0.173497  |    0.230031     |   1\n",
      "      23575 |   0.207181  |    0.031133     |   0\n",
      "      23576 |   0.189008  |    0.251848     |   1\n",
      "      23577 |   0.044408  |    0.040223     |   2\n",
      "      23578 |   0.187714  |    0.090344     |   0\n",
      "      23579 |   0.047863  |    0.080731     |   2\n",
      "      23580 |   0.221616  |    0.226249     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 23581: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      23581 |   0.130347  |    0.026425     |   0\n",
      "      23582 |   0.045217  |    0.073595     |   2\n",
      "      23583 |   0.216459  |    0.214881     |   1\n",
      "      23584 |   0.129266  |    0.022264     |   0\n",
      "      23585 |   0.031579  |    0.093595     |   2\n",
      "      23586 |   0.149290  |    0.199705     |   1\n",
      "      23587 |   0.037041  |    0.006475     |   2\n",
      "      23588 |   0.038912  |    0.097029     |   2\n",
      "      23589 |   0.170631  |    0.051845     |   0\n",
      "      23590 |   0.167461  |    0.025457     |   0\n",
      "      23591 |   0.026131  |    0.088506     |   2\n",
      "      23592 |   0.035258  |    0.068276     |   2\n",
      "      23593 |   0.160012  |    0.205178     |   1\n",
      "      23594 |   0.158685  |    0.023983     |   0\n",
      "      23595 |   0.224264  |    0.330671     |   1\n",
      "      23596 |   0.147117  |    0.038977     |   0\n",
      "      23597 |   0.169308  |    0.070446     |   0\n",
      "      23598 |   0.048017  |    0.101940     |   2\n",
      "      23599 |   0.148825  |    0.179660     |   1\n",
      "      23600 |   0.047732  |    0.148794     |   2\n",
      "      23601 |   0.173682  |    0.155479     |   1\n",
      "      23602 |   0.041693  |    0.069775     |   2\n",
      "      23603 |   0.172534  |    0.249156     |   1\n",
      "      23604 |   0.210108  |    0.103734     |   0\n",
      "      23605 |   0.021181  |    0.047911     |   2\n",
      "      23606 |   0.166570  |    0.237332     |   1\n",
      "      23607 |   0.159875  |    0.162523     |   1\n",
      "      23608 | \u001b[94m  0.000019\u001b[0m  |    0.110045     |   2\n",
      "      23609 |   0.005019  |    0.055486     |   2\n",
      "      23610 |   0.191748  |    0.073041     |   0\n",
      "      23611 |   0.140895  |    0.215505     |   1\n",
      "      23612 |   0.058950  |    0.008219     |   2\n",
      "      23613 |   0.034472  |    0.112288     |   2\n",
      "      23614 |   0.181494  |    0.078403     |   0\n",
      "      23615 |   0.053401  |    0.095524     |   2\n",
      "      23616 |   0.165921  |    0.187183     |   1\n",
      "      23617 |   0.224467  |    0.235612     |   1\n",
      "      23618 |   0.150848  |    0.006577     |   0\n",
      "      23619 |   0.167542  |    0.092606     |   0\n",
      "      23620 |   0.039687  |    0.040793     |   2\n",
      "      23621 |   0.015326  |    0.068595     |   2\n",
      "      23622 |   0.175812  |    0.203992     |   1\n",
      "      23623 |   0.033468  |    0.062979     |   2\n",
      "      23624 |   0.194848  |    0.068399     |   0\n",
      "      23625 |   0.216023  |    0.129877     |   0\n",
      "      23626 |   0.176314  |    0.063002     |   0\n",
      "      23627 |   0.185389  |    0.095867     |   0\n",
      "      23628 |   0.162736  |    0.045930     |   0\n",
      "      23629 |   0.190283  |    0.064433     |   0\n",
      "      23630 |   0.196910  |    0.069483     |   0\n",
      "      23631 |   0.201676  |    0.241743     |   1\n",
      "      23632 |   0.025604  |    0.005292     |   2\n",
      "      23633 |   0.253272  |    0.218854     |   1\n",
      "      23634 |   0.174997  |    0.073801     |   0\n",
      "      23635 |   0.188405  |    0.098664     |   0\n",
      "      23636 |   0.208288  |    0.012829     |   0\n",
      "      23637 |   0.175880  |    0.093410     |   0\n",
      "      23638 |   0.169292  |    0.255967     |   1\n",
      "      23639 |   0.181965  |    0.027555     |   0\n",
      "      23640 |   0.136349  |    0.049243     |   0\n",
      "      23641 | \u001b[94m  0.000018\u001b[0m  |    0.134265     |   2\n",
      "      23642 |   0.131342  |    0.218708     |   1\n",
      "      23643 |   0.278268  |    0.201918     |   1\n",
      "      23644 |   0.163571  |    0.005061     |   0\n",
      "      23645 |   0.000018  |    0.083575     |   2\n",
      "      23646 |   0.195644  |    0.098239     |   0\n",
      "      23647 |   0.189617  |    0.233801     |   1\n",
      "      23648 |   0.000018  |    0.006969     |   2\n",
      "      23649 |   0.201956  |    0.087184     |   0\n",
      "      23650 |   0.170324  |    0.038401     |   0\n",
      "      23651 |   0.000019  |    0.071579     |   2\n",
      "      23652 |   0.165689  |    0.224728     |   1\n",
      "      23653 |   0.190272  |    0.010096     |   0\n",
      "      23654 |   0.220255  |    0.179194     |   1\n",
      "      23655 |   0.185283  |    0.067539     |   0\n",
      "      23656 |   0.000019  |    0.077852     |   2\n",
      "      23657 |   0.187094  |    0.039940     |   0\n",
      "      23658 |   0.223850  |    0.096624     |   0\n",
      "      23659 |   0.000019  |    0.039279     |   2\n",
      "      23660 |   0.232441  |    0.152932     |   0\n",
      "      23661 |   0.046511  |    0.011792     |   2\n",
      "      23662 |   0.048174  |    0.069256     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 23663: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      23663 |   0.048134  |    0.069291     |   2\n",
      "      23664 |   0.033246  |    0.077163     |   2\n",
      "      23665 |   0.038950  |    0.026746     |   2\n",
      "      23666 |   0.219560  |    0.112914     |   0\n",
      "      23667 |   0.039948  |    0.025867     |   2\n",
      "      23668 |   0.026812  |    0.116110     |   2\n",
      "      23669 |   0.034705  |    0.039653     |   2\n",
      "      23670 |   0.266383  |    0.241128     |   1\n",
      "      23671 |   0.047240  |    0.014841     |   2\n",
      "      23672 |   0.050298  |    0.090336     |   2\n",
      "      23673 |   0.226421  |    0.075123     |   0\n",
      "      23674 |   0.202509  |    0.058664     |   0\n",
      "      23675 |   0.197690  |    0.267571     |   1\n",
      "      23676 |   0.187423  |    0.162493     |   1\n",
      "      23677 |   0.157525  |    0.098964     |   0\n",
      "      23678 |   0.162096  |    0.023601     |   0\n",
      "      23679 |   0.155575  |    0.087107     |   0\n",
      "      23680 |   0.156682  |    0.223905     |   1\n",
      "      23681 |   0.157250  |    0.041334     |   0\n",
      "      23682 |   0.040617  |    0.009237     |   2\n",
      "      23683 |   0.020243  |    0.099513     |   2\n",
      "      23684 |   0.146963  |    0.309020     |   1\n",
      "      23685 |   0.157238  |    0.003460     |   0\n",
      "      23686 |   0.195086  |    0.173810     |   1\n",
      "      23687 |   0.097368  |    0.250707     |   1\n",
      "      23688 |   0.213026  |    0.011209     |   0\n",
      "      23689 |   0.157167  |    0.078279     |   0\n",
      "      23690 |   0.159745  |    0.078432     |   0\n",
      "      23691 |   0.000019  |    0.090180     |   2\n",
      "      23692 |   0.005173  |    0.030417     |   2\n",
      "      23693 |   0.060166  |    0.068608     |   2\n",
      "      23694 |   0.235789  |    0.098751     |   0\n",
      "      23695 |   0.152026  |    0.004026     |   0\n",
      "      23696 |   0.164749  |    0.197328     |   1\n",
      "      23697 |   0.220875  |    0.093825     |   0\n",
      "      23698 |   0.170103  |    0.239143     |   1\n",
      "      23699 |   0.033755  |    0.009960     |   2\n",
      "      23700 |   0.168634  |    0.272403     |   1\n",
      "      23701 |   0.226121  |    0.217997     |   1\n",
      "      23702 |   0.160606  |    0.010726     |   0\n",
      "      23703 |   0.055467  |    0.093381     |   2\n",
      "      23704 |   0.044614  |    0.048143     |   2\n",
      "      23705 |   0.016161  |    0.118049     |   2\n",
      "      23706 |   0.183698  |    0.156346     |   1\n",
      "      23707 |   0.033949  |    0.029125     |   2\n",
      "      23708 |   0.168135  |    0.098132     |   0\n",
      "      23709 |   0.186757  |    0.240499     |   1\n",
      "      23710 |   0.027396  |    0.045499     |   2\n",
      "      23711 |   0.000019  |    0.043016     |   2\n",
      "      23712 |   0.000019  |    0.106300     |   2\n",
      "      23713 |   0.165980  |    0.260757     |   1\n",
      "      23714 |   0.223412  |    0.194264     |   1\n",
      "      23715 |   0.000019  |    0.057580     |   2\n",
      "      23716 |   0.000019  |    0.087594     |   2\n",
      "      23717 |   0.163999  |    0.038082     |   0\n",
      "      23718 |   0.236572  |    0.074905     |   0\n",
      "      23719 |   0.210368  |    0.066798     |   0\n",
      "      23720 |   0.197464  |    0.226296     |   1\n",
      "      23721 |   0.000019  |    0.066185     |   2\n",
      "      23722 |   0.132945  |    0.216458     |   1\n",
      "      23723 |   0.170619  |    0.208475     |   1\n",
      "      23724 |   0.000019  |    0.006458     |   2\n",
      "      23725 |   0.042130  |    0.119395     |   2\n",
      "      23726 |   0.046890  |    0.048567     |   2\n",
      "      23727 |   0.173806  |    0.073247     |   0\n",
      "      23728 |   0.203493  |    0.219723     |   1\n",
      "      23729 |   0.171917  |    0.219696     |   1\n",
      "      23730 |   0.195257  |    0.278137     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 23731: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      23731 |   0.226094  |    0.218711     |   1\n",
      "      23732 |   0.112663  |    0.128771     |   1\n",
      "      23733 |   0.041492  |    0.067286     |   2\n",
      "      23734 |   0.157957  |    0.073288     |   0\n",
      "      23735 |   0.202005  |    0.337658     |   1\n",
      "      23736 |   0.187542  |    0.055878     |   0\n",
      "      23737 |   0.030838  |    0.041579     |   2\n",
      "      23738 |   0.037165  |    0.081543     |   2\n",
      "      23739 |   0.177044  |    0.235164     |   1\n",
      "      23740 |   0.206055  |    0.316069     |   1\n",
      "      23741 |   0.159497  |    0.138372     |   1\n",
      "      23742 |   0.209714  |    0.094644     |   0\n",
      "      23743 |   0.172855  |    0.290402     |   1\n",
      "      23744 |   0.039978  |    0.005960     |   2\n",
      "      23745 |   0.025325  |    0.070333     |   2\n",
      "      23746 |   0.034430  |    0.039362     |   2\n",
      "      23747 |   0.159044  |    0.041162     |   0\n",
      "      23748 |   0.174097  |    0.201187     |   1\n",
      "      23749 |   0.041338  |    0.043706     |   2\n",
      "      23750 |   0.047341  |    0.075442     |   2\n",
      "      23751 |   0.040879  |    0.057936     |   2\n",
      "      23752 |   0.154808  |    0.099146     |   0\n",
      "      23753 |   0.193482  |    0.160043     |   1\n",
      "      23754 |   0.019589  |    0.067276     |   2\n",
      "      23755 |   0.000019  |    0.100600     |   2\n",
      "      23756 |   0.200605  |    0.020221     |   0\n",
      "      23757 |   0.143526  |    0.085403     |   0\n",
      "      23758 |   0.240625  |    0.228589     |   1\n",
      "      23759 |   0.198467  |    0.171954     |   1\n",
      "      23760 |   0.240967  |    0.294342     |   1\n",
      "      23761 |   0.232650  |    0.280084     |   1\n",
      "      23762 |   0.241874  |    0.154513     |   0\n",
      "      23763 |   0.004920  |    0.065875     |   2\n",
      "      23764 |   0.058446  |    0.151228     |   2\n",
      "      23765 |   0.209922  |    0.210713     |   1\n",
      "      23766 |   0.155798  |    0.048175     |   0\n",
      "      23767 |   0.032139  |    0.068644     |   2\n",
      "      23768 |   0.116378  |    0.021722     |   0\n",
      "      23769 |   0.144244  |    0.377725     |   1\n",
      "      23770 |   0.144839  |    0.331473     |   1\n",
      "      23771 |   0.150447  |    0.244388     |   1\n",
      "      23772 |   0.055000  |    0.047733     |   2\n",
      "      23773 |   0.207551  |    0.287264     |   1\n",
      "      23774 |   0.204939  |    0.054790     |   0\n",
      "      23775 |   0.039867  |    0.159152     |   2\n",
      "      23776 |   0.223158  |    0.301061     |   1\n",
      "      23777 |   0.013504  |    0.007555     |   2\n",
      "      23778 |   0.031496  |    0.129117     |   2\n",
      "      23779 |   0.024717  |    0.004875     |   2\n",
      "      23780 |   0.195195  |    0.098369     |   0\n",
      "      23781 |   0.000018  |    0.094837     |   2\n",
      "      23782 |   0.151358  |    0.086247     |   0\n",
      "      23783 |   0.179965  |    0.129359     |   0\n",
      "      23784 |   0.210055  |    0.370276     |   1\n",
      "      23785 | \u001b[94m  0.000018\u001b[0m  |    0.056865     |   2\n",
      "      23786 |   0.000018  |    0.102723     |   2\n",
      "      23787 |   0.000019  |    0.025551     |   2\n",
      "      23788 |   0.000018  |    0.066443     |   2\n",
      "      23789 |   0.161458  |    0.096894     |   0\n",
      "      23790 | \u001b[94m  0.000018\u001b[0m  |    0.051150     |   2\n",
      "      23791 |   0.042265  |    0.106586     |   2\n",
      "      23792 |   0.046956  |    0.044371     |   2\n",
      "      23793 |   0.234133  |    0.335585     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 23794: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      23794 |   0.178908  |    0.177187     |   1\n",
      "      23795 |   0.190655  |    0.288635     |   1\n",
      "      23796 |   0.194791  |    0.040122     |   0\n",
      "      23797 |   0.170125  |    0.118859     |   0\n",
      "      23798 |   0.203399  |    0.084848     |   0\n",
      "      23799 |   0.044864  |    0.033160     |   2\n",
      "      23800 |   0.194368  |    0.100992     |   0\n",
      "      23801 |   0.220235  |    0.152029     |   0\n",
      "      23802 |   0.031540  |    0.038590     |   2\n",
      "      23803 |   0.038590  |    0.128206     |   2\n",
      "      23804 |   0.190301  |    0.198727     |   1\n",
      "      23805 |   0.190887  |    0.097617     |   0\n",
      "      23806 |   0.140656  |    0.119219     |   0\n",
      "      23807 |   0.038990  |    0.069937     |   2\n",
      "      23808 |   0.025964  |    0.146096     |   2\n",
      "      23809 |   0.171556  |    0.358966     |   1\n",
      "      23810 |   0.034766  |    0.020237     |   2\n",
      "      23811 |   0.191668  |    0.131511     |   0\n",
      "      23812 |   0.160853  |    0.329127     |   1\n",
      "      23813 |   0.180324  |    0.315647     |   1\n",
      "      23814 |   0.221245  |    0.338009     |   1\n",
      "      23815 |   0.155915  |    0.361600     |   1\n",
      "      23816 |   0.185456  |    0.061990     |   0\n",
      "      23817 |   0.150562  |    0.096290     |   0\n",
      "      23818 |   0.169913  |    0.327711     |   1\n",
      "      23819 |   0.182707  |    0.083658     |   0\n",
      "      23820 |   0.043539  |    0.160006     |   2\n",
      "      23821 |   0.175901  |    0.227100     |   1\n",
      "      23822 |   0.145860  |    0.280181     |   1\n",
      "      23823 |   0.196696  |    0.179610     |   1\n",
      "      23824 |   0.168661  |    0.232324     |   1\n",
      "      23825 |   0.185533  |    0.223137     |   1\n",
      "      23826 |   0.210983  |    0.008663     |   0\n",
      "      23827 |   0.050356  |    0.062229     |   2\n",
      "      23828 |   0.039999  |    0.100443     |   2\n",
      "      23829 |   0.169280  |    0.213233     |   1\n",
      "      23830 |   0.157038  |    0.053319     |   0\n",
      "      23831 |   0.281603  |    0.217912     |   1\n",
      "      23832 |   0.124304  |    0.041133     |   0\n",
      "      23833 |   0.020567  |    0.065821     |   2\n",
      "      23834 |   0.200806  |    0.048528     |   0\n",
      "      23835 |   0.143723  |    0.052780     |   0\n",
      "      23836 |   0.258979  |    0.228657     |   1\n",
      "      23837 |   0.000019  |    0.011898     |   2\n",
      "      23838 |   0.005432  |    0.066904     |   2\n",
      "      23839 |   0.059640  |    0.119971     |   2\n",
      "      23840 |   0.205438  |    0.209457     |   1\n",
      "      23841 |   0.031138  |    0.051566     |   2\n",
      "      23842 |   0.175088  |    0.025076     |   0\n",
      "      23843 |   0.156355  |    0.114568     |   0\n",
      "      23844 |   0.142058  |    0.254780     |   1\n",
      "      23845 |   0.209599  |    0.233811     |   1\n",
      "      23846 |   0.055443  |    0.009264     |   2\n",
      "      23847 |   0.187514  |    0.086765     |   0\n",
      "      23848 |   0.040195  |    0.064771     |   2\n",
      "      23849 |   0.179679  |    0.049247     |   0\n",
      "      23850 |   0.177892  |    0.222134     |   1\n",
      "      23851 |   0.233234  |    0.208769     |   1\n",
      "      23852 |   0.192885  |    0.279461     |   1\n",
      "      23853 |   0.168714  |    0.213817     |   1\n",
      "      23854 |   0.014319  |    0.064029     |   2\n",
      "      23855 |   0.136757  |    0.276883     |   1\n",
      "      23856 |   0.210028  |    0.211663     |   1\n",
      "      23857 |   0.124670  |    0.007535     |   0\n",
      "      23858 |   0.185112  |    0.277170     |   1\n",
      "      23859 |   0.034154  |    0.008446     |   2\n",
      "      23860 |   0.151275  |    0.108610     |   0\n",
      "      23861 |   0.024136  |    0.043591     |   2\n",
      "      23862 |   0.157398  |    0.251011     |   1\n",
      "      23863 |   0.222643  |    0.042730     |   0\n",
      "      23864 |   0.187535  |    0.049365     |   0\n",
      "      23865 |   0.000019  |    0.020048     |   2\n",
      "      23866 |   0.189154  |    0.230958     |   1\n",
      "      23867 |   0.218885  |    0.301203     |   1\n",
      "      23868 |   0.192971  |    0.196768     |   1\n",
      "      23869 |   0.000019  |    0.017886     |   2\n",
      "      23870 |   0.200070  |    0.168273     |   1\n",
      "      23871 |   0.226050  |    0.122922     |   0\n",
      "      23872 |   0.175544  |    0.210482     |   1\n",
      "      23873 |   0.132426  |    0.210411     |   1\n",
      "      23874 |   0.000019  |    0.070060     |   2\n",
      "      23875 |   0.175165  |    0.247487     |   1\n",
      "      23876 |   0.154689  |    0.225269     |   1\n",
      "      23877 |   0.000019  |    0.003597     |   2\n",
      "      23878 |   0.145173  |    0.269700     |   1\n",
      "      23879 |   0.000019  |    0.015330     |   2\n",
      "      23880 |   0.000019  |    0.073004     |   2\n",
      "      23881 |   0.225330  |    0.211765     |   1\n",
      "      23882 |   0.214719  |    0.027626     |   0\n",
      "      23883 |   0.040628  |    0.113302     |   2\n",
      "      23884 |   0.157908  |    0.038445     |   0\n",
      "      23885 |   0.137831  |    0.237091     |   1\n",
      "      23886 |   0.046202  |    0.032925     |   2\n",
      "      23887 |   0.180692  |    0.086250     |   0\n",
      "      23888 |   0.135049  |    0.013991     |   0\n",
      "      23889 |   0.206007  |    0.106956     |   0\n",
      "      23890 |   0.208210  |    0.205816     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 23891: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      23891 |   0.045583  |    0.029941     |   2\n",
      "      23892 |   0.228298  |    0.072935     |   0\n",
      "      23893 |   0.208375  |    0.229653     |   1\n",
      "      23894 |   0.188866  |    0.213227     |   1\n",
      "      23895 |   0.031291  |    0.095266     |   2\n",
      "      23896 |   0.038139  |    0.011551     |   2\n",
      "      23897 |   0.193824  |    0.087610     |   0\n",
      "      23898 |   0.144679  |    0.067489     |   0\n",
      "      23899 |   0.162894  |    0.077172     |   0\n",
      "      23900 |   0.183644  |    0.196070     |   1\n",
      "      23901 |   0.131970  |    0.045759     |   0\n",
      "      23902 |   0.194690  |    0.069469     |   0\n",
      "      23903 |   0.195316  |    0.047761     |   0\n",
      "      23904 |   0.194213  |    0.228772     |   1\n",
      "      23905 |   0.185296  |    0.278249     |   1\n",
      "      23906 |   0.037976  |    0.008829     |   2\n",
      "      23907 |   0.027101  |    0.096409     |   2\n",
      "      23908 |   0.186032  |    0.071376     |   0\n",
      "      23909 |   0.036071  |    0.013875     |   2\n",
      "      23910 |   0.050957  |    0.119457     |   2\n",
      "      23911 |   0.166940  |    0.244858     |   1\n",
      "      23912 |   0.202146  |    0.160478     |   1\n",
      "      23913 |   0.236250  |    0.205744     |   1\n",
      "      23914 |   0.185700  |    0.191824     |   1\n",
      "      23915 |   0.051911  |    0.016540     |   2\n",
      "      23916 |   0.274136  |    0.084426     |   0\n",
      "      23917 |   0.173053  |    0.261625     |   1\n",
      "      23918 |   0.155811  |    0.040249     |   0\n",
      "      23919 |   0.176808  |    0.049632     |   0\n",
      "      23920 |   0.041405  |    0.091577     |   2\n",
      "      23921 |   0.020142  |    0.006825     |   2\n",
      "      23922 |   0.185672  |    0.130836     |   0\n",
      "      23923 |   0.186738  |    0.167406     |   1\n",
      "      23924 |   0.184668  |    0.050420     |   0\n",
      "      23925 |   0.000019  |    0.041945     |   2\n",
      "      23926 |   0.185311  |    0.082941     |   0\n",
      "      23927 |   0.188830  |    0.069647     |   0\n",
      "      23928 |   0.215970  |    0.227541     |   1\n",
      "      23929 |   0.005218  |    0.059066     |   2\n",
      "      23930 |   0.060375  |    0.070537     |   2\n",
      "      23931 |   0.182528  |    0.039883     |   0\n",
      "      23932 |   0.189641  |    0.102939     |   0\n",
      "      23933 |   0.203480  |    0.033327     |   0\n",
      "      23934 |   0.198522  |    0.238624     |   1\n",
      "      23935 |   0.194121  |    0.028726     |   0\n",
      "      23936 |   0.033219  |    0.058188     |   2\n",
      "      23937 |   0.055907  |    0.072750     |   2\n",
      "      23938 |   0.042818  |    0.117584     |   2\n",
      "      23939 |   0.137262  |    0.040676     |   0\n",
      "      23940 |   0.014934  |    0.046745     |   2\n",
      "      23941 |   0.225641  |    0.225308     |   1\n",
      "      23942 |   0.155004  |    0.026670     |   0\n",
      "      23943 |   0.223051  |    0.134477     |   0\n",
      "      23944 |   0.167010  |    0.243014     |   1\n",
      "      23945 |   0.292742  |    0.113543     |   1\n",
      "      23946 |   0.203490  |    0.071353     |   0\n",
      "      23947 |   0.175191  |    0.234868     |   1\n",
      "      23948 |   0.241875  |    0.190604     |   1\n",
      "      23949 |   0.146211  |    0.037663     |   0\n",
      "      23950 |   0.033933  |    0.050871     |   2\n",
      "      23951 |   0.166069  |    0.100127     |   0\n",
      "      23952 |   0.026691  |    0.066902     |   2\n",
      "      23953 |   0.246262  |    0.247002     |   1\n",
      "      23954 |   0.241641  |    0.202877     |   1\n",
      "      23955 |   0.156449  |    0.015547     |   0\n",
      "      23956 |   0.159290  |    0.120916     |   0\n",
      "      23957 |   0.178574  |    0.054436     |   0\n",
      "      23958 |   0.197665  |    0.249776     |   1\n",
      "      23959 |   0.182337  |    0.029781     |   0\n",
      "      23960 |   0.172353  |    0.172039     |   0\n",
      "      23961 |   0.151359  |    0.169832     |   1\n",
      "      23962 |   0.195830  |    0.211414     |   1\n",
      "      23963 |   0.226017  |    0.220831     |   1\n",
      "      23964 |   0.158441  |    0.069351     |   0\n",
      "      23965 |   0.174193  |    0.220428     |   1\n",
      "      23966 |   0.213556  |    0.211286     |   1\n",
      "      23967 |   0.145931  |    0.233028     |   1\n",
      "      23968 |   0.228492  |    0.170232     |   1\n",
      "      23969 |   0.160956  |    0.019103     |   0\n",
      "      23970 |   0.242488  |    0.244940     |   1\n",
      "      23971 |   0.000019  |    0.040589     |   2\n",
      "      23972 |   0.175070  |    0.247820     |   1\n",
      "      23973 |   0.229281  |    0.156405     |   1\n",
      "      23974 |   0.172364  |    0.323958     |   1\n",
      "      23975 |   0.210046  |    0.024303     |   0\n",
      "      23976 |   0.149434  |    0.350766     |   1\n",
      "      23977 |   0.221436  |    0.204643     |   1\n",
      "      23978 |   0.172500  |    0.208093     |   1\n",
      "      23979 |   0.199682  |    0.173421     |   1\n",
      "      23980 |   0.000019  |    0.022269     |   2\n",
      "      23981 |   0.000019  |    0.094325     |   2\n",
      "      23982 |   0.148214  |    0.274109     |   1\n",
      "      23983 |   0.197893  |    0.257859     |   1\n",
      "      23984 |   0.000019  |    0.005522     |   2\n",
      "      23985 |   0.000019  |    0.093247     |   2\n",
      "      23986 |   0.165514  |    0.069001     |   0\n",
      "      23987 |   0.000019  |    0.040230     |   2\n",
      "      23988 |   0.214524  |    0.074660     |   0\n",
      "      23989 |   0.180577  |    0.241033     |   1\n",
      "      23990 |   0.165232  |    0.291138     |   1\n",
      "      23991 |   0.137882  |    0.283181     |   1\n",
      "      23992 |   0.194416  |    0.014720     |   0\n",
      "      23993 |   0.040790  |    0.112272     |   2\n",
      "      23994 |   0.169815  |    0.235643     |   1\n",
      "      23995 |   0.045248  |    0.040192     |   2\n",
      "      23996 |   0.168213  |    0.121588     |   0\n",
      "      23997 |   0.152330  |    0.197135     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 23998: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      23998 |   0.184258  |    0.090367     |   0\n",
      "      23999 |   0.044341  |    0.091003     |   2\n",
      "      24000 |   0.231234  |    0.039942     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 24000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 24000: Plotting estimates.\n",
      "Exception in thread neuralnilm-data-process:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 810, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/jack/workspace/python/neuralnilm/neuralnilm/data/datathread.py\", line 16, in run\n",
      "    batch = self.data_pipeline.get_batch(**self._get_batch_kwargs)\n",
      "  File \"/home/jack/workspace/python/neuralnilm/neuralnilm/data/datapipeline.py\", line 46, in get_batch\n",
      "    batch = self._source_iterators[source_id].next()\n",
      "ValueError: generator already executing\n",
      "\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      24001 |   0.218320  |    0.044011     |   0\n",
      "      24002 |   0.044293  |    0.064658     |   2\n",
      "      24003 |   0.191590  |    0.218308     |   1\n",
      "      24004 |   0.186096  |    0.102720     |   0\n",
      "      24005 |   0.198846  |    0.326381     |   1\n",
      "      24006 |   0.275191  |    0.466698     |   1\n",
      "      24007 |   0.254157  |    0.038627     |   0\n",
      "      24008 |   0.177665  |    0.116694     |   0\n",
      "      24009 |   0.152714  |    0.357064     |   1\n",
      "      24010 |   0.031623  |    0.036394     |   2\n",
      "      24011 |   0.143605  |    0.099527     |   0\n",
      "      24012 |   0.167263  |    0.399551     |   1\n",
      "      24013 |   0.148027  |    0.062224     |   0\n",
      "      24014 |   0.193320  |    0.085613     |   0\n",
      "      24015 |   0.184374  |    0.344450     |   1\n",
      "      24016 |   0.170953  |    0.038585     |   0\n",
      "      24017 |   0.181525  |    0.117888     |   0\n",
      "      24018 |   0.198686  |    0.352654     |   1\n",
      "      24019 |   0.167268  |    0.040309     |   0\n",
      "      24020 |   0.178781  |    0.071636     |   0\n",
      "      24021 |   0.036997  |    0.130167     |   2\n",
      "      24022 |   0.205588  |    0.235662     |   1\n",
      "      24023 |   0.040110  |    0.119485     |   2\n",
      "      24024 |   0.219417  |    0.084626     |   0\n",
      "      24025 |   0.187941  |    0.069929     |   0\n",
      "      24026 |   0.211661  |    0.112482     |   0\n",
      "      24027 |   0.027346  |    0.073445     |   2\n",
      "      24028 |   0.229046  |    0.351745     |   1\n",
      "      24029 |   0.156368  |    0.019440     |   0\n",
      "      24030 |   0.034373  |    0.085213     |   2\n",
      "      24031 |   0.190123  |    0.113784     |   0\n",
      "      24032 |   0.222236  |    0.280022     |   1\n",
      "      24033 |   0.153226  |    0.094258     |   0\n",
      "      24034 |   0.200235  |    0.171018     |   0\n",
      "      24035 |   0.052710  |    0.004482     |   2\n",
      "      24036 |   0.049312  |    0.062983     |   2\n",
      "      24037 |   0.187124  |    0.447495     |   1\n",
      "      24038 |   0.186890  |    0.467859     |   1\n",
      "      24039 |   0.169502  |    0.087519     |   0\n",
      "      24040 |   0.175375  |    0.301621     |   1\n",
      "      24041 |   0.042443  |    0.119067     |   2\n",
      "      24042 |   0.172426  |    0.475009     |   1\n",
      "      24043 |   0.020939  |    0.040406     |   2\n",
      "      24044 |   0.218435  |    0.290292     |   1\n",
      "      24045 |   0.170300  |    0.087190     |   0\n",
      "      24046 |   0.000019  |    0.091636     |   2\n",
      "      24047 |   0.005444  |    0.038707     |   2\n",
      "      24048 |   0.219451  |    0.269730     |   1\n",
      "      24049 |   0.185020  |    0.294590     |   1\n",
      "      24050 |   0.200754  |    0.072106     |   0\n",
      "      24051 |   0.189643  |    0.079672     |   0\n",
      "      24052 |   0.060717  |    0.121365     |   2\n",
      "      24053 |   0.032069  |    0.038162     |   2\n",
      "      24054 |   0.056666  |    0.090939     |   2\n",
      "      24055 |   0.041835  |    0.092439     |   2\n",
      "      24056 |   0.150435  |    0.090378     |   0\n",
      "      24057 |   0.015275  |    0.120626     |   2\n",
      "      24058 |   0.209231  |    0.038701     |   0\n",
      "      24059 |   0.035473  |    0.089370     |   2\n",
      "      24060 |   0.026206  |    0.038478     |   2\n",
      "      24061 |   0.000019  |    0.054952     |   2\n",
      "      24062 |   0.160921  |    0.240711     |   1\n",
      "      24063 |   0.137413  |    0.114200     |   0\n",
      "      24064 |   0.000019  |    0.018169     |   2\n",
      "      24065 |   0.229610  |    0.225823     |   1\n",
      "      24066 |   0.254068  |    0.051084     |   0\n",
      "      24067 |   0.000019  |    0.074811     |   2\n",
      "      24068 |   0.000019  |    0.061887     |   2\n",
      "      24069 |   0.212706  |    0.043309     |   0\n",
      "      24070 |   0.217089  |    0.030136     |   0\n",
      "      24071 |   0.134194  |    0.075902     |   0\n",
      "      24072 |   0.000019  |    0.022474     |   2\n",
      "      24073 |   0.000019  |    0.089661     |   2\n",
      "      24074 |   0.165146  |    0.057388     |   0\n",
      "      24075 |   0.041872  |    0.089599     |   2\n",
      "      24076 |   0.151220  |    0.022373     |   0\n",
      "      24077 |   0.207057  |    0.165706     |   0\n",
      "      24078 |   0.206962  |    0.191321     |   1\n",
      "      24079 |   0.213429  |    0.138322     |   1\n",
      "      24080 |   0.187174  |    0.235318     |   1\n",
      "      24081 |   0.180883  |    0.088517     |   0\n",
      "      24082 |   0.236577  |    0.191229     |   1\n",
      "      24083 |   0.179049  |    0.214164     |   1\n",
      "      24084 |   0.191182  |    0.065220     |   0\n",
      "      24085 |   0.046813  |    0.098654     |   2\n",
      "      24086 |   0.195025  |    0.152628     |   1\n",
      "      24087 |   0.153296  |    0.069119     |   0\n",
      "      24088 |   0.213156  |    0.199219     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 24089: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      24089 |   0.141268  |    0.328257     |   1\n",
      "      24090 |   0.226110  |    0.300052     |   1\n",
      "      24091 |   0.041548  |    0.021363     |   2\n",
      "      24092 |   0.030092  |    0.105066     |   2\n",
      "      24093 |   0.182271  |    0.255098     |   1\n",
      "      24094 |   0.175464  |    0.042852     |   0\n",
      "      24095 |   0.125834  |    0.051737     |   0\n",
      "      24096 |   0.161848  |    0.071764     |   0\n",
      "      24097 |   0.195375  |    0.023644     |   0\n",
      "      24098 |   0.037118  |    0.117700     |   2\n",
      "      24099 |   0.192367  |    0.219542     |   1\n",
      "      24100 |   0.039637  |    0.062730     |   2\n",
      "      24101 |   0.140305  |    0.041503     |   0\n",
      "      24102 |   0.024990  |    0.047880     |   2\n",
      "      24103 |   0.144098  |    0.239510     |   1\n",
      "      24104 |   0.034877  |    0.009776     |   2\n",
      "      24105 |   0.184868  |    0.242035     |   1\n",
      "      24106 |   0.133354  |    0.072385     |   0\n",
      "      24107 |   0.050287  |    0.024606     |   2\n",
      "      24108 |   0.208708  |    0.248909     |   1\n",
      "      24109 |   0.180065  |    0.064403     |   0\n",
      "      24110 |   0.166499  |    0.285290     |   1\n",
      "      24111 |   0.216658  |    0.005490     |   0\n",
      "      24112 |   0.237397  |    0.281116     |   1\n",
      "      24113 |   0.050355  |    0.015451     |   2\n",
      "      24114 |   0.220436  |    0.286374     |   1\n",
      "      24115 |   0.174636  |    0.040869     |   0\n",
      "      24116 |   0.168095  |    0.072891     |   0\n",
      "      24117 |   0.191458  |    0.067027     |   0\n",
      "      24118 |   0.039913  |    0.074035     |   2\n",
      "      24119 |   0.201533  |    0.064290     |   0\n",
      "      24120 |   0.020226  |    0.074607     |   2\n",
      "      24121 |   0.155495  |    0.050947     |   0\n",
      "      24122 |   0.141600  |    0.284997     |   1\n",
      "      24123 |   0.199765  |    0.187475     |   1\n",
      "      24124 |   0.159717  |    0.047868     |   0\n",
      "      24125 |   0.127678  |    0.390968     |   1\n",
      "      24126 |   0.000019  |    0.004879     |   2\n",
      "      24127 |   0.186847  |    0.246222     |   1\n",
      "      24128 |   0.005546  |    0.010581     |   2\n",
      "      24129 |   0.062537  |    0.076590     |   2\n",
      "      24130 |   0.255504  |    0.245816     |   1\n",
      "      24131 |   0.034149  |    0.070114     |   2\n",
      "      24132 |   0.054770  |    0.078561     |   2\n",
      "      24133 |   0.210847  |    0.208588     |   1\n",
      "      24134 |   0.098195  |    0.272616     |   1\n",
      "      24135 |   0.161649  |    0.206962     |   1\n",
      "      24136 |   0.041758  |    0.030580     |   2\n",
      "      24137 |   0.014405  |    0.070178     |   2\n",
      "      24138 |   0.034357  |    0.049654     |   2\n",
      "      24139 |   0.227442  |    0.126330     |   0\n",
      "      24140 |   0.180193  |    0.150717     |   1\n",
      "      24141 |   0.182781  |    0.044222     |   0\n",
      "      24142 |   0.205996  |    0.094044     |   0\n",
      "      24143 |   0.253189  |    0.203175     |   1\n",
      "      24144 |   0.140330  |    0.010545     |   0\n",
      "      24145 |   0.141199  |    0.274663     |   1\n",
      "      24146 |   0.139612  |    0.044423     |   0\n",
      "      24147 |   0.025482  |    0.094460     |   2\n",
      "      24148 |   0.174095  |    0.023974     |   0\n",
      "      24149 |   0.178119  |    0.121853     |   0\n",
      "      24150 |   0.218080  |    0.208539     |   1\n",
      "      24151 |   0.000019  |    0.065010     |   2\n",
      "      24152 |   0.000019  |    0.062850     |   2\n",
      "      24153 |   0.204895  |    0.053876     |   0\n",
      "      24154 |   0.232067  |    0.238481     |   1\n",
      "      24155 |   0.218061  |    0.236652     |   1\n",
      "      24156 |   0.156938  |    0.007138     |   0\n",
      "      24157 |   0.000019  |    0.089630     |   2\n",
      "      24158 |   0.226286  |    0.181743     |   1\n",
      "      24159 |   0.000019  |    0.068904     |   2\n",
      "      24160 |   0.251427  |    0.200825     |   1\n",
      "      24161 |   0.191749  |    0.237204     |   1\n",
      "      24162 |   0.182492  |    0.253289     |   1\n",
      "      24163 |   0.161049  |    0.182706     |   1\n",
      "      24164 |   0.168528  |    0.066818     |   0\n",
      "      24165 |   0.192299  |    0.266299     |   1\n",
      "      24166 |   0.170715  |    0.009324     |   0\n",
      "      24167 |   0.173181  |    0.213432     |   1\n",
      "      24168 |   0.172031  |    0.040372     |   0\n",
      "      24169 |   0.206437  |    0.237246     |   1\n",
      "      24170 |   0.000019  |    0.099198     |   2\n",
      "      24171 |   0.000019  |    0.004321     |   2\n",
      "      24172 |   0.041646  |    0.059384     |   2\n",
      "      24173 |   0.045473  |    0.066014     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 24174: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      24174 |   0.192087  |    0.296781     |   1\n",
      "      24175 |   0.155281  |    0.149698     |   1\n",
      "      24176 |   0.223218  |    0.061566     |   0\n",
      "      24177 |   0.038537  |    0.072901     |   2\n",
      "      24178 |   0.181615  |    0.194459     |   1\n",
      "      24179 |   0.028874  |    0.078394     |   2\n",
      "      24180 |   0.208070  |    0.091660     |   0\n",
      "      24181 |   0.164974  |    0.036387     |   0\n",
      "      24182 |   0.202820  |    0.291802     |   1\n",
      "      24183 |   0.190477  |    0.207486     |   1\n",
      "      24184 |   0.183345  |    0.257374     |   1\n",
      "      24185 |   0.036449  |    0.003890     |   2\n",
      "      24186 |   0.213834  |    0.079097     |   0\n",
      "      24187 |   0.038955  |    0.094814     |   2\n",
      "      24188 |   0.025165  |    0.043442     |   2\n",
      "      24189 |   0.034828  |    0.066062     |   2\n",
      "      24190 |   0.188719  |    0.115885     |   0\n",
      "      24191 |   0.213410  |    0.026321     |   0\n",
      "      24192 |   0.219673  |    0.270993     |   1\n",
      "      24193 |   0.207925  |    0.070011     |   0\n",
      "      24194 |   0.047708  |    0.062019     |   2\n",
      "      24195 |   0.136581  |    0.234529     |   1\n",
      "      24196 |   0.050726  |    0.022901     |   2\n",
      "      24197 |   0.144963  |    0.118107     |   0\n",
      "      24198 |   0.196084  |    0.069273     |   0\n",
      "      24199 |   0.204794  |    0.066431     |   0\n",
      "      24200 |   0.202195  |    0.312511     |   1\n",
      "      24201 |   0.191472  |    0.188071     |   1\n",
      "      24202 |   0.168318  |    0.066918     |   0\n",
      "      24203 |   0.042182  |    0.075538     |   2\n",
      "      24204 |   0.186784  |    0.064566     |   0\n",
      "      24205 |   0.174369  |    0.350818     |   1\n",
      "      24206 |   0.175379  |    0.021273     |   0\n",
      "      24207 |   0.299300  |    0.259563     |   1\n",
      "      24208 |   0.021185  |    0.005922     |   2\n",
      "      24209 |   0.185356  |    0.326698     |   1\n",
      "      24210 |   0.156270  |    0.196633     |   1\n",
      "      24211 |   0.262489  |    0.012526     |   0\n",
      "      24212 |   0.234102  |    0.110180     |   0\n",
      "      24213 |   0.141576  |    0.076820     |   0\n",
      "      24214 |   0.226685  |    0.053947     |   0\n",
      "      24215 |   0.199949  |    0.092003     |   0\n",
      "      24216 |   0.182686  |    0.260533     |   1\n",
      "      24217 |   0.207588  |    0.361833     |   1\n",
      "      24218 |   0.249328  |    0.228170     |   1\n",
      "      24219 |   0.172742  |    0.014782     |   0\n",
      "      24220 |   0.221381  |    0.160639     |   0\n",
      "      24221 | \u001b[94m  0.000018\u001b[0m  |    0.005691     |   2\n",
      "      24222 |   0.005091  |    0.140092     |   2\n",
      "      24223 |   0.169097  |    0.057224     |   0\n",
      "      24224 |   0.260581  |    0.283779     |   1\n",
      "      24225 |   0.161705  |    0.383862     |   1\n",
      "      24226 |   0.233557  |    0.178537     |   1\n",
      "      24227 |   0.062739  |    0.071348     |   2\n",
      "      24228 |   0.035210  |    0.090213     |   2\n",
      "      24229 |   0.306487  |    0.267707     |   1\n",
      "      24230 |   0.189992  |    0.276357     |   1\n",
      "      24231 |   0.175318  |    0.106642     |   0\n",
      "      24232 |   0.056187  |    0.047463     |   2\n",
      "      24233 |   0.038736  |    0.081571     |   2\n",
      "      24234 |   0.015366  |    0.024117     |   2\n",
      "      24235 |   0.191583  |    0.253668     |   1\n",
      "      24236 |   0.190441  |    0.273201     |   1\n",
      "      24237 |   0.173203  |    0.145086     |   0\n",
      "      24238 |   0.035450  |    0.005827     |   2\n",
      "      24239 |   0.229032  |    0.234509     |   1\n",
      "      24240 |   0.228745  |    0.232310     |   1\n",
      "      24241 |   0.024511  |    0.142939     |   2\n",
      "      24242 |   0.200044  |    0.051639     |   0\n",
      "      24243 |   0.000019  |    0.168100     |   2\n",
      "      24244 |   0.201740  |    0.032988     |   0\n",
      "      24245 |   0.186522  |    0.234210     |   1\n",
      "      24246 |   0.000019  |    0.148420     |   2\n",
      "      24247 |   0.187652  |    0.330825     |   1\n",
      "      24248 |   0.000019  |    0.065952     |   2\n",
      "      24249 |   0.213033  |    0.254053     |   1\n",
      "      24250 |   0.000019  |    0.059161     |   2\n",
      "      24251 |   0.000019  |    0.094544     |   2\n",
      "      24252 |   0.161930  |    0.116490     |   0\n",
      "      24253 |   0.228479  |    0.145309     |   0\n",
      "      24254 |   0.245113  |    0.065782     |   0\n",
      "      24255 |   0.191528  |    0.099041     |   0\n",
      "      24256 |   0.000018  |    0.079133     |   2\n",
      "      24257 |   0.043199  |    0.093945     |   2\n",
      "      24258 |   0.279547  |    0.292110     |   1\n",
      "      24259 |   0.232678  |    0.156097     |   0\n",
      "      24260 |   0.198099  |    0.086680     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 24262: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      24261 |   0.047643  |    0.005126     |   2\n",
      "      24262 |   0.221923  |    0.387033     |   1\n",
      "      24263 |   0.162531  |    0.076689     |   0\n",
      "      24264 |   0.238794  |    0.336701     |   1\n",
      "      24265 |   0.213183  |    0.278761     |   1\n",
      "      24266 |   0.044332  |    0.088029     |   2\n",
      "      24267 |   0.031626  |    0.086640     |   2\n",
      "      24268 |   0.247625  |    0.146421     |   0\n",
      "      24269 |   0.161999  |    0.475295     |   1\n",
      "      24270 |   0.160930  |    0.477080     |   1\n",
      "      24271 |   0.149281  |    0.400269     |   1\n",
      "      24272 |   0.186812  |    0.110706     |   0\n",
      "      24273 |   0.038045  |    0.072574     |   2\n",
      "      24274 |   0.039618  |    0.091787     |   2\n",
      "      24275 |   0.025821  |    0.167931     |   2\n",
      "      24276 |   0.185741  |    0.023571     |   0\n",
      "      24277 |   0.036355  |    0.139911     |   2\n",
      "      24278 |   0.046008  |    0.092521     |   2\n",
      "      24279 |   0.145523  |    0.472466     |   1\n",
      "      24280 |   0.210411  |    0.122714     |   0\n",
      "      24281 |   0.051817  |    0.146685     |   2\n",
      "      24282 |   0.183987  |    0.072313     |   0\n",
      "      24283 |   0.191223  |    0.292263     |   1\n",
      "      24284 |   0.041539  |    0.120615     |   2\n",
      "      24285 |   0.218816  |    0.064921     |   0\n",
      "      24286 |   0.221546  |    0.322127     |   1\n",
      "      24287 |   0.019433  |    0.116752     |   2\n",
      "      24288 | \u001b[94m  0.000018\u001b[0m  |    0.124498     |   2\n",
      "      24289 |   0.004721  |    0.109834     |   2\n",
      "      24290 |   0.245762  |    0.290724     |   1\n",
      "      24291 |   0.196565  |    0.191003     |   1\n",
      "      24292 |   0.057220  |    0.012736     |   2\n",
      "      24293 |   0.032396  |    0.122824     |   2\n",
      "      24294 |   0.055325  |    0.045926     |   2\n",
      "      24295 |   0.167233  |    0.042225     |   0\n",
      "      24296 |   0.171655  |    0.059263     |   0\n",
      "      24297 |   0.159156  |    0.088826     |   0\n",
      "      24298 |   0.039754  |    0.027070     |   2\n",
      "      24299 |   0.221701  |    0.280681     |   1\n",
      "      24300 |   0.160292  |    0.023280     |   0\n",
      "      24301 |   0.177679  |    0.079292     |   0\n",
      "      24302 |   0.126799  |    0.248558     |   1\n",
      "      24303 |   0.222128  |    0.154900     |   1\n",
      "      24304 |   0.014078  |    0.040664     |   2\n",
      "      24305 |   0.205662  |    0.077139     |   0\n",
      "      24306 |   0.171740  |    0.212564     |   1\n",
      "      24307 |   0.032681  |    0.093298     |   2\n",
      "      24308 |   0.179790  |    0.210630     |   1\n",
      "      24309 |   0.198287  |    0.007752     |   0\n",
      "      24310 |   0.160703  |    0.088189     |   0\n",
      "      24311 |   0.026660  |    0.074885     |   2\n",
      "      24312 | \u001b[94m  0.000018\u001b[0m  |    0.045888     |   2\n",
      "      24313 |   0.000018  |    0.091297     |   2\n",
      "      24314 |   0.297366  |    0.048255     |   0\n",
      "      24315 | \u001b[94m  0.000018\u001b[0m  |    0.089884     |   2\n",
      "      24316 |   0.000018  |    0.069795     |   2\n",
      "      24317 | \u001b[94m  0.000018\u001b[0m  |    0.041243     |   2\n",
      "      24318 | \u001b[94m  0.000018\u001b[0m  |    0.109562     |   2\n",
      "      24319 |   0.043886  |    0.054027     |   2\n",
      "      24320 |   0.047101  |    0.065749     |   2\n",
      "      24321 |   0.150084  |    0.246170     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 24322: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      24322 |   0.187781  |    0.041003     |   0\n",
      "      24323 |   0.174344  |    0.084857     |   0\n",
      "      24324 |   0.191130  |    0.025253     |   0\n",
      "      24325 |   0.043902  |    0.048821     |   2\n",
      "      24326 |   0.179781  |    0.070174     |   0\n",
      "      24327 |   0.218072  |    0.244326     |   1\n",
      "      24328 |   0.201046  |    0.214361     |   1\n",
      "      24329 |   0.173223  |    0.228561     |   1\n",
      "      24330 |   0.032026  |    0.050365     |   2\n",
      "      24331 |   0.193302  |    0.049173     |   0\n",
      "      24332 |   0.154430  |    0.314411     |   1\n",
      "      24333 |   0.179380  |    0.044846     |   0\n",
      "      24334 |   0.170441  |    0.113203     |   0\n",
      "      24335 |   0.156992  |    0.042238     |   0\n",
      "      24336 |   0.179998  |    0.214476     |   1\n",
      "      24337 |   0.172659  |    0.158742     |   0\n",
      "      24338 |   0.200745  |    0.324563     |   1\n",
      "      24339 |   0.037239  |    0.069716     |   2\n",
      "      24340 |   0.168033  |    0.142572     |   0\n",
      "      24341 |   0.170427  |    0.039427     |   0\n",
      "      24342 |   0.153715  |    0.110034     |   0\n",
      "      24343 |   0.039706  |    0.125879     |   2\n",
      "      24344 |   0.025635  |    0.040534     |   2\n",
      "      24345 |   0.159135  |    0.133584     |   0\n",
      "      24346 |   0.125616  |    0.018283     |   0\n",
      "      24347 |   0.179977  |    0.125537     |   0\n",
      "      24348 |   0.190737  |    0.318190     |   1\n",
      "      24349 |   0.158833  |    0.365647     |   1\n",
      "      24350 |   0.220928  |    0.149117     |   0\n",
      "      24351 |   0.036897  |    0.072043     |   2\n",
      "      24352 |   0.186223  |    0.291207     |   1\n",
      "      24353 |   0.047894  |    0.092707     |   2\n",
      "      24354 |   0.048502  |    0.088145     |   2\n",
      "      24355 |   0.137788  |    0.104798     |   0\n",
      "      24356 |   0.155893  |    0.074098     |   0\n",
      "      24357 |   0.043932  |    0.152364     |   2\n",
      "      24358 |   0.181283  |    0.039319     |   0\n",
      "      24359 |   0.020882  |    0.152318     |   2\n",
      "      24360 |   0.160817  |    0.025384     |   0\n",
      "      24361 |   0.157573  |    0.118597     |   0\n",
      "      24362 |   0.141240  |    0.145320     |   0\n",
      "      24363 |   0.000018  |    0.024958     |   2\n",
      "      24364 |   0.005038  |    0.122562     |   2\n",
      "      24365 |   0.188281  |    0.128047     |   0\n",
      "      24366 |   0.108560  |    0.020467     |   0\n",
      "      24367 |   0.059922  |    0.135741     |   2\n",
      "      24368 |   0.035524  |    0.075894     |   2\n",
      "      24369 |   0.059620  |    0.147922     |   2\n",
      "      24370 |   0.194326  |    0.038749     |   0\n",
      "      24371 |   0.201626  |    0.431406     |   1\n",
      "      24372 |   0.195054  |    0.084135     |   0\n",
      "      24373 |   0.042505  |    0.065160     |   2\n",
      "      24374 |   0.208862  |    0.132714     |   0\n",
      "      24375 |   0.140913  |    0.352307     |   1\n",
      "      24376 |   0.162656  |    0.039508     |   0\n",
      "      24377 |   0.207142  |    0.400394     |   1\n",
      "      24378 |   0.180914  |    0.035527     |   0\n",
      "      24379 |   0.209939  |    0.112090     |   0\n",
      "      24380 |   0.196508  |    0.384326     |   1\n",
      "      24381 |   0.016491  |    0.057233     |   2\n",
      "      24382 |   0.187986  |    0.228605     |   1\n",
      "      24383 |   0.190519  |    0.242121     |   1\n",
      "      24384 |   0.206136  |    0.070476     |   0\n",
      "      24385 |   0.036199  |    0.070867     |   2\n",
      "      24386 |   0.165423  |    0.025948     |   0\n",
      "      24387 |   0.028358  |    0.069867     |   2\n",
      "      24388 |   0.000018  |    0.126336     |   2\n",
      "      24389 |   0.210406  |    0.017969     |   0\n",
      "      24390 |   0.161771  |    0.123912     |   0\n",
      "      24391 |   0.000018  |    0.022939     |   2\n",
      "      24392 |   0.173624  |    0.070843     |   0\n",
      "      24393 |   0.139781  |    0.038963     |   0\n",
      "      24394 |   0.160815  |    0.278131     |   1\n",
      "      24395 |   0.186683  |    0.131741     |   1\n",
      "      24396 |   0.214994  |    0.072814     |   0\n",
      "      24397 |   0.184567  |    0.068888     |   0\n",
      "      24398 |   0.183756  |    0.216691     |   1\n",
      "      24399 |   0.157561  |    0.042309     |   0\n",
      "      24400 |   0.000018  |    0.080019     |   2\n",
      "      24401 |   0.156386  |    0.078718     |   0\n",
      "      24402 |   0.153249  |    0.191377     |   1\n",
      "      24403 |   0.178151  |    0.033434     |   0\n",
      "      24404 |   0.000018  |    0.118601     |   2\n",
      "      24405 |   0.273468  |    0.212204     |   1\n",
      "      24406 |   0.187083  |    0.057791     |   0\n",
      "      24407 |   0.000018  |    0.054434     |   2\n",
      "      24408 |   0.000018  |    0.065049     |   2\n",
      "      24409 |   0.186963  |    0.253052     |   1\n",
      "      24410 |   0.046707  |    0.042253     |   2\n",
      "      24411 |   0.166760  |    0.107664     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 24413: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      24412 |   0.048218  |    0.004437     |   2\n",
      "      24413 |   0.158575  |    0.175458     |   1\n",
      "      24414 |   0.167850  |    0.080146     |   0\n",
      "      24415 |   0.193247  |    0.070841     |   0\n",
      "      24416 |   0.174198  |    0.198359     |   1\n",
      "      24417 |   0.046452  |    0.039009     |   2\n",
      "      24418 |   0.032078  |    0.096493     |   2\n",
      "      24419 |   0.152029  |    0.066569     |   0\n",
      "      24420 |   0.039947  |    0.082548     |   2\n",
      "      24421 |   0.161801  |    0.227707     |   1\n",
      "      24422 |   0.038132  |    0.012132     |   2\n",
      "      24423 |   0.163066  |    0.099590     |   0\n",
      "      24424 |   0.026025  |    0.010341     |   2\n",
      "      24425 |   0.175578  |    0.093089     |   0\n",
      "      24426 |   0.185772  |    0.245719     |   1\n",
      "      24427 |   0.166787  |    0.212085     |   1\n",
      "      24428 |   0.162075  |    0.406799     |   1\n",
      "      24429 |   0.175493  |    0.315633     |   1\n",
      "      24430 |   0.228584  |    0.383042     |   1\n",
      "      24431 |   0.035009  |    0.081602     |   2\n",
      "      24432 |   0.051791  |    0.150540     |   2\n",
      "      24433 |   0.213566  |    0.331167     |   1\n",
      "      24434 |   0.048045  |    0.087339     |   2\n",
      "      24435 |   0.039972  |    0.092317     |   2\n",
      "      24436 |   0.198553  |    0.151543     |   0\n",
      "      24437 |   0.172919  |    0.241875     |   1\n",
      "      24438 |   0.019562  |    0.137696     |   2\n",
      "      24439 |   0.000019  |    0.069657     |   2\n",
      "      24440 |   0.005187  |    0.076348     |   2\n",
      "      24441 |   0.058193  |    0.125866     |   2\n",
      "      24442 |   0.154610  |    0.007394     |   0\n",
      "      24443 |   0.030989  |    0.093030     |   2\n",
      "      24444 |   0.053266  |    0.089396     |   2\n",
      "      24445 |   0.240152  |    0.425214     |   1\n",
      "      24446 |   0.037629  |    0.079077     |   2\n",
      "      24447 |   0.141867  |    0.142378     |   0\n",
      "      24448 |   0.013504  |    0.022116     |   2\n",
      "      24449 |   0.031803  |    0.177617     |   2\n",
      "      24450 |   0.246856  |    0.005960     |   0\n",
      "      24451 |   0.184939  |    0.376364     |   1\n",
      "      24452 |   0.028632  |    0.144642     |   2\n",
      "      24453 |   0.203528  |    0.024349     |   0\n",
      "      24454 |   0.000019  |    0.193313     |   2\n",
      "      24455 |   0.259172  |    0.235881     |   1\n",
      "      24456 |   0.145784  |    0.072156     |   0\n",
      "      24457 |   0.196822  |    0.037799     |   0\n",
      "      24458 |   0.000019  |    0.116107     |   2\n",
      "      24459 |   0.173408  |    0.072208     |   0\n",
      "      24460 |   0.000019  |    0.127901     |   2\n",
      "      24461 |   0.219202  |    0.240784     |   1\n",
      "      24462 |   0.000019  |    0.066924     |   2\n",
      "      24463 |   0.157758  |    0.036920     |   0\n",
      "      24464 |   0.178444  |    0.088257     |   0\n",
      "      24465 |   0.171235  |    0.293631     |   1\n",
      "      24466 |   0.143827  |    0.023709     |   0\n",
      "      24467 |   0.000018  |    0.095033     |   2\n",
      "      24468 |   0.219669  |    0.301589     |   1\n",
      "      24469 |   0.159455  |    0.087884     |   0\n",
      "      24470 |   0.000018  |    0.047311     |   2\n",
      "      24471 |   0.187126  |    0.040888     |   0\n",
      "      24472 |   0.223977  |    0.222965     |   1\n",
      "      24473 |   0.201434  |    0.220788     |   1\n",
      "      24474 |   0.204359  |    0.205987     |   1\n",
      "      24475 |   0.166842  |    0.184801     |   1\n",
      "      24476 |   0.162183  |    0.063685     |   0\n",
      "      24477 |   0.041953  |    0.096699     |   2\n",
      "      24478 |   0.046851  |    0.003420     |   2\n",
      "      24479 |   0.205117  |    0.075399     |   0\n",
      "      24480 |   0.197300  |    0.064312     |   0\n",
      "      24481 |   0.178705  |    0.104373     |   0\n",
      "      24482 |   0.161886  |    0.163220     |   1\n",
      "      24483 |   0.178384  |    0.273282     |   1\n",
      "      24484 |   0.226380  |    0.218317     |   1\n",
      "      24485 |   0.214133  |    0.029705     |   0\n",
      "      24486 |   0.216891  |    0.168478     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 24487: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      24487 |   0.044496  |    0.044607     |   2\n",
      "      24488 |   0.030692  |    0.069943     |   2\n",
      "      24489 |   0.186564  |    0.047085     |   0\n",
      "      24490 |   0.038712  |    0.040352     |   2\n",
      "      24491 |   0.185096  |    0.214944     |   1\n",
      "      24492 |   0.175120  |    0.026517     |   0\n",
      "      24493 |   0.139037  |    0.041137     |   0\n",
      "      24494 |   0.153951  |    0.076163     |   0\n",
      "      24495 |   0.037475  |    0.046908     |   2\n",
      "      24496 |   0.211453  |    0.330632     |   1\n",
      "      24497 |   0.153294  |    0.010706     |   0\n",
      "      24498 |   0.213049  |    0.095906     |   0\n",
      "      24499 |   0.024413  |    0.017985     |   2\n",
      "      24500 |   0.035681  |    0.085399     |   2\n",
      "      24501 |   0.186623  |    0.085579     |   0\n",
      "      24502 |   0.042349  |    0.112343     |   2\n",
      "      24503 |   0.195015  |    0.064324     |   0\n",
      "      24504 |   0.029732  |    0.061232     |   2\n",
      "      24505 |   0.037314  |    0.080101     |   2\n",
      "      24506 |   0.035570  |    0.052484     |   2\n",
      "      24507 |   0.161792  |    0.096581     |   0\n",
      "      24508 |   0.191031  |    0.189392     |   1\n",
      "      24509 |   0.194138  |    0.293529     |   1\n",
      "      24510 |   0.024590  |    0.054285     |   2\n",
      "      24511 |   0.172749  |    0.231353     |   1\n",
      "      24512 |   0.192373  |    0.233824     |   1\n",
      "      24513 |   0.176409  |    0.240618     |   1\n",
      "      24514 |   0.166106  |    0.056677     |   0\n",
      "      24515 |   0.190183  |    0.084642     |   0\n",
      "      24516 |   0.172412  |    0.053905     |   0\n",
      "      24517 |   0.188254  |    0.243656     |   1\n",
      "      24518 |   0.192777  |    0.230106     |   1\n",
      "      24519 |   0.034415  |    0.017186     |   2\n",
      "      24520 |   0.047450  |    0.058208     |   2\n",
      "      24521 |   0.047853  |    0.075900     |   2\n",
      "      24522 |   0.132529  |    0.044588     |   0\n",
      "      24523 |   0.039325  |    0.071115     |   2\n",
      "      24524 |   0.119954  |    0.064594     |   0\n",
      "      24525 |   0.192998  |    0.218738     |   1\n",
      "      24526 |   0.197189  |    0.010878     |   0\n",
      "      24527 |   0.235387  |    0.251157     |   1\n",
      "      24528 |   0.019525  |    0.030505     |   2\n",
      "      24529 |   0.167768  |    0.073118     |   0\n",
      "      24530 |   0.000018  |    0.073907     |   2\n",
      "      24531 |   0.144280  |    0.271136     |   1\n",
      "      24532 |   0.220696  |    0.195061     |   1\n",
      "      24533 |   0.193301  |    0.007686     |   0\n",
      "      24534 |   0.202040  |    0.086988     |   0\n",
      "      24535 |   0.199692  |    0.043647     |   0\n",
      "      24536 |   0.202864  |    0.052525     |   0\n",
      "      24537 |   0.005291  |    0.077375     |   2\n",
      "      24538 |   0.186599  |    0.276911     |   1\n",
      "      24539 |   0.163769  |    0.222723     |   1\n",
      "      24540 |   0.057421  |    0.080636     |   2\n",
      "      24541 |   0.145974  |    0.067554     |   0\n",
      "      24542 |   0.160655  |    0.252198     |   1\n",
      "      24543 |   0.158084  |    0.040068     |   0\n",
      "      24544 |   0.032410  |    0.097417     |   2\n",
      "      24545 |   0.149630  |    0.273558     |   1\n",
      "      24546 |   0.195626  |    0.242202     |   1\n",
      "      24547 |   0.129066  |    0.012749     |   0\n",
      "      24548 |   0.175780  |    0.082713     |   0\n",
      "      24549 |   0.231327  |    0.056144     |   0\n",
      "      24550 |   0.193098  |    0.205946     |   1\n",
      "      24551 |   0.054656  |    0.070961     |   2\n",
      "      24552 |   0.198911  |    0.231877     |   1\n",
      "      24553 |   0.158901  |    0.059343     |   0\n",
      "      24554 |   0.158471  |    0.083843     |   0\n",
      "      24555 |   0.140733  |    0.221723     |   1\n",
      "      24556 |   0.225362  |    0.168971     |   1\n",
      "      24557 |   0.160472  |    0.280093     |   1\n",
      "      24558 |   0.223744  |    0.208139     |   1\n",
      "      24559 |   0.211570  |    0.015241     |   0\n",
      "      24560 |   0.210424  |    0.084567     |   0\n",
      "      24561 |   0.119630  |    0.202587     |   1\n",
      "      24562 |   0.039396  |    0.073172     |   2\n",
      "      24563 |   0.015012  |    0.054440     |   2\n",
      "      24564 |   0.188439  |    0.262288     |   1\n",
      "      24565 |   0.171440  |    0.011618     |   0\n",
      "      24566 |   0.169877  |    0.086204     |   0\n",
      "      24567 |   0.034909  |    0.077546     |   2\n",
      "      24568 |   0.216611  |    0.288236     |   1\n",
      "      24569 |   0.220621  |    0.198178     |   1\n",
      "      24570 |   0.212826  |    0.215792     |   1\n",
      "      24571 |   0.025628  |    0.104216     |   2\n",
      "      24572 |   0.153049  |    0.221648     |   1\n",
      "      24573 |   0.000018  |    0.016212     |   2\n",
      "      24574 |   0.200219  |    0.100260     |   0\n",
      "      24575 |   0.217784  |    0.214524     |   1\n",
      "      24576 |   0.194013  |    0.022608     |   0\n",
      "      24577 |   0.000018  |    0.114160     |   2\n",
      "      24578 |   0.000018  |    0.028239     |   2\n",
      "      24579 |   0.155212  |    0.112628     |   0\n",
      "      24580 |   0.169175  |    0.066060     |   0\n",
      "      24581 |   0.199611  |    0.015185     |   0\n",
      "      24582 |   0.163935  |    0.120380     |   0\n",
      "      24583 |   0.170143  |    0.026193     |   0\n",
      "      24584 |   0.000018  |    0.105258     |   2\n",
      "      24585 |   0.000018  |    0.059897     |   2\n",
      "      24586 |   0.000018  |    0.078202     |   2\n",
      "      24587 |   0.154991  |    0.055833     |   0\n",
      "      24588 |   0.198928  |    0.296805     |   1\n",
      "      24589 |   0.126287  |    0.008182     |   0\n",
      "      24590 |   0.043960  |    0.094254     |   2\n",
      "      24591 |   0.154775  |    0.047165     |   0\n",
      "      24592 |   0.178267  |    0.234628     |   1\n",
      "      24593 |   0.047442  |    0.078898     |   2\n",
      "      24594 |   0.175181  |    0.262652     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 24595: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      24595 |   0.042709  |    0.014632     |   2\n",
      "      24596 |   0.135237  |    0.245345     |   1\n",
      "      24597 |   0.150542  |    0.227701     |   1\n",
      "      24598 |   0.210525  |    0.191890     |   1\n",
      "      24599 |   0.148523  |    0.189017     |   1\n",
      "      24600 |   0.031184  |    0.022131     |   2\n",
      "      24601 |   0.035349  |    0.090264     |   2\n",
      "      24602 |   0.198539  |    0.232240     |   1\n",
      "      24603 |   0.182384  |    0.074528     |   0\n",
      "      24604 |   0.202979  |    0.059222     |   0\n",
      "      24605 |   0.231115  |    0.096155     |   0\n",
      "      24606 |   0.212353  |    0.046431     |   0\n",
      "      24607 |   0.187981  |    0.084808     |   0\n",
      "      24608 |   0.135414  |    0.097672     |   0\n",
      "      24609 |   0.036786  |    0.050404     |   2\n",
      "      24610 |   0.161079  |    0.066732     |   0\n",
      "      24611 |   0.187412  |    0.193898     |   1\n",
      "      24612 |   0.025784  |    0.061118     |   2\n",
      "      24613 |   0.182537  |    0.081760     |   0\n",
      "      24614 |   0.037935  |    0.073977     |   2\n",
      "      24615 |   0.169473  |    0.236338     |   1\n",
      "      24616 |   0.187885  |    0.100024     |   0\n",
      "      24617 |   0.168900  |    0.063894     |   0\n",
      "      24618 |   0.050717  |    0.021360     |   2\n",
      "      24619 |   0.158471  |    0.076146     |   0\n",
      "      24620 |   0.050095  |    0.024592     |   2\n",
      "      24621 |   0.152460  |    0.354436     |   1\n",
      "      24622 |   0.185320  |    0.003500     |   0\n",
      "      24623 |   0.170201  |    0.093866     |   0\n",
      "      24624 |   0.151157  |    0.223792     |   1\n",
      "      24625 |   0.172761  |    0.211518     |   1\n",
      "      24626 |   0.041850  |    0.077690     |   2\n",
      "      24627 |   0.019673  |    0.039178     |   2\n",
      "      24628 |   0.000018  |    0.078938     |   2\n",
      "      24629 |   0.005232  |    0.078269     |   2\n",
      "      24630 |   0.177904  |    0.069809     |   0\n",
      "      24631 |   0.058973  |    0.081272     |   2\n",
      "      24632 |   0.035590  |    0.093437     |   2\n",
      "      24633 |   0.162231  |    0.296002     |   1\n",
      "      24634 |   0.181493  |    0.208384     |   1\n",
      "      24635 |   0.125643  |    0.123705     |   0\n",
      "      24636 |   0.054634  |    0.064728     |   2\n",
      "      24637 |   0.041030  |    0.064105     |   2\n",
      "      24638 |   0.193001  |    0.074138     |   0\n",
      "      24639 |   0.015697  |    0.057316     |   2\n",
      "      24640 |   0.174094  |    0.375434     |   1\n",
      "      24641 |   0.035627  |    0.007615     |   2\n",
      "      24642 |   0.183804  |    0.093877     |   0\n",
      "      24643 |   0.027271  |    0.042558     |   2\n",
      "      24644 |   0.211714  |    0.230442     |   1\n",
      "      24645 |   0.163052  |    0.052396     |   0\n",
      "      24646 |   0.000018  |    0.038559     |   2\n",
      "      24647 |   0.222684  |    0.357769     |   1\n",
      "      24648 |   0.000018  |    0.104274     |   2\n",
      "      24649 |   0.241053  |    0.330616     |   1\n",
      "      24650 |   0.164233  |    0.270530     |   1\n",
      "      24651 |   0.176915  |    0.273751     |   1\n",
      "      24652 |   0.139177  |    0.052354     |   0\n",
      "      24653 |   0.000018  |    0.095127     |   2\n",
      "      24654 |   0.182653  |    0.347847     |   1\n",
      "      24655 |   0.157520  |    0.075298     |   0\n",
      "      24656 |   0.158561  |    0.295360     |   1\n",
      "      24657 |   0.161537  |    0.395884     |   1\n",
      "      24658 |   0.204349  |    0.307824     |   1\n",
      "      24659 |   0.175896  |    0.386663     |   1\n",
      "      24660 |   0.205234  |    0.517613     |   1\n",
      "      24661 |   0.000018  |    0.076558     |   2\n",
      "      24662 |   0.218322  |    0.150562     |   0\n",
      "      24663 |   0.156298  |    0.063268     |   0\n",
      "      24664 |   0.161172  |    0.272668     |   1\n",
      "      24665 |   0.139978  |    0.016327     |   0\n",
      "      24666 |   0.162965  |    0.288903     |   1\n",
      "      24667 |   0.153293  |    0.047007     |   0\n",
      "      24668 |   0.000018  |    0.147292     |   2\n",
      "      24669 |   0.000018  |    0.005855     |   2\n",
      "      24670 |   0.040394  |    0.080418     |   2\n",
      "      24671 |   0.046895  |    0.049082     |   2\n",
      "      24672 |   0.139534  |    0.557225     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 24673: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      24673 |   0.042936  |    0.200105     |   2\n",
      "      24674 |   0.148623  |    0.143755     |   0\n",
      "      24675 |   0.030047  |    0.091506     |   2\n",
      "      24676 |   0.037192  |    0.092561     |   2\n",
      "      24677 |   0.036887  |    0.109664     |   2\n",
      "      24678 |   0.025709  |    0.104090     |   2\n",
      "      24679 |   0.036157  |    0.049933     |   2\n",
      "      24680 |   0.155832  |    0.096024     |   0\n",
      "      24681 |   0.222517  |    0.361685     |   1\n",
      "      24682 |   0.137668  |    0.232536     |   0\n",
      "      24683 |   0.137636  |    0.121816     |   0\n",
      "      24684 |   0.178961  |    0.129971     |   0\n",
      "      24685 |   0.223815  |    0.237406     |   0\n",
      "      24686 |   0.047774  |    0.067082     |   2\n",
      "      24687 |   0.170430  |    0.070320     |   0\n",
      "      24688 |   0.047997  |    0.090542     |   2\n",
      "      24689 |   0.148972  |    0.119078     |   0\n",
      "      24690 |   0.202032  |    0.153762     |   0\n",
      "      24691 |   0.216445  |    0.053429     |   0\n",
      "      24692 |   0.042108  |    0.047982     |   2\n",
      "      24693 |   0.173254  |    0.219900     |   1\n",
      "      24694 |   0.233092  |    0.065745     |   0\n",
      "      24695 |   0.125713  |    0.048321     |   0\n",
      "      24696 |   0.126488  |    0.046087     |   0\n",
      "      24697 |   0.020062  |    0.046616     |   2\n",
      "      24698 |   0.159933  |    0.044024     |   0\n",
      "      24699 |   0.265923  |    0.222865     |   1\n",
      "      24700 |   0.000018  |    0.037800     |   2\n",
      "      24701 |   0.189992  |    0.270099     |   1\n",
      "      24702 |   0.158631  |    0.274049     |   1\n",
      "      24703 |   0.005658  |    0.028381     |   2\n",
      "      24704 |   0.190590  |    0.259803     |   1\n",
      "      24705 |   0.199068  |    0.026133     |   0\n",
      "      24706 |   0.171162  |    0.116915     |   0\n",
      "      24707 |   0.123416  |    0.004672     |   0\n",
      "      24708 |   0.142271  |    0.107169     |   0\n",
      "      24709 |   0.055975  |    0.008834     |   2\n",
      "      24710 |   0.034166  |    0.059996     |   2\n",
      "      24711 |   0.227604  |    0.264504     |   1\n",
      "      24712 |   0.130015  |    0.182248     |   1\n",
      "      24713 |   0.056554  |    0.017567     |   2\n",
      "      24714 |   0.131363  |    0.098739     |   0\n",
      "      24715 |   0.171123  |    0.020085     |   0\n",
      "      24716 |   0.042659  |    0.158056     |   2\n",
      "      24717 |   0.017054  |    0.006139     |   2\n",
      "      24718 |   0.152573  |    0.069448     |   0\n",
      "      24719 |   0.201596  |    0.048664     |   0\n",
      "      24720 |   0.179824  |    0.100229     |   0\n",
      "      24721 |   0.209634  |    0.218969     |   1\n",
      "      24722 |   0.037530  |    0.126738     |   2\n",
      "      24723 |   0.127275  |    0.287122     |   1\n",
      "      24724 |   0.185770  |    0.167927     |   1\n",
      "      24725 |   0.125085  |    0.041749     |   0\n",
      "      24726 |   0.183544  |    0.080803     |   0\n",
      "      24727 |   0.026620  |    0.017932     |   2\n",
      "      24728 |   0.000018  |    0.139344     |   2\n",
      "      24729 |   0.178402  |    0.227310     |   1\n",
      "      24730 |   0.175358  |    0.199853     |   1\n",
      "      24731 |   0.192965  |    0.206269     |   1\n",
      "      24732 |   0.000018  |    0.099118     |   2\n",
      "      24733 |   0.000018  |    0.043478     |   2\n",
      "      24734 |   0.188234  |    0.234397     |   1\n",
      "      24735 |   0.000018  |    0.125665     |   2\n",
      "      24736 |   0.206229  |    0.212913     |   1\n",
      "      24737 |   0.185675  |    0.073328     |   0\n",
      "      24738 |   0.228404  |    0.061685     |   0\n",
      "      24739 |   0.188838  |    0.174884     |   1\n",
      "      24740 |   0.176924  |    0.073153     |   0\n",
      "      24741 |   0.000018  |    0.073416     |   2\n",
      "      24742 |   0.000018  |    0.037544     |   2\n",
      "      24743 |   0.205993  |    0.045809     |   0\n",
      "      24744 |   0.041261  |    0.075178     |   2\n",
      "      24745 |   0.192299  |    0.078040     |   0\n",
      "      24746 |   0.167802  |    0.028440     |   0\n",
      "      24747 |   0.219273  |    0.266824     |   1\n",
      "      24748 |   0.047403  |    0.038480     |   2\n",
      "      24749 |   0.273401  |    0.257916     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 24751: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      24750 |   0.147756  |    0.014483     |   0\n",
      "      24751 |   0.041123  |    0.068893     |   2\n",
      "      24752 |   0.031230  |    0.127519     |   2\n",
      "      24753 |   0.036030  |    0.023031     |   2\n",
      "      24754 |   0.036840  |    0.089421     |   2\n",
      "      24755 |   0.219442  |    0.238438     |   1\n",
      "      24756 |   0.184555  |    0.209567     |   1\n",
      "      24757 |   0.184263  |    0.023609     |   0\n",
      "      24758 |   0.172683  |    0.276576     |   1\n",
      "      24759 |   0.208173  |    0.040991     |   0\n",
      "      24760 |   0.166516  |    0.085598     |   0\n",
      "      24761 |   0.025514  |    0.043164     |   2\n",
      "      24762 |   0.033284  |    0.039978     |   2\n",
      "      24763 |   0.047645  |    0.071391     |   2\n",
      "      24764 |   0.261252  |    0.038486     |   0\n",
      "      24765 |   0.046443  |    0.090348     |   2\n",
      "      24766 |   0.043561  |    0.065471     |   2\n",
      "      24767 |   0.192791  |    0.282679     |   1\n",
      "      24768 |   0.140791  |    0.138812     |   1\n",
      "      24769 |   0.198245  |    0.206122     |   1\n",
      "      24770 |   0.183074  |    0.018961     |   0\n",
      "      24771 |   0.021476  |    0.110280     |   2\n",
      "      24772 |   0.144863  |    0.214684     |   1\n",
      "      24773 |   0.000018  |    0.060900     |   2\n",
      "      24774 |   0.160282  |    0.027500     |   0\n",
      "      24775 |   0.172527  |    0.226839     |   1\n",
      "      24776 |   0.172042  |    0.064519     |   0\n",
      "      24777 |   0.150323  |    0.064545     |   0\n",
      "      24778 |   0.138961  |    0.120492     |   0\n",
      "      24779 |   0.194440  |    0.299427     |   1\n",
      "      24780 |   0.167175  |    0.034858     |   0\n",
      "      24781 |   0.183066  |    0.079820     |   0\n",
      "      24782 |   0.198683  |    0.096038     |   0\n",
      "      24783 |   0.173593  |    0.232470     |   1\n",
      "      24784 |   0.252769  |    0.237322     |   1\n",
      "      24785 |   0.175355  |    0.047822     |   0\n",
      "      24786 |   0.228676  |    0.149493     |   0\n",
      "      24787 |   0.005209  |    0.006198     |   2\n",
      "      24788 |   0.057841  |    0.075189     |   2\n",
      "      24789 |   0.030691  |    0.087706     |   2\n",
      "      24790 |   0.055727  |    0.032211     |   2\n",
      "      24791 |   0.165465  |    0.268577     |   1\n",
      "      24792 |   0.217131  |    0.012240     |   0\n",
      "      24793 |   0.202368  |    0.251035     |   1\n",
      "      24794 |   0.233634  |    0.058305     |   0\n",
      "      24795 |   0.154930  |    0.086905     |   0\n",
      "      24796 |   0.168705  |    0.257105     |   1\n",
      "      24797 |   0.143266  |    0.237366     |   1\n",
      "      24798 |   0.041737  |    0.022423     |   2\n",
      "      24799 |   0.140999  |    0.106807     |   0\n",
      "      24800 |   0.015668  |    0.050663     |   2\n",
      "      24801 |   0.232075  |    0.213201     |   1\n",
      "      24802 |   0.033304  |    0.021597     |   2\n",
      "      24803 |   0.218212  |    0.209921     |   1\n",
      "      24804 |   0.025095  |    0.046656     |   2\n",
      "      24805 |   0.000018  |    0.091750     |   2\n",
      "      24806 |   0.136222  |    0.013409     |   0\n",
      "      24807 |   0.134395  |    0.055900     |   0\n",
      "      24808 |   0.000018  |    0.067630     |   2\n",
      "      24809 |   0.000018  |    0.058849     |   2\n",
      "      24810 |   0.198351  |    0.101311     |   0\n",
      "      24811 |   0.188432  |    0.035579     |   0\n",
      "      24812 |   0.000018  |    0.081501     |   2\n",
      "      24813 |   0.189574  |    0.194335     |   1\n",
      "      24814 |   0.189954  |    0.257871     |   1\n",
      "      24815 |   0.149702  |    0.231981     |   1\n",
      "      24816 |   0.149024  |    0.057142     |   0\n",
      "      24817 |   0.159462  |    0.055540     |   0\n",
      "      24818 |   0.123751  |    0.094368     |   0\n",
      "      24819 |   0.181074  |    0.065086     |   0\n",
      "      24820 |   0.213484  |    0.224589     |   1\n",
      "      24821 |   0.228192  |    0.061995     |   0\n",
      "      24822 |   0.163542  |    0.101930     |   0\n",
      "      24823 |   0.000018  |    0.038362     |   2\n",
      "      24824 |   0.210030  |    0.272411     |   1\n",
      "      24825 |   0.162032  |    0.068612     |   0\n",
      "      24826 |   0.145480  |    0.063056     |   0\n",
      "      24827 |   0.000018  |    0.108826     |   2\n",
      "      24828 |   0.173870  |    0.040367     |   0\n",
      "      24829 |   0.140349  |    0.047522     |   0\n",
      "      24830 |   0.194446  |    0.206339     |   1\n",
      "      24831 |   0.179297  |    0.010344     |   0\n",
      "      24832 |   0.186154  |    0.246654     |   1\n",
      "      24833 |   0.200988  |    0.097792     |   0\n",
      "      24834 |   0.177858  |    0.064749     |   0\n",
      "      24835 |   0.141568  |    0.039837     |   0\n",
      "      24836 |   0.042914  |    0.087388     |   2\n",
      "      24837 |   0.046510  |    0.094135     |   2\n",
      "      24838 |   0.127635  |    0.034608     |   0\n",
      "      24839 |   0.145658  |    0.043393     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 24840: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      24840 |   0.047611  |    0.060051     |   2\n",
      "      24841 |   0.126787  |    0.042568     |   0\n",
      "      24842 |   0.032102  |    0.097919     |   2\n",
      "      24843 |   0.151456  |    0.028865     |   0\n",
      "      24844 |   0.194111  |    0.243595     |   1\n",
      "      24845 |   0.197878  |    0.231590     |   1\n",
      "      24846 |   0.198129  |    0.199490     |   1\n",
      "      24847 |   0.168867  |    0.233878     |   1\n",
      "      24848 |   0.183212  |    0.251093     |   1\n",
      "      24849 |   0.165330  |    0.429564     |   1\n",
      "      24850 |   0.176013  |    0.153908     |   0\n",
      "      24851 |   0.037378  |    0.075778     |   2\n",
      "      24852 |   0.037313  |    0.158045     |   2\n",
      "      24853 |   0.217881  |    0.343736     |   1\n",
      "      24854 |   0.224347  |    0.352801     |   1\n",
      "      24855 |   0.025551  |    0.071406     |   2\n",
      "      24856 |   0.147699  |    0.141755     |   0\n",
      "      24857 |   0.175766  |    0.037971     |   0\n",
      "      24858 |   0.178796  |    0.088902     |   0\n",
      "      24859 |   0.210727  |    0.402119     |   1\n",
      "      24860 |   0.034077  |    0.124138     |   2\n",
      "      24861 |   0.174841  |    0.325853     |   1\n",
      "      24862 |   0.047708  |    0.113819     |   2\n",
      "      24863 |   0.156684  |    0.077118     |   0\n",
      "      24864 |   0.181333  |    0.076559     |   0\n",
      "      24865 |   0.172951  |    0.202481     |   1\n",
      "      24866 |   0.115771  |    0.271952     |   1\n",
      "      24867 |   0.048899  |    0.042201     |   2\n",
      "      24868 |   0.153276  |    0.230877     |   1\n",
      "      24869 |   0.152987  |    0.025844     |   0\n",
      "      24870 |   0.041992  |    0.119527     |   2\n",
      "      24871 |   0.157271  |    0.006563     |   0\n",
      "      24872 |   0.022243  |    0.074367     |   2\n",
      "      24873 |   0.000018  |    0.120579     |   2\n",
      "      24874 |   0.004747  |    0.027399     |   2\n",
      "      24875 |   0.059708  |    0.076532     |   2\n",
      "      24876 |   0.169917  |    0.262940     |   1\n",
      "      24877 |   0.167813  |    0.063491     |   0\n",
      "      24878 |   0.167405  |    0.258312     |   1\n",
      "      24879 |   0.172377  |    0.042116     |   0\n",
      "      24880 |   0.156886  |    0.082480     |   0\n",
      "      24881 |   0.147989  |    0.057009     |   0\n",
      "      24882 |   0.174540  |    0.260864     |   1\n",
      "      24883 |   0.169781  |    0.009182     |   0\n",
      "      24884 |   0.163319  |    0.223863     |   1\n",
      "      24885 |   0.032994  |    0.006276     |   2\n",
      "      24886 |   0.124060  |    0.118404     |   0\n",
      "      24887 |   0.186222  |    0.207894     |   1\n",
      "      24888 |   0.055765  |    0.055437     |   2\n",
      "      24889 |   0.144716  |    0.066705     |   0\n",
      "      24890 |   0.189386  |    0.239473     |   1\n",
      "      24891 |   0.039187  |    0.034918     |   2\n",
      "      24892 |   0.260846  |    0.186401     |   1\n",
      "      24893 |   0.177214  |    0.043165     |   0\n",
      "      24894 |   0.145932  |    0.069932     |   0\n",
      "      24895 |   0.015096  |    0.125441     |   2\n",
      "      24896 |   0.183418  |    0.188172     |   1\n",
      "      24897 |   0.190905  |    0.020681     |   0\n",
      "      24898 |   0.192473  |    0.079952     |   0\n",
      "      24899 |   0.322566  |    0.244752     |   1\n",
      "      24900 |   0.250403  |    0.189953     |   1\n",
      "      24901 |   0.175482  |    0.262640     |   1\n",
      "      24902 |   0.170558  |    0.170573     |   1\n",
      "      24903 |   0.185896  |    0.078267     |   0\n",
      "      24904 |   0.033318  |    0.052122     |   2\n",
      "      24905 |   0.186090  |    0.220712     |   1\n",
      "      24906 |   0.164383  |    0.229293     |   1\n",
      "      24907 |   0.155966  |    0.225186     |   1\n",
      "      24908 |   0.168491  |    0.041363     |   0\n",
      "      24909 |   0.176804  |    0.147264     |   0\n",
      "      24910 |   0.207304  |    0.167187     |   1\n",
      "      24911 |   0.025688  |    0.074412     |   2\n",
      "      24912 |   0.171281  |    0.077066     |   0\n",
      "      24913 |   0.000019  |    0.026427     |   2\n",
      "      24914 |   0.000019  |    0.071783     |   2\n",
      "      24915 |   0.243990  |    0.201223     |   1\n",
      "      24916 |   0.192900  |    0.194720     |   1\n",
      "      24917 |   0.000019  |    0.011105     |   2\n",
      "      24918 |   0.151822  |    0.122604     |   0\n",
      "      24919 |   0.226034  |    0.005329     |   0\n",
      "      24920 |   0.235359  |    0.044205     |   0\n",
      "      24921 |   0.144309  |    0.316409     |   1\n",
      "      24922 |   0.196136  |    0.223775     |   1\n",
      "      24923 |   0.210317  |    0.162323     |   1\n",
      "      24924 |   0.201915  |    0.235051     |   1\n",
      "      24925 |   0.208103  |    0.021808     |   0\n",
      "      24926 |   0.158529  |    0.072661     |   0\n",
      "      24927 |   0.191003  |    0.079645     |   0\n",
      "      24928 |   0.195449  |    0.232190     |   1\n",
      "      24929 |   0.164032  |    0.139979     |   1\n",
      "      24930 |   0.140430  |    0.089422     |   0\n",
      "      24931 |   0.135250  |    0.012185     |   0\n",
      "      24932 |   0.000018  |    0.095476     |   2\n",
      "      24933 |   0.000018  |    0.060490     |   2\n",
      "      24934 |   0.000018  |    0.082783     |   2\n",
      "      24935 |   0.043172  |    0.048285     |   2\n",
      "      24936 |   0.045701  |    0.063188     |   2\n",
      "      24937 |   0.200527  |    0.087361     |   0\n",
      "      24938 |   0.179142  |    0.058898     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 24939: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      24939 |   0.236814  |    0.088496     |   0\n",
      "      24940 |   0.201468  |    0.216523     |   1\n",
      "      24941 |   0.215211  |    0.219237     |   1\n",
      "      24942 |   0.048637  |    0.069036     |   2\n",
      "      24943 |   0.163156  |    0.221077     |   1\n",
      "      24944 |   0.197611  |    0.209183     |   1\n",
      "      24945 |   0.032797  |    0.056940     |   2\n",
      "      24946 |   0.215679  |    0.086189     |   0\n",
      "      24947 |   0.146282  |    0.052960     |   0\n",
      "      24948 |   0.185236  |    0.167121     |   1\n",
      "      24949 |   0.178462  |    0.213748     |   1\n",
      "      24950 |   0.120486  |    0.262464     |   1\n",
      "      24951 |   0.158155  |    0.004832     |   0\n",
      "      24952 |   0.200416  |    0.194488     |   1\n",
      "      24953 |   0.038392  |    0.008387     |   2\n",
      "      24954 |   0.166030  |    0.276274     |   1\n",
      "      24955 |   0.184454  |    0.172054     |   1\n",
      "      24956 |   0.037130  |    0.100194     |   2\n",
      "      24957 |   0.164577  |    0.028882     |   0\n",
      "      24958 |   0.128513  |    0.081876     |   0\n",
      "      24959 |   0.234875  |    0.237781     |   1\n",
      "      24960 |   0.162210  |    0.199626     |   1\n",
      "      24961 |   0.025087  |    0.076204     |   2\n",
      "      24962 |   0.184392  |    0.066408     |   0\n",
      "      24963 |   0.167753  |    0.067272     |   0\n",
      "      24964 |   0.153621  |    0.188322     |   1\n",
      "      24965 |   0.177183  |    0.091971     |   0\n",
      "      24966 |   0.034352  |    0.013173     |   2\n",
      "      24967 |   0.193644  |    0.241016     |   1\n",
      "      24968 |   0.248245  |    0.187648     |   1\n",
      "      24969 |   0.270811  |    0.065324     |   0\n",
      "      24970 |   0.153741  |    0.068597     |   0\n",
      "      24971 |   0.048784  |    0.028895     |   2\n",
      "      24972 |   0.185918  |    0.111081     |   0\n",
      "      24973 |   0.047344  |    0.068408     |   2\n",
      "      24974 |   0.192727  |    0.043002     |   0\n",
      "      24975 |   0.185723  |    0.238160     |   1\n",
      "      24976 |   0.041655  |    0.059723     |   2\n",
      "      24977 |   0.133997  |    0.200282     |   1\n",
      "      24978 |   0.196300  |    0.048390     |   0\n",
      "      24979 |   0.021321  |    0.074700     |   2\n",
      "      24980 |   0.228059  |    0.195011     |   1\n",
      "      24981 |   0.178681  |    0.197492     |   1\n",
      "      24982 |   0.133766  |    0.082872     |   0\n",
      "      24983 |   0.000018  |    0.061407     |   2\n",
      "      24984 |   0.005215  |    0.098603     |   2\n",
      "      24985 |   0.144994  |    0.043945     |   0\n",
      "      24986 |   0.061962  |    0.039195     |   2\n",
      "      24987 |   0.100312  |    0.041678     |   0\n",
      "      24988 |   0.034044  |    0.098590     |   2\n",
      "      24989 |   0.191323  |    0.164193     |   1\n",
      "      24990 |   0.135860  |    0.057476     |   0\n",
      "      24991 |   0.055288  |    0.122267     |   2\n",
      "      24992 |   0.041960  |    0.026676     |   2\n",
      "      24993 |   0.217967  |    0.256805     |   1\n",
      "      24994 |   0.015369  |    0.146759     |   2\n",
      "      24995 |   0.184305  |    0.216305     |   1\n",
      "      24996 |   0.034156  |    0.049876     |   2\n",
      "      24997 |   0.216270  |    0.262344     |   1\n",
      "      24998 |   0.182948  |    0.185667     |   1\n",
      "      24999 |   0.125015  |    0.114936     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 25000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 25000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      25000 |   0.025420  |    0.016613     |   2\n",
      "      25001 |   0.041221  |    0.079801     |   2\n",
      "      25002 |   0.156302  |    0.093636     |   0\n",
      "      25003 |   0.029699  |    0.022260     |   2\n",
      "      25004 |   0.127940  |    0.071003     |   0\n",
      "      25005 |   0.170043  |    0.286377     |   1\n",
      "      25006 |   0.208299  |    0.194566     |   1\n",
      "      25007 |   0.208272  |    0.092267     |   0\n",
      "      25008 |   0.220065  |    0.296075     |   1\n",
      "      25009 |   0.224297  |    0.024329     |   0\n",
      "      25010 |   0.220435  |    0.164822     |   1\n",
      "      25011 |   0.171698  |    0.072300     |   0\n",
      "      25012 |   0.232615  |    0.057305     |   0\n",
      "      25013 |   0.137585  |    0.249348     |   1\n",
      "      25014 |   0.156976  |    0.058559     |   0\n",
      "      25015 |   0.176762  |    0.082626     |   0\n",
      "      25016 |   0.193256  |    0.220893     |   1\n",
      "      25017 |   0.037349  |    0.024482     |   2\n",
      "      25018 |   0.164622  |    0.093415     |   0\n",
      "      25019 |   0.161017  |    0.040275     |   0\n",
      "      25020 |   0.145510  |    0.050251     |   0\n",
      "      25021 |   0.167238  |    0.233221     |   1\n",
      "      25022 |   0.134617  |    0.090851     |   0\n",
      "      25023 |   0.139251  |    0.232021     |   1\n",
      "      25024 |   0.180735  |    0.278543     |   1\n",
      "      25025 |   0.150618  |    0.183345     |   1\n",
      "      25026 |   0.202290  |    0.045374     |   0\n",
      "      25027 |   0.036083  |    0.047970     |   2\n",
      "      25028 |   0.167588  |    0.241877     |   1\n",
      "      25029 |   0.190930  |    0.231282     |   1\n",
      "      25030 |   0.183111  |    0.175155     |   1\n",
      "      25031 |   0.146000  |    0.237043     |   1\n",
      "      25032 |   0.206906  |    0.201614     |   1\n",
      "      25033 |   0.025620  |    0.040463     |   2\n",
      "      25034 |   0.194564  |    0.215771     |   1\n",
      "      25035 |   0.033812  |    0.028776     |   2\n",
      "      25036 |   0.130712  |    0.072392     |   0\n",
      "      25037 |   0.044871  |    0.105262     |   2\n",
      "      25038 |   0.186288  |    0.210572     |   1\n",
      "      25039 |   0.173098  |    0.228618     |   1\n",
      "      25040 |   0.212124  |    0.217787     |   1\n",
      "      25041 |   0.139166  |    0.205930     |   1\n",
      "      25042 |   0.178694  |    0.155646     |   1\n",
      "      25043 |   0.048289  |    0.045731     |   2\n",
      "      25044 |   0.159423  |    0.260980     |   1\n",
      "      25045 |   0.042840  |    0.004210     |   2\n",
      "      25046 |   0.023311  |    0.055360     |   2\n",
      "      25047 |   0.000018  |    0.146307     |   2\n",
      "      25048 |   0.217217  |    0.222988     |   1\n",
      "      25049 |   0.149914  |    0.141091     |   1\n",
      "      25050 |   0.005249  |    0.066837     |   2\n",
      "      25051 |   0.156714  |    0.202348     |   1\n",
      "      25052 |   0.059901  |    0.096460     |   2\n",
      "      25053 |   0.033315  |    0.047857     |   2\n",
      "      25054 |   0.202884  |    0.220984     |   1\n",
      "      25055 |   0.207391  |    0.218547     |   1\n",
      "      25056 |   0.179711  |    0.052939     |   0\n",
      "      25057 |   0.180519  |    0.216895     |   1\n",
      "      25058 |   0.198478  |    0.015630     |   0\n",
      "      25059 |   0.149716  |    0.257891     |   1\n",
      "      25060 |   0.193893  |    0.092165     |   0\n",
      "      25061 |   0.238066  |    0.287401     |   1\n",
      "      25062 |   0.207119  |    0.194223     |   1\n",
      "      25063 |   0.051865  |    0.099670     |   2\n",
      "      25064 |   0.193283  |    0.027724     |   0\n",
      "      25065 |   0.199940  |    0.049337     |   0\n",
      "      25066 |   0.246907  |    0.069583     |   0\n",
      "      25067 |   0.039216  |    0.071392     |   2\n",
      "      25068 |   0.014872  |    0.061915     |   2\n",
      "      25069 |   0.206328  |    0.062829     |   0\n",
      "      25070 |   0.178169  |    0.057527     |   0\n",
      "      25071 |   0.035666  |    0.043955     |   2\n",
      "      25072 |   0.229262  |    0.082256     |   0\n",
      "      25073 |   0.025361  |    0.079973     |   2\n",
      "      25074 |   0.000018  |    0.047036     |   2\n",
      "      25075 |   0.000018  |    0.067101     |   2\n",
      "      25076 |   0.000018  |    0.075922     |   2\n",
      "      25077 |   0.000018  |    0.026951     |   2\n",
      "      25078 |   0.164881  |    0.330187     |   1\n",
      "      25079 |   0.130918  |    0.169138     |   1\n",
      "      25080 |   0.000018  |    0.051983     |   2\n",
      "      25081 |   0.140245  |    0.051742     |   0\n",
      "      25082 |   0.200349  |    0.265496     |   1\n",
      "      25083 |   0.000018  |    0.053242     |   2\n",
      "      25084 |   0.043177  |    0.038505     |   2\n",
      "      25085 |   0.225165  |    0.023626     |   0\n",
      "      25086 |   0.238743  |    0.262492     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 25088: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      25087 |   0.047760  |    0.040816     |   2\n",
      "      25088 |   0.045469  |    0.080116     |   2\n",
      "      25089 |   0.032056  |    0.076249     |   2\n",
      "      25090 |   0.190218  |    0.250454     |   1\n",
      "      25091 |   0.157747  |    0.161174     |   1\n",
      "      25092 |   0.035686  |    0.094853     |   2\n",
      "      25093 |   0.161080  |    0.027675     |   0\n",
      "      25094 |   0.036790  |    0.054033     |   2\n",
      "      25095 |   0.024604  |    0.082796     |   2\n",
      "      25096 |   0.156364  |    0.226972     |   1\n",
      "      25097 |   0.196511  |    0.178634     |   1\n",
      "      25098 |   0.139899  |    0.231224     |   1\n",
      "      25099 |   0.034409  |    0.027344     |   2\n",
      "      25100 |   0.042547  |    0.077086     |   2\n",
      "      25101 |   0.048864  |    0.062193     |   2\n",
      "      25102 |   0.151328  |    0.096879     |   0\n",
      "      25103 |   0.039755  |    0.004765     |   2\n",
      "      25104 |   0.021839  |    0.075165     |   2\n",
      "      25105 |   0.000018  |    0.074687     |   2\n",
      "      25106 |   0.168678  |    0.187867     |   1\n",
      "      25107 |   0.168499  |    0.063286     |   0\n",
      "      25108 |   0.004734  |    0.077403     |   2\n",
      "      25109 |   0.202136  |    0.078936     |   0\n",
      "      25110 |   0.291430  |    0.227220     |   1\n",
      "      25111 |   0.189065  |    0.214389     |   1\n",
      "      25112 |   0.181877  |    0.253899     |   1\n",
      "      25113 |   0.171569  |    0.003486     |   0\n",
      "      25114 |   0.057718  |    0.070209     |   2\n",
      "      25115 |   0.157997  |    0.272287     |   1\n",
      "      25116 |   0.182970  |    0.227958     |   1\n",
      "      25117 |   0.187743  |    0.216782     |   1\n",
      "      25118 |   0.033182  |    0.015885     |   2\n",
      "      25119 |   0.052926  |    0.079192     |   2\n",
      "      25120 |   0.036793  |    0.062268     |   2\n",
      "      25121 |   0.221730  |    0.246244     |   1\n",
      "      25122 |   0.190348  |    0.151040     |   1\n",
      "      25123 |   0.014593  |    0.064873     |   2\n",
      "      25124 |   0.155487  |    0.209499     |   1\n",
      "      25125 |   0.131317  |    0.285755     |   1\n",
      "      25126 |   0.031872  |    0.026074     |   2\n",
      "      25127 |   0.141084  |    0.224967     |   1\n",
      "      25128 |   0.177684  |    0.044785     |   0\n",
      "      25129 |   0.184409  |    0.034053     |   0\n",
      "      25130 |   0.239078  |    0.223696     |   1\n",
      "      25131 |   0.183249  |    0.202815     |   1\n",
      "      25132 |   0.226009  |    0.193738     |   1\n",
      "      25133 |   0.219710  |    0.003419     |   0\n",
      "      25134 |   0.189485  |    0.095067     |   0\n",
      "      25135 |   0.214912  |    0.233969     |   1\n",
      "      25136 |   0.242002  |    0.202563     |   1\n",
      "      25137 |   0.166535  |    0.005850     |   0\n",
      "      25138 |   0.176908  |    0.153105     |   0\n",
      "      25139 |   0.143684  |    0.166000     |   1\n",
      "      25140 |   0.129037  |    0.072337     |   0\n",
      "      25141 |   0.267931  |    0.080582     |   0\n",
      "      25142 |   0.184514  |    0.206138     |   1\n",
      "      25143 |   0.024846  |    0.016082     |   2\n",
      "      25144 |   0.230239  |    0.231726     |   1\n",
      "      25145 | \u001b[94m  0.000017\u001b[0m  |    0.029269     |   2\n",
      "      25146 |   0.000017  |    0.061726     |   2\n",
      "      25147 | \u001b[94m  0.000017\u001b[0m  |    0.064139     |   2\n",
      "      25148 |   0.000018  |    0.100585     |   2\n",
      "      25149 |   0.151744  |    0.255254     |   1\n",
      "      25150 |   0.128229  |    0.218794     |   1\n",
      "      25151 | \u001b[94m  0.000017\u001b[0m  |    0.045939     |   2\n",
      "      25152 |   0.215905  |    0.095201     |   0\n",
      "      25153 | \u001b[94m  0.000017\u001b[0m  |    0.051148     |   2\n",
      "      25154 |   0.171233  |    0.218972     |   1\n",
      "      25155 |   0.165936  |    0.240530     |   1\n",
      "      25156 |   0.191718  |    0.171966     |   1\n",
      "      25157 |   0.216169  |    0.237561     |   1\n",
      "      25158 |   0.173137  |    0.043739     |   0\n",
      "      25159 |   0.166960  |    0.219423     |   1\n",
      "      25160 |   0.044239  |    0.070464     |   2\n",
      "      25161 |   0.046665  |    0.064844     |   2\n",
      "      25162 |   0.136429  |    0.086369     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 25163: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      25163 |   0.133563  |    0.172818     |   1\n",
      "      25164 |   0.046240  |    0.082607     |   2\n",
      "      25165 |   0.211976  |    0.024234     |   0\n",
      "      25166 |   0.264219  |    0.049503     |   0\n",
      "      25167 |   0.150015  |    0.255654     |   1\n",
      "      25168 |   0.172344  |    0.004103     |   0\n",
      "      25169 |   0.035122  |    0.091182     |   2\n",
      "      25170 |   0.147548  |    0.049212     |   0\n",
      "      25171 |   0.036114  |    0.086207     |   2\n",
      "      25172 |   0.035626  |    0.020399     |   2\n",
      "      25173 |   0.026114  |    0.076497     |   2\n",
      "      25174 |   0.231822  |    0.253821     |   1\n",
      "      25175 |   0.035059  |    0.013903     |   2\n",
      "      25176 |   0.191036  |    0.244089     |   1\n",
      "      25177 |   0.046290  |    0.046831     |   2\n",
      "      25178 |   0.179662  |    0.215846     |   1\n",
      "      25179 |   0.106343  |    0.090907     |   0\n",
      "      25180 |   0.163440  |    0.076067     |   0\n",
      "      25181 |   0.051247  |    0.028734     |   2\n",
      "      25182 |   0.042664  |    0.070200     |   2\n",
      "      25183 |   0.177492  |    0.159930     |   1\n",
      "      25184 |   0.021893  |    0.112898     |   2\n",
      "      25185 |   0.208732  |    0.227094     |   1\n",
      "      25186 |   0.160939  |    0.206754     |   1\n",
      "      25187 |   0.000017  |    0.072687     |   2\n",
      "      25188 |   0.224040  |    0.205690     |   1\n",
      "      25189 |   0.150686  |    0.184593     |   1\n",
      "      25190 |   0.004674  |    0.089432     |   2\n",
      "      25191 |   0.163592  |    0.160860     |   1\n",
      "      25192 |   0.159197  |    0.072085     |   0\n",
      "      25193 |   0.125163  |    0.038925     |   0\n",
      "      25194 |   0.187415  |    0.268194     |   1\n",
      "      25195 |   0.190900  |    0.028277     |   0\n",
      "      25196 |   0.058357  |    0.079325     |   2\n",
      "      25197 |   0.219115  |    0.029794     |   0\n",
      "      25198 |   0.183408  |    0.109941     |   0\n",
      "      25199 |   0.183124  |    0.017153     |   0\n",
      "      25200 |   0.200518  |    0.289568     |   1\n",
      "      25201 |   0.127208  |    0.213119     |   1\n",
      "      25202 |   0.141573  |    0.227606     |   1\n",
      "      25203 |   0.183287  |    0.268042     |   1\n",
      "      25204 |   0.154487  |    0.003257     |   0\n",
      "      25205 |   0.152282  |    0.026102     |   0\n",
      "      25206 |   0.165200  |    0.274631     |   1\n",
      "      25207 |   0.031963  |    0.032222     |   2\n",
      "      25208 |   0.163456  |    0.111965     |   0\n",
      "      25209 |   0.138196  |    0.058479     |   0\n",
      "      25210 |   0.218427  |    0.172805     |   1\n",
      "      25211 |   0.144881  |    0.049486     |   0\n",
      "      25212 |   0.055981  |    0.094800     |   2\n",
      "      25213 |   0.216180  |    0.071212     |   0\n",
      "      25214 |   0.037894  |    0.079119     |   2\n",
      "      25215 |   0.137243  |    0.053923     |   0\n",
      "      25216 |   0.154189  |    0.269229     |   1\n",
      "      25217 |   0.013993  |    0.055150     |   2\n",
      "      25218 |   0.034259  |    0.027078     |   2\n",
      "      25219 |   0.238990  |    0.215977     |   1\n",
      "      25220 |   0.178126  |    0.221201     |   1\n",
      "      25221 |   0.025392  |    0.040865     |   2\n",
      "      25222 |   0.167652  |    0.047128     |   0\n",
      "      25223 |   0.000017  |    0.082974     |   2\n",
      "      25224 |   0.182044  |    0.223055     |   1\n",
      "      25225 |   0.153453  |    0.164619     |   1\n",
      "      25226 |   0.000017  |    0.106110     |   2\n",
      "      25227 |   0.182505  |    0.194647     |   1\n",
      "      25228 |   0.162079  |    0.076342     |   0\n",
      "      25229 |   0.000017  |    0.017156     |   2\n",
      "      25230 |   0.174136  |    0.312418     |   1\n",
      "      25231 |   0.190751  |    0.008621     |   0\n",
      "      25232 |   0.180951  |    0.114081     |   0\n",
      "      25233 |   0.207781  |    0.160156     |   1\n",
      "      25234 |   0.149957  |    0.207104     |   1\n",
      "      25235 |   0.000018  |    0.094300     |   2\n",
      "      25236 |   0.189819  |    0.163298     |   1\n",
      "      25237 |   0.000017  |    0.064013     |   2\n",
      "      25238 |   0.141173  |    0.202146     |   1\n",
      "      25239 |   0.000017  |    0.068611     |   2\n",
      "      25240 |   0.040138  |    0.076591     |   2\n",
      "      25241 |   0.129429  |    0.054042     |   0\n",
      "      25242 |   0.046860  |    0.061570     |   2\n",
      "      25243 |   0.137614  |    0.075098     |   0\n",
      "      25244 |   0.190975  |    0.063951     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 25245: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      25245 |   0.044229  |    0.065671     |   2\n",
      "      25246 |   0.171018  |    0.044088     |   0\n",
      "      25247 |   0.031998  |    0.142666     |   2\n",
      "      25248 |   0.039533  |    0.007137     |   2\n",
      "      25249 |   0.172299  |    0.273082     |   1\n",
      "      25250 |   0.200952  |    0.184891     |   1\n",
      "      25251 |   0.038070  |    0.007032     |   2\n",
      "      25252 |   0.183683  |    0.079050     |   0\n",
      "      25253 |   0.185993  |    0.291344     |   1\n",
      "      25254 |   0.159809  |    0.010382     |   0\n",
      "      25255 |   0.195723  |    0.293568     |   1\n",
      "      25256 |   0.199934  |    0.216226     |   1\n",
      "      25257 |   0.154965  |    0.005125     |   0\n",
      "      25258 |   0.178530  |    0.063750     |   0\n",
      "      25259 |   0.157223  |    0.299265     |   1\n",
      "      25260 |   0.208987  |    0.184959     |   1\n",
      "      25261 |   0.025257  |    0.044036     |   2\n",
      "      25262 |   0.194971  |    0.043821     |   0\n",
      "      25263 |   0.126862  |    0.238257     |   1\n",
      "      25264 |   0.145535  |    0.023265     |   0\n",
      "      25265 |   0.034668  |    0.117431     |   2\n",
      "      25266 |   0.044051  |    0.009981     |   2\n",
      "      25267 |   0.177858  |    0.092018     |   0\n",
      "      25268 |   0.047865  |    0.048615     |   2\n",
      "      25269 |   0.041561  |    0.128757     |   2\n",
      "      25270 |   0.020220  |    0.022520     |   2\n",
      "      25271 |   0.143152  |    0.093697     |   0\n",
      "      25272 |   0.168755  |    0.224793     |   1\n",
      "      25273 |   0.197572  |    0.012377     |   0\n",
      "      25274 |   0.126504  |    0.098784     |   0\n",
      "      25275 |   0.145233  |    0.012463     |   0\n",
      "      25276 | \u001b[94m  0.000017\u001b[0m  |    0.083656     |   2\n",
      "      25277 |   0.005509  |    0.062950     |   2\n",
      "      25278 |   0.190476  |    0.236409     |   1\n",
      "      25279 |   0.177454  |    0.059825     |   0\n",
      "      25280 |   0.133420  |    0.223151     |   1\n",
      "      25281 |   0.139930  |    0.282261     |   1\n",
      "      25282 |   0.194344  |    0.163887     |   1\n",
      "      25283 |   0.198521  |    0.008238     |   0\n",
      "      25284 |   0.268179  |    0.086997     |   0\n",
      "      25285 |   0.262567  |    0.172725     |   1\n",
      "      25286 |   0.057829  |    0.098564     |   2\n",
      "      25287 |   0.159750  |    0.261268     |   1\n",
      "      25288 |   0.161836  |    0.013272     |   0\n",
      "      25289 |   0.033942  |    0.085393     |   2\n",
      "      25290 |   0.193690  |    0.065865     |   0\n",
      "      25291 |   0.188334  |    0.044427     |   0\n",
      "      25292 |   0.200841  |    0.292666     |   1\n",
      "      25293 |   0.167028  |    0.013239     |   0\n",
      "      25294 |   0.183877  |    0.073284     |   0\n",
      "      25295 |   0.171990  |    0.240174     |   1\n",
      "      25296 |   0.051724  |    0.136262     |   2\n",
      "      25297 |   0.155268  |    0.483481     |   1\n",
      "      25298 |   0.040127  |    0.131298     |   2\n",
      "      25299 |   0.014375  |    0.079586     |   2\n",
      "      25300 |   0.033325  |    0.182205     |   2\n",
      "      25301 |   0.210938  |    0.299770     |   1\n",
      "      25302 |   0.205084  |    0.038436     |   0\n",
      "      25303 |   0.138925  |    0.115061     |   0\n",
      "      25304 |   0.188838  |    0.296184     |   1\n",
      "      25305 |   0.212029  |    0.069612     |   0\n",
      "      25306 |   0.209403  |    0.248338     |   1\n",
      "      25307 |   0.180603  |    0.004240     |   0\n",
      "      25308 |   0.025518  |    0.155541     |   2\n",
      "      25309 |   0.199255  |    0.003386     |   0\n",
      "      25310 |   0.177808  |    0.290817     |   1\n",
      "      25311 |   0.154529  |    0.102621     |   0\n",
      "      25312 |   0.000017  |    0.098937     |   2\n",
      "      25313 |   0.000017  |    0.078448     |   2\n",
      "      25314 |   0.180955  |    0.278516     |   1\n",
      "      25315 |   0.144165  |    0.011675     |   0\n",
      "      25316 |   0.232355  |    0.188836     |   1\n",
      "      25317 |   0.150272  |    0.046245     |   0\n",
      "      25318 |   0.185091  |    0.076345     |   0\n",
      "      25319 |   0.000017  |    0.098845     |   2\n",
      "      25320 |   0.000017  |    0.118156     |   2\n",
      "      25321 |   0.000017  |    0.117793     |   2\n",
      "      25322 |   0.153794  |    0.150636     |   0\n",
      "      25323 |   0.000017  |    0.004043     |   2\n",
      "      25324 |   0.224962  |    0.135981     |   0\n",
      "      25325 |   0.233425  |    0.269833     |   1\n",
      "      25326 |   0.044174  |    0.155659     |   2\n",
      "      25327 |   0.137497  |    0.181163     |   1\n",
      "      25328 |   0.047307  |    0.067965     |   2\n",
      "      25329 |   0.198557  |    0.263818     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 25330: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      25330 |   0.166002  |    0.198155     |   1\n",
      "      25331 |   0.045606  |    0.033245     |   2\n",
      "      25332 |   0.169856  |    0.296751     |   1\n",
      "      25333 |   0.033641  |    0.092034     |   2\n",
      "      25334 |   0.166074  |    0.057927     |   0\n",
      "      25335 |   0.152784  |    0.108491     |   0\n",
      "      25336 |   0.176751  |    0.182843     |   1\n",
      "      25337 |   0.037870  |    0.088799     |   2\n",
      "      25338 |   0.038857  |    0.143401     |   2\n",
      "      25339 |   0.169501  |    0.287674     |   1\n",
      "      25340 |   0.025417  |    0.086484     |   2\n",
      "      25341 |   0.033474  |    0.025286     |   2\n",
      "      25342 |   0.126008  |    0.073563     |   0\n",
      "      25343 |   0.045182  |    0.131124     |   2\n",
      "      25344 |   0.178267  |    0.071535     |   0\n",
      "      25345 |   0.049971  |    0.080962     |   2\n",
      "      25346 |   0.040171  |    0.056113     |   2\n",
      "      25347 |   0.237618  |    0.247229     |   1\n",
      "      25348 |   0.165805  |    0.075905     |   0\n",
      "      25349 |   0.192396  |    0.282477     |   1\n",
      "      25350 |   0.170975  |    0.139271     |   1\n",
      "      25351 |   0.116258  |    0.032929     |   0\n",
      "      25352 |   0.199088  |    0.282165     |   1\n",
      "      25353 |   0.172989  |    0.057090     |   0\n",
      "      25354 |   0.020333  |    0.106868     |   2\n",
      "      25355 |   0.155399  |    0.153356     |   0\n",
      "      25356 |   0.000017  |    0.158841     |   2\n",
      "      25357 |   0.174752  |    0.035409     |   0\n",
      "      25358 |   0.174209  |    0.294998     |   1\n",
      "      25359 |   0.222101  |    0.118214     |   0\n",
      "      25360 |   0.209196  |    0.259241     |   1\n",
      "      25361 |   0.143355  |    0.192860     |   0\n",
      "      25362 |   0.130964  |    0.115815     |   0\n",
      "      25363 |   0.229085  |    0.295769     |   1\n",
      "      25364 |   0.004624  |    0.130379     |   2\n",
      "      25365 |   0.059341  |    0.061439     |   2\n",
      "      25366 |   0.033896  |    0.082298     |   2\n",
      "      25367 |   0.154689  |    0.336203     |   1\n",
      "      25368 |   0.191511  |    0.011346     |   0\n",
      "      25369 |   0.054903  |    0.089638     |   2\n",
      "      25370 |   0.149897  |    0.151799     |   0\n",
      "      25371 |   0.172521  |    0.007751     |   0\n",
      "      25372 |   0.039247  |    0.087483     |   2\n",
      "      25373 |   0.253486  |    0.203368     |   1\n",
      "      25374 |   0.202018  |    0.240783     |   1\n",
      "      25375 |   0.148012  |    0.043168     |   0\n",
      "      25376 |   0.167916  |    0.073512     |   0\n",
      "      25377 |   0.013946  |    0.067333     |   2\n",
      "      25378 |   0.032305  |    0.066360     |   2\n",
      "      25379 |   0.216298  |    0.182496     |   1\n",
      "      25380 |   0.175041  |    0.311208     |   1\n",
      "      25381 |   0.024973  |    0.008719     |   2\n",
      "      25382 |   0.224472  |    0.274479     |   1\n",
      "      25383 |   0.218547  |    0.183323     |   1\n",
      "      25384 |   0.000018  |    0.069685     |   2\n",
      "      25385 |   0.000018  |    0.120239     |   2\n",
      "      25386 |   0.187478  |    0.023299     |   0\n",
      "      25387 |   0.158685  |    0.236579     |   1\n",
      "      25388 |   0.179638  |    0.191382     |   1\n",
      "      25389 |   0.150500  |    0.226690     |   1\n",
      "      25390 |   0.204922  |    0.097344     |   0\n",
      "      25391 |   0.189619  |    0.222023     |   1\n",
      "      25392 |   0.204602  |    0.003546     |   0\n",
      "      25393 |   0.121221  |    0.258757     |   1\n",
      "      25394 |   0.000018  |    0.038120     |   2\n",
      "      25395 |   0.177146  |    0.240940     |   1\n",
      "      25396 |   0.000018  |    0.047177     |   2\n",
      "      25397 |   0.217717  |    0.230945     |   1\n",
      "      25398 |   0.222136  |    0.152352     |   1\n",
      "      25399 |   0.187123  |    0.239712     |   1\n",
      "      25400 |   0.177270  |    0.044372     |   0\n",
      "      25401 |   0.227866  |    0.222044     |   1\n",
      "      25402 |   0.000017  |    0.038786     |   2\n",
      "      25403 |   0.142469  |    0.118955     |   0\n",
      "      25404 |   0.226806  |    0.052654     |   0\n",
      "      25405 |   0.000017  |    0.034038     |   2\n",
      "      25406 |   0.201502  |    0.267866     |   1\n",
      "      25407 |   0.039850  |    0.068791     |   2\n",
      "      25408 |   0.126479  |    0.170811     |   1\n",
      "      25409 |   0.045875  |    0.024135     |   2\n",
      "      25410 |   0.128113  |    0.293067     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 25411: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      25411 |   0.152021  |    0.017433     |   0\n",
      "      25412 |   0.187165  |    0.126925     |   0\n",
      "      25413 |   0.199335  |    0.199325     |   1\n",
      "      25414 |   0.043136  |    0.022364     |   2\n",
      "      25415 |   0.194124  |    0.218758     |   1\n",
      "      25416 |   0.123879  |    0.070996     |   0\n",
      "      25417 |   0.220309  |    0.192718     |   1\n",
      "      25418 |   0.197310  |    0.031382     |   0\n",
      "      25419 |   0.033087  |    0.110497     |   2\n",
      "      25420 |   0.183986  |    0.210998     |   1\n",
      "      25421 |   0.224018  |    0.203502     |   1\n",
      "      25422 |   0.153820  |    0.070369     |   0\n",
      "      25423 |   0.164071  |    0.247499     |   1\n",
      "      25424 |   0.152311  |    0.235161     |   1\n",
      "      25425 |   0.035500  |    0.025325     |   2\n",
      "      25426 |   0.211471  |    0.236406     |   1\n",
      "      25427 |   0.036616  |    0.005624     |   2\n",
      "      25428 |   0.179553  |    0.100274     |   0\n",
      "      25429 |   0.177123  |    0.331512     |   1\n",
      "      25430 |   0.215332  |    0.176652     |   1\n",
      "      25431 |   0.142592  |    0.040837     |   0\n",
      "      25432 |   0.191287  |    0.057685     |   0\n",
      "      25433 |   0.206981  |    0.117326     |   0\n",
      "      25434 |   0.025382  |    0.051648     |   2\n",
      "      25435 |   0.035281  |    0.029587     |   2\n",
      "      25436 |   0.047464  |    0.112401     |   2\n",
      "      25437 |   0.049806  |    0.047132     |   2\n",
      "      25438 |   0.043178  |    0.042224     |   2\n",
      "      25439 |   0.154053  |    0.116013     |   0\n",
      "      25440 |   0.142344  |    0.204566     |   1\n",
      "      25441 |   0.021464  |    0.015047     |   2\n",
      "      25442 |   0.000017  |    0.094346     |   2\n",
      "      25443 |   0.198940  |    0.236146     |   1\n",
      "      25444 |   0.133895  |    0.262701     |   1\n",
      "      25445 |   0.187564  |    0.233904     |   1\n",
      "      25446 |   0.152876  |    0.006399     |   0\n",
      "      25447 |   0.267017  |    0.300102     |   1\n",
      "      25448 |   0.246774  |    0.195261     |   1\n",
      "      25449 |   0.193354  |    0.006593     |   0\n",
      "      25450 |   0.004758  |    0.137300     |   2\n",
      "      25451 |   0.135345  |    0.217448     |   1\n",
      "      25452 |   0.058195  |    0.008667     |   2\n",
      "      25453 |   0.032906  |    0.103494     |   2\n",
      "      25454 |   0.214511  |    0.254072     |   1\n",
      "      25455 |   0.175025  |    0.171127     |   1\n",
      "      25456 |   0.179186  |    0.005282     |   0\n",
      "      25457 |   0.051292  |    0.067743     |   2\n",
      "      25458 |   0.037600  |    0.072622     |   2\n",
      "      25459 |   0.171873  |    0.152604     |   1\n",
      "      25460 |   0.175278  |    0.089820     |   0\n",
      "      25461 |   0.014223  |    0.073244     |   2\n",
      "      25462 |   0.235319  |    0.168630     |   1\n",
      "      25463 |   0.173892  |    0.068441     |   0\n",
      "      25464 |   0.033080  |    0.081229     |   2\n",
      "      25465 |   0.139760  |    0.051598     |   0\n",
      "      25466 |   0.234303  |    0.074581     |   0\n",
      "      25467 |   0.132822  |    0.037128     |   0\n",
      "      25468 |   0.151981  |    0.156163     |   0\n",
      "      25469 |   0.168268  |    0.197852     |   1\n",
      "      25470 |   0.215377  |    0.150996     |   1\n",
      "      25471 |   0.160522  |    0.228764     |   1\n",
      "      25472 |   0.205075  |    0.197166     |   1\n",
      "      25473 |   0.169791  |    0.061136     |   0\n",
      "      25474 |   0.026816  |    0.099528     |   2\n",
      "      25475 |   0.000017  |    0.066464     |   2\n",
      "      25476 |   0.146896  |    0.216957     |   1\n",
      "      25477 |   0.000017  |    0.071367     |   2\n",
      "      25478 |   0.000017  |    0.052744     |   2\n",
      "      25479 |   0.197501  |    0.245200     |   1\n",
      "      25480 |   0.000017  |    0.011021     |   2\n",
      "      25481 |   0.157124  |    0.251185     |   1\n",
      "      25482 |   0.190849  |    0.097928     |   0\n",
      "      25483 |   0.191479  |    0.168232     |   1\n",
      "      25484 |   0.000017  |    0.056038     |   2\n",
      "      25485 |   0.212013  |    0.283851     |   1\n",
      "      25486 |   0.176084  |    0.212452     |   1\n",
      "      25487 |   0.166739  |    0.017596     |   0\n",
      "      25488 |   0.130828  |    0.263979     |   1\n",
      "      25489 |   0.150343  |    0.034837     |   0\n",
      "      25490 |   0.159092  |    0.122312     |   0\n",
      "      25491 |   0.224583  |    0.038418     |   0\n",
      "      25492 | \u001b[94m  0.000017\u001b[0m  |    0.069353     |   2\n",
      "      25493 |   0.042827  |    0.025413     |   2\n",
      "      25494 |   0.181335  |    0.318446     |   1\n",
      "      25495 |   0.208755  |    0.210334     |   1\n",
      "      25496 |   0.045787  |    0.063679     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 25497: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      25497 |   0.145700  |    0.232085     |   1\n",
      "      25498 |   0.171925  |    0.214318     |   1\n",
      "      25499 |   0.045972  |    0.046966     |   2\n",
      "      25500 |   0.152421  |    0.091449     |   0\n",
      "      25501 |   0.186003  |    0.326647     |   1\n",
      "      25502 |   0.152940  |    0.253094     |   1\n",
      "      25503 |   0.045032  |    0.039460     |   2\n",
      "      25504 |   0.125330  |    0.127508     |   0\n",
      "      25505 |   0.174707  |    0.044790     |   0\n",
      "      25506 |   0.032431  |    0.075743     |   2\n",
      "      25507 |   0.185170  |    0.229667     |   1\n",
      "      25508 |   0.149748  |    0.026688     |   0\n",
      "      25509 |   0.129066  |    0.040743     |   0\n",
      "      25510 |   0.199439  |    0.074597     |   0\n",
      "      25511 |   0.035875  |    0.069325     |   2\n",
      "      25512 |   0.034529  |    0.130220     |   2\n",
      "      25513 |   0.025023  |    0.021598     |   2\n",
      "      25514 |   0.181032  |    0.094584     |   0\n",
      "      25515 |   0.033243  |    0.030424     |   2\n",
      "      25516 |   0.045445  |    0.132997     |   2\n",
      "      25517 |   0.182157  |    0.021657     |   0\n",
      "      25518 |   0.122933  |    0.374784     |   1\n",
      "      25519 |   0.236988  |    0.095520     |   0\n",
      "      25520 |   0.159710  |    0.380989     |   1\n",
      "      25521 |   0.180416  |    0.111223     |   0\n",
      "      25522 |   0.050594  |    0.053238     |   2\n",
      "      25523 |   0.150125  |    0.354526     |   1\n",
      "      25524 |   0.045530  |    0.077796     |   2\n",
      "      25525 |   0.020035  |    0.133752     |   2\n",
      "      25526 |   0.216540  |    0.250456     |   1\n",
      "      25527 | \u001b[94m  0.000017\u001b[0m  |    0.116963     |   2\n",
      "      25528 |   0.004613  |    0.053080     |   2\n",
      "      25529 |   0.173785  |    0.129316     |   0\n",
      "      25530 |   0.058208  |    0.103911     |   2\n",
      "      25531 |   0.216593  |    0.235890     |   1\n",
      "      25532 |   0.174966  |    0.080584     |   0\n",
      "      25533 |   0.033522  |    0.119140     |   2\n",
      "      25534 |   0.183511  |    0.322739     |   1\n",
      "      25535 |   0.156284  |    0.092590     |   0\n",
      "      25536 |   0.057829  |    0.039568     |   2\n",
      "      25537 |   0.177292  |    0.274109     |   1\n",
      "      25538 |   0.150397  |    0.339388     |   1\n",
      "      25539 |   0.140591  |    0.291356     |   1\n",
      "      25540 |   0.149174  |    0.362859     |   1\n",
      "      25541 |   0.039810  |    0.036615     |   2\n",
      "      25542 |   0.014669  |    0.142678     |   2\n",
      "      25543 |   0.206510  |    0.276357     |   1\n",
      "      25544 |   0.165054  |    0.244012     |   1\n",
      "      25545 |   0.031217  |    0.145956     |   2\n",
      "      25546 |   0.189488  |    0.004427     |   0\n",
      "      25547 |   0.023965  |    0.095399     |   2\n",
      "      25548 |   0.179161  |    0.315108     |   1\n",
      "      25549 |   0.159844  |    0.238670     |   1\n",
      "      25550 |   0.000017  |    0.029929     |   2\n",
      "      25551 |   0.000017  |    0.067690     |   2\n",
      "      25552 |   0.000017  |    0.066896     |   2\n",
      "      25553 |   0.000017  |    0.045782     |   2\n",
      "      25554 |   0.000017  |    0.038422     |   2\n",
      "      25555 |   0.000017  |    0.167857     |   2\n",
      "      25556 |   0.152296  |    0.218793     |   1\n",
      "      25557 |   0.161281  |    0.149391     |   0\n",
      "      25558 |   0.165447  |    0.036512     |   0\n",
      "      25559 |   0.189363  |    0.305422     |   1\n",
      "      25560 |   0.042898  |    0.160398     |   2\n",
      "      25561 |   0.212685  |    0.085130     |   0\n",
      "      25562 |   0.128540  |    0.091008     |   0\n",
      "      25563 |   0.179965  |    0.288354     |   1\n",
      "      25564 |   0.164923  |    0.135663     |   0\n",
      "      25565 |   0.044938  |    0.054841     |   2\n",
      "      25566 |   0.176398  |    0.333850     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 25567: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      25567 |   0.244773  |    0.352652     |   1\n",
      "      25568 |   0.141711  |    0.360785     |   1\n",
      "      25569 |   0.242617  |    0.287613     |   1\n",
      "      25570 |   0.040622  |    0.087405     |   2\n",
      "      25571 |   0.215725  |    0.387666     |   1\n",
      "      25572 |   0.134812  |    0.032561     |   0\n",
      "      25573 |   0.208258  |    0.430063     |   1\n",
      "      25574 |   0.203581  |    0.434765     |   1\n",
      "      25575 |   0.179170  |    0.022274     |   0\n",
      "      25576 |   0.191621  |    0.452145     |   1\n",
      "      25577 |   0.195131  |    0.247360     |   1\n",
      "      25578 |   0.171125  |    0.087851     |   0\n",
      "      25579 |   0.168399  |    0.327259     |   1\n",
      "      25580 |   0.199158  |    0.240620     |   1\n",
      "      25581 |   0.168481  |    0.345871     |   1\n",
      "      25582 |   0.172437  |    0.165502     |   1\n",
      "      25583 |   0.175310  |    0.172651     |   1\n",
      "      25584 |   0.183832  |    0.241685     |   1\n",
      "      25585 |   0.154358  |    0.024433     |   0\n",
      "      25586 |   0.028558  |    0.073205     |   2\n",
      "      25587 |   0.206089  |    0.062787     |   0\n",
      "      25588 |   0.179501  |    0.066288     |   0\n",
      "      25589 |   0.034130  |    0.134068     |   2\n",
      "      25590 |   0.176651  |    0.176958     |   1\n",
      "      25591 |   0.185878  |    0.215455     |   1\n",
      "      25592 |   0.140404  |    0.213841     |   1\n",
      "      25593 |   0.034882  |    0.003788     |   2\n",
      "      25594 |   0.025055  |    0.092256     |   2\n",
      "      25595 |   0.213331  |    0.047569     |   0\n",
      "      25596 |   0.183267  |    0.161259     |   1\n",
      "      25597 |   0.147894  |    0.058330     |   0\n",
      "      25598 |   0.237018  |    0.231990     |   1\n",
      "      25599 |   0.216697  |    0.242830     |   1\n",
      "      25600 |   0.206257  |    0.161513     |   1\n",
      "      25601 |   0.213439  |    0.093781     |   0\n",
      "      25602 |   0.034167  |    0.019334     |   2\n",
      "      25603 |   0.041891  |    0.091441     |   2\n",
      "      25604 |   0.049657  |    0.088489     |   2\n",
      "      25605 |   0.228021  |    0.268487     |   1\n",
      "      25606 |   0.177070  |    0.004910     |   0\n",
      "      25607 |   0.041281  |    0.021379     |   2\n",
      "      25608 |   0.147264  |    0.073575     |   0\n",
      "      25609 |   0.180605  |    0.232684     |   1\n",
      "      25610 |   0.200833  |    0.094176     |   0\n",
      "      25611 |   0.018393  |    0.015391     |   2\n",
      "      25612 |   0.189069  |    0.091068     |   0\n",
      "      25613 | \u001b[94m  0.000017\u001b[0m  |    0.039172     |   2\n",
      "      25614 |   0.004968  |    0.107838     |   2\n",
      "      25615 |   0.057681  |    0.028082     |   2\n",
      "      25616 |   0.032170  |    0.063258     |   2\n",
      "      25617 |   0.143576  |    0.064931     |   0\n",
      "      25618 |   0.194575  |    0.072603     |   0\n",
      "      25619 |   0.198832  |    0.072838     |   0\n",
      "      25620 |   0.194427  |    0.060731     |   0\n",
      "      25621 |   0.057565  |    0.040413     |   2\n",
      "      25622 |   0.151925  |    0.071885     |   0\n",
      "      25623 |   0.040377  |    0.096072     |   2\n",
      "      25624 |   0.015525  |    0.005610     |   2\n",
      "      25625 |   0.036240  |    0.065201     |   2\n",
      "      25626 |   0.025778  |    0.070986     |   2\n",
      "      25627 | \u001b[94m  0.000016\u001b[0m  |    0.068896     |   2\n",
      "      25628 |   0.149616  |    0.229490     |   1\n",
      "      25629 |   0.192511  |    0.015541     |   0\n",
      "      25630 |   0.250340  |    0.253130     |   1\n",
      "      25631 |   0.206207  |    0.228885     |   1\n",
      "      25632 |   0.166687  |    0.010030     |   0\n",
      "      25633 |   0.174542  |    0.090464     |   0\n",
      "      25634 |   0.000016  |    0.023859     |   2\n",
      "      25635 |   0.162833  |    0.078474     |   0\n",
      "      25636 |   0.267902  |    0.222299     |   1\n",
      "      25637 |   0.194574  |    0.225232     |   1\n",
      "      25638 |   0.000016  |    0.014721     |   2\n",
      "      25639 |   0.215437  |    0.273484     |   1\n",
      "      25640 |   0.154270  |    0.043402     |   0\n",
      "      25641 |   0.000017  |    0.103172     |   2\n",
      "      25642 |   0.178066  |    0.204801     |   1\n",
      "      25643 |   0.000017  |    0.072522     |   2\n",
      "      25644 |   0.147714  |    0.245661     |   1\n",
      "      25645 |   0.189911  |    0.177419     |   1\n",
      "      25646 |   0.133783  |    0.020401     |   0\n",
      "      25647 |   0.142207  |    0.056079     |   0\n",
      "      25648 |   0.217605  |    0.075095     |   0\n",
      "      25649 |   0.158121  |    0.021591     |   0\n",
      "      25650 |   0.134825  |    0.047673     |   0\n",
      "      25651 |   0.180651  |    0.111949     |   0\n",
      "      25652 |   0.176098  |    0.199046     |   1\n",
      "      25653 |   0.152617  |    0.215678     |   1\n",
      "      25654 |   0.197137  |    0.072604     |   0\n",
      "      25655 |   0.197685  |    0.242586     |   1\n",
      "      25656 |   0.000017  |    0.041714     |   2\n",
      "      25657 |   0.159799  |    0.073282     |   0\n",
      "      25658 |   0.200211  |    0.089297     |   0\n",
      "      25659 |   0.043035  |    0.082508     |   2\n",
      "      25660 |   0.167252  |    0.025912     |   0\n",
      "      25661 |   0.211392  |    0.117541     |   0\n",
      "      25662 |   0.164776  |    0.012531     |   0\n",
      "      25663 |   0.153992  |    0.248918     |   1\n",
      "      25664 |   0.046672  |    0.068737     |   2\n",
      "      25665 |   0.170732  |    0.229406     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 25666: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      25666 |   0.041703  |    0.027527     |   2\n",
      "      25667 |   0.210063  |    0.244904     |   1\n",
      "      25668 |   0.166577  |    0.231144     |   1\n",
      "      25669 |   0.238870  |    0.013511     |   0\n",
      "      25670 |   0.031065  |    0.066757     |   2\n",
      "      25671 |   0.158376  |    0.312646     |   1\n",
      "      25672 |   0.160887  |    0.199124     |   1\n",
      "      25673 |   0.035660  |    0.010077     |   2\n",
      "      25674 |   0.173131  |    0.080703     |   0\n",
      "      25675 |   0.035763  |    0.043852     |   2\n",
      "      25676 |   0.220008  |    0.267604     |   1\n",
      "      25677 |   0.201403  |    0.013467     |   0\n",
      "      25678 |   0.164953  |    0.092642     |   0\n",
      "      25679 |   0.026111  |    0.052920     |   2\n",
      "      25680 |   0.200488  |    0.219406     |   1\n",
      "      25681 |   0.034454  |    0.070186     |   2\n",
      "      25682 |   0.169915  |    0.025573     |   0\n",
      "      25683 |   0.162553  |    0.100914     |   0\n",
      "      25684 |   0.159816  |    0.033149     |   0\n",
      "      25685 |   0.163777  |    0.051242     |   0\n",
      "      25686 |   0.157678  |    0.261702     |   1\n",
      "      25687 |   0.185743  |    0.229848     |   1\n",
      "      25688 |   0.208605  |    0.156620     |   1\n",
      "      25689 |   0.048372  |    0.065096     |   2\n",
      "      25690 |   0.051236  |    0.014126     |   2\n",
      "      25691 |   0.205026  |    0.120345     |   0\n",
      "      25692 |   0.040863  |    0.042696     |   2\n",
      "      25693 |   0.019549  |    0.051396     |   2\n",
      "      25694 |   0.177909  |    0.045477     |   0\n",
      "      25695 |   0.252967  |    0.254142     |   1\n",
      "      25696 |   0.137294  |    0.004677     |   0\n",
      "      25697 |   0.180805  |    0.221292     |   1\n",
      "      25698 |   0.174445  |    0.079018     |   0\n",
      "      25699 |   0.000017  |    0.060358     |   2\n",
      "      25700 |   0.158161  |    0.286129     |   1\n",
      "      25701 |   0.223822  |    0.162734     |   1\n",
      "      25702 |   0.242482  |    0.185246     |   1\n",
      "      25703 |   0.004941  |    0.027172     |   2\n",
      "      25704 |   0.142377  |    0.118625     |   0\n",
      "      25705 |   0.057738  |    0.014943     |   2\n",
      "      25706 |   0.207832  |    0.255308     |   1\n",
      "      25707 |   0.184662  |    0.030419     |   0\n",
      "      25708 |   0.127369  |    0.221691     |   1\n",
      "      25709 |   0.187313  |    0.048127     |   0\n",
      "      25710 |   0.192983  |    0.199158     |   1\n",
      "      25711 |   0.031743  |    0.043296     |   2\n",
      "      25712 |   0.173354  |    0.129471     |   0\n",
      "      25713 |   0.160367  |    0.209354     |   1\n",
      "      25714 |   0.116215  |    0.052865     |   0\n",
      "      25715 |   0.133518  |    0.094188     |   0\n",
      "      25716 |   0.264470  |    0.223374     |   1\n",
      "      25717 |   0.185971  |    0.194454     |   1\n",
      "      25718 |   0.187031  |    0.234888     |   1\n",
      "      25719 |   0.124385  |    0.214529     |   1\n",
      "      25720 |   0.186543  |    0.046448     |   0\n",
      "      25721 |   0.214676  |    0.044925     |   0\n",
      "      25722 |   0.053955  |    0.112004     |   2\n",
      "      25723 |   0.175925  |    0.018030     |   0\n",
      "      25724 |   0.238193  |    0.253452     |   1\n",
      "      25725 |   0.191941  |    0.039504     |   0\n",
      "      25726 |   0.037388  |    0.073848     |   2\n",
      "      25727 |   0.014097  |    0.102835     |   2\n",
      "      25728 |   0.189693  |    0.223954     |   1\n",
      "      25729 |   0.031238  |    0.096541     |   2\n",
      "      25730 |   0.214311  |    0.065868     |   0\n",
      "      25731 |   0.165616  |    0.217477     |   1\n",
      "      25732 |   0.221314  |    0.072429     |   0\n",
      "      25733 |   0.180292  |    0.057375     |   0\n",
      "      25734 |   0.026616  |    0.060345     |   2\n",
      "      25735 |   0.149545  |    0.057434     |   0\n",
      "      25736 |   0.189430  |    0.269757     |   1\n",
      "      25737 |   0.000017  |    0.013013     |   2\n",
      "      25738 |   0.145514  |    0.126639     |   0\n",
      "      25739 |   0.208458  |    0.172413     |   1\n",
      "      25740 |   0.155123  |    0.064002     |   0\n",
      "      25741 |   0.204497  |    0.032083     |   0\n",
      "      25742 |   0.000017  |    0.059635     |   2\n",
      "      25743 |   0.000017  |    0.083209     |   2\n",
      "      25744 |   0.222560  |    0.240976     |   1\n",
      "      25745 |   0.000017  |    0.026071     |   2\n",
      "      25746 |   0.217096  |    0.227860     |   1\n",
      "      25747 |   0.196190  |    0.049018     |   0\n",
      "      25748 |   0.157177  |    0.039896     |   0\n",
      "      25749 |   0.285039  |    0.248296     |   1\n",
      "      25750 |   0.000017  |    0.013952     |   2\n",
      "      25751 |   0.000017  |    0.122483     |   2\n",
      "      25752 |   0.164343  |    0.025138     |   0\n",
      "      25753 |   0.040404  |    0.073258     |   2\n",
      "      25754 |   0.046529  |    0.037702     |   2\n",
      "      25755 |   0.219589  |    0.046495     |   0\n",
      "      25756 |   0.186022  |    0.063834     |   0\n",
      "      25757 |   0.218603  |    0.271104     |   1\n",
      "      25758 |   0.178869  |    0.042601     |   0\n",
      "      25759 |   0.239960  |    0.193103     |   1\n",
      "      25760 |   0.191961  |    0.039807     |   0\n",
      "      25761 |   0.193079  |    0.079650     |   0\n",
      "      25762 |   0.158070  |    0.064857     |   0\n",
      "      25763 |   0.188392  |    0.207324     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 25764: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      25764 |   0.202297  |    0.180344     |   1\n",
      "      25765 |   0.229064  |    0.081217     |   0\n",
      "      25766 |   0.184731  |    0.206143     |   1\n",
      "      25767 |   0.222127  |    0.085302     |   0\n",
      "      25768 |   0.193009  |    0.139911     |   1\n",
      "      25769 |   0.042154  |    0.106776     |   2\n",
      "      25770 |   0.158166  |    0.241833     |   1\n",
      "      25771 |   0.185495  |    0.134234     |   0\n",
      "      25772 |   0.200488  |    0.268282     |   1\n",
      "      25773 |   0.160118  |    0.172129     |   1\n",
      "      25774 |   0.031130  |    0.021525     |   2\n",
      "      25775 |   0.165962  |    0.064159     |   0\n",
      "      25776 |   0.212204  |    0.092125     |   0\n",
      "      25777 |   0.035449  |    0.044879     |   2\n",
      "      25778 |   0.036301  |    0.051044     |   2\n",
      "      25779 |   0.026182  |    0.077973     |   2\n",
      "      25780 |   0.188408  |    0.196588     |   1\n",
      "      25781 |   0.193314  |    0.019331     |   0\n",
      "      25782 |   0.169330  |    0.070910     |   0\n",
      "      25783 |   0.035729  |    0.094199     |   2\n",
      "      25784 |   0.046015  |    0.014234     |   2\n",
      "      25785 |   0.120560  |    0.078200     |   0\n",
      "      25786 |   0.151271  |    0.233098     |   1\n",
      "      25787 |   0.156047  |    0.280873     |   1\n",
      "      25788 |   0.047790  |    0.016159     |   2\n",
      "      25789 |   0.040277  |    0.133729     |   2\n",
      "      25790 |   0.166608  |    0.308763     |   1\n",
      "      25791 |   0.020429  |    0.146534     |   2\n",
      "      25792 |   0.226649  |    0.244833     |   1\n",
      "      25793 |   0.175179  |    0.122805     |   0\n",
      "      25794 |   0.000017  |    0.118201     |   2\n",
      "      25795 |   0.165399  |    0.315406     |   1\n",
      "      25796 |   0.149933  |    0.074469     |   0\n",
      "      25797 |   0.175911  |    0.378999     |   1\n",
      "      25798 |   0.114590  |    0.056754     |   0\n",
      "      25799 |   0.166145  |    0.150869     |   0\n",
      "      25800 |   0.004820  |    0.062757     |   2\n",
      "      25801 |   0.167601  |    0.257795     |   1\n",
      "      25802 |   0.178668  |    0.086369     |   0\n",
      "      25803 |   0.174411  |    0.108668     |   0\n",
      "      25804 |   0.057789  |    0.107346     |   2\n",
      "      25805 |   0.148002  |    0.015023     |   0\n",
      "      25806 |   0.119403  |    0.234161     |   1\n",
      "      25807 |   0.165379  |    0.063332     |   0\n",
      "      25808 |   0.210436  |    0.170798     |   1\n",
      "      25809 |   0.144590  |    0.299814     |   1\n",
      "      25810 |   0.190648  |    0.066385     |   0\n",
      "      25811 |   0.151598  |    0.272863     |   1\n",
      "      25812 |   0.127230  |    0.394726     |   1\n",
      "      25813 |   0.159830  |    0.097283     |   0\n",
      "      25814 |   0.222031  |    0.435056     |   1\n",
      "      25815 |   0.178340  |    0.037462     |   0\n",
      "      25816 |   0.033069  |    0.157454     |   2\n",
      "      25817 |   0.056431  |    0.043933     |   2\n",
      "      25818 |   0.037951  |    0.157110     |   2\n",
      "      25819 |   0.182839  |    0.041453     |   0\n",
      "      25820 |   0.134949  |    0.124524     |   0\n",
      "      25821 |   0.189940  |    0.135548     |   0\n",
      "      25822 |   0.018013  |    0.094643     |   2\n",
      "      25823 |   0.145337  |    0.461598     |   1\n",
      "      25824 |   0.034654  |    0.143964     |   2\n",
      "      25825 |   0.025618  |    0.061297     |   2\n",
      "      25826 |   0.153452  |    0.337442     |   1\n",
      "      25827 |   0.166730  |    0.376791     |   1\n",
      "      25828 |   0.183281  |    0.362424     |   1\n",
      "      25829 |   0.200622  |    0.349483     |   1\n",
      "      25830 |   0.000017  |    0.122851     |   2\n",
      "      25831 |   0.198750  |    0.061262     |   0\n",
      "      25832 |   0.000017  |    0.090693     |   2\n",
      "      25833 |   0.000017  |    0.127335     |   2\n",
      "      25834 |   0.177512  |    0.023419     |   0\n",
      "      25835 |   0.147995  |    0.085700     |   0\n",
      "      25836 |   0.175330  |    0.120792     |   0\n",
      "      25837 |   0.214025  |    0.344434     |   1\n",
      "      25838 |   0.218548  |    0.067794     |   0\n",
      "      25839 |   0.000017  |    0.147040     |   2\n",
      "      25840 |   0.171932  |    0.362806     |   1\n",
      "      25841 |   0.216229  |    0.068436     |   0\n",
      "      25842 |   0.166705  |    0.148790     |   0\n",
      "      25843 |   0.239518  |    0.303524     |   1\n",
      "      25844 |   0.183054  |    0.373517     |   1\n",
      "      25845 |   0.183395  |    0.159779     |   0\n",
      "      25846 |   0.182218  |    0.099850     |   0\n",
      "      25847 |   0.153388  |    0.083248     |   0\n",
      "      25848 |   0.000017  |    0.017714     |   2\n",
      "      25849 |   0.169089  |    0.100222     |   0\n",
      "      25850 |   0.185931  |    0.180468     |   1\n",
      "      25851 |   0.182059  |    0.381859     |   1\n",
      "      25852 |   0.000017  |    0.116843     |   2\n",
      "      25853 |   0.206026  |    0.086330     |   0\n",
      "      25854 |   0.203298  |    0.361287     |   1\n",
      "      25855 |   0.191012  |    0.541720     |   1\n",
      "      25856 |   0.198186  |    0.028537     |   0\n",
      "      25857 |   0.040489  |    0.157186     |   2\n",
      "      25858 |   0.164454  |    0.038753     |   0\n",
      "      25859 |   0.046687  |    0.084780     |   2\n",
      "      25860 |   0.181611  |    0.389361     |   1\n",
      "      25861 |   0.184746  |    0.363191     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 25862: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      25862 |   0.226641  |    0.373121     |   1\n",
      "      25863 |   0.216865  |    0.325292     |   1\n",
      "      25864 |   0.181185  |    0.081474     |   0\n",
      "      25865 |   0.155257  |    0.143122     |   0\n",
      "      25866 |   0.041282  |    0.084310     |   2\n",
      "      25867 |   0.191039  |    0.372119     |   1\n",
      "      25868 |   0.155831  |    0.336681     |   1\n",
      "      25869 |   0.181925  |    0.330874     |   1\n",
      "      25870 |   0.194002  |    0.144571     |   0\n",
      "      25871 |   0.207805  |    0.311108     |   1\n",
      "      25872 |   0.218618  |    0.378472     |   1\n",
      "      25873 |   0.159633  |    0.071502     |   0\n",
      "      25874 |   0.028149  |    0.129346     |   2\n",
      "      25875 |   0.212110  |    0.386504     |   1\n",
      "      25876 |   0.207758  |    0.104994     |   0\n",
      "      25877 |   0.162061  |    0.274129     |   1\n",
      "      25878 |   0.197399  |    0.042274     |   0\n",
      "      25879 |   0.184463  |    0.063473     |   0\n",
      "      25880 |   0.216912  |    0.223388     |   1\n",
      "      25881 |   0.035890  |    0.127304     |   2\n",
      "      25882 |   0.140760  |    0.009844     |   0\n",
      "      25883 |   0.108674  |    0.097183     |   0\n",
      "      25884 |   0.204037  |    0.050826     |   0\n",
      "      25885 |   0.157922  |    0.079822     |   0\n",
      "      25886 |   0.156226  |    0.267760     |   1\n",
      "      25887 |   0.189978  |    0.245651     |   1\n",
      "      25888 |   0.133477  |    0.184084     |   1\n",
      "      25889 |   0.156585  |    0.025259     |   0\n",
      "      25890 |   0.037261  |    0.088620     |   2\n",
      "      25891 |   0.185994  |    0.058692     |   0\n",
      "      25892 |   0.174252  |    0.239501     |   1\n",
      "      25893 |   0.137327  |    0.039866     |   0\n",
      "      25894 |   0.184729  |    0.022594     |   0\n",
      "      25895 |   0.025690  |    0.066323     |   2\n",
      "      25896 |   0.145942  |    0.098423     |   0\n",
      "      25897 |   0.139823  |    0.022148     |   0\n",
      "      25898 |   0.034899  |    0.094534     |   2\n",
      "      25899 |   0.050615  |    0.075215     |   2\n",
      "      25900 |   0.166799  |    0.226391     |   1\n",
      "      25901 |   0.225139  |    0.159505     |   1\n",
      "      25902 |   0.146267  |    0.019498     |   0\n",
      "      25903 |   0.206856  |    0.109748     |   0\n",
      "      25904 |   0.174858  |    0.046091     |   0\n",
      "      25905 |   0.272953  |    0.189265     |   1\n",
      "      25906 |   0.196782  |    0.210021     |   1\n",
      "      25907 |   0.156407  |    0.264874     |   1\n",
      "      25908 |   0.050495  |    0.007576     |   2\n",
      "      25909 |   0.166153  |    0.085267     |   0\n",
      "      25910 |   0.150500  |    0.073515     |   0\n",
      "      25911 |   0.041551  |    0.080515     |   2\n",
      "      25912 |   0.131433  |    0.028091     |   0\n",
      "      25913 |   0.102280  |    0.300884     |   1\n",
      "      25914 |   0.019915  |    0.013512     |   2\n",
      "      25915 |   0.198104  |    0.281575     |   1\n",
      "      25916 |   0.147526  |    0.192587     |   1\n",
      "      25917 |   0.199203  |    0.070408     |   0\n",
      "      25918 |   0.208623  |    0.192344     |   1\n",
      "      25919 |   0.000017  |    0.078318     |   2\n",
      "      25920 |   0.132125  |    0.023981     |   0\n",
      "      25921 |   0.005170  |    0.114841     |   2\n",
      "      25922 |   0.060711  |    0.013357     |   2\n",
      "      25923 |   0.034100  |    0.048056     |   2\n",
      "      25924 |   0.142695  |    0.072024     |   0\n",
      "      25925 |   0.164255  |    0.248024     |   1\n",
      "      25926 |   0.053930  |    0.013481     |   2\n",
      "      25927 |   0.188495  |    0.241930     |   1\n",
      "      25928 |   0.155755  |    0.198766     |   1\n",
      "      25929 |   0.172866  |    0.042630     |   0\n",
      "      25930 |   0.155642  |    0.043937     |   0\n",
      "      25931 |   0.237383  |    0.292018     |   1\n",
      "      25932 |   0.159122  |    0.211988     |   1\n",
      "      25933 |   0.154234  |    0.184752     |   1\n",
      "      25934 |   0.146090  |    0.028265     |   0\n",
      "      25935 |   0.188049  |    0.243104     |   1\n",
      "      25936 |   0.037352  |    0.019036     |   2\n",
      "      25937 |   0.148283  |    0.062581     |   0\n",
      "      25938 |   0.014537  |    0.096403     |   2\n",
      "      25939 |   0.034389  |    0.072194     |   2\n",
      "      25940 |   0.213241  |    0.232201     |   1\n",
      "      25941 |   0.173865  |    0.146204     |   1\n",
      "      25942 |   0.170443  |    0.032899     |   0\n",
      "      25943 |   0.023548  |    0.105742     |   2\n",
      "      25944 |   0.000017  |    0.013316     |   2\n",
      "      25945 |   0.183792  |    0.123617     |   0\n",
      "      25946 |   0.225797  |    0.044291     |   0\n",
      "      25947 |   0.000017  |    0.068097     |   2\n",
      "      25948 |   0.000017  |    0.056548     |   2\n",
      "      25949 |   0.166100  |    0.070955     |   0\n",
      "      25950 |   0.197880  |    0.213264     |   1\n",
      "      25951 |   0.178956  |    0.065989     |   0\n",
      "      25952 |   0.173363  |    0.306717     |   1\n",
      "      25953 |   0.154110  |    0.172744     |   1\n",
      "      25954 |   0.140932  |    0.086817     |   0\n",
      "      25955 |   0.200440  |    0.165956     |   1\n",
      "      25956 |   0.000017  |    0.072893     |   2\n",
      "      25957 |   0.177611  |    0.238892     |   1\n",
      "      25958 |   0.240012  |    0.215528     |   1\n",
      "      25959 |   0.000017  |    0.012617     |   2\n",
      "      25960 |   0.177471  |    0.237526     |   1\n",
      "      25961 |   0.201656  |    0.179305     |   1\n",
      "      25962 |   0.148740  |    0.244834     |   1\n",
      "      25963 |   0.000017  |    0.017231     |   2\n",
      "      25964 |   0.184336  |    0.271429     |   1\n",
      "      25965 |   0.249502  |    0.233828     |   1\n",
      "      25966 |   0.209249  |    0.036424     |   0\n",
      "      25967 |   0.163510  |    0.243098     |   1\n",
      "      25968 |   0.039047  |    0.055658     |   2\n",
      "      25969 |   0.219689  |    0.258266     |   1\n",
      "      25970 |   0.143730  |    0.171851     |   1\n",
      "      25971 |   0.169135  |    0.022872     |   0\n",
      "      25972 |   0.046242  |    0.116707     |   2\n",
      "      25973 |   0.169255  |    0.270922     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 25974: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      25974 |   0.222059  |    0.015011     |   0\n",
      "      25975 |   0.242996  |    0.293898     |   1\n",
      "      25976 |   0.171537  |    0.026267     |   0\n",
      "      25977 |   0.041619  |    0.047409     |   2\n",
      "      25978 |   0.260881  |    0.094778     |   0\n",
      "      25979 |   0.226960  |    0.241923     |   1\n",
      "      25980 |   0.115687  |    0.067357     |   0\n",
      "      25981 |   0.150141  |    0.209221     |   1\n",
      "      25982 |   0.166346  |    0.028448     |   0\n",
      "      25983 |   0.030455  |    0.115929     |   2\n",
      "      25984 |   0.158909  |    0.060943     |   0\n",
      "      25985 |   0.195971  |    0.209849     |   1\n",
      "      25986 |   0.196575  |    0.204796     |   1\n",
      "      25987 |   0.153894  |    0.229743     |   1\n",
      "      25988 |   0.035512  |    0.035717     |   2\n",
      "      25989 |   0.243388  |    0.095186     |   0\n",
      "      25990 |   0.220860  |    0.108918     |   0\n",
      "      25991 |   0.036456  |    0.013549     |   2\n",
      "      25992 |   0.208942  |    0.271875     |   1\n",
      "      25993 |   0.026110  |    0.053283     |   2\n",
      "      25994 |   0.162346  |    0.261235     |   1\n",
      "      25995 |   0.036535  |    0.050740     |   2\n",
      "      25996 |   0.139999  |    0.318475     |   1\n",
      "      25997 |   0.146726  |    0.202080     |   1\n",
      "      25998 |   0.153955  |    0.219600     |   1\n",
      "      25999 |   0.155058  |    0.006848     |   0\n",
      "      26000 |   0.044891  |    0.093154     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 26000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 26000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      26001 |   0.040031  |    0.156674     |   2\n",
      "      26002 |   0.190334  |    0.004541     |   0\n",
      "      26003 |   0.028703  |    0.065831     |   2\n",
      "      26004 |   0.215338  |    0.052713     |   0\n",
      "      26005 |   0.034815  |    0.087257     |   2\n",
      "      26006 |   0.199575  |    0.046252     |   0\n",
      "      26007 |   0.035291  |    0.103015     |   2\n",
      "      26008 |   0.196821  |    0.176715     |   1\n",
      "      26009 |   0.025017  |    0.046274     |   2\n",
      "      26010 |   0.279807  |    0.204626     |   1\n",
      "      26011 |   0.177464  |    0.194244     |   1\n",
      "      26012 |   0.211186  |    0.290452     |   1\n",
      "      26013 |   0.165644  |    0.279180     |   1\n",
      "      26014 |   0.171779  |    0.009898     |   0\n",
      "      26015 |   0.035963  |    0.118450     |   2\n",
      "      26016 |   0.217213  |    0.042336     |   0\n",
      "      26017 |   0.041931  |    0.071330     |   2\n",
      "      26018 |   0.179816  |    0.275175     |   1\n",
      "      26019 |   0.047376  |    0.005854     |   2\n",
      "      26020 |   0.042097  |    0.082119     |   2\n",
      "      26021 |   0.168950  |    0.195128     |   1\n",
      "      26022 |   0.209586  |    0.241651     |   1\n",
      "      26023 |   0.187763  |    0.023980     |   0\n",
      "      26024 |   0.233168  |    0.281055     |   1\n",
      "      26025 |   0.184012  |    0.174183     |   1\n",
      "      26026 |   0.021515  |    0.063781     |   2\n",
      "      26027 |   0.202877  |    0.190655     |   1\n",
      "      26028 |   0.000017  |    0.105094     |   2\n",
      "      26029 |   0.005817  |    0.015592     |   2\n",
      "      26030 |   0.208971  |    0.276212     |   1\n",
      "      26031 |   0.057381  |    0.067156     |   2\n",
      "      26032 |   0.221206  |    0.179329     |   1\n",
      "      26033 |   0.031455  |    0.080962     |   2\n",
      "      26034 |   0.223534  |    0.272264     |   1\n",
      "      26035 |   0.165746  |    0.172412     |   1\n",
      "      26036 |   0.163113  |    0.229548     |   1\n",
      "      26037 |   0.149089  |    0.066763     |   0\n",
      "      26038 |   0.055174  |    0.058014     |   2\n",
      "      26039 |   0.152022  |    0.024528     |   0\n",
      "      26040 |   0.035866  |    0.114447     |   2\n",
      "      26041 |   0.014781  |    0.025602     |   2\n",
      "      26042 |   0.030979  |    0.080791     |   2\n",
      "      26043 |   0.191665  |    0.244503     |   1\n",
      "      26044 |   0.155815  |    0.224740     |   1\n",
      "      26045 |   0.027316  |    0.076896     |   2\n",
      "      26046 |   0.216568  |    0.157454     |   1\n",
      "      26047 |   0.175586  |    0.073890     |   0\n",
      "      26048 |   0.226245  |    0.041723     |   0\n",
      "      26049 |   0.199800  |    0.043938     |   0\n",
      "      26050 |   0.237120  |    0.104988     |   0\n",
      "      26051 |   0.000017  |    0.019248     |   2\n",
      "      26052 |   0.000017  |    0.075356     |   2\n",
      "      26053 |   0.000017  |    0.076279     |   2\n",
      "      26054 |   0.000017  |    0.074570     |   2\n",
      "      26055 |   0.159623  |    0.225237     |   1\n",
      "      26056 |   0.000017  |    0.068861     |   2\n",
      "      26057 |   0.207281  |    0.216834     |   1\n",
      "      26058 |   0.214800  |    0.212717     |   1\n",
      "      26059 |   0.180509  |    0.058684     |   0\n",
      "      26060 |   0.000017  |    0.040406     |   2\n",
      "      26061 |   0.043781  |    0.075899     |   2\n",
      "      26062 |   0.047048  |    0.043373     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 26063: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      26063 |   0.202602  |    0.107789     |   0\n",
      "      26064 |   0.177281  |    0.176920     |   1\n",
      "      26065 |   0.201721  |    0.212768     |   1\n",
      "      26066 |   0.170487  |    0.056157     |   0\n",
      "      26067 |   0.182306  |    0.089641     |   0\n",
      "      26068 |   0.142921  |    0.044077     |   0\n",
      "      26069 |   0.165841  |    0.092923     |   0\n",
      "      26070 |   0.040981  |    0.064241     |   2\n",
      "      26071 |   0.164859  |    0.039013     |   0\n",
      "      26072 |   0.190661  |    0.248569     |   1\n",
      "      26073 |   0.184376  |    0.087631     |   0\n",
      "      26074 |   0.028177  |    0.068617     |   2\n",
      "      26075 |   0.218825  |    0.076013     |   0\n",
      "      26076 |   0.035670  |    0.007328     |   2\n",
      "      26077 |   0.037136  |    0.090820     |   2\n",
      "      26078 |   0.024945  |    0.040889     |   2\n",
      "      26079 |   0.035627  |    0.049286     |   2\n",
      "      26080 |   0.202559  |    0.237627     |   1\n",
      "      26081 |   0.179236  |    0.006684     |   0\n",
      "      26082 |   0.047993  |    0.069486     |   2\n",
      "      26083 |   0.202875  |    0.073240     |   0\n",
      "      26084 |   0.121509  |    0.067350     |   0\n",
      "      26085 |   0.048472  |    0.061686     |   2\n",
      "      26086 |   0.038712  |    0.070389     |   2\n",
      "      26087 |   0.016625  |    0.070271     |   2\n",
      "      26088 |   0.196437  |    0.237168     |   1\n",
      "      26089 |   0.251356  |    0.223936     |   1\n",
      "      26090 |   0.188984  |    0.006552     |   0\n",
      "      26091 |   0.000017  |    0.094917     |   2\n",
      "      26092 |   0.177033  |    0.057567     |   0\n",
      "      26093 |   0.004636  |    0.067260     |   2\n",
      "      26094 |   0.059540  |    0.065591     |   2\n",
      "      26095 |   0.033318  |    0.044640     |   2\n",
      "      26096 |   0.056050  |    0.087276     |   2\n",
      "      26097 |   0.172152  |    0.202622     |   1\n",
      "      26098 |   0.036990  |    0.008699     |   2\n",
      "      26099 |   0.223986  |    0.092508     |   0\n",
      "      26100 |   0.212274  |    0.046692     |   0\n",
      "      26101 |   0.014586  |    0.093206     |   2\n",
      "      26102 |   0.155903  |    0.241656     |   1\n",
      "      26103 |   0.151942  |    0.078685     |   0\n",
      "      26104 |   0.181652  |    0.208022     |   1\n",
      "      26105 |   0.201710  |    0.232283     |   1\n",
      "      26106 |   0.163544  |    0.007718     |   0\n",
      "      26107 |   0.215283  |    0.116696     |   0\n",
      "      26108 |   0.033376  |    0.046709     |   2\n",
      "      26109 |   0.209728  |    0.248053     |   1\n",
      "      26110 |   0.026199  |    0.072496     |   2\n",
      "      26111 |   0.176638  |    0.166942     |   1\n",
      "      26112 |   0.000017  |    0.076941     |   2\n",
      "      26113 |   0.179548  |    0.042307     |   0\n",
      "      26114 |   0.150707  |    0.097808     |   0\n",
      "      26115 |   0.184566  |    0.226377     |   1\n",
      "      26116 |   0.000017  |    0.008584     |   2\n",
      "      26117 |   0.152447  |    0.252055     |   1\n",
      "      26118 |   0.150908  |    0.176261     |   1\n",
      "      26119 |   0.000017  |    0.033905     |   2\n",
      "      26120 |   0.168206  |    0.074773     |   0\n",
      "      26121 |   0.210767  |    0.043061     |   0\n",
      "      26122 |   0.181150  |    0.074589     |   0\n",
      "      26123 |   0.213350  |    0.115250     |   1\n",
      "      26124 |   0.192235  |    0.230785     |   1\n",
      "      26125 |   0.145257  |    0.062043     |   0\n",
      "      26126 |   0.183465  |    0.224358     |   1\n",
      "      26127 |   0.000017  |    0.058517     |   2\n",
      "      26128 |   0.151933  |    0.079208     |   0\n",
      "      26129 |   0.000016  |    0.051853     |   2\n",
      "      26130 |   0.194460  |    0.297350     |   1\n",
      "      26131 |   0.000016  |    0.034130     |   2\n",
      "      26132 |   0.232844  |    0.263723     |   1\n",
      "      26133 |   0.204691  |    0.008530     |   0\n",
      "      26134 |   0.040955  |    0.102863     |   2\n",
      "      26135 |   0.208398  |    0.201829     |   1\n",
      "      26136 |   0.149092  |    0.305838     |   1\n",
      "      26137 |   0.045153  |    0.006764     |   2\n",
      "      26138 |   0.149614  |    0.055169     |   0\n",
      "      26139 |   0.149780  |    0.077891     |   0\n",
      "      26140 |   0.177171  |    0.233242     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 26141: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      26141 |   0.215461  |    0.233704     |   1\n",
      "      26142 |   0.147345  |    0.219245     |   1\n",
      "      26143 |   0.176285  |    0.058526     |   0\n",
      "      26144 |   0.185280  |    0.179183     |   1\n",
      "      26145 |   0.039129  |    0.040113     |   2\n",
      "      26146 |   0.213878  |    0.098362     |   0\n",
      "      26147 |   0.028871  |    0.064972     |   2\n",
      "      26148 |   0.033745  |    0.038667     |   2\n",
      "      26149 |   0.213597  |    0.076585     |   0\n",
      "      26150 |   0.174990  |    0.041853     |   0\n",
      "      26151 |   0.175627  |    0.067417     |   0\n",
      "      26152 |   0.034056  |    0.068690     |   2\n",
      "      26153 |   0.168155  |    0.232993     |   1\n",
      "      26154 |   0.024970  |    0.087325     |   2\n",
      "      26155 |   0.034571  |    0.009277     |   2\n",
      "      26156 |   0.045493  |    0.096932     |   2\n",
      "      26157 |   0.049920  |    0.042079     |   2\n",
      "      26158 |   0.038876  |    0.076498     |   2\n",
      "      26159 |   0.020502  |    0.026891     |   2\n",
      "      26160 |   0.173289  |    0.114373     |   0\n",
      "      26161 |   0.219475  |    0.015723     |   0\n",
      "      26162 |   0.154498  |    0.281224     |   1\n",
      "      26163 |   0.204269  |    0.048777     |   0\n",
      "      26164 |   0.188162  |    0.057024     |   0\n",
      "      26165 |   0.181334  |    0.072456     |   0\n",
      "      26166 |   0.184588  |    0.175296     |   1\n",
      "      26167 |   0.000016  |    0.095575     |   2\n",
      "      26168 |   0.150388  |    0.015570     |   0\n",
      "      26169 |   0.229725  |    0.263595     |   1\n",
      "      26170 |   0.128846  |    0.009823     |   0\n",
      "      26171 |   0.004952  |    0.113381     |   2\n",
      "      26172 |   0.146553  |    0.272186     |   1\n",
      "      26173 |   0.215236  |    0.008582     |   0\n",
      "      26174 |   0.059479  |    0.110976     |   2\n",
      "      26175 |   0.150340  |    0.024694     |   0\n",
      "      26176 |   0.162562  |    0.256631     |   1\n",
      "      26177 |   0.213960  |    0.218899     |   1\n",
      "      26178 |   0.032081  |    0.007145     |   2\n",
      "      26179 |   0.167579  |    0.268918     |   1\n",
      "      26180 |   0.145277  |    0.249138     |   1\n",
      "      26181 |   0.191302  |    0.039034     |   0\n",
      "      26182 |   0.143218  |    0.087345     |   0\n",
      "      26183 |   0.054111  |    0.033435     |   2\n",
      "      26184 |   0.188255  |    0.243260     |   1\n",
      "      26185 |   0.144939  |    0.306655     |   1\n",
      "      26186 |   0.171642  |    0.039407     |   0\n",
      "      26187 |   0.039376  |    0.040022     |   2\n",
      "      26188 |   0.220949  |    0.109226     |   0\n",
      "      26189 |   0.144541  |    0.048943     |   0\n",
      "      26190 |   0.015944  |    0.086444     |   2\n",
      "      26191 |   0.136676  |    0.050879     |   0\n",
      "      26192 |   0.159211  |    0.038262     |   0\n",
      "      26193 |   0.184249  |    0.309864     |   1\n",
      "      26194 |   0.179289  |    0.010040     |   0\n",
      "      26195 |   0.216286  |    0.089462     |   0\n",
      "      26196 |   0.035252  |    0.072766     |   2\n",
      "      26197 |   0.195473  |    0.067290     |   0\n",
      "      26198 |   0.026936  |    0.029756     |   2\n",
      "      26199 |   0.164316  |    0.255908     |   1\n",
      "      26200 |   0.231809  |    0.260580     |   1\n",
      "      26201 |   0.201233  |    0.208814     |   1\n",
      "      26202 |   0.154373  |    0.221143     |   1\n",
      "      26203 |   0.000016  |    0.040498     |   2\n",
      "      26204 |   0.190811  |    0.261385     |   1\n",
      "      26205 |   0.200491  |    0.151206     |   1\n",
      "      26206 |   0.131827  |    0.209151     |   1\n",
      "      26207 |   0.126710  |    0.071778     |   0\n",
      "      26208 |   0.166053  |    0.205305     |   1\n",
      "      26209 |   0.237243  |    0.262658     |   1\n",
      "      26210 |   0.154947  |    0.011106     |   0\n",
      "      26211 |   0.190376  |    0.082260     |   0\n",
      "      26212 |   0.184444  |    0.090772     |   0\n",
      "      26213 |   0.000016  |    0.073878     |   2\n",
      "      26214 |   0.146778  |    0.266056     |   1\n",
      "      26215 |   0.000016  |    0.067025     |   2\n",
      "      26216 |   0.228969  |    0.251793     |   1\n",
      "      26217 |   0.182287  |    0.201884     |   1\n",
      "      26218 |   0.187716  |    0.236097     |   1\n",
      "      26219 |   0.163113  |    0.006079     |   0\n",
      "      26220 |   0.230936  |    0.089457     |   0\n",
      "      26221 |   0.000017  |    0.045173     |   2\n",
      "      26222 |   0.000016  |    0.014942     |   2\n",
      "      26223 |   0.000016  |    0.097621     |   2\n",
      "      26224 |   0.188402  |    0.251618     |   1\n",
      "      26225 |   0.039420  |    0.022537     |   2\n",
      "      26226 |   0.045617  |    0.108899     |   2\n",
      "      26227 |   0.196320  |    0.039324     |   0\n",
      "      26228 |   0.275763  |    0.164143     |   1\n",
      "      26229 |   0.112054  |    0.286285     |   1\n",
      "      26230 |   0.191167  |    0.250896     |   1\n",
      "      26231 |   0.181562  |    0.167420     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 26233: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      26232 |   0.213699  |    0.029745     |   0\n",
      "      26233 |   0.198949  |    0.076111     |   0\n",
      "      26234 |   0.209575  |    0.183227     |   1\n",
      "      26235 |   0.146166  |    0.243798     |   1\n",
      "      26236 |   0.042529  |    0.084015     |   2\n",
      "      26237 |   0.190501  |    0.210281     |   1\n",
      "      26238 |   0.166113  |    0.098418     |   0\n",
      "      26239 |   0.180314  |    0.221794     |   1\n",
      "      26240 |   0.169166  |    0.034588     |   0\n",
      "      26241 |   0.233662  |    0.218457     |   1\n",
      "      26242 |   0.195839  |    0.026097     |   0\n",
      "      26243 |   0.177582  |    0.076421     |   0\n",
      "      26244 |   0.029544  |    0.076984     |   2\n",
      "      26245 |   0.221939  |    0.236049     |   1\n",
      "      26246 |   0.135369  |    0.270600     |   1\n",
      "      26247 |   0.034472  |    0.006470     |   2\n",
      "      26248 |   0.036472  |    0.082519     |   2\n",
      "      26249 |   0.024772  |    0.064118     |   2\n",
      "      26250 |   0.033158  |    0.050078     |   2\n",
      "      26251 |   0.128517  |    0.009796     |   0\n",
      "      26252 |   0.166236  |    0.239044     |   1\n",
      "      26253 |   0.043167  |    0.068145     |   2\n",
      "      26254 |   0.170647  |    0.063098     |   0\n",
      "      26255 |   0.166907  |    0.256375     |   1\n",
      "      26256 |   0.166352  |    0.026426     |   0\n",
      "      26257 |   0.047909  |    0.109553     |   2\n",
      "      26258 |   0.157686  |    0.039606     |   0\n",
      "      26259 |   0.175558  |    0.102352     |   0\n",
      "      26260 |   0.041471  |    0.042788     |   2\n",
      "      26261 |   0.175213  |    0.087548     |   0\n",
      "      26262 |   0.188687  |    0.021903     |   0\n",
      "      26263 |   0.145355  |    0.051510     |   0\n",
      "      26264 |   0.020702  |    0.096151     |   2\n",
      "      26265 |   0.000016  |    0.027936     |   2\n",
      "      26266 |   0.146863  |    0.314066     |   1\n",
      "      26267 |   0.181377  |    0.194359     |   1\n",
      "      26268 |   0.004372  |    0.005499     |   2\n",
      "      26269 |   0.150061  |    0.076137     |   0\n",
      "      26270 |   0.182080  |    0.087458     |   0\n",
      "      26271 |   0.178436  |    0.038278     |   0\n",
      "      26272 |   0.229085  |    0.083261     |   0\n",
      "      26273 |   0.129061  |    0.216059     |   1\n",
      "      26274 |   0.190266  |    0.212657     |   1\n",
      "      26275 |   0.176951  |    0.164596     |   1\n",
      "      26276 |   0.257577  |    0.208543     |   1\n",
      "      26277 |   0.171213  |    0.083896     |   0\n",
      "      26278 |   0.131092  |    0.224866     |   1\n",
      "      26279 |   0.059697  |    0.048044     |   2\n",
      "      26280 |   0.166527  |    0.323062     |   1\n",
      "      26281 |   0.034239  |    0.003840     |   2\n",
      "      26282 |   0.138026  |    0.234138     |   1\n",
      "      26283 |   0.056781  |    0.013448     |   2\n",
      "      26284 |   0.038907  |    0.103674     |   2\n",
      "      26285 |   0.157530  |    0.214455     |   1\n",
      "      26286 |   0.205228  |    0.019647     |   0\n",
      "      26287 |   0.015649  |    0.099624     |   2\n",
      "      26288 |   0.208091  |    0.216703     |   1\n",
      "      26289 |   0.032488  |    0.025415     |   2\n",
      "      26290 |   0.225877  |    0.291720     |   1\n",
      "      26291 |   0.235724  |    0.009628     |   0\n",
      "      26292 |   0.025805  |    0.052622     |   2\n",
      "      26293 |   0.000016  |    0.071989     |   2\n",
      "      26294 |   0.199326  |    0.196063     |   1\n",
      "      26295 |   0.203269  |    0.269568     |   1\n",
      "      26296 |   0.000016  |    0.074333     |   2\n",
      "      26297 |   0.114261  |    0.236400     |   1\n",
      "      26298 |   0.197616  |    0.265404     |   1\n",
      "      26299 |   0.190863  |    0.251560     |   1\n",
      "      26300 |   0.000016  |    0.025665     |   2\n",
      "      26301 |   0.000017  |    0.079167     |   2\n",
      "      26302 |   0.172939  |    0.075155     |   0\n",
      "      26303 |   0.115512  |    0.239445     |   1\n",
      "      26304 |   0.000016  |    0.068736     |   2\n",
      "      26305 |   0.119352  |    0.277272     |   1\n",
      "      26306 |   0.146464  |    0.007539     |   0\n",
      "      26307 |   0.000016  |    0.042173     |   2\n",
      "      26308 |   0.200732  |    0.226687     |   1\n",
      "      26309 |   0.218355  |    0.097055     |   0\n",
      "      26310 |   0.229468  |    0.148315     |   1\n",
      "      26311 |   0.231291  |    0.236738     |   1\n",
      "      26312 |   0.039819  |    0.048621     |   2\n",
      "      26313 |   0.164656  |    0.282454     |   1\n",
      "      26314 |   0.186322  |    0.218009     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 26316: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      26315 |   0.046216  |    0.005976     |   2\n",
      "      26316 |   0.225127  |    0.048698     |   0\n",
      "      26317 |   0.039266  |    0.149207     |   2\n",
      "      26318 |   0.029907  |    0.020938     |   2\n",
      "      26319 |   0.034145  |    0.074842     |   2\n",
      "      26320 |   0.284042  |    0.041220     |   0\n",
      "      26321 |   0.037406  |    0.093432     |   2\n",
      "      26322 |   0.172451  |    0.027983     |   0\n",
      "      26323 |   0.171246  |    0.103321     |   0\n",
      "      26324 |   0.247889  |    0.216439     |   1\n",
      "      26325 |   0.232581  |    0.223218     |   1\n",
      "      26326 |   0.179633  |    0.039503     |   0\n",
      "      26327 |   0.160386  |    0.040035     |   0\n",
      "      26328 |   0.026024  |    0.071270     |   2\n",
      "      26329 |   0.186750  |    0.064294     |   0\n",
      "      26330 |   0.177528  |    0.075705     |   0\n",
      "      26331 |   0.201084  |    0.237305     |   1\n",
      "      26332 |   0.241283  |    0.156003     |   1\n",
      "      26333 |   0.197955  |    0.222369     |   1\n",
      "      26334 |   0.138981  |    0.256213     |   1\n",
      "      26335 |   0.147134  |    0.016431     |   0\n",
      "      26336 |   0.036330  |    0.066381     |   2\n",
      "      26337 |   0.043935  |    0.088223     |   2\n",
      "      26338 |   0.189663  |    0.036939     |   0\n",
      "      26339 |   0.177905  |    0.048705     |   0\n",
      "      26340 |   0.158321  |    0.259413     |   1\n",
      "      26341 |   0.170829  |    0.214086     |   1\n",
      "      26342 |   0.181578  |    0.215408     |   1\n",
      "      26343 |   0.200406  |    0.076039     |   0\n",
      "      26344 |   0.173990  |    0.217986     |   1\n",
      "      26345 |   0.206266  |    0.059923     |   0\n",
      "      26346 |   0.192420  |    0.239869     |   1\n",
      "      26347 |   0.163636  |    0.059604     |   0\n",
      "      26348 |   0.201550  |    0.060376     |   0\n",
      "      26349 |   0.047646  |    0.044151     |   2\n",
      "      26350 |   0.171494  |    0.258170     |   1\n",
      "      26351 |   0.181085  |    0.164633     |   1\n",
      "      26352 |   0.189541  |    0.182178     |   1\n",
      "      26353 |   0.174157  |    0.275703     |   1\n",
      "      26354 |   0.044418  |    0.021188     |   2\n",
      "      26355 |   0.164126  |    0.127502     |   0\n",
      "      26356 |   0.197126  |    0.208318     |   1\n",
      "      26357 |   0.020487  |    0.008063     |   2\n",
      "      26358 |   0.000016  |    0.031768     |   2\n",
      "      26359 |   0.119683  |    0.085109     |   0\n",
      "      26360 |   0.186395  |    0.060577     |   0\n",
      "      26361 |   0.151314  |    0.107969     |   0\n",
      "      26362 |   0.158339  |    0.164332     |   1\n",
      "      26363 |   0.209671  |    0.228363     |   1\n",
      "      26364 |   0.191814  |    0.065924     |   0\n",
      "      26365 |   0.191581  |    0.114843     |   0\n",
      "      26366 |   0.166794  |    0.006949     |   0\n",
      "      26367 |   0.005088  |    0.087396     |   2\n",
      "      26368 |   0.218872  |    0.025675     |   0\n",
      "      26369 |   0.290526  |    0.238492     |   1\n",
      "      26370 |   0.058058  |    0.013429     |   2\n",
      "      26371 |   0.237764  |    0.269922     |   1\n",
      "      26372 |   0.205385  |    0.185662     |   1\n",
      "      26373 |   0.179790  |    0.180164     |   1\n",
      "      26374 |   0.170335  |    0.229332     |   1\n",
      "      26375 |   0.264520  |    0.193803     |   1\n",
      "      26376 |   0.265405  |    0.231050     |   1\n",
      "      26377 |   0.031800  |    0.031978     |   2\n",
      "      26378 |   0.053504  |    0.048190     |   2\n",
      "      26379 |   0.040099  |    0.085234     |   2\n",
      "      26380 |   0.152448  |    0.233687     |   1\n",
      "      26381 |   0.130718  |    0.027831     |   0\n",
      "      26382 |   0.135145  |    0.273170     |   1\n",
      "      26383 |   0.015785  |    0.005514     |   2\n",
      "      26384 |   0.193583  |    0.082067     |   0\n",
      "      26385 |   0.176786  |    0.064146     |   0\n",
      "      26386 |   0.184932  |    0.090794     |   0\n",
      "      26387 |   0.191466  |    0.025538     |   0\n",
      "      26388 |   0.193557  |    0.271255     |   1\n",
      "      26389 |   0.192403  |    0.187648     |   1\n",
      "      26390 |   0.129613  |    0.248363     |   1\n",
      "      26391 |   0.194275  |    0.024782     |   0\n",
      "      26392 |   0.036053  |    0.072571     |   2\n",
      "      26393 |   0.026181  |    0.067148     |   2\n",
      "      26394 | \u001b[94m  0.000016\u001b[0m  |    0.093063     |   2\n",
      "      26395 |   0.214624  |    0.204357     |   1\n",
      "      26396 |   0.184811  |    0.009413     |   0\n",
      "      26397 |   0.000016  |    0.087533     |   2\n",
      "      26398 |   0.214739  |    0.250938     |   1\n",
      "      26399 |   0.175574  |    0.164840     |   1\n",
      "      26400 | \u001b[94m  0.000016\u001b[0m  |    0.026984     |   2\n",
      "      26401 |   0.218546  |    0.258565     |   1\n",
      "      26402 |   0.238384  |    0.008229     |   0\n",
      "      26403 |   0.191080  |    0.090838     |   0\n",
      "      26404 |   0.178591  |    0.053733     |   0\n",
      "      26405 |   0.168077  |    0.274984     |   1\n",
      "      26406 |   0.000016  |    0.003958     |   2\n",
      "      26407 |   0.000016  |    0.090863     |   2\n",
      "      26408 | \u001b[94m  0.000016\u001b[0m  |    0.036127     |   2\n",
      "      26409 |   0.166922  |    0.211084     |   1\n",
      "      26410 |   0.041247  |    0.071564     |   2\n",
      "      26411 |   0.046804  |    0.087769     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 26412: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      26412 |   0.166288  |    0.048417     |   0\n",
      "      26413 |   0.166241  |    0.248263     |   1\n",
      "      26414 |   0.213668  |    0.006911     |   0\n",
      "      26415 |   0.152241  |    0.128866     |   0\n",
      "      26416 |   0.175501  |    0.004709     |   0\n",
      "      26417 |   0.160929  |    0.072793     |   0\n",
      "      26418 |   0.165171  |    0.072964     |   0\n",
      "      26419 |   0.144261  |    0.066026     |   0\n",
      "      26420 |   0.043791  |    0.097645     |   2\n",
      "      26421 |   0.159219  |    0.206002     |   1\n",
      "      26422 |   0.031392  |    0.084164     |   2\n",
      "      26423 |   0.204165  |    0.249441     |   1\n",
      "      26424 |   0.130606  |    0.004337     |   0\n",
      "      26425 |   0.166903  |    0.097159     |   0\n",
      "      26426 |   0.035287  |    0.021677     |   2\n",
      "      26427 |   0.036639  |    0.085242     |   2\n",
      "      26428 |   0.213814  |    0.049063     |   0\n",
      "      26429 |   0.155591  |    0.242971     |   1\n",
      "      26430 |   0.189528  |    0.219306     |   1\n",
      "      26431 |   0.187214  |    0.025988     |   0\n",
      "      26432 |   0.155545  |    0.236224     |   1\n",
      "      26433 |   0.177682  |    0.191438     |   1\n",
      "      26434 |   0.026979  |    0.096042     |   2\n",
      "      26435 |   0.175314  |    0.035757     |   0\n",
      "      26436 |   0.205133  |    0.262191     |   1\n",
      "      26437 |   0.175815  |    0.003633     |   0\n",
      "      26438 |   0.134573  |    0.040848     |   0\n",
      "      26439 |   0.035250  |    0.054437     |   2\n",
      "      26440 |   0.172276  |    0.102045     |   0\n",
      "      26441 |   0.176502  |    0.024173     |   0\n",
      "      26442 |   0.163766  |    0.090279     |   0\n",
      "      26443 |   0.158779  |    0.207906     |   1\n",
      "      26444 |   0.221375  |    0.305296     |   1\n",
      "      26445 |   0.210547  |    0.201389     |   1\n",
      "      26446 |   0.173805  |    0.026308     |   0\n",
      "      26447 |   0.184974  |    0.245379     |   1\n",
      "      26448 |   0.044452  |    0.034820     |   2\n",
      "      26449 |   0.183124  |    0.249209     |   1\n",
      "      26450 |   0.164295  |    0.168774     |   1\n",
      "      26451 |   0.167461  |    0.248926     |   1\n",
      "      26452 |   0.048924  |    0.088242     |   2\n",
      "      26453 |   0.222147  |    0.169439     |   1\n",
      "      26454 |   0.169718  |    0.151534     |   1\n",
      "      26455 |   0.192314  |    0.051972     |   0\n",
      "      26456 |   0.041182  |    0.092043     |   2\n",
      "      26457 |   0.235307  |    0.132168     |   1\n",
      "      26458 |   0.020070  |    0.090724     |   2\n",
      "      26459 |   0.000017  |    0.046746     |   2\n",
      "      26460 |   0.122064  |    0.053832     |   0\n",
      "      26461 |   0.166237  |    0.072898     |   0\n",
      "      26462 |   0.189475  |    0.229162     |   1\n",
      "      26463 |   0.005003  |    0.060213     |   2\n",
      "      26464 |   0.208320  |    0.057249     |   0\n",
      "      26465 |   0.264165  |    0.295604     |   1\n",
      "      26466 |   0.227752  |    0.131256     |   1\n",
      "      26467 |   0.056471  |    0.066166     |   2\n",
      "      26468 |   0.160677  |    0.065604     |   0\n",
      "      26469 |   0.031163  |    0.093010     |   2\n",
      "      26470 |   0.149590  |    0.030230     |   0\n",
      "      26471 |   0.179068  |    0.238437     |   1\n",
      "      26472 |   0.230549  |    0.009421     |   0\n",
      "      26473 |   0.145898  |    0.080888     |   0\n",
      "      26474 |   0.171573  |    0.063764     |   0\n",
      "      26475 |   0.204185  |    0.069471     |   0\n",
      "      26476 |   0.175910  |    0.221462     |   1\n",
      "      26477 |   0.142730  |    0.055865     |   0\n",
      "      26478 |   0.057784  |    0.050978     |   2\n",
      "      26479 |   0.203229  |    0.077372     |   0\n",
      "      26480 |   0.041365  |    0.073590     |   2\n",
      "      26481 |   0.195880  |    0.231775     |   1\n",
      "      26482 |   0.169134  |    0.216768     |   1\n",
      "      26483 |   0.157670  |    0.209203     |   1\n",
      "      26484 |   0.153692  |    0.205557     |   1\n",
      "      26485 |   0.280856  |    0.198816     |   1\n",
      "      26486 |   0.158014  |    0.042852     |   0\n",
      "      26487 |   0.210421  |    0.260710     |   1\n",
      "      26488 |   0.016660  |    0.069530     |   2\n",
      "      26489 |   0.034918  |    0.039388     |   2\n",
      "      26490 |   0.024467  |    0.073956     |   2\n",
      "      26491 |   0.000016  |    0.039326     |   2\n",
      "      26492 |   0.180312  |    0.061446     |   0\n",
      "      26493 |   0.000017  |    0.074540     |   2\n",
      "      26494 |   0.143361  |    0.268666     |   1\n",
      "      26495 |   0.179572  |    0.008256     |   0\n",
      "      26496 |   0.000017  |    0.064041     |   2\n",
      "      26497 |   0.000017  |    0.074548     |   2\n",
      "      26498 |   0.152714  |    0.044484     |   0\n",
      "      26499 |   0.191012  |    0.239859     |   1\n",
      "      26500 |   0.141341  |    0.064557     |   0\n",
      "      26501 |   0.179574  |    0.146086     |   0\n",
      "      26502 |   0.161447  |    0.096163     |   0\n",
      "      26503 |   0.039481  |    0.038211     |   2\n",
      "      26504 |   0.163488  |    0.290164     |   1\n",
      "      26505 |   0.031272  |    0.066243     |   2\n",
      "      26506 |   0.201444  |    0.064776     |   0\n",
      "      26507 |   0.033924  |    0.057519     |   2\n",
      "      26508 |   0.180441  |    0.270411     |   1\n",
      "      26509 |   0.180360  |    0.026235     |   0\n",
      "      26510 |   0.034784  |    0.060164     |   2\n",
      "      26511 |   0.183883  |    0.044618     |   0\n",
      "      26512 |   0.025813  |    0.073745     |   2\n",
      "      26513 |   0.033235  |    0.095911     |   2\n",
      "      26514 |   0.213319  |    0.005673     |   0\n",
      "      26515 |   0.187396  |    0.071603     |   0\n",
      "      26516 |   0.046244  |    0.064927     |   2\n",
      "      26517 |   0.204394  |    0.233688     |   1\n",
      "      26518 |   0.050127  |    0.066544     |   2\n",
      "      26519 |   0.181974  |    0.104009     |   0\n",
      "      26520 |   0.042496  |    0.034207     |   2\n",
      "      26521 |   0.020927  |    0.116137     |   2\n",
      "      26522 |   0.000016  |    0.045868     |   2\n",
      "      26523 |   0.235835  |    0.221442     |   1\n",
      "      26524 |   0.004518  |    0.045182     |   2\n",
      "      26525 |   0.179054  |    0.253064     |   1\n",
      "      26526 |   0.177452  |    0.298218     |   1\n",
      "      26527 |   0.218019  |    0.177121     |   1\n",
      "      26528 |   0.154132  |    0.162998     |   1\n",
      "      26529 |   0.171219  |    0.251710     |   1\n",
      "      26530 |   0.165279  |    0.052025     |   0\n",
      "      26531 |   0.216491  |    0.085899     |   0\n",
      "      26532 |   0.057419  |    0.083837     |   2\n",
      "      26533 |   0.142738  |    0.026524     |   0\n",
      "      26534 |   0.032677  |    0.106275     |   2\n",
      "      26535 |   0.056175  |    0.027509     |   2\n",
      "      26536 |   0.209500  |    0.124033     |   0\n",
      "      26537 |   0.166861  |    0.375949     |   1\n",
      "      26538 |   0.169975  |    0.222517     |   1\n",
      "      26539 |   0.038972  |    0.006505     |   2\n",
      "      26540 |   0.185187  |    0.114425     |   0\n",
      "      26541 |   0.015280  |    0.054485     |   2\n",
      "      26542 |   0.177332  |    0.308753     |   1\n",
      "      26543 |   0.034993  |    0.060276     |   2\n",
      "      26544 |   0.169822  |    0.075968     |   0\n",
      "      26545 |   0.200890  |    0.247714     |   1\n",
      "      26546 |   0.237227  |    0.160938     |   1\n",
      "      26547 |   0.197038  |    0.140683     |   0\n",
      "      26548 |   0.195067  |    0.155759     |   1\n",
      "      26549 |   0.199898  |    0.197593     |   1\n",
      "      26550 |   0.023527  |    0.045390     |   2\n",
      "      26551 |   0.190018  |    0.251979     |   1\n",
      "      26552 |   0.000016  |    0.013681     |   2\n",
      "      26553 |   0.000016  |    0.033045     |   2\n",
      "      26554 |   0.178514  |    0.085632     |   0\n",
      "      26555 |   0.000016  |    0.071973     |   2\n",
      "      26556 |   0.000016  |    0.039514     |   2\n",
      "      26557 |   0.200136  |    0.311369     |   1\n",
      "      26558 |   0.000016  |    0.004516     |   2\n",
      "      26559 |   0.000016  |    0.062880     |   2\n",
      "      26560 |   0.229913  |    0.115282     |   0\n",
      "      26561 |   0.150935  |    0.220277     |   1\n",
      "      26562 |   0.150999  |    0.074861     |   0\n",
      "      26563 |   0.042077  |    0.087946     |   2\n",
      "      26564 |   0.045471  |    0.010788     |   2\n",
      "      26565 |   0.230076  |    0.066959     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 26566: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      26566 |   0.156999  |    0.073350     |   0\n",
      "      26567 |   0.041144  |    0.094048     |   2\n",
      "      26568 |   0.029932  |    0.007491     |   2\n",
      "      26569 |   0.155501  |    0.239820     |   1\n",
      "      26570 |   0.132694  |    0.197641     |   1\n",
      "      26571 |   0.034935  |    0.077857     |   2\n",
      "      26572 |   0.033816  |    0.016143     |   2\n",
      "      26573 |   0.156987  |    0.077220     |   0\n",
      "      26574 |   0.144389  |    0.045012     |   0\n",
      "      26575 |   0.134191  |    0.109633     |   0\n",
      "      26576 |   0.236433  |    0.163767     |   1\n",
      "      26577 |   0.025529  |    0.098956     |   2\n",
      "      26578 |   0.239688  |    0.141426     |   1\n",
      "      26579 |   0.033608  |    0.051454     |   2\n",
      "      26580 |   0.045061  |    0.092667     |   2\n",
      "      26581 |   0.050149  |    0.039608     |   2\n",
      "      26582 |   0.206512  |    0.052269     |   0\n",
      "      26583 |   0.178009  |    0.225112     |   1\n",
      "      26584 |   0.250133  |    0.138738     |   1\n",
      "      26585 |   0.131486  |    0.089549     |   0\n",
      "      26586 |   0.165564  |    0.059809     |   0\n",
      "      26587 |   0.041069  |    0.042447     |   2\n",
      "      26588 |   0.147422  |    0.102768     |   0\n",
      "      26589 |   0.235825  |    0.115138     |   1\n",
      "      26590 |   0.176586  |    0.082751     |   0\n",
      "      26591 |   0.181712  |    0.197731     |   1\n",
      "      26592 |   0.131514  |    0.225188     |   1\n",
      "      26593 |   0.148245  |    0.257108     |   1\n",
      "      26594 |   0.019079  |    0.003843     |   2\n",
      "      26595 | \u001b[94m  0.000016\u001b[0m  |    0.051877     |   2\n",
      "      26596 |   0.172730  |    0.218520     |   1\n",
      "      26597 |   0.164298  |    0.059214     |   0\n",
      "      26598 |   0.141360  |    0.271153     |   1\n",
      "      26599 |   0.004596  |    0.059328     |   2\n",
      "      26600 |   0.055221  |    0.057200     |   2\n",
      "      26601 |   0.182863  |    0.294848     |   1\n",
      "      26602 |   0.170010  |    0.113724     |   1\n",
      "      26603 |   0.166239  |    0.248825     |   1\n",
      "      26604 |   0.218477  |    0.206780     |   1\n",
      "      26605 |   0.032128  |    0.021884     |   2\n",
      "      26606 |   0.182469  |    0.074942     |   0\n",
      "      26607 |   0.150381  |    0.020295     |   0\n",
      "      26608 |   0.175452  |    0.122638     |   0\n",
      "      26609 |   0.247828  |    0.166610     |   1\n",
      "      26610 |   0.170247  |    0.230463     |   1\n",
      "      26611 |   0.055394  |    0.063783     |   2\n",
      "      26612 |   0.159050  |    0.249134     |   1\n",
      "      26613 |   0.214979  |    0.201111     |   1\n",
      "      26614 |   0.039188  |    0.028673     |   2\n",
      "      26615 |   0.153126  |    0.043238     |   0\n",
      "      26616 |   0.014300  |    0.067533     |   2\n",
      "      26617 |   0.197993  |    0.298598     |   1\n",
      "      26618 |   0.213839  |    0.014221     |   0\n",
      "      26619 |   0.195987  |    0.237118     |   1\n",
      "      26620 |   0.183364  |    0.027080     |   0\n",
      "      26621 |   0.155457  |    0.220884     |   1\n",
      "      26622 |   0.151747  |    0.114982     |   0\n",
      "      26623 |   0.145475  |    0.073619     |   0\n",
      "      26624 |   0.200190  |    0.026684     |   0\n",
      "      26625 |   0.144469  |    0.456200     |   1\n",
      "      26626 |   0.186632  |    0.217871     |   1\n",
      "      26627 |   0.034387  |    0.019301     |   2\n",
      "      26628 |   0.026646  |    0.115652     |   2\n",
      "      26629 | \u001b[94m  0.000016\u001b[0m  |    0.075297     |   2\n",
      "      26630 |   0.179871  |    0.230927     |   1\n",
      "      26631 |   0.201868  |    0.225923     |   1\n",
      "      26632 |   0.000016  |    0.069299     |   2\n",
      "      26633 |   0.169000  |    0.247026     |   1\n",
      "      26634 |   0.000016  |    0.018306     |   2\n",
      "      26635 |   0.000016  |    0.092263     |   2\n",
      "      26636 |   0.186712  |    0.242533     |   1\n",
      "      26637 |   0.197543  |    0.016365     |   0\n",
      "      26638 | \u001b[94m  0.000016\u001b[0m  |    0.057340     |   2\n",
      "      26639 |   0.151722  |    0.125996     |   0\n",
      "      26640 |   0.251342  |    0.065438     |   0\n",
      "      26641 |   0.132572  |    0.218195     |   1\n",
      "      26642 |   0.173700  |    0.177172     |   1\n",
      "      26643 |   0.140101  |    0.212310     |   1\n",
      "      26644 |   0.193887  |    0.201433     |   1\n",
      "      26645 |   0.173925  |    0.014992     |   0\n",
      "      26646 | \u001b[94m  0.000016\u001b[0m  |    0.091976     |   2\n",
      "      26647 |   0.043153  |    0.115469     |   2\n",
      "      26648 |   0.204857  |    0.070448     |   0\n",
      "      26649 |   0.180827  |    0.081390     |   0\n",
      "      26650 |   0.192077  |    0.292100     |   1\n",
      "      26651 |   0.046538  |    0.011473     |   2\n",
      "      26652 |   0.178925  |    0.080368     |   0\n",
      "      26653 |   0.257727  |    0.220495     |   1\n",
      "      26654 |   0.135835  |    0.011148     |   0\n",
      "      26655 |   0.179779  |    0.085736     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 26656: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      26656 |   0.218856  |    0.272862     |   1\n",
      "      26657 |   0.126938  |    0.021986     |   0\n",
      "      26658 |   0.046092  |    0.158420     |   2\n",
      "      26659 |   0.216627  |    0.170666     |   1\n",
      "      26660 |   0.158497  |    0.010366     |   0\n",
      "      26661 |   0.185687  |    0.285909     |   1\n",
      "      26662 |   0.031341  |    0.006296     |   2\n",
      "      26663 |   0.034020  |    0.096590     |   2\n",
      "      26664 |   0.186417  |    0.073449     |   0\n",
      "      26665 |   0.152023  |    0.052993     |   0\n",
      "      26666 |   0.204512  |    0.243481     |   1\n",
      "      26667 |   0.144977  |    0.066242     |   0\n",
      "      26668 |   0.219614  |    0.240488     |   1\n",
      "      26669 |   0.035107  |    0.015504     |   2\n",
      "      26670 |   0.026249  |    0.079849     |   2\n",
      "      26671 |   0.169521  |    0.248826     |   1\n",
      "      26672 |   0.193538  |    0.003932     |   0\n",
      "      26673 |   0.152114  |    0.064992     |   0\n",
      "      26674 |   0.033484  |    0.067705     |   2\n",
      "      26675 |   0.160095  |    0.070490     |   0\n",
      "      26676 |   0.202081  |    0.091182     |   0\n",
      "      26677 |   0.150024  |    0.149570     |   1\n",
      "      26678 |   0.043777  |    0.088117     |   2\n",
      "      26679 |   0.051243  |    0.066878     |   2\n",
      "      26680 |   0.173196  |    0.252542     |   1\n",
      "      26681 |   0.041174  |    0.060884     |   2\n",
      "      26682 |   0.020869  |    0.092799     |   2\n",
      "      26683 |   0.155234  |    0.036733     |   0\n",
      "      26684 |   0.000016  |    0.077487     |   2\n",
      "      26685 |   0.126644  |    0.093365     |   0\n",
      "      26686 |   0.179484  |    0.146260     |   1\n",
      "      26687 |   0.198484  |    0.061631     |   0\n",
      "      26688 |   0.004768  |    0.036002     |   2\n",
      "      26689 |   0.203870  |    0.278791     |   1\n",
      "      26690 |   0.197660  |    0.006877     |   0\n",
      "      26691 |   0.211845  |    0.080169     |   0\n",
      "      26692 |   0.161634  |    0.052497     |   0\n",
      "      26693 |   0.164152  |    0.226590     |   1\n",
      "      26694 |   0.217072  |    0.117311     |   0\n",
      "      26695 |   0.180582  |    0.077562     |   0\n",
      "      26696 |   0.165282  |    0.078165     |   0\n",
      "      26697 |   0.057055  |    0.044684     |   2\n",
      "      26698 |   0.032637  |    0.098426     |   2\n",
      "      26699 |   0.151166  |    0.063134     |   0\n",
      "      26700 |   0.172802  |    0.070166     |   0\n",
      "      26701 |   0.054337  |    0.094834     |   2\n",
      "      26702 |   0.168022  |    0.026649     |   0\n",
      "      26703 |   0.178894  |    0.271606     |   1\n",
      "      26704 |   0.141838  |    0.186955     |   1\n",
      "      26705 |   0.146462  |    0.128724     |   0\n",
      "      26706 |   0.164845  |    0.021708     |   0\n",
      "      26707 |   0.148751  |    0.146318     |   0\n",
      "      26708 |   0.166555  |    0.035908     |   0\n",
      "      26709 |   0.146010  |    0.323220     |   1\n",
      "      26710 |   0.164807  |    0.219864     |   1\n",
      "      26711 |   0.162207  |    0.209887     |   1\n",
      "      26712 |   0.229002  |    0.028294     |   0\n",
      "      26713 |   0.160184  |    0.238636     |   1\n",
      "      26714 |   0.147015  |    0.220385     |   1\n",
      "      26715 |   0.148558  |    0.089031     |   0\n",
      "      26716 |   0.150544  |    0.191781     |   1\n",
      "      26717 |   0.041240  |    0.089240     |   2\n",
      "      26718 |   0.016256  |    0.030755     |   2\n",
      "      26719 |   0.223579  |    0.267498     |   1\n",
      "      26720 |   0.203620  |    0.013290     |   0\n",
      "      26721 |   0.132743  |    0.089302     |   0\n",
      "      26722 |   0.031829  |    0.061359     |   2\n",
      "      26723 |   0.186103  |    0.279972     |   1\n",
      "      26724 |   0.151960  |    0.067931     |   0\n",
      "      26725 |   0.024660  |    0.123575     |   2\n",
      "      26726 |   0.190216  |    0.366422     |   1\n",
      "      26727 |   0.000016  |    0.007666     |   2\n",
      "      26728 |   0.000016  |    0.075398     |   2\n",
      "      26729 |   0.188639  |    0.058905     |   0\n",
      "      26730 |   0.000016  |    0.069110     |   2\n",
      "      26731 |   0.000016  |    0.103011     |   2\n",
      "      26732 |   0.137169  |    0.225668     |   1\n",
      "      26733 |   0.188769  |    0.031655     |   0\n",
      "      26734 |   0.160794  |    0.120214     |   0\n",
      "      26735 |   0.000016  |    0.047897     |   2\n",
      "      26736 |   0.000016  |    0.043395     |   2\n",
      "      26737 |   0.167894  |    0.044284     |   0\n",
      "      26738 |   0.044155  |    0.114016     |   2\n",
      "      26739 |   0.177765  |    0.214656     |   1\n",
      "      26740 |   0.047634  |    0.060214     |   2\n",
      "      26741 |   0.207029  |    0.029163     |   0\n",
      "      26742 |   0.196072  |    0.272325     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 26743: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      26743 |   0.211437  |    0.200132     |   1\n",
      "      26744 |   0.166614  |    0.015871     |   0\n",
      "      26745 |   0.202988  |    0.234961     |   1\n",
      "      26746 |   0.040978  |    0.061135     |   2\n",
      "      26747 |   0.180866  |    0.072425     |   0\n",
      "      26748 |   0.158297  |    0.066783     |   0\n",
      "      26749 |   0.031855  |    0.065128     |   2\n",
      "      26750 |   0.035391  |    0.073988     |   2\n",
      "      26751 |   0.197071  |    0.163814     |   1\n",
      "      26752 |   0.034912  |    0.095537     |   2\n",
      "      26753 |   0.257470  |    0.232040     |   1\n",
      "      26754 |   0.161717  |    0.214415     |   1\n",
      "      26755 |   0.025324  |    0.064994     |   2\n",
      "      26756 |   0.169509  |    0.299672     |   1\n",
      "      26757 |   0.035357  |    0.016406     |   2\n",
      "      26758 |   0.201377  |    0.222069     |   1\n",
      "      26759 |   0.043061  |    0.060823     |   2\n",
      "      26760 |   0.191773  |    0.075846     |   0\n",
      "      26761 |   0.170326  |    0.045077     |   0\n",
      "      26762 |   0.048979  |    0.092106     |   2\n",
      "      26763 |   0.042201  |    0.045484     |   2\n",
      "      26764 |   0.224241  |    0.096474     |   0\n",
      "      26765 |   0.199697  |    0.071998     |   0\n",
      "      26766 |   0.019772  |    0.044362     |   2\n",
      "      26767 |   0.203628  |    0.261370     |   1\n",
      "      26768 |   0.000016  |    0.014291     |   2\n",
      "      26769 |   0.223398  |    0.238282     |   1\n",
      "      26770 |   0.185715  |    0.163978     |   1\n",
      "      26771 |   0.177621  |    0.321689     |   1\n",
      "      26772 |   0.174325  |    0.083530     |   0\n",
      "      26773 |   0.198222  |    0.089058     |   0\n",
      "      26774 |   0.154353  |    0.023018     |   0\n",
      "      26775 |   0.005087  |    0.153056     |   2\n",
      "      26776 |   0.056772  |    0.028824     |   2\n",
      "      26777 |   0.147108  |    0.227041     |   1\n",
      "      26778 |   0.201974  |    0.162623     |   1\n",
      "      26779 |   0.235654  |    0.247559     |   1\n",
      "      26780 |   0.208133  |    0.218343     |   1\n",
      "      26781 |   0.192906  |    0.015419     |   0\n",
      "      26782 |   0.160150  |    0.165803     |   1\n",
      "      26783 |   0.129341  |    0.091083     |   0\n",
      "      26784 |   0.033503  |    0.028782     |   2\n",
      "      26785 |   0.167433  |    0.225723     |   1\n",
      "      26786 |   0.054329  |    0.021807     |   2\n",
      "      26787 |   0.158349  |    0.095389     |   0\n",
      "      26788 |   0.041283  |    0.048102     |   2\n",
      "      26789 |   0.015938  |    0.020505     |   2\n",
      "      26790 |   0.215056  |    0.076313     |   0\n",
      "      26791 |   0.175027  |    0.066692     |   0\n",
      "      26792 |   0.033666  |    0.119161     |   2\n",
      "      26793 |   0.144844  |    0.053881     |   0\n",
      "      26794 |   0.025983  |    0.110740     |   2\n",
      "      26795 |   0.164442  |    0.154735     |   1\n",
      "      26796 |   0.188026  |    0.064001     |   0\n",
      "      26797 |   0.182296  |    0.065893     |   0\n",
      "      26798 |   0.210030  |    0.162853     |   1\n",
      "      26799 |   0.141214  |    0.041506     |   0\n",
      "      26800 |   0.000016  |    0.072229     |   2\n",
      "      26801 |   0.000016  |    0.015610     |   2\n",
      "      26802 |   0.000016  |    0.085119     |   2\n",
      "      26803 |   0.000016  |    0.104272     |   2\n",
      "      26804 |   0.000016  |    0.027471     |   2\n",
      "      26805 |   0.000016  |    0.038041     |   2\n",
      "      26806 |   0.208619  |    0.097045     |   0\n",
      "      26807 |   0.182415  |    0.021246     |   0\n",
      "      26808 |   0.042700  |    0.095412     |   2\n",
      "      26809 |   0.046937  |    0.070649     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 26810: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      26810 |   0.041455  |    0.012820     |   2\n",
      "      26811 |   0.030768  |    0.117861     |   2\n",
      "      26812 |   0.170356  |    0.015409     |   0\n",
      "      26813 |   0.176578  |    0.092342     |   0\n",
      "      26814 |   0.035211  |    0.042227     |   2\n",
      "      26815 |   0.036079  |    0.027421     |   2\n",
      "      26816 |   0.025080  |    0.082297     |   2\n",
      "      26817 |   0.034923  |    0.047627     |   2\n",
      "      26818 |   0.168292  |    0.042776     |   0\n",
      "      26819 |   0.182965  |    0.240754     |   1\n",
      "      26820 |   0.043027  |    0.050642     |   2\n",
      "      26821 |   0.048563  |    0.038830     |   2\n",
      "      26822 |   0.203230  |    0.079740     |   0\n",
      "      26823 |   0.159687  |    0.060223     |   0\n",
      "      26824 |   0.041276  |    0.040477     |   2\n",
      "      26825 |   0.020188  |    0.072454     |   2\n",
      "      26826 |   0.220625  |    0.027725     |   0\n",
      "      26827 |   0.000016  |    0.121664     |   2\n",
      "      26828 |   0.154135  |    0.067455     |   0\n",
      "      26829 |   0.132993  |    0.016641     |   0\n",
      "      26830 |   0.004523  |    0.121277     |   2\n",
      "      26831 |   0.188771  |    0.199621     |   1\n",
      "      26832 |   0.174053  |    0.051201     |   0\n",
      "      26833 |   0.181451  |    0.102483     |   0\n",
      "      26834 |   0.056026  |    0.026507     |   2\n",
      "      26835 |   0.207296  |    0.204056     |   1\n",
      "      26836 |   0.146275  |    0.079152     |   0\n",
      "      26837 |   0.146702  |    0.023067     |   0\n",
      "      26838 |   0.170103  |    0.081895     |   0\n",
      "      26839 |   0.164753  |    0.015800     |   0\n",
      "      26840 |   0.193360  |    0.090011     |   0\n",
      "      26841 |   0.034118  |    0.117806     |   2\n",
      "      26842 |   0.227612  |    0.004692     |   0\n",
      "      26843 |   0.057070  |    0.074754     |   2\n",
      "      26844 |   0.149904  |    0.280683     |   1\n",
      "      26845 |   0.165234  |    0.014584     |   0\n",
      "      26846 |   0.196593  |    0.072509     |   0\n",
      "      26847 |   0.041884  |    0.119579     |   2\n",
      "      26848 |   0.179859  |    0.215015     |   1\n",
      "      26849 |   0.223785  |    0.064358     |   0\n",
      "      26850 |   0.197306  |    0.236876     |   1\n",
      "      26851 |   0.015949  |    0.028081     |   2\n",
      "      26852 |   0.212177  |    0.261035     |   1\n",
      "      26853 |   0.184813  |    0.047573     |   0\n",
      "      26854 |   0.153714  |    0.119630     |   0\n",
      "      26855 |   0.164341  |    0.024430     |   0\n",
      "      26856 |   0.033474  |    0.065220     |   2\n",
      "      26857 |   0.224778  |    0.220607     |   1\n",
      "      26858 |   0.026138  |    0.068916     |   2\n",
      "      26859 |   0.211228  |    0.075634     |   0\n",
      "      26860 |   0.159624  |    0.238008     |   1\n",
      "      26861 |   0.000016  |    0.004713     |   2\n",
      "      26862 |   0.000016  |    0.094051     |   2\n",
      "      26863 |   0.000016  |    0.084569     |   2\n",
      "      26864 |   0.000016  |    0.017816     |   2\n",
      "      26865 |   0.000016  |    0.097035     |   2\n",
      "      26866 |   0.154161  |    0.039583     |   0\n",
      "      26867 |   0.163333  |    0.087662     |   0\n",
      "      26868 |   0.155316  |    0.043555     |   0\n",
      "      26869 |   0.000016  |    0.036132     |   2\n",
      "      26870 |   0.044443  |    0.112584     |   2\n",
      "      26871 |   0.214441  |    0.176920     |   1\n",
      "      26872 |   0.197194  |    0.226986     |   1\n",
      "      26873 |   0.160396  |    0.067560     |   0\n",
      "      26874 |   0.047587  |    0.065187     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 26875: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      26875 |   0.040555  |    0.084000     |   2\n",
      "      26876 |   0.029897  |    0.037220     |   2\n",
      "      26877 |   0.033462  |    0.099831     |   2\n",
      "      26878 |   0.036740  |    0.010718     |   2\n",
      "      26879 |   0.025436  |    0.097140     |   2\n",
      "      26880 |   0.165508  |    0.277749     |   1\n",
      "      26881 |   0.193816  |    0.006561     |   0\n",
      "      26882 |   0.178661  |    0.028572     |   0\n",
      "      26883 |   0.193226  |    0.208611     |   1\n",
      "      26884 |   0.190804  |    0.294732     |   1\n",
      "      26885 |   0.197466  |    0.110965     |   1\n",
      "      26886 |   0.182631  |    0.068294     |   0\n",
      "      26887 |   0.160665  |    0.051505     |   0\n",
      "      26888 |   0.113281  |    0.225135     |   1\n",
      "      26889 |   0.206529  |    0.041560     |   0\n",
      "      26890 |   0.154881  |    0.084989     |   0\n",
      "      26891 |   0.033409  |    0.098180     |   2\n",
      "      26892 |   0.154553  |    0.193628     |   1\n",
      "      26893 |   0.150834  |    0.008740     |   0\n",
      "      26894 |   0.180453  |    0.098071     |   0\n",
      "      26895 |   0.196216  |    0.243324     |   1\n",
      "      26896 |   0.154224  |    0.154411     |   1\n",
      "      26897 |   0.042697  |    0.078655     |   2\n",
      "      26898 |   0.047457  |    0.072873     |   2\n",
      "      26899 |   0.168380  |    0.326757     |   1\n",
      "      26900 |   0.160573  |    0.070512     |   0\n",
      "      26901 |   0.208630  |    0.261984     |   1\n",
      "      26902 |   0.042272  |    0.003246     |   2\n",
      "      26903 |   0.134512  |    0.360557     |   1\n",
      "      26904 |   0.214479  |    0.239251     |   1\n",
      "      26905 |   0.125302  |    0.178520     |   1\n",
      "      26906 |   0.019268  |    0.006966     |   2\n",
      "      26907 |   0.168551  |    0.085732     |   0\n",
      "      26908 |   0.136101  |    0.238241     |   1\n",
      "      26909 |   0.000016  |    0.015313     |   2\n",
      "      26910 |   0.004977  |    0.119186     |   2\n",
      "      26911 |   0.228993  |    0.223379     |   1\n",
      "      26912 |   0.218299  |    0.220513     |   1\n",
      "      26913 |   0.179278  |    0.075390     |   0\n",
      "      26914 |   0.055009  |    0.062042     |   2\n",
      "      26915 |   0.201365  |    0.224187     |   1\n",
      "      26916 |   0.031398  |    0.059392     |   2\n",
      "      26917 |   0.151555  |    0.062226     |   0\n",
      "      26918 |   0.202649  |    0.288869     |   1\n",
      "      26919 |   0.157864  |    0.181313     |   1\n",
      "      26920 |   0.174337  |    0.306645     |   1\n",
      "      26921 |   0.223771  |    0.227330     |   1\n",
      "      26922 |   0.052352  |    0.004869     |   2\n",
      "      26923 |   0.192524  |    0.096079     |   0\n",
      "      26924 |   0.210836  |    0.056679     |   0\n",
      "      26925 |   0.039576  |    0.066782     |   2\n",
      "      26926 |   0.204198  |    0.232895     |   1\n",
      "      26927 |   0.133033  |    0.261900     |   1\n",
      "      26928 |   0.012151  |    0.004657     |   2\n",
      "      26929 |   0.029941  |    0.115571     |   2\n",
      "      26930 |   0.024263  |    0.073826     |   2\n",
      "      26931 |   0.000016  |    0.058951     |   2\n",
      "      26932 |   0.153827  |    0.086539     |   0\n",
      "      26933 |   0.127071  |    0.240751     |   1\n",
      "      26934 |   0.173094  |    0.013693     |   0\n",
      "      26935 |   0.151130  |    0.300300     |   1\n",
      "      26936 |   0.144339  |    0.062890     |   0\n",
      "      26937 |   0.194033  |    0.307244     |   1\n",
      "      26938 |   0.000016  |    0.007700     |   2\n",
      "      26939 |   0.166874  |    0.093024     |   0\n",
      "      26940 |   0.000016  |    0.023151     |   2\n",
      "      26941 |   0.000016  |    0.120027     |   2\n",
      "      26942 |   0.000016  |    0.024477     |   2\n",
      "      26943 |   0.177501  |    0.085823     |   0\n",
      "      26944 | \u001b[94m  0.000016\u001b[0m  |    0.040715     |   2\n",
      "      26945 |   0.187016  |    0.179273     |   1\n",
      "      26946 |   0.165246  |    0.091759     |   0\n",
      "      26947 |   0.041065  |    0.103150     |   2\n",
      "      26948 |   0.212692  |    0.032924     |   0\n",
      "      26949 |   0.125575  |    0.246292     |   1\n",
      "      26950 |   0.045427  |    0.036745     |   2\n",
      "      26951 |   0.149163  |    0.272834     |   1\n",
      "      26952 |   0.204224  |    0.123740     |   1\n",
      "      26953 |   0.162698  |    0.377822     |   1\n",
      "      26954 |   0.202928  |    0.036006     |   0\n",
      "      26955 |   0.181764  |    0.295997     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 26956: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      26956 |   0.044373  |    0.039280     |   2\n",
      "      26957 |   0.182565  |    0.072655     |   0\n",
      "      26958 |   0.120141  |    0.339234     |   1\n",
      "      26959 |   0.228240  |    0.122101     |   0\n",
      "      26960 |   0.144797  |    0.007001     |   0\n",
      "      26961 |   0.030274  |    0.115572     |   2\n",
      "      26962 |   0.035704  |    0.043569     |   2\n",
      "      26963 |   0.171628  |    0.074394     |   0\n",
      "      26964 |   0.173823  |    0.073543     |   0\n",
      "      26965 |   0.189835  |    0.286490     |   1\n",
      "      26966 |   0.193291  |    0.216354     |   1\n",
      "      26967 |   0.158523  |    0.099717     |   0\n",
      "      26968 |   0.037043  |    0.023369     |   2\n",
      "      26969 |   0.026168  |    0.203268     |   2\n",
      "      26970 |   0.033083  |    0.004212     |   2\n",
      "      26971 |   0.047839  |    0.087705     |   2\n",
      "      26972 |   0.051378  |    0.080006     |   2\n",
      "      26973 |   0.188532  |    0.151465     |   0\n",
      "      26974 |   0.039019  |    0.041240     |   2\n",
      "      26975 |   0.019195  |    0.097627     |   2\n",
      "      26976 |   0.171114  |    0.073421     |   0\n",
      "      26977 | \u001b[94m  0.000015\u001b[0m  |    0.062903     |   2\n",
      "      26978 |   0.171662  |    0.274973     |   1\n",
      "      26979 |   0.005666  |    0.095109     |   2\n",
      "      26980 |   0.148807  |    0.224117     |   1\n",
      "      26981 |   0.157056  |    0.318755     |   1\n",
      "      26982 |   0.054900  |    0.097605     |   2\n",
      "      26983 |   0.206355  |    0.078130     |   0\n",
      "      26984 |   0.154505  |    0.293364     |   1\n",
      "      26985 |   0.158292  |    0.016238     |   0\n",
      "      26986 |   0.032812  |    0.151530     |   2\n",
      "      26987 |   0.204888  |    0.027362     |   0\n",
      "      26988 |   0.208615  |    0.069122     |   0\n",
      "      26989 |   0.157808  |    0.112858     |   0\n",
      "      26990 |   0.054434  |    0.098473     |   2\n",
      "      26991 |   0.041581  |    0.115250     |   2\n",
      "      26992 |   0.155442  |    0.073712     |   0\n",
      "      26993 |   0.193951  |    0.158937     |   1\n",
      "      26994 |   0.185254  |    0.327530     |   1\n",
      "      26995 |   0.135129  |    0.388377     |   1\n",
      "      26996 |   0.165142  |    0.192503     |   1\n",
      "      26997 |   0.015534  |    0.071205     |   2\n",
      "      26998 |   0.122132  |    0.071359     |   0\n",
      "      26999 |   0.174778  |    0.100231     |   0\n",
      "      27000 |   0.187254  |    0.111416     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 27000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 27000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      27001 |   0.044115  |    0.122075     |   2\n",
      "      27002 |   0.210016  |    0.214150     |   1\n",
      "      27003 |   0.030118  |    0.065778     |   2\n",
      "      27004 |   0.243407  |    0.072269     |   0\n",
      "      27005 |   0.185530  |    0.221572     |   1\n",
      "      27006 |   0.196678  |    0.160135     |   1\n",
      "      27007 |   0.158159  |    0.066934     |   0\n",
      "      27008 |   0.148301  |    0.054343     |   0\n",
      "      27009 |   0.169234  |    0.259473     |   1\n",
      "      27010 |   0.275663  |    0.190162     |   1\n",
      "      27011 |   0.155819  |    0.281819     |   1\n",
      "      27012 |   0.178645  |    0.207772     |   1\n",
      "      27013 |   0.034999  |    0.003437     |   2\n",
      "      27014 |   0.173908  |    0.187901     |   1\n",
      "      27015 |   0.035250  |    0.019256     |   2\n",
      "      27016 |   0.224795  |    0.278458     |   1\n",
      "      27017 |   0.177717  |    0.219043     |   1\n",
      "      27018 |   0.024769  |    0.091097     |   2\n",
      "      27019 |   0.180216  |    0.035606     |   0\n",
      "      27020 |   0.194065  |    0.266070     |   1\n",
      "      27021 |   0.164166  |    0.234372     |   1\n",
      "      27022 |   0.156674  |    0.022579     |   0\n",
      "      27023 |   0.173410  |    0.072821     |   0\n",
      "      27024 |   0.202683  |    0.258008     |   1\n",
      "      27025 |   0.033135  |    0.027635     |   2\n",
      "      27026 |   0.137746  |    0.082153     |   0\n",
      "      27027 |   0.181079  |    0.231224     |   1\n",
      "      27028 |   0.157727  |    0.255279     |   1\n",
      "      27029 |   0.045998  |    0.011785     |   2\n",
      "      27030 |   0.047634  |    0.088597     |   2\n",
      "      27031 |   0.040045  |    0.059226     |   2\n",
      "      27032 |   0.157864  |    0.192198     |   1\n",
      "      27033 |   0.171235  |    0.310411     |   1\n",
      "      27034 |   0.153054  |    0.201458     |   1\n",
      "      27035 |   0.189949  |    0.169754     |   1\n",
      "      27036 |   0.158273  |    0.029781     |   0\n",
      "      27037 |   0.231675  |    0.235658     |   1\n",
      "      27038 |   0.137085  |    0.207887     |   1\n",
      "      27039 |   0.147386  |    0.212940     |   1\n",
      "      27040 |   0.150086  |    0.216272     |   1\n",
      "      27041 |   0.021866  |    0.046294     |   2\n",
      "      27042 |   0.177305  |    0.044555     |   0\n",
      "      27043 |   0.160098  |    0.069429     |   0\n",
      "      27044 |   0.000016  |    0.058552     |   2\n",
      "      27045 |   0.190914  |    0.040142     |   0\n",
      "      27046 |   0.174053  |    0.043139     |   0\n",
      "      27047 |   0.005014  |    0.082688     |   2\n",
      "      27048 |   0.130670  |    0.232696     |   1\n",
      "      27049 |   0.056394  |    0.052489     |   2\n",
      "      27050 |   0.254387  |    0.213465     |   1\n",
      "      27051 |   0.156791  |    0.031544     |   0\n",
      "      27052 |   0.180701  |    0.073108     |   0\n",
      "      27053 |   0.177636  |    0.071453     |   0\n",
      "      27054 |   0.033121  |    0.146389     |   2\n",
      "      27055 |   0.183588  |    0.083040     |   0\n",
      "      27056 |   0.053392  |    0.147932     |   2\n",
      "      27057 |   0.183035  |    0.042689     |   0\n",
      "      27058 |   0.225616  |    0.439928     |   1\n",
      "      27059 |   0.120446  |    0.137193     |   0\n",
      "      27060 |   0.154203  |    0.467387     |   1\n",
      "      27061 |   0.039224  |    0.120921     |   2\n",
      "      27062 |   0.016290  |    0.128926     |   2\n",
      "      27063 |   0.035265  |    0.083914     |   2\n",
      "      27064 |   0.023707  |    0.120737     |   2\n",
      "      27065 |   0.205312  |    0.447625     |   1\n",
      "      27066 |   0.219937  |    0.339045     |   1\n",
      "      27067 |   0.196575  |    0.186590     |   0\n",
      "      27068 |   0.000015  |    0.038484     |   2\n",
      "      27069 |   0.178577  |    0.515145     |   1\n",
      "      27070 |   0.000016  |    0.102546     |   2\n",
      "      27071 |   0.118250  |    0.351391     |   1\n",
      "      27072 |   0.000016  |    0.006769     |   2\n",
      "      27073 |   0.251776  |    0.085540     |   0\n",
      "      27074 |   0.157289  |    0.204123     |   1\n",
      "      27075 |   0.127031  |    0.005441     |   0\n",
      "      27076 |   0.186783  |    0.029332     |   0\n",
      "      27077 |   0.181993  |    0.333599     |   1\n",
      "      27078 |   0.244588  |    0.313433     |   1\n",
      "      27079 |   0.196839  |    0.346318     |   1\n",
      "      27080 |   0.199866  |    0.320215     |   1\n",
      "      27081 |   0.166616  |    0.121747     |   0\n",
      "      27082 |   0.000016  |    0.039664     |   2\n",
      "      27083 |   0.141188  |    0.444353     |   1\n",
      "      27084 |   0.000016  |    0.065267     |   2\n",
      "      27085 |   0.162489  |    0.153326     |   0\n",
      "      27086 |   0.000016  |    0.046906     |   2\n",
      "      27087 |   0.040297  |    0.160138     |   2\n",
      "      27088 |   0.044812  |    0.044418     |   2\n",
      "      27089 |   0.220701  |    0.368002     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 27090: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      27090 |   0.039073  |    0.074351     |   2\n",
      "      27091 |   0.028618  |    0.091736     |   2\n",
      "      27092 |   0.034433  |    0.148149     |   2\n",
      "      27093 |   0.034451  |    0.075170     |   2\n",
      "      27094 |   0.024434  |    0.122865     |   2\n",
      "      27095 |   0.031933  |    0.072993     |   2\n",
      "      27096 |   0.171074  |    0.319734     |   1\n",
      "      27097 |   0.179280  |    0.084694     |   0\n",
      "      27098 |   0.044233  |    0.090968     |   2\n",
      "      27099 |   0.182367  |    0.330291     |   1\n",
      "      27100 |   0.138877  |    0.337474     |   1\n",
      "      27101 |   0.154721  |    0.005370     |   0\n",
      "      27102 |   0.201401  |    0.088556     |   0\n",
      "      27103 |   0.180258  |    0.301863     |   1\n",
      "      27104 |   0.047286  |    0.045842     |   2\n",
      "      27105 |   0.038962  |    0.136979     |   2\n",
      "      27106 |   0.142993  |    0.068084     |   0\n",
      "      27107 |   0.202345  |    0.503851     |   1\n",
      "      27108 |   0.152854  |    0.115611     |   0\n",
      "      27109 |   0.121281  |    0.122507     |   0\n",
      "      27110 |   0.168873  |    0.064646     |   0\n",
      "      27111 |   0.151139  |    0.126515     |   0\n",
      "      27112 |   0.192550  |    0.098450     |   0\n",
      "      27113 |   0.127398  |    0.087291     |   0\n",
      "      27114 |   0.181661  |    0.469057     |   1\n",
      "      27115 |   0.019505  |    0.123515     |   2\n",
      "      27116 |   0.307613  |    0.418450     |   1\n",
      "      27117 |   0.175984  |    0.467661     |   1\n",
      "      27118 |   0.162370  |    0.087717     |   0\n",
      "      27119 |   0.123811  |    0.136251     |   0\n",
      "      27120 |   0.000016  |    0.091470     |   2\n",
      "      27121 |   0.182800  |    0.194301     |   0\n",
      "      27122 |   0.143901  |    0.388180     |   1\n",
      "      27123 |   0.182496  |    0.102526     |   0\n",
      "      27124 |   0.136012  |    0.085188     |   0\n",
      "      27125 |   0.004542  |    0.013191     |   2\n",
      "      27126 |   0.180368  |    0.520244     |   1\n",
      "      27127 |   0.170841  |    0.319800     |   1\n",
      "      27128 |   0.235897  |    0.367880     |   1\n",
      "      27129 |   0.145308  |    0.030255     |   0\n",
      "      27130 |   0.172693  |    0.116537     |   0\n",
      "      27131 |   0.173212  |    0.329893     |   1\n",
      "      27132 |   0.054957  |    0.155415     |   2\n",
      "      27133 |   0.209613  |    0.314051     |   1\n",
      "      27134 |   0.032949  |    0.090531     |   2\n",
      "      27135 |   0.174847  |    0.286834     |   1\n",
      "      27136 |   0.053863  |    0.037793     |   2\n",
      "      27137 |   0.038118  |    0.121977     |   2\n",
      "      27138 |   0.214599  |    0.308038     |   1\n",
      "      27139 |   0.178320  |    0.363714     |   1\n",
      "      27140 |   0.216544  |    0.310963     |   1\n",
      "      27141 |   0.014430  |    0.067727     |   2\n",
      "      27142 |   0.194153  |    0.090830     |   0\n",
      "      27143 |   0.151540  |    0.380444     |   1\n",
      "      27144 |   0.034568  |    0.128782     |   2\n",
      "      27145 |   0.261219  |    0.085624     |   0\n",
      "      27146 |   0.022604  |    0.059903     |   2\n",
      "      27147 |   0.180561  |    0.364691     |   1\n",
      "      27148 |   0.160670  |    0.147571     |   0\n",
      "      27149 |   0.217388  |    0.078179     |   0\n",
      "      27150 |   0.224598  |    0.360010     |   1\n",
      "      27151 |   0.164783  |    0.290580     |   1\n",
      "      27152 |   0.230993  |    0.394980     |   1\n",
      "      27153 |   0.000016  |    0.037842     |   2\n",
      "      27154 |   0.000016  |    0.128051     |   2\n",
      "      27155 |   0.000016  |    0.036614     |   2\n",
      "      27156 |   0.223706  |    0.144217     |   0\n",
      "      27157 |   0.000016  |    0.116936     |   2\n",
      "      27158 |   0.156437  |    0.074146     |   0\n",
      "      27159 |   0.000016  |    0.124475     |   2\n",
      "      27160 |   0.000016  |    0.036758     |   2\n",
      "      27161 |   0.041434  |    0.116445     |   2\n",
      "      27162 |   0.149248  |    0.394614     |   1\n",
      "      27163 |   0.045724  |    0.095144     |   2\n",
      "      27164 |   0.205872  |    0.112432     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 27165: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      27165 |   0.187838  |    0.124273     |   0\n",
      "      27166 |   0.043612  |    0.021283     |   2\n",
      "      27167 |   0.209093  |    0.114856     |   0\n",
      "      27168 |   0.031145  |    0.157733     |   2\n",
      "      27169 |   0.184542  |    0.342055     |   1\n",
      "      27170 |   0.166270  |    0.021566     |   0\n",
      "      27171 |   0.237678  |    0.343600     |   1\n",
      "      27172 |   0.184810  |    0.325548     |   1\n",
      "      27173 |   0.033534  |    0.056086     |   2\n",
      "      27174 |   0.280515  |    0.425404     |   1\n",
      "      27175 |   0.173735  |    0.077272     |   0\n",
      "      27176 |   0.185657  |    0.142736     |   0\n",
      "      27177 |   0.160274  |    0.036193     |   0\n",
      "      27178 |   0.033636  |    0.125825     |   2\n",
      "      27179 |   0.171985  |    0.036222     |   0\n",
      "      27180 |   0.025246  |    0.183307     |   2\n",
      "      27181 |   0.032916  |    0.070423     |   2\n",
      "      27182 |   0.228287  |    0.457504     |   1\n",
      "      27183 |   0.044674  |    0.143488     |   2\n",
      "      27184 |   0.249623  |    0.063485     |   0\n",
      "      27185 |   0.191788  |    0.099242     |   0\n",
      "      27186 |   0.048134  |    0.192730     |   2\n",
      "      27187 |   0.163080  |    0.020139     |   0\n",
      "      27188 |   0.221658  |    0.136477     |   0\n",
      "      27189 |   0.039977  |    0.121346     |   2\n",
      "      27190 |   0.183914  |    0.084430     |   0\n",
      "      27191 |   0.018373  |    0.146938     |   2\n",
      "      27192 |   0.000016  |    0.083126     |   2\n",
      "      27193 |   0.229872  |    0.441638     |   1\n",
      "      27194 |   0.004471  |    0.126803     |   2\n",
      "      27195 |   0.056806  |    0.073586     |   2\n",
      "      27196 |   0.031755  |    0.128191     |   2\n",
      "      27197 |   0.155855  |    0.498309     |   1\n",
      "      27198 |   0.170020  |    0.533564     |   1\n",
      "      27199 |   0.054484  |    0.078851     |   2\n",
      "      27200 |   0.037432  |    0.068998     |   2\n",
      "      27201 |   0.140450  |    0.090517     |   0\n",
      "      27202 |   0.219482  |    0.140651     |   0\n",
      "      27203 |   0.208301  |    0.460689     |   1\n",
      "      27204 |   0.144385  |    0.451730     |   1\n",
      "      27205 |   0.013681  |    0.094944     |   2\n",
      "      27206 |   0.033359  |    0.118726     |   2\n",
      "      27207 |   0.190073  |    0.158357     |   0\n",
      "      27208 |   0.023181  |    0.139652     |   2\n",
      "      27209 |   0.187893  |    0.437597     |   1\n",
      "      27210 |   0.169835  |    0.157963     |   0\n",
      "      27211 |   0.187722  |    0.454377     |   1\n",
      "      27212 |   0.000015  |    0.124020     |   2\n",
      "      27213 |   0.165345  |    0.037815     |   0\n",
      "      27214 |   0.160566  |    0.515254     |   1\n",
      "      27215 |   0.200798  |    0.473159     |   1\n",
      "      27216 |   0.154203  |    0.036020     |   0\n",
      "      27217 |   0.165795  |    0.188269     |   0\n",
      "      27218 |   0.180629  |    0.039820     |   0\n",
      "      27219 |   0.000015  |    0.114540     |   2\n",
      "      27220 |   0.000015  |    0.145556     |   2\n",
      "      27221 |   0.000016  |    0.156979     |   2\n",
      "      27222 |   0.120811  |    0.301574     |   1\n",
      "      27223 |   0.187947  |    0.094377     |   0\n",
      "      27224 |   0.149426  |    0.366420     |   1\n",
      "      27225 |   0.000015  |    0.120621     |   2\n",
      "      27226 |   0.000015  |    0.043929     |   2\n",
      "      27227 |   0.043035  |    0.111984     |   2\n",
      "      27228 |   0.175785  |    0.125649     |   0\n",
      "      27229 |   0.205377  |    0.290045     |   1\n",
      "      27230 |   0.046623  |    0.151720     |   2\n",
      "      27231 |   0.224648  |    0.276494     |   1\n",
      "      27232 |   0.173232  |    0.343519     |   1\n",
      "      27233 |   0.153402  |    0.081374     |   0\n",
      "      27234 |   0.150026  |    0.090263     |   0\n",
      "      27235 |   0.163087  |    0.426052     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 27236: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      27236 |   0.178454  |    0.073327     |   0\n",
      "      27237 |   0.121907  |    0.440316     |   1\n",
      "      27238 |   0.191449  |    0.324241     |   1\n",
      "      27239 |   0.045406  |    0.102833     |   2\n",
      "      27240 |   0.233461  |    0.365448     |   1\n",
      "      27241 |   0.153197  |    0.012561     |   0\n",
      "      27242 |   0.031545  |    0.142978     |   2\n",
      "      27243 |   0.172572  |    0.336018     |   1\n",
      "      27244 |   0.034632  |    0.089783     |   2\n",
      "      27245 |   0.033872  |    0.083185     |   2\n",
      "      27246 |   0.185593  |    0.354769     |   1\n",
      "      27247 |   0.175946  |    0.314262     |   1\n",
      "      27248 |   0.025697  |    0.146080     |   2\n",
      "      27249 |   0.199154  |    0.307821     |   1\n",
      "      27250 |   0.212292  |    0.394560     |   1\n",
      "      27251 |   0.033075  |    0.016956     |   2\n",
      "      27252 |   0.043456  |    0.128224     |   2\n",
      "      27253 |   0.240463  |    0.158590     |   0\n",
      "      27254 |   0.166790  |    0.293803     |   1\n",
      "      27255 |   0.190806  |    0.328612     |   1\n",
      "      27256 |   0.206324  |    0.087230     |   0\n",
      "      27257 |   0.155193  |    0.442892     |   1\n",
      "      27258 |   0.171004  |    0.038292     |   0\n",
      "      27259 |   0.193226  |    0.134983     |   0\n",
      "      27260 |   0.047894  |    0.061837     |   2\n",
      "      27261 |   0.091802  |    0.089145     |   0\n",
      "      27262 |   0.174703  |    0.399698     |   1\n",
      "      27263 |   0.212916  |    0.074116     |   0\n",
      "      27264 |   0.140060  |    0.152477     |   0\n",
      "      27265 |   0.039015  |    0.042869     |   2\n",
      "      27266 |   0.148404  |    0.374327     |   1\n",
      "      27267 |   0.017649  |    0.133896     |   2\n",
      "      27268 |   0.000015  |    0.071949     |   2\n",
      "      27269 |   0.188161  |    0.150488     |   0\n",
      "      27270 |   0.172718  |    0.388992     |   1\n",
      "      27271 |   0.004685  |    0.020585     |   2\n",
      "      27272 |   0.053857  |    0.133383     |   2\n",
      "      27273 |   0.138107  |    0.323132     |   1\n",
      "      27274 |   0.280822  |    0.362830     |   1\n",
      "      27275 |   0.149529  |    0.355928     |   1\n",
      "      27276 |   0.029590  |    0.040391     |   2\n",
      "      27277 |   0.211664  |    0.437897     |   1\n",
      "      27278 |   0.187140  |    0.327776     |   1\n",
      "      27279 |   0.179921  |    0.073947     |   0\n",
      "      27280 |   0.056117  |    0.075540     |   2\n",
      "      27281 |   0.037143  |    0.120662     |   2\n",
      "      27282 |   0.172229  |    0.379614     |   1\n",
      "      27283 |   0.013287  |    0.021067     |   2\n",
      "      27284 |   0.031258  |    0.168702     |   2\n",
      "      27285 |   0.190246  |    0.315731     |   1\n",
      "      27286 |   0.159398  |    0.078782     |   0\n",
      "      27287 |   0.148901  |    0.407677     |   1\n",
      "      27288 |   0.194538  |    0.087703     |   0\n",
      "      27289 |   0.145449  |    0.076320     |   0\n",
      "      27290 |   0.172643  |    0.147684     |   0\n",
      "      27291 |   0.024043  |    0.040010     |   2\n",
      "      27292 | \u001b[94m  0.000015\u001b[0m  |    0.084568     |   2\n",
      "      27293 |   0.000015  |    0.149474     |   2\n",
      "      27294 |   0.180669  |    0.040325     |   0\n",
      "      27295 | \u001b[94m  0.000015\u001b[0m  |    0.115902     |   2\n",
      "      27296 |   0.000015  |    0.146987     |   2\n",
      "      27297 |   0.197174  |    0.320389     |   1\n",
      "      27298 |   0.212714  |    0.360058     |   1\n",
      "      27299 |   0.111135  |    0.021601     |   0\n",
      "      27300 |   0.277715  |    0.347256     |   1\n",
      "      27301 |   0.205700  |    0.127136     |   0\n",
      "      27302 |   0.127650  |    0.370551     |   1\n",
      "      27303 | \u001b[94m  0.000015\u001b[0m  |    0.063863     |   2\n",
      "      27304 |   0.150022  |    0.391930     |   1\n",
      "      27305 |   0.142883  |    0.363332     |   1\n",
      "      27306 | \u001b[94m  0.000015\u001b[0m  |    0.122262     |   2\n",
      "      27307 |   0.142822  |    0.006118     |   0\n",
      "      27308 |   0.043889  |    0.143082     |   2\n",
      "      27309 |   0.207856  |    0.338085     |   1\n",
      "      27310 |   0.137718  |    0.086801     |   0\n",
      "      27311 |   0.159803  |    0.091651     |   0\n",
      "      27312 |   0.126640  |    0.106988     |   0\n",
      "      27313 |   0.044832  |    0.125507     |   2\n",
      "      27314 |   0.218482  |    0.061170     |   0\n",
      "      27315 |   0.181390  |    0.088232     |   0\n",
      "      27316 |   0.139493  |    0.398149     |   1\n",
      "      27317 |   0.154099  |    0.327978     |   1\n",
      "      27318 |   0.198116  |    0.361053     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 27320: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      27319 |   0.140226  |    0.037424     |   0\n",
      "      27320 |   0.176085  |    0.116707     |   0\n",
      "      27321 |   0.171255  |    0.339560     |   1\n",
      "      27322 |   0.044552  |    0.130854     |   2\n",
      "      27323 |   0.149245  |    0.390200     |   1\n",
      "      27324 |   0.030177  |    0.070120     |   2\n",
      "      27325 |   0.190104  |    0.125077     |   0\n",
      "      27326 |   0.035910  |    0.040025     |   2\n",
      "      27327 |   0.214453  |    0.110213     |   0\n",
      "      27328 |   0.160483  |    0.395353     |   1\n",
      "      27329 |   0.140488  |    0.389816     |   1\n",
      "      27330 |   0.173129  |    0.328476     |   1\n",
      "      27331 |   0.167522  |    0.369459     |   1\n",
      "      27332 |   0.157103  |    0.349785     |   1\n",
      "      27333 |   0.177857  |    0.286133     |   1\n",
      "      27334 |   0.158041  |    0.341296     |   1\n",
      "      27335 |   0.203742  |    0.367869     |   1\n",
      "      27336 |   0.141137  |    0.344837     |   1\n",
      "      27337 |   0.224365  |    0.284506     |   1\n",
      "      27338 |   0.219613  |    0.126632     |   0\n",
      "      27339 |   0.195535  |    0.020949     |   0\n",
      "      27340 |   0.168903  |    0.135000     |   0\n",
      "      27341 |   0.200836  |    0.142301     |   0\n",
      "      27342 |   0.161423  |    0.020554     |   0\n",
      "      27343 |   0.204239  |    0.383265     |   1\n",
      "      27344 |   0.034019  |    0.090028     |   2\n",
      "      27345 |   0.024649  |    0.081398     |   2\n",
      "      27346 |   0.140312  |    0.121503     |   0\n",
      "      27347 |   0.164000  |    0.334498     |   1\n",
      "      27348 |   0.196818  |    0.087010     |   0\n",
      "      27349 |   0.191836  |    0.070516     |   0\n",
      "      27350 |   0.256805  |    0.355720     |   1\n",
      "      27351 |   0.202111  |    0.443843     |   1\n",
      "      27352 |   0.034314  |    0.191588     |   2\n",
      "      27353 |   0.153717  |    0.141590     |   0\n",
      "      27354 |   0.123746  |    0.139119     |   0\n",
      "      27355 |   0.182656  |    0.179489     |   0\n",
      "      27356 |   0.193338  |    0.080856     |   0\n",
      "      27357 |   0.047006  |    0.143810     |   2\n",
      "      27358 |   0.217238  |    0.390171     |   1\n",
      "      27359 |   0.149889  |    0.338187     |   1\n",
      "      27360 |   0.047704  |    0.098422     |   2\n",
      "      27361 |   0.250962  |    0.429296     |   1\n",
      "      27362 |   0.040674  |    0.098857     |   2\n",
      "      27363 |   0.195748  |    0.056538     |   0\n",
      "      27364 |   0.199457  |    0.397203     |   1\n",
      "      27365 |   0.185724  |    0.146356     |   0\n",
      "      27366 |   0.019693  |    0.090214     |   2\n",
      "      27367 | \u001b[94m  0.000015\u001b[0m  |    0.100806     |   2\n",
      "      27368 |   0.004941  |    0.089612     |   2\n",
      "      27369 |   0.056151  |    0.106636     |   2\n",
      "      27370 |   0.175235  |    0.293037     |   1\n",
      "      27371 |   0.171252  |    0.284617     |   1\n",
      "      27372 |   0.166638  |    0.053001     |   0\n",
      "      27373 |   0.030954  |    0.086912     |   2\n",
      "      27374 |   0.155405  |    0.279891     |   1\n",
      "      27375 |   0.057075  |    0.013297     |   2\n",
      "      27376 |   0.152335  |    0.101107     |   0\n",
      "      27377 |   0.189950  |    0.246022     |   1\n",
      "      27378 |   0.037328  |    0.053557     |   2\n",
      "      27379 |   0.178565  |    0.105142     |   0\n",
      "      27380 |   0.186236  |    0.235138     |   1\n",
      "      27381 |   0.187645  |    0.033839     |   0\n",
      "      27382 |   0.263074  |    0.234797     |   1\n",
      "      27383 |   0.183526  |    0.075758     |   0\n",
      "      27384 |   0.200060  |    0.298636     |   1\n",
      "      27385 |   0.013487  |    0.045504     |   2\n",
      "      27386 |   0.156140  |    0.138671     |   0\n",
      "      27387 |   0.193354  |    0.211137     |   1\n",
      "      27388 |   0.177303  |    0.041073     |   0\n",
      "      27389 |   0.190858  |    0.098977     |   0\n",
      "      27390 |   0.172967  |    0.102403     |   0\n",
      "      27391 |   0.173506  |    0.032479     |   0\n",
      "      27392 |   0.032967  |    0.119798     |   2\n",
      "      27393 |   0.024813  |    0.043994     |   2\n",
      "      27394 |   0.000016  |    0.099239     |   2\n",
      "      27395 |   0.000016  |    0.045719     |   2\n",
      "      27396 |   0.145642  |    0.096776     |   0\n",
      "      27397 |   0.165650  |    0.035749     |   0\n",
      "      27398 |   0.000016  |    0.076693     |   2\n",
      "      27399 |   0.000016  |    0.059791     |   2\n",
      "      27400 |   0.206334  |    0.056135     |   0\n",
      "      27401 |   0.196951  |    0.193354     |   1\n",
      "      27402 |   0.000016  |    0.062713     |   2\n",
      "      27403 |   0.201634  |    0.238338     |   1\n",
      "      27404 |   0.000015  |    0.025019     |   2\n",
      "      27405 |   0.202845  |    0.079830     |   0\n",
      "      27406 |   0.043485  |    0.028119     |   2\n",
      "      27407 |   0.176353  |    0.099234     |   0\n",
      "      27408 |   0.286675  |    0.163794     |   1\n",
      "      27409 |   0.046507  |    0.093440     |   2\n",
      "      27410 |   0.108940  |    0.022117     |   0\n",
      "      27411 |   0.195622  |    0.100015     |   0\n",
      "      27412 |   0.148574  |    0.181412     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 27413: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      27413 |   0.042603  |    0.046757     |   2\n",
      "      27414 |   0.030880  |    0.071132     |   2\n",
      "      27415 |   0.186277  |    0.016647     |   0\n",
      "      27416 |   0.193068  |    0.099778     |   0\n",
      "      27417 |   0.169211  |    0.236254     |   1\n",
      "      27418 |   0.164171  |    0.236854     |   1\n",
      "      27419 |   0.138368  |    0.218211     |   1\n",
      "      27420 |   0.034343  |    0.059891     |   2\n",
      "      27421 |   0.033916  |    0.070248     |   2\n",
      "      27422 |   0.024953  |    0.072819     |   2\n",
      "      27423 |   0.227875  |    0.160817     |   1\n",
      "      27424 |   0.031360  |    0.020015     |   2\n",
      "      27425 |   0.168283  |    0.254416     |   1\n",
      "      27426 |   0.044261  |    0.004208     |   2\n",
      "      27427 |   0.047603  |    0.099065     |   2\n",
      "      27428 |   0.037693  |    0.005097     |   2\n",
      "      27429 |   0.179027  |    0.066885     |   0\n",
      "      27430 |   0.017700  |    0.093623     |   2\n",
      "      27431 |   0.177430  |    0.198238     |   1\n",
      "      27432 |   0.174301  |    0.191405     |   1\n",
      "      27433 |   0.173848  |    0.203545     |   1\n",
      "      27434 |   0.000016  |    0.010233     |   2\n",
      "      27435 |   0.004473  |    0.049452     |   2\n",
      "      27436 |   0.201609  |    0.150971     |   1\n",
      "      27437 |   0.194926  |    0.226752     |   1\n",
      "      27438 |   0.191045  |    0.043801     |   0\n",
      "      27439 |   0.157596  |    0.078788     |   0\n",
      "      27440 |   0.055661  |    0.015705     |   2\n",
      "      27441 |   0.030797  |    0.089934     |   2\n",
      "      27442 |   0.052758  |    0.039515     |   2\n",
      "      27443 |   0.224855  |    0.063454     |   0\n",
      "      27444 |   0.166391  |    0.150004     |   1\n",
      "      27445 |   0.172403  |    0.042687     |   0\n",
      "      27446 |   0.173663  |    0.176758     |   1\n",
      "      27447 |   0.038620  |    0.047541     |   2\n",
      "      27448 |   0.149569  |    0.102755     |   0\n",
      "      27449 |   0.014057  |    0.043204     |   2\n",
      "      27450 |   0.030782  |    0.032956     |   2\n",
      "      27451 |   0.197791  |    0.244433     |   1\n",
      "      27452 |   0.220611  |    0.175092     |   1\n",
      "      27453 |   0.157814  |    0.244518     |   1\n",
      "      27454 |   0.023347  |    0.004849     |   2\n",
      "      27455 |   0.000015  |    0.073042     |   2\n",
      "      27456 |   0.000015  |    0.039160     |   2\n",
      "      27457 |   0.141109  |    0.038846     |   0\n",
      "      27458 |   0.000015  |    0.075712     |   2\n",
      "      27459 |   0.161434  |    0.039362     |   0\n",
      "      27460 |   0.206248  |    0.066401     |   0\n",
      "      27461 |   0.169490  |    0.084600     |   0\n",
      "      27462 |   0.179155  |    0.074901     |   0\n",
      "      27463 |   0.163122  |    0.192785     |   1\n",
      "      27464 |   0.000015  |    0.043680     |   2\n",
      "      27465 |   0.166701  |    0.105639     |   0\n",
      "      27466 |   0.000015  |    0.026869     |   2\n",
      "      27467 |   0.000015  |    0.052733     |   2\n",
      "      27468 |   0.042853  |    0.050915     |   2\n",
      "      27469 |   0.046583  |    0.059272     |   2\n",
      "      27470 |   0.243113  |    0.144938     |   1\n",
      "      27471 |   0.198374  |    0.152543     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 27472: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      27472 |   0.180999  |    0.147978     |   1\n",
      "      27473 |   0.165024  |    0.200120     |   1\n",
      "      27474 |   0.043837  |    0.080642     |   2\n",
      "      27475 |   0.191265  |    0.119178     |   0\n",
      "      27476 |   0.030536  |    0.070652     |   2\n",
      "      27477 |   0.034603  |    0.043477     |   2\n",
      "      27478 |   0.215211  |    0.226014     |   1\n",
      "      27479 |   0.179410  |    0.097528     |   0\n",
      "      27480 |   0.105616  |    0.329366     |   1\n",
      "      27481 |   0.168511  |    0.036477     |   0\n",
      "      27482 |   0.033290  |    0.076444     |   2\n",
      "      27483 |   0.024574  |    0.069108     |   2\n",
      "      27484 |   0.032430  |    0.098001     |   2\n",
      "      27485 |   0.187327  |    0.272349     |   1\n",
      "      27486 |   0.212165  |    0.036652     |   0\n",
      "      27487 |   0.041867  |    0.079135     |   2\n",
      "      27488 |   0.046984  |    0.097350     |   2\n",
      "      27489 |   0.206766  |    0.071040     |   0\n",
      "      27490 |   0.183050  |    0.289592     |   1\n",
      "      27491 |   0.230552  |    0.220696     |   1\n",
      "      27492 |   0.178044  |    0.278600     |   1\n",
      "      27493 |   0.038633  |    0.071071     |   2\n",
      "      27494 |   0.168101  |    0.282013     |   1\n",
      "      27495 |   0.017911  |    0.084128     |   2\n",
      "      27496 |   0.000016  |    0.078539     |   2\n",
      "      27497 |   0.190797  |    0.271180     |   1\n",
      "      27498 |   0.140350  |    0.352166     |   1\n",
      "      27499 |   0.004616  |    0.013737     |   2\n",
      "      27500 |   0.178732  |    0.069829     |   0\n",
      "      27501 |   0.268524  |    0.358112     |   1\n",
      "      27502 |   0.203357  |    0.103607     |   0\n",
      "      27503 |   0.039227  |    0.118227     |   2\n",
      "      27504 |   0.156765  |    0.092930     |   0\n",
      "      27505 |   0.167466  |    0.336121     |   1\n",
      "      27506 |   0.028496  |    0.073776     |   2\n",
      "      27507 |   0.034220  |    0.082611     |   2\n",
      "      27508 |   0.191670  |    0.141134     |   0\n",
      "      27509 |   0.034124  |    0.016703     |   2\n",
      "      27510 |   0.172084  |    0.351759     |   1\n",
      "      27511 |   0.207412  |    0.289602     |   1\n",
      "      27512 |   0.023635  |    0.088474     |   2\n",
      "      27513 |   0.033004  |    0.138692     |   2\n",
      "      27514 |   0.043803  |    0.056125     |   2\n",
      "      27515 |   0.175243  |    0.285370     |   1\n",
      "      27516 |   0.046330  |    0.071762     |   2\n",
      "      27517 |   0.162080  |    0.092767     |   0\n",
      "      27518 |   0.214484  |    0.098148     |   0\n",
      "      27519 |   0.138413  |    0.314846     |   1\n",
      "      27520 |   0.164407  |    0.290094     |   1\n",
      "      27521 |   0.152276  |    0.357522     |   1\n",
      "      27522 |   0.186072  |    0.134854     |   0\n",
      "      27523 |   0.154223  |    0.287935     |   1\n",
      "      27524 |   0.190784  |    0.021977     |   0\n",
      "      27525 |   0.037288  |    0.074766     |   2\n",
      "      27526 |   0.199862  |    0.133308     |   0\n",
      "      27527 |   0.017233  |    0.087369     |   2\n",
      "      27528 |   0.184811  |    0.305355     |   1\n",
      "      27529 |   0.000016  |    0.097886     |   2\n",
      "      27530 |   0.193133  |    0.068277     |   0\n",
      "      27531 |   0.209326  |    0.410283     |   1\n",
      "      27532 |   0.177265  |    0.090357     |   0\n",
      "      27533 |   0.004750  |    0.077387     |   2\n",
      "      27534 |   0.055753  |    0.079945     |   2\n",
      "      27535 |   0.149631  |    0.079356     |   0\n",
      "      27536 |   0.032171  |    0.129722     |   2\n",
      "      27537 |   0.179416  |    0.293305     |   1\n",
      "      27538 |   0.052461  |    0.020419     |   2\n",
      "      27539 |   0.216749  |    0.075970     |   0\n",
      "      27540 |   0.221358  |    0.103907     |   0\n",
      "      27541 |   0.040127  |    0.073399     |   2\n",
      "      27542 |   0.015398  |    0.041250     |   2\n",
      "      27543 |   0.184771  |    0.114581     |   0\n",
      "      27544 |   0.223231  |    0.283944     |   1\n",
      "      27545 |   0.032207  |    0.071314     |   2\n",
      "      27546 |   0.202514  |    0.094088     |   0\n",
      "      27547 |   0.156443  |    0.074804     |   0\n",
      "      27548 |   0.026834  |    0.096902     |   2\n",
      "      27549 |   0.186630  |    0.073641     |   0\n",
      "      27550 |   0.139992  |    0.398301     |   1\n",
      "      27551 |   0.174260  |    0.154100     |   0\n",
      "      27552 |   0.142154  |    0.417966     |   1\n",
      "      27553 |   0.000016  |    0.122583     |   2\n",
      "      27554 |   0.000016  |    0.069097     |   2\n",
      "      27555 |   0.000016  |    0.079632     |   2\n",
      "      27556 |   0.162767  |    0.036700     |   0\n",
      "      27557 |   0.000016  |    0.070865     |   2\n",
      "      27558 |   0.232573  |    0.332237     |   1\n",
      "      27559 |   0.122737  |    0.079960     |   0\n",
      "      27560 |   0.000016  |    0.119452     |   2\n",
      "      27561 |   0.000016  |    0.086635     |   2\n",
      "      27562 |   0.043221  |    0.073026     |   2\n",
      "      27563 |   0.046685  |    0.101772     |   2\n",
      "      27564 |   0.179071  |    0.312852     |   1\n",
      "      27565 |   0.108293  |    0.021460     |   0\n",
      "      27566 |   0.172996  |    0.371241     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 27567: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      27567 |   0.171935  |    0.038418     |   0\n",
      "      27568 |   0.040284  |    0.139916     |   2\n",
      "      27569 |   0.152822  |    0.036445     |   0\n",
      "      27570 |   0.181494  |    0.370961     |   1\n",
      "      27571 |   0.029279  |    0.046413     |   2\n",
      "      27572 |   0.034972  |    0.040335     |   2\n",
      "      27573 |   0.271773  |    0.275604     |   1\n",
      "      27574 |   0.163590  |    0.078006     |   0\n",
      "      27575 |   0.199074  |    0.075298     |   0\n",
      "      27576 |   0.151629  |    0.078226     |   0\n",
      "      27577 |   0.034793  |    0.072008     |   2\n",
      "      27578 |   0.198315  |    0.047601     |   0\n",
      "      27579 |   0.183378  |    0.126942     |   0\n",
      "      27580 |   0.024668  |    0.081418     |   2\n",
      "      27581 |   0.160058  |    0.046582     |   0\n",
      "      27582 |   0.158015  |    0.094542     |   0\n",
      "      27583 |   0.032907  |    0.069264     |   2\n",
      "      27584 |   0.141080  |    0.080110     |   0\n",
      "      27585 |   0.043399  |    0.070489     |   2\n",
      "      27586 |   0.176132  |    0.075923     |   0\n",
      "      27587 |   0.193576  |    0.091510     |   0\n",
      "      27588 |   0.049677  |    0.037639     |   2\n",
      "      27589 |   0.221820  |    0.284804     |   1\n",
      "      27590 |   0.157791  |    0.064173     |   0\n",
      "      27591 |   0.173035  |    0.072752     |   0\n",
      "      27592 |   0.166604  |    0.070296     |   0\n",
      "      27593 |   0.037308  |    0.160615     |   2\n",
      "      27594 |   0.147098  |    0.385981     |   1\n",
      "      27595 |   0.151019  |    0.121905     |   0\n",
      "      27596 |   0.195123  |    0.285753     |   1\n",
      "      27597 |   0.196785  |    0.395625     |   1\n",
      "      27598 |   0.169479  |    0.135182     |   0\n",
      "      27599 |   0.153649  |    0.093176     |   0\n",
      "      27600 |   0.154374  |    0.072267     |   0\n",
      "      27601 |   0.160535  |    0.126072     |   0\n",
      "      27602 |   0.167629  |    0.025636     |   0\n",
      "      27603 |   0.163923  |    0.119464     |   0\n",
      "      27604 |   0.185539  |    0.283639     |   1\n",
      "      27605 |   0.019641  |    0.071369     |   2\n",
      "      27606 |   0.234879  |    0.293251     |   1\n",
      "      27607 |   0.249935  |    0.289454     |   1\n",
      "      27608 |   0.000016  |    0.037489     |   2\n",
      "      27609 |   0.005316  |    0.144604     |   2\n",
      "      27610 |   0.161170  |    0.036614     |   0\n",
      "      27611 |   0.220376  |    0.072293     |   0\n",
      "      27612 |   0.053767  |    0.081923     |   2\n",
      "      27613 |   0.193675  |    0.327643     |   1\n",
      "      27614 |   0.201189  |    0.296117     |   1\n",
      "      27615 |   0.186464  |    0.106648     |   0\n",
      "      27616 |   0.243923  |    0.286531     |   1\n",
      "      27617 |   0.233933  |    0.324683     |   1\n",
      "      27618 |   0.136271  |    0.336675     |   1\n",
      "      27619 |   0.219505  |    0.414827     |   1\n",
      "      27620 |   0.179268  |    0.040043     |   0\n",
      "      27621 |   0.167939  |    0.161724     |   0\n",
      "      27622 |   0.181081  |    0.069852     |   0\n",
      "      27623 |   0.032330  |    0.083036     |   2\n",
      "      27624 |   0.199719  |    0.072222     |   0\n",
      "      27625 |   0.127725  |    0.447786     |   1\n",
      "      27626 |   0.113643  |    0.317656     |   1\n",
      "      27627 |   0.120363  |    0.259635     |   1\n",
      "      27628 |   0.052143  |    0.074338     |   2\n",
      "      27629 |   0.035053  |    0.154991     |   2\n",
      "      27630 |   0.184600  |    0.041933     |   0\n",
      "      27631 |   0.185312  |    0.069717     |   0\n",
      "      27632 |   0.168145  |    0.112510     |   0\n",
      "      27633 |   0.139016  |    0.370146     |   1\n",
      "      27634 |   0.168797  |    0.044785     |   0\n",
      "      27635 |   0.197562  |    0.081234     |   0\n",
      "      27636 |   0.013922  |    0.139508     |   2\n",
      "      27637 |   0.174339  |    0.093754     |   0\n",
      "      27638 |   0.186099  |    0.114405     |   0\n",
      "      27639 |   0.032512  |    0.157579     |   2\n",
      "      27640 |   0.024484  |    0.126938     |   2\n",
      "      27641 |   0.000015  |    0.130077     |   2\n",
      "      27642 |   0.000015  |    0.077010     |   2\n",
      "      27643 |   0.107611  |    0.150611     |   0\n",
      "      27644 |   0.000015  |    0.128706     |   2\n",
      "      27645 |   0.000016  |    0.099276     |   2\n",
      "      27646 |   0.286738  |    0.570264     |   1\n",
      "      27647 |   0.000015  |    0.143602     |   2\n",
      "      27648 |   0.000015  |    0.179104     |   2\n",
      "      27649 |   0.136553  |    0.465162     |   1\n",
      "      27650 |   0.169635  |    0.155346     |   0\n",
      "      27651 |   0.042486  |    0.146099     |   2\n",
      "      27652 |   0.209949  |    0.087347     |   0\n",
      "      27653 |   0.155737  |    0.132772     |   0\n",
      "      27654 |   0.045878  |    0.134683     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 27655: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      27655 |   0.173880  |    0.120217     |   0\n",
      "      27656 |   0.183064  |    0.101303     |   0\n",
      "      27657 |   0.043535  |    0.137368     |   2\n",
      "      27658 |   0.124783  |    0.095867     |   0\n",
      "      27659 |   0.030420  |    0.109002     |   2\n",
      "      27660 |   0.179740  |    0.401027     |   1\n",
      "      27661 |   0.205894  |    0.432323     |   1\n",
      "      27662 |   0.204957  |    0.284972     |   1\n",
      "      27663 |   0.036627  |    0.118162     |   2\n",
      "      27664 |   0.192411  |    0.115123     |   0\n",
      "      27665 |   0.145797  |    0.292824     |   1\n",
      "      27666 |   0.152371  |    0.088346     |   0\n",
      "      27667 |   0.158091  |    0.008957     |   0\n",
      "      27668 |   0.034260  |    0.171635     |   2\n",
      "      27669 |   0.201007  |    0.281840     |   1\n",
      "      27670 |   0.186955  |    0.504611     |   1\n",
      "      27671 |   0.024939  |    0.112820     |   2\n",
      "      27672 |   0.033370  |    0.069011     |   2\n",
      "      27673 |   0.199207  |    0.166128     |   0\n",
      "      27674 |   0.045873  |    0.067591     |   2\n",
      "      27675 |   0.047600  |    0.084399     |   2\n",
      "      27676 |   0.223903  |    0.372863     |   1\n",
      "      27677 |   0.201118  |    0.126377     |   0\n",
      "      27678 |   0.038312  |    0.082964     |   2\n",
      "      27679 |   0.270078  |    0.317478     |   1\n",
      "      27680 |   0.019601  |    0.111128     |   2\n",
      "      27681 |   0.160069  |    0.417485     |   1\n",
      "      27682 |   0.179397  |    0.302450     |   1\n",
      "      27683 |   0.175536  |    0.316131     |   1\n",
      "      27684 |   0.208359  |    0.452231     |   1\n",
      "      27685 |   0.205005  |    0.072198     |   0\n",
      "      27686 |   0.160960  |    0.393073     |   1\n",
      "      27687 |   0.112402  |    0.069412     |   0\n",
      "      27688 |   0.154171  |    0.078811     |   0\n",
      "      27689 |   0.000016  |    0.119050     |   2\n",
      "      27690 |   0.155476  |    0.094864     |   0\n",
      "      27691 |   0.232933  |    0.395393     |   1\n",
      "      27692 |   0.217761  |    0.068885     |   0\n",
      "      27693 |   0.173665  |    0.068763     |   0\n",
      "      27694 |   0.166356  |    0.084219     |   0\n",
      "      27695 |   0.005283  |    0.042683     |   2\n",
      "      27696 |   0.177124  |    0.072048     |   0\n",
      "      27697 |   0.055701  |    0.074681     |   2\n",
      "      27698 |   0.033743  |    0.070625     |   2\n",
      "      27699 |   0.251271  |    0.289986     |   1\n",
      "      27700 |   0.123729  |    0.368684     |   1\n",
      "      27701 |   0.053285  |    0.004274     |   2\n",
      "      27702 |   0.205908  |    0.081679     |   0\n",
      "      27703 |   0.246522  |    0.298822     |   1\n",
      "      27704 |   0.219728  |    0.406164     |   1\n",
      "      27705 |   0.181310  |    0.086902     |   0\n",
      "      27706 |   0.221734  |    0.322924     |   1\n",
      "      27707 |   0.166117  |    0.278170     |   1\n",
      "      27708 |   0.164434  |    0.320075     |   1\n",
      "      27709 |   0.039041  |    0.085593     |   2\n",
      "      27710 |   0.131821  |    0.128418     |   0\n",
      "      27711 |   0.180999  |    0.130500     |   0\n",
      "      27712 |   0.013809  |    0.010674     |   2\n",
      "      27713 |   0.161135  |    0.154429     |   0\n",
      "      27714 |   0.174283  |    0.328472     |   1\n",
      "      27715 |   0.186215  |    0.370464     |   1\n",
      "      27716 |   0.033552  |    0.136842     |   2\n",
      "      27717 |   0.025430  |    0.074254     |   2\n",
      "      27718 |   0.231297  |    0.330951     |   1\n",
      "      27719 |   0.185836  |    0.232778     |   1\n",
      "      27720 |   0.176511  |    0.212019     |   1\n",
      "      27721 |   0.163887  |    0.242687     |   1\n",
      "      27722 |   0.000016  |    0.039990     |   2\n",
      "      27723 |   0.177562  |    0.078218     |   0\n",
      "      27724 |   0.206148  |    0.073949     |   0\n",
      "      27725 |   0.205584  |    0.029945     |   0\n",
      "      27726 |   0.155705  |    0.238685     |   1\n",
      "      27727 |   0.190612  |    0.250256     |   1\n",
      "      27728 |   0.154402  |    0.192633     |   1\n",
      "      27729 |   0.205594  |    0.043254     |   0\n",
      "      27730 |   0.000016  |    0.049209     |   2\n",
      "      27731 |   0.000015  |    0.114548     |   2\n",
      "      27732 |   0.218743  |    0.187692     |   1\n",
      "      27733 |   0.000016  |    0.020158     |   2\n",
      "      27734 |   0.153021  |    0.284086     |   1\n",
      "      27735 |   0.000015  |    0.038823     |   2\n",
      "      27736 |   0.000015  |    0.099577     |   2\n",
      "      27737 |   0.162747  |    0.041221     |   0\n",
      "      27738 |   0.042772  |    0.127397     |   2\n",
      "      27739 |   0.188022  |    0.098359     |   1\n",
      "      27740 |   0.137724  |    0.084315     |   0\n",
      "      27741 |   0.182810  |    0.175850     |   1\n",
      "      27742 |   0.044971  |    0.048904     |   2\n",
      "      27743 |   0.153758  |    0.058593     |   0\n",
      "      27744 |   0.160383  |    0.090726     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 27745: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      27745 |   0.154273  |    0.185721     |   1\n",
      "      27746 |   0.222652  |    0.306544     |   1\n",
      "      27747 |   0.168713  |    0.225703     |   1\n",
      "      27748 |   0.149386  |    0.310014     |   1\n",
      "      27749 |   0.044082  |    0.070030     |   2\n",
      "      27750 |   0.187820  |    0.282830     |   1\n",
      "      27751 |   0.032221  |    0.092012     |   2\n",
      "      27752 |   0.036153  |    0.076290     |   2\n",
      "      27753 |   0.034989  |    0.073109     |   2\n",
      "      27754 |   0.167569  |    0.295806     |   1\n",
      "      27755 |   0.195829  |    0.092690     |   0\n",
      "      27756 |   0.024644  |    0.088861     |   2\n",
      "      27757 |   0.184497  |    0.071659     |   0\n",
      "      27758 |   0.229676  |    0.346476     |   1\n",
      "      27759 |   0.212816  |    0.073973     |   0\n",
      "      27760 |   0.203299  |    0.090150     |   0\n",
      "      27761 |   0.142321  |    0.428732     |   1\n",
      "      27762 |   0.251274  |    0.331909     |   1\n",
      "      27763 |   0.033187  |    0.087073     |   2\n",
      "      27764 |   0.048736  |    0.113839     |   2\n",
      "      27765 |   0.149154  |    0.375538     |   1\n",
      "      27766 |   0.162308  |    0.036685     |   0\n",
      "      27767 |   0.051740  |    0.156429     |   2\n",
      "      27768 |   0.039551  |    0.039297     |   2\n",
      "      27769 |   0.202253  |    0.434286     |   1\n",
      "      27770 |   0.148142  |    0.031932     |   0\n",
      "      27771 |   0.141276  |    0.119714     |   0\n",
      "      27772 |   0.227567  |    0.345824     |   1\n",
      "      27773 |   0.182543  |    0.337111     |   1\n",
      "      27774 |   0.210617  |    0.356057     |   1\n",
      "      27775 |   0.020731  |    0.069458     |   2\n",
      "      27776 |   0.000015  |    0.119551     |   2\n",
      "      27777 |   0.004390  |    0.099236     |   2\n",
      "      27778 |   0.054858  |    0.042127     |   2\n",
      "      27779 |   0.031191  |    0.119909     |   2\n",
      "      27780 |   0.162080  |    0.045262     |   0\n",
      "      27781 |   0.195177  |    0.069345     |   0\n",
      "      27782 |   0.051481  |    0.150658     |   2\n",
      "      27783 |   0.181296  |    0.031125     |   0\n",
      "      27784 |   0.192150  |    0.317810     |   1\n",
      "      27785 |   0.240246  |    0.343786     |   1\n",
      "      27786 |   0.150906  |    0.343978     |   1\n",
      "      27787 |   0.036686  |    0.096904     |   2\n",
      "      27788 |   0.012331  |    0.068789     |   2\n",
      "      27789 |   0.031396  |    0.070077     |   2\n",
      "      27790 |   0.170528  |    0.096927     |   0\n",
      "      27791 |   0.024329  |    0.140357     |   2\n",
      "      27792 | \u001b[94m  0.000015\u001b[0m  |    0.023753     |   2\n",
      "      27793 |   0.230194  |    0.134112     |   0\n",
      "      27794 |   0.206628  |    0.066498     |   0\n",
      "      27795 | \u001b[94m  0.000015\u001b[0m  |    0.070594     |   2\n",
      "      27796 |   0.181890  |    0.071475     |   0\n",
      "      27797 |   0.149071  |    0.318791     |   1\n",
      "      27798 | \u001b[94m  0.000015\u001b[0m  |    0.073309     |   2\n",
      "      27799 |   0.158662  |    0.279189     |   1\n",
      "      27800 |   0.197566  |    0.294489     |   1\n",
      "      27801 |   0.000015  |    0.069259     |   2\n",
      "      27802 | \u001b[94m  0.000015\u001b[0m  |    0.091634     |   2\n",
      "      27803 |   0.127755  |    0.074111     |   0\n",
      "      27804 |   0.193597  |    0.069232     |   0\n",
      "      27805 |   0.195750  |    0.130748     |   0\n",
      "      27806 | \u001b[94m  0.000015\u001b[0m  |    0.042840     |   2\n",
      "      27807 |   0.041119  |    0.133300     |   2\n",
      "      27808 |   0.192314  |    0.083603     |   0\n",
      "      27809 |   0.163591  |    0.341358     |   1\n",
      "      27810 |   0.044564  |    0.024670     |   2\n",
      "      27811 |   0.177437  |    0.070360     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 27812: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      27812 |   0.040158  |    0.130608     |   2\n",
      "      27813 |   0.164588  |    0.256584     |   1\n",
      "      27814 |   0.136829  |    0.038588     |   0\n",
      "      27815 |   0.149314  |    0.153765     |   0\n",
      "      27816 |   0.030554  |    0.006882     |   2\n",
      "      27817 |   0.035386  |    0.134989     |   2\n",
      "      27818 |   0.172862  |    0.072641     |   0\n",
      "      27819 |   0.250786  |    0.296157     |   1\n",
      "      27820 |   0.034721  |    0.158113     |   2\n",
      "      27821 |   0.184231  |    0.237706     |   1\n",
      "      27822 |   0.167714  |    0.120417     |   0\n",
      "      27823 |   0.172364  |    0.293601     |   1\n",
      "      27824 |   0.025574  |    0.156904     |   2\n",
      "      27825 |   0.141509  |    0.312766     |   1\n",
      "      27826 |   0.175491  |    0.435732     |   1\n",
      "      27827 |   0.219559  |    0.259880     |   1\n",
      "      27828 |   0.033199  |    0.053864     |   2\n",
      "      27829 |   0.047388  |    0.070566     |   2\n",
      "      27830 |   0.164086  |    0.294169     |   1\n",
      "      27831 |   0.049785  |    0.099846     |   2\n",
      "      27832 |   0.148440  |    0.293548     |   1\n",
      "      27833 |   0.040259  |    0.037494     |   2\n",
      "      27834 |   0.182281  |    0.304721     |   1\n",
      "      27835 |   0.156493  |    0.040761     |   0\n",
      "      27836 |   0.016224  |    0.093635     |   2\n",
      "      27837 |   0.213626  |    0.080890     |   0\n",
      "      27838 |   0.000015  |    0.095271     |   2\n",
      "      27839 |   0.004355  |    0.069683     |   2\n",
      "      27840 |   0.160462  |    0.270378     |   1\n",
      "      27841 |   0.144883  |    0.275074     |   1\n",
      "      27842 |   0.054204  |    0.089763     |   2\n",
      "      27843 |   0.031389  |    0.128316     |   2\n",
      "      27844 |   0.051986  |    0.020813     |   2\n",
      "      27845 |   0.201730  |    0.068703     |   0\n",
      "      27846 |   0.137224  |    0.068598     |   0\n",
      "      27847 |   0.038519  |    0.042612     |   2\n",
      "      27848 |   0.013340  |    0.070558     |   2\n",
      "      27849 |   0.168545  |    0.080275     |   0\n",
      "      27850 |   0.152522  |    0.038715     |   0\n",
      "      27851 |   0.182067  |    0.317758     |   1\n",
      "      27852 |   0.224984  |    0.043925     |   0\n",
      "      27853 |   0.202226  |    0.306466     |   1\n",
      "      27854 |   0.166234  |    0.072871     |   0\n",
      "      27855 |   0.032864  |    0.041102     |   2\n",
      "      27856 |   0.025054  |    0.096042     |   2\n",
      "      27857 |   0.220501  |    0.297085     |   1\n",
      "      27858 |   0.164190  |    0.078693     |   0\n",
      "      27859 |   0.154441  |    0.381087     |   1\n",
      "      27860 |   0.187570  |    0.277652     |   1\n",
      "      27861 |   0.000015  |    0.043197     |   2\n",
      "      27862 |   0.000015  |    0.082699     |   2\n",
      "      27863 |   0.000015  |    0.092521     |   2\n",
      "      27864 |   0.204930  |    0.273657     |   1\n",
      "      27865 |   0.000015  |    0.092634     |   2\n",
      "      27866 |   0.147506  |    0.275874     |   1\n",
      "      27867 |   0.000015  |    0.037617     |   2\n",
      "      27868 |   0.170476  |    0.293476     |   1\n",
      "      27869 |   0.167156  |    0.357856     |   1\n",
      "      27870 |   0.000015  |    0.038862     |   2\n",
      "      27871 |   0.199171  |    0.257566     |   1\n",
      "      27872 |   0.201662  |    0.269493     |   1\n",
      "      27873 |   0.232765  |    0.274435     |   1\n",
      "      27874 |   0.145726  |    0.083052     |   0\n",
      "      27875 |   0.166245  |    0.075745     |   0\n",
      "      27876 |   0.039305  |    0.097794     |   2\n",
      "      27877 |   0.219534  |    0.276458     |   1\n",
      "      27878 |   0.157072  |    0.322881     |   1\n",
      "      27879 |   0.044115  |    0.099608     |   2\n",
      "      27880 |   0.153254  |    0.180068     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 27881: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      27881 |   0.191736  |    0.355923     |   1\n",
      "      27882 |   0.038093  |    0.213040     |   2\n",
      "      27883 |   0.200538  |    0.307981     |   1\n",
      "      27884 |   0.211411  |    0.293054     |   1\n",
      "      27885 |   0.157511  |    0.041614     |   0\n",
      "      27886 |   0.028581  |    0.110333     |   2\n",
      "      27887 |   0.184154  |    0.327619     |   1\n",
      "      27888 |   0.136299  |    0.340804     |   1\n",
      "      27889 |   0.200364  |    0.290462     |   1\n",
      "      27890 |   0.220836  |    0.041982     |   0\n",
      "      27891 |   0.033676  |    0.163814     |   2\n",
      "      27892 |   0.154020  |    0.155601     |   0\n",
      "      27893 |   0.035669  |    0.076140     |   2\n",
      "      27894 |   0.154418  |    0.190812     |   0\n",
      "      27895 |   0.166993  |    0.529766     |   1\n",
      "      27896 |   0.167724  |    0.011888     |   0\n",
      "      27897 |   0.175411  |    0.144000     |   0\n",
      "      27898 |   0.186366  |    0.183999     |   0\n",
      "      27899 |   0.197407  |    0.136193     |   0\n",
      "      27900 |   0.197398  |    0.146716     |   0\n",
      "      27901 |   0.025458  |    0.093020     |   2\n",
      "      27902 |   0.205738  |    0.575347     |   1\n",
      "      27903 |   0.129879  |    0.443871     |   1\n",
      "      27904 |   0.245869  |    0.292806     |   1\n",
      "      27905 |   0.032325  |    0.198360     |   2\n",
      "      27906 |   0.229956  |    0.375541     |   1\n",
      "      27907 |   0.050270  |    0.152740     |   2\n",
      "      27908 |   0.224451  |    0.135317     |   0\n",
      "      27909 |   0.047158  |    0.152201     |   2\n",
      "      27910 |   0.239821  |    0.448499     |   1\n",
      "      27911 |   0.037254  |    0.149218     |   2\n",
      "      27912 |   0.225515  |    0.428887     |   1\n",
      "      27913 |   0.016996  |    0.134328     |   2\n",
      "      27914 |   0.140248  |    0.131647     |   0\n",
      "      27915 |   0.170228  |    0.189107     |   0\n",
      "      27916 |   0.147019  |    0.126230     |   0\n",
      "      27917 |   0.209926  |    0.140345     |   0\n",
      "      27918 |   0.155238  |    0.148080     |   0\n",
      "      27919 |   0.000015  |    0.140095     |   2\n",
      "      27920 |   0.160197  |    0.120920     |   0\n",
      "      27921 |   0.146068  |    0.193912     |   0\n",
      "      27922 |   0.191318  |    0.193522     |   0\n",
      "      27923 |   0.122549  |    0.615323     |   1\n",
      "      27924 |   0.154042  |    0.567828     |   1\n",
      "      27925 |   0.004621  |    0.189951     |   2\n",
      "      27926 |   0.133349  |    0.581351     |   1\n",
      "      27927 |   0.186058  |    0.512276     |   1\n",
      "      27928 |   0.195210  |    0.133470     |   0\n",
      "      27929 |   0.056063  |    0.177011     |   2\n",
      "      27930 |   0.032319  |    0.204679     |   2\n",
      "      27931 |   0.163314  |    0.045966     |   0\n",
      "      27932 |   0.053078  |    0.141372     |   2\n",
      "      27933 |   0.134594  |    0.341001     |   1\n",
      "      27934 |   0.037569  |    0.128426     |   2\n",
      "      27935 |   0.179977  |    0.087121     |   0\n",
      "      27936 |   0.185842  |    0.290904     |   1\n",
      "      27937 |   0.173372  |    0.534599     |   1\n",
      "      27938 |   0.204882  |    0.188095     |   0\n",
      "      27939 |   0.170746  |    0.143393     |   0\n",
      "      27940 |   0.183286  |    0.102181     |   0\n",
      "      27941 |   0.015150  |    0.110063     |   2\n",
      "      27942 |   0.142253  |    0.142570     |   0\n",
      "      27943 |   0.032349  |    0.111583     |   2\n",
      "      27944 |   0.024082  |    0.156190     |   2\n",
      "      27945 |   0.190698  |    0.475623     |   1\n",
      "      27946 |   0.154971  |    0.403690     |   1\n",
      "      27947 |   0.000015  |    0.148942     |   2\n",
      "      27948 |   0.000016  |    0.046750     |   2\n",
      "      27949 |   0.000016  |    0.098580     |   2\n",
      "      27950 |   0.131551  |    0.425203     |   1\n",
      "      27951 |   0.205161  |    0.437821     |   1\n",
      "      27952 |   0.194356  |    0.138718     |   0\n",
      "      27953 |   0.000016  |    0.113933     |   2\n",
      "      27954 |   0.156740  |    0.083549     |   0\n",
      "      27955 |   0.206898  |    0.187663     |   0\n",
      "      27956 |   0.224726  |    0.140119     |   0\n",
      "      27957 |   0.139997  |    0.143452     |   0\n",
      "      27958 |   0.213214  |    0.105329     |   0\n",
      "      27959 |   0.188487  |    0.181368     |   0\n",
      "      27960 |   0.175190  |    0.622504     |   1\n",
      "      27961 |   0.000015  |    0.184158     |   2\n",
      "      27962 |   0.184824  |    0.571779     |   1\n",
      "      27963 |   0.180602  |    0.200276     |   0\n",
      "      27964 |   0.215859  |    0.144190     |   0\n",
      "      27965 |   0.000015  |    0.176952     |   2\n",
      "      27966 |   0.154660  |    0.526737     |   1\n",
      "      27967 |   0.276892  |    0.494576     |   1\n",
      "      27968 |   0.131839  |    0.191414     |   0\n",
      "      27969 |   0.042982  |    0.127421     |   2\n",
      "      27970 |   0.045573  |    0.143426     |   2\n",
      "      27971 |   0.158500  |    0.127019     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 27972: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      27972 |   0.174717  |    0.847571     |   1\n",
      "      27973 |   0.043846  |    0.186405     |   2\n",
      "      27974 |   0.030940  |    0.338105     |   2\n",
      "      27975 |   0.034935  |    0.132812     |   2\n",
      "      27976 |   0.148919  |    0.175930     |   0\n",
      "      27977 |   0.118471  |    0.053193     |   0\n",
      "      27978 |   0.034215  |    0.095553     |   2\n",
      "      27979 |   0.024551  |    0.191529     |   2\n",
      "      27980 |   0.245860  |    0.345066     |   1\n",
      "      27981 |   0.148616  |    0.199453     |   0\n",
      "      27982 |   0.032876  |    0.153958     |   2\n",
      "      27983 |   0.049841  |    0.141855     |   2\n",
      "      27984 |   0.184015  |    0.137804     |   0\n",
      "      27985 |   0.160929  |    0.179759     |   0\n",
      "      27986 |   0.046619  |    0.088393     |   2\n",
      "      27987 |   0.172330  |    0.191263     |   0\n",
      "      27988 |   0.040301  |    0.137410     |   2\n",
      "      27989 |   0.235198  |    0.773854     |   1\n",
      "      27990 |   0.175030  |    0.435817     |   1\n",
      "      27991 |   0.017522  |    0.182663     |   2\n",
      "      27992 |   0.000016  |    0.059744     |   2\n",
      "      27993 |   0.004088  |    0.164626     |   2\n",
      "      27994 |   0.129533  |    0.050535     |   0\n",
      "      27995 |   0.056553  |    0.095033     |   2\n",
      "      27996 |   0.223378  |    0.091007     |   0\n",
      "      27997 |   0.217789  |    0.139071     |   0\n",
      "      27998 |   0.033318  |    0.095794     |   2\n",
      "      27999 |   0.149720  |    0.183819     |   0\n",
      "      28000 |   0.053123  |    0.152379     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 28000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 28000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      28001 |   0.042742  |    0.081062     |   2\n",
      "      28002 |   0.126178  |    0.018894     |   0\n",
      "      28003 |   0.030110  |    0.082153     |   2\n",
      "      28004 |   0.034365  |    0.016794     |   2\n",
      "      28005 |   0.151281  |    0.083591     |   0\n",
      "      28006 |   0.217471  |    0.145543     |   1\n",
      "      28007 |   0.032887  |    0.075024     |   2\n",
      "      28008 |   0.024101  |    0.039161     |   2\n",
      "      28009 |   0.218943  |    0.193969     |   1\n",
      "      28010 |   0.034624  |    0.004138     |   2\n",
      "      28011 |   0.043800  |    0.077307     |   2\n",
      "      28012 |   0.205460  |    0.193071     |   1\n",
      "      28013 |   0.160069  |    0.187625     |   1\n",
      "      28014 |   0.161123  |    0.004514     |   0\n",
      "      28015 |   0.183181  |    0.207995     |   1\n",
      "      28016 |   0.047395  |    0.025943     |   2\n",
      "      28017 |   0.134847  |    0.149069     |   1\n",
      "      28018 |   0.039825  |    0.023639     |   2\n",
      "      28019 |   0.018298  |    0.075612     |   2\n",
      "      28020 |   0.000016  |    0.025637     |   2\n",
      "      28021 |   0.004653  |    0.079851     |   2\n",
      "      28022 |   0.185503  |    0.163409     |   1\n",
      "      28023 |   0.167779  |    0.199446     |   1\n",
      "      28024 |   0.051174  |    0.014397     |   2\n",
      "      28025 |   0.141243  |    0.088196     |   0\n",
      "      28026 |   0.160918  |    0.146224     |   1\n",
      "      28027 |   0.182830  |    0.035026     |   0\n",
      "      28028 |   0.033502  |    0.074492     |   2\n",
      "      28029 |   0.171143  |    0.051990     |   0\n",
      "      28030 |   0.211859  |    0.213789     |   1\n",
      "      28031 |   0.192014  |    0.157262     |   1\n",
      "      28032 |   0.173607  |    0.010696     |   0\n",
      "      28033 |   0.052827  |    0.088143     |   2\n",
      "      28034 |   0.034151  |    0.027561     |   2\n",
      "      28035 |   0.190341  |    0.193460     |   1\n",
      "      28036 |   0.247172  |    0.124569     |   1\n",
      "      28037 |   0.144692  |    0.041850     |   0\n",
      "      28038 |   0.016343  |    0.077442     |   2\n",
      "      28039 |   0.178847  |    0.045601     |   0\n",
      "      28040 |   0.032090  |    0.049528     |   2\n",
      "      28041 |   0.182391  |    0.139483     |   1\n",
      "      28042 |   0.147751  |    0.035605     |   0\n",
      "      28043 |   0.201926  |    0.214322     |   1\n",
      "      28044 |   0.162413  |    0.149298     |   1\n",
      "      28045 |   0.177419  |    0.190322     |   1\n",
      "      28046 |   0.203491  |    0.030158     |   0\n",
      "      28047 |   0.159314  |    0.186908     |   1\n",
      "      28048 |   0.164442  |    0.025396     |   0\n",
      "      28049 |   0.185483  |    0.074786     |   0\n",
      "      28050 |   0.159097  |    0.026736     |   0\n",
      "      28051 |   0.201155  |    0.195479     |   1\n",
      "      28052 |   0.212075  |    0.161677     |   1\n",
      "      28053 |   0.219766  |    0.197063     |   1\n",
      "      28054 |   0.024310  |    0.003659     |   2\n",
      "      28055 |   0.000016  |    0.070522     |   2\n",
      "      28056 |   0.191958  |    0.050347     |   0\n",
      "      28057 |   0.201082  |    0.152094     |   1\n",
      "      28058 |   0.000016  |    0.022312     |   2\n",
      "      28059 |   0.217521  |    0.081289     |   0\n",
      "      28060 |   0.160390  |    0.139883     |   1\n",
      "      28061 |   0.156932  |    0.051875     |   0\n",
      "      28062 |   0.174924  |    0.156123     |   1\n",
      "      28063 |   0.183319  |    0.183640     |   1\n",
      "      28064 |   0.158648  |    0.004401     |   0\n",
      "      28065 |   0.183034  |    0.190254     |   1\n",
      "      28066 |   0.162046  |    0.078744     |   0\n",
      "      28067 |   0.000016  |    0.016776     |   2\n",
      "      28068 |   0.000016  |    0.076053     |   2\n",
      "      28069 |   0.156977  |    0.029318     |   0\n",
      "      28070 |   0.176949  |    0.077558     |   0\n",
      "      28071 |   0.000015  |    0.009527     |   2\n",
      "      28072 |   0.169146  |    0.084353     |   0\n",
      "      28073 |   0.000015  |    0.046334     |   2\n",
      "      28074 |   0.040736  |    0.049814     |   2\n",
      "      28075 |   0.142545  |    0.188816     |   1\n",
      "      28076 |   0.044187  |    0.044841     |   2\n",
      "      28077 |   0.254782  |    0.048364     |   0\n",
      "      28078 |   0.177508  |    0.212120     |   1\n",
      "      28079 |   0.194872  |    0.003995     |   0\n",
      "      28080 |   0.158773  |    0.081929     |   0\n",
      "      28081 |   0.140074  |    0.036362     |   0\n",
      "      28082 |   0.176980  |    0.208549     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 28083: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      28083 |   0.172709  |    0.130468     |   1\n",
      "      28084 |   0.042379  |    0.050595     |   2\n",
      "      28085 |   0.144383  |    0.057555     |   0\n",
      "      28086 |   0.146884  |    0.076582     |   0\n",
      "      28087 |   0.170957  |    0.031547     |   0\n",
      "      28088 |   0.030292  |    0.079412     |   2\n",
      "      28089 |   0.034409  |    0.024719     |   2\n",
      "      28090 |   0.167451  |    0.073551     |   0\n",
      "      28091 |   0.144043  |    0.028471     |   0\n",
      "      28092 |   0.184837  |    0.081479     |   0\n",
      "      28093 |   0.032516  |    0.014983     |   2\n",
      "      28094 |   0.182111  |    0.078717     |   0\n",
      "      28095 |   0.024288  |    0.021001     |   2\n",
      "      28096 |   0.035077  |    0.080412     |   2\n",
      "      28097 |   0.053440  |    0.045566     |   2\n",
      "      28098 |   0.048328  |    0.042881     |   2\n",
      "      28099 |   0.166502  |    0.037936     |   0\n",
      "      28100 |   0.038925  |    0.074083     |   2\n",
      "      28101 |   0.153834  |    0.024089     |   0\n",
      "      28102 |   0.198348  |    0.074244     |   0\n",
      "      28103 |   0.016871  |    0.042880     |   2\n",
      "      28104 |   0.000015  |    0.048328     |   2\n",
      "      28105 |   0.206896  |    0.205020     |   1\n",
      "      28106 |   0.192503  |    0.022970     |   0\n",
      "      28107 |   0.004693  |    0.074345     |   2\n",
      "      28108 |   0.056356  |    0.039857     |   2\n",
      "      28109 |   0.197999  |    0.196655     |   1\n",
      "      28110 |   0.220877  |    0.139593     |   1\n",
      "      28111 |   0.149596  |    0.028586     |   0\n",
      "      28112 |   0.030356  |    0.080183     |   2\n",
      "      28113 |   0.188575  |    0.141507     |   1\n",
      "      28114 |   0.053338  |    0.023347     |   2\n",
      "      28115 |   0.239380  |    0.086591     |   0\n",
      "      28116 |   0.173975  |    0.041125     |   0\n",
      "      28117 |   0.036537  |    0.050713     |   2\n",
      "      28118 |   0.203591  |    0.038824     |   0\n",
      "      28119 |   0.188118  |    0.089790     |   0\n",
      "      28120 |   0.232660  |    0.141908     |   1\n",
      "      28121 |   0.015264  |    0.044400     |   2\n",
      "      28122 |   0.143889  |    0.154996     |   1\n",
      "      28123 |   0.031584  |    0.043291     |   2\n",
      "      28124 |   0.148831  |    0.203046     |   1\n",
      "      28125 |   0.205785  |    0.022801     |   0\n",
      "      28126 |   0.025425  |    0.073346     |   2\n",
      "      28127 |   0.000016  |    0.025804     |   2\n",
      "      28128 |   0.000016  |    0.080684     |   2\n",
      "      28129 |   0.199393  |    0.131849     |   1\n",
      "      28130 |   0.000016  |    0.048809     |   2\n",
      "      28131 |   0.236702  |    0.220741     |   1\n",
      "      28132 |   0.194988  |    0.141970     |   1\n",
      "      28133 |   0.194077  |    0.048799     |   0\n",
      "      28134 |   0.200744  |    0.069475     |   0\n",
      "      28135 |   0.176530  |    0.028580     |   0\n",
      "      28136 |   0.218439  |    0.079511     |   0\n",
      "      28137 |   0.000016  |    0.028480     |   2\n",
      "      28138 |   0.189802  |    0.085964     |   0\n",
      "      28139 |   0.000015  |    0.054771     |   2\n",
      "      28140 |   0.187282  |    0.081547     |   0\n",
      "      28141 |   0.178954  |    0.050999     |   0\n",
      "      28142 |   0.196918  |    0.147723     |   1\n",
      "      28143 |   0.174978  |    0.140991     |   1\n",
      "      28144 |   0.153800  |    0.076074     |   0\n",
      "      28145 |   0.000015  |    0.005834     |   2\n",
      "      28146 |   0.233857  |    0.194754     |   1\n",
      "      28147 |   0.042644  |    0.046804     |   2\n",
      "      28148 |   0.044968  |    0.048519     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 28149: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      28149 |   0.174775  |    0.154883     |   1\n",
      "      28150 |   0.179822  |    0.221229     |   1\n",
      "      28151 |   0.039145  |    0.009134     |   2\n",
      "      28152 |   0.027989  |    0.085130     |   2\n",
      "      28153 |   0.177159  |    0.027874     |   0\n",
      "      28154 |   0.145477  |    0.077740     |   0\n",
      "      28155 |   0.176573  |    0.155683     |   1\n",
      "      28156 |   0.190710  |    0.077938     |   0\n",
      "      28157 |   0.034316  |    0.022700     |   2\n",
      "      28158 |   0.229277  |    0.081252     |   0\n",
      "      28159 |   0.161310  |    0.013642     |   0\n",
      "      28160 |   0.160793  |    0.205988     |   1\n",
      "      28161 |   0.032675  |    0.043676     |   2\n",
      "      28162 |   0.169171  |    0.197660     |   1\n",
      "      28163 |   0.147667  |    0.161869     |   1\n",
      "      28164 |   0.202391  |    0.132839     |   1\n",
      "      28165 |   0.023622  |    0.010940     |   2\n",
      "      28166 |   0.162541  |    0.080600     |   0\n",
      "      28167 |   0.033600  |    0.032902     |   2\n",
      "      28168 |   0.145313  |    0.202419     |   1\n",
      "      28169 |   0.152614  |    0.030082     |   0\n",
      "      28170 |   0.173588  |    0.203721     |   1\n",
      "      28171 |   0.189429  |    0.167519     |   1\n",
      "      28172 |   0.043855  |    0.032926     |   2\n",
      "      28173 |   0.185776  |    0.081884     |   0\n",
      "      28174 |   0.199724  |    0.153684     |   1\n",
      "      28175 |   0.185896  |    0.159951     |   1\n",
      "      28176 |   0.046102  |    0.027278     |   2\n",
      "      28177 |   0.037956  |    0.071774     |   2\n",
      "      28178 |   0.016960  |    0.032543     |   2\n",
      "      28179 |   0.160456  |    0.186677     |   1\n",
      "      28180 |   0.234610  |    0.146382     |   1\n",
      "      28181 |   0.000016  |    0.016669     |   2\n",
      "      28182 |   0.171064  |    0.087624     |   0\n",
      "      28183 |   0.184563  |    0.029507     |   0\n",
      "      28184 |   0.168423  |    0.193871     |   1\n",
      "      28185 |   0.004962  |    0.081772     |   2\n",
      "      28186 |   0.210012  |    0.184537     |   1\n",
      "      28187 |   0.167037  |    0.152149     |   1\n",
      "      28188 |   0.200639  |    0.018074     |   0\n",
      "      28189 |   0.228914  |    0.082360     |   0\n",
      "      28190 |   0.213467  |    0.156700     |   1\n",
      "      28191 |   0.192006  |    0.136712     |   1\n",
      "      28192 |   0.183419  |    0.140584     |   1\n",
      "      28193 |   0.211404  |    0.083336     |   0\n",
      "      28194 |   0.174713  |    0.149758     |   1\n",
      "      28195 |   0.176470  |    0.084485     |   0\n",
      "      28196 |   0.197217  |    0.191401     |   1\n",
      "      28197 |   0.055132  |    0.005278     |   2\n",
      "      28198 |   0.230782  |    0.195259     |   1\n",
      "      28199 |   0.161173  |    0.032822     |   0\n",
      "      28200 |   0.179351  |    0.228366     |   1\n",
      "      28201 |   0.150798  |    0.214925     |   1\n",
      "      28202 |   0.135690  |    0.166931     |   1\n",
      "      28203 |   0.248121  |    0.153263     |   1\n",
      "      28204 |   0.031004  |    0.045960     |   2\n",
      "      28205 |   0.052825  |    0.076363     |   2\n",
      "      28206 |   0.177654  |    0.021980     |   0\n",
      "      28207 |   0.172329  |    0.089558     |   0\n",
      "      28208 |   0.183903  |    0.206517     |   1\n",
      "      28209 |   0.156380  |    0.148189     |   1\n",
      "      28210 |   0.035568  |    0.050037     |   2\n",
      "      28211 |   0.141379  |    0.045366     |   0\n",
      "      28212 |   0.155867  |    0.079469     |   0\n",
      "      28213 |   0.014138  |    0.037950     |   2\n",
      "      28214 |   0.030111  |    0.069712     |   2\n",
      "      28215 |   0.147533  |    0.075854     |   0\n",
      "      28216 |   0.025836  |    0.043918     |   2\n",
      "      28217 |   0.000016  |    0.081906     |   2\n",
      "      28218 |   0.179210  |    0.236255     |   1\n",
      "      28219 |   0.165020  |    0.127731     |   1\n",
      "      28220 |   0.161147  |    0.040161     |   0\n",
      "      28221 |   0.168050  |    0.086338     |   0\n",
      "      28222 |   0.216002  |    0.157610     |   1\n",
      "      28223 |   0.000016  |    0.048247     |   2\n",
      "      28224 |   0.195754  |    0.144251     |   1\n",
      "      28225 |   0.000016  |    0.050869     |   2\n",
      "      28226 |   0.000016  |    0.042621     |   2\n",
      "      28227 |   0.192958  |    0.047564     |   0\n",
      "      28228 |   0.135996  |    0.212467     |   1\n",
      "      28229 |   0.170201  |    0.025955     |   0\n",
      "      28230 |   0.000016  |    0.076786     |   2\n",
      "      28231 |   0.000016  |    0.053223     |   2\n",
      "      28232 |   0.040147  |    0.044625     |   2\n",
      "      28233 |   0.140015  |    0.076673     |   0\n",
      "      28234 |   0.045207  |    0.028133     |   2\n",
      "      28235 |   0.184855  |    0.075560     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 28236: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      28236 |   0.193762  |    0.037947     |   0\n",
      "      28237 |   0.144047  |    0.165121     |   1\n",
      "      28238 |   0.190466  |    0.175978     |   1\n",
      "      28239 |   0.185572  |    0.197956     |   1\n",
      "      28240 |   0.232483  |    0.146374     |   1\n",
      "      28241 |   0.036801  |    0.012077     |   2\n",
      "      28242 |   0.027045  |    0.087588     |   2\n",
      "      28243 |   0.033139  |    0.041382     |   2\n",
      "      28244 |   0.182796  |    0.041964     |   0\n",
      "      28245 |   0.034833  |    0.051316     |   2\n",
      "      28246 |   0.024581  |    0.059521     |   2\n",
      "      28247 |   0.032514  |    0.042452     |   2\n",
      "      28248 |   0.156608  |    0.192340     |   1\n",
      "      28249 |   0.129051  |    0.189603     |   1\n",
      "      28250 |   0.162688  |    0.152109     |   1\n",
      "      28251 |   0.213830  |    0.200356     |   1\n",
      "      28252 |   0.182857  |    0.124603     |   1\n",
      "      28253 |   0.046461  |    0.040331     |   2\n",
      "      28254 |   0.170740  |    0.185784     |   1\n",
      "      28255 |   0.166732  |    0.036892     |   0\n",
      "      28256 |   0.159255  |    0.047629     |   0\n",
      "      28257 |   0.149006  |    0.041610     |   0\n",
      "      28258 |   0.047654  |    0.077208     |   2\n",
      "      28259 |   0.176511  |    0.031179     |   0\n",
      "      28260 |   0.157482  |    0.193815     |   1\n",
      "      28261 |   0.162287  |    0.195238     |   1\n",
      "      28262 |   0.145754  |    0.004291     |   0\n",
      "      28263 |   0.037700  |    0.079928     |   2\n",
      "      28264 |   0.017642  |    0.041406     |   2\n",
      "      28265 |   0.187696  |    0.206374     |   1\n",
      "      28266 |   0.176771  |    0.154512     |   1\n",
      "      28267 |   0.000016  |    0.016958     |   2\n",
      "      28268 |   0.004152  |    0.080182     |   2\n",
      "      28269 |   0.054299  |    0.021807     |   2\n",
      "      28270 |   0.211958  |    0.081417     |   0\n",
      "      28271 |   0.194972  |    0.021906     |   0\n",
      "      28272 |   0.212604  |    0.079045     |   0\n",
      "      28273 |   0.031493  |    0.042802     |   2\n",
      "      28274 |   0.173943  |    0.042728     |   0\n",
      "      28275 |   0.180585  |    0.074222     |   0\n",
      "      28276 |   0.197261  |    0.025792     |   0\n",
      "      28277 |   0.175135  |    0.186606     |   1\n",
      "      28278 |   0.054182  |    0.045241     |   2\n",
      "      28279 |   0.173128  |    0.073288     |   0\n",
      "      28280 |   0.163704  |    0.197127     |   1\n",
      "      28281 |   0.159552  |    0.160716     |   1\n",
      "      28282 |   0.038355  |    0.022314     |   2\n",
      "      28283 |   0.015122  |    0.091888     |   2\n",
      "      28284 |   0.208274  |    0.151141     |   1\n",
      "      28285 |   0.032463  |    0.022583     |   2\n",
      "      28286 |   0.200813  |    0.059384     |   0\n",
      "      28287 |   0.219060  |    0.201152     |   1\n",
      "      28288 |   0.228000  |    0.145702     |   1\n",
      "      28289 |   0.157381  |    0.009880     |   0\n",
      "      28290 |   0.166967  |    0.208216     |   1\n",
      "      28291 |   0.160286  |    0.142430     |   1\n",
      "      28292 |   0.162484  |    0.040304     |   0\n",
      "      28293 |   0.154244  |    0.091425     |   0\n",
      "      28294 |   0.153715  |    0.144084     |   1\n",
      "      28295 |   0.166767  |    0.052018     |   0\n",
      "      28296 |   0.189912  |    0.045959     |   0\n",
      "      28297 |   0.233310  |    0.078195     |   0\n",
      "      28298 |   0.025288  |    0.013456     |   2\n",
      "      28299 |   0.000016  |    0.080487     |   2\n",
      "      28300 |   0.189364  |    0.137588     |   1\n",
      "      28301 |   0.143975  |    0.084615     |   0\n",
      "      28302 |   0.135495  |    0.006354     |   0\n",
      "      28303 |   0.175160  |    0.083579     |   0\n",
      "      28304 |   0.164326  |    0.028916     |   0\n",
      "      28305 |   0.167938  |    0.200875     |   1\n",
      "      28306 |   0.156542  |    0.044222     |   0\n",
      "      28307 |   0.000016  |    0.050013     |   2\n",
      "      28308 |   0.201754  |    0.143876     |   1\n",
      "      28309 |   0.175543  |    0.042907     |   0\n",
      "      28310 |   0.192699  |    0.078252     |   0\n",
      "      28311 |   0.211775  |    0.045086     |   0\n",
      "      28312 |   0.157944  |    0.086556     |   0\n",
      "      28313 |   0.133438  |    0.012877     |   0\n",
      "      28314 |   0.000015  |    0.077096     |   2\n",
      "      28315 |   0.000016  |    0.022242     |   2\n",
      "      28316 |   0.000015  |    0.060153     |   2\n",
      "      28317 |   0.174017  |    0.206490     |   1\n",
      "      28318 |   0.000015  |    0.007601     |   2\n",
      "      28319 |   0.173444  |    0.077806     |   0\n",
      "      28320 |   0.186025  |    0.156018     |   1\n",
      "      28321 |   0.044202  |    0.019319     |   2\n",
      "      28322 |   0.232512  |    0.202181     |   1\n",
      "      28323 |   0.045780  |    0.051556     |   2\n",
      "      28324 |   0.176603  |    0.044036     |   0\n",
      "      28325 |   0.148232  |    0.196926     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 28326: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      28326 |   0.217535  |    0.023366     |   0\n",
      "      28327 |   0.041912  |    0.045039     |   2\n",
      "      28328 |   0.172964  |    0.205869     |   1\n",
      "      28329 |   0.184997  |    0.006696     |   0\n",
      "      28330 |   0.029276  |    0.087856     |   2\n",
      "      28331 |   0.163160  |    0.155916     |   1\n",
      "      28332 |   0.034716  |    0.039515     |   2\n",
      "      28333 |   0.031402  |    0.076453     |   2\n",
      "      28334 |   0.179773  |    0.158240     |   1\n",
      "      28335 |   0.024514  |    0.048435     |   2\n",
      "      28336 |   0.034535  |    0.037955     |   2\n",
      "      28337 |   0.144534  |    0.222403     |   1\n",
      "      28338 |   0.045470  |    0.022435     |   2\n",
      "      28339 |   0.112697  |    0.063118     |   0\n",
      "      28340 |   0.047930  |    0.030148     |   2\n",
      "      28341 |   0.039046  |    0.067990     |   2\n",
      "      28342 |   0.172997  |    0.043116     |   0\n",
      "      28343 |   0.017453  |    0.050430     |   2\n",
      "      28344 |   0.156492  |    0.047118     |   0\n",
      "      28345 |   0.000016  |    0.044272     |   2\n",
      "      28346 |   0.185296  |    0.046350     |   0\n",
      "      28347 |   0.003992  |    0.072610     |   2\n",
      "      28348 |   0.160437  |    0.043529     |   0\n",
      "      28349 |   0.142430  |    0.207034     |   1\n",
      "      28350 |   0.160472  |    0.015700     |   0\n",
      "      28351 |   0.053043  |    0.074986     |   2\n",
      "      28352 |   0.165368  |    0.039388     |   0\n",
      "      28353 |   0.031410  |    0.073492     |   2\n",
      "      28354 |   0.052144  |    0.040073     |   2\n",
      "      28355 |   0.142862  |    0.046529     |   0\n",
      "      28356 |   0.039170  |    0.052831     |   2\n",
      "      28357 |   0.182186  |    0.234629     |   1\n",
      "      28358 |   0.163339  |    0.148655     |   1\n",
      "      28359 |   0.192255  |    0.011002     |   0\n",
      "      28360 |   0.199353  |    0.190915     |   1\n",
      "      28361 |   0.219146  |    0.151997     |   1\n",
      "      28362 |   0.206585  |    0.074763     |   0\n",
      "      28363 |   0.219837  |    0.041662     |   0\n",
      "      28364 |   0.191954  |    0.029276     |   0\n",
      "      28365 |   0.228331  |    0.079239     |   0\n",
      "      28366 |   0.155750  |    0.045738     |   0\n",
      "      28367 |   0.172060  |    0.046672     |   0\n",
      "      28368 |   0.212109  |    0.036540     |   0\n",
      "      28369 |   0.167987  |    0.075434     |   0\n",
      "      28370 |   0.015692  |    0.057067     |   2\n",
      "      28371 |   0.168822  |    0.161045     |   1\n",
      "      28372 |   0.154524  |    0.217241     |   1\n",
      "      28373 |   0.180391  |    0.048157     |   0\n",
      "      28374 |   0.223217  |    0.210222     |   1\n",
      "      28375 |   0.167953  |    0.005130     |   0\n",
      "      28376 |   0.205009  |    0.187671     |   1\n",
      "      28377 |   0.032408  |    0.054106     |   2\n",
      "      28378 |   0.023006  |    0.041802     |   2\n",
      "      28379 |   0.198760  |    0.039648     |   0\n",
      "      28380 |   0.236722  |    0.267842     |   1\n",
      "      28381 |   0.183667  |    0.186570     |   1\n",
      "      28382 |   0.190973  |    0.007758     |   0\n",
      "      28383 |   0.157086  |    0.085040     |   0\n",
      "      28384 |   0.171784  |    0.010646     |   0\n",
      "      28385 |   0.188238  |    0.076352     |   0\n",
      "      28386 |   0.000016  |    0.021532     |   2\n",
      "      28387 |   0.163794  |    0.079524     |   0\n",
      "      28388 |   0.209247  |    0.049356     |   0\n",
      "      28389 |   0.000016  |    0.045504     |   2\n",
      "      28390 |   0.156577  |    0.043031     |   0\n",
      "      28391 |   0.205510  |    0.247252     |   1\n",
      "      28392 |   0.173817  |    0.138378     |   1\n",
      "      28393 |   0.000016  |    0.030830     |   2\n",
      "      28394 |   0.231964  |    0.204379     |   1\n",
      "      28395 |   0.207162  |    0.036676     |   0\n",
      "      28396 |   0.215433  |    0.211656     |   1\n",
      "      28397 |   0.183915  |    0.161826     |   1\n",
      "      28398 |   0.155173  |    0.188367     |   1\n",
      "      28399 |   0.000016  |    0.005320     |   2\n",
      "      28400 |   0.000016  |    0.085436     |   2\n",
      "      28401 |   0.000016  |    0.029398     |   2\n",
      "      28402 |   0.041380  |    0.074027     |   2\n",
      "      28403 |   0.206328  |    0.139600     |   1\n",
      "      28404 |   0.043620  |    0.028767     |   2\n",
      "      28405 |   0.233526  |    0.197943     |   1\n",
      "      28406 |   0.227465  |    0.193677     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 28407: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      28407 |   0.221546  |    0.024994     |   0\n",
      "      28408 |   0.038930  |    0.041516     |   2\n",
      "      28409 |   0.172317  |    0.207090     |   1\n",
      "      28410 |   0.241412  |    0.143046     |   1\n",
      "      28411 |   0.212542  |    0.009137     |   0\n",
      "      28412 |   0.179569  |    0.200658     |   1\n",
      "      28413 |   0.134935  |    0.029657     |   0\n",
      "      28414 |   0.028601  |    0.092118     |   2\n",
      "      28415 |   0.118303  |    0.151235     |   1\n",
      "      28416 |   0.035621  |    0.043073     |   2\n",
      "      28417 |   0.164127  |    0.149883     |   1\n",
      "      28418 |   0.214282  |    0.205479     |   1\n",
      "      28419 |   0.206458  |    0.021890     |   0\n",
      "      28420 |   0.173549  |    0.195221     |   1\n",
      "      28421 |   0.033271  |    0.029527     |   2\n",
      "      28422 |   0.126965  |    0.081487     |   0\n",
      "      28423 |   0.171548  |    0.154608     |   1\n",
      "      28424 |   0.224826  |    0.136743     |   1\n",
      "      28425 |   0.024438  |    0.029968     |   2\n",
      "      28426 |   0.185892  |    0.183038     |   1\n",
      "      28427 |   0.206328  |    0.042296     |   0\n",
      "      28428 |   0.146491  |    0.043499     |   0\n",
      "      28429 |   0.206670  |    0.151509     |   1\n",
      "      28430 |   0.113406  |    0.203705     |   1\n",
      "      28431 |   0.128193  |    0.221522     |   1\n",
      "      28432 |   0.152830  |    0.181690     |   1\n",
      "      28433 |   0.202382  |    0.046493     |   0\n",
      "      28434 |   0.201260  |    0.079854     |   0\n",
      "      28435 |   0.145628  |    0.033255     |   0\n",
      "      28436 |   0.116089  |    0.190634     |   1\n",
      "      28437 |   0.173932  |    0.024924     |   0\n",
      "      28438 |   0.033247  |    0.052368     |   2\n",
      "      28439 |   0.191327  |    0.087337     |   0\n",
      "      28440 |   0.177065  |    0.153904     |   1\n",
      "      28441 |   0.041900  |    0.045071     |   2\n",
      "      28442 |   0.047014  |    0.039167     |   2\n",
      "      28443 |   0.039107  |    0.071974     |   2\n",
      "      28444 |   0.138958  |    0.147571     |   1\n",
      "      28445 |   0.189651  |    0.079881     |   0\n",
      "      28446 |   0.198616  |    0.029805     |   0\n",
      "      28447 |   0.181975  |    0.085099     |   0\n",
      "      28448 |   0.215142  |    0.198421     |   1\n",
      "      28449 |   0.018449  |    0.009326     |   2\n",
      "      28450 |   0.143431  |    0.078153     |   0\n",
      "      28451 |   0.000016  |    0.027358     |   2\n",
      "      28452 |   0.005082  |    0.082762     |   2\n",
      "      28453 |   0.167062  |    0.141590     |   1\n",
      "      28454 |   0.154870  |    0.059154     |   0\n",
      "      28455 |   0.147913  |    0.202958     |   1\n",
      "      28456 |   0.222192  |    0.144967     |   1\n",
      "      28457 |   0.175671  |    0.063692     |   0\n",
      "      28458 |   0.177395  |    0.135098     |   1\n",
      "      28459 |   0.174909  |    0.026919     |   0\n",
      "      28460 |   0.184212  |    0.189786     |   1\n",
      "      28461 |   0.119077  |    0.025001     |   0\n",
      "      28462 |   0.055810  |    0.090552     |   2\n",
      "      28463 |   0.197380  |    0.153162     |   1\n",
      "      28464 |   0.031540  |    0.005545     |   2\n",
      "      28465 |   0.051402  |    0.087759     |   2\n",
      "      28466 |   0.209069  |    0.036016     |   0\n",
      "      28467 |   0.200269  |    0.184687     |   1\n",
      "      28468 |   0.169056  |    0.027376     |   0\n",
      "      28469 |   0.159257  |    0.042774     |   0\n",
      "      28470 |   0.178687  |    0.043560     |   0\n",
      "      28471 |   0.038409  |    0.047791     |   2\n",
      "      28472 |   0.167292  |    0.043595     |   0\n",
      "      28473 |   0.147207  |    0.047230     |   0\n",
      "      28474 |   0.164703  |    0.136345     |   1\n",
      "      28475 |   0.149840  |    0.054695     |   0\n",
      "      28476 |   0.196718  |    0.157553     |   1\n",
      "      28477 |   0.212727  |    0.206798     |   1\n",
      "      28478 |   0.161708  |    0.167312     |   1\n",
      "      28479 |   0.167919  |    0.096156     |   1\n",
      "      28480 |   0.178696  |    0.045421     |   0\n",
      "      28481 |   0.149017  |    0.079725     |   0\n",
      "      28482 |   0.014550  |    0.044131     |   2\n",
      "      28483 |   0.176291  |    0.140642     |   1\n",
      "      28484 |   0.030375  |    0.045546     |   2\n",
      "      28485 |   0.024448  |    0.057391     |   2\n",
      "      28486 |   0.162534  |    0.197512     |   1\n",
      "      28487 |   0.241725  |    0.150607     |   1\n",
      "      28488 |   0.000016  |    0.071581     |   2\n",
      "      28489 |   0.000016  |    0.025624     |   2\n",
      "      28490 |   0.144313  |    0.045595     |   0\n",
      "      28491 |   0.000016  |    0.043314     |   2\n",
      "      28492 |   0.000016  |    0.057686     |   2\n",
      "      28493 |   0.176053  |    0.200966     |   1\n",
      "      28494 |   0.000016  |    0.031557     |   2\n",
      "      28495 |   0.000016  |    0.092789     |   2\n",
      "      28496 |   0.222155  |    0.167685     |   1\n",
      "      28497 |   0.209900  |    0.006503     |   0\n",
      "      28498 |   0.206879  |    0.091859     |   0\n",
      "      28499 |   0.041821  |    0.037206     |   2\n",
      "      28500 |   0.196385  |    0.203207     |   1\n",
      "      28501 |   0.177521  |    0.203032     |   1\n",
      "      28502 |   0.044637  |    0.032609     |   2\n",
      "      28503 |   0.028701  |    0.046096     |   2\n",
      "      28504 |   0.035679  |    0.044067     |   2\n",
      "      28505 |   0.191245  |    0.093464     |   0\n",
      "      28506 |   0.032727  |    0.003340     |   2\n",
      "      28507 |   0.110975  |    0.195997     |   1\n",
      "      28508 |   0.175585  |    0.006299     |   0\n",
      "      28509 |   0.024552  |    0.057582     |   2\n",
      "      28510 |   0.173927  |    0.049938     |   0\n",
      "      28511 |   0.146429  |    0.191547     |   1\n",
      "      28512 |   0.167783  |    0.180848     |   1\n",
      "      28513 |   0.184508  |    0.009660     |   0\n",
      "      28514 |   0.033077  |    0.080091     |   2\n",
      "      28515 |   0.041924  |    0.006019     |   2\n",
      "      28516 |   0.160367  |    0.076059     |   0\n",
      "      28517 |   0.045738  |    0.041280     |   2\n",
      "      28518 |   0.157997  |    0.191510     |   1\n",
      "      28519 |   0.038519  |    0.045224     |   2\n",
      "      28520 |   0.163210  |    0.080803     |   0\n",
      "      28521 |   0.154956  |    0.020923     |   0\n",
      "      28522 |   0.217366  |    0.204854     |   1\n",
      "      28523 |   0.226009  |    0.143272     |   1\n",
      "      28524 |   0.017344  |    0.045290     |   2\n",
      "      28525 |   0.000016  |    0.038584     |   2\n",
      "      28526 |   0.153828  |    0.052555     |   0\n",
      "      28527 |   0.239370  |    0.198607     |   1\n",
      "      28528 |   0.173473  |    0.169815     |   1\n",
      "      28529 |   0.156185  |    0.158093     |   1\n",
      "      28530 |   0.166046  |    0.028216     |   0\n",
      "      28531 |   0.004640  |    0.078968     |   2\n",
      "      28532 |   0.184394  |    0.057328     |   0\n",
      "      28533 |   0.174798  |    0.070699     |   0\n",
      "      28534 |   0.057116  |    0.048677     |   2\n",
      "      28535 |   0.034687  |    0.051096     |   2\n",
      "      28536 |   0.052753  |    0.076330     |   2\n",
      "      28537 |   0.169367  |    0.144853     |   1\n",
      "      28538 |   0.036422  |    0.047820     |   2\n",
      "      28539 |   0.153373  |    0.208527     |   1\n",
      "      28540 |   0.013702  |    0.030857     |   2\n",
      "      28541 |   0.030315  |    0.071519     |   2\n",
      "      28542 |   0.023049  |    0.048728     |   2\n",
      "      28543 |   0.157186  |    0.059449     |   0\n",
      "      28544 |   0.202738  |    0.194496     |   1\n",
      "      28545 |   0.202694  |    0.137724     |   1\n",
      "      28546 |   0.000016  |    0.028572     |   2\n",
      "      28547 |   0.157724  |    0.207157     |   1\n",
      "      28548 |   0.000016  |    0.032138     |   2\n",
      "      28549 |   0.000016  |    0.049324     |   2\n",
      "      28550 |   0.000016  |    0.054736     |   2\n",
      "      28551 |   0.000016  |    0.039993     |   2\n",
      "      28552 |   0.189039  |    0.190105     |   1\n",
      "      28553 |   0.000016  |    0.083791     |   2\n",
      "      28554 |   0.231784  |    0.013191     |   0\n",
      "      28555 |   0.224287  |    0.206564     |   1\n",
      "      28556 |   0.224797  |    0.049336     |   0\n",
      "      28557 |   0.157565  |    0.162599     |   1\n",
      "      28558 |   0.043792  |    0.005425     |   2\n",
      "      28559 |   0.236664  |    0.251478     |   1\n",
      "      28560 |   0.189414  |    0.010945     |   0\n",
      "      28561 |   0.142204  |    0.086025     |   0\n",
      "      28562 |   0.044441  |    0.070291     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 28564: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      28563 |   0.141395  |    0.041887     |   0\n",
      "      28564 |   0.174017  |    0.080608     |   0\n",
      "      28565 |   0.040709  |    0.013465     |   2\n",
      "      28566 |   0.235893  |    0.222161     |   1\n",
      "      28567 |   0.147761  |    0.053033     |   0\n",
      "      28568 |   0.163986  |    0.048436     |   0\n",
      "      28569 |   0.027339  |    0.077790     |   2\n",
      "      28570 |   0.034926  |    0.021054     |   2\n",
      "      28571 |   0.170896  |    0.088969     |   0\n",
      "      28572 |   0.215222  |    0.151436     |   1\n",
      "      28573 |   0.032659  |    0.026753     |   2\n",
      "      28574 |   0.196196  |    0.072876     |   0\n",
      "      28575 |   0.024442  |    0.007508     |   2\n",
      "      28576 |   0.216043  |    0.081216     |   0\n",
      "      28577 |   0.033774  |    0.040944     |   2\n",
      "      28578 |   0.042075  |    0.073590     |   2\n",
      "      28579 |   0.045968  |    0.025649     |   2\n",
      "      28580 |   0.218988  |    0.253722     |   1\n",
      "      28581 |   0.037761  |    0.022625     |   2\n",
      "      28582 |   0.016797  |    0.079045     |   2\n",
      "      28583 |   0.184041  |    0.157632     |   1\n",
      "      28584 |   0.151987  |    0.144045     |   1\n",
      "      28585 |   0.210500  |    0.143894     |   1\n",
      "      28586 |   0.161064  |    0.142987     |   1\n",
      "      28587 |   0.135862  |    0.080638     |   0\n",
      "      28588 |   0.132779  |    0.188326     |   1\n",
      "      28589 |   0.000015  |    0.014092     |   2\n",
      "      28590 |   0.165948  |    0.299901     |   1\n",
      "      28591 |   0.196774  |    0.079337     |   0\n",
      "      28592 |   0.004281  |    0.041384     |   2\n",
      "      28593 |   0.054971  |    0.099090     |   2\n",
      "      28594 |   0.193517  |    0.237415     |   1\n",
      "      28595 |   0.185876  |    0.134706     |   0\n",
      "      28596 |   0.031937  |    0.008805     |   2\n",
      "      28597 |   0.192723  |    0.289368     |   1\n",
      "      28598 |   0.195444  |    0.086328     |   0\n",
      "      28599 |   0.197598  |    0.015715     |   0\n",
      "      28600 |   0.050087  |    0.085960     |   2\n",
      "      28601 |   0.237112  |    0.156493     |   1\n",
      "      28602 |   0.036124  |    0.033163     |   2\n",
      "      28603 |   0.156907  |    0.190798     |   1\n",
      "      28604 |   0.135742  |    0.029460     |   0\n",
      "      28605 |   0.153972  |    0.061731     |   0\n",
      "      28606 |   0.162755  |    0.201950     |   1\n",
      "      28607 |   0.167890  |    0.084646     |   0\n",
      "      28608 |   0.211493  |    0.141144     |   1\n",
      "      28609 |   0.014171  |    0.028635     |   2\n",
      "      28610 |   0.136993  |    0.193762     |   1\n",
      "      28611 |   0.166593  |    0.043117     |   0\n",
      "      28612 |   0.031630  |    0.073527     |   2\n",
      "      28613 |   0.024617  |    0.033760     |   2\n",
      "      28614 |   0.186925  |    0.211759     |   1\n",
      "      28615 |   0.180111  |    0.146146     |   1\n",
      "      28616 |   0.000016  |    0.043261     |   2\n",
      "      28617 |   0.155368  |    0.078995     |   0\n",
      "      28618 |   0.217369  |    0.033657     |   0\n",
      "      28619 |   0.124707  |    0.211999     |   1\n",
      "      28620 |   0.149611  |    0.077078     |   0\n",
      "      28621 |   0.000015  |    0.028286     |   2\n",
      "      28622 |   0.000015  |    0.053216     |   2\n",
      "      28623 |   0.000016  |    0.043272     |   2\n",
      "      28624 |   0.151624  |    0.048950     |   0\n",
      "      28625 |   0.152871  |    0.195198     |   1\n",
      "      28626 |   0.185043  |    0.022638     |   0\n",
      "      28627 |   0.163281  |    0.202746     |   1\n",
      "      28628 |   0.165745  |    0.019711     |   0\n",
      "      28629 |   0.166991  |    0.073628     |   0\n",
      "      28630 |   0.170687  |    0.025376     |   0\n",
      "      28631 |   0.149460  |    0.072057     |   0\n",
      "      28632 |   0.210758  |    0.164812     |   1\n",
      "      28633 |   0.000015  |    0.010610     |   2\n",
      "      28634 |   0.000015  |    0.083528     |   2\n",
      "      28635 |   0.185638  |    0.023498     |   0\n",
      "      28636 |   0.172999  |    0.091403     |   0\n",
      "      28637 |   0.044239  |    0.020767     |   2\n",
      "      28638 |   0.159842  |    0.212681     |   1\n",
      "      28639 |   0.167524  |    0.039397     |   0\n",
      "      28640 |   0.263857  |    0.154781     |   1\n",
      "      28641 |   0.216556  |    0.183658     |   1\n",
      "      28642 |   0.161608  |    0.030581     |   0\n",
      "      28643 |   0.045037  |    0.051875     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 28644: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      28644 |   0.041540  |    0.046207     |   2\n",
      "      28645 |   0.165074  |    0.130567     |   1\n",
      "      28646 |   0.192777  |    0.137971     |   1\n",
      "      28647 |   0.173414  |    0.188983     |   1\n",
      "      28648 |   0.146838  |    0.017255     |   0\n",
      "      28649 |   0.028901  |    0.072073     |   2\n",
      "      28650 |   0.172605  |    0.038958     |   0\n",
      "      28651 |   0.034839  |    0.044327     |   2\n",
      "      28652 |   0.156765  |    0.079613     |   0\n",
      "      28653 |   0.146131  |    0.026549     |   0\n",
      "      28654 |   0.193319  |    0.072853     |   0\n",
      "      28655 |   0.033371  |    0.053798     |   2\n",
      "      28656 |   0.024655  |    0.024775     |   2\n",
      "      28657 |   0.142847  |    0.195095     |   1\n",
      "      28658 |   0.032491  |    0.041569     |   2\n",
      "      28659 |   0.154322  |    0.211148     |   1\n",
      "      28660 |   0.045838  |    0.011684     |   2\n",
      "      28661 |   0.043647  |    0.081468     |   2\n",
      "      28662 |   0.228029  |    0.034509     |   0\n",
      "      28663 |   0.037142  |    0.047843     |   2\n",
      "      28664 |   0.139660  |    0.224321     |   1\n",
      "      28665 |   0.188243  |    0.151024     |   1\n",
      "      28666 |   0.151274  |    0.221618     |   1\n",
      "      28667 |   0.153830  |    0.155959     |   1\n",
      "      28668 |   0.017366  |    0.045219     |   2\n",
      "      28669 |   0.000016  |    0.066971     |   2\n",
      "      28670 |   0.250351  |    0.148985     |   1\n",
      "      28671 |   0.004820  |    0.045057     |   2\n",
      "      28672 |   0.200064  |    0.045958     |   0\n",
      "      28673 |   0.054396  |    0.045115     |   2\n",
      "      28674 |   0.302679  |    0.199617     |   1\n",
      "      28675 |   0.028998  |    0.017358     |   2\n",
      "      28676 |   0.161325  |    0.216642     |   1\n",
      "      28677 |   0.138371  |    0.007880     |   0\n",
      "      28678 |   0.166768  |    0.079644     |   0\n",
      "      28679 |   0.162426  |    0.149456     |   1\n",
      "      28680 |   0.163399  |    0.192101     |   1\n",
      "      28681 |   0.165904  |    0.154160     |   1\n",
      "      28682 |   0.180166  |    0.146957     |   1\n",
      "      28683 |   0.050523  |    0.048606     |   2\n",
      "      28684 |   0.233798  |    0.147572     |   1\n",
      "      28685 |   0.036001  |    0.024889     |   2\n",
      "      28686 |   0.013838  |    0.077023     |   2\n",
      "      28687 |   0.207168  |    0.042127     |   0\n",
      "      28688 |   0.191867  |    0.048096     |   0\n",
      "      28689 |   0.178508  |    0.091549     |   0\n",
      "      28690 |   0.220083  |    0.148712     |   1\n",
      "      28691 |   0.160619  |    0.161265     |   1\n",
      "      28692 |   0.029970  |    0.070837     |   2\n",
      "      28693 |   0.024503  |    0.012622     |   2\n",
      "      28694 |   0.165452  |    0.188615     |   1\n",
      "      28695 |   0.000016  |    0.037673     |   2\n",
      "      28696 |   0.171706  |    0.078765     |   0\n",
      "      28697 |   0.198920  |    0.207464     |   1\n",
      "      28698 |   0.000016  |    0.029970     |   2\n",
      "      28699 |   0.000016  |    0.085656     |   2\n",
      "      28700 |   0.178408  |    0.048456     |   0\n",
      "      28701 |   0.000016  |    0.052317     |   2\n",
      "      28702 |   0.145399  |    0.208983     |   1\n",
      "      28703 |   0.196372  |    0.028202     |   0\n",
      "      28704 |   0.000016  |    0.038452     |   2\n",
      "      28705 |   0.147986  |    0.077043     |   0\n",
      "      28706 |   0.155492  |    0.053204     |   0\n",
      "      28707 |   0.182188  |    0.057913     |   0\n",
      "      28708 |   0.228430  |    0.073796     |   0\n",
      "      28709 |   0.177171  |    0.042267     |   0\n",
      "      28710 |   0.000015  |    0.077860     |   2\n",
      "      28711 |   0.152950  |    0.026575     |   0\n",
      "      28712 |   0.043612  |    0.077220     |   2\n",
      "      28713 |   0.183755  |    0.025764     |   0\n",
      "      28714 |   0.263861  |    0.209189     |   1\n",
      "      28715 |   0.200853  |    0.077706     |   0\n",
      "      28716 |   0.043550  |    0.034751     |   2\n",
      "      28717 |   0.138883  |    0.264519     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 28718: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      28718 |   0.171813  |    0.018207     |   0\n",
      "      28719 |   0.042683  |    0.086425     |   2\n",
      "      28720 |   0.028417  |    0.099669     |   2\n",
      "      28721 |   0.200427  |    0.331970     |   1\n",
      "      28722 |   0.147630  |    0.330851     |   1\n",
      "      28723 |   0.035913  |    0.043247     |   2\n",
      "      28724 |   0.145855  |    0.221473     |   1\n",
      "      28725 |   0.033037  |    0.062501     |   2\n",
      "      28726 |   0.182753  |    0.258297     |   1\n",
      "      28727 |   0.203543  |    0.205980     |   1\n",
      "      28728 |   0.216168  |    0.197365     |   1\n",
      "      28729 |   0.025013  |    0.080878     |   2\n",
      "      28730 |   0.033154  |    0.075759     |   2\n",
      "      28731 |   0.042834  |    0.032313     |   2\n",
      "      28732 |   0.045757  |    0.076394     |   2\n",
      "      28733 |   0.169675  |    0.050064     |   0\n",
      "      28734 |   0.192798  |    0.234831     |   1\n",
      "      28735 |   0.274011  |    0.003472     |   0\n",
      "      28736 |   0.143653  |    0.086590     |   0\n",
      "      28737 |   0.204044  |    0.078810     |   0\n",
      "      28738 |   0.036680  |    0.047445     |   2\n",
      "      28739 |   0.147331  |    0.084730     |   0\n",
      "      28740 |   0.181641  |    0.159396     |   1\n",
      "      28741 |   0.185670  |    0.045408     |   0\n",
      "      28742 |   0.193993  |    0.052665     |   0\n",
      "      28743 |   0.213522  |    0.223525     |   1\n",
      "      28744 |   0.018461  |    0.039111     |   2\n",
      "      28745 |   0.000015  |    0.082299     |   2\n",
      "      28746 |   0.186045  |    0.053988     |   0\n",
      "      28747 |   0.201941  |    0.168427     |   1\n",
      "      28748 |   0.004675  |    0.050570     |   2\n",
      "      28749 |   0.144570  |    0.206016     |   1\n",
      "      28750 |   0.055444  |    0.044109     |   2\n",
      "      28751 |   0.191712  |    0.156577     |   1\n",
      "      28752 |   0.169898  |    0.184769     |   1\n",
      "      28753 |   0.193658  |    0.200695     |   1\n",
      "      28754 |   0.140986  |    0.028180     |   0\n",
      "      28755 |   0.032487  |    0.077503     |   2\n",
      "      28756 |   0.167893  |    0.045719     |   0\n",
      "      28757 |   0.213091  |    0.228147     |   1\n",
      "      28758 |   0.214395  |    0.146000     |   1\n",
      "      28759 |   0.209979  |    0.189012     |   1\n",
      "      28760 |   0.200354  |    0.150130     |   1\n",
      "      28761 |   0.164841  |    0.181467     |   1\n",
      "      28762 |   0.050081  |    0.038285     |   2\n",
      "      28763 |   0.212345  |    0.048997     |   0\n",
      "      28764 |   0.220954  |    0.085747     |   0\n",
      "      28765 |   0.154953  |    0.189978     |   1\n",
      "      28766 |   0.192185  |    0.006217     |   0\n",
      "      28767 |   0.170719  |    0.080878     |   0\n",
      "      28768 |   0.257696  |    0.154517     |   1\n",
      "      28769 |   0.119580  |    0.028221     |   0\n",
      "      28770 |   0.036411  |    0.078053     |   2\n",
      "      28771 |   0.130747  |    0.185174     |   1\n",
      "      28772 |   0.194268  |    0.145021     |   1\n",
      "      28773 |   0.014142  |    0.043422     |   2\n",
      "      28774 |   0.172803  |    0.199614     |   1\n",
      "      28775 |   0.166270  |    0.010779     |   0\n",
      "      28776 |   0.139409  |    0.044953     |   0\n",
      "      28777 |   0.029883  |    0.054748     |   2\n",
      "      28778 |   0.023177  |    0.043139     |   2\n",
      "      28779 |   0.157942  |    0.078811     |   0\n",
      "      28780 |   0.000015  |    0.028743     |   2\n",
      "      28781 |   0.198013  |    0.198247     |   1\n",
      "      28782 |   0.000015  |    0.017955     |   2\n",
      "      28783 |   0.000015  |    0.078174     |   2\n",
      "      28784 |   0.217678  |    0.154316     |   1\n",
      "      28785 |   0.199968  |    0.047755     |   0\n",
      "      28786 |   0.197647  |    0.161307     |   1\n",
      "      28787 |   0.224979  |    0.137744     |   1\n",
      "      28788 |   0.175450  |    0.094722     |   0\n",
      "      28789 |   0.183494  |    0.148648     |   1\n",
      "      28790 |   0.000016  |    0.026836     |   2\n",
      "      28791 |   0.000015  |    0.051911     |   2\n",
      "      28792 |   0.165532  |    0.041970     |   0\n",
      "      28793 |   0.167651  |    0.044614     |   0\n",
      "      28794 |   0.000015  |    0.080430     |   2\n",
      "      28795 |   0.216444  |    0.150134     |   1\n",
      "      28796 |   0.041228  |    0.030898     |   2\n",
      "      28797 |   0.148480  |    0.200118     |   1\n",
      "      28798 |   0.042482  |    0.025281     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 28799: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      28799 |   0.148320  |    0.196249     |   1\n",
      "      28800 |   0.171552  |    0.032515     |   0\n",
      "      28801 |   0.038296  |    0.082530     |   2\n",
      "      28802 |   0.225417  |    0.009799     |   0\n",
      "      28803 |   0.125493  |    0.263657     |   1\n",
      "      28804 |   0.028011  |    0.007618     |   2\n",
      "      28805 |   0.035001  |    0.090395     |   2\n",
      "      28806 |   0.179102  |    0.154205     |   1\n",
      "      28807 |   0.137247  |    0.226511     |   1\n",
      "      28808 |   0.168245  |    0.142798     |   1\n",
      "      28809 |   0.187153  |    0.155088     |   1\n",
      "      28810 |   0.161215  |    0.151531     |   1\n",
      "      28811 |   0.033520  |    0.027744     |   2\n",
      "      28812 |   0.208411  |    0.081051     |   0\n",
      "      28813 |   0.024033  |    0.044625     |   2\n",
      "      28814 |   0.032558  |    0.082747     |   2\n",
      "      28815 |   0.040898  |    0.009895     |   2\n",
      "      28816 |   0.167675  |    0.072593     |   0\n",
      "      28817 |   0.141208  |    0.028057     |   0\n",
      "      28818 |   0.045058  |    0.048575     |   2\n",
      "      28819 |   0.182048  |    0.202722     |   1\n",
      "      28820 |   0.175145  |    0.198916     |   1\n",
      "      28821 |   0.039052  |    0.004105     |   2\n",
      "      28822 |   0.019191  |    0.082505     |   2\n",
      "      28823 |   0.186116  |    0.205629     |   1\n",
      "      28824 |   0.196083  |    0.010293     |   0\n",
      "      28825 |   0.000015  |    0.056765     |   2\n",
      "      28826 |   0.172766  |    0.164728     |   1\n",
      "      28827 |   0.167990  |    0.187202     |   1\n",
      "      28828 |   0.004146  |    0.005051     |   2\n",
      "      28829 |   0.053537  |    0.078275     |   2\n",
      "      28830 |   0.191394  |    0.039149     |   0\n",
      "      28831 |   0.131674  |    0.038274     |   0\n",
      "      28832 |   0.245719  |    0.180495     |   1\n",
      "      28833 |   0.177665  |    0.195750     |   1\n",
      "      28834 |   0.159167  |    0.150017     |   1\n",
      "      28835 |   0.031211  |    0.040648     |   2\n",
      "      28836 |   0.142482  |    0.154888     |   1\n",
      "      28837 |   0.185813  |    0.043444     |   0\n",
      "      28838 |   0.049989  |    0.053473     |   2\n",
      "      28839 |   0.252275  |    0.198537     |   1\n",
      "      28840 |   0.171751  |    0.140021     |   1\n",
      "      28841 |   0.036241  |    0.044265     |   2\n",
      "      28842 |   0.173459  |    0.045014     |   0\n",
      "      28843 |   0.143838  |    0.073657     |   0\n",
      "      28844 |   0.148502  |    0.044502     |   0\n",
      "      28845 |   0.165278  |    0.154559     |   1\n",
      "      28846 |   0.219998  |    0.196563     |   1\n",
      "      28847 |   0.152246  |    0.041835     |   0\n",
      "      28848 |   0.171780  |    0.199476     |   1\n",
      "      28849 |   0.176560  |    0.044898     |   0\n",
      "      28850 |   0.014378  |    0.038765     |   2\n",
      "      28851 |   0.174227  |    0.179885     |   1\n",
      "      28852 |   0.191711  |    0.183663     |   1\n",
      "      28853 |   0.135834  |    0.017934     |   0\n",
      "      28854 |   0.198262  |    0.215839     |   1\n",
      "      28855 |   0.232661  |    0.027576     |   0\n",
      "      28856 |   0.167906  |    0.076291     |   0\n",
      "      28857 |   0.029926  |    0.007676     |   2\n",
      "      28858 |   0.024067  |    0.078004     |   2\n",
      "      28859 |   0.232314  |    0.152895     |   1\n",
      "      28860 |   0.160485  |    0.209137     |   1\n",
      "      28861 |   0.207454  |    0.161614     |   1\n",
      "      28862 |   0.123859  |    0.043410     |   0\n",
      "      28863 |   0.172843  |    0.037969     |   0\n",
      "      28864 |   0.232712  |    0.052361     |   0\n",
      "      28865 |   0.138885  |    0.152955     |   1\n",
      "      28866 |   0.219150  |    0.049244     |   0\n",
      "      28867 |   0.000015  |    0.044087     |   2\n",
      "      28868 |   0.226293  |    0.075019     |   0\n",
      "      28869 |   0.171478  |    0.043392     |   0\n",
      "      28870 |   0.156068  |    0.138409     |   1\n",
      "      28871 |   0.190304  |    0.085422     |   0\n",
      "      28872 |   0.231019  |    0.140525     |   1\n",
      "      28873 |   0.191563  |    0.047924     |   0\n",
      "      28874 |   0.000015  |    0.046748     |   2\n",
      "      28875 |   0.000015  |    0.038961     |   2\n",
      "      28876 |   0.150174  |    0.077581     |   0\n",
      "      28877 |   0.243543  |    0.186865     |   1\n",
      "      28878 |   0.128829  |    0.007195     |   0\n",
      "      28879 |   0.171947  |    0.043437     |   0\n",
      "      28880 |   0.000015  |    0.073115     |   2\n",
      "      28881 |   0.000015  |    0.012054     |   2\n",
      "      28882 |   0.000015  |    0.073955     |   2\n",
      "      28883 |   0.046168  |    0.028310     |   2\n",
      "      28884 |   0.182347  |    0.044806     |   0\n",
      "      28885 |   0.043646  |    0.075932     |   2\n",
      "      28886 |   0.165493  |    0.212495     |   1\n",
      "      28887 |   0.210091  |    0.142025     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 28889: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      28888 |   0.142283  |    0.007562     |   0\n",
      "      28889 |   0.207228  |    0.074671     |   0\n",
      "      28890 |   0.043928  |    0.079099     |   2\n",
      "      28891 |   0.028780  |    0.044534     |   2\n",
      "      28892 |   0.169705  |    0.203434     |   1\n",
      "      28893 |   0.033993  |    0.027095     |   2\n",
      "      28894 |   0.033447  |    0.083199     |   2\n",
      "      28895 |   0.175084  |    0.148771     |   1\n",
      "      28896 |   0.224874  |    0.223555     |   1\n",
      "      28897 |   0.025717  |    0.022976     |   2\n",
      "      28898 |   0.214226  |    0.078292     |   0\n",
      "      28899 |   0.155788  |    0.049113     |   0\n",
      "      28900 |   0.033349  |    0.052076     |   2\n",
      "      28901 |   0.046753  |    0.041163     |   2\n",
      "      28902 |   0.178431  |    0.054345     |   0\n",
      "      28903 |   0.208165  |    0.157641     |   1\n",
      "      28904 |   0.047157  |    0.079522     |   2\n",
      "      28905 |   0.228646  |    0.154268     |   1\n",
      "      28906 |   0.037683  |    0.026104     |   2\n",
      "      28907 |   0.173739  |    0.040370     |   0\n",
      "      28908 |   0.016144  |    0.081538     |   2\n",
      "      28909 |   0.000015  |    0.013305     |   2\n",
      "      28910 |   0.004399  |    0.074058     |   2\n",
      "      28911 |   0.055020  |    0.076477     |   2\n",
      "      28912 |   0.031697  |    0.041091     |   2\n",
      "      28913 |   0.206192  |    0.186886     |   1\n",
      "      28914 |   0.175601  |    0.134963     |   1\n",
      "      28915 |   0.139265  |    0.053499     |   0\n",
      "      28916 |   0.151709  |    0.153880     |   1\n",
      "      28917 |   0.175883  |    0.138911     |   1\n",
      "      28918 |   0.174281  |    0.081956     |   0\n",
      "      28919 |   0.050782  |    0.038367     |   2\n",
      "      28920 |   0.199094  |    0.070986     |   0\n",
      "      28921 |   0.167320  |    0.153018     |   1\n",
      "      28922 |   0.125936  |    0.201457     |   1\n",
      "      28923 |   0.242400  |    0.139680     |   1\n",
      "      28924 |   0.164134  |    0.041898     |   0\n",
      "      28925 |   0.141824  |    0.147428     |   1\n",
      "      28926 |   0.181272  |    0.053183     |   0\n",
      "      28927 |   0.036777  |    0.053521     |   2\n",
      "      28928 |   0.014353  |    0.040313     |   2\n",
      "      28929 |   0.030399  |    0.051802     |   2\n",
      "      28930 |   0.164205  |    0.194590     |   1\n",
      "      28931 |   0.152749  |    0.162435     |   1\n",
      "      28932 |   0.025528  |    0.063653     |   2\n",
      "      28933 |   0.146692  |    0.183378     |   1\n",
      "      28934 |   0.148006  |    0.051644     |   0\n",
      "      28935 |   0.000015  |    0.074952     |   2\n",
      "      28936 |   0.239384  |    0.153444     |   1\n",
      "      28937 |   0.000015  |    0.018316     |   2\n",
      "      28938 |   0.176498  |    0.087231     |   0\n",
      "      28939 |   0.250221  |    0.039181     |   0\n",
      "      28940 |   0.139275  |    0.044105     |   0\n",
      "      28941 |   0.164138  |    0.045533     |   0\n",
      "      28942 |   0.189649  |    0.191384     |   1\n",
      "      28943 |   0.145344  |    0.017975     |   0\n",
      "      28944 |   0.222399  |    0.188881     |   1\n",
      "      28945 |   0.000015  |    0.042947     |   2\n",
      "      28946 |   0.152005  |    0.218895     |   1\n",
      "      28947 |   0.187832  |    0.193846     |   1\n",
      "      28948 |   0.000015  |    0.024634     |   2\n",
      "      28949 |   0.214339  |    0.212693     |   1\n",
      "      28950 |   0.000015  |    0.046052     |   2\n",
      "      28951 |   0.164137  |    0.045479     |   0\n",
      "      28952 |   0.203932  |    0.075475     |   0\n",
      "      28953 |   0.221889  |    0.041044     |   0\n",
      "      28954 | \u001b[94m  0.000015\u001b[0m  |    0.054598     |   2\n",
      "      28955 |   0.228635  |    0.194674     |   1\n",
      "      28956 |   0.190220  |    0.044759     |   0\n",
      "      28957 |   0.217211  |    0.047679     |   0\n",
      "      28958 |   0.188334  |    0.046136     |   0\n",
      "      28959 |   0.041815  |    0.039432     |   2\n",
      "      28960 |   0.211858  |    0.181381     |   1\n",
      "      28961 |   0.171647  |    0.033920     |   0\n",
      "      28962 |   0.182586  |    0.080014     |   0\n",
      "      28963 |   0.140777  |    0.023532     |   0\n",
      "      28964 |   0.160649  |    0.074201     |   0\n",
      "      28965 |   0.151174  |    0.218359     |   1\n",
      "      28966 |   0.184438  |    0.194492     |   1\n",
      "      28967 |   0.130157  |    0.023944     |   0\n",
      "      28968 |   0.044097  |    0.056056     |   2\n",
      "      28969 |   0.203676  |    0.199208     |   1\n",
      "      28970 |   0.171287  |    0.187513     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 28972: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      28971 |   0.187205  |    0.007195     |   0\n",
      "      28972 |   0.200571  |    0.074720     |   0\n",
      "      28973 |   0.178657  |    0.039706     |   0\n",
      "      28974 |   0.189187  |    0.197166     |   1\n",
      "      28975 |   0.221197  |    0.154855     |   1\n",
      "      28976 |   0.040340  |    0.057009     |   2\n",
      "      28977 |   0.119864  |    0.056999     |   0\n",
      "      28978 |   0.197312  |    0.146472     |   1\n",
      "      28979 |   0.029602  |    0.045611     |   2\n",
      "      28980 |   0.170018  |    0.050022     |   0\n",
      "      28981 |   0.197827  |    0.148471     |   1\n",
      "      28982 |   0.185140  |    0.193377     |   1\n",
      "      28983 |   0.136542  |    0.040474     |   0\n",
      "      28984 |   0.035715  |    0.075499     |   2\n",
      "      28985 |   0.223972  |    0.043277     |   0\n",
      "      28986 |   0.034554  |    0.038358     |   2\n",
      "      28987 |   0.213275  |    0.149766     |   1\n",
      "      28988 |   0.024067  |    0.081406     |   2\n",
      "      28989 |   0.175557  |    0.151375     |   1\n",
      "      28990 |   0.181004  |    0.152261     |   1\n",
      "      28991 |   0.207700  |    0.005690     |   0\n",
      "      28992 |   0.186051  |    0.079699     |   0\n",
      "      28993 |   0.186295  |    0.146643     |   1\n",
      "      28994 |   0.160493  |    0.205197     |   1\n",
      "      28995 |   0.165503  |    0.151300     |   1\n",
      "      28996 |   0.033180  |    0.046436     |   2\n",
      "      28997 |   0.134110  |    0.042029     |   0\n",
      "      28998 |   0.168525  |    0.056721     |   0\n",
      "      28999 |   0.177848  |    0.045677     |   0\n",
      "      29000 |   0.172984  |    0.076622     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 29000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 29000: Plotting estimates.\n",
      "Exception in thread neuralnilm-data-process:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 810, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/jack/workspace/python/neuralnilm/neuralnilm/data/datathread.py\", line 16, in run\n",
      "    batch = self.data_pipeline.get_batch(**self._get_batch_kwargs)\n",
      "  File \"/home/jack/workspace/python/neuralnilm/neuralnilm/data/datapipeline.py\", line 46, in get_batch\n",
      "    batch = self._source_iterators[source_id].next()\n",
      "ValueError: generator already executing\n",
      "\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      29001 |   0.040960  |    0.080657     |   2\n",
      "      29002 |   0.169167  |    0.034271     |   0\n",
      "      29003 |   0.247289  |    0.189321     |   1\n",
      "      29004 |   0.172536  |    0.228987     |   1\n",
      "      29005 |   0.160417  |    0.274538     |   1\n",
      "      29006 |   0.147966  |    0.288738     |   1\n",
      "      29007 |   0.200134  |    0.219795     |   1\n",
      "      29008 |   0.126059  |    0.301356     |   1\n",
      "      29009 |   0.028262  |    0.038033     |   2\n",
      "      29010 |   0.192311  |    0.075334     |   0\n",
      "      29011 |   0.034233  |    0.120353     |   2\n",
      "      29012 |   0.034420  |    0.039429     |   2\n",
      "      29013 |   0.134059  |    0.282655     |   1\n",
      "      29014 |   0.024295  |    0.073312     |   2\n",
      "      29015 |   0.167571  |    0.348178     |   1\n",
      "      29016 |   0.031648  |    0.070132     |   2\n",
      "      29017 |   0.047004  |    0.072058     |   2\n",
      "      29018 |   0.046570  |    0.037001     |   2\n",
      "      29019 |   0.038833  |    0.070056     |   2\n",
      "      29020 |   0.018944  |    0.078084     |   2\n",
      "      29021 |   0.000015  |    0.130584     |   2\n",
      "      29022 |   0.214354  |    0.038578     |   0\n",
      "      29023 |   0.190594  |    0.276212     |   1\n",
      "      29024 |   0.005160  |    0.074619     |   2\n",
      "      29025 |   0.200889  |    0.271326     |   1\n",
      "      29026 |   0.180055  |    0.077945     |   0\n",
      "      29027 |   0.055235  |    0.074068     |   2\n",
      "      29028 |   0.241511  |    0.134336     |   0\n",
      "      29029 |   0.181837  |    0.091589     |   0\n",
      "      29030 |   0.177142  |    0.039244     |   0\n",
      "      29031 |   0.030782  |    0.131430     |   2\n",
      "      29032 |   0.163307  |    0.097066     |   0\n",
      "      29033 |   0.184297  |    0.302638     |   1\n",
      "      29034 |   0.051183  |    0.078059     |   2\n",
      "      29035 |   0.144823  |    0.338121     |   1\n",
      "      29036 |   0.204834  |    0.276971     |   1\n",
      "      29037 |   0.175399  |    0.183756     |   1\n",
      "      29038 |   0.170472  |    0.099781     |   0\n",
      "      29039 |   0.170335  |    0.028413     |   0\n",
      "      29040 |   0.038441  |    0.089644     |   2\n",
      "      29041 |   0.016668  |    0.033818     |   2\n",
      "      29042 |   0.190382  |    0.217417     |   1\n",
      "      29043 |   0.186995  |    0.043511     |   0\n",
      "      29044 |   0.192062  |    0.047399     |   0\n",
      "      29045 |   0.231438  |    0.040718     |   0\n",
      "      29046 |   0.031977  |    0.096626     |   2\n",
      "      29047 |   0.151191  |    0.026424     |   0\n",
      "      29048 |   0.187003  |    0.194185     |   1\n",
      "      29049 |   0.024566  |    0.080718     |   2\n",
      "      29050 |   0.141130  |    0.013189     |   0\n",
      "      29051 |   0.197165  |    0.098333     |   0\n",
      "      29052 |   0.159759  |    0.148950     |   1\n",
      "      29053 |   0.000015  |    0.041702     |   2\n",
      "      29054 |   0.161511  |    0.198050     |   1\n",
      "      29055 |   0.187778  |    0.130480     |   1\n",
      "      29056 |   0.000015  |    0.054063     |   2\n",
      "      29057 |   0.185459  |    0.195031     |   1\n",
      "      29058 |   0.000015  |    0.046949     |   2\n",
      "      29059 |   0.182524  |    0.048043     |   0\n",
      "      29060 |   0.158531  |    0.046830     |   0\n",
      "      29061 |   0.180609  |    0.084216     |   0\n",
      "      29062 |   0.177608  |    0.014707     |   0\n",
      "      29063 |   0.000015  |    0.080632     |   2\n",
      "      29064 | \u001b[94m  0.000015\u001b[0m  |    0.054049     |   2\n",
      "      29065 |   0.159079  |    0.147744     |   1\n",
      "      29066 |   0.170739  |    0.084238     |   0\n",
      "      29067 |   0.150537  |    0.016335     |   0\n",
      "      29068 | \u001b[94m  0.000015\u001b[0m  |    0.073952     |   2\n",
      "      29069 |   0.207339  |    0.186483     |   1\n",
      "      29070 |   0.158255  |    0.026235     |   0\n",
      "      29071 |   0.166009  |    0.077603     |   0\n",
      "      29072 |   0.188124  |    0.014479     |   0\n",
      "      29073 |   0.170285  |    0.204529     |   1\n",
      "      29074 |   0.043132  |    0.021641     |   2\n",
      "      29075 |   0.187513  |    0.153598     |   1\n",
      "      29076 |   0.172945  |    0.147711     |   1\n",
      "      29077 |   0.043053  |    0.077888     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 29078: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      29078 |   0.040954  |    0.009139     |   2\n",
      "      29079 |   0.130104  |    0.086114     |   0\n",
      "      29080 |   0.112439  |    0.153705     |   1\n",
      "      29081 |   0.232881  |    0.197207     |   1\n",
      "      29082 |   0.028558  |    0.027680     |   2\n",
      "      29083 |   0.196333  |    0.208105     |   1\n",
      "      29084 |   0.159073  |    0.104155     |   1\n",
      "      29085 |   0.177084  |    0.073231     |   0\n",
      "      29086 |   0.233001  |    0.035571     |   0\n",
      "      29087 |   0.242399  |    0.211611     |   1\n",
      "      29088 |   0.219330  |    0.110876     |   1\n",
      "      29089 |   0.195186  |    0.183994     |   1\n",
      "      29090 |   0.035491  |    0.003659     |   2\n",
      "      29091 |   0.138764  |    0.207494     |   1\n",
      "      29092 |   0.229994  |    0.028058     |   0\n",
      "      29093 |   0.033674  |    0.078185     |   2\n",
      "      29094 |   0.175013  |    0.022917     |   0\n",
      "      29095 |   0.125230  |    0.210684     |   1\n",
      "      29096 |   0.122003  |    0.137038     |   1\n",
      "      29097 |   0.023292  |    0.019884     |   2\n",
      "      29098 |   0.157535  |    0.201037     |   1\n",
      "      29099 |   0.031791  |    0.050795     |   2\n",
      "      29100 |   0.044135  |    0.047021     |   2\n",
      "      29101 |   0.095989  |    0.211421     |   1\n",
      "      29102 |   0.168105  |    0.198213     |   1\n",
      "      29103 |   0.162213  |    0.008531     |   0\n",
      "      29104 |   0.214051  |    0.147386     |   1\n",
      "      29105 |   0.191466  |    0.192988     |   1\n",
      "      29106 |   0.241701  |    0.168951     |   1\n",
      "      29107 |   0.174687  |    0.202693     |   1\n",
      "      29108 |   0.199812  |    0.132777     |   1\n",
      "      29109 |   0.149488  |    0.005005     |   0\n",
      "      29110 |   0.175923  |    0.141010     |   1\n",
      "      29111 |   0.219362  |    0.187908     |   1\n",
      "      29112 |   0.173910  |    0.024982     |   0\n",
      "      29113 |   0.167381  |    0.076055     |   0\n",
      "      29114 |   0.047589  |    0.019633     |   2\n",
      "      29115 |   0.191727  |    0.074292     |   0\n",
      "      29116 |   0.038882  |    0.043733     |   2\n",
      "      29117 |   0.018505  |    0.044032     |   2\n",
      "      29118 |   0.192932  |    0.144882     |   1\n",
      "      29119 |   0.000015  |    0.048768     |   2\n",
      "      29120 |   0.004876  |    0.050200     |   2\n",
      "      29121 |   0.056053  |    0.079194     |   2\n",
      "      29122 |   0.213027  |    0.038354     |   0\n",
      "      29123 |   0.029813  |    0.048113     |   2\n",
      "      29124 |   0.050869  |    0.045284     |   2\n",
      "      29125 |   0.148287  |    0.077508     |   0\n",
      "      29126 |   0.139713  |    0.008995     |   0\n",
      "      29127 |   0.175226  |    0.077180     |   0\n",
      "      29128 |   0.036988  |    0.026233     |   2\n",
      "      29129 |   0.014077  |    0.052926     |   2\n",
      "      29130 |   0.032928  |    0.077536     |   2\n",
      "      29131 |   0.132994  |    0.014941     |   0\n",
      "      29132 |   0.139425  |    0.193265     |   1\n",
      "      29133 |   0.171161  |    0.159507     |   1\n",
      "      29134 |   0.232960  |    0.046533     |   0\n",
      "      29135 |   0.142271  |    0.194727     |   1\n",
      "      29136 |   0.184760  |    0.132496     |   1\n",
      "      29137 |   0.203788  |    0.189159     |   1\n",
      "      29138 |   0.208127  |    0.195711     |   1\n",
      "      29139 |   0.184230  |    0.183288     |   1\n",
      "      29140 |   0.174154  |    0.005540     |   0\n",
      "      29141 |   0.022737  |    0.048984     |   2\n",
      "      29142 |   0.161295  |    0.040419     |   0\n",
      "      29143 |   0.182793  |    0.169454     |   1\n",
      "      29144 |   0.160245  |    0.040077     |   0\n",
      "      29145 |   0.156902  |    0.041027     |   0\n",
      "      29146 |   0.139290  |    0.195823     |   1\n",
      "      29147 |   0.178183  |    0.075204     |   0\n",
      "      29148 | \u001b[94m  0.000015\u001b[0m  |    0.020695     |   2\n",
      "      29149 |   0.170909  |    0.208278     |   1\n",
      "      29150 |   0.182679  |    0.023701     |   0\n",
      "      29151 |   0.000015  |    0.046503     |   2\n",
      "      29152 |   0.000015  |    0.072515     |   2\n",
      "      29153 |   0.162294  |    0.051946     |   0\n",
      "      29154 |   0.184817  |    0.191641     |   1\n",
      "      29155 |   0.196104  |    0.008475     |   0\n",
      "      29156 |   0.000015  |    0.040322     |   2\n",
      "      29157 |   0.153803  |    0.050604     |   0\n",
      "      29158 |   0.230347  |    0.128108     |   1\n",
      "      29159 |   0.174840  |    0.075550     |   0\n",
      "      29160 | \u001b[94m  0.000015\u001b[0m  |    0.023676     |   2\n",
      "      29161 |   0.213190  |    0.088047     |   0\n",
      "      29162 |   0.156935  |    0.035315     |   0\n",
      "      29163 |   0.103899  |    0.162813     |   1\n",
      "      29164 |   0.168794  |    0.142392     |   1\n",
      "      29165 |   0.160309  |    0.200505     |   1\n",
      "      29166 | \u001b[94m  0.000015\u001b[0m  |    0.010599     |   2\n",
      "      29167 |   0.205438  |    0.079084     |   0\n",
      "      29168 |   0.043156  |    0.047264     |   2\n",
      "      29169 |   0.043738  |    0.044104     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 29170: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      29170 |   0.144506  |    0.210858     |   1\n",
      "      29171 |   0.157931  |    0.151890     |   1\n",
      "      29172 |   0.160874  |    0.154515     |   1\n",
      "      29173 |   0.041821  |    0.041671     |   2\n",
      "      29174 |   0.031108  |    0.047192     |   2\n",
      "      29175 |   0.140723  |    0.202750     |   1\n",
      "      29176 |   0.199279  |    0.007592     |   0\n",
      "      29177 |   0.164149  |    0.076911     |   0\n",
      "      29178 |   0.176546  |    0.158090     |   1\n",
      "      29179 |   0.032817  |    0.016456     |   2\n",
      "      29180 |   0.134248  |    0.078135     |   0\n",
      "      29181 |   0.034913  |    0.012787     |   2\n",
      "      29182 |   0.168849  |    0.201356     |   1\n",
      "      29183 |   0.172911  |    0.156348     |   1\n",
      "      29184 |   0.212894  |    0.175591     |   1\n",
      "      29185 |   0.153908  |    0.114673     |   1\n",
      "      29186 |   0.138942  |    0.200538     |   1\n",
      "      29187 |   0.204356  |    0.155470     |   1\n",
      "      29188 |   0.182244  |    0.018818     |   0\n",
      "      29189 |   0.024621  |    0.089011     |   2\n",
      "      29190 |   0.218672  |    0.154487     |   1\n",
      "      29191 |   0.031790  |    0.011333     |   2\n",
      "      29192 |   0.100959  |    0.224028     |   1\n",
      "      29193 |   0.146191  |    0.138430     |   1\n",
      "      29194 |   0.047039  |    0.026596     |   2\n",
      "      29195 |   0.170775  |    0.202551     |   1\n",
      "      29196 |   0.203077  |    0.146467     |   1\n",
      "      29197 |   0.236218  |    0.040818     |   0\n",
      "      29198 |   0.045770  |    0.043429     |   2\n",
      "      29199 |   0.168533  |    0.076277     |   0\n",
      "      29200 |   0.038433  |    0.041004     |   2\n",
      "      29201 |   0.020319  |    0.025358     |   2\n",
      "      29202 |   0.139121  |    0.075795     |   0\n",
      "      29203 |   0.134847  |    0.014368     |   0\n",
      "      29204 |   0.152885  |    0.221259     |   1\n",
      "      29205 |   0.218896  |    0.154954     |   1\n",
      "      29206 |   0.165874  |    0.137886     |   1\n",
      "      29207 |   0.151177  |    0.166071     |   1\n",
      "      29208 |   0.161677  |    0.139851     |   1\n",
      "      29209 |   0.000015  |    0.009686     |   2\n",
      "      29210 |   0.180707  |    0.197955     |   1\n",
      "      29211 |   0.004103  |    0.081275     |   2\n",
      "      29212 |   0.146818  |    0.156542     |   1\n",
      "      29213 |   0.168831  |    0.137382     |   1\n",
      "      29214 |   0.057163  |    0.039507     |   2\n",
      "      29215 |   0.161106  |    0.201503     |   1\n",
      "      29216 |   0.030713  |    0.036630     |   2\n",
      "      29217 |   0.192292  |    0.211681     |   1\n",
      "      29218 |   0.051097  |    0.006947     |   2\n",
      "      29219 |   0.163316  |    0.087985     |   0\n",
      "      29220 |   0.181931  |    0.142696     |   1\n",
      "      29221 |   0.216075  |    0.200150     |   1\n",
      "      29222 |   0.169995  |    0.153007     |   1\n",
      "      29223 |   0.165072  |    0.052480     |   0\n",
      "      29224 |   0.194858  |    0.145260     |   1\n",
      "      29225 |   0.036153  |    0.076504     |   2\n",
      "      29226 |   0.157132  |    0.030891     |   0\n",
      "      29227 |   0.219965  |    0.052305     |   0\n",
      "      29228 |   0.013152  |    0.076270     |   2\n",
      "      29229 |   0.139266  |    0.155247     |   1\n",
      "      29230 |   0.031295  |    0.042569     |   2\n",
      "      29231 |   0.160234  |    0.181452     |   1\n",
      "      29232 |   0.197228  |    0.150948     |   1\n",
      "      29233 |   0.021433  |    0.071569     |   2\n",
      "      29234 |   0.165421  |    0.024176     |   0\n",
      "      29235 |   0.160468  |    0.080497     |   0\n",
      "      29236 |   0.000015  |    0.026695     |   2\n",
      "      29237 |   0.000015  |    0.079101     |   2\n",
      "      29238 |   0.000015  |    0.029431     |   2\n",
      "      29239 |   0.000015  |    0.083554     |   2\n",
      "      29240 |   0.194421  |    0.149965     |   1\n",
      "      29241 |   0.000015  |    0.048098     |   2\n",
      "      29242 |   0.000015  |    0.043027     |   2\n",
      "      29243 |   0.157281  |    0.080671     |   0\n",
      "      29244 |   0.036666  |    0.030178     |   2\n",
      "      29245 |   0.042944  |    0.048551     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 29246: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      29246 |   0.040315  |    0.050218     |   2\n",
      "      29247 |   0.030106  |    0.078501     |   2\n",
      "      29248 |   0.156679  |    0.187560     |   1\n",
      "      29249 |   0.143029  |    0.004687     |   0\n",
      "      29250 |   0.032906  |    0.045638     |   2\n",
      "      29251 |   0.173670  |    0.051695     |   0\n",
      "      29252 |   0.220834  |    0.208770     |   1\n",
      "      29253 |   0.252295  |    0.007568     |   0\n",
      "      29254 |   0.034953  |    0.079210     |   2\n",
      "      29255 |   0.024149  |    0.039949     |   2\n",
      "      29256 |   0.030881  |    0.075337     |   2\n",
      "      29257 |   0.044052  |    0.025362     |   2\n",
      "      29258 |   0.043872  |    0.081941     |   2\n",
      "      29259 |   0.135152  |    0.023158     |   0\n",
      "      29260 |   0.039956  |    0.076443     |   2\n",
      "      29261 |   0.172680  |    0.191664     |   1\n",
      "      29262 |   0.198663  |    0.016671     |   0\n",
      "      29263 |   0.018747  |    0.075738     |   2\n",
      "      29264 | \u001b[94m  0.000015\u001b[0m  |    0.027178     |   2\n",
      "      29265 |   0.177692  |    0.172677     |   1\n",
      "      29266 |   0.004501  |    0.024973     |   2\n",
      "      29267 |   0.139124  |    0.193541     |   1\n",
      "      29268 |   0.177162  |    0.198911     |   1\n",
      "      29269 |   0.129145  |    0.010154     |   0\n",
      "      29270 |   0.196888  |    0.052414     |   0\n",
      "      29271 |   0.181882  |    0.148048     |   1\n",
      "      29272 |   0.052633  |    0.082591     |   2\n",
      "      29273 |   0.185050  |    0.153030     |   1\n",
      "      29274 |   0.029305  |    0.019336     |   2\n",
      "      29275 |   0.053469  |    0.076916     |   2\n",
      "      29276 |   0.148263  |    0.150505     |   1\n",
      "      29277 |   0.036319  |    0.058772     |   2\n",
      "      29278 |   0.013144  |    0.031027     |   2\n",
      "      29279 |   0.151830  |    0.195766     |   1\n",
      "      29280 |   0.030373  |    0.027548     |   2\n",
      "      29281 |   0.169525  |    0.073855     |   0\n",
      "      29282 |   0.148165  |    0.158612     |   1\n",
      "      29283 |   0.148327  |    0.194401     |   1\n",
      "      29284 |   0.152717  |    0.134679     |   1\n",
      "      29285 |   0.023265  |    0.080817     |   2\n",
      "      29286 | \u001b[94m  0.000014\u001b[0m  |    0.039002     |   2\n",
      "      29287 |   0.000014  |    0.076475     |   2\n",
      "      29288 |   0.193400  |    0.042217     |   0\n",
      "      29289 |   0.226587  |    0.223619     |   1\n",
      "      29290 |   0.000014  |    0.013457     |   2\n",
      "      29291 |   0.241434  |    0.206626     |   1\n",
      "      29292 |   0.149886  |    0.006663     |   0\n",
      "      29293 |   0.245866  |    0.047993     |   0\n",
      "      29294 |   0.145906  |    0.197595     |   1\n",
      "      29295 |   0.000015  |    0.053480     |   2\n",
      "      29296 |   0.173446  |    0.208175     |   1\n",
      "      29297 |   0.121401  |    0.146024     |   1\n",
      "      29298 |   0.000014  |    0.020760     |   2\n",
      "      29299 |   0.183915  |    0.188106     |   1\n",
      "      29300 |   0.219694  |    0.187202     |   1\n",
      "      29301 |   0.137312  |    0.016927     |   0\n",
      "      29302 |   0.000014  |    0.078025     |   2\n",
      "      29303 |   0.153436  |    0.157913     |   1\n",
      "      29304 |   0.039829  |    0.041083     |   2\n",
      "      29305 |   0.172091  |    0.099906     |   0\n",
      "      29306 |   0.228926  |    0.123170     |   1\n",
      "      29307 |   0.152866  |    0.159001     |   1\n",
      "      29308 |   0.213275  |    0.105209     |   1\n",
      "      29309 |   0.155681  |    0.049009     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 29311: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      29310 |   0.043145  |    0.024414     |   2\n",
      "      29311 |   0.172452  |    0.075222     |   0\n",
      "      29312 |   0.174672  |    0.191567     |   1\n",
      "      29313 |   0.130657  |    0.168963     |   1\n",
      "      29314 |   0.146490  |    0.008321     |   0\n",
      "      29315 |   0.036631  |    0.048055     |   2\n",
      "      29316 |   0.028427  |    0.053648     |   2\n",
      "      29317 |   0.183627  |    0.073393     |   0\n",
      "      29318 |   0.031232  |    0.034382     |   2\n",
      "      29319 |   0.143094  |    0.196884     |   1\n",
      "      29320 |   0.116479  |    0.154786     |   1\n",
      "      29321 |   0.033667  |    0.029878     |   2\n",
      "      29322 |   0.197305  |    0.181842     |   1\n",
      "      29323 |   0.024283  |    0.021394     |   2\n",
      "      29324 |   0.173675  |    0.064166     |   0\n",
      "      29325 |   0.160256  |    0.142142     |   1\n",
      "      29326 |   0.180316  |    0.042713     |   0\n",
      "      29327 |   0.030655  |    0.051017     |   2\n",
      "      29328 |   0.188279  |    0.219240     |   1\n",
      "      29329 |   0.160547  |    0.167815     |   1\n",
      "      29330 |   0.170414  |    0.139743     |   1\n",
      "      29331 |   0.230472  |    0.042386     |   0\n",
      "      29332 |   0.196020  |    0.080422     |   0\n",
      "      29333 |   0.042763  |    0.039270     |   2\n",
      "      29334 |   0.184595  |    0.044117     |   0\n",
      "      29335 |   0.043576  |    0.078984     |   2\n",
      "      29336 |   0.168944  |    0.194331     |   1\n",
      "      29337 |   0.038962  |    0.011532     |   2\n",
      "      29338 |   0.131832  |    0.249254     |   1\n",
      "      29339 |   0.016973  |    0.076039     |   2\n",
      "      29340 | \u001b[94m  0.000014\u001b[0m  |    0.122414     |   2\n",
      "      29341 |   0.170458  |    0.362562     |   1\n",
      "      29342 |   0.208952  |    0.333227     |   1\n",
      "      29343 |   0.146870  |    0.043540     |   0\n",
      "      29344 |   0.103496  |    0.380269     |   1\n",
      "      29345 |   0.140218  |    0.069180     |   0\n",
      "      29346 |   0.194440  |    0.069849     |   0\n",
      "      29347 |   0.231180  |    0.321171     |   1\n",
      "      29348 |   0.161088  |    0.071086     |   0\n",
      "      29349 |   0.004430  |    0.078320     |   2\n",
      "      29350 |   0.177895  |    0.276917     |   1\n",
      "      29351 |   0.055056  |    0.071318     |   2\n",
      "      29352 |   0.159952  |    0.320067     |   1\n",
      "      29353 |   0.028343  |    0.043978     |   2\n",
      "      29354 |   0.202043  |    0.070754     |   0\n",
      "      29355 |   0.175696  |    0.330475     |   1\n",
      "      29356 |   0.054916  |    0.036262     |   2\n",
      "      29357 |   0.036761  |    0.068204     |   2\n",
      "      29358 |   0.014283  |    0.134758     |   2\n",
      "      29359 |   0.177006  |    0.070231     |   0\n",
      "      29360 |   0.174980  |    0.123070     |   0\n",
      "      29361 |   0.031776  |    0.036423     |   2\n",
      "      29362 |   0.178870  |    0.074323     |   0\n",
      "      29363 |   0.193947  |    0.150585     |   0\n",
      "      29364 |   0.132382  |    0.070240     |   0\n",
      "      29365 |   0.021681  |    0.075049     |   2\n",
      "      29366 |   0.195693  |    0.325103     |   1\n",
      "      29367 |   0.121629  |    0.079921     |   0\n",
      "      29368 |   0.208992  |    0.275345     |   1\n",
      "      29369 |   0.181830  |    0.478517     |   1\n",
      "      29370 |   0.000014  |    0.121095     |   2\n",
      "      29371 |   0.000014  |    0.093920     |   2\n",
      "      29372 |   0.158121  |    0.329153     |   1\n",
      "      29373 |   0.207961  |    0.287652     |   1\n",
      "      29374 |   0.185939  |    0.271617     |   1\n",
      "      29375 |   0.173733  |    0.037725     |   0\n",
      "      29376 |   0.104052  |    0.068855     |   0\n",
      "      29377 |   0.170625  |    0.046777     |   0\n",
      "      29378 |   0.171232  |    0.357464     |   1\n",
      "      29379 |   0.165643  |    0.095246     |   0\n",
      "      29380 |   0.000015  |    0.085413     |   2\n",
      "      29381 |   0.193708  |    0.069685     |   0\n",
      "      29382 |   0.000015  |    0.120671     |   2\n",
      "      29383 |   0.172210  |    0.041235     |   0\n",
      "      29384 |   0.000015  |    0.165255     |   2\n",
      "      29385 |   0.183081  |    0.070004     |   0\n",
      "      29386 |   0.000014  |    0.103756     |   2\n",
      "      29387 |   0.176573  |    0.346584     |   1\n",
      "      29388 |   0.175238  |    0.113354     |   0\n",
      "      29389 |   0.042018  |    0.094377     |   2\n",
      "      29390 |   0.189268  |    0.191736     |   0\n",
      "      29391 |   0.179495  |    0.081522     |   0\n",
      "      29392 |   0.226423  |    0.220107     |   1\n",
      "      29393 |   0.176844  |    0.356624     |   1\n",
      "      29394 |   0.206118  |    0.311397     |   1\n",
      "      29395 |   0.043918  |    0.077970     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 29396: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      29396 |   0.037162  |    0.050066     |   2\n",
      "      29397 |   0.166086  |    0.080933     |   0\n",
      "      29398 |   0.225524  |    0.038801     |   0\n",
      "      29399 |   0.151580  |    0.101833     |   0\n",
      "      29400 |   0.028845  |    0.044959     |   2\n",
      "      29401 |   0.165026  |    0.159251     |   0\n",
      "      29402 |   0.033243  |    0.095478     |   2\n",
      "      29403 |   0.139882  |    0.052664     |   0\n",
      "      29404 |   0.196158  |    0.254907     |   1\n",
      "      29405 |   0.219969  |    0.170812     |   1\n",
      "      29406 |   0.149243  |    0.247339     |   1\n",
      "      29407 |   0.168449  |    0.099935     |   0\n",
      "      29408 |   0.165051  |    0.025710     |   0\n",
      "      29409 |   0.191844  |    0.326073     |   1\n",
      "      29410 |   0.173786  |    0.286942     |   1\n",
      "      29411 |   0.240794  |    0.321840     |   1\n",
      "      29412 |   0.158215  |    0.012130     |   0\n",
      "      29413 |   0.244770  |    0.365538     |   1\n",
      "      29414 |   0.169565  |    0.116289     |   0\n",
      "      29415 |   0.177209  |    0.033167     |   0\n",
      "      29416 |   0.155584  |    0.074562     |   0\n",
      "      29417 |   0.186751  |    0.217986     |   1\n",
      "      29418 |   0.033302  |    0.047433     |   2\n",
      "      29419 |   0.024534  |    0.054393     |   2\n",
      "      29420 |   0.033220  |    0.085964     |   2\n",
      "      29421 |   0.196023  |    0.082120     |   0\n",
      "      29422 |   0.041415  |    0.045361     |   2\n",
      "      29423 |   0.047974  |    0.064525     |   2\n",
      "      29424 |   0.174866  |    0.038099     |   0\n",
      "      29425 |   0.131832  |    0.281724     |   1\n",
      "      29426 |   0.039546  |    0.025664     |   2\n",
      "      29427 |   0.017637  |    0.095319     |   2\n",
      "      29428 |   0.000015  |    0.012338     |   2\n",
      "      29429 |   0.005211  |    0.121464     |   2\n",
      "      29430 |   0.193354  |    0.009381     |   0\n",
      "      29431 |   0.055768  |    0.077001     |   2\n",
      "      29432 |   0.210588  |    0.078505     |   0\n",
      "      29433 |   0.033753  |    0.030910     |   2\n",
      "      29434 |   0.133595  |    0.041083     |   0\n",
      "      29435 |   0.151117  |    0.050257     |   0\n",
      "      29436 |   0.128559  |    0.239049     |   1\n",
      "      29437 |   0.137551  |    0.203364     |   1\n",
      "      29438 |   0.055366  |    0.008766     |   2\n",
      "      29439 |   0.174220  |    0.199049     |   1\n",
      "      29440 |   0.170609  |    0.153760     |   1\n",
      "      29441 |   0.200475  |    0.152274     |   1\n",
      "      29442 |   0.111202  |    0.150911     |   1\n",
      "      29443 |   0.039859  |    0.071137     |   2\n",
      "      29444 |   0.015589  |    0.053604     |   2\n",
      "      29445 |   0.158952  |    0.051466     |   0\n",
      "      29446 |   0.183139  |    0.204719     |   1\n",
      "      29447 |   0.211938  |    0.203710     |   1\n",
      "      29448 |   0.231489  |    0.159379     |   1\n",
      "      29449 |   0.145515  |    0.215378     |   1\n",
      "      29450 |   0.213855  |    0.212767     |   1\n",
      "      29451 |   0.166016  |    0.003736     |   0\n",
      "      29452 |   0.029391  |    0.043624     |   2\n",
      "      29453 |   0.023070  |    0.073969     |   2\n",
      "      29454 |   0.159049  |    0.029427     |   0\n",
      "      29455 |   0.193702  |    0.222032     |   1\n",
      "      29456 |   0.188116  |    0.005153     |   0\n",
      "      29457 |   0.000015  |    0.079806     |   2\n",
      "      29458 |   0.156391  |    0.030978     |   0\n",
      "      29459 |   0.000015  |    0.107863     |   2\n",
      "      29460 |   0.187272  |    0.148325     |   1\n",
      "      29461 |   0.000015  |    0.046314     |   2\n",
      "      29462 |   0.000015  |    0.035670     |   2\n",
      "      29463 |   0.199076  |    0.192874     |   1\n",
      "      29464 |   0.000015  |    0.025938     |   2\n",
      "      29465 |   0.150800  |    0.050264     |   0\n",
      "      29466 |   0.206452  |    0.079518     |   0\n",
      "      29467 |   0.183485  |    0.155071     |   1\n",
      "      29468 |   0.000015  |    0.026193     |   2\n",
      "      29469 |   0.177873  |    0.081209     |   0\n",
      "      29470 |   0.148675  |    0.183251     |   1\n",
      "      29471 |   0.038474  |    0.010907     |   2\n",
      "      29472 |   0.152102  |    0.087609     |   0\n",
      "      29473 |   0.179641  |    0.009812     |   0\n",
      "      29474 |   0.042354  |    0.049789     |   2\n",
      "      29475 |   0.195674  |    0.143273     |   1\n",
      "      29476 |   0.198729  |    0.139919     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 29477: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      29477 |   0.191146  |    0.042502     |   0\n",
      "      29478 |   0.188474  |    0.205598     |   1\n",
      "      29479 |   0.166137  |    0.155063     |   1\n",
      "      29480 |   0.125260  |    0.151295     |   1\n",
      "      29481 |   0.039968  |    0.024473     |   2\n",
      "      29482 |   0.129342  |    0.197235     |   1\n",
      "      29483 |   0.170668  |    0.042088     |   0\n",
      "      29484 |   0.170516  |    0.048557     |   0\n",
      "      29485 |   0.171593  |    0.046109     |   0\n",
      "      29486 |   0.029559  |    0.069483     |   2\n",
      "      29487 |   0.034272  |    0.041490     |   2\n",
      "      29488 |   0.171255  |    0.186819     |   1\n",
      "      29489 |   0.226688  |    0.043221     |   0\n",
      "      29490 |   0.152134  |    0.043127     |   0\n",
      "      29491 |   0.034753  |    0.022833     |   2\n",
      "      29492 |   0.243962  |    0.080070     |   0\n",
      "      29493 |   0.168204  |    0.040123     |   0\n",
      "      29494 |   0.177000  |    0.080113     |   0\n",
      "      29495 |   0.178035  |    0.142465     |   1\n",
      "      29496 |   0.024298  |    0.045452     |   2\n",
      "      29497 |   0.147794  |    0.053992     |   0\n",
      "      29498 |   0.191037  |    0.137600     |   1\n",
      "      29499 |   0.177906  |    0.200706     |   1\n",
      "      29500 |   0.034337  |    0.049110     |   2\n",
      "      29501 |   0.181370  |    0.075924     |   0\n",
      "      29502 |   0.044234  |    0.046071     |   2\n",
      "      29503 |   0.143999  |    0.072504     |   0\n",
      "      29504 |   0.030532  |    0.021855     |   2\n",
      "      29505 |   0.034676  |    0.075695     |   2\n",
      "      29506 |   0.031837  |    0.065752     |   2\n",
      "      29507 |   0.139620  |    0.166376     |   1\n",
      "      29508 |   0.024382  |    0.015317     |   2\n",
      "      29509 |   0.171410  |    0.202164     |   1\n",
      "      29510 |   0.161044  |    0.037642     |   0\n",
      "      29511 |   0.201291  |    0.075571     |   0\n",
      "      29512 |   0.149837  |    0.028001     |   0\n",
      "      29513 |   0.194607  |    0.202929     |   1\n",
      "      29514 |   0.172503  |    0.021701     |   0\n",
      "      29515 |   0.033152  |    0.077349     |   2\n",
      "      29516 |   0.044867  |    0.038351     |   2\n",
      "      29517 |   0.046685  |    0.088339     |   2\n",
      "      29518 |   0.167071  |    0.206853     |   1\n",
      "      29519 |   0.193124  |    0.134247     |   1\n",
      "      29520 |   0.038007  |    0.045617     |   2\n",
      "      29521 |   0.018769  |    0.041511     |   2\n",
      "      29522 |   0.134098  |    0.073206     |   0\n",
      "      29523 |   0.000014  |    0.032771     |   2\n",
      "      29524 |   0.173779  |    0.216580     |   1\n",
      "      29525 |   0.167479  |    0.005750     |   0\n",
      "      29526 |   0.172983  |    0.220570     |   1\n",
      "      29527 |   0.213511  |    0.183519     |   1\n",
      "      29528 |   0.003999  |    0.025126     |   2\n",
      "      29529 |   0.185174  |    0.185261     |   1\n",
      "      29530 |   0.179065  |    0.163633     |   1\n",
      "      29531 |   0.183140  |    0.201556     |   1\n",
      "      29532 |   0.187040  |    0.022504     |   0\n",
      "      29533 |   0.206137  |    0.074738     |   0\n",
      "      29534 |   0.191549  |    0.152511     |   1\n",
      "      29535 |   0.154254  |    0.193868     |   1\n",
      "      29536 |   0.178801  |    0.021463     |   0\n",
      "      29537 |   0.166301  |    0.053370     |   0\n",
      "      29538 |   0.128033  |    0.188433     |   1\n",
      "      29539 |   0.052622  |    0.044706     |   2\n",
      "      29540 |   0.179962  |    0.136494     |   1\n",
      "      29541 |   0.172563  |    0.047073     |   0\n",
      "      29542 |   0.311640  |    0.047768     |   0\n",
      "      29543 |   0.028857  |    0.082743     |   2\n",
      "      29544 |   0.204356  |    0.187671     |   1\n",
      "      29545 |   0.133098  |    0.003426     |   0\n",
      "      29546 |   0.052011  |    0.052038     |   2\n",
      "      29547 |   0.038763  |    0.049452     |   2\n",
      "      29548 |   0.215185  |    0.090963     |   0\n",
      "      29549 |   0.173053  |    0.146783     |   1\n",
      "      29550 |   0.133070  |    0.192492     |   1\n",
      "      29551 |   0.015050  |    0.003605     |   2\n",
      "      29552 |   0.030387  |    0.040307     |   2\n",
      "      29553 |   0.021833  |    0.072426     |   2\n",
      "      29554 |   0.153146  |    0.023935     |   0\n",
      "      29555 |   0.165508  |    0.082957     |   0\n",
      "      29556 | \u001b[94m  0.000014\u001b[0m  |    0.006437     |   2\n",
      "      29557 |   0.000014  |    0.074339     |   2\n",
      "      29558 |   0.141781  |    0.039106     |   0\n",
      "      29559 |   0.234834  |    0.187381     |   1\n",
      "      29560 |   0.160326  |    0.033897     |   0\n",
      "      29561 |   0.160647  |    0.205724     |   1\n",
      "      29562 |   0.000014  |    0.022292     |   2\n",
      "      29563 |   0.159526  |    0.075189     |   0\n",
      "      29564 |   0.000014  |    0.045010     |   2\n",
      "      29565 |   0.222965  |    0.248026     |   1\n",
      "      29566 |   0.158169  |    0.008314     |   0\n",
      "      29567 |   0.000014  |    0.044118     |   2\n",
      "      29568 |   0.000014  |    0.041424     |   2\n",
      "      29569 |   0.192531  |    0.079792     |   0\n",
      "      29570 |   0.043060  |    0.024893     |   2\n",
      "      29571 |   0.164835  |    0.071611     |   0\n",
      "      29572 |   0.138791  |    0.033912     |   0\n",
      "      29573 |   0.220098  |    0.210357     |   1\n",
      "      29574 |   0.171474  |    0.142116     |   1\n",
      "      29575 |   0.187911  |    0.019606     |   0\n",
      "      29576 |   0.042106  |    0.074724     |   2\n",
      "      29577 |   0.191362  |    0.159428     |   1\n",
      "      29578 |   0.168803  |    0.053960     |   0\n",
      "      29579 |   0.156640  |    0.178614     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 29580: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      29580 |   0.038620  |    0.024791     |   2\n",
      "      29581 |   0.160124  |    0.196141     |   1\n",
      "      29582 |   0.222291  |    0.052746     |   0\n",
      "      29583 |   0.166777  |    0.205993     |   1\n",
      "      29584 |   0.127074  |    0.155852     |   1\n",
      "      29585 |   0.130577  |    0.023764     |   0\n",
      "      29586 |   0.030551  |    0.075413     |   2\n",
      "      29587 |   0.179742  |    0.026784     |   0\n",
      "      29588 |   0.032268  |    0.046554     |   2\n",
      "      29589 |   0.154927  |    0.054690     |   0\n",
      "      29590 |   0.218101  |    0.139988     |   1\n",
      "      29591 |   0.145067  |    0.040244     |   0\n",
      "      29592 |   0.153141  |    0.047508     |   0\n",
      "      29593 |   0.032469  |    0.075225     |   2\n",
      "      29594 |   0.230750  |    0.138915     |   1\n",
      "      29595 |   0.170915  |    0.045351     |   0\n",
      "      29596 |   0.154944  |    0.041719     |   0\n",
      "      29597 |   0.024412  |    0.043719     |   2\n",
      "      29598 |   0.031563  |    0.043591     |   2\n",
      "      29599 |   0.042588  |    0.040913     |   2\n",
      "      29600 |   0.165220  |    0.182397     |   1\n",
      "      29601 |   0.200617  |    0.016135     |   0\n",
      "      29602 |   0.174199  |    0.082890     |   0\n",
      "      29603 |   0.155069  |    0.019961     |   0\n",
      "      29604 |   0.196785  |    0.073690     |   0\n",
      "      29605 |   0.047304  |    0.096154     |   2\n",
      "      29606 |   0.217213  |    0.142314     |   1\n",
      "      29607 |   0.037956  |    0.043998     |   2\n",
      "      29608 |   0.018077  |    0.075624     |   2\n",
      "      29609 |   0.171966  |    0.152142     |   1\n",
      "      29610 |   0.191579  |    0.153957     |   1\n",
      "      29611 |   0.237925  |    0.061407     |   0\n",
      "      29612 |   0.165829  |    0.160449     |   1\n",
      "      29613 |   0.166415  |    0.042949     |   0\n",
      "      29614 |   0.177462  |    0.042834     |   0\n",
      "      29615 |   0.184357  |    0.044065     |   0\n",
      "      29616 |   0.202568  |    0.077390     |   0\n",
      "      29617 |   0.230353  |    0.162787     |   1\n",
      "      29618 |   0.000015  |    0.042427     |   2\n",
      "      29619 |   0.094187  |    0.212463     |   1\n",
      "      29620 |   0.187897  |    0.005269     |   0\n",
      "      29621 |   0.201208  |    0.041034     |   0\n",
      "      29622 |   0.004059  |    0.067887     |   2\n",
      "      29623 |   0.132375  |    0.173859     |   1\n",
      "      29624 |   0.054462  |    0.040382     |   2\n",
      "      29625 |   0.031528  |    0.040770     |   2\n",
      "      29626 |   0.179474  |    0.201532     |   1\n",
      "      29627 |   0.131020  |    0.006537     |   0\n",
      "      29628 |   0.154352  |    0.078688     |   0\n",
      "      29629 |   0.054717  |    0.051664     |   2\n",
      "      29630 |   0.267392  |    0.141508     |   1\n",
      "      29631 |   0.038441  |    0.044320     |   2\n",
      "      29632 |   0.210789  |    0.059972     |   0\n",
      "      29633 |   0.190159  |    0.150748     |   1\n",
      "      29634 |   0.182831  |    0.077635     |   0\n",
      "      29635 |   0.015136  |    0.024247     |   2\n",
      "      29636 |   0.168797  |    0.080973     |   0\n",
      "      29637 |   0.177503  |    0.027129     |   0\n",
      "      29638 |   0.034917  |    0.047898     |   2\n",
      "      29639 |   0.169774  |    0.056591     |   0\n",
      "      29640 |   0.222022  |    0.199592     |   1\n",
      "      29641 |   0.140670  |    0.004068     |   0\n",
      "      29642 |   0.152502  |    0.214114     |   1\n",
      "      29643 |   0.188751  |    0.185456     |   1\n",
      "      29644 |   0.178053  |    0.133070     |   1\n",
      "      29645 |   0.168215  |    0.022941     |   0\n",
      "      29646 |   0.022973  |    0.075554     |   2\n",
      "      29647 |   0.161531  |    0.157161     |   1\n",
      "      29648 |   0.000014  |    0.050035     |   2\n",
      "      29649 |   0.236078  |    0.160841     |   1\n",
      "      29650 |   0.170142  |    0.152913     |   1\n",
      "      29651 |   0.137754  |    0.006221     |   0\n",
      "      29652 |   0.159102  |    0.076261     |   0\n",
      "      29653 |   0.000015  |    0.025508     |   2\n",
      "      29654 |   0.143973  |    0.201480     |   1\n",
      "      29655 |   0.188034  |    0.013915     |   0\n",
      "      29656 |   0.150254  |    0.073888     |   0\n",
      "      29657 |   0.139288  |    0.027345     |   0\n",
      "      29658 |   0.140411  |    0.095058     |   0\n",
      "      29659 |   0.183456  |    0.148632     |   1\n",
      "      29660 |   0.110846  |    0.016395     |   0\n",
      "      29661 |   0.209425  |    0.190233     |   1\n",
      "      29662 |   0.166884  |    0.157979     |   1\n",
      "      29663 |   0.167504  |    0.007392     |   0\n",
      "      29664 |   0.000015  |    0.082786     |   2\n",
      "      29665 |   0.191932  |    0.144075     |   1\n",
      "      29666 |   0.000015  |    0.075295     |   2\n",
      "      29667 |   0.000015  |    0.018075     |   2\n",
      "      29668 |   0.000015  |    0.085915     |   2\n",
      "      29669 |   0.213199  |    0.194924     |   1\n",
      "      29670 |   0.158981  |    0.143149     |   1\n",
      "      29671 |   0.043481  |    0.043327     |   2\n",
      "      29672 |   0.043251  |    0.034905     |   2\n",
      "      29673 |   0.119204  |    0.153963     |   1\n",
      "      29674 |   0.169355  |    0.042934     |   0\n",
      "      29675 |   0.141648  |    0.048829     |   0\n",
      "      29676 |   0.138968  |    0.180607     |   1\n",
      "      29677 |   0.206646  |    0.205213     |   1\n",
      "      29678 |   0.161555  |    0.022401     |   0\n",
      "      29679 |   0.172326  |    0.215938     |   1\n",
      "      29680 |   0.135575  |    0.139284     |   1\n",
      "      29681 |   0.171611  |    0.232359     |   1\n",
      "      29682 |   0.192873  |    0.151316     |   1\n",
      "      29683 |   0.157294  |    0.137494     |   1\n",
      "      29684 |   0.208258  |    0.011715     |   0\n",
      "      29685 |   0.198109  |    0.087624     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 29686: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      29686 |   0.166641  |    0.170276     |   1\n",
      "      29687 |   0.038337  |    0.025004     |   2\n",
      "      29688 |   0.129639  |    0.189166     |   1\n",
      "      29689 |   0.028728  |    0.021943     |   2\n",
      "      29690 |   0.113366  |    0.199518     |   1\n",
      "      29691 |   0.032917  |    0.004566     |   2\n",
      "      29692 |   0.159725  |    0.046362     |   0\n",
      "      29693 |   0.258723  |    0.080203     |   0\n",
      "      29694 |   0.187757  |    0.148785     |   1\n",
      "      29695 |   0.035249  |    0.042718     |   2\n",
      "      29696 |   0.147111  |    0.048468     |   0\n",
      "      29697 |   0.192906  |    0.071458     |   0\n",
      "      29698 |   0.023956  |    0.026910     |   2\n",
      "      29699 |   0.137576  |    0.209280     |   1\n",
      "      29700 |   0.029592  |    0.022800     |   2\n",
      "      29701 |   0.162076  |    0.203631     |   1\n",
      "      29702 |   0.243158  |    0.114580     |   1\n",
      "      29703 |   0.180068  |    0.214779     |   1\n",
      "      29704 |   0.043617  |    0.006694     |   2\n",
      "      29705 |   0.182409  |    0.192810     |   1\n",
      "      29706 |   0.044917  |    0.036072     |   2\n",
      "      29707 |   0.152885  |    0.193413     |   1\n",
      "      29708 |   0.038726  |    0.006849     |   2\n",
      "      29709 |   0.156973  |    0.086741     |   0\n",
      "      29710 |   0.166454  |    0.163917     |   1\n",
      "      29711 |   0.150442  |    0.044353     |   0\n",
      "      29712 |   0.150863  |    0.075472     |   0\n",
      "      29713 |   0.179829  |    0.029162     |   0\n",
      "      29714 |   0.019243  |    0.083619     |   2\n",
      "      29715 |   0.170694  |    0.201014     |   1\n",
      "      29716 |   0.000014  |    0.015455     |   2\n",
      "      29717 |   0.218765  |    0.078048     |   0\n",
      "      29718 |   0.004022  |    0.032670     |   2\n",
      "      29719 |   0.174799  |    0.195949     |   1\n",
      "      29720 |   0.197166  |    0.038881     |   0\n",
      "      29721 |   0.132368  |    0.195831     |   1\n",
      "      29722 |   0.153028  |    0.042033     |   0\n",
      "      29723 |   0.052675  |    0.054085     |   2\n",
      "      29724 |   0.208558  |    0.047425     |   0\n",
      "      29725 |   0.031759  |    0.048349     |   2\n",
      "      29726 |   0.183306  |    0.075108     |   0\n",
      "      29727 |   0.052679  |    0.005920     |   2\n",
      "      29728 |   0.203430  |    0.090352     |   0\n",
      "      29729 |   0.128868  |    0.198167     |   1\n",
      "      29730 |   0.150041  |    0.008978     |   0\n",
      "      29731 |   0.159918  |    0.086612     |   0\n",
      "      29732 |   0.198472  |    0.222305     |   1\n",
      "      29733 |   0.220286  |    0.264366     |   1\n",
      "      29734 |   0.038504  |    0.019898     |   2\n",
      "      29735 |   0.144362  |    0.093679     |   0\n",
      "      29736 |   0.153810  |    0.038949     |   0\n",
      "      29737 |   0.015685  |    0.083354     |   2\n",
      "      29738 |   0.180711  |    0.151507     |   1\n",
      "      29739 |   0.194326  |    0.245852     |   1\n",
      "      29740 |   0.036117  |    0.032184     |   2\n",
      "      29741 |   0.191303  |    0.203888     |   1\n",
      "      29742 |   0.195114  |    0.203463     |   1\n",
      "      29743 |   0.022685  |    0.042903     |   2\n",
      "      29744 |   0.171528  |    0.190002     |   1\n",
      "      29745 |   0.130485  |    0.036899     |   0\n",
      "      29746 |   0.151780  |    0.076663     |   0\n",
      "      29747 |   0.000015  |    0.039157     |   2\n",
      "      29748 |   0.177219  |    0.193816     |   1\n",
      "      29749 |   0.000015  |    0.071650     |   2\n",
      "      29750 |   0.177589  |    0.042190     |   0\n",
      "      29751 |   0.000015  |    0.052247     |   2\n",
      "      29752 |   0.218893  |    0.055746     |   0\n",
      "      29753 |   0.215079  |    0.157192     |   1\n",
      "      29754 |   0.000015  |    0.051207     |   2\n",
      "      29755 |   0.000015  |    0.047299     |   2\n",
      "      29756 |   0.129526  |    0.198043     |   1\n",
      "      29757 |   0.188929  |    0.022427     |   0\n",
      "      29758 |   0.186991  |    0.078731     |   0\n",
      "      29759 |   0.178714  |    0.060070     |   0\n",
      "      29760 |   0.000015  |    0.040192     |   2\n",
      "      29761 |   0.168282  |    0.029797     |   0\n",
      "      29762 |   0.044215  |    0.077194     |   2\n",
      "      29763 |   0.182948  |    0.036436     |   0\n",
      "      29764 |   0.042681  |    0.053852     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 29765: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      29765 |   0.193156  |    0.219961     |   1\n",
      "      29766 |   0.042672  |    0.016058     |   2\n",
      "      29767 |   0.179129  |    0.073012     |   0\n",
      "      29768 |   0.153846  |    0.045703     |   0\n",
      "      29769 |   0.186268  |    0.032659     |   0\n",
      "      29770 |   0.180876  |    0.209222     |   1\n",
      "      29771 |   0.119014  |    0.132344     |   1\n",
      "      29772 |   0.029285  |    0.040839     |   2\n",
      "      29773 |   0.119890  |    0.081898     |   0\n",
      "      29774 |   0.034648  |    0.048475     |   2\n",
      "      29775 |   0.208080  |    0.049953     |   0\n",
      "      29776 |   0.123795  |    0.044363     |   0\n",
      "      29777 |   0.188413  |    0.064883     |   0\n",
      "      29778 |   0.189759  |    0.201045     |   1\n",
      "      29779 |   0.033729  |    0.016351     |   2\n",
      "      29780 |   0.186584  |    0.084754     |   0\n",
      "      29781 |   0.176671  |    0.256936     |   1\n",
      "      29782 |   0.025177  |    0.078928     |   2\n",
      "      29783 |   0.146836  |    0.079027     |   0\n",
      "      29784 |   0.169147  |    0.098162     |   0\n",
      "      29785 |   0.191890  |    0.250577     |   1\n",
      "      29786 |   0.031798  |    0.138183     |   2\n",
      "      29787 |   0.044129  |    0.049222     |   2\n",
      "      29788 |   0.245055  |    0.265254     |   1\n",
      "      29789 |   0.230309  |    0.091189     |   0\n",
      "      29790 |   0.045164  |    0.003391     |   2\n",
      "      29791 |   0.038447  |    0.086172     |   2\n",
      "      29792 |   0.179416  |    0.277968     |   1\n",
      "      29793 |   0.019068  |    0.029623     |   2\n",
      "      29794 |   0.176291  |    0.095460     |   0\n",
      "      29795 |   0.203658  |    0.286855     |   1\n",
      "      29796 |   0.128325  |    0.083790     |   0\n",
      "      29797 |   0.193852  |    0.337876     |   1\n",
      "      29798 |   0.190045  |    0.245286     |   1\n",
      "      29799 |   0.192117  |    0.083486     |   0\n",
      "      29800 |   0.153270  |    0.044136     |   0\n",
      "      29801 |   0.000015  |    0.133086     |   2\n",
      "      29802 |   0.005001  |    0.039757     |   2\n",
      "      29803 |   0.168045  |    0.094866     |   0\n",
      "      29804 |   0.146088  |    0.174965     |   1\n",
      "      29805 |   0.053279  |    0.073155     |   2\n",
      "      29806 |   0.031235  |    0.049555     |   2\n",
      "      29807 |   0.214493  |    0.248175     |   1\n",
      "      29808 |   0.202029  |    0.134221     |   1\n",
      "      29809 |   0.164352  |    0.080290     |   0\n",
      "      29810 |   0.053827  |    0.029682     |   2\n",
      "      29811 |   0.039171  |    0.088886     |   2\n",
      "      29812 |   0.162873  |    0.274098     |   1\n",
      "      29813 |   0.014917  |    0.009189     |   2\n",
      "      29814 |   0.297109  |    0.275653     |   1\n",
      "      29815 |   0.225779  |    0.231021     |   1\n",
      "      29816 |   0.032893  |    0.072485     |   2\n",
      "      29817 |   0.204884  |    0.071175     |   0\n",
      "      29818 |   0.226987  |    0.405842     |   1\n",
      "      29819 |   0.163247  |    0.031980     |   0\n",
      "      29820 |   0.156692  |    0.264210     |   1\n",
      "      29821 |   0.156551  |    0.023860     |   0\n",
      "      29822 |   0.024516  |    0.069663     |   2\n",
      "      29823 |   0.189406  |    0.271712     |   1\n",
      "      29824 |   0.000015  |    0.073061     |   2\n",
      "      29825 |   0.180951  |    0.073976     |   0\n",
      "      29826 |   0.118885  |    0.270183     |   1\n",
      "      29827 |   0.180037  |    0.220952     |   1\n",
      "      29828 |   0.000015  |    0.071548     |   2\n",
      "      29829 |   0.169920  |    0.278150     |   1\n",
      "      29830 |   0.145520  |    0.071746     |   0\n",
      "      29831 |   0.212587  |    0.195922     |   1\n",
      "      29832 |   0.192331  |    0.044190     |   0\n",
      "      29833 |   0.190965  |    0.091488     |   0\n",
      "      29834 |   0.175234  |    0.141633     |   1\n",
      "      29835 |   0.180830  |    0.073149     |   0\n",
      "      29836 |   0.195978  |    0.153066     |   1\n",
      "      29837 |   0.155434  |    0.043447     |   0\n",
      "      29838 |   0.184074  |    0.230763     |   1\n",
      "      29839 |   0.000015  |    0.026578     |   2\n",
      "      29840 |   0.000015  |    0.081300     |   2\n",
      "      29841 |   0.139803  |    0.034295     |   0\n",
      "      29842 |   0.257202  |    0.224901     |   1\n",
      "      29843 |   0.000015  |    0.021596     |   2\n",
      "      29844 |   0.112819  |    0.075388     |   0\n",
      "      29845 |   0.000015  |    0.046257     |   2\n",
      "      29846 |   0.206077  |    0.205994     |   1\n",
      "      29847 |   0.194194  |    0.188096     |   1\n",
      "      29848 |   0.181272  |    0.242491     |   1\n",
      "      29849 |   0.040417  |    0.081231     |   2\n",
      "      29850 |   0.204533  |    0.050504     |   0\n",
      "      29851 |   0.177020  |    0.130209     |   0\n",
      "      29852 |   0.239826  |    0.018057     |   0\n",
      "      29853 |   0.043452  |    0.120268     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 29854: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      29854 |   0.040040  |    0.017489     |   2\n",
      "      29855 |   0.028732  |    0.045953     |   2\n",
      "      29856 |   0.033039  |    0.105381     |   2\n",
      "      29857 |   0.194203  |    0.341007     |   1\n",
      "      29858 |   0.177599  |    0.215345     |   1\n",
      "      29859 |   0.221454  |    0.140527     |   1\n",
      "      29860 |   0.034673  |    0.083066     |   2\n",
      "      29861 |   0.141394  |    0.223643     |   1\n",
      "      29862 |   0.181540  |    0.179987     |   1\n",
      "      29863 |   0.023935  |    0.083609     |   2\n",
      "      29864 |   0.230188  |    0.191747     |   1\n",
      "      29865 |   0.169031  |    0.020446     |   0\n",
      "      29866 |   0.233313  |    0.165476     |   1\n",
      "      29867 |   0.147571  |    0.202943     |   1\n",
      "      29868 |   0.259095  |    0.157181     |   1\n",
      "      29869 |   0.180292  |    0.156828     |   1\n",
      "      29870 |   0.031133  |    0.044959     |   2\n",
      "      29871 |   0.179878  |    0.073155     |   0\n",
      "      29872 |   0.167030  |    0.045535     |   0\n",
      "      29873 |   0.042140  |    0.079268     |   2\n",
      "      29874 |   0.185547  |    0.148791     |   1\n",
      "      29875 |   0.217653  |    0.020119     |   0\n",
      "      29876 |   0.041499  |    0.051702     |   2\n",
      "      29877 |   0.192560  |    0.195186     |   1\n",
      "      29878 |   0.176776  |    0.195820     |   1\n",
      "      29879 |   0.215340  |    0.007758     |   0\n",
      "      29880 |   0.176398  |    0.220194     |   1\n",
      "      29881 |   0.034338  |    0.028621     |   2\n",
      "      29882 |   0.017689  |    0.083581     |   2\n",
      "      29883 |   0.181049  |    0.154232     |   1\n",
      "      29884 |   0.187814  |    0.159044     |   1\n",
      "      29885 |   0.000015  |    0.046858     |   2\n",
      "      29886 |   0.144885  |    0.202114     |   1\n",
      "      29887 |   0.004469  |    0.016225     |   2\n",
      "      29888 |   0.056026  |    0.083361     |   2\n",
      "      29889 |   0.268587  |    0.033695     |   0\n",
      "      29890 |   0.216700  |    0.081719     |   0\n",
      "      29891 |   0.180136  |    0.027253     |   0\n",
      "      29892 |   0.028163  |    0.082348     |   2\n",
      "      29893 |   0.169438  |    0.153042     |   1\n",
      "      29894 |   0.180407  |    0.183385     |   1\n",
      "      29895 |   0.052294  |    0.030840     |   2\n",
      "      29896 |   0.154434  |    0.203173     |   1\n",
      "      29897 |   0.035700  |    0.077758     |   2\n",
      "      29898 |   0.207887  |    0.210842     |   1\n",
      "      29899 |   0.284042  |    0.093715     |   1\n",
      "      29900 |   0.131815  |    0.199739     |   1\n",
      "      29901 |   0.202574  |    0.029399     |   0\n",
      "      29902 |   0.144071  |    0.193781     |   1\n",
      "      29903 |   0.254667  |    0.159678     |   1\n",
      "      29904 |   0.160827  |    0.148642     |   1\n",
      "      29905 |   0.189210  |    0.196241     |   1\n",
      "      29906 |   0.014578  |    0.006464     |   2\n",
      "      29907 |   0.200546  |    0.078527     |   0\n",
      "      29908 |   0.216128  |    0.039828     |   0\n",
      "      29909 |   0.149342  |    0.209463     |   1\n",
      "      29910 |   0.032554  |    0.020944     |   2\n",
      "      29911 |   0.023376  |    0.080517     |   2\n",
      "      29912 |   0.143818  |    0.023100     |   0\n",
      "      29913 |   0.154821  |    0.084190     |   0\n",
      "      29914 |   0.178055  |    0.038220     |   0\n",
      "      29915 |   0.214027  |    0.200947     |   1\n",
      "      29916 |   0.179876  |    0.149029     |   1\n",
      "      29917 | \u001b[94m  0.000014\u001b[0m  |    0.012917     |   2\n",
      "      29918 |   0.150451  |    0.075710     |   0\n",
      "      29919 |   0.000014  |    0.012716     |   2\n",
      "      29920 |   0.227217  |    0.078706     |   0\n",
      "      29921 |   0.132455  |    0.041389     |   0\n",
      "      29922 | \u001b[94m  0.000014\u001b[0m  |    0.075214     |   2\n",
      "      29923 |   0.000014  |    0.040365     |   2\n",
      "      29924 |   0.160461  |    0.045845     |   0\n",
      "      29925 |   0.168232  |    0.075038     |   0\n",
      "      29926 | \u001b[94m  0.000014\u001b[0m  |    0.028789     |   2\n",
      "      29927 | \u001b[94m  0.000014\u001b[0m  |    0.081293     |   2\n",
      "      29928 |   0.045781  |    0.003459     |   2\n",
      "      29929 |   0.165479  |    0.194574     |   1\n",
      "      29930 |   0.254600  |    0.192126     |   1\n",
      "      29931 |   0.188390  |    0.142559     |   1\n",
      "      29932 |   0.160013  |    0.063214     |   0\n",
      "      29933 |   0.110809  |    0.177858     |   1\n",
      "      29934 |   0.182881  |    0.040277     |   0\n",
      "      29935 |   0.152479  |    0.049518     |   0\n",
      "      29936 |   0.142301  |    0.045794     |   0\n",
      "      29937 |   0.043747  |    0.044529     |   2\n",
      "      29938 |   0.167764  |    0.197845     |   1\n",
      "      29939 |   0.146869  |    0.049875     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 29940: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      29940 |   0.044045  |    0.026346     |   2\n",
      "      29941 |   0.030614  |    0.047299     |   2\n",
      "      29942 |   0.189925  |    0.160993     |   1\n",
      "      29943 |   0.141922  |    0.050193     |   0\n",
      "      29944 |   0.033719  |    0.045250     |   2\n",
      "      29945 |   0.034070  |    0.056147     |   2\n",
      "      29946 |   0.126958  |    0.043673     |   0\n",
      "      29947 |   0.023579  |    0.043166     |   2\n",
      "      29948 |   0.202999  |    0.201183     |   1\n",
      "      29949 |   0.237772  |    0.152296     |   1\n",
      "      29950 |   0.199694  |    0.141597     |   1\n",
      "      29951 |   0.205606  |    0.150565     |   1\n",
      "      29952 |   0.147852  |    0.210408     |   1\n",
      "      29953 |   0.030968  |    0.025758     |   2\n",
      "      29954 |   0.180008  |    0.194186     |   1\n",
      "      29955 |   0.040136  |    0.007287     |   2\n",
      "      29956 |   0.043804  |    0.073481     |   2\n",
      "      29957 |   0.139767  |    0.159757     |   1\n",
      "      29958 |   0.167187  |    0.153413     |   1\n",
      "      29959 |   0.168920  |    0.030150     |   0\n",
      "      29960 |   0.037048  |    0.076076     |   2\n",
      "      29961 |   0.160369  |    0.048269     |   0\n",
      "      29962 |   0.020396  |    0.039881     |   2\n",
      "      29963 |   0.237831  |    0.080533     |   0\n",
      "      29964 |   0.201200  |    0.199339     |   1\n",
      "      29965 |   0.196150  |    0.009695     |   0\n",
      "      29966 |   0.176868  |    0.073600     |   0\n",
      "      29967 |   0.000014  |    0.006130     |   2\n",
      "      29968 |   0.004537  |    0.082765     |   2\n",
      "      29969 |   0.053669  |    0.011107     |   2\n",
      "      29970 |   0.177053  |    0.211017     |   1\n",
      "      29971 |   0.186222  |    0.005189     |   0\n",
      "      29972 |   0.168448  |    0.047229     |   0\n",
      "      29973 |   0.141425  |    0.050282     |   0\n",
      "      29974 |   0.177993  |    0.213865     |   1\n",
      "      29975 |   0.184897  |    0.023494     |   0\n",
      "      29976 |   0.154316  |    0.150338     |   1\n",
      "      29977 |   0.218298  |    0.202903     |   1\n",
      "      29978 |   0.158565  |    0.042045     |   0\n",
      "      29979 |   0.164218  |    0.057478     |   0\n",
      "      29980 |   0.190439  |    0.199052     |   1\n",
      "      29981 |   0.129538  |    0.040130     |   0\n",
      "      29982 |   0.028855  |    0.054752     |   2\n",
      "      29983 |   0.054329  |    0.043926     |   2\n",
      "      29984 |   0.198495  |    0.207468     |   1\n",
      "      29985 |   0.195578  |    0.174528     |   1\n",
      "      29986 |   0.156042  |    0.158368     |   1\n",
      "      29987 |   0.175033  |    0.197701     |   1\n",
      "      29988 |   0.136985  |    0.008505     |   0\n",
      "      29989 |   0.039368  |    0.048360     |   2\n",
      "      29990 |   0.207028  |    0.201256     |   1\n",
      "      29991 |   0.013459  |    0.032342     |   2\n",
      "      29992 |   0.029298  |    0.079076     |   2\n",
      "      29993 |   0.208809  |    0.141098     |   1\n",
      "      29994 |   0.178641  |    0.057235     |   0\n",
      "      29995 |   0.136628  |    0.188578     |   1\n",
      "      29996 |   0.024014  |    0.009202     |   2\n",
      "      29997 |   0.000014  |    0.076052     |   2\n",
      "      29998 |   0.196922  |    0.155836     |   1\n",
      "      29999 |   0.200488  |    0.138839     |   1\n",
      "      30000 |   0.185869  |    0.208190     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 30000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 30000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      30001 |   0.217063  |    0.220307     |   1\n",
      "      30002 |   0.038065  |    0.004210     |   2\n",
      "      30003 |   0.027242  |    0.083642     |   2\n",
      "      30004 |   0.167238  |    0.025414     |   0\n",
      "      30005 |   0.152423  |    0.219758     |   1\n",
      "      30006 |   0.150786  |    0.007559     |   0\n",
      "      30007 |   0.032730  |    0.075670     |   2\n",
      "      30008 |   0.207825  |    0.131238     |   1\n",
      "      30009 |   0.032521  |    0.076416     |   2\n",
      "      30010 |   0.023766  |    0.019717     |   2\n",
      "      30011 |   0.166598  |    0.076740     |   0\n",
      "      30012 |   0.202144  |    0.044285     |   0\n",
      "      30013 |   0.117278  |    0.203211     |   1\n",
      "      30014 |   0.030358  |    0.036716     |   2\n",
      "      30015 |   0.171520  |    0.187133     |   1\n",
      "      30016 |   0.173215  |    0.007690     |   0\n",
      "      30017 |   0.043246  |    0.081188     |   2\n",
      "      30018 |   0.181953  |    0.148345     |   1\n",
      "      30019 |   0.180885  |    0.183881     |   1\n",
      "      30020 |   0.043204  |    0.054587     |   2\n",
      "      30021 |   0.195285  |    0.187897     |   1\n",
      "      30022 |   0.040138  |    0.014209     |   2\n",
      "      30023 |   0.018923  |    0.039587     |   2\n",
      "      30024 |   0.188125  |    0.198360     |   1\n",
      "      30025 |   0.181629  |    0.164646     |   1\n",
      "      30026 |   0.188194  |    0.186434     |   1\n",
      "      30027 |   0.229972  |    0.185207     |   1\n",
      "      30028 |   0.187686  |    0.005039     |   0\n",
      "      30029 | \u001b[94m  0.000014\u001b[0m  |    0.053808     |   2\n",
      "      30030 |   0.116236  |    0.195919     |   1\n",
      "      30031 |   0.004455  |    0.052727     |   2\n",
      "      30032 |   0.175269  |    0.156681     |   1\n",
      "      30033 |   0.053199  |    0.023991     |   2\n",
      "      30034 |   0.159755  |    0.198428     |   1\n",
      "      30035 |   0.136473  |    0.163010     |   1\n",
      "      30036 |   0.028086  |    0.077784     |   2\n",
      "      30037 |   0.053807  |    0.085263     |   2\n",
      "      30038 |   0.146750  |    0.263786     |   1\n",
      "      30039 |   0.237847  |    0.039715     |   0\n",
      "      30040 |   0.159573  |    0.079166     |   0\n",
      "      30041 |   0.037036  |    0.008964     |   2\n",
      "      30042 |   0.148366  |    0.198718     |   1\n",
      "      30043 |   0.157103  |    0.161487     |   1\n",
      "      30044 |   0.194775  |    0.048385     |   0\n",
      "      30045 |   0.162007  |    0.182909     |   1\n",
      "      30046 |   0.211767  |    0.151698     |   1\n",
      "      30047 |   0.185109  |    0.055816     |   0\n",
      "      30048 |   0.193989  |    0.190843     |   1\n",
      "      30049 |   0.014565  |    0.028351     |   2\n",
      "      30050 |   0.206930  |    0.188819     |   1\n",
      "      30051 |   0.030093  |    0.004010     |   2\n",
      "      30052 |   0.197296  |    0.195810     |   1\n",
      "      30053 |   0.215675  |    0.101333     |   1\n",
      "      30054 |   0.156274  |    0.145593     |   1\n",
      "      30055 |   0.202289  |    0.086179     |   0\n",
      "      30056 |   0.213926  |    0.134641     |   1\n",
      "      30057 |   0.165960  |    0.010070     |   0\n",
      "      30058 |   0.023036  |    0.092066     |   2\n",
      "      30059 |   0.143097  |    0.137516     |   1\n",
      "      30060 | \u001b[94m  0.000014\u001b[0m  |    0.056829     |   2\n",
      "      30061 |   0.132602  |    0.208681     |   1\n",
      "      30062 |   0.110759  |    0.046949     |   0\n",
      "      30063 | \u001b[94m  0.000014\u001b[0m  |    0.041391     |   2\n",
      "      30064 |   0.000014  |    0.049802     |   2\n",
      "      30065 |   0.228571  |    0.075323     |   0\n",
      "      30066 |   0.156630  |    0.021117     |   0\n",
      "      30067 |   0.199597  |    0.188143     |   1\n",
      "      30068 |   0.000014  |    0.017363     |   2\n",
      "      30069 | \u001b[94m  0.000014\u001b[0m  |    0.079369     |   2\n",
      "      30070 |   0.174704  |    0.152320     |   1\n",
      "      30071 |   0.146856  |    0.039985     |   0\n",
      "      30072 |   0.113914  |    0.218075     |   1\n",
      "      30073 |   0.130443  |    0.174319     |   1\n",
      "      30074 |   0.172112  |    0.037871     |   0\n",
      "      30075 | \u001b[94m  0.000014\u001b[0m  |    0.036454     |   2\n",
      "      30076 |   0.199572  |    0.200126     |   1\n",
      "      30077 |   0.042216  |    0.016278     |   2\n",
      "      30078 |   0.162014  |    0.190629     |   1\n",
      "      30079 |   0.152530  |    0.028822     |   0\n",
      "      30080 |   0.043020  |    0.048175     |   2\n",
      "      30081 |   0.141905  |    0.086320     |   0\n",
      "      30082 |   0.193762  |    0.199738     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 30083: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      30083 |   0.160045  |    0.008854     |   0\n",
      "      30084 |   0.203552  |    0.073916     |   0\n",
      "      30085 |   0.174116  |    0.034201     |   0\n",
      "      30086 |   0.180571  |    0.187708     |   1\n",
      "      30087 |   0.169170  |    0.027365     |   0\n",
      "      30088 |   0.038969  |    0.083268     |   2\n",
      "      30089 |   0.027478  |    0.040540     |   2\n",
      "      30090 |   0.167718  |    0.215410     |   1\n",
      "      30091 |   0.185237  |    0.010861     |   0\n",
      "      30092 |   0.033096  |    0.064757     |   2\n",
      "      30093 |   0.191326  |    0.200537     |   1\n",
      "      30094 |   0.187237  |    0.152145     |   1\n",
      "      30095 |   0.194097  |    0.195749     |   1\n",
      "      30096 |   0.149009  |    0.144350     |   1\n",
      "      30097 |   0.198696  |    0.030424     |   0\n",
      "      30098 |   0.185028  |    0.200892     |   1\n",
      "      30099 |   0.200339  |    0.150940     |   1\n",
      "      30100 |   0.175238  |    0.185624     |   1\n",
      "      30101 |   0.173372  |    0.137771     |   1\n",
      "      30102 |   0.109619  |    0.179999     |   1\n",
      "      30103 |   0.159311  |    0.208673     |   1\n",
      "      30104 |   0.034034  |    0.020327     |   2\n",
      "      30105 |   0.197804  |    0.205778     |   1\n",
      "      30106 |   0.023667  |    0.016232     |   2\n",
      "      30107 |   0.220495  |    0.083645     |   0\n",
      "      30108 |   0.153391  |    0.337840     |   1\n",
      "      30109 |   0.185196  |    0.230971     |   1\n",
      "      30110 |   0.213220  |    0.063989     |   0\n",
      "      30111 |   0.191679  |    0.192297     |   1\n",
      "      30112 |   0.140211  |    0.195820     |   1\n",
      "      30113 |   0.160596  |    0.150223     |   1\n",
      "      30114 |   0.149413  |    0.151812     |   1\n",
      "      30115 |   0.139785  |    0.078381     |   0\n",
      "      30116 |   0.030858  |    0.015738     |   2\n",
      "      30117 |   0.043742  |    0.081795     |   2\n",
      "      30118 |   0.043158  |    0.023679     |   2\n",
      "      30119 |   0.214367  |    0.222409     |   1\n",
      "      30120 |   0.233550  |    0.138441     |   1\n",
      "      30121 |   0.138296  |    0.004688     |   0\n",
      "      30122 |   0.215794  |    0.075976     |   0\n",
      "      30123 |   0.170953  |    0.193495     |   1\n",
      "      30124 |   0.133236  |    0.185412     |   1\n",
      "      30125 |   0.037559  |    0.008787     |   2\n",
      "      30126 |   0.022498  |    0.076397     |   2\n",
      "      30127 |   0.000014  |    0.045957     |   2\n",
      "      30128 |   0.185069  |    0.085069     |   0\n",
      "      30129 |   0.224464  |    0.149872     |   1\n",
      "      30130 |   0.207242  |    0.071569     |   0\n",
      "      30131 |   0.004220  |    0.027197     |   2\n",
      "      30132 |   0.177697  |    0.091391     |   0\n",
      "      30133 |   0.177562  |    0.165863     |   1\n",
      "      30134 |   0.146859  |    0.212102     |   1\n",
      "      30135 |   0.181257  |    0.014982     |   0\n",
      "      30136 |   0.053872  |    0.082157     |   2\n",
      "      30137 |   0.030557  |    0.023324     |   2\n",
      "      30138 |   0.176493  |    0.089074     |   0\n",
      "      30139 |   0.053270  |    0.023901     |   2\n",
      "      30140 |   0.036839  |    0.046288     |   2\n",
      "      30141 |   0.168832  |    0.077785     |   0\n",
      "      30142 |   0.175975  |    0.162174     |   1\n",
      "      30143 |   0.187670  |    0.172749     |   1\n",
      "      30144 |   0.169086  |    0.074974     |   0\n",
      "      30145 |   0.014826  |    0.041436     |   2\n",
      "      30146 |   0.032961  |    0.086482     |   2\n",
      "      30147 |   0.229120  |    0.048094     |   0\n",
      "      30148 |   0.022257  |    0.038251     |   2\n",
      "      30149 |   0.223513  |    0.209216     |   1\n",
      "      30150 |   0.124120  |    0.139544     |   1\n",
      "      30151 |   0.181576  |    0.028400     |   0\n",
      "      30152 |   0.191899  |    0.075549     |   0\n",
      "      30153 |   0.235582  |    0.079373     |   0\n",
      "      30154 | \u001b[94m  0.000014\u001b[0m  |    0.011413     |   2\n",
      "      30155 |   0.000014  |    0.071982     |   2\n",
      "      30156 |   0.000014  |    0.040163     |   2\n",
      "      30157 |   0.174837  |    0.074781     |   0\n",
      "      30158 |   0.281431  |    0.147174     |   1\n",
      "      30159 |   0.138418  |    0.203481     |   1\n",
      "      30160 |   0.184640  |    0.202500     |   1\n",
      "      30161 |   0.000014  |    0.030496     |   2\n",
      "      30162 | \u001b[94m  0.000013\u001b[0m  |    0.080181     |   2\n",
      "      30163 |   0.168121  |    0.154923     |   1\n",
      "      30164 | \u001b[94m  0.000013\u001b[0m  |    0.039547     |   2\n",
      "      30165 |   0.183016  |    0.199638     |   1\n",
      "      30166 |   0.198284  |    0.163634     |   1\n",
      "      30167 |   0.041688  |    0.038974     |   2\n",
      "      30168 |   0.043922  |    0.044221     |   2\n",
      "      30169 |   0.216871  |    0.181940     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 30170: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      30170 |   0.039636  |    0.015465     |   2\n",
      "      30171 |   0.202490  |    0.196285     |   1\n",
      "      30172 |   0.173725  |    0.026408     |   0\n",
      "      30173 |   0.029286  |    0.080231     |   2\n",
      "      30174 |   0.032659  |    0.027213     |   2\n",
      "      30175 |   0.031592  |    0.071896     |   2\n",
      "      30176 |   0.161838  |    0.032674     |   0\n",
      "      30177 |   0.185220  |    0.078841     |   0\n",
      "      30178 |   0.023652  |    0.015683     |   2\n",
      "      30179 |   0.033990  |    0.082501     |   2\n",
      "      30180 |   0.189846  |    0.026074     |   0\n",
      "      30181 |   0.149775  |    0.256858     |   1\n",
      "      30182 |   0.221797  |    0.055280     |   0\n",
      "      30183 |   0.046012  |    0.073355     |   2\n",
      "      30184 |   0.140042  |    0.071544     |   0\n",
      "      30185 |   0.197884  |    0.270082     |   1\n",
      "      30186 |   0.043931  |    0.079871     |   2\n",
      "      30187 |   0.039800  |    0.071169     |   2\n",
      "      30188 |   0.172929  |    0.270821     |   1\n",
      "      30189 |   0.020855  |    0.038633     |   2\n",
      "      30190 |   0.180433  |    0.276878     |   1\n",
      "      30191 |   0.165014  |    0.271168     |   1\n",
      "      30192 |   0.000014  |    0.071361     |   2\n",
      "      30193 |   0.227827  |    0.269941     |   1\n",
      "      30194 |   0.004254  |    0.071522     |   2\n",
      "      30195 |   0.052754  |    0.070310     |   2\n",
      "      30196 |   0.176051  |    0.273044     |   1\n",
      "      30197 |   0.119685  |    0.028196     |   0\n",
      "      30198 |   0.167435  |    0.271091     |   1\n",
      "      30199 |   0.030360  |    0.041218     |   2\n",
      "      30200 |   0.137427  |    0.071682     |   0\n",
      "      30201 |   0.051559  |    0.069215     |   2\n",
      "      30202 |   0.035986  |    0.068975     |   2\n",
      "      30203 |   0.107847  |    0.298547     |   1\n",
      "      30204 |   0.150758  |    0.269743     |   1\n",
      "      30205 |   0.163356  |    0.079687     |   0\n",
      "      30206 |   0.143948  |    0.073575     |   0\n",
      "      30207 |   0.012499  |    0.070402     |   2\n",
      "      30208 |   0.029134  |    0.073293     |   2\n",
      "      30209 |   0.183665  |    0.084433     |   0\n",
      "      30210 |   0.180836  |    0.075155     |   0\n",
      "      30211 |   0.202088  |    0.338168     |   1\n",
      "      30212 |   0.022239  |    0.073635     |   2\n",
      "      30213 |   0.000014  |    0.068597     |   2\n",
      "      30214 |   0.133937  |    0.376462     |   1\n",
      "      30215 |   0.000014  |    0.050107     |   2\n",
      "      30216 |   0.180224  |    0.070042     |   0\n",
      "      30217 |   0.126321  |    0.071128     |   0\n",
      "      30218 |   0.239446  |    0.358355     |   1\n",
      "      30219 |   0.187092  |    0.296906     |   1\n",
      "      30220 |   0.164304  |    0.066315     |   0\n",
      "      30221 |   0.167895  |    0.333602     |   1\n",
      "      30222 |   0.000014  |    0.076347     |   2\n",
      "      30223 |   0.186778  |    0.069089     |   0\n",
      "      30224 |   0.164922  |    0.073680     |   0\n",
      "      30225 |   0.120550  |    0.119094     |   0\n",
      "      30226 |   0.149887  |    0.069129     |   0\n",
      "      30227 |   0.186410  |    0.391268     |   1\n",
      "      30228 |   0.155194  |    0.374269     |   1\n",
      "      30229 |   0.000014  |    0.068635     |   2\n",
      "      30230 |   0.160352  |    0.076833     |   0\n",
      "      30231 |   0.140228  |    0.145410     |   0\n",
      "      30232 |   0.000014  |    0.068227     |   2\n",
      "      30233 |   0.117472  |    0.148797     |   0\n",
      "      30234 |   0.000014  |    0.067697     |   2\n",
      "      30235 |   0.213046  |    0.396574     |   1\n",
      "      30236 |   0.179572  |    0.327325     |   1\n",
      "      30237 |   0.041426  |    0.071686     |   2\n",
      "      30238 |   0.043491  |    0.091218     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 30239: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      30239 |   0.039530  |    0.061727     |   2\n",
      "      30240 |   0.211019  |    0.366638     |   1\n",
      "      30241 |   0.202551  |    0.339978     |   1\n",
      "      30242 |   0.185969  |    0.318981     |   1\n",
      "      30243 |   0.173808  |    0.331341     |   1\n",
      "      30244 |   0.026992  |    0.045091     |   2\n",
      "      30245 |   0.033896  |    0.130322     |   2\n",
      "      30246 |   0.032798  |    0.003635     |   2\n",
      "      30247 |   0.024320  |    0.083742     |   2\n",
      "      30248 |   0.255332  |    0.096864     |   0\n",
      "      30249 |   0.032927  |    0.014827     |   2\n",
      "      30250 |   0.155419  |    0.105330     |   0\n",
      "      30251 |   0.179863  |    0.055439     |   0\n",
      "      30252 |   0.162588  |    0.226183     |   1\n",
      "      30253 |   0.132940  |    0.086115     |   0\n",
      "      30254 |   0.164820  |    0.077766     |   0\n",
      "      30255 |   0.040170  |    0.027397     |   2\n",
      "      30256 |   0.238673  |    0.078903     |   0\n",
      "      30257 |   0.045893  |    0.018219     |   2\n",
      "      30258 |   0.152890  |    0.046403     |   0\n",
      "      30259 |   0.154746  |    0.081904     |   0\n",
      "      30260 |   0.208325  |    0.189032     |   1\n",
      "      30261 |   0.180566  |    0.022742     |   0\n",
      "      30262 |   0.038984  |    0.095827     |   2\n",
      "      30263 |   0.158463  |    0.246827     |   1\n",
      "      30264 |   0.211968  |    0.118451     |   1\n",
      "      30265 |   0.159716  |    0.202177     |   1\n",
      "      30266 |   0.198653  |    0.173820     |   1\n",
      "      30267 |   0.186803  |    0.194189     |   1\n",
      "      30268 |   0.139335  |    0.040106     |   0\n",
      "      30269 |   0.095305  |    0.090193     |   0\n",
      "      30270 |   0.209430  |    0.078744     |   0\n",
      "      30271 |   0.186848  |    0.007385     |   0\n",
      "      30272 |   0.214237  |    0.085401     |   0\n",
      "      30273 |   0.175371  |    0.223524     |   1\n",
      "      30274 |   0.154234  |    0.247355     |   1\n",
      "      30275 |   0.019412  |    0.038266     |   2\n",
      "      30276 |   0.168987  |    0.073021     |   0\n",
      "      30277 |   0.000014  |    0.100034     |   2\n",
      "      30278 |   0.004333  |    0.041050     |   2\n",
      "      30279 |   0.203551  |    0.277628     |   1\n",
      "      30280 |   0.153717  |    0.007092     |   0\n",
      "      30281 |   0.054323  |    0.132091     |   2\n",
      "      30282 |   0.131693  |    0.202456     |   1\n",
      "      30283 |   0.031899  |    0.053007     |   2\n",
      "      30284 |   0.176529  |    0.197354     |   1\n",
      "      30285 |   0.051648  |    0.093714     |   2\n",
      "      30286 |   0.157943  |    0.078309     |   0\n",
      "      30287 |   0.117374  |    0.096327     |   0\n",
      "      30288 |   0.167469  |    0.256903     |   1\n",
      "      30289 |   0.129707  |    0.301151     |   1\n",
      "      30290 |   0.037192  |    0.079541     |   2\n",
      "      30291 |   0.015844  |    0.105442     |   2\n",
      "      30292 |   0.239213  |    0.249074     |   1\n",
      "      30293 |   0.127485  |    0.267783     |   1\n",
      "      30294 |   0.148768  |    0.024152     |   0\n",
      "      30295 |   0.202764  |    0.358791     |   1\n",
      "      30296 |   0.030765  |    0.007164     |   2\n",
      "      30297 |   0.191726  |    0.089196     |   0\n",
      "      30298 |   0.203971  |    0.183909     |   1\n",
      "      30299 |   0.177702  |    0.071915     |   0\n",
      "      30300 |   0.218563  |    0.022211     |   0\n",
      "      30301 |   0.023768  |    0.078961     |   2\n",
      "      30302 |   0.149369  |    0.080648     |   0\n",
      "      30303 |   0.000014  |    0.097235     |   2\n",
      "      30304 |   0.176547  |    0.212776     |   1\n",
      "      30305 |   0.000014  |    0.038219     |   2\n",
      "      30306 |   0.255951  |    0.314031     |   1\n",
      "      30307 |   0.178432  |    0.232469     |   1\n",
      "      30308 |   0.000014  |    0.045100     |   2\n",
      "      30309 |   0.000014  |    0.114763     |   2\n",
      "      30310 |   0.000014  |    0.038005     |   2\n",
      "      30311 |   0.123372  |    0.134978     |   0\n",
      "      30312 |   0.182890  |    0.243453     |   1\n",
      "      30313 |   0.206019  |    0.021130     |   0\n",
      "      30314 |   0.187448  |    0.171131     |   0\n",
      "      30315 |   0.000014  |    0.038359     |   2\n",
      "      30316 |   0.292597  |    0.249924     |   1\n",
      "      30317 |   0.198832  |    0.110411     |   0\n",
      "      30318 |   0.251970  |    0.313011     |   1\n",
      "      30319 |   0.147044  |    0.290530     |   1\n",
      "      30320 |   0.039594  |    0.095265     |   2\n",
      "      30321 |   0.125382  |    0.386413     |   1\n",
      "      30322 |   0.184342  |    0.192509     |   1\n",
      "      30323 |   0.042701  |    0.062677     |   2\n",
      "      30324 |   0.118764  |    0.264145     |   1\n",
      "      30325 |   0.135828  |    0.167217     |   1\n",
      "      30326 |   0.162286  |    0.270555     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 30328: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      30327 |   0.231303  |    0.042322     |   0\n",
      "      30328 |   0.141215  |    0.060997     |   0\n",
      "      30329 |   0.189299  |    0.069478     |   0\n",
      "      30330 |   0.193828  |    0.290719     |   1\n",
      "      30331 |   0.154880  |    0.022918     |   0\n",
      "      30332 |   0.145278  |    0.076666     |   0\n",
      "      30333 |   0.127747  |    0.068775     |   0\n",
      "      30334 |   0.135496  |    0.352861     |   1\n",
      "      30335 |   0.170926  |    0.084468     |   0\n",
      "      30336 |   0.157381  |    0.125032     |   0\n",
      "      30337 |   0.210413  |    0.317205     |   1\n",
      "      30338 |   0.041884  |    0.089437     |   2\n",
      "      30339 |   0.028889  |    0.041198     |   2\n",
      "      30340 |   0.033273  |    0.082261     |   2\n",
      "      30341 |   0.177107  |    0.118782     |   0\n",
      "      30342 |   0.031416  |    0.038670     |   2\n",
      "      30343 |   0.153394  |    0.146044     |   0\n",
      "      30344 |   0.024821  |    0.036550     |   2\n",
      "      30345 |   0.035301  |    0.120307     |   2\n",
      "      30346 |   0.143457  |    0.261847     |   1\n",
      "      30347 |   0.044149  |    0.006420     |   2\n",
      "      30348 |   0.045121  |    0.077916     |   2\n",
      "      30349 |   0.038301  |    0.024553     |   2\n",
      "      30350 |   0.162584  |    0.051876     |   0\n",
      "      30351 |   0.139553  |    0.039551     |   0\n",
      "      30352 |   0.194739  |    0.194426     |   1\n",
      "      30353 |   0.161875  |    0.199836     |   1\n",
      "      30354 |   0.184662  |    0.041514     |   0\n",
      "      30355 |   0.173520  |    0.043718     |   0\n",
      "      30356 |   0.205077  |    0.172637     |   1\n",
      "      30357 |   0.171202  |    0.198427     |   1\n",
      "      30358 |   0.125837  |    0.038970     |   0\n",
      "      30359 |   0.146861  |    0.043216     |   0\n",
      "      30360 |   0.230940  |    0.047087     |   0\n",
      "      30361 |   0.150278  |    0.154225     |   1\n",
      "      30362 |   0.019610  |    0.043032     |   2\n",
      "      30363 |   0.160700  |    0.190909     |   1\n",
      "      30364 |   0.000014  |    0.014113     |   2\n",
      "      30365 |   0.240938  |    0.076909     |   0\n",
      "      30366 |   0.127742  |    0.034011     |   0\n",
      "      30367 |   0.188701  |    0.070836     |   0\n",
      "      30368 |   0.004738  |    0.072727     |   2\n",
      "      30369 |   0.055010  |    0.072322     |   2\n",
      "      30370 |   0.170199  |    0.070419     |   0\n",
      "      30371 |   0.199104  |    0.271128     |   1\n",
      "      30372 |   0.155156  |    0.024658     |   0\n",
      "      30373 |   0.035684  |    0.074297     |   2\n",
      "      30374 |   0.234113  |    0.275556     |   1\n",
      "      30375 |   0.173054  |    0.072317     |   0\n",
      "      30376 |   0.106119  |    0.322722     |   1\n",
      "      30377 |   0.054158  |    0.042698     |   2\n",
      "      30378 |   0.157990  |    0.272435     |   1\n",
      "      30379 |   0.182195  |    0.274714     |   1\n",
      "      30380 |   0.036285  |    0.038946     |   2\n",
      "      30381 |   0.133373  |    0.295839     |   1\n",
      "      30382 |   0.161232  |    0.069317     |   0\n",
      "      30383 |   0.147216  |    0.070368     |   0\n",
      "      30384 |   0.171278  |    0.281904     |   1\n",
      "      30385 |   0.014436  |    0.075800     |   2\n",
      "      30386 |   0.152087  |    0.323189     |   1\n",
      "      30387 |   0.244899  |    0.292843     |   1\n",
      "      30388 |   0.136286  |    0.037351     |   0\n",
      "      30389 |   0.185809  |    0.309740     |   1\n",
      "      30390 |   0.187832  |    0.072147     |   0\n",
      "      30391 |   0.146023  |    0.287778     |   1\n",
      "      30392 |   0.196861  |    0.147130     |   0\n",
      "      30393 |   0.032701  |    0.037702     |   2\n",
      "      30394 |   0.021770  |    0.072826     |   2\n",
      "      30395 |   0.000014  |    0.068743     |   2\n",
      "      30396 |   0.000014  |    0.041261     |   2\n",
      "      30397 |   0.000014  |    0.094633     |   2\n",
      "      30398 |   0.000014  |    0.074743     |   2\n",
      "      30399 |   0.156083  |    0.071548     |   0\n",
      "      30400 |   0.165108  |    0.345949     |   1\n",
      "      30401 |   0.178923  |    0.268447     |   1\n",
      "      30402 |   0.160755  |    0.264692     |   1\n",
      "      30403 |   0.000014  |    0.074201     |   2\n",
      "      30404 |   0.248391  |    0.079195     |   0\n",
      "      30405 |   0.000014  |    0.061189     |   2\n",
      "      30406 |   0.037841  |    0.097073     |   2\n",
      "      30407 |   0.132297  |    0.092234     |   0\n",
      "      30408 |   0.203511  |    0.287444     |   1\n",
      "      30409 |   0.042422  |    0.039694     |   2\n",
      "      30410 |   0.186896  |    0.088723     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 30411: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      30411 |   0.156804  |    0.057779     |   0\n",
      "      30412 |   0.041067  |    0.051592     |   2\n",
      "      30413 |   0.164129  |    0.075915     |   0\n",
      "      30414 |   0.161052  |    0.054838     |   0\n",
      "      30415 |   0.145360  |    0.186263     |   1\n",
      "      30416 |   0.191357  |    0.040795     |   0\n",
      "      30417 |   0.159215  |    0.177791     |   1\n",
      "      30418 |   0.155876  |    0.038705     |   0\n",
      "      30419 |   0.169969  |    0.213684     |   1\n",
      "      30420 |   0.029680  |    0.011363     |   2\n",
      "      30421 |   0.117424  |    0.210029     |   1\n",
      "      30422 |   0.160312  |    0.053907     |   0\n",
      "      30423 |   0.167717  |    0.201116     |   1\n",
      "      30424 |   0.033473  |    0.006402     |   2\n",
      "      30425 |   0.173778  |    0.256699     |   1\n",
      "      30426 |   0.205017  |    0.005212     |   0\n",
      "      30427 |   0.158651  |    0.056071     |   0\n",
      "      30428 |   0.213067  |    0.195209     |   1\n",
      "      30429 |   0.032508  |    0.005725     |   2\n",
      "      30430 |   0.206585  |    0.084440     |   0\n",
      "      30431 |   0.023783  |    0.013286     |   2\n",
      "      30432 |   0.128602  |    0.079872     |   0\n",
      "      30433 |   0.150021  |    0.021796     |   0\n",
      "      30434 |   0.160423  |    0.077254     |   0\n",
      "      30435 |   0.177061  |    0.041197     |   0\n",
      "      30436 |   0.164423  |    0.218479     |   1\n",
      "      30437 |   0.179695  |    0.154170     |   1\n",
      "      30438 |   0.115962  |    0.018881     |   0\n",
      "      30439 |   0.034002  |    0.075385     |   2\n",
      "      30440 |   0.047859  |    0.036309     |   2\n",
      "      30441 |   0.044147  |    0.074070     |   2\n",
      "      30442 |   0.037091  |    0.013897     |   2\n",
      "      30443 |   0.018419  |    0.076427     |   2\n",
      "      30444 |   0.000014  |    0.021722     |   2\n",
      "      30445 |   0.004568  |    0.081137     |   2\n",
      "      30446 |   0.248533  |    0.154224     |   1\n",
      "      30447 |   0.181649  |    0.032319     |   0\n",
      "      30448 |   0.191287  |    0.074315     |   0\n",
      "      30449 |   0.171444  |    0.035598     |   0\n",
      "      30450 |   0.152895  |    0.193402     |   1\n",
      "      30451 |   0.178930  |    0.011298     |   0\n",
      "      30452 |   0.160508  |    0.081739     |   0\n",
      "      30453 |   0.053892  |    0.030197     |   2\n",
      "      30454 |   0.145716  |    0.190689     |   1\n",
      "      30455 |   0.032784  |    0.009255     |   2\n",
      "      30456 |   0.179944  |    0.074527     |   0\n",
      "      30457 |   0.247623  |    0.026089     |   0\n",
      "      30458 |   0.196768  |    0.073151     |   0\n",
      "      30459 |   0.168014  |    0.039492     |   0\n",
      "      30460 |   0.054371  |    0.041192     |   2\n",
      "      30461 |   0.036784  |    0.079810     |   2\n",
      "      30462 |   0.201440  |    0.031839     |   0\n",
      "      30463 |   0.181457  |    0.222736     |   1\n",
      "      30464 |   0.156797  |    0.014148     |   0\n",
      "      30465 |   0.209162  |    0.156002     |   1\n",
      "      30466 |   0.170908  |    0.205510     |   1\n",
      "      30467 |   0.161058  |    0.149073     |   1\n",
      "      30468 |   0.013919  |    0.005718     |   2\n",
      "      30469 |   0.032611  |    0.046528     |   2\n",
      "      30470 |   0.204166  |    0.157152     |   1\n",
      "      30471 |   0.185483  |    0.027633     |   0\n",
      "      30472 |   0.182874  |    0.046714     |   0\n",
      "      30473 |   0.024028  |    0.075798     |   2\n",
      "      30474 |   0.000014  |    0.037485     |   2\n",
      "      30475 |   0.188977  |    0.201832     |   1\n",
      "      30476 |   0.000014  |    0.047526     |   2\n",
      "      30477 |   0.000014  |    0.049883     |   2\n",
      "      30478 |   0.121925  |    0.162907     |   1\n",
      "      30479 |   0.188965  |    0.203761     |   1\n",
      "      30480 |   0.186729  |    0.156838     |   1\n",
      "      30481 |   0.147757  |    0.159163     |   1\n",
      "      30482 |   0.155755  |    0.202690     |   1\n",
      "      30483 |   0.155628  |    0.150149     |   1\n",
      "      30484 |   0.000014  |    0.007319     |   2\n",
      "      30485 |   0.143073  |    0.074738     |   0\n",
      "      30486 |   0.150519  |    0.102120     |   1\n",
      "      30487 |   0.223820  |    0.201865     |   1\n",
      "      30488 |   0.185834  |    0.149543     |   1\n",
      "      30489 |   0.000014  |    0.019481     |   2\n",
      "      30490 |   0.193864  |    0.081471     |   0\n",
      "      30491 |   0.150796  |    0.147451     |   1\n",
      "      30492 |   0.000014  |    0.045972     |   2\n",
      "      30493 |   0.038543  |    0.041180     |   2\n",
      "      30494 |   0.042506  |    0.027568     |   2\n",
      "      30495 |   0.188426  |    0.093305     |   0\n",
      "      30496 |   0.200391  |    0.015228     |   0\n",
      "      30497 |   0.162297  |    0.077340     |   0\n",
      "      30498 |   0.120961  |    0.010333     |   0\n",
      "      30499 |   0.152740  |    0.242969     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 30500: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      30500 |   0.037924  |    0.004610     |   2\n",
      "      30501 |   0.211412  |    0.070322     |   0\n",
      "      30502 |   0.160519  |    0.047211     |   0\n",
      "      30503 |   0.037945  |    0.043644     |   2\n",
      "      30504 |   0.029051  |    0.086567     |   2\n",
      "      30505 |   0.171584  |    0.025019     |   0\n",
      "      30506 |   0.170152  |    0.224818     |   1\n",
      "      30507 |   0.174801  |    0.043153     |   0\n",
      "      30508 |   0.032861  |    0.050716     |   2\n",
      "      30509 |   0.033669  |    0.044838     |   2\n",
      "      30510 |   0.170739  |    0.072565     |   0\n",
      "      30511 |   0.175806  |    0.042934     |   0\n",
      "      30512 |   0.151756  |    0.056778     |   0\n",
      "      30513 |   0.183864  |    0.208462     |   1\n",
      "      30514 |   0.158912  |    0.006387     |   0\n",
      "      30515 |   0.173204  |    0.073756     |   0\n",
      "      30516 |   0.024348  |    0.043904     |   2\n",
      "      30517 |   0.035380  |    0.077141     |   2\n",
      "      30518 |   0.301257  |    0.142958     |   1\n",
      "      30519 |   0.131169  |    0.211019     |   1\n",
      "      30520 |   0.049940  |    0.026617     |   2\n",
      "      30521 |   0.159381  |    0.208566     |   1\n",
      "      30522 |   0.199599  |    0.135774     |   1\n",
      "      30523 |   0.143953  |    0.044727     |   0\n",
      "      30524 |   0.163199  |    0.199751     |   1\n",
      "      30525 |   0.165020  |    0.017999     |   0\n",
      "      30526 |   0.152812  |    0.192591     |   1\n",
      "      30527 |   0.156860  |    0.213659     |   1\n",
      "      30528 |   0.183928  |    0.025846     |   0\n",
      "      30529 |   0.143784  |    0.149532     |   1\n",
      "      30530 |   0.175950  |    0.079771     |   0\n",
      "      30531 |   0.047118  |    0.026743     |   2\n",
      "      30532 |   0.038684  |    0.077001     |   2\n",
      "      30533 |   0.154062  |    0.143911     |   1\n",
      "      30534 |   0.149855  |    0.195901     |   1\n",
      "      30535 |   0.203230  |    0.009229     |   0\n",
      "      30536 |   0.142321  |    0.074824     |   0\n",
      "      30537 |   0.168115  |    0.023262     |   0\n",
      "      30538 |   0.186094  |    0.078795     |   0\n",
      "      30539 |   0.019851  |    0.026648     |   2\n",
      "      30540 |   0.188510  |    0.158128     |   1\n",
      "      30541 |   0.161758  |    0.030668     |   0\n",
      "      30542 |   0.177606  |    0.199274     |   1\n",
      "      30543 |   0.136638  |    0.023638     |   0\n",
      "      30544 |   0.193648  |    0.084536     |   0\n",
      "      30545 |   0.000014  |    0.014079     |   2\n",
      "      30546 |   0.187024  |    0.183875     |   1\n",
      "      30547 |   0.172961  |    0.152215     |   1\n",
      "      30548 |   0.138531  |    0.037060     |   0\n",
      "      30549 |   0.139523  |    0.050158     |   0\n",
      "      30550 |   0.158026  |    0.070577     |   0\n",
      "      30551 |   0.202830  |    0.048913     |   0\n",
      "      30552 |   0.004404  |    0.039815     |   2\n",
      "      30553 |   0.159968  |    0.074250     |   0\n",
      "      30554 |   0.055669  |    0.028812     |   2\n",
      "      30555 |   0.033707  |    0.052618     |   2\n",
      "      30556 |   0.053096  |    0.079539     |   2\n",
      "      30557 |   0.036307  |    0.009305     |   2\n",
      "      30558 |   0.013391  |    0.081873     |   2\n",
      "      30559 |   0.116230  |    0.157683     |   1\n",
      "      30560 |   0.195723  |    0.054126     |   0\n",
      "      30561 |   0.179452  |    0.193399     |   1\n",
      "      30562 |   0.159333  |    0.013913     |   0\n",
      "      30563 |   0.164261  |    0.200631     |   1\n",
      "      30564 |   0.032466  |    0.008241     |   2\n",
      "      30565 |   0.024614  |    0.081007     |   2\n",
      "      30566 |   0.169137  |    0.025807     |   0\n",
      "      30567 |   0.000014  |    0.077399     |   2\n",
      "      30568 |   0.000014  |    0.026583     |   2\n",
      "      30569 |   0.000014  |    0.078928     |   2\n",
      "      30570 |   0.134729  |    0.034636     |   0\n",
      "      30571 |   0.171731  |    0.165976     |   1\n",
      "      30572 |   0.165424  |    0.045790     |   0\n",
      "      30573 |   0.157293  |    0.188210     |   1\n",
      "      30574 |   0.153367  |    0.024596     |   0\n",
      "      30575 |   0.165834  |    0.214652     |   1\n",
      "      30576 |   0.236086  |    0.153366     |   1\n",
      "      30577 |   0.000014  |    0.044891     |   2\n",
      "      30578 |   0.202165  |    0.174932     |   1\n",
      "      30579 |   0.000014  |    0.037567     |   2\n",
      "      30580 |   0.000014  |    0.086284     |   2\n",
      "      30581 |   0.042312  |    0.026885     |   2\n",
      "      30582 |   0.201981  |    0.192439     |   1\n",
      "      30583 |   0.042188  |    0.016445     |   2\n",
      "      30584 |   0.157233  |    0.072639     |   0\n",
      "      30585 |   0.190812  |    0.207746     |   1\n",
      "      30586 |   0.160971  |    0.009372     |   0\n",
      "      30587 |   0.174698  |    0.176151     |   1\n",
      "      30588 |   0.150259  |    0.209511     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 30589: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      30589 |   0.038748  |    0.005090     |   2\n",
      "      30590 |   0.126689  |    0.094142     |   0\n",
      "      30591 |   0.183717  |    0.166358     |   1\n",
      "      30592 |   0.028149  |    0.005822     |   2\n",
      "      30593 |   0.183137  |    0.076563     |   0\n",
      "      30594 |   0.179980  |    0.024149     |   0\n",
      "      30595 |   0.161092  |    0.161774     |   1\n",
      "      30596 |   0.225681  |    0.007229     |   0\n",
      "      30597 |   0.191993  |    0.111442     |   0\n",
      "      30598 |   0.197010  |    0.090729     |   1\n",
      "      30599 |   0.033592  |    0.051153     |   2\n",
      "      30600 |   0.032730  |    0.057793     |   2\n",
      "      30601 |   0.183752  |    0.196750     |   1\n",
      "      30602 |   0.220334  |    0.138191     |   1\n",
      "      30603 |   0.194473  |    0.048337     |   0\n",
      "      30604 |   0.023836  |    0.051058     |   2\n",
      "      30605 |   0.033473  |    0.039761     |   2\n",
      "      30606 |   0.041388  |    0.049485     |   2\n",
      "      30607 |   0.148263  |    0.201575     |   1\n",
      "      30608 |   0.044763  |    0.008046     |   2\n",
      "      30609 |   0.204625  |    0.081041     |   0\n",
      "      30610 |   0.037158  |    0.020777     |   2\n",
      "      30611 |   0.197703  |    0.078812     |   0\n",
      "      30612 |   0.196300  |    0.152300     |   1\n",
      "      30613 |   0.140185  |    0.082281     |   0\n",
      "      30614 |   0.144496  |    0.183481     |   1\n",
      "      30615 |   0.020754  |    0.005874     |   2\n",
      "      30616 |   0.137043  |    0.083884     |   0\n",
      "      30617 |   0.179388  |    0.030848     |   0\n",
      "      30618 |   0.000014  |    0.072409     |   2\n",
      "      30619 |   0.004365  |    0.017239     |   2\n",
      "      30620 |   0.052340  |    0.078568     |   2\n",
      "      30621 |   0.031803  |    0.019432     |   2\n",
      "      30622 |   0.054421  |    0.077877     |   2\n",
      "      30623 |   0.168643  |    0.025683     |   0\n",
      "      30624 |   0.179672  |    0.050061     |   0\n",
      "      30625 |   0.035483  |    0.055249     |   2\n",
      "      30626 |   0.137940  |    0.200960     |   1\n",
      "      30627 |   0.014070  |    0.027518     |   2\n",
      "      30628 |   0.033274  |    0.078634     |   2\n",
      "      30629 |   0.024977  |    0.027981     |   2\n",
      "      30630 |   0.147560  |    0.197424     |   1\n",
      "      30631 |   0.146177  |    0.076381     |   0\n",
      "      30632 |   0.000014  |    0.010097     |   2\n",
      "      30633 |   0.185968  |    0.079407     |   0\n",
      "      30634 |   0.000014  |    0.044287     |   2\n",
      "      30635 |   0.173658  |    0.193202     |   1\n",
      "      30636 |   0.133182  |    0.011608     |   0\n",
      "      30637 |   0.198518  |    0.081602     |   0\n",
      "      30638 |   0.188556  |    0.158927     |   1\n",
      "      30639 |   0.000014  |    0.041189     |   2\n",
      "      30640 |   0.144420  |    0.078791     |   0\n",
      "      30641 |   0.000014  |    0.026336     |   2\n",
      "      30642 |   0.000014  |    0.050449     |   2\n",
      "      30643 |   0.215080  |    0.073090     |   0\n",
      "      30644 |   0.000014  |    0.030660     |   2\n",
      "      30645 |   0.182675  |    0.088266     |   0\n",
      "      30646 |   0.040099  |    0.013848     |   2\n",
      "      30647 |   0.043751  |    0.085065     |   2\n",
      "      30648 |   0.200717  |    0.042937     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 30649: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      30649 |   0.039460  |    0.036832     |   2\n",
      "      30650 |   0.219732  |    0.042805     |   0\n",
      "      30651 |   0.177884  |    0.200345     |   1\n",
      "      30652 |   0.261400  |    0.043204     |   0\n",
      "      30653 |   0.154420  |    0.046486     |   0\n",
      "      30654 |   0.028399  |    0.042520     |   2\n",
      "      30655 |   0.148617  |    0.073540     |   0\n",
      "      30656 |   0.136609  |    0.025525     |   0\n",
      "      30657 |   0.198657  |    0.074990     |   0\n",
      "      30658 |   0.191118  |    0.197593     |   1\n",
      "      30659 |   0.128493  |    0.009178     |   0\n",
      "      30660 |   0.036885  |    0.044151     |   2\n",
      "      30661 |   0.199301  |    0.198089     |   1\n",
      "      30662 |   0.036387  |    0.004630     |   2\n",
      "      30663 |   0.150009  |    0.043218     |   0\n",
      "      30664 |   0.277766  |    0.205300     |   1\n",
      "      30665 |   0.023734  |    0.008613     |   2\n",
      "      30666 |   0.035396  |    0.055932     |   2\n",
      "      30667 |   0.045067  |    0.077406     |   2\n",
      "      30668 |   0.152452  |    0.191782     |   1\n",
      "      30669 |   0.141084  |    0.006017     |   0\n",
      "      30670 |   0.046278  |    0.044745     |   2\n",
      "      30671 |   0.208220  |    0.160891     |   1\n",
      "      30672 |   0.115333  |    0.150315     |   1\n",
      "      30673 |   0.166759  |    0.048965     |   0\n",
      "      30674 |   0.039540  |    0.091327     |   2\n",
      "      30675 |   0.215000  |    0.157748     |   1\n",
      "      30676 |   0.020928  |    0.010122     |   2\n",
      "      30677 |   0.156259  |    0.198480     |   1\n",
      "      30678 |   0.155599  |    0.042434     |   0\n",
      "      30679 |   0.000014  |    0.044811     |   2\n",
      "      30680 |   0.175113  |    0.072860     |   0\n",
      "      30681 |   0.176683  |    0.162903     |   1\n",
      "      30682 |   0.186771  |    0.014032     |   0\n",
      "      30683 |   0.150675  |    0.266896     |   1\n",
      "      30684 |   0.171614  |    0.116016     |   1\n",
      "      30685 |   0.180923  |    0.147080     |   1\n",
      "      30686 |   0.004349  |    0.059059     |   2\n",
      "      30687 |   0.180851  |    0.087046     |   0\n",
      "      30688 |   0.165692  |    0.166730     |   1\n",
      "      30689 |   0.181767  |    0.004945     |   0\n",
      "      30690 |   0.152336  |    0.184265     |   1\n",
      "      30691 |   0.052167  |    0.011916     |   2\n",
      "      30692 |   0.030448  |    0.075141     |   2\n",
      "      30693 |   0.055585  |    0.049691     |   2\n",
      "      30694 |   0.231818  |    0.175441     |   1\n",
      "      30695 |   0.217175  |    0.207979     |   1\n",
      "      30696 |   0.210995  |    0.007423     |   0\n",
      "      30697 |   0.034656  |    0.079664     |   2\n",
      "      30698 |   0.014118  |    0.022813     |   2\n",
      "      30699 |   0.031079  |    0.078105     |   2\n",
      "      30700 |   0.137369  |    0.009466     |   0\n",
      "      30701 |   0.023025  |    0.085932     |   2\n",
      "      30702 |   0.000014  |    0.020512     |   2\n",
      "      30703 |   0.000014  |    0.080616     |   2\n",
      "      30704 |   0.000014  |    0.023949     |   2\n",
      "      30705 |   0.197914  |    0.206940     |   1\n",
      "      30706 |   0.188993  |    0.004675     |   0\n",
      "      30707 |   0.000014  |    0.052233     |   2\n",
      "      30708 |   0.174987  |    0.200643     |   1\n",
      "      30709 |   0.193484  |    0.124521     |   1\n",
      "      30710 |   0.208795  |    0.157166     |   1\n",
      "      30711 |   0.102865  |    0.018439     |   0\n",
      "      30712 |   0.190248  |    0.074422     |   0\n",
      "      30713 |   0.000014  |    0.032748     |   2\n",
      "      30714 |   0.000014  |    0.074388     |   2\n",
      "      30715 |   0.037919  |    0.039387     |   2\n",
      "      30716 |   0.177992  |    0.076231     |   0\n",
      "      30717 |   0.043219  |    0.031075     |   2\n",
      "      30718 |   0.167357  |    0.208597     |   1\n",
      "      30719 |   0.191259  |    0.134795     |   1\n",
      "      30720 |   0.157425  |    0.195757     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 30721: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      30721 |   0.232407  |    0.009103     |   0\n",
      "      30722 |   0.154996  |    0.077950     |   0\n",
      "      30723 |   0.137930  |    0.027404     |   0\n",
      "      30724 |   0.037475  |    0.038254     |   2\n",
      "      30725 |   0.174421  |    0.086216     |   0\n",
      "      30726 |   0.156714  |    0.181361     |   1\n",
      "      30727 |   0.187059  |    0.149371     |   1\n",
      "      30728 |   0.165945  |    0.141474     |   1\n",
      "      30729 |   0.027480  |    0.077142     |   2\n",
      "      30730 |   0.172300  |    0.024685     |   0\n",
      "      30731 |   0.033580  |    0.078109     |   2\n",
      "      30732 |   0.156956  |    0.028979     |   0\n",
      "      30733 |   0.180530  |    0.211169     |   1\n",
      "      30734 |   0.183569  |    0.151633     |   1\n",
      "      30735 |   0.032496  |    0.024312     |   2\n",
      "      30736 |   0.166819  |    0.077739     |   0\n",
      "      30737 |   0.022623  |    0.033384     |   2\n",
      "      30738 |   0.031559  |    0.078538     |   2\n",
      "      30739 |   0.044335  |    0.004607     |   2\n",
      "      30740 |   0.167298  |    0.076131     |   0\n",
      "      30741 |   0.166691  |    0.045034     |   0\n",
      "      30742 |   0.187460  |    0.203775     |   1\n",
      "      30743 |   0.131571  |    0.136091     |   1\n",
      "      30744 |   0.044485  |    0.027027     |   2\n",
      "      30745 |   0.037933  |    0.077694     |   2\n",
      "      30746 |   0.192435  |    0.024782     |   0\n",
      "      30747 |   0.160367  |    0.200459     |   1\n",
      "      30748 |   0.018934  |    0.023535     |   2\n",
      "      30749 |   0.191076  |    0.077248     |   0\n",
      "      30750 |   0.169568  |    0.013548     |   0\n",
      "      30751 |   0.171590  |    0.073783     |   0\n",
      "      30752 |   0.000014  |    0.041073     |   2\n",
      "      30753 |   0.201639  |    0.190593     |   1\n",
      "      30754 |   0.004280  |    0.013550     |   2\n",
      "      30755 |   0.163417  |    0.193524     |   1\n",
      "      30756 |   0.177427  |    0.023121     |   0\n",
      "      30757 |   0.053538  |    0.075083     |   2\n",
      "      30758 |   0.183526  |    0.139793     |   1\n",
      "      30759 |   0.178801  |    0.045139     |   0\n",
      "      30760 |   0.030517  |    0.048832     |   2\n",
      "      30761 |   0.184293  |    0.211749     |   1\n",
      "      30762 |   0.257445  |    0.139417     |   1\n",
      "      30763 |   0.056548  |    0.009774     |   2\n",
      "      30764 |   0.150400  |    0.077633     |   0\n",
      "      30765 |   0.176257  |    0.023427     |   0\n",
      "      30766 |   0.210936  |    0.215819     |   1\n",
      "      30767 |   0.193245  |    0.135928     |   1\n",
      "      30768 |   0.183203  |    0.045553     |   0\n",
      "      30769 |   0.037237  |    0.041147     |   2\n",
      "      30770 |   0.013613  |    0.075755     |   2\n",
      "      30771 |   0.269933  |    0.134988     |   1\n",
      "      30772 |   0.162898  |    0.030714     |   0\n",
      "      30773 |   0.200058  |    0.165094     |   1\n",
      "      30774 |   0.028377  |    0.050144     |   2\n",
      "      30775 |   0.023446  |    0.073103     |   2\n",
      "      30776 |   0.156477  |    0.138576     |   1\n",
      "      30777 |   0.000014  |    0.045906     |   2\n",
      "      30778 |   0.000014  |    0.048876     |   2\n",
      "      30779 |   0.000014  |    0.039707     |   2\n",
      "      30780 |   0.214318  |    0.213111     |   1\n",
      "      30781 |   0.212750  |    0.005400     |   0\n",
      "      30782 |   0.191894  |    0.068567     |   0\n",
      "      30783 |   0.000014  |    0.023140     |   2\n",
      "      30784 |   0.166809  |    0.208252     |   1\n",
      "      30785 |   0.000014  |    0.048393     |   2\n",
      "      30786 |   0.180941  |    0.042984     |   0\n",
      "      30787 |   0.156047  |    0.046099     |   0\n",
      "      30788 |   0.215985  |    0.210680     |   1\n",
      "      30789 |   0.228154  |    0.084943     |   1\n",
      "      30790 |   0.135989  |    0.048739     |   0\n",
      "      30791 |   0.170368  |    0.040818     |   0\n",
      "      30792 |   0.155015  |    0.076573     |   0\n",
      "      30793 |   0.000014  |    0.023184     |   2\n",
      "      30794 |   0.152087  |    0.077306     |   0\n",
      "      30795 |   0.185723  |    0.010841     |   0\n",
      "      30796 |   0.227486  |    0.084088     |   0\n",
      "      30797 |   0.140836  |    0.035096     |   0\n",
      "      30798 |   0.166120  |    0.159968     |   1\n",
      "      30799 |   0.039426  |    0.041348     |   2\n",
      "      30800 |   0.043031  |    0.041285     |   2\n",
      "      30801 |   0.169369  |    0.214108     |   1\n",
      "      30802 |   0.214654  |    0.134154     |   1\n",
      "      30803 |   0.228366  |    0.137634     |   1\n",
      "      30804 |   0.199514  |    0.075022     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 30805: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      30805 |   0.041127  |    0.038812     |   2\n",
      "      30806 |   0.201441  |    0.195900     |   1\n",
      "      30807 |   0.152202  |    0.143502     |   1\n",
      "      30808 |   0.143373  |    0.023770     |   0\n",
      "      30809 |   0.028360  |    0.056537     |   2\n",
      "      30810 |   0.034090  |    0.078024     |   2\n",
      "      30811 |   0.031924  |    0.006463     |   2\n",
      "      30812 |   0.023862  |    0.080038     |   2\n",
      "      30813 |   0.034542  |    0.038105     |   2\n",
      "      30814 |   0.157179  |    0.052619     |   0\n",
      "      30815 |   0.183348  |    0.188920     |   1\n",
      "      30816 |   0.191409  |    0.146987     |   1\n",
      "      30817 |   0.159002  |    0.039844     |   0\n",
      "      30818 |   0.043671  |    0.047605     |   2\n",
      "      30819 |   0.194175  |    0.197014     |   1\n",
      "      30820 |   0.046826  |    0.021052     |   2\n",
      "      30821 |   0.040191  |    0.078510     |   2\n",
      "      30822 |   0.020124  |    0.042731     |   2\n",
      "      30823 |   0.126891  |    0.184935     |   1\n",
      "      30824 |   0.149244  |    0.030544     |   0\n",
      "      30825 |   0.205867  |    0.200318     |   1\n",
      "      30826 |   0.198785  |    0.167121     |   1\n",
      "      30827 | \u001b[94m  0.000013\u001b[0m  |    0.013859     |   2\n",
      "      30828 |   0.161053  |    0.190044     |   1\n",
      "      30829 |   0.198594  |    0.017526     |   0\n",
      "      30830 |   0.175057  |    0.198834     |   1\n",
      "      30831 |   0.169038  |    0.186065     |   1\n",
      "      30832 |   0.004471  |    0.023013     |   2\n",
      "      30833 |   0.164959  |    0.204837     |   1\n",
      "      30834 |   0.186626  |    0.146193     |   1\n",
      "      30835 |   0.188425  |    0.045371     |   0\n",
      "      30836 |   0.184346  |    0.048607     |   0\n",
      "      30837 |   0.183839  |    0.048969     |   0\n",
      "      30838 |   0.194009  |    0.188451     |   1\n",
      "      30839 |   0.052362  |    0.005031     |   2\n",
      "      30840 |   0.169343  |    0.206365     |   1\n",
      "      30841 |   0.028976  |    0.018868     |   2\n",
      "      30842 |   0.133013  |    0.231649     |   1\n",
      "      30843 |   0.052182  |    0.007211     |   2\n",
      "      30844 |   0.034442  |    0.047015     |   2\n",
      "      30845 |   0.127612  |    0.077472     |   0\n",
      "      30846 |   0.013906  |    0.019748     |   2\n",
      "      30847 |   0.159914  |    0.085066     |   0\n",
      "      30848 |   0.144019  |    0.019265     |   0\n",
      "      30849 |   0.027923  |    0.081119     |   2\n",
      "      30850 |   0.224360  |    0.190366     |   1\n",
      "      30851 |   0.025997  |    0.006018     |   2\n",
      "      30852 |   0.162501  |    0.046875     |   0\n",
      "      30853 |   0.000014  |    0.051489     |   2\n",
      "      30854 |   0.000014  |    0.042915     |   2\n",
      "      30855 |   0.000014  |    0.074202     |   2\n",
      "      30856 |   0.169113  |    0.046690     |   0\n",
      "      30857 |   0.191195  |    0.191382     |   1\n",
      "      30858 |   0.000014  |    0.017257     |   2\n",
      "      30859 |   0.000014  |    0.091191     |   2\n",
      "      30860 |   0.162920  |    0.149111     |   1\n",
      "      30861 |   0.000013  |    0.024826     |   2\n",
      "      30862 |   0.038325  |    0.088160     |   2\n",
      "      30863 |   0.159414  |    0.200982     |   1\n",
      "      30864 |   0.171631  |    0.140093     |   1\n",
      "      30865 |   0.153704  |    0.142115     |   1\n",
      "      30866 |   0.042775  |    0.082509     |   2\n",
      "      30867 |   0.151133  |    0.027806     |   0\n",
      "      30868 |   0.159225  |    0.074583     |   0\n",
      "      30869 |   0.223836  |    0.146556     |   1\n",
      "      30870 |   0.162489  |    0.156900     |   1\n",
      "      30871 |   0.196932  |    0.159652     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 30872: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      30872 |   0.192560  |    0.051973     |   0\n",
      "      30873 |   0.192270  |    0.145566     |   1\n",
      "      30874 |   0.202593  |    0.052131     |   0\n",
      "      30875 |   0.164194  |    0.045981     |   0\n",
      "      30876 |   0.163778  |    0.155725     |   1\n",
      "      30877 |   0.169919  |    0.175599     |   1\n",
      "      30878 |   0.037712  |    0.045834     |   2\n",
      "      30879 |   0.147305  |    0.199953     |   1\n",
      "      30880 |   0.026936  |    0.009835     |   2\n",
      "      30881 |   0.112721  |    0.255026     |   1\n",
      "      30882 |   0.172064  |    0.144928     |   1\n",
      "      30883 |   0.032750  |    0.014263     |   2\n",
      "      30884 |   0.032468  |    0.079625     |   2\n",
      "      30885 |   0.213019  |    0.145892     |   1\n",
      "      30886 |   0.023922  |    0.038828     |   2\n",
      "      30887 |   0.128977  |    0.078673     |   0\n",
      "      30888 |   0.195293  |    0.024923     |   0\n",
      "      30889 |   0.250415  |    0.193422     |   1\n",
      "      30890 |   0.221882  |    0.158077     |   1\n",
      "      30891 |   0.033175  |    0.005667     |   2\n",
      "      30892 |   0.041008  |    0.083076     |   2\n",
      "      30893 |   0.143952  |    0.138822     |   1\n",
      "      30894 |   0.225910  |    0.044667     |   0\n",
      "      30895 |   0.177819  |    0.048978     |   0\n",
      "      30896 |   0.199616  |    0.206282     |   1\n",
      "      30897 |   0.045601  |    0.009367     |   2\n",
      "      30898 |   0.039451  |    0.089614     |   2\n",
      "      30899 |   0.017766  |    0.021433     |   2\n",
      "      30900 | \u001b[94m  0.000013\u001b[0m  |    0.074534     |   2\n",
      "      30901 |   0.170909  |    0.149655     |   1\n",
      "      30902 |   0.004183  |    0.043898     |   2\n",
      "      30903 |   0.179622  |    0.043175     |   0\n",
      "      30904 |   0.173416  |    0.201731     |   1\n",
      "      30905 |   0.179046  |    0.006514     |   0\n",
      "      30906 |   0.175710  |    0.145760     |   1\n",
      "      30907 |   0.189995  |    0.143410     |   1\n",
      "      30908 |   0.136374  |    0.225874     |   1\n",
      "      30909 |   0.227019  |    0.010372     |   0\n",
      "      30910 |   0.170225  |    0.195489     |   1\n",
      "      30911 |   0.050132  |    0.036058     |   2\n",
      "      30912 |   0.191933  |    0.044964     |   0\n",
      "      30913 |   0.204569  |    0.076648     |   0\n",
      "      30914 |   0.183434  |    0.025368     |   0\n",
      "      30915 |   0.030512  |    0.049799     |   2\n",
      "      30916 |   0.166998  |    0.041578     |   0\n",
      "      30917 |   0.170415  |    0.153929     |   1\n",
      "      30918 |   0.053116  |    0.056662     |   2\n",
      "      30919 |   0.037209  |    0.024373     |   2\n",
      "      30920 |   0.015406  |    0.057011     |   2\n",
      "      30921 |   0.142492  |    0.047019     |   0\n",
      "      30922 |   0.162499  |    0.195272     |   1\n",
      "      30923 |   0.130590  |    0.133664     |   1\n",
      "      30924 |   0.030393  |    0.048410     |   2\n",
      "      30925 |   0.159600  |    0.055261     |   0\n",
      "      30926 |   0.232375  |    0.146074     |   1\n",
      "      30927 |   0.136952  |    0.206246     |   1\n",
      "      30928 |   0.207629  |    0.162634     |   1\n",
      "      30929 |   0.171584  |    0.143852     |   1\n",
      "      30930 |   0.144631  |    0.031399     |   0\n",
      "      30931 |   0.149141  |    0.046544     |   0\n",
      "      30932 |   0.021634  |    0.051203     |   2\n",
      "      30933 |   0.122104  |    0.196480     |   1\n",
      "      30934 | \u001b[94m  0.000013\u001b[0m  |    0.038965     |   2\n",
      "      30935 |   0.000013  |    0.044632     |   2\n",
      "      30936 |   0.152895  |    0.156994     |   1\n",
      "      30937 |   0.196379  |    0.039566     |   0\n",
      "      30938 |   0.195015  |    0.206005     |   1\n",
      "      30939 |   0.186659  |    0.027683     |   0\n",
      "      30940 |   0.000013  |    0.048010     |   2\n",
      "      30941 |   0.228003  |    0.035722     |   0\n",
      "      30942 |   0.162588  |    0.212269     |   1\n",
      "      30943 |   0.000013  |    0.046033     |   2\n",
      "      30944 |   0.181481  |    0.210629     |   1\n",
      "      30945 |   0.185627  |    0.008841     |   0\n",
      "      30946 |   0.159064  |    0.075750     |   0\n",
      "      30947 |   0.150482  |    0.047115     |   0\n",
      "      30948 |   0.143184  |    0.261682     |   1\n",
      "      30949 |   0.000013  |    0.016073     |   2\n",
      "      30950 |   0.191823  |    0.080481     |   0\n",
      "      30951 |   0.171999  |    0.022574     |   0\n",
      "      30952 |   0.000013  |    0.072929     |   2\n",
      "      30953 |   0.198460  |    0.158261     |   1\n",
      "      30954 |   0.146250  |    0.007362     |   0\n",
      "      30955 |   0.171544  |    0.136844     |   1\n",
      "      30956 |   0.201436  |    0.052993     |   0\n",
      "      30957 |   0.200875  |    0.147024     |   1\n",
      "      30958 |   0.117708  |    0.075282     |   0\n",
      "      30959 |   0.203032  |    0.037504     |   0\n",
      "      30960 |   0.141101  |    0.206747     |   1\n",
      "      30961 |   0.039895  |    0.028463     |   2\n",
      "      30962 |   0.043707  |    0.048226     |   2\n",
      "      30963 |   0.198312  |    0.078065     |   0\n",
      "      30964 |   0.173617  |    0.180634     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 30965: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      30965 |   0.216773  |    0.036728     |   0\n",
      "      30966 |   0.167590  |    0.221870     |   1\n",
      "      30967 |   0.184888  |    0.150184     |   1\n",
      "      30968 |   0.040485  |    0.024309     |   2\n",
      "      30969 |   0.211438  |    0.085253     |   0\n",
      "      30970 |   0.172338  |    0.016487     |   0\n",
      "      30971 |   0.125433  |    0.081581     |   0\n",
      "      30972 |   0.146153  |    0.015730     |   0\n",
      "      30973 |   0.184798  |    0.225821     |   1\n",
      "      30974 |   0.190189  |    0.032421     |   0\n",
      "      30975 |   0.228399  |    0.190289     |   1\n",
      "      30976 |   0.028048  |    0.019986     |   2\n",
      "      30977 |   0.165283  |    0.204180     |   1\n",
      "      30978 |   0.209810  |    0.193520     |   1\n",
      "      30979 |   0.034328  |    0.014911     |   2\n",
      "      30980 |   0.225305  |    0.182322     |   1\n",
      "      30981 |   0.250604  |    0.144930     |   1\n",
      "      30982 |   0.199925  |    0.087633     |   0\n",
      "      30983 |   0.137352  |    0.193113     |   1\n",
      "      30984 |   0.140985  |    0.117213     |   1\n",
      "      30985 |   0.168521  |    0.082045     |   0\n",
      "      30986 |   0.217328  |    0.029424     |   0\n",
      "      30987 |   0.143222  |    0.076142     |   0\n",
      "      30988 |   0.132953  |    0.144290     |   1\n",
      "      30989 |   0.197840  |    0.079608     |   0\n",
      "      30990 |   0.033939  |    0.012664     |   2\n",
      "      30991 |   0.142365  |    0.080316     |   0\n",
      "      30992 |   0.188154  |    0.028202     |   0\n",
      "      30993 |   0.155692  |    0.233628     |   1\n",
      "      30994 |   0.154463  |    0.015829     |   0\n",
      "      30995 |   0.168040  |    0.196372     |   1\n",
      "      30996 |   0.024767  |    0.077327     |   2\n",
      "      30997 |   0.034139  |    0.025879     |   2\n",
      "      30998 |   0.174165  |    0.073628     |   0\n",
      "      30999 |   0.145539  |    0.036816     |   0\n",
      "      31000 |   0.042346  |    0.069523     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 31000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 31000: Plotting estimates.\n",
      "Exception in thread neuralnilm-data-process:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 810, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/jack/workspace/python/neuralnilm/neuralnilm/data/datathread.py\", line 16, in run\n",
      "    batch = self.data_pipeline.get_batch(**self._get_batch_kwargs)\n",
      "  File \"/home/jack/workspace/python/neuralnilm/neuralnilm/data/datapipeline.py\", line 46, in get_batch\n",
      "    batch = self._source_iterators[source_id].next()\n",
      "ValueError: generator already executing\n",
      "\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      31001 |   0.167389  |    0.200851     |   1\n",
      "      31002 |   0.187909  |    0.011170     |   0\n",
      "      31003 |   0.040674  |    0.078858     |   2\n",
      "      31004 |   0.028200  |    0.046730     |   2\n",
      "      31005 |   0.172584  |    0.191948     |   1\n",
      "      31006 |   0.033050  |    0.009417     |   2\n",
      "      31007 |   0.199957  |    0.074565     |   0\n",
      "      31008 |   0.033399  |    0.048975     |   2\n",
      "      31009 |   0.024575  |    0.052973     |   2\n",
      "      31010 |   0.141674  |    0.189853     |   1\n",
      "      31011 |   0.152631  |    0.143292     |   1\n",
      "      31012 |   0.033216  |    0.028616     |   2\n",
      "      31013 |   0.042844  |    0.076124     |   2\n",
      "      31014 |   0.143809  |    0.168978     |   1\n",
      "      31015 |   0.045160  |    0.014503     |   2\n",
      "      31016 |   0.169832  |    0.138925     |   0\n",
      "      31017 |   0.131106  |    0.014849     |   0\n",
      "      31018 |   0.037213  |    0.043557     |   2\n",
      "      31019 |   0.166961  |    0.082520     |   0\n",
      "      31020 |   0.153156  |    0.026869     |   0\n",
      "      31021 |   0.017466  |    0.052151     |   2\n",
      "      31022 |   0.000013  |    0.079717     |   2\n",
      "      31023 |   0.193455  |    0.035107     |   0\n",
      "      31024 |   0.158757  |    0.221568     |   1\n",
      "      31025 |   0.222297  |    0.144082     |   1\n",
      "      31026 |   0.004525  |    0.091537     |   2\n",
      "      31027 |   0.207040  |    0.189573     |   1\n",
      "      31028 |   0.146559  |    0.012699     |   0\n",
      "      31029 |   0.218336  |    0.208480     |   1\n",
      "      31030 |   0.165571  |    0.049343     |   0\n",
      "      31031 |   0.209000  |    0.275876     |   1\n",
      "      31032 |   0.264197  |    0.210595     |   1\n",
      "      31033 |   0.218564  |    0.282902     |   1\n",
      "      31034 |   0.053077  |    0.050341     |   2\n",
      "      31035 |   0.029034  |    0.080301     |   2\n",
      "      31036 |   0.145445  |    0.286840     |   1\n",
      "      31037 |   0.172254  |    0.198917     |   1\n",
      "      31038 |   0.051022  |    0.017350     |   2\n",
      "      31039 |   0.035532  |    0.078637     |   2\n",
      "      31040 |   0.197189  |    0.023871     |   0\n",
      "      31041 |   0.138143  |    0.076170     |   0\n",
      "      31042 |   0.133535  |    0.074825     |   0\n",
      "      31043 |   0.012952  |    0.050044     |   2\n",
      "      31044 |   0.213021  |    0.164995     |   1\n",
      "      31045 |   0.223651  |    0.257374     |   1\n",
      "      31046 |   0.186620  |    0.043090     |   0\n",
      "      31047 |   0.144638  |    0.361796     |   1\n",
      "      31048 |   0.167319  |    0.035517     |   0\n",
      "      31049 |   0.028781  |    0.080202     |   2\n",
      "      31050 |   0.160708  |    0.253623     |   1\n",
      "      31051 |   0.170437  |    0.276766     |   1\n",
      "      31052 |   0.193235  |    0.150621     |   1\n",
      "      31053 |   0.147538  |    0.053931     |   0\n",
      "      31054 |   0.019881  |    0.007349     |   2\n",
      "      31055 |   0.000013  |    0.049896     |   2\n",
      "      31056 |   0.225592  |    0.319592     |   1\n",
      "      31057 |   0.166432  |    0.075010     |   0\n",
      "      31058 |   0.108103  |    0.027403     |   0\n",
      "      31059 |   0.162599  |    0.244428     |   1\n",
      "      31060 |   0.190662  |    0.043089     |   0\n",
      "      31061 | \u001b[94m  0.000013\u001b[0m  |    0.079284     |   2\n",
      "      31062 |   0.000013  |    0.055803     |   2\n",
      "      31063 |   0.186305  |    0.272995     |   1\n",
      "      31064 |   0.000013  |    0.074967     |   2\n",
      "      31065 |   0.173193  |    0.310203     |   1\n",
      "      31066 |   0.131639  |    0.011175     |   0\n",
      "      31067 |   0.133373  |    0.301220     |   1\n",
      "      31068 |   0.201510  |    0.239623     |   1\n",
      "      31069 | \u001b[94m  0.000013\u001b[0m  |    0.081364     |   2\n",
      "      31070 |   0.164765  |    0.332436     |   1\n",
      "      31071 | \u001b[94m  0.000013\u001b[0m  |    0.023523     |   2\n",
      "      31072 |   0.173273  |    0.320412     |   1\n",
      "      31073 |   0.155048  |    0.299045     |   1\n",
      "      31074 |   0.177660  |    0.072660     |   0\n",
      "      31075 |   0.170501  |    0.074420     |   0\n",
      "      31076 |   0.202455  |    0.255861     |   1\n",
      "      31077 |   0.042875  |    0.068398     |   2\n",
      "      31078 |   0.159529  |    0.042077     |   0\n",
      "      31079 |   0.043592  |    0.057257     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 31080: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      31080 |   0.132940  |    0.217002     |   1\n",
      "      31081 |   0.284311  |    0.140726     |   1\n",
      "      31082 |   0.163198  |    0.234452     |   1\n",
      "      31083 |   0.175841  |    0.015663     |   0\n",
      "      31084 |   0.040773  |    0.052777     |   2\n",
      "      31085 |   0.028714  |    0.128892     |   2\n",
      "      31086 |   0.033249  |    0.072188     |   2\n",
      "      31087 |   0.031557  |    0.084083     |   2\n",
      "      31088 |   0.194771  |    0.358991     |   1\n",
      "      31089 |   0.024098  |    0.068959     |   2\n",
      "      31090 |   0.220226  |    0.409399     |   1\n",
      "      31091 |   0.031953  |    0.072030     |   2\n",
      "      31092 |   0.041470  |    0.122106     |   2\n",
      "      31093 |   0.044275  |    0.079941     |   2\n",
      "      31094 |   0.144265  |    0.472614     |   1\n",
      "      31095 |   0.038859  |    0.096672     |   2\n",
      "      31096 |   0.215524  |    0.201246     |   0\n",
      "      31097 |   0.017493  |    0.081300     |   2\n",
      "      31098 |   0.178041  |    0.347268     |   1\n",
      "      31099 |   0.169353  |    0.463867     |   1\n",
      "      31100 |   0.172671  |    0.119218     |   0\n",
      "      31101 |   0.190309  |    0.103061     |   0\n",
      "      31102 |   0.120403  |    0.401758     |   1\n",
      "      31103 |   0.111991  |    0.100867     |   0\n",
      "      31104 |   0.000013  |    0.051678     |   2\n",
      "      31105 |   0.136958  |    0.554839     |   1\n",
      "      31106 |   0.197995  |    0.357168     |   1\n",
      "      31107 |   0.208693  |    0.204286     |   1\n",
      "      31108 |   0.004333  |    0.006701     |   2\n",
      "      31109 |   0.052013  |    0.099454     |   2\n",
      "      31110 |   0.177192  |    0.197611     |   1\n",
      "      31111 |   0.108930  |    0.212566     |   1\n",
      "      31112 |   0.182360  |    0.241593     |   1\n",
      "      31113 |   0.151373  |    0.158202     |   1\n",
      "      31114 |   0.174645  |    0.049473     |   0\n",
      "      31115 |   0.031536  |    0.105519     |   2\n",
      "      31116 |   0.143193  |    0.009638     |   0\n",
      "      31117 |   0.047687  |    0.109332     |   2\n",
      "      31118 |   0.184188  |    0.020867     |   0\n",
      "      31119 |   0.033859  |    0.099984     |   2\n",
      "      31120 |   0.014002  |    0.010425     |   2\n",
      "      31121 |   0.138397  |    0.086764     |   0\n",
      "      31122 |   0.164646  |    0.221530     |   1\n",
      "      31123 |   0.030773  |    0.051127     |   2\n",
      "      31124 |   0.215960  |    0.233257     |   1\n",
      "      31125 |   0.022537  |    0.005875     |   2\n",
      "      31126 |   0.185153  |    0.078959     |   0\n",
      "      31127 |   0.204179  |    0.183509     |   1\n",
      "      31128 |   0.187932  |    0.176104     |   1\n",
      "      31129 |   0.190566  |    0.018852     |   0\n",
      "      31130 |   0.000013  |    0.045124     |   2\n",
      "      31131 |   0.198790  |    0.077421     |   0\n",
      "      31132 |   0.222190  |    0.047142     |   0\n",
      "      31133 |   0.251312  |    0.185478     |   1\n",
      "      31134 |   0.155145  |    0.243934     |   1\n",
      "      31135 |   0.156944  |    0.082485     |   0\n",
      "      31136 |   0.149204  |    0.048198     |   0\n",
      "      31137 |   0.000013  |    0.053217     |   2\n",
      "      31138 |   0.000013  |    0.044506     |   2\n",
      "      31139 |   0.000013  |    0.091191     |   2\n",
      "      31140 |   0.000013  |    0.083007     |   2\n",
      "      31141 |   0.167967  |    0.216168     |   1\n",
      "      31142 |   0.165750  |    0.210188     |   1\n",
      "      31143 |   0.186121  |    0.021938     |   0\n",
      "      31144 |   0.193211  |    0.073175     |   0\n",
      "      31145 |   0.140230  |    0.039111     |   0\n",
      "      31146 |   0.165663  |    0.226534     |   1\n",
      "      31147 |   0.148585  |    0.191688     |   1\n",
      "      31148 |   0.000013  |    0.023513     |   2\n",
      "      31149 |   0.038957  |    0.079937     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 31151: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      31150 |   0.043230  |    0.019741     |   2\n",
      "      31151 |   0.039325  |    0.082330     |   2\n",
      "      31152 |   0.145811  |    0.059584     |   0\n",
      "      31153 |   0.194076  |    0.218964     |   1\n",
      "      31154 |   0.131359  |    0.009399     |   0\n",
      "      31155 |   0.171014  |    0.219927     |   1\n",
      "      31156 |   0.184478  |    0.227834     |   1\n",
      "      31157 |   0.181584  |    0.133371     |   1\n",
      "      31158 |   0.027488  |    0.017740     |   2\n",
      "      31159 |   0.237410  |    0.211496     |   1\n",
      "      31160 |   0.032157  |    0.013445     |   2\n",
      "      31161 |   0.213047  |    0.096848     |   0\n",
      "      31162 |   0.149962  |    0.223952     |   1\n",
      "      31163 |   0.155692  |    0.150813     |   1\n",
      "      31164 |   0.164121  |    0.003852     |   0\n",
      "      31165 |   0.032220  |    0.075446     |   2\n",
      "      31166 |   0.201789  |    0.147049     |   1\n",
      "      31167 |   0.025186  |    0.007977     |   2\n",
      "      31168 |   0.160719  |    0.072103     |   0\n",
      "      31169 |   0.116195  |    0.038554     |   0\n",
      "      31170 |   0.199198  |    0.209339     |   1\n",
      "      31171 |   0.158258  |    0.009595     |   0\n",
      "      31172 |   0.178059  |    0.094927     |   0\n",
      "      31173 |   0.210836  |    0.222845     |   1\n",
      "      31174 |   0.191264  |    0.136585     |   1\n",
      "      31175 |   0.166637  |    0.022793     |   0\n",
      "      31176 |   0.031582  |    0.079904     |   2\n",
      "      31177 |   0.133675  |    0.155458     |   1\n",
      "      31178 |   0.167543  |    0.130077     |   1\n",
      "      31179 |   0.044711  |    0.056550     |   2\n",
      "      31180 |   0.124956  |    0.153934     |   1\n",
      "      31181 |   0.240723  |    0.199446     |   1\n",
      "      31182 |   0.195729  |    0.162932     |   1\n",
      "      31183 |   0.041756  |    0.025787     |   2\n",
      "      31184 |   0.037279  |    0.075507     |   2\n",
      "      31185 |   0.017441  |    0.046125     |   2\n",
      "      31186 |   0.202757  |    0.079533     |   0\n",
      "      31187 |   0.000014  |    0.025107     |   2\n",
      "      31188 |   0.004331  |    0.076358     |   2\n",
      "      31189 |   0.216688  |    0.038916     |   0\n",
      "      31190 |   0.148588  |    0.054000     |   0\n",
      "      31191 |   0.052320  |    0.042645     |   2\n",
      "      31192 |   0.027936  |    0.045661     |   2\n",
      "      31193 |   0.204409  |    0.070492     |   0\n",
      "      31194 |   0.050126  |    0.030161     |   2\n",
      "      31195 |   0.156068  |    0.208982     |   1\n",
      "      31196 |   0.175721  |    0.147558     |   1\n",
      "      31197 |   0.188039  |    0.158610     |   1\n",
      "      31198 |   0.035310  |    0.008850     |   2\n",
      "      31199 |   0.012486  |    0.085081     |   2\n",
      "      31200 |   0.203882  |    0.145873     |   1\n",
      "      31201 |   0.146749  |    0.062947     |   0\n",
      "      31202 |   0.230872  |    0.325769     |   1\n",
      "      31203 |   0.155561  |    0.084399     |   0\n",
      "      31204 |   0.029295  |    0.087184     |   2\n",
      "      31205 |   0.181811  |    0.078831     |   0\n",
      "      31206 |   0.022038  |    0.124288     |   2\n",
      "      31207 |   0.000013  |    0.043844     |   2\n",
      "      31208 |   0.124616  |    0.072817     |   0\n",
      "      31209 |   0.230185  |    0.335675     |   1\n",
      "      31210 | \u001b[94m  0.000013\u001b[0m  |    0.043072     |   2\n",
      "      31211 |   0.187282  |    0.135114     |   0\n",
      "      31212 |   0.155045  |    0.385346     |   1\n",
      "      31213 |   0.134629  |    0.030483     |   0\n",
      "      31214 |   0.140270  |    0.043564     |   0\n",
      "      31215 | \u001b[94m  0.000013\u001b[0m  |    0.076490     |   2\n",
      "      31216 |   0.153695  |    0.184044     |   1\n",
      "      31217 |   0.200417  |    0.147437     |   1\n",
      "      31218 |   0.000013  |    0.048477     |   2\n",
      "      31219 |   0.198119  |    0.138224     |   1\n",
      "      31220 |   0.181964  |    0.057672     |   0\n",
      "      31221 |   0.173654  |    0.175317     |   1\n",
      "      31222 | \u001b[94m  0.000013\u001b[0m  |    0.073445     |   2\n",
      "      31223 |   0.157322  |    0.015663     |   0\n",
      "      31224 | \u001b[94m  0.000013\u001b[0m  |    0.075421     |   2\n",
      "      31225 |   0.199680  |    0.135893     |   1\n",
      "      31226 |   0.132799  |    0.039592     |   0\n",
      "      31227 |   0.174588  |    0.157925     |   1\n",
      "      31228 |   0.203718  |    0.180488     |   1\n",
      "      31229 |   0.129849  |    0.251867     |   1\n",
      "      31230 |   0.168085  |    0.071767     |   0\n",
      "      31231 |   0.038661  |    0.044479     |   2\n",
      "      31232 |   0.042514  |    0.051353     |   2\n",
      "      31233 |   0.160381  |    0.098847     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 31234: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      31234 |   0.194057  |    0.241455     |   1\n",
      "      31235 |   0.040928  |    0.090182     |   2\n",
      "      31236 |   0.028362  |    0.096348     |   2\n",
      "      31237 |   0.031924  |    0.082016     |   2\n",
      "      31238 |   0.029894  |    0.143541     |   2\n",
      "      31239 |   0.185099  |    0.070685     |   0\n",
      "      31240 |   0.024342  |    0.096910     |   2\n",
      "      31241 |   0.178148  |    0.246292     |   1\n",
      "      31242 |   0.177960  |    0.081165     |   0\n",
      "      31243 |   0.158032  |    0.278238     |   1\n",
      "      31244 |   0.202752  |    0.134987     |   0\n",
      "      31245 |   0.033633  |    0.073727     |   2\n",
      "      31246 |   0.044698  |    0.068376     |   2\n",
      "      31247 |   0.154391  |    0.402444     |   1\n",
      "      31248 |   0.207680  |    0.357287     |   1\n",
      "      31249 |   0.148215  |    0.030842     |   0\n",
      "      31250 |   0.158808  |    0.406159     |   1\n",
      "      31251 |   0.186460  |    0.440546     |   1\n",
      "      31252 |   0.044639  |    0.079769     |   2\n",
      "      31253 |   0.213601  |    0.102599     |   0\n",
      "      31254 |   0.179246  |    0.349123     |   1\n",
      "      31255 |   0.162203  |    0.149999     |   0\n",
      "      31256 |   0.138663  |    0.028928     |   0\n",
      "      31257 |   0.184910  |    0.076127     |   0\n",
      "      31258 |   0.039223  |    0.089110     |   2\n",
      "      31259 |   0.019497  |    0.125874     |   2\n",
      "      31260 |   0.129834  |    0.038493     |   0\n",
      "      31261 | \u001b[94m  0.000013\u001b[0m  |    0.122885     |   2\n",
      "      31262 |   0.004179  |    0.147868     |   2\n",
      "      31263 |   0.049691  |    0.102083     |   2\n",
      "      31264 |   0.195869  |    0.141286     |   0\n",
      "      31265 |   0.174963  |    0.229326     |   1\n",
      "      31266 |   0.154110  |    0.271950     |   1\n",
      "      31267 |   0.029855  |    0.004137     |   2\n",
      "      31268 |   0.179698  |    0.243588     |   1\n",
      "      31269 |   0.054090  |    0.050964     |   2\n",
      "      31270 |   0.163880  |    0.145246     |   0\n",
      "      31271 |   0.231296  |    0.200903     |   1\n",
      "      31272 |   0.165255  |    0.065198     |   0\n",
      "      31273 |   0.037753  |    0.152548     |   2\n",
      "      31274 |   0.173018  |    0.213604     |   1\n",
      "      31275 |   0.014684  |    0.003783     |   2\n",
      "      31276 |   0.112603  |    0.332290     |   1\n",
      "      31277 |   0.030843  |    0.098923     |   2\n",
      "      31278 |   0.022164  |    0.030332     |   2\n",
      "      31279 |   0.000013  |    0.113480     |   2\n",
      "      31280 |   0.181918  |    0.099107     |   0\n",
      "      31281 |   0.164790  |    0.317355     |   1\n",
      "      31282 |   0.244750  |    0.021967     |   0\n",
      "      31283 |   0.000013  |    0.138717     |   2\n",
      "      31284 |   0.175015  |    0.360080     |   1\n",
      "      31285 |   0.182244  |    0.293760     |   1\n",
      "      31286 |   0.000013  |    0.101326     |   2\n",
      "      31287 |   0.210166  |    0.445606     |   1\n",
      "      31288 |   0.160126  |    0.036575     |   0\n",
      "      31289 |   0.170422  |    0.364726     |   1\n",
      "      31290 |   0.000013  |    0.026749     |   2\n",
      "      31291 |   0.000013  |    0.065712     |   2\n",
      "      31292 |   0.000013  |    0.063236     |   2\n",
      "      31293 |   0.166936  |    0.304120     |   1\n",
      "      31294 |   0.167958  |    0.023011     |   0\n",
      "      31295 |   0.036847  |    0.122436     |   2\n",
      "      31296 |   0.042230  |    0.067401     |   2\n",
      "      31297 |   0.151226  |    0.063676     |   0\n",
      "      31298 |   0.110891  |    0.352424     |   1\n",
      "      31299 |   0.184698  |    0.333731     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 31300: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      31300 |   0.148757  |    0.094498     |   0\n",
      "      31301 |   0.036243  |    0.045233     |   2\n",
      "      31302 |   0.026204  |    0.101234     |   2\n",
      "      31303 |   0.031931  |    0.010846     |   2\n",
      "      31304 |   0.030789  |    0.110085     |   2\n",
      "      31305 |   0.023349  |    0.075343     |   2\n",
      "      31306 |   0.032537  |    0.049148     |   2\n",
      "      31307 |   0.146742  |    0.096661     |   0\n",
      "      31308 |   0.140449  |    0.024437     |   0\n",
      "      31309 |   0.039184  |    0.132918     |   2\n",
      "      31310 |   0.045837  |    0.005505     |   2\n",
      "      31311 |   0.152362  |    0.136885     |   0\n",
      "      31312 |   0.216850  |    0.238408     |   1\n",
      "      31313 |   0.177967  |    0.100810     |   0\n",
      "      31314 |   0.194344  |    0.088933     |   0\n",
      "      31315 |   0.157277  |    0.032311     |   0\n",
      "      31316 |   0.149040  |    0.082361     |   0\n",
      "      31317 |   0.116775  |    0.021677     |   0\n",
      "      31318 |   0.157004  |    0.106304     |   0\n",
      "      31319 |   0.148240  |    0.067425     |   0\n",
      "      31320 |   0.035439  |    0.141200     |   2\n",
      "      31321 |   0.195421  |    0.289945     |   1\n",
      "      31322 |   0.016549  |    0.016713     |   2\n",
      "      31323 |   0.172050  |    0.302762     |   1\n",
      "      31324 |   0.174144  |    0.281664     |   1\n",
      "      31325 |   0.172731  |    0.387360     |   1\n",
      "      31326 |   0.141896  |    0.036605     |   0\n",
      "      31327 |   0.000013  |    0.084064     |   2\n",
      "      31328 |   0.162937  |    0.103792     |   0\n",
      "      31329 |   0.161450  |    0.366100     |   1\n",
      "      31330 |   0.143263  |    0.379642     |   1\n",
      "      31331 |   0.144991  |    0.068969     |   0\n",
      "      31332 |   0.003729  |    0.090342     |   2\n",
      "      31333 |   0.205917  |    0.129839     |   0\n",
      "      31334 |   0.173620  |    0.349090     |   1\n",
      "      31335 |   0.163539  |    0.038813     |   0\n",
      "      31336 |   0.192798  |    0.268051     |   1\n",
      "      31337 |   0.050300  |    0.127073     |   2\n",
      "      31338 |   0.032250  |    0.053082     |   2\n",
      "      31339 |   0.119675  |    0.147109     |   0\n",
      "      31340 |   0.155265  |    0.292919     |   1\n",
      "      31341 |   0.052784  |    0.151609     |   2\n",
      "      31342 |   0.168854  |    0.080960     |   0\n",
      "      31343 |   0.127065  |    0.025214     |   0\n",
      "      31344 |   0.168501  |    0.111952     |   0\n",
      "      31345 |   0.033931  |    0.081665     |   2\n",
      "      31346 |   0.014284  |    0.049791     |   2\n",
      "      31347 |   0.029994  |    0.099634     |   2\n",
      "      31348 |   0.189983  |    0.037503     |   0\n",
      "      31349 |   0.025570  |    0.113143     |   2\n",
      "      31350 |   0.178851  |    0.203103     |   1\n",
      "      31351 |   0.160089  |    0.226724     |   1\n",
      "      31352 |   0.163561  |    0.121615     |   0\n",
      "      31353 |   0.156590  |    0.040433     |   0\n",
      "      31354 |   0.151991  |    0.278301     |   1\n",
      "      31355 |   0.173261  |    0.007326     |   0\n",
      "      31356 |   0.000013  |    0.078506     |   2\n",
      "      31357 |   0.139456  |    0.217986     |   1\n",
      "      31358 |   0.164825  |    0.158638     |   0\n",
      "      31359 |   0.155687  |    0.216713     |   1\n",
      "      31360 |   0.000013  |    0.013586     |   2\n",
      "      31361 |   0.000013  |    0.082797     |   2\n",
      "      31362 |   0.236108  |    0.082662     |   0\n",
      "      31363 |   0.000013  |    0.064507     |   2\n",
      "      31364 |   0.146404  |    0.068117     |   0\n",
      "      31365 |   0.000013  |    0.094724     |   2\n",
      "      31366 |   0.192231  |    0.043465     |   0\n",
      "      31367 |   0.165151  |    0.080376     |   0\n",
      "      31368 |   0.000013  |    0.088127     |   2\n",
      "      31369 |   0.197043  |    0.261263     |   1\n",
      "      31370 |   0.161224  |    0.058777     |   0\n",
      "      31371 |   0.208424  |    0.310745     |   1\n",
      "      31372 |   0.193964  |    0.151659     |   1\n",
      "      31373 |   0.148895  |    0.082461     |   0\n",
      "      31374 |   0.171397  |    0.214924     |   1\n",
      "      31375 |   0.189798  |    0.051967     |   0\n",
      "      31376 |   0.178085  |    0.220894     |   1\n",
      "      31377 |   0.040886  |    0.053702     |   2\n",
      "      31378 |   0.044051  |    0.071170     |   2\n",
      "      31379 |   0.148939  |    0.269384     |   1\n",
      "      31380 |   0.148421  |    0.205382     |   1\n",
      "      31381 |   0.173598  |    0.052681     |   0\n",
      "      31382 |   0.140511  |    0.129209     |   0\n",
      "      31383 |   0.197615  |    0.072946     |   0\n",
      "      31384 |   0.200244  |    0.091359     |   0\n",
      "      31385 |   0.190957  |    0.351601     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 31387: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      31386 |   0.143034  |    0.036227     |   0\n",
      "      31387 |   0.039321  |    0.142724     |   2\n",
      "      31388 |   0.194786  |    0.475792     |   1\n",
      "      31389 |   0.027029  |    0.085545     |   2\n",
      "      31390 |   0.032875  |    0.193583     |   2\n",
      "      31391 |   0.031906  |    0.083475     |   2\n",
      "      31392 |   0.144795  |    0.090392     |   0\n",
      "      31393 |   0.184583  |    0.097179     |   0\n",
      "      31394 |   0.206218  |    0.120585     |   0\n",
      "      31395 |   0.150084  |    0.419054     |   1\n",
      "      31396 |   0.024007  |    0.092401     |   2\n",
      "      31397 |   0.034112  |    0.083706     |   2\n",
      "      31398 |   0.043541  |    0.087944     |   2\n",
      "      31399 |   0.168399  |    0.072479     |   0\n",
      "      31400 |   0.181966  |    0.378878     |   1\n",
      "      31401 |   0.044363  |    0.086849     |   2\n",
      "      31402 |   0.035241  |    0.156259     |   2\n",
      "      31403 |   0.018093  |    0.019168     |   2\n",
      "      31404 |   0.000013  |    0.169543     |   2\n",
      "      31405 |   0.004232  |    0.034605     |   2\n",
      "      31406 |   0.049018  |    0.091945     |   2\n",
      "      31407 |   0.030000  |    0.127376     |   2\n",
      "      31408 |   0.164108  |    0.042609     |   0\n",
      "      31409 |   0.150127  |    0.093408     |   0\n",
      "      31410 |   0.147905  |    0.398342     |   1\n",
      "      31411 |   0.163186  |    0.087453     |   0\n",
      "      31412 |   0.177732  |    0.062326     |   0\n",
      "      31413 |   0.053993  |    0.114035     |   2\n",
      "      31414 |   0.186677  |    0.152361     |   0\n",
      "      31415 |   0.212154  |    0.307897     |   1\n",
      "      31416 |   0.036586  |    0.148904     |   2\n",
      "      31417 |   0.015321  |    0.024067     |   2\n",
      "      31418 |   0.173371  |    0.510845     |   1\n",
      "      31419 |   0.208848  |    0.333719     |   1\n",
      "      31420 |   0.031745  |    0.004908     |   2\n",
      "      31421 |   0.147481  |    0.240034     |   1\n",
      "      31422 |   0.158254  |    0.208331     |   1\n",
      "      31423 |   0.022571  |    0.067488     |   2\n",
      "      31424 |   0.189224  |    0.261983     |   1\n",
      "      31425 |   0.179515  |    0.252933     |   1\n",
      "      31426 |   0.000013  |    0.095493     |   2\n",
      "      31427 |   0.000013  |    0.040827     |   2\n",
      "      31428 |   0.000013  |    0.084908     |   2\n",
      "      31429 |   0.000013  |    0.069857     |   2\n",
      "      31430 |   0.189071  |    0.076637     |   0\n",
      "      31431 |   0.000013  |    0.115767     |   2\n",
      "      31432 |   0.000013  |    0.053085     |   2\n",
      "      31433 |   0.164379  |    0.231647     |   1\n",
      "      31434 |   0.135177  |    0.242676     |   1\n",
      "      31435 |   0.039354  |    0.015147     |   2\n",
      "      31436 |   0.198064  |    0.292357     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 31438: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      31437 |   0.042925  |    0.013948     |   2\n",
      "      31438 |   0.160527  |    0.233020     |   1\n",
      "      31439 |   0.186398  |    0.225499     |   1\n",
      "      31440 |   0.141377  |    0.056975     |   0\n",
      "      31441 |   0.160415  |    0.301514     |   1\n",
      "      31442 |   0.176807  |    0.189826     |   1\n",
      "      31443 |   0.121329  |    0.071085     |   0\n",
      "      31444 |   0.036473  |    0.017817     |   2\n",
      "      31445 |   0.026552  |    0.127549     |   2\n",
      "      31446 |   0.173485  |    0.223480     |   1\n",
      "      31447 |   0.032435  |    0.042804     |   2\n",
      "      31448 |   0.191490  |    0.279423     |   1\n",
      "      31449 |   0.031189  |    0.012353     |   2\n",
      "      31450 |   0.195067  |    0.269998     |   1\n",
      "      31451 |   0.147767  |    0.245460     |   1\n",
      "      31452 |   0.193294  |    0.020506     |   0\n",
      "      31453 |   0.217379  |    0.087135     |   0\n",
      "      31454 |   0.023480  |    0.064684     |   2\n",
      "      31455 |   0.031430  |    0.090622     |   2\n",
      "      31456 |   0.041663  |    0.017842     |   2\n",
      "      31457 |   0.214436  |    0.192779     |   1\n",
      "      31458 |   0.183578  |    0.100409     |   0\n",
      "      31459 |   0.149064  |    0.048732     |   0\n",
      "      31460 |   0.043394  |    0.086493     |   2\n",
      "      31461 |   0.168746  |    0.020704     |   0\n",
      "      31462 |   0.187299  |    0.241041     |   1\n",
      "      31463 |   0.035747  |    0.041735     |   2\n",
      "      31464 |   0.166976  |    0.088501     |   0\n",
      "      31465 |   0.180463  |    0.234845     |   1\n",
      "      31466 |   0.141873  |    0.216718     |   1\n",
      "      31467 |   0.227312  |    0.025642     |   0\n",
      "      31468 |   0.186066  |    0.092615     |   0\n",
      "      31469 |   0.016661  |    0.055120     |   2\n",
      "      31470 |   0.171326  |    0.070420     |   0\n",
      "      31471 |   0.162728  |    0.070040     |   0\n",
      "      31472 |   0.000013  |    0.069660     |   2\n",
      "      31473 |   0.200569  |    0.085715     |   0\n",
      "      31474 |   0.003853  |    0.124284     |   2\n",
      "      31475 |   0.156549  |    0.004730     |   0\n",
      "      31476 |   0.052388  |    0.145190     |   2\n",
      "      31477 |   0.030899  |    0.013023     |   2\n",
      "      31478 |   0.054101  |    0.074459     |   2\n",
      "      31479 |   0.163150  |    0.179955     |   1\n",
      "      31480 |   0.163843  |    0.272753     |   1\n",
      "      31481 |   0.035110  |    0.014413     |   2\n",
      "      31482 |   0.017149  |    0.129964     |   2\n",
      "      31483 |   0.187170  |    0.182716     |   1\n",
      "      31484 |   0.030587  |    0.081200     |   2\n",
      "      31485 |   0.106173  |    0.066803     |   0\n",
      "      31486 |   0.021390  |    0.077983     |   2\n",
      "      31487 |   0.170436  |    0.159586     |   1\n",
      "      31488 |   0.000013  |    0.102327     |   2\n",
      "      31489 |   0.164071  |    0.182422     |   1\n",
      "      31490 |   0.136766  |    0.217741     |   1\n",
      "      31491 |   0.000013  |    0.031637     |   2\n",
      "      31492 |   0.192763  |    0.240254     |   1\n",
      "      31493 |   0.173838  |    0.046643     |   0\n",
      "      31494 |   0.205572  |    0.058806     |   0\n",
      "      31495 |   0.000013  |    0.099292     |   2\n",
      "      31496 |   0.204194  |    0.077387     |   0\n",
      "      31497 |   0.170673  |    0.030973     |   0\n",
      "      31498 |   0.150167  |    0.070708     |   0\n",
      "      31499 |   0.247588  |    0.243654     |   1\n",
      "      31500 |   0.200734  |    0.007179     |   0\n",
      "      31501 |   0.165024  |    0.118647     |   0\n",
      "      31502 |   0.180116  |    0.185857     |   1\n",
      "      31503 |   0.191849  |    0.064925     |   0\n",
      "      31504 |   0.040594  |    0.097188     |   2\n",
      "      31505 |   0.028835  |    0.031765     |   2\n",
      "      31506 |   0.033469  |    0.044518     |   2\n",
      "      31507 |   0.151894  |    0.077509     |   0\n",
      "      31508 |   0.030593  |    0.050650     |   2\n",
      "      31509 |   0.023477  |    0.054135     |   2\n",
      "      31510 |   0.142523  |    0.301069     |   1\n",
      "      31511 |   0.177194  |    0.255049     |   1\n",
      "      31512 |   0.178865  |    0.042027     |   0\n",
      "      31513 |   0.152780  |    0.227781     |   1\n",
      "      31514 |   0.194296  |    0.064173     |   0\n",
      "      31515 |   0.030938  |    0.044079     |   2\n",
      "      31516 |   0.153681  |    0.091191     |   0\n",
      "      31517 |   0.128215  |    0.029811     |   0\n",
      "      31518 |   0.218866  |    0.230860     |   1\n",
      "      31519 |   0.047110  |    0.012082     |   2\n",
      "      31520 |   0.044851  |    0.093421     |   2\n",
      "      31521 |   0.142648  |    0.222549     |   1\n",
      "      31522 |   0.203580  |    0.239064     |   1\n",
      "      31523 |   0.038118  |    0.043208     |   2\n",
      "      31524 |   0.016348  |    0.164466     |   2\n",
      "      31525 |   0.146157  |    0.004607     |   0\n",
      "      31526 |   0.171913  |    0.009302     |   0\n",
      "      31527 |   0.000013  |    0.086915     |   2\n",
      "      31528 |   0.158018  |    0.303000     |   1\n",
      "      31529 |   0.189479  |    0.211412     |   1\n",
      "      31530 |   0.157273  |    0.072847     |   0\n",
      "      31531 |   0.003957  |    0.083757     |   2\n",
      "      31532 |   0.164120  |    0.022451     |   0\n",
      "      31533 |   0.050701  |    0.112483     |   2\n",
      "      31534 |   0.027708  |    0.085054     |   2\n",
      "      31535 |   0.255267  |    0.276580     |   1\n",
      "      31536 |   0.139258  |    0.063983     |   0\n",
      "      31537 |   0.152547  |    0.278302     |   1\n",
      "      31538 |   0.155820  |    0.219934     |   1\n",
      "      31539 |   0.167409  |    0.016745     |   0\n",
      "      31540 |   0.181708  |    0.140786     |   0\n",
      "      31541 |   0.174274  |    0.266559     |   1\n",
      "      31542 |   0.050936  |    0.007103     |   2\n",
      "      31543 |   0.034388  |    0.046983     |   2\n",
      "      31544 |   0.220214  |    0.092581     |   0\n",
      "      31545 |   0.016294  |    0.046738     |   2\n",
      "      31546 |   0.149987  |    0.076855     |   0\n",
      "      31547 |   0.171557  |    0.060666     |   0\n",
      "      31548 |   0.030286  |    0.048387     |   2\n",
      "      31549 |   0.219844  |    0.072919     |   0\n",
      "      31550 |   0.193291  |    0.273948     |   1\n",
      "      31551 |   0.164670  |    0.007226     |   0\n",
      "      31552 |   0.158078  |    0.065367     |   0\n",
      "      31553 |   0.137800  |    0.292559     |   1\n",
      "      31554 |   0.179813  |    0.059871     |   0\n",
      "      31555 |   0.022135  |    0.075555     |   2\n",
      "      31556 |   0.200521  |    0.093850     |   0\n",
      "      31557 |   0.196739  |    0.004113     |   0\n",
      "      31558 |   0.177131  |    0.227788     |   1\n",
      "      31559 |   0.000013  |    0.090781     |   2\n",
      "      31560 |   0.000013  |    0.010912     |   2\n",
      "      31561 |   0.198746  |    0.126261     |   0\n",
      "      31562 |   0.160146  |    0.056984     |   0\n",
      "      31563 |   0.124619  |    0.221815     |   1\n",
      "      31564 |   0.225602  |    0.239389     |   1\n",
      "      31565 |   0.000013  |    0.077663     |   2\n",
      "      31566 |   0.171227  |    0.081097     |   0\n",
      "      31567 |   0.000013  |    0.064779     |   2\n",
      "      31568 |   0.124179  |    0.091636     |   0\n",
      "      31569 |   0.219067  |    0.251300     |   1\n",
      "      31570 |   0.141182  |    0.008699     |   0\n",
      "      31571 |   0.157867  |    0.259077     |   1\n",
      "      31572 |   0.168372  |    0.025441     |   0\n",
      "      31573 |   0.000013  |    0.091985     |   2\n",
      "      31574 |   0.000013  |    0.029491     |   2\n",
      "      31575 |   0.156215  |    0.072163     |   0\n",
      "      31576 |   0.170865  |    0.276260     |   1\n",
      "      31577 |   0.204482  |    0.083299     |   0\n",
      "      31578 |   0.231003  |    0.224160     |   1\n",
      "      31579 |   0.143500  |    0.226401     |   1\n",
      "      31580 |   0.044143  |    0.085734     |   2\n",
      "      31581 |   0.043166  |    0.047258     |   2\n",
      "      31582 |   0.198149  |    0.074785     |   0\n",
      "      31583 |   0.152321  |    0.013573     |   0\n",
      "      31584 |   0.145024  |    0.089921     |   0\n",
      "      31585 |   0.128401  |    0.122656     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 31586: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      31586 |   0.217409  |    0.233501     |   1\n",
      "      31587 |   0.039887  |    0.008343     |   2\n",
      "      31588 |   0.029162  |    0.074420     |   2\n",
      "      31589 |   0.202610  |    0.088648     |   0\n",
      "      31590 |   0.132919  |    0.025405     |   0\n",
      "      31591 |   0.033784  |    0.082114     |   2\n",
      "      31592 |   0.168347  |    0.092267     |   0\n",
      "      31593 |   0.198595  |    0.251751     |   1\n",
      "      31594 |   0.183177  |    0.238632     |   1\n",
      "      31595 |   0.149596  |    0.021271     |   0\n",
      "      31596 |   0.208588  |    0.289014     |   1\n",
      "      31597 |   0.172143  |    0.033616     |   0\n",
      "      31598 |   0.161023  |    0.236720     |   1\n",
      "      31599 |   0.188614  |    0.011836     |   0\n",
      "      31600 |   0.131165  |    0.311383     |   1\n",
      "      31601 |   0.224280  |    0.019089     |   0\n",
      "      31602 |   0.161388  |    0.422493     |   1\n",
      "      31603 |   0.030970  |    0.004337     |   2\n",
      "      31604 |   0.153452  |    0.214039     |   1\n",
      "      31605 |   0.023210  |    0.096337     |   2\n",
      "      31606 |   0.182905  |    0.168140     |   1\n",
      "      31607 |   0.033032  |    0.092306     |   2\n",
      "      31608 |   0.042867  |    0.052920     |   2\n",
      "      31609 |   0.185604  |    0.298089     |   1\n",
      "      31610 |   0.164266  |    0.075314     |   0\n",
      "      31611 |   0.045089  |    0.070923     |   2\n",
      "      31612 |   0.180305  |    0.240413     |   1\n",
      "      31613 |   0.188382  |    0.071278     |   0\n",
      "      31614 |   0.171703  |    0.074080     |   0\n",
      "      31615 |   0.145915  |    0.117117     |   0\n",
      "      31616 |   0.156322  |    0.212262     |   1\n",
      "      31617 |   0.038127  |    0.060085     |   2\n",
      "      31618 |   0.169294  |    0.098268     |   0\n",
      "      31619 |   0.018047  |    0.027509     |   2\n",
      "      31620 |   0.119919  |    0.239826     |   1\n",
      "      31621 |   0.184030  |    0.278473     |   1\n",
      "      31622 |   0.157654  |    0.262798     |   1\n",
      "      31623 |   0.156884  |    0.025809     |   0\n",
      "      31624 |   0.228381  |    0.208008     |   1\n",
      "      31625 |   0.000013  |    0.099783     |   2\n",
      "      31626 |   0.004349  |    0.004279     |   2\n",
      "      31627 |   0.202473  |    0.148266     |   0\n",
      "      31628 |   0.130909  |    0.159642     |   1\n",
      "      31629 |   0.050984  |    0.063324     |   2\n",
      "      31630 |   0.029377  |    0.129675     |   2\n",
      "      31631 |   0.128459  |    0.003439     |   0\n",
      "      31632 |   0.165067  |    0.228498     |   1\n",
      "      31633 |   0.170798  |    0.233785     |   1\n",
      "      31634 |   0.203248  |    0.029515     |   0\n",
      "      31635 |   0.049693  |    0.105059     |   2\n",
      "      31636 |   0.036379  |    0.043356     |   2\n",
      "      31637 |   0.015043  |    0.080592     |   2\n",
      "      31638 |   0.030925  |    0.051162     |   2\n",
      "      31639 |   0.021943  |    0.065736     |   2\n",
      "      31640 |   0.157351  |    0.073943     |   0\n",
      "      31641 |   0.170885  |    0.261977     |   1\n",
      "      31642 |   0.186309  |    0.203795     |   1\n",
      "      31643 |   0.186532  |    0.080731     |   0\n",
      "      31644 |   0.000013  |    0.083601     |   2\n",
      "      31645 |   0.163740  |    0.184540     |   1\n",
      "      31646 |   0.000013  |    0.123298     |   2\n",
      "      31647 |   0.175626  |    0.228641     |   1\n",
      "      31648 |   0.191734  |    0.125224     |   1\n",
      "      31649 |   0.000013  |    0.084364     |   2\n",
      "      31650 |   0.000013  |    0.041367     |   2\n",
      "      31651 |   0.000013  |    0.149107     |   2\n",
      "      31652 |   0.179022  |    0.026526     |   0\n",
      "      31653 |   0.132211  |    0.076670     |   0\n",
      "      31654 |   0.167873  |    0.071256     |   0\n",
      "      31655 |   0.183588  |    0.230578     |   1\n",
      "      31656 |   0.144871  |    0.075382     |   0\n",
      "      31657 |   0.143095  |    0.017482     |   0\n",
      "      31658 |   0.151503  |    0.241247     |   1\n",
      "      31659 |   0.172707  |    0.045580     |   0\n",
      "      31660 |   0.000013  |    0.044577     |   2\n",
      "      31661 |   0.164246  |    0.070495     |   0\n",
      "      31662 |   0.181404  |    0.043358     |   0\n",
      "      31663 |   0.183604  |    0.027161     |   0\n",
      "      31664 |   0.212683  |    0.251647     |   1\n",
      "      31665 |   0.152883  |    0.075358     |   0\n",
      "      31666 |   0.136827  |    0.040663     |   0\n",
      "      31667 |   0.038634  |    0.103998     |   2\n",
      "      31668 |   0.041898  |    0.013388     |   2\n",
      "      31669 |   0.104226  |    0.072788     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 31670: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      31670 |   0.165396  |    0.222589     |   1\n",
      "      31671 |   0.141801  |    0.188566     |   1\n",
      "      31672 |   0.043222  |    0.076309     |   2\n",
      "      31673 |   0.172333  |    0.188043     |   1\n",
      "      31674 |   0.200579  |    0.219662     |   1\n",
      "      31675 |   0.202026  |    0.088111     |   0\n",
      "      31676 |   0.179606  |    0.074676     |   0\n",
      "      31677 |   0.205658  |    0.212419     |   1\n",
      "      31678 |   0.177152  |    0.034083     |   0\n",
      "      31679 |   0.170802  |    0.079804     |   0\n",
      "      31680 |   0.152476  |    0.031557     |   0\n",
      "      31681 |   0.186486  |    0.221172     |   1\n",
      "      31682 |   0.154492  |    0.095524     |   0\n",
      "      31683 |   0.192839  |    0.050325     |   0\n",
      "      31684 |   0.029551  |    0.071489     |   2\n",
      "      31685 |   0.234913  |    0.033362     |   0\n",
      "      31686 |   0.178313  |    0.072697     |   0\n",
      "      31687 |   0.187476  |    0.254570     |   1\n",
      "      31688 |   0.148342  |    0.004462     |   0\n",
      "      31689 |   0.034709  |    0.111598     |   2\n",
      "      31690 |   0.031070  |    0.027504     |   2\n",
      "      31691 |   0.023598  |    0.055653     |   2\n",
      "      31692 |   0.153051  |    0.077082     |   0\n",
      "      31693 |   0.183151  |    0.065331     |   0\n",
      "      31694 |   0.200486  |    0.076552     |   0\n",
      "      31695 |   0.196276  |    0.239244     |   1\n",
      "      31696 |   0.168689  |    0.059201     |   0\n",
      "      31697 |   0.235597  |    0.235899     |   1\n",
      "      31698 |   0.032767  |    0.057475     |   2\n",
      "      31699 |   0.174246  |    0.116181     |   0\n",
      "      31700 |   0.207928  |    0.198508     |   1\n",
      "      31701 |   0.044106  |    0.073098     |   2\n",
      "      31702 |   0.047791  |    0.099580     |   2\n",
      "      31703 |   0.035589  |    0.008029     |   2\n",
      "      31704 |   0.158651  |    0.263987     |   1\n",
      "      31705 |   0.171737  |    0.273945     |   1\n",
      "      31706 |   0.247710  |    0.227322     |   1\n",
      "      31707 |   0.017839  |    0.028688     |   2\n",
      "      31708 |   0.000013  |    0.064115     |   2\n",
      "      31709 |   0.004035  |    0.040138     |   2\n",
      "      31710 |   0.179002  |    0.109391     |   0\n",
      "      31711 |   0.049711  |    0.066449     |   2\n",
      "      31712 |   0.029948  |    0.016081     |   2\n",
      "      31713 |   0.050944  |    0.083951     |   2\n",
      "      31714 |   0.037193  |    0.064058     |   2\n",
      "      31715 |   0.172930  |    0.076204     |   0\n",
      "      31716 |   0.147535  |    0.276576     |   1\n",
      "      31717 |   0.221985  |    0.012106     |   0\n",
      "      31718 |   0.016352  |    0.122546     |   2\n",
      "      31719 |   0.028234  |    0.046681     |   2\n",
      "      31720 |   0.022496  |    0.040314     |   2\n",
      "      31721 |   0.174055  |    0.194644     |   1\n",
      "      31722 |   0.000013  |    0.088041     |   2\n",
      "      31723 |   0.000013  |    0.034870     |   2\n",
      "      31724 |   0.164539  |    0.216246     |   1\n",
      "      31725 |   0.203982  |    0.122318     |   0\n",
      "      31726 |   0.000013  |    0.041602     |   2\n",
      "      31727 |   0.000013  |    0.026998     |   2\n",
      "      31728 |   0.144892  |    0.085642     |   0\n",
      "      31729 |   0.000013  |    0.082647     |   2\n",
      "      31730 |   0.165562  |    0.192622     |   1\n",
      "      31731 |   0.155053  |    0.094136     |   0\n",
      "      31732 |   0.171844  |    0.025709     |   0\n",
      "      31733 |   0.145505  |    0.268682     |   1\n",
      "      31734 |   0.160880  |    0.229268     |   1\n",
      "      31735 |   0.000013  |    0.067291     |   2\n",
      "      31736 |   0.037958  |    0.046881     |   2\n",
      "      31737 |   0.229465  |    0.276032     |   1\n",
      "      31738 |   0.040773  |    0.007202     |   2\n",
      "      31739 |   0.143712  |    0.094067     |   0\n",
      "      31740 |   0.156840  |    0.238487     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 31741: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      31741 |   0.037063  |    0.004655     |   2\n",
      "      31742 |   0.161610  |    0.225773     |   1\n",
      "      31743 |   0.026909  |    0.069656     |   2\n",
      "      31744 |   0.208661  |    0.031617     |   0\n",
      "      31745 |   0.140109  |    0.279795     |   1\n",
      "      31746 |   0.194152  |    0.049556     |   0\n",
      "      31747 |   0.031611  |    0.070703     |   2\n",
      "      31748 |   0.030452  |    0.111011     |   2\n",
      "      31749 |   0.177430  |    0.045792     |   0\n",
      "      31750 |   0.169580  |    0.085529     |   0\n",
      "      31751 |   0.175530  |    0.041175     |   0\n",
      "      31752 |   0.023009  |    0.083364     |   2\n",
      "      31753 |   0.031152  |    0.045503     |   2\n",
      "      31754 |   0.195078  |    0.081490     |   0\n",
      "      31755 |   0.190751  |    0.273902     |   1\n",
      "      31756 |   0.040061  |    0.017576     |   2\n",
      "      31757 |   0.180065  |    0.228528     |   1\n",
      "      31758 |   0.160885  |    0.074878     |   0\n",
      "      31759 |   0.043762  |    0.079827     |   2\n",
      "      31760 |   0.162581  |    0.249193     |   1\n",
      "      31761 |   0.150820  |    0.029765     |   0\n",
      "      31762 |   0.188521  |    0.225172     |   1\n",
      "      31763 |   0.165122  |    0.189264     |   1\n",
      "      31764 |   0.159719  |    0.074377     |   0\n",
      "      31765 |   0.037415  |    0.102320     |   2\n",
      "      31766 |   0.214204  |    0.269245     |   1\n",
      "      31767 |   0.017681  |    0.067007     |   2\n",
      "      31768 |   0.000013  |    0.044722     |   2\n",
      "      31769 |   0.242057  |    0.288184     |   1\n",
      "      31770 |   0.004493  |    0.017916     |   2\n",
      "      31771 |   0.216898  |    0.282670     |   1\n",
      "      31772 |   0.160479  |    0.207393     |   1\n",
      "      31773 |   0.160823  |    0.065776     |   0\n",
      "      31774 |   0.176377  |    0.010547     |   0\n",
      "      31775 |   0.145097  |    0.279875     |   1\n",
      "      31776 |   0.169245  |    0.097012     |   0\n",
      "      31777 |   0.048433  |    0.058082     |   2\n",
      "      31778 |   0.316371  |    0.063069     |   0\n",
      "      31779 |   0.187487  |    0.123193     |   0\n",
      "      31780 |   0.029138  |    0.024449     |   2\n",
      "      31781 |   0.182097  |    0.279275     |   1\n",
      "      31782 |   0.177696  |    0.220030     |   1\n",
      "      31783 |   0.051169  |    0.077587     |   2\n",
      "      31784 |   0.174541  |    0.214465     |   1\n",
      "      31785 |   0.037894  |    0.043644     |   2\n",
      "      31786 |   0.183707  |    0.297585     |   1\n",
      "      31787 |   0.121386  |    0.023619     |   0\n",
      "      31788 |   0.180641  |    0.084666     |   0\n",
      "      31789 |   0.013877  |    0.038210     |   2\n",
      "      31790 |   0.208578  |    0.259769     |   1\n",
      "      31791 |   0.139602  |    0.008706     |   0\n",
      "      31792 |   0.150913  |    0.101892     |   0\n",
      "      31793 |   0.174801  |    0.168289     |   1\n",
      "      31794 |   0.180722  |    0.094660     |   0\n",
      "      31795 |   0.030516  |    0.052945     |   2\n",
      "      31796 |   0.023373  |    0.129217     |   2\n",
      "      31797 |   0.147163  |    0.031072     |   0\n",
      "      31798 |   0.162274  |    0.060314     |   0\n",
      "      31799 |   0.142074  |    0.317163     |   1\n",
      "      31800 |   0.190824  |    0.160494     |   1\n",
      "      31801 |   0.000013  |    0.073163     |   2\n",
      "      31802 |   0.183610  |    0.253225     |   1\n",
      "      31803 |   0.000013  |    0.003884     |   2\n",
      "      31804 |   0.126857  |    0.146871     |   0\n",
      "      31805 |   0.148353  |    0.012276     |   0\n",
      "      31806 |   0.184081  |    0.293908     |   1\n",
      "      31807 |   0.000013  |    0.037826     |   2\n",
      "      31808 |   0.000013  |    0.039773     |   2\n",
      "      31809 |   0.138855  |    0.073789     |   0\n",
      "      31810 |   0.203079  |    0.230227     |   1\n",
      "      31811 |   0.233142  |    0.226106     |   1\n",
      "      31812 |   0.152884  |    0.281035     |   1\n",
      "      31813 |   0.207383  |    0.012089     |   0\n",
      "      31814 |   0.164197  |    0.248876     |   1\n",
      "      31815 |   0.145674  |    0.089010     |   0\n",
      "      31816 |   0.179215  |    0.112902     |   0\n",
      "      31817 |   0.152344  |    0.285390     |   1\n",
      "      31818 |   0.000013  |    0.068734     |   2\n",
      "      31819 |   0.134513  |    0.063219     |   0\n",
      "      31820 |   0.000013  |    0.054867     |   2\n",
      "      31821 |   0.040546  |    0.066359     |   2\n",
      "      31822 |   0.164790  |    0.078105     |   0\n",
      "      31823 |   0.042146  |    0.088197     |   2\n",
      "      31824 |   0.182283  |    0.231855     |   1\n",
      "      31825 |   0.195147  |    0.290727     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 31826: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      31826 |   0.199822  |    0.020333     |   0\n",
      "      31827 |   0.176283  |    0.262983     |   1\n",
      "      31828 |   0.186428  |    0.082407     |   0\n",
      "      31829 |   0.166834  |    0.099050     |   0\n",
      "      31830 |   0.131877  |    0.182550     |   1\n",
      "      31831 |   0.202257  |    0.049890     |   0\n",
      "      31832 |   0.041557  |    0.122630     |   2\n",
      "      31833 |   0.163457  |    0.311427     |   1\n",
      "      31834 |   0.029532  |    0.052817     |   2\n",
      "      31835 |   0.033893  |    0.065834     |   2\n",
      "      31836 |   0.221923  |    0.235299     |   1\n",
      "      31837 |   0.031652  |    0.114105     |   2\n",
      "      31838 |   0.023055  |    0.104161     |   2\n",
      "      31839 |   0.032192  |    0.177462     |   2\n",
      "      31840 |   0.122880  |    0.626954     |   1\n",
      "      31841 |   0.044424  |    0.154869     |   2\n",
      "      31842 |   0.134548  |    0.534348     |   1\n",
      "      31843 |   0.045455  |    0.071289     |   2\n",
      "      31844 |   0.148833  |    0.279402     |   1\n",
      "      31845 |   0.179007  |    0.346969     |   1\n",
      "      31846 |   0.036344  |    0.071668     |   2\n",
      "      31847 |   0.155513  |    0.036508     |   0\n",
      "      31848 |   0.202738  |    0.141881     |   0\n",
      "      31849 |   0.014425  |    0.071284     |   2\n",
      "      31850 |   0.154774  |    0.081755     |   0\n",
      "      31851 |   0.185188  |    0.374046     |   1\n",
      "      31852 |   0.153607  |    0.284749     |   1\n",
      "      31853 |   0.000013  |    0.071182     |   2\n",
      "      31854 |   0.143710  |    0.327482     |   1\n",
      "      31855 |   0.165784  |    0.284476     |   1\n",
      "      31856 |   0.238192  |    0.280541     |   1\n",
      "      31857 |   0.185568  |    0.070921     |   0\n",
      "      31858 |   0.181556  |    0.076955     |   0\n",
      "      31859 |   0.192266  |    0.352486     |   1\n",
      "      31860 |   0.155625  |    0.072616     |   0\n",
      "      31861 |   0.003914  |    0.133424     |   2\n",
      "      31862 |   0.051377  |    0.037831     |   2\n",
      "      31863 |   0.192751  |    0.149046     |   0\n",
      "      31864 |   0.161604  |    0.068834     |   0\n",
      "      31865 |   0.170638  |    0.064033     |   0\n",
      "      31866 |   0.157972  |    0.126983     |   0\n",
      "      31867 |   0.029213  |    0.009898     |   2\n",
      "      31868 |   0.153363  |    0.423215     |   1\n",
      "      31869 |   0.048016  |    0.100910     |   2\n",
      "      31870 |   0.168784  |    0.307809     |   1\n",
      "      31871 |   0.211319  |    0.102882     |   0\n",
      "      31872 |   0.038569  |    0.109819     |   2\n",
      "      31873 |   0.149308  |    0.404177     |   1\n",
      "      31874 |   0.191182  |    0.293814     |   1\n",
      "      31875 |   0.197714  |    0.403503     |   1\n",
      "      31876 |   0.158402  |    0.458897     |   1\n",
      "      31877 |   0.156954  |    0.397073     |   1\n",
      "      31878 |   0.170082  |    0.013340     |   0\n",
      "      31879 |   0.161810  |    0.192555     |   0\n",
      "      31880 |   0.146769  |    0.294643     |   1\n",
      "      31881 |   0.012948  |    0.078171     |   2\n",
      "      31882 |   0.165028  |    0.362150     |   1\n",
      "      31883 |   0.142322  |    0.257181     |   1\n",
      "      31884 |   0.187608  |    0.037297     |   0\n",
      "      31885 |   0.172145  |    0.085336     |   0\n",
      "      31886 |   0.186871  |    0.079130     |   0\n",
      "      31887 |   0.029786  |    0.092643     |   2\n",
      "      31888 |   0.233099  |    0.033944     |   0\n",
      "      31889 |   0.172812  |    0.249548     |   1\n",
      "      31890 |   0.206057  |    0.130459     |   0\n",
      "      31891 |   0.160541  |    0.206518     |   1\n",
      "      31892 |   0.149313  |    0.223359     |   1\n",
      "      31893 |   0.171498  |    0.122938     |   0\n",
      "      31894 |   0.024025  |    0.050867     |   2\n",
      "      31895 |   0.173794  |    0.284105     |   1\n",
      "      31896 |   0.000013  |    0.007446     |   2\n",
      "      31897 |   0.000013  |    0.127222     |   2\n",
      "      31898 |   0.000013  |    0.041746     |   2\n",
      "      31899 |   0.000013  |    0.080500     |   2\n",
      "      31900 |   0.000013  |    0.018300     |   2\n",
      "      31901 |   0.175412  |    0.082837     |   0\n",
      "      31902 |   0.201146  |    0.280794     |   1\n",
      "      31903 |   0.000013  |    0.003835     |   2\n",
      "      31904 |   0.172059  |    0.131234     |   0\n",
      "      31905 |   0.193856  |    0.193825     |   1\n",
      "      31906 |   0.199771  |    0.024667     |   0\n",
      "      31907 |   0.154766  |    0.151593     |   0\n",
      "      31908 |   0.039413  |    0.006035     |   2\n",
      "      31909 |   0.042519  |    0.087435     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 31910: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      31910 |   0.166001  |    0.056226     |   0\n",
      "      31911 |   0.223878  |    0.267116     |   1\n",
      "      31912 |   0.142535  |    0.011256     |   0\n",
      "      31913 |   0.143870  |    0.093025     |   0\n",
      "      31914 |   0.108068  |    0.255272     |   1\n",
      "      31915 |   0.178956  |    0.210640     |   1\n",
      "      31916 |   0.044396  |    0.048645     |   2\n",
      "      31917 |   0.182382  |    0.277250     |   1\n",
      "      31918 |   0.030080  |    0.096583     |   2\n",
      "      31919 |   0.035117  |    0.069386     |   2\n",
      "      31920 |   0.150796  |    0.042337     |   0\n",
      "      31921 |   0.198091  |    0.062401     |   0\n",
      "      31922 |   0.032412  |    0.121983     |   2\n",
      "      31923 |   0.199371  |    0.048403     |   0\n",
      "      31924 |   0.158762  |    0.294337     |   1\n",
      "      31925 |   0.210213  |    0.016212     |   0\n",
      "      31926 |   0.023134  |    0.100504     |   2\n",
      "      31927 |   0.031939  |    0.023114     |   2\n",
      "      31928 |   0.042934  |    0.130291     |   2\n",
      "      31929 |   0.044156  |    0.016514     |   2\n",
      "      31930 |   0.037949  |    0.096064     |   2\n",
      "      31931 |   0.016585  |    0.032216     |   2\n",
      "      31932 |   0.170595  |    0.103025     |   0\n",
      "      31933 |   0.212201  |    0.106002     |   0\n",
      "      31934 |   0.191737  |    0.260219     |   1\n",
      "      31935 |   0.000013  |    0.006624     |   2\n",
      "      31936 |   0.140101  |    0.296012     |   1\n",
      "      31937 |   0.160442  |    0.067165     |   0\n",
      "      31938 |   0.004056  |    0.090124     |   2\n",
      "      31939 |   0.226454  |    0.074298     |   0\n",
      "      31940 |   0.229997  |    0.237641     |   1\n",
      "      31941 |   0.221231  |    0.059818     |   0\n",
      "      31942 |   0.198029  |    0.220580     |   1\n",
      "      31943 |   0.136985  |    0.027206     |   0\n",
      "      31944 |   0.052747  |    0.116888     |   2\n",
      "      31945 |   0.166754  |    0.070313     |   0\n",
      "      31946 |   0.186304  |    0.203441     |   1\n",
      "      31947 |   0.165098  |    0.137885     |   0\n",
      "      31948 |   0.160116  |    0.225067     |   1\n",
      "      31949 |   0.224573  |    0.266450     |   1\n",
      "      31950 |   0.154655  |    0.171347     |   1\n",
      "      31951 |   0.030787  |    0.099648     |   2\n",
      "      31952 |   0.051392  |    0.026042     |   2\n",
      "      31953 |   0.205273  |    0.094447     |   0\n",
      "      31954 |   0.132585  |    0.059771     |   0\n",
      "      31955 |   0.239160  |    0.263659     |   1\n",
      "      31956 |   0.222262  |    0.230018     |   1\n",
      "      31957 |   0.235752  |    0.207025     |   1\n",
      "      31958 |   0.185123  |    0.309934     |   1\n",
      "      31959 |   0.106244  |    0.007452     |   0\n",
      "      31960 |   0.169664  |    0.242847     |   1\n",
      "      31961 |   0.216672  |    0.196227     |   1\n",
      "      31962 |   0.143781  |    0.251407     |   1\n",
      "      31963 |   0.167937  |    0.033746     |   0\n",
      "      31964 |   0.208120  |    0.236738     |   1\n",
      "      31965 |   0.034220  |    0.017899     |   2\n",
      "      31966 |   0.221587  |    0.294128     |   1\n",
      "      31967 |   0.164791  |    0.031679     |   0\n",
      "      31968 |   0.140401  |    0.071417     |   0\n",
      "      31969 |   0.123863  |    0.005324     |   0\n",
      "      31970 |   0.168660  |    0.093137     |   0\n",
      "      31971 |   0.013716  |    0.048307     |   2\n",
      "      31972 |   0.235229  |    0.271193     |   1\n",
      "      31973 |   0.231599  |    0.025182     |   0\n",
      "      31974 |   0.028232  |    0.097483     |   2\n",
      "      31975 |   0.171015  |    0.236531     |   1\n",
      "      31976 |   0.022981  |    0.059695     |   2\n",
      "      31977 |   0.000013  |    0.044400     |   2\n",
      "      31978 |   0.148605  |    0.195193     |   1\n",
      "      31979 |   0.147164  |    0.056308     |   0\n",
      "      31980 |   0.206079  |    0.308081     |   1\n",
      "      31981 |   0.148679  |    0.214800     |   1\n",
      "      31982 |   0.203942  |    0.147507     |   1\n",
      "      31983 |   0.153283  |    0.261457     |   1\n",
      "      31984 |   0.176513  |    0.067307     |   0\n",
      "      31985 |   0.000013  |    0.051295     |   2\n",
      "      31986 |   0.000013  |    0.109247     |   2\n",
      "      31987 |   0.162127  |    0.044089     |   0\n",
      "      31988 |   0.169855  |    0.214757     |   1\n",
      "      31989 |   0.164220  |    0.055274     |   0\n",
      "      31990 |   0.165249  |    0.101227     |   0\n",
      "      31991 |   0.184943  |    0.040622     |   0\n",
      "      31992 |   0.000013  |    0.070758     |   2\n",
      "      31993 | \u001b[94m  0.000013\u001b[0m  |    0.068007     |   2\n",
      "      31994 | \u001b[94m  0.000013\u001b[0m  |    0.093497     |   2\n",
      "      31995 |   0.175194  |    0.231975     |   1\n",
      "      31996 |   0.037378  |    0.160990     |   2\n",
      "      31997 |   0.042514  |    0.082070     |   2\n",
      "      31998 |   0.170615  |    0.343353     |   1\n",
      "      31999 |   0.149051  |    0.257037     |   1\n",
      "      32000 |   0.138679  |    0.289480     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 32000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 32000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      32001 |   0.038450  |    0.074292     |   2\n",
      "      32002 |   0.142719  |    0.067822     |   0\n",
      "      32003 |   0.027624  |    0.062591     |   2\n",
      "      32004 |   0.033868  |    0.063791     |   2\n",
      "      32005 |   0.181692  |    0.237143     |   1\n",
      "      32006 |   0.172628  |    0.211840     |   1\n",
      "      32007 |   0.129584  |    0.020282     |   0\n",
      "      32008 |   0.146155  |    0.293230     |   1\n",
      "      32009 |   0.183105  |    0.102560     |   0\n",
      "      32010 |   0.197477  |    0.259510     |   1\n",
      "      32011 |   0.228155  |    0.174086     |   1\n",
      "      32012 |   0.031771  |    0.006024     |   2\n",
      "      32013 |   0.159194  |    0.227633     |   1\n",
      "      32014 |   0.023187  |    0.069754     |   2\n",
      "      32015 |   0.031312  |    0.050790     |   2\n",
      "      32016 |   0.168685  |    0.258365     |   1\n",
      "      32017 |   0.127231  |    0.287594     |   1\n",
      "      32018 |   0.128612  |    0.009061     |   0\n",
      "      32019 |   0.044700  |    0.091743     |   2\n",
      "      32020 |   0.136533  |    0.045422     |   0\n",
      "      32021 |   0.187550  |    0.246364     |   1\n",
      "      32022 |   0.135948  |    0.060263     |   0\n",
      "      32023 |   0.153896  |    0.083688     |   0\n",
      "      32024 |   0.251253  |    0.214326     |   1\n",
      "      32025 |   0.045513  |    0.014680     |   2\n",
      "      32026 |   0.148822  |    0.094206     |   0\n",
      "      32027 |   0.241397  |    0.216917     |   1\n",
      "      32028 |   0.189855  |    0.044718     |   0\n",
      "      32029 |   0.159905  |    0.224100     |   1\n",
      "      32030 |   0.035897  |    0.010048     |   2\n",
      "      32031 |   0.017584  |    0.127020     |   2\n",
      "      32032 |   0.176077  |    0.217945     |   1\n",
      "      32033 |   0.178000  |    0.084601     |   0\n",
      "      32034 | \u001b[94m  0.000013\u001b[0m  |    0.052769     |   2\n",
      "      32035 |   0.181780  |    0.275008     |   1\n",
      "      32036 |   0.133925  |    0.013366     |   0\n",
      "      32037 |   0.146385  |    0.078539     |   0\n",
      "      32038 |   0.172560  |    0.046008     |   0\n",
      "      32039 |   0.004317  |    0.070519     |   2\n",
      "      32040 |   0.051359  |    0.077041     |   2\n",
      "      32041 |   0.152057  |    0.026617     |   0\n",
      "      32042 |   0.179790  |    0.242668     |   1\n",
      "      32043 |   0.027638  |    0.051563     |   2\n",
      "      32044 |   0.049433  |    0.073865     |   2\n",
      "      32045 |   0.038077  |    0.038713     |   2\n",
      "      32046 |   0.015510  |    0.083238     |   2\n",
      "      32047 |   0.028708  |    0.028978     |   2\n",
      "      32048 |   0.179514  |    0.113553     |   0\n",
      "      32049 |   0.173452  |    0.021117     |   0\n",
      "      32050 |   0.152812  |    0.274952     |   1\n",
      "      32051 |   0.190419  |    0.032889     |   0\n",
      "      32052 |   0.153765  |    0.077769     |   0\n",
      "      32053 |   0.022442  |    0.039975     |   2\n",
      "      32054 |   0.178678  |    0.109428     |   0\n",
      "      32055 | \u001b[94m  0.000012\u001b[0m  |    0.016154     |   2\n",
      "      32056 |   0.199736  |    0.064735     |   0\n",
      "      32057 | \u001b[94m  0.000012\u001b[0m  |    0.077868     |   2\n",
      "      32058 |   0.154771  |    0.120032     |   0\n",
      "      32059 |   0.000012  |    0.042149     |   2\n",
      "      32060 |   0.188616  |    0.099867     |   0\n",
      "      32061 |   0.000012  |    0.056237     |   2\n",
      "      32062 |   0.154626  |    0.086171     |   0\n",
      "      32063 |   0.191976  |    0.054577     |   0\n",
      "      32064 | \u001b[94m  0.000012\u001b[0m  |    0.071410     |   2\n",
      "      32065 |   0.185638  |    0.137825     |   0\n",
      "      32066 |   0.107655  |    0.207216     |   1\n",
      "      32067 |   0.172581  |    0.012075     |   0\n",
      "      32068 |   0.137474  |    0.305545     |   1\n",
      "      32069 |   0.165536  |    0.303799     |   1\n",
      "      32070 |   0.149715  |    0.437023     |   1\n",
      "      32071 |   0.174242  |    0.318720     |   1\n",
      "      32072 |   0.176040  |    0.129541     |   0\n",
      "      32073 |   0.000012  |    0.147792     |   2\n",
      "      32074 |   0.178193  |    0.314118     |   1\n",
      "      32075 |   0.160102  |    0.046637     |   0\n",
      "      32076 |   0.199641  |    0.081223     |   0\n",
      "      32077 |   0.208894  |    0.241148     |   1\n",
      "      32078 |   0.186966  |    0.039691     |   0\n",
      "      32079 |   0.162155  |    0.211437     |   1\n",
      "      32080 |   0.174098  |    0.239185     |   1\n",
      "      32081 |   0.039214  |    0.006330     |   2\n",
      "      32082 |   0.172381  |    0.065052     |   0\n",
      "      32083 |   0.178161  |    0.218489     |   1\n",
      "      32084 |   0.042204  |    0.044707     |   2\n",
      "      32085 |   0.173115  |    0.097312     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 32086: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      32086 |   0.041344  |    0.019982     |   2\n",
      "      32087 |   0.028448  |    0.060732     |   2\n",
      "      32088 |   0.180165  |    0.087526     |   0\n",
      "      32089 |   0.178329  |    0.069813     |   0\n",
      "      32090 |   0.169287  |    0.104348     |   0\n",
      "      32091 |   0.174724  |    0.217869     |   1\n",
      "      32092 |   0.205274  |    0.241806     |   1\n",
      "      32093 |   0.151249  |    0.058502     |   0\n",
      "      32094 |   0.204529  |    0.083099     |   0\n",
      "      32095 |   0.033531  |    0.047539     |   2\n",
      "      32096 |   0.156883  |    0.166153     |   0\n",
      "      32097 |   0.170474  |    0.027978     |   0\n",
      "      32098 |   0.031516  |    0.085782     |   2\n",
      "      32099 |   0.023713  |    0.141731     |   2\n",
      "      32100 |   0.031661  |    0.148724     |   2\n",
      "      32101 |   0.157764  |    0.442462     |   1\n",
      "      32102 |   0.046804  |    0.098358     |   2\n",
      "      32103 |   0.166600  |    0.078208     |   0\n",
      "      32104 |   0.194078  |    0.377307     |   1\n",
      "      32105 |   0.147376  |    0.093983     |   0\n",
      "      32106 |   0.172618  |    0.286020     |   1\n",
      "      32107 |   0.155443  |    0.130201     |   0\n",
      "      32108 |   0.191728  |    0.323886     |   1\n",
      "      32109 |   0.045300  |    0.091178     |   2\n",
      "      32110 |   0.035401  |    0.068313     |   2\n",
      "      32111 |   0.016978  |    0.162130     |   2\n",
      "      32112 |   0.000013  |    0.004760     |   2\n",
      "      32113 |   0.004764  |    0.151994     |   2\n",
      "      32114 |   0.198106  |    0.391679     |   1\n",
      "      32115 |   0.156659  |    0.284713     |   1\n",
      "      32116 |   0.181026  |    0.267929     |   1\n",
      "      32117 |   0.152497  |    0.067851     |   0\n",
      "      32118 |   0.152610  |    0.045603     |   0\n",
      "      32119 |   0.125118  |    0.042319     |   0\n",
      "      32120 |   0.157691  |    0.119994     |   0\n",
      "      32121 |   0.167624  |    0.043975     |   0\n",
      "      32122 |   0.160069  |    0.280944     |   1\n",
      "      32123 |   0.056755  |    0.055098     |   2\n",
      "      32124 |   0.119197  |    0.096062     |   0\n",
      "      32125 |   0.170205  |    0.257049     |   1\n",
      "      32126 |   0.174369  |    0.220825     |   1\n",
      "      32127 |   0.031237  |    0.067820     |   2\n",
      "      32128 |   0.048988  |    0.097906     |   2\n",
      "      32129 |   0.036168  |    0.064005     |   2\n",
      "      32130 |   0.114051  |    0.273916     |   1\n",
      "      32131 |   0.013111  |    0.069504     |   2\n",
      "      32132 |   0.030397  |    0.055821     |   2\n",
      "      32133 |   0.023212  |    0.070817     |   2\n",
      "      32134 |   0.170483  |    0.104016     |   0\n",
      "      32135 |   0.135470  |    0.008669     |   0\n",
      "      32136 |   0.000013  |    0.083475     |   2\n",
      "      32137 |   0.225803  |    0.236003     |   1\n",
      "      32138 |   0.000013  |    0.003281     |   2\n",
      "      32139 |   0.000013  |    0.086954     |   2\n",
      "      32140 |   0.152536  |    0.190216     |   1\n",
      "      32141 |   0.156575  |    0.234377     |   1\n",
      "      32142 |   0.199256  |    0.025835     |   0\n",
      "      32143 |   0.146957  |    0.238326     |   1\n",
      "      32144 |   0.000013  |    0.062810     |   2\n",
      "      32145 |   0.153090  |    0.065745     |   0\n",
      "      32146 |   0.189550  |    0.100907     |   0\n",
      "      32147 |   0.000013  |    0.081023     |   2\n",
      "      32148 |   0.152077  |    0.235236     |   1\n",
      "      32149 |   0.166119  |    0.063999     |   0\n",
      "      32150 |   0.000013  |    0.126278     |   2\n",
      "      32151 |   0.036620  |    0.022605     |   2\n",
      "      32152 |   0.041387  |    0.086525     |   2\n",
      "      32153 |   0.230671  |    0.209090     |   1\n",
      "      32154 |   0.214135  |    0.093433     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 32155: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      32155 |   0.037516  |    0.071514     |   2\n",
      "      32156 |   0.134849  |    0.273970     |   1\n",
      "      32157 |   0.026653  |    0.024077     |   2\n",
      "      32158 |   0.189144  |    0.318347     |   1\n",
      "      32159 |   0.032963  |    0.065842     |   2\n",
      "      32160 |   0.210093  |    0.320150     |   1\n",
      "      32161 |   0.031317  |    0.007996     |   2\n",
      "      32162 |   0.164994  |    0.357378     |   1\n",
      "      32163 |   0.134794  |    0.202587     |   1\n",
      "      32164 |   0.163058  |    0.056347     |   0\n",
      "      32165 |   0.160976  |    0.280879     |   1\n",
      "      32166 |   0.171905  |    0.154915     |   1\n",
      "      32167 |   0.152129  |    0.032455     |   0\n",
      "      32168 |   0.135615  |    0.099735     |   0\n",
      "      32169 |   0.193526  |    0.051300     |   0\n",
      "      32170 |   0.203545  |    0.042781     |   0\n",
      "      32171 |   0.153468  |    0.213437     |   1\n",
      "      32172 |   0.174975  |    0.029024     |   0\n",
      "      32173 |   0.022806  |    0.116485     |   2\n",
      "      32174 |   0.031006  |    0.058801     |   2\n",
      "      32175 |   0.130493  |    0.042600     |   0\n",
      "      32176 |   0.142257  |    0.326928     |   1\n",
      "      32177 |   0.046532  |    0.036422     |   2\n",
      "      32178 |   0.198270  |    0.157572     |   0\n",
      "      32179 |   0.208088  |    0.187219     |   1\n",
      "      32180 |   0.182578  |    0.208587     |   1\n",
      "      32181 |   0.046684  |    0.058514     |   2\n",
      "      32182 |   0.188411  |    0.116010     |   0\n",
      "      32183 |   0.198943  |    0.355592     |   1\n",
      "      32184 |   0.036435  |    0.076715     |   2\n",
      "      32185 |   0.190692  |    0.229028     |   1\n",
      "      32186 |   0.144315  |    0.057916     |   0\n",
      "      32187 |   0.017751  |    0.064443     |   2\n",
      "      32188 |   0.000013  |    0.120656     |   2\n",
      "      32189 |   0.004260  |    0.076552     |   2\n",
      "      32190 |   0.152541  |    0.092070     |   0\n",
      "      32191 |   0.143425  |    0.256566     |   1\n",
      "      32192 |   0.054665  |    0.003198     |   2\n",
      "      32193 |   0.029991  |    0.127326     |   2\n",
      "      32194 |   0.048894  |    0.072142     |   2\n",
      "      32195 |   0.143362  |    0.129944     |   0\n",
      "      32196 |   0.035758  |    0.009416     |   2\n",
      "      32197 |   0.167532  |    0.271768     |   1\n",
      "      32198 |   0.131534  |    0.019757     |   0\n",
      "      32199 |   0.208376  |    0.273335     |   1\n",
      "      32200 |   0.193305  |    0.042241     |   0\n",
      "      32201 |   0.190805  |    0.130103     |   0\n",
      "      32202 |   0.162689  |    0.147376     |   1\n",
      "      32203 |   0.180032  |    0.289873     |   1\n",
      "      32204 |   0.159776  |    0.164992     |   1\n",
      "      32205 |   0.015200  |    0.010979     |   2\n",
      "      32206 |   0.151979  |    0.067829     |   0\n",
      "      32207 |   0.135307  |    0.067857     |   0\n",
      "      32208 |   0.221016  |    0.355996     |   1\n",
      "      32209 |   0.031908  |    0.066418     |   2\n",
      "      32210 |   0.172546  |    0.223592     |   1\n",
      "      32211 |   0.226410  |    0.223868     |   1\n",
      "      32212 |   0.195212  |    0.053870     |   0\n",
      "      32213 |   0.143180  |    0.412161     |   1\n",
      "      32214 |   0.021572  |    0.074041     |   2\n",
      "      32215 |   0.000013  |    0.163747     |   2\n",
      "      32216 |   0.000013  |    0.004411     |   2\n",
      "      32217 |   0.000013  |    0.120172     |   2\n",
      "      32218 |   0.129326  |    0.147360     |   0\n",
      "      32219 |   0.000013  |    0.102939     |   2\n",
      "      32220 |   0.000013  |    0.077874     |   2\n",
      "      32221 |   0.000013  |    0.155908     |   2\n",
      "      32222 |   0.035722  |    0.045402     |   2\n",
      "      32223 |   0.148431  |    0.292111     |   1\n",
      "      32224 |   0.161359  |    0.229682     |   1\n",
      "      32225 |   0.175330  |    0.288627     |   1\n",
      "      32226 |   0.207815  |    0.200749     |   1\n",
      "      32227 |   0.174795  |    0.115240     |   0\n",
      "      32228 |   0.153857  |    0.009313     |   0\n",
      "      32229 |   0.137129  |    0.088346     |   0\n",
      "      32230 |   0.173692  |    0.223076     |   1\n",
      "      32231 |   0.041409  |    0.058091     |   2\n",
      "      32232 |   0.212114  |    0.058282     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 32233: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      32233 |   0.195557  |    0.055252     |   0\n",
      "      32234 |   0.039239  |    0.080407     |   2\n",
      "      32235 |   0.028485  |    0.077969     |   2\n",
      "      32236 |   0.177141  |    0.236257     |   1\n",
      "      32237 |   0.033178  |    0.049484     |   2\n",
      "      32238 |   0.179170  |    0.074465     |   0\n",
      "      32239 |   0.219457  |    0.231270     |   1\n",
      "      32240 |   0.032455  |    0.050059     |   2\n",
      "      32241 |   0.161043  |    0.087556     |   0\n",
      "      32242 |   0.173422  |    0.237533     |   1\n",
      "      32243 |   0.184141  |    0.208008     |   1\n",
      "      32244 |   0.216829  |    0.191196     |   1\n",
      "      32245 |   0.208874  |    0.230655     |   1\n",
      "      32246 |   0.149298  |    0.031270     |   0\n",
      "      32247 |   0.023467  |    0.077100     |   2\n",
      "      32248 |   0.222106  |    0.245453     |   1\n",
      "      32249 |   0.031978  |    0.021969     |   2\n",
      "      32250 |   0.164456  |    0.090685     |   0\n",
      "      32251 |   0.198591  |    0.196131     |   1\n",
      "      32252 |   0.156890  |    0.104918     |   0\n",
      "      32253 |   0.140375  |    0.167854     |   1\n",
      "      32254 |   0.045732  |    0.118791     |   2\n",
      "      32255 |   0.047644  |    0.052769     |   2\n",
      "      32256 |   0.173135  |    0.267671     |   1\n",
      "      32257 |   0.035123  |    0.003413     |   2\n",
      "      32258 |   0.173855  |    0.067528     |   0\n",
      "      32259 |   0.162880  |    0.169101     |   0\n",
      "      32260 |   0.206739  |    0.227447     |   1\n",
      "      32261 |   0.184426  |    0.203780     |   1\n",
      "      32262 |   0.016817  |    0.048097     |   2\n",
      "      32263 |   0.000013  |    0.036451     |   2\n",
      "      32264 |   0.157752  |    0.230019     |   1\n",
      "      32265 |   0.004363  |    0.021731     |   2\n",
      "      32266 |   0.119360  |    0.075729     |   0\n",
      "      32267 |   0.053556  |    0.026502     |   2\n",
      "      32268 |   0.166386  |    0.270186     |   1\n",
      "      32269 |   0.144853  |    0.213189     |   1\n",
      "      32270 |   0.028640  |    0.015354     |   2\n",
      "      32271 |   0.048286  |    0.106904     |   2\n",
      "      32272 |   0.222774  |    0.038440     |   0\n",
      "      32273 |   0.036463  |    0.124502     |   2\n",
      "      32274 |   0.184175  |    0.057241     |   0\n",
      "      32275 |   0.166406  |    0.227999     |   1\n",
      "      32276 |   0.191253  |    0.055619     |   0\n",
      "      32277 |   0.161052  |    0.088200     |   0\n",
      "      32278 |   0.154363  |    0.046209     |   0\n",
      "      32279 |   0.171745  |    0.084951     |   0\n",
      "      32280 |   0.173434  |    0.270399     |   1\n",
      "      32281 |   0.013715  |    0.015010     |   2\n",
      "      32282 |   0.154977  |    0.293028     |   1\n",
      "      32283 |   0.157572  |    0.234459     |   1\n",
      "      32284 |   0.192754  |    0.083564     |   0\n",
      "      32285 |   0.031313  |    0.019437     |   2\n",
      "      32286 |   0.149631  |    0.159848     |   0\n",
      "      32287 |   0.021807  |    0.007556     |   2\n",
      "      32288 |   0.163213  |    0.143124     |   0\n",
      "      32289 |   0.164460  |    0.202359     |   1\n",
      "      32290 |   0.131691  |    0.284322     |   1\n",
      "      32291 |   0.000013  |    0.010053     |   2\n",
      "      32292 |   0.000013  |    0.083392     |   2\n",
      "      32293 |   0.000013  |    0.072055     |   2\n",
      "      32294 |   0.000013  |    0.088281     |   2\n",
      "      32295 |   0.131025  |    0.238065     |   1\n",
      "      32296 |   0.196263  |    0.190259     |   1\n",
      "      32297 |   0.000013  |    0.045210     |   2\n",
      "      32298 |   0.176446  |    0.077603     |   0\n",
      "      32299 |   0.186622  |    0.097139     |   0\n",
      "      32300 |   0.000013  |    0.038913     |   2\n",
      "      32301 |   0.183632  |    0.243273     |   1\n",
      "      32302 |   0.035594  |    0.010110     |   2\n",
      "      32303 |   0.123046  |    0.270080     |   1\n",
      "      32304 |   0.189752  |    0.067374     |   0\n",
      "      32305 |   0.144477  |    0.077865     |   0\n",
      "      32306 |   0.123772  |    0.106203     |   0\n",
      "      32307 |   0.157470  |    0.190311     |   1\n",
      "      32308 |   0.155954  |    0.213713     |   1\n",
      "      32309 |   0.194486  |    0.224758     |   1\n",
      "      32310 |   0.041902  |    0.077247     |   2\n",
      "      32311 |   0.184967  |    0.173660     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 32312: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      32312 |   0.038159  |    0.119001     |   2\n",
      "      32313 |   0.026317  |    0.099072     |   2\n",
      "      32314 |   0.174249  |    0.037086     |   0\n",
      "      32315 |   0.032522  |    0.146524     |   2\n",
      "      32316 |   0.148548  |    0.154033     |   1\n",
      "      32317 |   0.164515  |    0.278528     |   1\n",
      "      32318 |   0.179050  |    0.204244     |   1\n",
      "      32319 |   0.173353  |    0.315624     |   1\n",
      "      32320 |   0.033201  |    0.023377     |   2\n",
      "      32321 |   0.145301  |    0.117050     |   0\n",
      "      32322 |   0.179991  |    0.034132     |   0\n",
      "      32323 |   0.189658  |    0.085012     |   0\n",
      "      32324 |   0.215821  |    0.019896     |   0\n",
      "      32325 |   0.194471  |    0.273977     |   1\n",
      "      32326 |   0.141307  |    0.298826     |   1\n",
      "      32327 |   0.140911  |    0.196105     |   1\n",
      "      32328 |   0.022518  |    0.105734     |   2\n",
      "      32329 |   0.167244  |    0.220883     |   1\n",
      "      32330 |   0.030263  |    0.045589     |   2\n",
      "      32331 |   0.214246  |    0.044918     |   0\n",
      "      32332 |   0.156051  |    0.351856     |   1\n",
      "      32333 |   0.167872  |    0.204822     |   1\n",
      "      32334 |   0.190801  |    0.179871     |   1\n",
      "      32335 |   0.147232  |    0.063881     |   0\n",
      "      32336 |   0.147199  |    0.224793     |   1\n",
      "      32337 |   0.050444  |    0.046420     |   2\n",
      "      32338 |   0.047069  |    0.079240     |   2\n",
      "      32339 |   0.128066  |    0.314286     |   1\n",
      "      32340 |   0.193387  |    0.132316     |   0\n",
      "      32341 |   0.214889  |    0.260456     |   1\n",
      "      32342 |   0.128157  |    0.189672     |   1\n",
      "      32343 |   0.036268  |    0.106600     |   2\n",
      "      32344 |   0.141916  |    0.275617     |   1\n",
      "      32345 |   0.016745  |    0.009844     |   2\n",
      "      32346 |   0.158254  |    0.130386     |   0\n",
      "      32347 |   0.154847  |    0.023956     |   0\n",
      "      32348 |   0.146715  |    0.244255     |   1\n",
      "      32349 |   0.000013  |    0.043484     |   2\n",
      "      32350 |   0.004960  |    0.096540     |   2\n",
      "      32351 |   0.056402  |    0.059191     |   2\n",
      "      32352 |   0.158197  |    0.323359     |   1\n",
      "      32353 |   0.183915  |    0.215042     |   1\n",
      "      32354 |   0.160432  |    0.081236     |   0\n",
      "      32355 |   0.031599  |    0.076197     |   2\n",
      "      32356 |   0.046192  |    0.025786     |   2\n",
      "      32357 |   0.037346  |    0.116321     |   2\n",
      "      32358 |   0.158171  |    0.076938     |   0\n",
      "      32359 |   0.206524  |    0.204764     |   1\n",
      "      32360 |   0.013402  |    0.122230     |   2\n",
      "      32361 |   0.179340  |    0.049253     |   0\n",
      "      32362 |   0.170129  |    0.039794     |   0\n",
      "      32363 |   0.031979  |    0.077776     |   2\n",
      "      32364 |   0.174455  |    0.076831     |   0\n",
      "      32365 |   0.020699  |    0.070917     |   2\n",
      "      32366 |   0.111346  |    0.237944     |   1\n",
      "      32367 |   0.147780  |    0.118226     |   0\n",
      "      32368 |   0.000013  |    0.069723     |   2\n",
      "      32369 |   0.000013  |    0.077362     |   2\n",
      "      32370 |   0.147444  |    0.021796     |   0\n",
      "      32371 |   0.000013  |    0.091107     |   2\n",
      "      32372 |   0.173155  |    0.045230     |   0\n",
      "      32373 |   0.152310  |    0.225112     |   1\n",
      "      32374 |   0.154800  |    0.105242     |   0\n",
      "      32375 |   0.000013  |    0.074135     |   2\n",
      "      32376 |   0.184358  |    0.249879     |   1\n",
      "      32377 |   0.000013  |    0.048273     |   2\n",
      "      32378 |   0.000013  |    0.089480     |   2\n",
      "      32379 |   0.187877  |    0.276539     |   1\n",
      "      32380 |   0.036972  |    0.005960     |   2\n",
      "      32381 |   0.142672  |    0.106836     |   0\n",
      "      32382 |   0.160457  |    0.251748     |   1\n",
      "      32383 |   0.161353  |    0.015344     |   0\n",
      "      32384 |   0.146141  |    0.119626     |   0\n",
      "      32385 |   0.041641  |    0.076907     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 32386: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      32386 |   0.038407  |    0.134328     |   2\n",
      "      32387 |   0.219437  |    0.058412     |   0\n",
      "      32388 |   0.239194  |    0.048585     |   0\n",
      "      32389 |   0.208470  |    0.081140     |   0\n",
      "      32390 |   0.164869  |    0.059087     |   0\n",
      "      32391 |   0.026727  |    0.066352     |   2\n",
      "      32392 |   0.168155  |    0.085969     |   0\n",
      "      32393 |   0.172860  |    0.038747     |   0\n",
      "      32394 |   0.173269  |    0.092765     |   0\n",
      "      32395 |   0.032675  |    0.026447     |   2\n",
      "      32396 |   0.230781  |    0.093918     |   0\n",
      "      32397 |   0.180057  |    0.106143     |   0\n",
      "      32398 |   0.174558  |    0.276711     |   1\n",
      "      32399 |   0.158894  |    0.029435     |   0\n",
      "      32400 |   0.147197  |    0.059258     |   0\n",
      "      32401 |   0.190175  |    0.066949     |   0\n",
      "      32402 |   0.032601  |    0.117596     |   2\n",
      "      32403 |   0.022896  |    0.007597     |   2\n",
      "      32404 |   0.032136  |    0.080480     |   2\n",
      "      32405 |   0.049365  |    0.072034     |   2\n",
      "      32406 |   0.204184  |    0.238975     |   1\n",
      "      32407 |   0.182433  |    0.236229     |   1\n",
      "      32408 |   0.046417  |    0.009630     |   2\n",
      "      32409 |   0.036599  |    0.081667     |   2\n",
      "      32410 |   0.228107  |    0.145844     |   1\n",
      "      32411 |   0.016130  |    0.070247     |   2\n",
      "      32412 |   0.174817  |    0.088679     |   0\n",
      "      32413 |   0.163945  |    0.122620     |   0\n",
      "      32414 |   0.154681  |    0.062008     |   0\n",
      "      32415 |   0.000013  |    0.042568     |   2\n",
      "      32416 |   0.180316  |    0.309864     |   1\n",
      "      32417 |   0.183388  |    0.267956     |   1\n",
      "      32418 |   0.004054  |    0.014758     |   2\n",
      "      32419 |   0.180239  |    0.167775     |   0\n",
      "      32420 |   0.147363  |    0.286268     |   1\n",
      "      32421 |   0.149087  |    0.018372     |   0\n",
      "      32422 |   0.160701  |    0.165813     |   0\n",
      "      32423 |   0.245052  |    0.264425     |   1\n",
      "      32424 |   0.178391  |    0.204825     |   1\n",
      "      32425 |   0.157867  |    0.226048     |   1\n",
      "      32426 |   0.155705  |    0.076711     |   0\n",
      "      32427 |   0.187917  |    0.240066     |   1\n",
      "      32428 |   0.051913  |    0.048361     |   2\n",
      "      32429 |   0.171207  |    0.077375     |   0\n",
      "      32430 |   0.029679  |    0.101799     |   2\n",
      "      32431 |   0.162350  |    0.044846     |   0\n",
      "      32432 |   0.049425  |    0.125913     |   2\n",
      "      32433 |   0.035591  |    0.075879     |   2\n",
      "      32434 |   0.226510  |    0.250544     |   1\n",
      "      32435 |   0.163299  |    0.074787     |   0\n",
      "      32436 |   0.014405  |    0.063822     |   2\n",
      "      32437 |   0.031133  |    0.123976     |   2\n",
      "      32438 |   0.022584  |    0.085025     |   2\n",
      "      32439 |   0.000013  |    0.078653     |   2\n",
      "      32440 |   0.000013  |    0.074873     |   2\n",
      "      32441 |   0.000013  |    0.100547     |   2\n",
      "      32442 |   0.162376  |    0.221831     |   1\n",
      "      32443 |   0.198702  |    0.272835     |   1\n",
      "      32444 |   0.000013  |    0.002912     |   2\n",
      "      32445 |   0.182009  |    0.415938     |   1\n",
      "      32446 |   0.175925  |    0.227614     |   1\n",
      "      32447 |   0.000013  |    0.006890     |   2\n",
      "      32448 |   0.000013  |    0.072337     |   2\n",
      "      32449 |   0.160657  |    0.066895     |   0\n",
      "      32450 |   0.176392  |    0.273577     |   1\n",
      "      32451 |   0.035247  |    0.074022     |   2\n",
      "      32452 |   0.152303  |    0.092709     |   0\n",
      "      32453 |   0.040865  |    0.071399     |   2\n",
      "      32454 |   0.176049  |    0.223423     |   1\n",
      "      32455 |   0.187677  |    0.203241     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 32456: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      32456 |   0.157716  |    0.054176     |   0\n",
      "      32457 |   0.036418  |    0.067431     |   2\n",
      "      32458 |   0.025259  |    0.073915     |   2\n",
      "      32459 |   0.032799  |    0.045230     |   2\n",
      "      32460 |   0.156504  |    0.122103     |   0\n",
      "      32461 |   0.180593  |    0.212652     |   1\n",
      "      32462 |   0.102870  |    0.079045     |   0\n",
      "      32463 |   0.169189  |    0.222765     |   1\n",
      "      32464 |   0.032727  |    0.025576     |   2\n",
      "      32465 |   0.186379  |    0.094556     |   0\n",
      "      32466 |   0.173854  |    0.064653     |   0\n",
      "      32467 |   0.173046  |    0.134479     |   0\n",
      "      32468 |   0.151979  |    0.013360     |   0\n",
      "      32469 |   0.138546  |    0.067104     |   0\n",
      "      32470 |   0.022779  |    0.063942     |   2\n",
      "      32471 |   0.168727  |    0.075737     |   0\n",
      "      32472 |   0.187192  |    0.123636     |   0\n",
      "      32473 |   0.032491  |    0.022494     |   2\n",
      "      32474 |   0.154587  |    0.070881     |   0\n",
      "      32475 |   0.043670  |    0.074292     |   2\n",
      "      32476 |   0.157536  |    0.263176     |   1\n",
      "      32477 |   0.209459  |    0.200903     |   1\n",
      "      32478 |   0.153935  |    0.254381     |   1\n",
      "      32479 |   0.176146  |    0.059830     |   0\n",
      "      32480 |   0.045635  |    0.068645     |   2\n",
      "      32481 |   0.196203  |    0.266412     |   1\n",
      "      32482 |   0.138669  |    0.004811     |   0\n",
      "      32483 |   0.169361  |    0.194395     |   1\n",
      "      32484 |   0.154540  |    0.104044     |   0\n",
      "      32485 |   0.197579  |    0.158326     |   1\n",
      "      32486 |   0.035400  |    0.106729     |   2\n",
      "      32487 |   0.197877  |    0.071653     |   0\n",
      "      32488 |   0.201468  |    0.027328     |   0\n",
      "      32489 |   0.205298  |    0.287313     |   1\n",
      "      32490 |   0.017097  |    0.035537     |   2\n",
      "      32491 |   0.000013  |    0.130023     |   2\n",
      "      32492 |   0.004927  |    0.002900     |   2\n",
      "      32493 |   0.166894  |    0.086349     |   0\n",
      "      32494 |   0.049827  |    0.096502     |   2\n",
      "      32495 |   0.191866  |    0.018618     |   0\n",
      "      32496 |   0.029928  |    0.159185     |   2\n",
      "      32497 |   0.050177  |    0.006339     |   2\n",
      "      32498 |   0.037717  |    0.054774     |   2\n",
      "      32499 |   0.014769  |    0.095440     |   2\n",
      "      32500 |   0.030568  |    0.029061     |   2\n",
      "      32501 |   0.034672  |    0.157157     |   2\n",
      "      32502 |   0.178647  |    0.061406     |   0\n",
      "      32503 |   0.145505  |    0.151324     |   0\n",
      "      32504 |   0.212043  |    0.383057     |   1\n",
      "      32505 |   0.196710  |    0.329706     |   1\n",
      "      32506 |   0.202007  |    0.294806     |   1\n",
      "      32507 |   0.179482  |    0.401221     |   1\n",
      "      32508 |   0.226597  |    0.283512     |   1\n",
      "      32509 |   0.168371  |    0.406539     |   1\n",
      "      32510 |   0.023866  |    0.148085     |   2\n",
      "      32511 |   0.031144  |    0.076391     |   2\n",
      "      32512 |   0.210886  |    0.319374     |   1\n",
      "      32513 |   0.158764  |    0.121633     |   0\n",
      "      32514 |   0.122963  |    0.082295     |   0\n",
      "      32515 |   0.032053  |    0.122119     |   2\n",
      "      32516 |   0.151594  |    0.039225     |   0\n",
      "      32517 |   0.137863  |    0.408320     |   1\n",
      "      32518 |   0.174610  |    0.086959     |   0\n",
      "      32519 |   0.022479  |    0.199645     |   2\n",
      "      32520 |   0.175148  |    0.322385     |   1\n",
      "      32521 |   0.122357  |    0.092070     |   0\n",
      "      32522 |   0.030553  |    0.199883     |   2\n",
      "      32523 |   0.163524  |    0.278215     |   1\n",
      "      32524 |   0.043785  |    0.125473     |   2\n",
      "      32525 |   0.158117  |    0.038418     |   0\n",
      "      32526 |   0.204249  |    0.431066     |   1\n",
      "      32527 |   0.186031  |    0.217528     |   0\n",
      "      32528 |   0.042279  |    0.249030     |   2\n",
      "      32529 |   0.178091  |    0.069369     |   0\n",
      "      32530 |   0.137176  |    0.046204     |   0\n",
      "      32531 |   0.132758  |    0.204374     |   1\n",
      "      32532 |   0.037186  |    0.053140     |   2\n",
      "      32533 |   0.016378  |    0.111986     |   2\n",
      "      32534 |   0.187070  |    0.191465     |   1\n",
      "      32535 |   0.144416  |    0.298059     |   1\n",
      "      32536 |   0.189176  |    0.016105     |   0\n",
      "      32537 |   0.000013  |    0.136514     |   2\n",
      "      32538 |   0.180608  |    0.205915     |   1\n",
      "      32539 |   0.190274  |    0.223964     |   1\n",
      "      32540 |   0.224630  |    0.228960     |   1\n",
      "      32541 |   0.208696  |    0.230292     |   1\n",
      "      32542 |   0.210888  |    0.133809     |   1\n",
      "      32543 |   0.004579  |    0.129927     |   2\n",
      "      32544 |   0.156404  |    0.163090     |   1\n",
      "      32545 |   0.125279  |    0.271243     |   1\n",
      "      32546 |   0.145203  |    0.223056     |   1\n",
      "      32547 |   0.048525  |    0.004249     |   2\n",
      "      32548 |   0.180621  |    0.285243     |   1\n",
      "      32549 |   0.147392  |    0.017398     |   0\n",
      "      32550 |   0.145427  |    0.270473     |   1\n",
      "      32551 |   0.135773  |    0.006857     |   0\n",
      "      32552 |   0.029408  |    0.121721     |   2\n",
      "      32553 |   0.169749  |    0.163734     |   1\n",
      "      32554 |   0.222180  |    0.121003     |   0\n",
      "      32555 |   0.218703  |    0.170617     |   1\n",
      "      32556 |   0.129486  |    0.243933     |   1\n",
      "      32557 |   0.048933  |    0.077103     |   2\n",
      "      32558 |   0.033270  |    0.076491     |   2\n",
      "      32559 |   0.150291  |    0.201513     |   1\n",
      "      32560 |   0.172638  |    0.067921     |   0\n",
      "      32561 |   0.013548  |    0.068304     |   2\n",
      "      32562 |   0.028223  |    0.018657     |   2\n",
      "      32563 |   0.023296  |    0.076655     |   2\n",
      "      32564 |   0.000013  |    0.040537     |   2\n",
      "      32565 |   0.199873  |    0.204882     |   1\n",
      "      32566 |   0.154119  |    0.047989     |   0\n",
      "      32567 |   0.189457  |    0.064721     |   0\n",
      "      32568 |   0.169103  |    0.073674     |   0\n",
      "      32569 |   0.201215  |    0.223019     |   1\n",
      "      32570 |   0.137839  |    0.086986     |   0\n",
      "      32571 |   0.197572  |    0.203042     |   1\n",
      "      32572 |   0.122585  |    0.196221     |   1\n",
      "      32573 |   0.000013  |    0.028306     |   2\n",
      "      32574 |   0.158887  |    0.271405     |   1\n",
      "      32575 |   0.185489  |    0.219774     |   1\n",
      "      32576 |   0.167070  |    0.219834     |   1\n",
      "      32577 |   0.195369  |    0.050628     |   0\n",
      "      32578 |   0.000013  |    0.104800     |   2\n",
      "      32579 |   0.166610  |    0.014681     |   0\n",
      "      32580 |   0.000013  |    0.094346     |   2\n",
      "      32581 |   0.152287  |    0.233952     |   1\n",
      "      32582 |   0.188590  |    0.054110     |   0\n",
      "      32583 |   0.165890  |    0.038900     |   0\n",
      "      32584 |   0.256863  |    0.124331     |   0\n",
      "      32585 |   0.169271  |    0.042723     |   0\n",
      "      32586 |   0.000013  |    0.092889     |   2\n",
      "      32587 |   0.000013  |    0.007200     |   2\n",
      "      32588 |   0.037469  |    0.120420     |   2\n",
      "      32589 |   0.162498  |    0.227082     |   1\n",
      "      32590 |   0.164086  |    0.004323     |   0\n",
      "      32591 |   0.153726  |    0.058100     |   0\n",
      "      32592 |   0.123941  |    0.048997     |   0\n",
      "      32593 |   0.206315  |    0.103350     |   0\n",
      "      32594 |   0.141784  |    0.231730     |   1\n",
      "      32595 |   0.194558  |    0.236069     |   1\n",
      "      32596 |   0.164346  |    0.101015     |   0\n",
      "      32597 |   0.160284  |    0.260691     |   1\n",
      "      32598 |   0.041805  |    0.014303     |   2\n",
      "      32599 |   0.213638  |    0.151700     |   0\n",
      "      32600 |   0.174755  |    0.008547     |   0\n",
      "      32601 |   0.138742  |    0.072673     |   0\n",
      "      32602 |   0.153231  |    0.275252     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 32603: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      32603 |   0.140220  |    0.048225     |   0\n",
      "      32604 |   0.038285  |    0.049226     |   2\n",
      "      32605 |   0.025862  |    0.089948     |   2\n",
      "      32606 |   0.032651  |    0.086245     |   2\n",
      "      32607 |   0.124697  |    0.006881     |   0\n",
      "      32608 |   0.182725  |    0.081081     |   0\n",
      "      32609 |   0.032393  |    0.085106     |   2\n",
      "      32610 |   0.023264  |    0.066345     |   2\n",
      "      32611 |   0.145719  |    0.204180     |   1\n",
      "      32612 |   0.206734  |    0.251560     |   1\n",
      "      32613 |   0.160911  |    0.220816     |   1\n",
      "      32614 |   0.031745  |    0.043022     |   2\n",
      "      32615 |   0.047910  |    0.091095     |   2\n",
      "      32616 |   0.156627  |    0.063583     |   0\n",
      "      32617 |   0.181324  |    0.092707     |   0\n",
      "      32618 |   0.214434  |    0.243573     |   1\n",
      "      32619 |   0.176061  |    0.046823     |   0\n",
      "      32620 |   0.147954  |    0.070723     |   0\n",
      "      32621 |   0.186770  |    0.218249     |   1\n",
      "      32622 |   0.157351  |    0.025949     |   0\n",
      "      32623 |   0.166354  |    0.133147     |   0\n",
      "      32624 |   0.139506  |    0.209056     |   1\n",
      "      32625 |   0.231185  |    0.223961     |   1\n",
      "      32626 |   0.041541  |    0.014948     |   2\n",
      "      32627 |   0.179017  |    0.290586     |   1\n",
      "      32628 |   0.034129  |    0.089850     |   2\n",
      "      32629 |   0.169438  |    0.052202     |   0\n",
      "      32630 |   0.179881  |    0.230810     |   1\n",
      "      32631 |   0.135911  |    0.063695     |   0\n",
      "      32632 |   0.158049  |    0.280221     |   1\n",
      "      32633 |   0.188989  |    0.065050     |   0\n",
      "      32634 |   0.171869  |    0.097842     |   0\n",
      "      32635 |   0.188596  |    0.219811     |   1\n",
      "      32636 |   0.235222  |    0.236552     |   1\n",
      "      32637 |   0.192214  |    0.138778     |   0\n",
      "      32638 |   0.017732  |    0.014025     |   2\n",
      "      32639 |   0.000013  |    0.077829     |   2\n",
      "      32640 |   0.171839  |    0.244036     |   1\n",
      "      32641 |   0.180321  |    0.006270     |   0\n",
      "      32642 |   0.004255  |    0.059216     |   2\n",
      "      32643 |   0.170774  |    0.234812     |   1\n",
      "      32644 |   0.155127  |    0.115574     |   0\n",
      "      32645 |   0.051029  |    0.062099     |   2\n",
      "      32646 |   0.183520  |    0.265543     |   1\n",
      "      32647 |   0.172298  |    0.005440     |   0\n",
      "      32648 |   0.032307  |    0.096872     |   2\n",
      "      32649 |   0.205273  |    0.213624     |   1\n",
      "      32650 |   0.141343  |    0.049751     |   0\n",
      "      32651 |   0.182275  |    0.197611     |   1\n",
      "      32652 |   0.191914  |    0.278822     |   1\n",
      "      32653 |   0.183861  |    0.224861     |   1\n",
      "      32654 |   0.155220  |    0.244853     |   1\n",
      "      32655 |   0.048273  |    0.049723     |   2\n",
      "      32656 |   0.126691  |    0.037133     |   0\n",
      "      32657 |   0.185303  |    0.091698     |   0\n",
      "      32658 |   0.170083  |    0.224990     |   1\n",
      "      32659 |   0.160872  |    0.301495     |   1\n",
      "      32660 |   0.148965  |    0.053790     |   0\n",
      "      32661 |   0.034661  |    0.109898     |   2\n",
      "      32662 |   0.175967  |    0.044826     |   0\n",
      "      32663 |   0.168918  |    0.072310     |   0\n",
      "      32664 |   0.014805  |    0.117685     |   2\n",
      "      32665 |   0.122264  |    0.003080     |   0\n",
      "      32666 |   0.192886  |    0.348353     |   1\n",
      "      32667 |   0.118224  |    0.331164     |   1\n",
      "      32668 |   0.032164  |    0.020407     |   2\n",
      "      32669 |   0.144427  |    0.088341     |   0\n",
      "      32670 |   0.196494  |    0.072729     |   0\n",
      "      32671 |   0.201395  |    0.271576     |   1\n",
      "      32672 |   0.166856  |    0.224714     |   1\n",
      "      32673 |   0.136456  |    0.005599     |   0\n",
      "      32674 |   0.184329  |    0.236171     |   1\n",
      "      32675 |   0.190234  |    0.124055     |   0\n",
      "      32676 |   0.204661  |    0.235881     |   1\n",
      "      32677 |   0.165390  |    0.029083     |   0\n",
      "      32678 |   0.150545  |    0.071998     |   0\n",
      "      32679 |   0.165177  |    0.088256     |   0\n",
      "      32680 |   0.145094  |    0.219383     |   1\n",
      "      32681 |   0.020851  |    0.097081     |   2\n",
      "      32682 |   0.169898  |    0.085612     |   0\n",
      "      32683 |   0.176173  |    0.042076     |   0\n",
      "      32684 |   0.000013  |    0.110631     |   2\n",
      "      32685 |   0.000013  |    0.079817     |   2\n",
      "      32686 |   0.150111  |    0.312072     |   1\n",
      "      32687 |   0.158141  |    0.045275     |   0\n",
      "      32688 |   0.158270  |    0.224335     |   1\n",
      "      32689 |   0.216763  |    0.174934     |   1\n",
      "      32690 |   0.000013  |    0.067181     |   2\n",
      "      32691 |   0.000013  |    0.120487     |   2\n",
      "      32692 |   0.195901  |    0.012682     |   0\n",
      "      32693 |   0.000013  |    0.163235     |   2\n",
      "      32694 |   0.000013  |    0.005737     |   2\n",
      "      32695 |   0.206261  |    0.123417     |   0\n",
      "      32696 |   0.040490  |    0.049241     |   2\n",
      "      32697 |   0.189263  |    0.045706     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 32699: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      32698 |   0.042534  |    0.019486     |   2\n",
      "      32699 |   0.148514  |    0.268544     |   1\n",
      "      32700 |   0.042381  |    0.062868     |   2\n",
      "      32701 |   0.169133  |    0.072238     |   0\n",
      "      32702 |   0.205228  |    0.322017     |   1\n",
      "      32703 |   0.027203  |    0.067623     |   2\n",
      "      32704 |   0.136105  |    0.064747     |   0\n",
      "      32705 |   0.033305  |    0.113887     |   2\n",
      "      32706 |   0.184814  |    0.147743     |   0\n",
      "      32707 |   0.184459  |    0.036810     |   0\n",
      "      32708 |   0.032204  |    0.067486     |   2\n",
      "      32709 |   0.023619  |    0.073073     |   2\n",
      "      32710 |   0.159537  |    0.406307     |   1\n",
      "      32711 |   0.033590  |    0.061236     |   2\n",
      "      32712 |   0.131971  |    0.446652     |   1\n",
      "      32713 |   0.199249  |    0.346412     |   1\n",
      "      32714 |   0.207264  |    0.334262     |   1\n",
      "      32715 |   0.180179  |    0.308835     |   1\n",
      "      32716 |   0.173180  |    0.463133     |   1\n",
      "      32717 |   0.045593  |    0.037680     |   2\n",
      "      32718 |   0.042134  |    0.188461     |   2\n",
      "      32719 |   0.200579  |    0.157348     |   0\n",
      "      32720 |   0.038739  |    0.057297     |   2\n",
      "      32721 |   0.018715  |    0.142269     |   2\n",
      "      32722 |   0.175966  |    0.071249     |   0\n",
      "      32723 |   0.000013  |    0.097503     |   2\n",
      "      32724 |   0.222536  |    0.065895     |   0\n",
      "      32725 |   0.113950  |    0.235314     |   1\n",
      "      32726 |   0.174357  |    0.042139     |   0\n",
      "      32727 |   0.004110  |    0.065904     |   2\n",
      "      32728 |   0.160684  |    0.055978     |   0\n",
      "      32729 |   0.136231  |    0.068621     |   0\n",
      "      32730 |   0.186688  |    0.228535     |   1\n",
      "      32731 |   0.179837  |    0.272091     |   1\n",
      "      32732 |   0.159457  |    0.027782     |   0\n",
      "      32733 |   0.050636  |    0.096103     |   2\n",
      "      32734 |   0.188189  |    0.228435     |   1\n",
      "      32735 |   0.209888  |    0.165278     |   1\n",
      "      32736 |   0.030896  |    0.168155     |   2\n",
      "      32737 |   0.161982  |    0.005340     |   0\n",
      "      32738 |   0.133969  |    0.240174     |   1\n",
      "      32739 |   0.168207  |    0.139282     |   1\n",
      "      32740 |   0.218125  |    0.216786     |   1\n",
      "      32741 |   0.153382  |    0.036021     |   0\n",
      "      32742 |   0.049971  |    0.110337     |   2\n",
      "      32743 |   0.154212  |    0.004808     |   0\n",
      "      32744 |   0.195277  |    0.250899     |   1\n",
      "      32745 |   0.138529  |    0.221572     |   1\n",
      "      32746 |   0.136009  |    0.066750     |   0\n",
      "      32747 |   0.182184  |    0.081972     |   0\n",
      "      32748 |   0.130630  |    0.028693     |   0\n",
      "      32749 |   0.034804  |    0.107007     |   2\n",
      "      32750 |   0.201795  |    0.042510     |   0\n",
      "      32751 |   0.141709  |    0.054671     |   0\n",
      "      32752 |   0.014476  |    0.117655     |   2\n",
      "      32753 |   0.166349  |    0.286286     |   1\n",
      "      32754 |   0.034312  |    0.005013     |   2\n",
      "      32755 |   0.020724  |    0.057172     |   2\n",
      "      32756 |   0.191830  |    0.285173     |   1\n",
      "      32757 |   0.145243  |    0.213515     |   1\n",
      "      32758 |   0.000013  |    0.027553     |   2\n",
      "      32759 |   0.151103  |    0.284260     |   1\n",
      "      32760 |   0.135307  |    0.017205     |   0\n",
      "      32761 |   0.185355  |    0.058892     |   0\n",
      "      32762 |   0.181887  |    0.067389     |   0\n",
      "      32763 |   0.162418  |    0.223810     |   1\n",
      "      32764 |   0.180026  |    0.202456     |   1\n",
      "      32765 |   0.141520  |    0.076995     |   0\n",
      "      32766 |   0.000013  |    0.020732     |   2\n",
      "      32767 |   0.000013  |    0.085091     |   2\n",
      "      32768 |   0.185557  |    0.127889     |   0\n",
      "      32769 |   0.119495  |    0.231537     |   1\n",
      "      32770 |   0.139868  |    0.004203     |   0\n",
      "      32771 |   0.143282  |    0.218786     |   1\n",
      "      32772 |   0.000013  |    0.064271     |   2\n",
      "      32773 |   0.166912  |    0.098522     |   0\n",
      "      32774 |   0.177262  |    0.025648     |   0\n",
      "      32775 |   0.174377  |    0.291966     |   1\n",
      "      32776 |   0.185255  |    0.013098     |   0\n",
      "      32777 |   0.221767  |    0.178641     |   1\n",
      "      32778 |   0.000013  |    0.040469     |   2\n",
      "      32779 |   0.147247  |    0.028032     |   0\n",
      "      32780 |   0.000013  |    0.080156     |   2\n",
      "      32781 |   0.190484  |    0.116594     |   0\n",
      "      32782 |   0.039730  |    0.039944     |   2\n",
      "      32783 |   0.164729  |    0.066505     |   0\n",
      "      32784 |   0.198903  |    0.221523     |   1\n",
      "      32785 |   0.161108  |    0.164459     |   0\n",
      "      32786 |   0.171581  |    0.304311     |   1\n",
      "      32787 |   0.207087  |    0.270296     |   1\n",
      "      32788 |   0.175079  |    0.225982     |   0\n",
      "      32789 |   0.160903  |    0.356477     |   1\n",
      "      32790 |   0.197767  |    0.339925     |   1\n",
      "      32791 |   0.133114  |    0.086479     |   0\n",
      "      32792 |   0.176824  |    0.274809     |   1\n",
      "      32793 |   0.159425  |    0.067164     |   0\n",
      "      32794 |   0.041405  |    0.070782     |   2\n",
      "      32795 |   0.187652  |    0.213701     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 32796: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      32796 |   0.035853  |    0.069956     |   2\n",
      "      32797 |   0.133907  |    0.230602     |   1\n",
      "      32798 |   0.190466  |    0.293969     |   1\n",
      "      32799 |   0.207940  |    0.241612     |   1\n",
      "      32800 |   0.195902  |    0.041467     |   0\n",
      "      32801 |   0.026053  |    0.057540     |   2\n",
      "      32802 |   0.152267  |    0.316769     |   1\n",
      "      32803 |   0.198495  |    0.222547     |   1\n",
      "      32804 |   0.164511  |    0.191374     |   1\n",
      "      32805 |   0.032349  |    0.094361     |   2\n",
      "      32806 |   0.033985  |    0.055598     |   2\n",
      "      32807 |   0.224168  |    0.231388     |   1\n",
      "      32808 |   0.136323  |    0.254496     |   1\n",
      "      32809 |   0.022577  |    0.030649     |   2\n",
      "      32810 |   0.163153  |    0.277009     |   1\n",
      "      32811 |   0.207553  |    0.082243     |   0\n",
      "      32812 |   0.156366  |    0.214488     |   1\n",
      "      32813 |   0.030456  |    0.043467     |   2\n",
      "      32814 |   0.174381  |    0.068081     |   0\n",
      "      32815 |   0.178876  |    0.223052     |   1\n",
      "      32816 |   0.206295  |    0.186192     |   1\n",
      "      32817 |   0.119320  |    0.045646     |   0\n",
      "      32818 |   0.043455  |    0.102758     |   2\n",
      "      32819 |   0.178844  |    0.259916     |   1\n",
      "      32820 |   0.196276  |    0.003925     |   0\n",
      "      32821 |   0.182246  |    0.282829     |   1\n",
      "      32822 |   0.194153  |    0.248703     |   1\n",
      "      32823 |   0.196658  |    0.148355     |   1\n",
      "      32824 |   0.179435  |    0.222519     |   1\n",
      "      32825 |   0.203608  |    0.045814     |   0\n",
      "      32826 |   0.178197  |    0.232782     |   1\n",
      "      32827 |   0.040229  |    0.023847     |   2\n",
      "      32828 |   0.171211  |    0.076331     |   0\n",
      "      32829 |   0.035083  |    0.028541     |   2\n",
      "      32830 |   0.158460  |    0.105412     |   0\n",
      "      32831 |   0.018403  |    0.016550     |   2\n",
      "      32832 |   0.000013  |    0.122715     |   2\n",
      "      32833 |   0.003912  |    0.020319     |   2\n",
      "      32834 |   0.182849  |    0.212669     |   1\n",
      "      32835 |   0.183502  |    0.053945     |   0\n",
      "      32836 |   0.158351  |    0.134189     |   0\n",
      "      32837 |   0.051738  |    0.004374     |   2\n",
      "      32838 |   0.028818  |    0.058164     |   2\n",
      "      32839 |   0.181524  |    0.076867     |   0\n",
      "      32840 |   0.188313  |    0.218686     |   1\n",
      "      32841 |   0.151691  |    0.068650     |   0\n",
      "      32842 |   0.121829  |    0.059984     |   0\n",
      "      32843 |   0.189484  |    0.296641     |   1\n",
      "      32844 |   0.216684  |    0.178569     |   1\n",
      "      32845 |   0.191227  |    0.046099     |   0\n",
      "      32846 |   0.227242  |    0.240142     |   1\n",
      "      32847 |   0.195784  |    0.221141     |   1\n",
      "      32848 |   0.050819  |    0.085255     |   2\n",
      "      32849 |   0.035937  |    0.064233     |   2\n",
      "      32850 |   0.207062  |    0.194849     |   1\n",
      "      32851 |   0.163165  |    0.045530     |   0\n",
      "      32852 |   0.144949  |    0.065462     |   0\n",
      "      32853 |   0.013781  |    0.111365     |   2\n",
      "      32854 |   0.149442  |    0.219047     |   1\n",
      "      32855 |   0.162747  |    0.149839     |   0\n",
      "      32856 |   0.175074  |    0.200385     |   1\n",
      "      32857 |   0.119040  |    0.176123     |   1\n",
      "      32858 |   0.030480  |    0.024350     |   2\n",
      "      32859 |   0.020134  |    0.118619     |   2\n",
      "      32860 |   0.000013  |    0.053804     |   2\n",
      "      32861 |   0.146263  |    0.049064     |   0\n",
      "      32862 |   0.153591  |    0.040942     |   0\n",
      "      32863 |   0.000013  |    0.056150     |   2\n",
      "      32864 |   0.173962  |    0.238675     |   1\n",
      "      32865 |   0.213300  |    0.205623     |   1\n",
      "      32866 |   0.150842  |    0.111517     |   0\n",
      "      32867 |   0.169234  |    0.417564     |   1\n",
      "      32868 |   0.000013  |    0.035614     |   2\n",
      "      32869 |   0.217344  |    0.291963     |   1\n",
      "      32870 |   0.175301  |    0.252204     |   1\n",
      "      32871 |   0.000013  |    0.149940     |   2\n",
      "      32872 |   0.138357  |    0.084613     |   0\n",
      "      32873 |   0.197138  |    0.078491     |   0\n",
      "      32874 |   0.143631  |    0.281461     |   1\n",
      "      32875 |   0.157754  |    0.078636     |   0\n",
      "      32876 |   0.195945  |    0.037747     |   0\n",
      "      32877 |   0.000013  |    0.163558     |   2\n",
      "      32878 |   0.000013  |    0.033987     |   2\n",
      "      32879 |   0.197901  |    0.095953     |   0\n",
      "      32880 |   0.153496  |    0.044899     |   0\n",
      "      32881 |   0.201600  |    0.284316     |   1\n",
      "      32882 |   0.038420  |    0.009692     |   2\n",
      "      32883 |   0.168182  |    0.249763     |   1\n",
      "      32884 |   0.041338  |    0.063632     |   2\n",
      "      32885 |   0.161788  |    0.090782     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 32886: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      32886 |   0.039109  |    0.009583     |   2\n",
      "      32887 |   0.210251  |    0.108726     |   0\n",
      "      32888 |   0.215806  |    0.083581     |   0\n",
      "      32889 |   0.201555  |    0.147463     |   0\n",
      "      32890 |   0.226443  |    0.197932     |   1\n",
      "      32891 |   0.143505  |    0.016294     |   0\n",
      "      32892 |   0.026432  |    0.118901     |   2\n",
      "      32893 |   0.216329  |    0.225938     |   1\n",
      "      32894 |   0.140871  |    0.236988     |   1\n",
      "      32895 |   0.200051  |    0.259087     |   1\n",
      "      32896 |   0.185949  |    0.027775     |   0\n",
      "      32897 |   0.196757  |    0.078739     |   0\n",
      "      32898 |   0.034100  |    0.080933     |   2\n",
      "      32899 |   0.198551  |    0.279353     |   1\n",
      "      32900 |   0.158868  |    0.053458     |   0\n",
      "      32901 |   0.180705  |    0.219012     |   1\n",
      "      32902 |   0.032202  |    0.060059     |   2\n",
      "      32903 |   0.023515  |    0.077246     |   2\n",
      "      32904 |   0.031683  |    0.042893     |   2\n",
      "      32905 |   0.172787  |    0.266201     |   1\n",
      "      32906 |   0.174014  |    0.066279     |   0\n",
      "      32907 |   0.170328  |    0.104430     |   0\n",
      "      32908 |   0.107099  |    0.049868     |   0\n",
      "      32909 |   0.179938  |    0.079472     |   0\n",
      "      32910 |   0.154068  |    0.073879     |   0\n",
      "      32911 |   0.161636  |    0.254885     |   1\n",
      "      32912 |   0.193241  |    0.209897     |   1\n",
      "      32913 |   0.045833  |    0.089864     |   2\n",
      "      32914 |   0.199769  |    0.192963     |   1\n",
      "      32915 |   0.206589  |    0.029567     |   0\n",
      "      32916 |   0.044379  |    0.102411     |   2\n",
      "      32917 |   0.166920  |    0.245739     |   1\n",
      "      32918 |   0.156376  |    0.207110     |   1\n",
      "      32919 |   0.225781  |    0.246918     |   1\n",
      "      32920 |   0.154462  |    0.210199     |   1\n",
      "      32921 |   0.196522  |    0.045320     |   0\n",
      "      32922 |   0.165587  |    0.248633     |   1\n",
      "      32923 |   0.152739  |    0.270993     |   1\n",
      "      32924 |   0.175101  |    0.015477     |   0\n",
      "      32925 |   0.037132  |    0.117164     |   2\n",
      "      32926 |   0.130913  |    0.038698     |   0\n",
      "      32927 |   0.016361  |    0.071733     |   2\n",
      "      32928 |   0.172703  |    0.239052     |   1\n",
      "      32929 |   0.000013  |    0.088919     |   2\n",
      "      32930 |   0.189553  |    0.233904     |   1\n",
      "      32931 |   0.180011  |    0.197695     |   1\n",
      "      32932 |   0.198084  |    0.026390     |   0\n",
      "      32933 |   0.004352  |    0.124319     |   2\n",
      "      32934 |   0.173642  |    0.061408     |   0\n",
      "      32935 |   0.173467  |    0.265803     |   1\n",
      "      32936 |   0.201074  |    0.240314     |   1\n",
      "      32937 |   0.049568  |    0.017983     |   2\n",
      "      32938 |   0.166205  |    0.230235     |   1\n",
      "      32939 |   0.030004  |    0.018631     |   2\n",
      "      32940 |   0.125282  |    0.278893     |   1\n",
      "      32941 |   0.189687  |    0.228364     |   1\n",
      "      32942 |   0.190879  |    0.206489     |   1\n",
      "      32943 |   0.183591  |    0.281369     |   1\n",
      "      32944 |   0.049391  |    0.016486     |   2\n",
      "      32945 |   0.156365  |    0.318937     |   1\n",
      "      32946 |   0.035775  |    0.065257     |   2\n",
      "      32947 |   0.012264  |    0.110144     |   2\n",
      "      32948 |   0.031375  |    0.014274     |   2\n",
      "      32949 |   0.022284  |    0.073051     |   2\n",
      "      32950 |   0.166777  |    0.100281     |   0\n",
      "      32951 |   0.000013  |    0.023773     |   2\n",
      "      32952 |   0.140061  |    0.121066     |   0\n",
      "      32953 |   0.130382  |    0.042202     |   0\n",
      "      32954 |   0.000013  |    0.049443     |   2\n",
      "      32955 |   0.146606  |    0.122996     |   0\n",
      "      32956 |   0.000013  |    0.054350     |   2\n",
      "      32957 |   0.136999  |    0.204603     |   1\n",
      "      32958 |   0.187098  |    0.105914     |   0\n",
      "      32959 |   0.185259  |    0.035781     |   0\n",
      "      32960 |   0.000013  |    0.061558     |   2\n",
      "      32961 |   0.000013  |    0.046283     |   2\n",
      "      32962 |   0.000013  |    0.146909     |   2\n",
      "      32963 |   0.037728  |    0.012889     |   2\n",
      "      32964 |   0.199905  |    0.104106     |   0\n",
      "      32965 |   0.170812  |    0.234461     |   1\n",
      "      32966 |   0.237052  |    0.107700     |   0\n",
      "      32967 |   0.041411  |    0.026449     |   2\n",
      "      32968 |   0.182128  |    0.084766     |   0\n",
      "      32969 |   0.146240  |    0.240331     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 32970: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      32970 |   0.202728  |    0.061777     |   0\n",
      "      32971 |   0.038607  |    0.051804     |   2\n",
      "      32972 |   0.164627  |    0.294490     |   1\n",
      "      32973 |   0.027259  |    0.023260     |   2\n",
      "      32974 |   0.168232  |    0.225804     |   1\n",
      "      32975 |   0.192482  |    0.273855     |   1\n",
      "      32976 |   0.154586  |    0.025963     |   0\n",
      "      32977 |   0.185569  |    0.257109     |   1\n",
      "      32978 |   0.031623  |    0.038009     |   2\n",
      "      32979 |   0.159446  |    0.105301     |   0\n",
      "      32980 |   0.179919  |    0.029380     |   0\n",
      "      32981 |   0.154024  |    0.116075     |   0\n",
      "      32982 |   0.170057  |    0.056241     |   0\n",
      "      32983 |   0.198746  |    0.265085     |   1\n",
      "      32984 |   0.179679  |    0.200918     |   1\n",
      "      32985 |   0.031192  |    0.047785     |   2\n",
      "      32986 |   0.143646  |    0.045225     |   0\n",
      "      32987 |   0.200629  |    0.104375     |   0\n",
      "      32988 |   0.023664  |    0.029391     |   2\n",
      "      32989 |   0.198534  |    0.057081     |   0\n",
      "      32990 |   0.032845  |    0.069235     |   2\n",
      "      32991 |   0.176625  |    0.210691     |   1\n",
      "      32992 |   0.043770  |    0.093679     |   2\n",
      "      32993 |   0.164226  |    0.232892     |   1\n",
      "      32994 |   0.161804  |    0.040831     |   0\n",
      "      32995 |   0.043631  |    0.074205     |   2\n",
      "      32996 |   0.164600  |    0.212366     |   1\n",
      "      32997 |   0.236596  |    0.086688     |   0\n",
      "      32998 |   0.207191  |    0.094974     |   0\n",
      "      32999 |   0.225295  |    0.304231     |   1\n",
      "      33000 |   0.037453  |    0.040857     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 33000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 33000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      33001 |   0.035636  |    0.096314     |   2\n",
      "      33002 |   0.142215  |    0.290972     |   1\n",
      "      33003 |   0.024944  |    0.046026     |   2\n",
      "      33004 |   0.145326  |    0.084905     |   0\n",
      "      33005 |   0.155773  |    0.053957     |   0\n",
      "      33006 |   0.120311  |    0.212633     |   1\n",
      "      33007 |   0.031232  |    0.069974     |   2\n",
      "      33008 |   0.180867  |    0.237000     |   1\n",
      "      33009 |   0.182474  |    0.226295     |   1\n",
      "      33010 |   0.175800  |    0.199417     |   1\n",
      "      33011 |   0.179866  |    0.245467     |   1\n",
      "      33012 |   0.131777  |    0.031992     |   0\n",
      "      33013 |   0.130670  |    0.092830     |   0\n",
      "      33014 |   0.150700  |    0.272769     |   1\n",
      "      33015 |   0.142416  |    0.276854     |   1\n",
      "      33016 |   0.207923  |    0.158631     |   1\n",
      "      33017 |   0.032761  |    0.129763     |   2\n",
      "      33018 |   0.156428  |    0.211673     |   1\n",
      "      33019 |   0.022862  |    0.060375     |   2\n",
      "      33020 |   0.174068  |    0.231423     |   1\n",
      "      33021 |   0.030400  |    0.076187     |   2\n",
      "      33022 |   0.172460  |    0.073118     |   0\n",
      "      33023 |   0.039401  |    0.066742     |   2\n",
      "      33024 |   0.207137  |    0.215754     |   1\n",
      "      33025 |   0.170528  |    0.094499     |   0\n",
      "      33026 |   0.110910  |    0.175032     |   1\n",
      "      33027 |   0.138026  |    0.037204     |   0\n",
      "      33028 |   0.136897  |    0.077172     |   0\n",
      "      33029 |   0.138646  |    0.015635     |   0\n",
      "      33030 |   0.134562  |    0.124924     |   0\n",
      "      33031 |   0.192154  |    0.053870     |   0\n",
      "      33032 |   0.043722  |    0.042366     |   2\n",
      "      33033 |   0.240417  |    0.108221     |   0\n",
      "      33034 |   0.183395  |    0.218699     |   1\n",
      "      33035 |   0.100589  |    0.070007     |   0\n",
      "      33036 |   0.134577  |    0.142617     |   0\n",
      "      33037 |   0.144992  |    0.214455     |   1\n",
      "      33038 |   0.133075  |    0.047001     |   0\n",
      "      33039 |   0.123983  |    0.216302     |   1\n",
      "      33040 |   0.036031  |    0.034898     |   2\n",
      "      33041 |   0.171499  |    0.232868     |   1\n",
      "      33042 |   0.149700  |    0.220168     |   1\n",
      "      33043 |   0.015849  |    0.011375     |   2\n",
      "      33044 |   0.133726  |    0.313983     |   1\n",
      "      33045 |   0.178578  |    0.241454     |   1\n",
      "      33046 |   0.184224  |    0.201645     |   1\n",
      "      33047 |   0.270376  |    0.198425     |   1\n",
      "      33048 |   0.155747  |    0.039726     |   0\n",
      "      33049 |   0.173011  |    0.044589     |   0\n",
      "      33050 |   0.187197  |    0.076165     |   0\n",
      "      33051 |   0.151249  |    0.162013     |   1\n",
      "      33052 |   0.000013  |    0.119689     |   2\n",
      "      33053 |   0.166976  |    0.068316     |   0\n",
      "      33054 |   0.179737  |    0.252028     |   1\n",
      "      33055 |   0.004131  |    0.076118     |   2\n",
      "      33056 |   0.052310  |    0.017488     |   2\n",
      "      33057 |   0.029517  |    0.123323     |   2\n",
      "      33058 |   0.147764  |    0.068412     |   0\n",
      "      33059 |   0.049057  |    0.098592     |   2\n",
      "      33060 |   0.036220  |    0.052262     |   2\n",
      "      33061 |   0.163647  |    0.229631     |   1\n",
      "      33062 |   0.013128  |    0.073083     |   2\n",
      "      33063 |   0.174204  |    0.264692     |   1\n",
      "      33064 |   0.031295  |    0.005079     |   2\n",
      "      33065 |   0.158351  |    0.142412     |   0\n",
      "      33066 |   0.181144  |    0.007533     |   0\n",
      "      33067 |   0.152454  |    0.077777     |   0\n",
      "      33068 |   0.135634  |    0.051300     |   0\n",
      "      33069 |   0.180182  |    0.251813     |   1\n",
      "      33070 |   0.022486  |    0.038351     |   2\n",
      "      33071 |   0.140064  |    0.279517     |   1\n",
      "      33072 |   0.169073  |    0.084257     |   0\n",
      "      33073 |   0.203576  |    0.205939     |   1\n",
      "      33074 |   0.141378  |    0.234589     |   1\n",
      "      33075 |   0.000013  |    0.063605     |   2\n",
      "      33076 |   0.000013  |    0.085887     |   2\n",
      "      33077 |   0.131971  |    0.046940     |   0\n",
      "      33078 |   0.000013  |    0.099534     |   2\n",
      "      33079 |   0.000013  |    0.050633     |   2\n",
      "      33080 |   0.187786  |    0.125608     |   0\n",
      "      33081 |   0.168995  |    0.037157     |   0\n",
      "      33082 |   0.190531  |    0.260765     |   1\n",
      "      33083 |   0.000013  |    0.009537     |   2\n",
      "      33084 |   0.185545  |    0.081034     |   0\n",
      "      33085 |   0.166352  |    0.091347     |   0\n",
      "      33086 |   0.152781  |    0.064999     |   0\n",
      "      33087 |   0.187663  |    0.191492     |   1\n",
      "      33088 |   0.190232  |    0.063728     |   0\n",
      "      33089 |   0.000013  |    0.066613     |   2\n",
      "      33090 |   0.229947  |    0.104301     |   0\n",
      "      33091 |   0.191980  |    0.221084     |   1\n",
      "      33092 |   0.118227  |    0.164703     |   1\n",
      "      33093 |   0.170922  |    0.029190     |   0\n",
      "      33094 |   0.174119  |    0.214431     |   1\n",
      "      33095 |   0.163882  |    0.006333     |   0\n",
      "      33096 |   0.189225  |    0.099149     |   0\n",
      "      33097 |   0.042772  |    0.031126     |   2\n",
      "      33098 |   0.207256  |    0.095452     |   0\n",
      "      33099 |   0.182603  |    0.046970     |   0\n",
      "      33100 |   0.042698  |    0.069569     |   2\n",
      "      33101 |   0.200947  |    0.116845     |   0\n",
      "      33102 |   0.156479  |    0.054993     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 33103: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      33103 |   0.041407  |    0.028431     |   2\n",
      "      33104 |   0.197610  |    0.072072     |   0\n",
      "      33105 |   0.028447  |    0.027263     |   2\n",
      "      33106 |   0.139057  |    0.113522     |   0\n",
      "      33107 |   0.170775  |    0.210355     |   1\n",
      "      33108 |   0.207857  |    0.233772     |   1\n",
      "      33109 |   0.033197  |    0.037553     |   2\n",
      "      33110 |   0.153365  |    0.234764     |   1\n",
      "      33111 |   0.172863  |    0.040069     |   0\n",
      "      33112 |   0.137974  |    0.317267     |   1\n",
      "      33113 |   0.031397  |    0.013201     |   2\n",
      "      33114 |   0.023993  |    0.067019     |   2\n",
      "      33115 |   0.116649  |    0.322498     |   1\n",
      "      33116 |   0.159259  |    0.004089     |   0\n",
      "      33117 |   0.162423  |    0.053805     |   0\n",
      "      33118 |   0.031921  |    0.103595     |   2\n",
      "      33119 |   0.045886  |    0.080569     |   2\n",
      "      33120 |   0.170960  |    0.209818     |   1\n",
      "      33121 |   0.044978  |    0.065709     |   2\n",
      "      33122 |   0.200221  |    0.062863     |   0\n",
      "      33123 |   0.175816  |    0.091860     |   0\n",
      "      33124 |   0.146057  |    0.068570     |   0\n",
      "      33125 |   0.183893  |    0.053727     |   0\n",
      "      33126 |   0.155979  |    0.132896     |   0\n",
      "      33127 |   0.132761  |    0.222577     |   1\n",
      "      33128 |   0.214077  |    0.273263     |   1\n",
      "      33129 |   0.037257  |    0.011356     |   2\n",
      "      33130 |   0.221122  |    0.326278     |   1\n",
      "      33131 |   0.158673  |    0.027879     |   0\n",
      "      33132 |   0.165148  |    0.226234     |   1\n",
      "      33133 |   0.017232  |    0.026310     |   2\n",
      "      33134 |   0.000013  |    0.129780     |   2\n",
      "      33135 |   0.003941  |    0.005225     |   2\n",
      "      33136 |   0.139434  |    0.215159     |   1\n",
      "      33137 |   0.181037  |    0.091032     |   0\n",
      "      33138 |   0.164926  |    0.198892     |   1\n",
      "      33139 |   0.122994  |    0.034170     |   0\n",
      "      33140 |   0.049680  |    0.092452     |   2\n",
      "      33141 |   0.028404  |    0.041260     |   2\n",
      "      33142 |   0.184827  |    0.180594     |   1\n",
      "      33143 |   0.216951  |    0.366055     |   1\n",
      "      33144 |   0.193525  |    0.006421     |   0\n",
      "      33145 |   0.163503  |    0.074500     |   0\n",
      "      33146 |   0.186693  |    0.213039     |   1\n",
      "      33147 |   0.048104  |    0.011880     |   2\n",
      "      33148 |   0.035998  |    0.125981     |   2\n",
      "      33149 |   0.104807  |    0.045204     |   0\n",
      "      33150 |   0.013074  |    0.072928     |   2\n",
      "      33151 |   0.195085  |    0.296552     |   1\n",
      "      33152 |   0.030947  |    0.014682     |   2\n",
      "      33153 |   0.162029  |    0.076731     |   0\n",
      "      33154 |   0.202640  |    0.248191     |   1\n",
      "      33155 |   0.021664  |    0.008207     |   2\n",
      "      33156 |   0.000013  |    0.047116     |   2\n",
      "      33157 |   0.180635  |    0.096139     |   0\n",
      "      33158 |   0.161570  |    0.029864     |   0\n",
      "      33159 |   0.161465  |    0.282667     |   1\n",
      "      33160 |   0.186411  |    0.207457     |   1\n",
      "      33161 |   0.145246  |    0.040628     |   0\n",
      "      33162 |   0.000013  |    0.070859     |   2\n",
      "      33163 |   0.165047  |    0.043998     |   0\n",
      "      33164 |   0.000013  |    0.057200     |   2\n",
      "      33165 |   0.178929  |    0.234752     |   1\n",
      "      33166 |   0.196326  |    0.022054     |   0\n",
      "      33167 |   0.161944  |    0.081717     |   0\n",
      "      33168 |   0.000013  |    0.040714     |   2\n",
      "      33169 |   0.000013  |    0.111848     |   2\n",
      "      33170 |   0.172099  |    0.197609     |   1\n",
      "      33171 |   0.176172  |    0.007354     |   0\n",
      "      33172 |   0.146456  |    0.120105     |   0\n",
      "      33173 |   0.121876  |    0.007202     |   0\n",
      "      33174 |   0.000013  |    0.071688     |   2\n",
      "      33175 |   0.228554  |    0.241710     |   1\n",
      "      33176 |   0.182959  |    0.217105     |   1\n",
      "      33177 |   0.122861  |    0.238689     |   1\n",
      "      33178 |   0.182861  |    0.061262     |   0\n",
      "      33179 |   0.043276  |    0.098391     |   2\n",
      "      33180 |   0.211593  |    0.224113     |   1\n",
      "      33181 |   0.173506  |    0.216558     |   1\n",
      "      33182 |   0.041806  |    0.042450     |   2\n",
      "      33183 |   0.220160  |    0.308955     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 33185: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      33184 |   0.161188  |    0.028987     |   0\n",
      "      33185 |   0.147883  |    0.043768     |   0\n",
      "      33186 |   0.044076  |    0.111587     |   2\n",
      "      33187 |   0.027483  |    0.050820     |   2\n",
      "      33188 |   0.194297  |    0.082080     |   0\n",
      "      33189 |   0.162162  |    0.312961     |   1\n",
      "      33190 |   0.035670  |    0.006227     |   2\n",
      "      33191 |   0.200677  |    0.092206     |   0\n",
      "      33192 |   0.031481  |    0.065160     |   2\n",
      "      33193 |   0.197550  |    0.080564     |   0\n",
      "      33194 |   0.120216  |    0.041254     |   0\n",
      "      33195 |   0.148759  |    0.202030     |   1\n",
      "      33196 |   0.175902  |    0.221626     |   1\n",
      "      33197 |   0.213574  |    0.213363     |   1\n",
      "      33198 |   0.023768  |    0.061806     |   2\n",
      "      33199 |   0.144367  |    0.079583     |   0\n",
      "      33200 |   0.182850  |    0.063115     |   0\n",
      "      33201 |   0.033399  |    0.101575     |   2\n",
      "      33202 |   0.240641  |    0.216751     |   1\n",
      "      33203 |   0.181168  |    0.030175     |   0\n",
      "      33204 |   0.159342  |    0.366036     |   1\n",
      "      33205 |   0.174860  |    0.007325     |   0\n",
      "      33206 |   0.149472  |    0.078942     |   0\n",
      "      33207 |   0.149729  |    0.059958     |   0\n",
      "      33208 |   0.181981  |    0.119639     |   0\n",
      "      33209 |   0.047295  |    0.090838     |   2\n",
      "      33210 |   0.199720  |    0.249580     |   1\n",
      "      33211 |   0.163576  |    0.261316     |   1\n",
      "      33212 |   0.196718  |    0.005512     |   0\n",
      "      33213 |   0.043504  |    0.070589     |   2\n",
      "      33214 |   0.199646  |    0.246395     |   1\n",
      "      33215 |   0.138517  |    0.193231     |   1\n",
      "      33216 |   0.036475  |    0.024904     |   2\n",
      "      33217 |   0.177551  |    0.130646     |   0\n",
      "      33218 |   0.152267  |    0.205886     |   1\n",
      "      33219 |   0.164736  |    0.017550     |   0\n",
      "      33220 |   0.014868  |    0.113116     |   2\n",
      "      33221 |   0.000013  |    0.068928     |   2\n",
      "      33222 |   0.006026  |    0.025774     |   2\n",
      "      33223 |   0.186845  |    0.308504     |   1\n",
      "      33224 |   0.171167  |    0.208572     |   1\n",
      "      33225 |   0.052448  |    0.089323     |   2\n",
      "      33226 |   0.031006  |    0.077480     |   2\n",
      "      33227 |   0.176329  |    0.236462     |   1\n",
      "      33228 |   0.148814  |    0.198340     |   1\n",
      "      33229 |   0.052983  |    0.064266     |   2\n",
      "      33230 |   0.179849  |    0.089806     |   0\n",
      "      33231 |   0.111516  |    0.040411     |   0\n",
      "      33232 |   0.172751  |    0.220134     |   1\n",
      "      33233 |   0.173018  |    0.180198     |   1\n",
      "      33234 |   0.130618  |    0.238368     |   1\n",
      "      33235 |   0.035662  |    0.060578     |   2\n",
      "      33236 |   0.147625  |    0.066027     |   0\n",
      "      33237 |   0.012472  |    0.069241     |   2\n",
      "      33238 |   0.141867  |    0.284202     |   1\n",
      "      33239 |   0.143838  |    0.227726     |   1\n",
      "      33240 |   0.166522  |    0.047745     |   0\n",
      "      33241 |   0.031460  |    0.039817     |   2\n",
      "      33242 |   0.022923  |    0.072115     |   2\n",
      "      33243 |   0.167691  |    0.081537     |   0\n",
      "      33244 |   0.000013  |    0.083135     |   2\n",
      "      33245 |   0.191700  |    0.028176     |   0\n",
      "      33246 |   0.000013  |    0.169419     |   2\n",
      "      33247 |   0.168118  |    0.126101     |   1\n",
      "      33248 |   0.184645  |    0.110794     |   0\n",
      "      33249 |   0.000013  |    0.072355     |   2\n",
      "      33250 |   0.187332  |    0.033506     |   0\n",
      "      33251 |   0.179660  |    0.228351     |   1\n",
      "      33252 |   0.156193  |    0.067941     |   0\n",
      "      33253 |   0.000013  |    0.070671     |   2\n",
      "      33254 |   0.000013  |    0.072228     |   2\n",
      "      33255 |   0.109303  |    0.288536     |   1\n",
      "      33256 |   0.000013  |    0.024170     |   2\n",
      "      33257 |   0.149907  |    0.116048     |   0\n",
      "      33258 |   0.151934  |    0.067902     |   0\n",
      "      33259 |   0.189523  |    0.221795     |   1\n",
      "      33260 |   0.044333  |    0.022287     |   2\n",
      "      33261 |   0.174608  |    0.308631     |   1\n",
      "      33262 |   0.143762  |    0.189180     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 33264: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      33263 |   0.042350  |    0.023198     |   2\n",
      "      33264 |   0.039861  |    0.054330     |   2\n",
      "      33265 |   0.180939  |    0.187096     |   1\n",
      "      33266 |   0.026932  |    0.070518     |   2\n",
      "      33267 |   0.032709  |    0.076226     |   2\n",
      "      33268 |   0.186544  |    0.082369     |   0\n",
      "      33269 |   0.109015  |    0.232904     |   1\n",
      "      33270 |   0.032095  |    0.124023     |   2\n",
      "      33271 |   0.122224  |    0.004611     |   0\n",
      "      33272 |   0.133136  |    0.272450     |   1\n",
      "      33273 |   0.181153  |    0.029293     |   0\n",
      "      33274 |   0.210386  |    0.076323     |   0\n",
      "      33275 |   0.023682  |    0.108659     |   2\n",
      "      33276 |   0.032703  |    0.079835     |   2\n",
      "      33277 |   0.185224  |    0.253644     |   1\n",
      "      33278 |   0.176011  |    0.217650     |   1\n",
      "      33279 |   0.168352  |    0.005908     |   0\n",
      "      33280 |   0.046090  |    0.052351     |   2\n",
      "      33281 |   0.207609  |    0.218717     |   1\n",
      "      33282 |   0.043248  |    0.095289     |   2\n",
      "      33283 |   0.162697  |    0.040091     |   0\n",
      "      33284 |   0.121578  |    0.079579     |   0\n",
      "      33285 |   0.171095  |    0.073499     |   0\n",
      "      33286 |   0.198335  |    0.247257     |   1\n",
      "      33287 |   0.197046  |    0.042616     |   0\n",
      "      33288 |   0.038851  |    0.063401     |   2\n",
      "      33289 |   0.017220  |    0.068782     |   2\n",
      "      33290 |   0.175633  |    0.070473     |   0\n",
      "      33291 |   0.154096  |    0.219468     |   1\n",
      "      33292 |   0.181660  |    0.048017     |   0\n",
      "      33293 |   0.147745  |    0.305324     |   1\n",
      "      33294 |   0.173486  |    0.008177     |   0\n",
      "      33295 |   0.180262  |    0.110950     |   0\n",
      "      33296 |   0.121468  |    0.228705     |   1\n",
      "      33297 |   0.213230  |    0.048894     |   0\n",
      "      33298 |   0.000013  |    0.070793     |   2\n",
      "      33299 |   0.005329  |    0.096727     |   2\n",
      "      33300 |   0.153774  |    0.013625     |   0\n",
      "      33301 |   0.169581  |    0.078608     |   0\n",
      "      33302 |   0.203737  |    0.224066     |   1\n",
      "      33303 |   0.157451  |    0.246142     |   1\n",
      "      33304 |   0.051937  |    0.014342     |   2\n",
      "      33305 |   0.030585  |    0.104605     |   2\n",
      "      33306 |   0.173698  |    0.017410     |   0\n",
      "      33307 |   0.053927  |    0.118343     |   2\n",
      "      33308 |   0.038869  |    0.056207     |   2\n",
      "      33309 |   0.164589  |    0.255118     |   1\n",
      "      33310 |   0.165246  |    0.084978     |   0\n",
      "      33311 |   0.192063  |    0.026057     |   0\n",
      "      33312 |   0.165013  |    0.082372     |   0\n",
      "      33313 |   0.014581  |    0.056525     |   2\n",
      "      33314 |   0.164236  |    0.253965     |   1\n",
      "      33315 |   0.036087  |    0.049563     |   2\n",
      "      33316 |   0.149480  |    0.225062     |   1\n",
      "      33317 |   0.170214  |    0.027413     |   0\n",
      "      33318 |   0.166984  |    0.259534     |   1\n",
      "      33319 |   0.157784  |    0.028876     |   0\n",
      "      33320 |   0.165445  |    0.282264     |   1\n",
      "      33321 |   0.164521  |    0.027794     |   0\n",
      "      33322 |   0.023246  |    0.074389     |   2\n",
      "      33323 |   0.000013  |    0.026379     |   2\n",
      "      33324 |   0.000013  |    0.086155     |   2\n",
      "      33325 |   0.130592  |    0.065756     |   0\n",
      "      33326 |   0.000013  |    0.021970     |   2\n",
      "      33327 |   0.000013  |    0.102135     |   2\n",
      "      33328 |   0.190710  |    0.291949     |   1\n",
      "      33329 |   0.136160  |    0.004022     |   0\n",
      "      33330 |   0.178430  |    0.211494     |   1\n",
      "      33331 |   0.000013  |    0.071178     |   2\n",
      "      33332 |   0.000013  |    0.073519     |   2\n",
      "      33333 |   0.178627  |    0.234927     |   1\n",
      "      33334 |   0.038286  |    0.021082     |   2\n",
      "      33335 |   0.180210  |    0.082032     |   0\n",
      "      33336 |   0.155227  |    0.050496     |   0\n",
      "      33337 |   0.192181  |    0.277817     |   1\n",
      "      33338 |   0.041844  |    0.008598     |   2\n",
      "      33339 |   0.154246  |    0.104597     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 33340: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      33340 |   0.251277  |    0.043353     |   0\n",
      "      33341 |   0.122109  |    0.262132     |   1\n",
      "      33342 |   0.162188  |    0.201303     |   1\n",
      "      33343 |   0.191054  |    0.054008     |   0\n",
      "      33344 |   0.162615  |    0.231793     |   1\n",
      "      33345 |   0.039209  |    0.032007     |   2\n",
      "      33346 |   0.027149  |    0.095255     |   2\n",
      "      33347 |   0.032255  |    0.028061     |   2\n",
      "      33348 |   0.219755  |    0.091349     |   0\n",
      "      33349 |   0.030382  |    0.030665     |   2\n",
      "      33350 |   0.023155  |    0.065533     |   2\n",
      "      33351 |   0.174371  |    0.099338     |   0\n",
      "      33352 |   0.138496  |    0.024503     |   0\n",
      "      33353 |   0.031112  |    0.119290     |   2\n",
      "      33354 |   0.206930  |    0.027774     |   0\n",
      "      33355 |   0.168062  |    0.074078     |   0\n",
      "      33356 |   0.046428  |    0.047255     |   2\n",
      "      33357 |   0.115910  |    0.207030     |   1\n",
      "      33358 |   0.044378  |    0.083030     |   2\n",
      "      33359 |   0.152057  |    0.096411     |   0\n",
      "      33360 |   0.233434  |    0.161530     |   1\n",
      "      33361 |   0.037437  |    0.072538     |   2\n",
      "      33362 |   0.170803  |    0.054299     |   0\n",
      "      33363 |   0.015497  |    0.082695     |   2\n",
      "      33364 |   0.000013  |    0.062585     |   2\n",
      "      33365 |   0.188997  |    0.277348     |   1\n",
      "      33366 |   0.004262  |    0.034828     |   2\n",
      "      33367 |   0.250723  |    0.227834     |   1\n",
      "      33368 |   0.186589  |    0.042146     |   0\n",
      "      33369 |   0.142196  |    0.241066     |   1\n",
      "      33370 |   0.049728  |    0.092519     |   2\n",
      "      33371 |   0.153878  |    0.044091     |   0\n",
      "      33372 |   0.027755  |    0.093289     |   2\n",
      "      33373 |   0.179908  |    0.054775     |   0\n",
      "      33374 |   0.240659  |    0.248906     |   1\n",
      "      33375 |   0.158400  |    0.247763     |   1\n",
      "      33376 |   0.049181  |    0.036745     |   2\n",
      "      33377 |   0.034323  |    0.167047     |   2\n",
      "      33378 |   0.164355  |    0.025069     |   0\n",
      "      33379 |   0.013664  |    0.135653     |   2\n",
      "      33380 |   0.030507  |    0.072193     |   2\n",
      "      33381 |   0.178760  |    0.266868     |   1\n",
      "      33382 |   0.022806  |    0.057973     |   2\n",
      "      33383 |   0.178004  |    0.046495     |   0\n",
      "      33384 |   0.000013  |    0.094390     |   2\n",
      "      33385 |   0.000013  |    0.043121     |   2\n",
      "      33386 |   0.218156  |    0.193609     |   1\n",
      "      33387 |   0.000013  |    0.015583     |   2\n",
      "      33388 |   0.174406  |    0.057066     |   0\n",
      "      33389 |   0.193452  |    0.075224     |   0\n",
      "      33390 |   0.000013  |    0.091343     |   2\n",
      "      33391 |   0.000013  |    0.055898     |   2\n",
      "      33392 |   0.181829  |    0.237974     |   1\n",
      "      33393 |   0.119957  |    0.010637     |   0\n",
      "      33394 |   0.189295  |    0.068072     |   0\n",
      "      33395 |   0.152266  |    0.036784     |   0\n",
      "      33396 |   0.000013  |    0.087238     |   2\n",
      "      33397 |   0.038983  |    0.049925     |   2\n",
      "      33398 |   0.041833  |    0.071777     |   2\n",
      "      33399 |   0.169059  |    0.296972     |   1\n",
      "      33400 |   0.208901  |    0.226555     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 33401: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      33401 |   0.177750  |    0.200573     |   1\n",
      "      33402 |   0.036202  |    0.043832     |   2\n",
      "      33403 |   0.171795  |    0.075722     |   0\n",
      "      33404 |   0.200092  |    0.042623     |   0\n",
      "      33405 |   0.132528  |    0.075312     |   0\n",
      "      33406 |   0.154421  |    0.259008     |   1\n",
      "      33407 |   0.171408  |    0.177173     |   1\n",
      "      33408 |   0.139741  |    0.060050     |   0\n",
      "      33409 |   0.026059  |    0.102835     |   2\n",
      "      33410 |   0.257000  |    0.250886     |   1\n",
      "      33411 |   0.188151  |    0.159263     |   1\n",
      "      33412 |   0.264097  |    0.264695     |   1\n",
      "      33413 |   0.137893  |    0.012351     |   0\n",
      "      33414 |   0.202605  |    0.233938     |   1\n",
      "      33415 |   0.033177  |    0.055373     |   2\n",
      "      33416 |   0.136609  |    0.101005     |   0\n",
      "      33417 |   0.153355  |    0.268648     |   1\n",
      "      33418 |   0.239437  |    0.158116     |   1\n",
      "      33419 |   0.133963  |    0.059762     |   0\n",
      "      33420 |   0.031274  |    0.099402     |   2\n",
      "      33421 |   0.022378  |    0.041586     |   2\n",
      "      33422 |   0.185963  |    0.115360     |   0\n",
      "      33423 |   0.178741  |    0.046432     |   0\n",
      "      33424 |   0.176289  |    0.212918     |   1\n",
      "      33425 |   0.030727  |    0.030815     |   2\n",
      "      33426 |   0.039256  |    0.121736     |   2\n",
      "      33427 |   0.255533  |    0.204811     |   1\n",
      "      33428 |   0.127316  |    0.294239     |   1\n",
      "      33429 |   0.042073  |    0.014958     |   2\n",
      "      33430 |   0.037884  |    0.055235     |   2\n",
      "      33431 |   0.018008  |    0.070779     |   2\n",
      "      33432 |   0.000013  |    0.121847     |   2\n",
      "      33433 |   0.171494  |    0.042758     |   0\n",
      "      33434 |   0.004847  |    0.053523     |   2\n",
      "      33435 |   0.046173  |    0.118038     |   2\n",
      "      33436 |   0.214263  |    0.217309     |   1\n",
      "      33437 |   0.111372  |    0.028356     |   0\n",
      "      33438 |   0.178565  |    0.109033     |   0\n",
      "      33439 |   0.159142  |    0.275424     |   1\n",
      "      33440 |   0.155221  |    0.227702     |   1\n",
      "      33441 |   0.167867  |    0.005219     |   0\n",
      "      33442 |   0.244410  |    0.166123     |   1\n",
      "      33443 |   0.026791  |    0.054987     |   2\n",
      "      33444 |   0.200604  |    0.066288     |   0\n",
      "      33445 |   0.116658  |    0.230143     |   1\n",
      "      33446 |   0.150734  |    0.063603     |   0\n",
      "      33447 |   0.196726  |    0.208525     |   1\n",
      "      33448 |   0.169028  |    0.218685     |   1\n",
      "      33449 |   0.169882  |    0.084832     |   0\n",
      "      33450 |   0.048779  |    0.063224     |   2\n",
      "      33451 |   0.153536  |    0.048476     |   0\n",
      "      33452 |   0.207830  |    0.253695     |   1\n",
      "      33453 |   0.166471  |    0.227095     |   1\n",
      "      33454 |   0.035139  |    0.018367     |   2\n",
      "      33455 |   0.148079  |    0.292729     |   1\n",
      "      33456 |   0.013393  |    0.053936     |   2\n",
      "      33457 |   0.176459  |    0.214854     |   1\n",
      "      33458 |   0.180855  |    0.104282     |   0\n",
      "      33459 |   0.034254  |    0.064602     |   2\n",
      "      33460 |   0.191051  |    0.068284     |   0\n",
      "      33461 |   0.146212  |    0.015194     |   0\n",
      "      33462 |   0.023673  |    0.121166     |   2\n",
      "      33463 |   0.224977  |    0.212264     |   1\n",
      "      33464 |   0.162718  |    0.205670     |   1\n",
      "      33465 |   0.000013  |    0.037379     |   2\n",
      "      33466 |   0.239630  |    0.074745     |   0\n",
      "      33467 |   0.151153  |    0.042684     |   0\n",
      "      33468 |   0.167522  |    0.269153     |   1\n",
      "      33469 |   0.000013  |    0.042579     |   2\n",
      "      33470 |   0.000013  |    0.099731     |   2\n",
      "      33471 |   0.000013  |    0.068918     |   2\n",
      "      33472 |   0.167256  |    0.300013     |   1\n",
      "      33473 |   0.000013  |    0.007538     |   2\n",
      "      33474 |   0.162610  |    0.052912     |   0\n",
      "      33475 |   0.000013  |    0.097951     |   2\n",
      "      33476 |   0.253650  |    0.185403     |   1\n",
      "      33477 |   0.039422  |    0.080094     |   2\n",
      "      33478 |   0.157186  |    0.259839     |   1\n",
      "      33479 |   0.133811  |    0.037550     |   0\n",
      "      33480 |   0.166334  |    0.222648     |   1\n",
      "      33481 |   0.179953  |    0.026850     |   0\n",
      "      33482 |   0.041514  |    0.113034     |   2\n",
      "      33483 |   0.163633  |    0.083982     |   0\n",
      "      33484 |   0.144688  |    0.041672     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 33485: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      33485 |   0.236493  |    0.083360     |   0\n",
      "      33486 |   0.195293  |    0.045803     |   0\n",
      "      33487 |   0.152842  |    0.126511     |   0\n",
      "      33488 |   0.185881  |    0.223915     |   1\n",
      "      33489 |   0.204779  |    0.056608     |   0\n",
      "      33490 |   0.173089  |    0.105989     |   0\n",
      "      33491 |   0.214307  |    0.162201     |   1\n",
      "      33492 |   0.162621  |    0.273780     |   1\n",
      "      33493 |   0.041798  |    0.014827     |   2\n",
      "      33494 |   0.156138  |    0.099531     |   0\n",
      "      33495 |   0.027815  |    0.012457     |   2\n",
      "      33496 |   0.033566  |    0.118222     |   2\n",
      "      33497 |   0.031360  |    0.019177     |   2\n",
      "      33498 |   0.023357  |    0.125023     |   2\n",
      "      33499 |   0.031741  |    0.016313     |   2\n",
      "      33500 |   0.041833  |    0.079996     |   2\n",
      "      33501 |   0.040499  |    0.076170     |   2\n",
      "      33502 |   0.195081  |    0.163107     |   1\n",
      "      33503 |   0.134262  |    0.074148     |   0\n",
      "      33504 |   0.189932  |    0.156193     |   1\n",
      "      33505 |   0.026588  |    0.066144     |   2\n",
      "      33506 |   0.032336  |    0.108993     |   2\n",
      "      33507 |   0.030083  |    0.016798     |   2\n",
      "      33508 |   0.022883  |    0.104512     |   2\n",
      "      33509 |   0.156082  |    0.047130     |   0\n",
      "      33510 |   0.236737  |    0.223409     |   1\n",
      "      33511 |   0.129344  |    0.060385     |   0\n",
      "      33512 |   0.189268  |    0.036194     |   0\n",
      "      33513 |   0.199609  |    0.031400     |   0\n",
      "      33514 |   0.129992  |    0.109209     |   0\n",
      "      33515 |   0.028949  |    0.005906     |   2\n",
      "      33516 |   0.151257  |    0.097091     |   0\n",
      "      33517 |   0.146372  |    0.221058     |   1\n",
      "      33518 |   0.151991  |    0.227969     |   1\n",
      "      33519 |   0.194151  |    0.003437     |   0\n",
      "      33520 |   0.171856  |    0.113131     |   0\n",
      "      33521 |   0.137198  |    0.028516     |   0\n",
      "      33522 |   0.136606  |    0.094148     |   0\n",
      "      33523 |   0.040280  |    0.008099     |   2\n",
      "      33524 |   0.119594  |    0.127308     |   0\n",
      "      33525 |   0.148994  |    0.034704     |   0\n",
      "      33526 |   0.212998  |    0.221247     |   1\n",
      "      33527 |   0.041956  |    0.089793     |   2\n",
      "      33528 |   0.188215  |    0.068151     |   0\n",
      "      33529 |   0.154069  |    0.005228     |   0\n",
      "      33530 |   0.035858  |    0.076367     |   2\n",
      "      33531 |   0.120380  |    0.083336     |   0\n",
      "      33532 |   0.017218  |    0.076440     |   2\n",
      "      33533 |   0.000013  |    0.020671     |   2\n",
      "      33534 |   0.143229  |    0.098675     |   0\n",
      "      33535 |   0.003763  |    0.008247     |   2\n",
      "      33536 |   0.143958  |    0.299039     |   1\n",
      "      33537 |   0.155183  |    0.017758     |   0\n",
      "      33538 |   0.166211  |    0.189817     |   1\n",
      "      33539 |   0.049440  |    0.083040     |   2\n",
      "      33540 |   0.031192  |    0.071192     |   2\n",
      "      33541 |   0.146910  |    0.042170     |   0\n",
      "      33542 |   0.128030  |    0.075701     |   0\n",
      "      33543 |   0.082739  |    0.328617     |   1\n",
      "      33544 |   0.225084  |    0.139973     |   1\n",
      "      33545 |   0.190128  |    0.211500     |   1\n",
      "      33546 |   0.198437  |    0.219736     |   1\n",
      "      33547 |   0.191659  |    0.264107     |   1\n",
      "      33548 |   0.050075  |    0.042103     |   2\n",
      "      33549 |   0.196132  |    0.248148     |   1\n",
      "      33550 |   0.035573  |    0.025701     |   2\n",
      "      33551 |   0.201916  |    0.207994     |   1\n",
      "      33552 |   0.014228  |    0.085388     |   2\n",
      "      33553 |   0.152159  |    0.049922     |   0\n",
      "      33554 |   0.185079  |    0.216165     |   1\n",
      "      33555 |   0.029510  |    0.078052     |   2\n",
      "      33556 |   0.023863  |    0.014711     |   2\n",
      "      33557 |   0.189697  |    0.089146     |   0\n",
      "      33558 |   0.184003  |    0.288354     |   1\n",
      "      33559 |   0.171074  |    0.210253     |   1\n",
      "      33560 |   0.194498  |    0.022406     |   0\n",
      "      33561 |   0.000013  |    0.057534     |   2\n",
      "      33562 |   0.190096  |    0.240982     |   1\n",
      "      33563 |   0.183010  |    0.017398     |   0\n",
      "      33564 |   0.149702  |    0.090768     |   0\n",
      "      33565 |   0.218221  |    0.027694     |   0\n",
      "      33566 |   0.148559  |    0.273195     |   1\n",
      "      33567 |   0.000013  |    0.007690     |   2\n",
      "      33568 |   0.175302  |    0.098192     |   0\n",
      "      33569 |   0.185629  |    0.048079     |   0\n",
      "      33570 |   0.000013  |    0.074203     |   2\n",
      "      33571 |   0.179992  |    0.042432     |   0\n",
      "      33572 |   0.192437  |    0.073167     |   0\n",
      "      33573 |   0.132018  |    0.024082     |   0\n",
      "      33574 |   0.145062  |    0.105073     |   0\n",
      "      33575 |   0.000013  |    0.027674     |   2\n",
      "      33576 |   0.000013  |    0.063437     |   2\n",
      "      33577 |   0.000013  |    0.073054     |   2\n",
      "      33578 |   0.147575  |    0.203119     |   1\n",
      "      33579 |   0.195741  |    0.222468     |   1\n",
      "      33580 |   0.041901  |    0.077186     |   2\n",
      "      33581 |   0.042351  |    0.060581     |   2\n",
      "      33582 |   0.210959  |    0.061892     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 33583: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      33583 |   0.046288  |    0.100842     |   2\n",
      "      33584 |   0.201149  |    0.227916     |   1\n",
      "      33585 |   0.228774  |    0.200784     |   1\n",
      "      33586 |   0.196831  |    0.223909     |   1\n",
      "      33587 |   0.164192  |    0.021685     |   0\n",
      "      33588 |   0.026831  |    0.099818     |   2\n",
      "      33589 |   0.122124  |    0.300422     |   1\n",
      "      33590 |   0.190370  |    0.017966     |   0\n",
      "      33591 |   0.033142  |    0.125713     |   2\n",
      "      33592 |   0.029999  |    0.032632     |   2\n",
      "      33593 |   0.211159  |    0.295199     |   1\n",
      "      33594 |   0.129406  |    0.005937     |   0\n",
      "      33595 |   0.187422  |    0.078824     |   0\n",
      "      33596 |   0.022659  |    0.066919     |   2\n",
      "      33597 |   0.166829  |    0.067797     |   0\n",
      "      33598 |   0.148758  |    0.129981     |   0\n",
      "      33599 |   0.203729  |    0.194709     |   1\n",
      "      33600 |   0.031626  |    0.036317     |   2\n",
      "      33601 |   0.038098  |    0.044852     |   2\n",
      "      33602 |   0.154759  |    0.246391     |   1\n",
      "      33603 |   0.045726  |    0.032475     |   2\n",
      "      33604 |   0.037361  |    0.089620     |   2\n",
      "      33605 |   0.137344  |    0.028485     |   0\n",
      "      33606 |   0.160787  |    0.076665     |   0\n",
      "      33607 |   0.148785  |    0.040554     |   0\n",
      "      33608 |   0.150982  |    0.046093     |   0\n",
      "      33609 |   0.207809  |    0.083718     |   0\n",
      "      33610 |   0.230924  |    0.217511     |   1\n",
      "      33611 |   0.016321  |    0.040696     |   2\n",
      "      33612 |   0.137849  |    0.084532     |   0\n",
      "      33613 |   0.149719  |    0.053229     |   0\n",
      "      33614 |   0.158894  |    0.190004     |   1\n",
      "      33615 |   0.207782  |    0.032428     |   0\n",
      "      33616 |   0.163206  |    0.171233     |   1\n",
      "      33617 |   0.000013  |    0.093640     |   2\n",
      "      33618 |   0.151140  |    0.066983     |   0\n",
      "      33619 |   0.004347  |    0.050532     |   2\n",
      "      33620 |   0.197679  |    0.087144     |   0\n",
      "      33621 |   0.200892  |    0.113891     |   0\n",
      "      33622 |   0.174130  |    0.238773     |   1\n",
      "      33623 |   0.200398  |    0.177126     |   1\n",
      "      33624 |   0.200338  |    0.238873     |   1\n",
      "      33625 |   0.050106  |    0.073089     |   2\n",
      "      33626 |   0.137189  |    0.049658     |   0\n",
      "      33627 |   0.178605  |    0.077077     |   0\n",
      "      33628 |   0.030116  |    0.056800     |   2\n",
      "      33629 |   0.197289  |    0.259246     |   1\n",
      "      33630 |   0.049474  |    0.006535     |   2\n",
      "      33631 |   0.167530  |    0.297519     |   1\n",
      "      33632 |   0.035472  |    0.070622     |   2\n",
      "      33633 |   0.129036  |    0.040644     |   0\n",
      "      33634 |   0.012149  |    0.077013     |   2\n",
      "      33635 |   0.155947  |    0.198534     |   1\n",
      "      33636 |   0.029031  |    0.069764     |   2\n",
      "      33637 |   0.022550  |    0.090654     |   2\n",
      "      33638 |   0.179464  |    0.272268     |   1\n",
      "      33639 |   0.185620  |    0.225199     |   1\n",
      "      33640 |   0.000013  |    0.022991     |   2\n",
      "      33641 |   0.159383  |    0.257192     |   1\n",
      "      33642 |   0.111067  |    0.038814     |   0\n",
      "      33643 |   0.144116  |    0.126475     |   0\n",
      "      33644 |   0.173852  |    0.044139     |   0\n",
      "      33645 |   0.203813  |    0.263659     |   1\n",
      "      33646 |   0.178982  |    0.217650     |   1\n",
      "      33647 |   0.275939  |    0.036191     |   0\n",
      "      33648 |   0.157912  |    0.295586     |   1\n",
      "      33649 |   0.000013  |    0.004899     |   2\n",
      "      33650 |   0.142752  |    0.084437     |   0\n",
      "      33651 |   0.153460  |    0.246184     |   1\n",
      "      33652 |   0.210076  |    0.232189     |   1\n",
      "      33653 |   0.000013  |    0.015128     |   2\n",
      "      33654 |   0.000013  |    0.085469     |   2\n",
      "      33655 |   0.199424  |    0.025948     |   0\n",
      "      33656 |   0.168693  |    0.121990     |   0\n",
      "      33657 |   0.000013  |    0.018258     |   2\n",
      "      33658 |   0.000013  |    0.109932     |   2\n",
      "      33659 |   0.156902  |    0.338364     |   1\n",
      "      33660 |   0.185725  |    0.327032     |   1\n",
      "      33661 |   0.125860  |    0.403568     |   1\n",
      "      33662 |   0.036888  |    0.039113     |   2\n",
      "      33663 |   0.041218  |    0.095938     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 33664: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      33664 |   0.036579  |    0.123652     |   2\n",
      "      33665 |   0.027388  |    0.129421     |   2\n",
      "      33666 |   0.031522  |    0.070228     |   2\n",
      "      33667 |   0.177672  |    0.124054     |   0\n",
      "      33668 |   0.030858  |    0.102855     |   2\n",
      "      33669 |   0.201749  |    0.128795     |   0\n",
      "      33670 |   0.220328  |    0.039151     |   0\n",
      "      33671 |   0.140918  |    0.139284     |   0\n",
      "      33672 |   0.022364  |    0.068748     |   2\n",
      "      33673 |   0.209693  |    0.327570     |   1\n",
      "      33674 |   0.165444  |    0.144813     |   0\n",
      "      33675 |   0.130561  |    0.021109     |   0\n",
      "      33676 |   0.029112  |    0.131588     |   2\n",
      "      33677 |   0.201518  |    0.195803     |   1\n",
      "      33678 |   0.131446  |    0.060012     |   0\n",
      "      33679 |   0.043236  |    0.170566     |   2\n",
      "      33680 |   0.160654  |    0.231041     |   1\n",
      "      33681 |   0.154402  |    0.066616     |   0\n",
      "      33682 |   0.168946  |    0.046689     |   0\n",
      "      33683 |   0.041456  |    0.069036     |   2\n",
      "      33684 |   0.036425  |    0.027124     |   2\n",
      "      33685 |   0.016775  |    0.079155     |   2\n",
      "      33686 |   0.221590  |    0.079796     |   0\n",
      "      33687 |   0.000013  |    0.099560     |   2\n",
      "      33688 |   0.215275  |    0.175983     |   1\n",
      "      33689 |   0.151094  |    0.121891     |   0\n",
      "      33690 |   0.004017  |    0.078355     |   2\n",
      "      33691 |   0.221736  |    0.275431     |   1\n",
      "      33692 |   0.194056  |    0.199859     |   1\n",
      "      33693 |   0.183996  |    0.009652     |   0\n",
      "      33694 |   0.145104  |    0.095536     |   0\n",
      "      33695 |   0.048105  |    0.017559     |   2\n",
      "      33696 |   0.201172  |    0.312142     |   1\n",
      "      33697 |   0.028143  |    0.104539     |   2\n",
      "      33698 |   0.219430  |    0.075066     |   0\n",
      "      33699 |   0.174028  |    0.089915     |   0\n",
      "      33700 |   0.051001  |    0.093005     |   2\n",
      "      33701 |   0.220594  |    0.165436     |   0\n",
      "      33702 |   0.183523  |    0.174414     |   1\n",
      "      33703 |   0.037774  |    0.090532     |   2\n",
      "      33704 |   0.127123  |    0.047720     |   0\n",
      "      33705 |   0.211928  |    0.313882     |   1\n",
      "      33706 |   0.234591  |    0.021458     |   0\n",
      "      33707 |   0.013044  |    0.090114     |   2\n",
      "      33708 |   0.029532  |    0.102153     |   2\n",
      "      33709 |   0.025242  |    0.070867     |   2\n",
      "      33710 |   0.000013  |    0.037704     |   2\n",
      "      33711 |   0.223148  |    0.148449     |   0\n",
      "      33712 |   0.000013  |    0.012709     |   2\n",
      "      33713 |   0.000013  |    0.090258     |   2\n",
      "      33714 |   0.000013  |    0.073948     |   2\n",
      "      33715 |   0.148162  |    0.023441     |   0\n",
      "      33716 |   0.189066  |    0.077193     |   0\n",
      "      33717 |   0.182699  |    0.284160     |   1\n",
      "      33718 |   0.000013  |    0.008448     |   2\n",
      "      33719 |   0.155721  |    0.126828     |   0\n",
      "      33720 |   0.149593  |    0.069404     |   0\n",
      "      33721 |   0.134905  |    0.065207     |   0\n",
      "      33722 |   0.138305  |    0.091561     |   0\n",
      "      33723 |   0.134066  |    0.185153     |   1\n",
      "      33724 |   0.204718  |    0.285177     |   1\n",
      "      33725 |   0.180494  |    0.064931     |   0\n",
      "      33726 |   0.161164  |    0.138813     |   0\n",
      "      33727 |   0.173311  |    0.051934     |   0\n",
      "      33728 |   0.143662  |    0.320601     |   1\n",
      "      33729 |   0.177261  |    0.087869     |   0\n",
      "      33730 |   0.000013  |    0.074755     |   2\n",
      "      33731 |   0.042773  |    0.126893     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 33733: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      33732 |   0.041183  |    0.024120     |   2\n",
      "      33733 |   0.118415  |    0.109717     |   0\n",
      "      33734 |   0.038217  |    0.073006     |   2\n",
      "      33735 |   0.199401  |    0.105583     |   0\n",
      "      33736 |   0.152446  |    0.243747     |   1\n",
      "      33737 |   0.026288  |    0.030700     |   2\n",
      "      33738 |   0.031434  |    0.081047     |   2\n",
      "      33739 |   0.032636  |    0.064395     |   2\n",
      "      33740 |   0.022953  |    0.072482     |   2\n",
      "      33741 |   0.199297  |    0.121520     |   0\n",
      "      33742 |   0.030468  |    0.085617     |   2\n",
      "      33743 |   0.046763  |    0.132150     |   2\n",
      "      33744 |   0.153318  |    0.297706     |   1\n",
      "      33745 |   0.166238  |    0.004907     |   0\n",
      "      33746 |   0.042564  |    0.146947     |   2\n",
      "      33747 |   0.191417  |    0.043365     |   0\n",
      "      33748 |   0.188843  |    0.238054     |   1\n",
      "      33749 |   0.180542  |    0.307385     |   1\n",
      "      33750 |   0.161881  |    0.236025     |   1\n",
      "      33751 |   0.162316  |    0.112501     |   0\n",
      "      33752 |   0.142968  |    0.270584     |   1\n",
      "      33753 |   0.035338  |    0.007046     |   2\n",
      "      33754 |   0.203821  |    0.159886     |   0\n",
      "      33755 |   0.016319  |    0.040440     |   2\n",
      "      33756 |   0.182455  |    0.344410     |   1\n",
      "      33757 |   0.159625  |    0.428492     |   1\n",
      "      33758 |   0.000013  |    0.020586     |   2\n",
      "      33759 |   0.003938  |    0.106466     |   2\n",
      "      33760 |   0.141815  |    0.050150     |   0\n",
      "      33761 |   0.048597  |    0.073915     |   2\n",
      "      33762 |   0.205608  |    0.127641     |   0\n",
      "      33763 |   0.156811  |    0.086170     |   0\n",
      "      33764 |   0.167673  |    0.089795     |   0\n",
      "      33765 |   0.028906  |    0.037910     |   2\n",
      "      33766 |   0.049534  |    0.166529     |   2\n",
      "      33767 |   0.204570  |    0.304875     |   1\n",
      "      33768 |   0.194728  |    0.240938     |   1\n",
      "      33769 |   0.147143  |    0.124584     |   0\n",
      "      33770 |   0.035687  |    0.098146     |   2\n",
      "      33771 |   0.014457  |    0.150964     |   2\n",
      "      33772 |   0.117350  |    0.293112     |   1\n",
      "      33773 |   0.172587  |    0.291825     |   1\n",
      "      33774 |   0.209615  |    0.540071     |   1\n",
      "      33775 |   0.030680  |    0.078403     |   2\n",
      "      33776 |   0.196607  |    0.466867     |   1\n",
      "      33777 |   0.169423  |    0.474814     |   1\n",
      "      33778 |   0.022389  |    0.159204     |   2\n",
      "      33779 |   0.000013  |    0.094038     |   2\n",
      "      33780 |   0.000013  |    0.068287     |   2\n",
      "      33781 |   0.173015  |    0.114336     |   0\n",
      "      33782 |   0.149472  |    0.068853     |   0\n",
      "      33783 |   0.000013  |    0.123327     |   2\n",
      "      33784 |   0.162376  |    0.154830     |   0\n",
      "      33785 |   0.128770  |    0.307762     |   1\n",
      "      33786 |   0.000013  |    0.122912     |   2\n",
      "      33787 |   0.000013  |    0.071634     |   2\n",
      "      33788 |   0.000013  |    0.056759     |   2\n",
      "      33789 |   0.171450  |    0.124815     |   0\n",
      "      33790 |   0.156281  |    0.229268     |   1\n",
      "      33791 |   0.190355  |    0.042464     |   0\n",
      "      33792 |   0.037939  |    0.092911     |   2\n",
      "      33793 |   0.039819  |    0.037466     |   2\n",
      "      33794 |   0.190713  |    0.089605     |   0\n",
      "      33795 |   0.190023  |    0.050979     |   0\n",
      "      33796 |   0.186144  |    0.064011     |   0\n",
      "      33797 |   0.136110  |    0.119980     |   0\n",
      "      33798 |   0.194911  |    0.183834     |   1\n",
      "      33799 |   0.156484  |    0.205809     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 33800: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      33800 |   0.155786  |    0.263184     |   1\n",
      "      33801 |   0.170537  |    0.011886     |   0\n",
      "      33802 |   0.037202  |    0.156385     |   2\n",
      "      33803 |   0.028020  |    0.007309     |   2\n",
      "      33804 |   0.145462  |    0.081033     |   0\n",
      "      33805 |   0.031116  |    0.088905     |   2\n",
      "      33806 |   0.166561  |    0.212045     |   1\n",
      "      33807 |   0.167633  |    0.263130     |   1\n",
      "      33808 |   0.157406  |    0.227663     |   1\n",
      "      33809 |   0.131633  |    0.221396     |   1\n",
      "      33810 |   0.029701  |    0.073516     |   2\n",
      "      33811 |   0.022207  |    0.044078     |   2\n",
      "      33812 |   0.143137  |    0.270362     |   1\n",
      "      33813 |   0.029598  |    0.015667     |   2\n",
      "      33814 |   0.181388  |    0.116500     |   0\n",
      "      33815 |   0.153091  |    0.022514     |   0\n",
      "      33816 |   0.148653  |    0.266008     |   1\n",
      "      33817 |   0.044226  |    0.088308     |   2\n",
      "      33818 |   0.040916  |    0.045528     |   2\n",
      "      33819 |   0.034349  |    0.097010     |   2\n",
      "      33820 |   0.170392  |    0.035980     |   0\n",
      "      33821 |   0.175079  |    0.165267     |   1\n",
      "      33822 |   0.015505  |    0.100669     |   2\n",
      "      33823 |   0.195908  |    0.201766     |   1\n",
      "      33824 |   0.140431  |    0.211988     |   1\n",
      "      33825 |   0.173609  |    0.056741     |   0\n",
      "      33826 |   0.000013  |    0.103920     |   2\n",
      "      33827 |   0.004110  |    0.005972     |   2\n",
      "      33828 |   0.188983  |    0.155385     |   0\n",
      "      33829 |   0.133116  |    0.222933     |   1\n",
      "      33830 |   0.155929  |    0.224408     |   1\n",
      "      33831 |   0.052296  |    0.051654     |   2\n",
      "      33832 |   0.154201  |    0.221901     |   1\n",
      "      33833 |   0.029226  |    0.072392     |   2\n",
      "      33834 |   0.185300  |    0.239795     |   1\n",
      "      33835 |   0.049575  |    0.053948     |   2\n",
      "      33836 |   0.160622  |    0.228488     |   1\n",
      "      33837 |   0.035066  |    0.050096     |   2\n",
      "      33838 |   0.159306  |    0.072986     |   0\n",
      "      33839 |   0.150379  |    0.032099     |   0\n",
      "      33840 |   0.158257  |    0.258140     |   1\n",
      "      33841 |   0.209776  |    0.291520     |   1\n",
      "      33842 |   0.013350  |    0.033927     |   2\n",
      "      33843 |   0.192703  |    0.254566     |   1\n",
      "      33844 |   0.030335  |    0.088433     |   2\n",
      "      33845 |   0.171589  |    0.070428     |   0\n",
      "      33846 |   0.155398  |    0.055632     |   0\n",
      "      33847 |   0.022889  |    0.094672     |   2\n",
      "      33848 |   0.148481  |    0.023530     |   0\n",
      "      33849 |   0.175504  |    0.228499     |   1\n",
      "      33850 |   0.140839  |    0.252089     |   1\n",
      "      33851 |   0.208935  |    0.195557     |   1\n",
      "      33852 |   0.201973  |    0.075156     |   0\n",
      "      33853 |   0.159100  |    0.105632     |   0\n",
      "      33854 |   0.221851  |    0.236634     |   1\n",
      "      33855 |   0.149380  |    0.014659     |   0\n",
      "      33856 |   0.158068  |    0.067044     |   0\n",
      "      33857 |   0.197474  |    0.269997     |   1\n",
      "      33858 |   0.167525  |    0.108049     |   1\n",
      "      33859 |   0.157291  |    0.117886     |   0\n",
      "      33860 |   0.000013  |    0.048719     |   2\n",
      "      33861 |   0.173992  |    0.020820     |   0\n",
      "      33862 |   0.138092  |    0.288961     |   1\n",
      "      33863 |   0.212782  |    0.098442     |   0\n",
      "      33864 |   0.137953  |    0.050300     |   0\n",
      "      33865 |   0.000013  |    0.059574     |   2\n",
      "      33866 |   0.153862  |    0.149111     |   0\n",
      "      33867 |   0.191688  |    0.010059     |   0\n",
      "      33868 |   0.000013  |    0.048868     |   2\n",
      "      33869 |   0.119447  |    0.095184     |   0\n",
      "      33870 |   0.163710  |    0.283021     |   1\n",
      "      33871 |   0.170382  |    0.005697     |   0\n",
      "      33872 |   0.151758  |    0.269018     |   1\n",
      "      33873 |   0.000013  |    0.068587     |   2\n",
      "      33874 |   0.156670  |    0.225013     |   1\n",
      "      33875 |   0.135701  |    0.067081     |   0\n",
      "      33876 |   0.150671  |    0.241405     |   1\n",
      "      33877 |   0.146678  |    0.074903     |   0\n",
      "      33878 |   0.209515  |    0.301456     |   1\n",
      "      33879 |   0.142248  |    0.007065     |   0\n",
      "      33880 |   0.173467  |    0.277093     |   1\n",
      "      33881 |   0.228982  |    0.283215     |   1\n",
      "      33882 |   0.200469  |    0.185016     |   1\n",
      "      33883 |   0.161282  |    0.275553     |   1\n",
      "      33884 |   0.000013  |    0.063761     |   2\n",
      "      33885 |   0.151899  |    0.068952     |   0\n",
      "      33886 |   0.190869  |    0.082993     |   0\n",
      "      33887 |   0.181525  |    0.152532     |   1\n",
      "      33888 |   0.166828  |    0.024477     |   0\n",
      "      33889 |   0.212729  |    0.116334     |   0\n",
      "      33890 |   0.192437  |    0.227552     |   1\n",
      "      33891 |   0.000013  |    0.013496     |   2\n",
      "      33892 |   0.037326  |    0.109659     |   2\n",
      "      33893 |   0.182543  |    0.031122     |   0\n",
      "      33894 |   0.040033  |    0.051320     |   2\n",
      "      33895 |   0.145597  |    0.122041     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 33896: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      33896 |   0.172844  |    0.180372     |   1\n",
      "      33897 |   0.202250  |    0.179830     |   1\n",
      "      33898 |   0.155361  |    0.038985     |   0\n",
      "      33899 |   0.164559  |    0.263093     |   1\n",
      "      33900 |   0.177667  |    0.060810     |   0\n",
      "      33901 |   0.157530  |    0.239054     |   1\n",
      "      33902 |   0.141384  |    0.006460     |   0\n",
      "      33903 |   0.037375  |    0.082788     |   2\n",
      "      33904 |   0.208902  |    0.216529     |   1\n",
      "      33905 |   0.025977  |    0.044018     |   2\n",
      "      33906 |   0.167289  |    0.263333     |   1\n",
      "      33907 |   0.181338  |    0.282153     |   1\n",
      "      33908 |   0.032212  |    0.039238     |   2\n",
      "      33909 |   0.030960  |    0.085360     |   2\n",
      "      33910 |   0.147171  |    0.217848     |   1\n",
      "      33911 |   0.207262  |    0.345802     |   1\n",
      "      33912 |   0.021813  |    0.007874     |   2\n",
      "      33913 |   0.027601  |    0.073310     |   2\n",
      "      33914 |   0.214245  |    0.292989     |   1\n",
      "      33915 |   0.041313  |    0.021646     |   2\n",
      "      33916 |   0.185830  |    0.235309     |   1\n",
      "      33917 |   0.167754  |    0.051922     |   0\n",
      "      33918 |   0.178655  |    0.069566     |   0\n",
      "      33919 |   0.157533  |    0.022757     |   0\n",
      "      33920 |   0.132009  |    0.117837     |   0\n",
      "      33921 |   0.232046  |    0.092678     |   0\n",
      "      33922 |   0.239376  |    0.043500     |   0\n",
      "      33923 |   0.215537  |    0.085104     |   0\n",
      "      33924 |   0.039043  |    0.092267     |   2\n",
      "      33925 |   0.034951  |    0.011109     |   2\n",
      "      33926 |   0.169848  |    0.282129     |   1\n",
      "      33927 |   0.016932  |    0.035202     |   2\n",
      "      33928 |   0.000013  |    0.140916     |   2\n",
      "      33929 |   0.004023  |    0.007371     |   2\n",
      "      33930 |   0.050990  |    0.083173     |   2\n",
      "      33931 |   0.028124  |    0.068306     |   2\n",
      "      33932 |   0.166184  |    0.269686     |   1\n",
      "      33933 |   0.203397  |    0.027251     |   0\n",
      "      33934 |   0.160059  |    0.072733     |   0\n",
      "      33935 |   0.214953  |    0.209057     |   1\n",
      "      33936 |   0.050677  |    0.064651     |   2\n",
      "      33937 |   0.036517  |    0.077834     |   2\n",
      "      33938 |   0.166443  |    0.292048     |   1\n",
      "      33939 |   0.015102  |    0.055242     |   2\n",
      "      33940 |   0.029099  |    0.045061     |   2\n",
      "      33941 |   0.163647  |    0.086075     |   0\n",
      "      33942 |   0.169304  |    0.232899     |   1\n",
      "      33943 |   0.022211  |    0.019012     |   2\n",
      "      33944 |   0.163277  |    0.270848     |   1\n",
      "      33945 |   0.143810  |    0.183513     |   1\n",
      "      33946 |   0.178547  |    0.236106     |   1\n",
      "      33947 |   0.204183  |    0.307735     |   1\n",
      "      33948 |   0.164289  |    0.065473     |   0\n",
      "      33949 |   0.143866  |    0.248318     |   1\n",
      "      33950 |   0.140179  |    0.174313     |   1\n",
      "      33951 |   0.167766  |    0.039413     |   0\n",
      "      33952 |   0.000013  |    0.115226     |   2\n",
      "      33953 |   0.000013  |    0.092842     |   2\n",
      "      33954 |   0.000013  |    0.171870     |   2\n",
      "      33955 |   0.209198  |    0.288817     |   1\n",
      "      33956 |   0.224548  |    0.482302     |   1\n",
      "      33957 |   0.000013  |    0.007494     |   2\n",
      "      33958 |   0.140468  |    0.207551     |   0\n",
      "      33959 |   0.000013  |    0.090322     |   2\n",
      "      33960 |   0.000013  |    0.068861     |   2\n",
      "      33961 |   0.039891  |    0.127093     |   2\n",
      "      33962 |   0.040430  |    0.065692     |   2\n",
      "      33963 |   0.187005  |    0.096644     |   0\n",
      "      33964 |   0.166205  |    0.400401     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 33965: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      33965 |   0.042091  |    0.147248     |   2\n",
      "      33966 |   0.154089  |    0.469985     |   1\n",
      "      33967 |   0.127867  |    0.021020     |   0\n",
      "      33968 |   0.026242  |    0.191138     |   2\n",
      "      33969 |   0.106158  |    0.009682     |   0\n",
      "      33970 |   0.200588  |    0.230386     |   1\n",
      "      33971 |   0.189158  |    0.065243     |   0\n",
      "      33972 |   0.157472  |    0.061244     |   0\n",
      "      33973 |   0.032546  |    0.111861     |   2\n",
      "      33974 |   0.136819  |    0.046896     |   0\n",
      "      33975 |   0.137842  |    0.318410     |   1\n",
      "      33976 |   0.177629  |    0.311357     |   1\n",
      "      33977 |   0.147460  |    0.067131     |   0\n",
      "      33978 |   0.222414  |    0.229142     |   1\n",
      "      33979 |   0.167235  |    0.079043     |   0\n",
      "      33980 |   0.169890  |    0.281798     |   1\n",
      "      33981 |   0.173936  |    0.290796     |   1\n",
      "      33982 |   0.211214  |    0.261896     |   1\n",
      "      33983 |   0.169306  |    0.086818     |   0\n",
      "      33984 |   0.175064  |    0.356569     |   1\n",
      "      33985 |   0.030581  |    0.131157     |   2\n",
      "      33986 |   0.191339  |    0.290243     |   1\n",
      "      33987 |   0.219168  |    0.276302     |   1\n",
      "      33988 |   0.177820  |    0.215339     |   1\n",
      "      33989 |   0.109976  |    0.273471     |   1\n",
      "      33990 |   0.185114  |    0.016461     |   0\n",
      "      33991 |   0.022553  |    0.091950     |   2\n",
      "      33992 |   0.156269  |    0.021674     |   0\n",
      "      33993 |   0.029191  |    0.081576     |   2\n",
      "      33994 |   0.044365  |    0.078125     |   2\n",
      "      33995 |   0.213064  |    0.273337     |   1\n",
      "      33996 |   0.201940  |    0.213503     |   1\n",
      "      33997 |   0.184319  |    0.208805     |   1\n",
      "      33998 |   0.042592  |    0.048676     |   2\n",
      "      33999 |   0.195700  |    0.276900     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 34000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 34000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      34000 |   0.184283  |    0.027085     |   0\n",
      "      34001 |   0.039866  |    0.139836     |   2\n",
      "      34002 |   0.145751  |    0.046102     |   0\n",
      "      34003 |   0.180907  |    0.208238     |   1\n",
      "      34004 |   0.164665  |    0.159223     |   1\n",
      "      34005 |   0.174836  |    0.126732     |   0\n",
      "      34006 |   0.156270  |    0.029181     |   0\n",
      "      34007 |   0.173653  |    0.042634     |   0\n",
      "      34008 |   0.175352  |    0.068795     |   0\n",
      "      34009 |   0.135298  |    0.049835     |   0\n",
      "      34010 |   0.026192  |    0.042708     |   2\n",
      "      34011 |   0.162582  |    0.113179     |   0\n",
      "      34012 |   0.187300  |    0.051915     |   0\n",
      "      34013 |   0.031339  |    0.068125     |   2\n",
      "      34014 |   0.154682  |    0.289746     |   1\n",
      "      34015 |   0.158909  |    0.005872     |   0\n",
      "      34016 |   0.192080  |    0.298228     |   1\n",
      "      34017 |   0.184849  |    0.203954     |   1\n",
      "      34018 |   0.166333  |    0.069740     |   0\n",
      "      34019 |   0.141521  |    0.232196     |   1\n",
      "      34020 |   0.029510  |    0.071080     |   2\n",
      "      34021 |   0.181010  |    0.269884     |   1\n",
      "      34022 |   0.153786  |    0.020564     |   0\n",
      "      34023 |   0.159045  |    0.109447     |   0\n",
      "      34024 |   0.130469  |    0.285243     |   1\n",
      "      34025 |   0.217744  |    0.161214     |   1\n",
      "      34026 |   0.185676  |    0.166631     |   1\n",
      "      34027 |   0.022070  |    0.126741     |   2\n",
      "      34028 |   0.124799  |    0.007076     |   0\n",
      "      34029 |   0.230855  |    0.082376     |   0\n",
      "      34030 |   0.028881  |    0.004322     |   2\n",
      "      34031 |   0.244302  |    0.098778     |   0\n",
      "      34032 |   0.042787  |    0.037187     |   2\n",
      "      34033 |   0.039147  |    0.105066     |   2\n",
      "      34034 |   0.037901  |    0.026067     |   2\n",
      "      34035 |   0.169945  |    0.075916     |   0\n",
      "      34036 |   0.018080  |    0.117180     |   2\n",
      "      34037 |   0.216992  |    0.049840     |   0\n",
      "      34038 |   0.160785  |    0.214517     |   1\n",
      "      34039 |   0.196523  |    0.034843     |   0\n",
      "      34040 |   0.136928  |    0.216350     |   1\n",
      "      34041 |   0.000013  |    0.075460     |   2\n",
      "      34042 |   0.158263  |    0.085821     |   0\n",
      "      34043 |   0.149405  |    0.147337     |   1\n",
      "      34044 |   0.146124  |    0.230552     |   1\n",
      "      34045 |   0.003845  |    0.079653     |   2\n",
      "      34046 |   0.113130  |    0.262820     |   1\n",
      "      34047 |   0.143547  |    0.174997     |   1\n",
      "      34048 |   0.145357  |    0.187819     |   1\n",
      "      34049 |   0.176993  |    0.024986     |   0\n",
      "      34050 |   0.050494  |    0.084567     |   2\n",
      "      34051 |   0.028157  |    0.051686     |   2\n",
      "      34052 |   0.138548  |    0.279055     |   1\n",
      "      34053 |   0.050942  |    0.023405     |   2\n",
      "      34054 |   0.035681  |    0.102721     |   2\n",
      "      34055 |   0.174399  |    0.022273     |   0\n",
      "      34056 |   0.013280  |    0.083552     |   2\n",
      "      34057 |   0.028061  |    0.024500     |   2\n",
      "      34058 |   0.186995  |    0.100777     |   0\n",
      "      34059 |   0.167341  |    0.036396     |   0\n",
      "      34060 |   0.159980  |    0.059406     |   0\n",
      "      34061 |   0.162780  |    0.112624     |   0\n",
      "      34062 |   0.217002  |    0.220855     |   1\n",
      "      34063 |   0.134883  |    0.229664     |   1\n",
      "      34064 |   0.201828  |    0.092783     |   0\n",
      "      34065 |   0.181510  |    0.067004     |   0\n",
      "      34066 |   0.184139  |    0.072267     |   0\n",
      "      34067 |   0.021890  |    0.067096     |   2\n",
      "      34068 |   0.000013  |    0.059638     |   2\n",
      "      34069 |   0.000013  |    0.071074     |   2\n",
      "      34070 |   0.220220  |    0.069939     |   0\n",
      "      34071 |   0.000013  |    0.066333     |   2\n",
      "      34072 |   0.178666  |    0.062270     |   0\n",
      "      34073 |   0.000013  |    0.088747     |   2\n",
      "      34074 |   0.000013  |    0.021450     |   2\n",
      "      34075 |   0.000013  |    0.060178     |   2\n",
      "      34076 |   0.038832  |    0.084158     |   2\n",
      "      34077 |   0.144147  |    0.220285     |   1\n",
      "      34078 |   0.260857  |    0.282236     |   1\n",
      "      34079 |   0.040745  |    0.004184     |   2\n",
      "      34080 |   0.159938  |    0.070405     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 34081: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      34081 |   0.178724  |    0.294744     |   1\n",
      "      34082 |   0.040514  |    0.027378     |   2\n",
      "      34083 |   0.136638  |    0.284082     |   1\n",
      "      34084 |   0.198523  |    0.064315     |   0\n",
      "      34085 |   0.231796  |    0.189629     |   1\n",
      "      34086 |   0.027201  |    0.060082     |   2\n",
      "      34087 |   0.031133  |    0.067892     |   2\n",
      "      34088 |   0.182228  |    0.060351     |   0\n",
      "      34089 |   0.028414  |    0.096460     |   2\n",
      "      34090 |   0.022102  |    0.030420     |   2\n",
      "      34091 |   0.154210  |    0.276425     |   1\n",
      "      34092 |   0.140637  |    0.063010     |   0\n",
      "      34093 |   0.198514  |    0.215637     |   1\n",
      "      34094 |   0.029686  |    0.100183     |   2\n",
      "      34095 |   0.148882  |    0.262202     |   1\n",
      "      34096 |   0.178743  |    0.007057     |   0\n",
      "      34097 |   0.041596  |    0.052824     |   2\n",
      "      34098 |   0.238898  |    0.232954     |   1\n",
      "      34099 |   0.198683  |    0.044258     |   0\n",
      "      34100 |   0.041492  |    0.039933     |   2\n",
      "      34101 |   0.035750  |    0.091268     |   2\n",
      "      34102 |   0.015822  |    0.043976     |   2\n",
      "      34103 |   0.177093  |    0.022972     |   0\n",
      "      34104 |   0.180363  |    0.095566     |   0\n",
      "      34105 |   0.000013  |    0.042163     |   2\n",
      "      34106 |   0.202128  |    0.257796     |   1\n",
      "      34107 |   0.187189  |    0.259914     |   1\n",
      "      34108 |   0.211587  |    0.053387     |   0\n",
      "      34109 |   0.173172  |    0.254302     |   1\n",
      "      34110 |   0.229640  |    0.179355     |   1\n",
      "      34111 |   0.170665  |    0.064640     |   0\n",
      "      34112 |   0.003559  |    0.099474     |   2\n",
      "      34113 |   0.049337  |    0.008305     |   2\n",
      "      34114 |   0.193143  |    0.257113     |   1\n",
      "      34115 |   0.028780  |    0.022791     |   2\n",
      "      34116 |   0.213961  |    0.224528     |   1\n",
      "      34117 |   0.184050  |    0.044689     |   0\n",
      "      34118 |   0.177040  |    0.077437     |   0\n",
      "      34119 |   0.214649  |    0.013367     |   0\n",
      "      34120 |   0.173288  |    0.130809     |   0\n",
      "      34121 |   0.144388  |    0.253308     |   1\n",
      "      34122 |   0.194223  |    0.207899     |   1\n",
      "      34123 |   0.157600  |    0.186398     |   1\n",
      "      34124 |   0.192803  |    0.076873     |   0\n",
      "      34125 |   0.111172  |    0.323969     |   1\n",
      "      34126 |   0.188669  |    0.198097     |   1\n",
      "      34127 |   0.185038  |    0.199712     |   1\n",
      "      34128 |   0.164266  |    0.198893     |   1\n",
      "      34129 |   0.151899  |    0.040146     |   0\n",
      "      34130 |   0.179868  |    0.081274     |   0\n",
      "      34131 |   0.146164  |    0.075823     |   0\n",
      "      34132 |   0.180174  |    0.242664     |   1\n",
      "      34133 |   0.155666  |    0.153901     |   1\n",
      "      34134 |   0.189628  |    0.270821     |   1\n",
      "      34135 |   0.049266  |    0.004359     |   2\n",
      "      34136 |   0.249206  |    0.101093     |   0\n",
      "      34137 |   0.170155  |    0.040721     |   0\n",
      "      34138 |   0.034164  |    0.073489     |   2\n",
      "      34139 |   0.231723  |    0.269840     |   1\n",
      "      34140 |   0.172343  |    0.010191     |   0\n",
      "      34141 |   0.178153  |    0.144525     |   0\n",
      "      34142 |   0.165195  |    0.191536     |   1\n",
      "      34143 |   0.171768  |    0.010468     |   0\n",
      "      34144 |   0.012795  |    0.074337     |   2\n",
      "      34145 |   0.030567  |    0.062980     |   2\n",
      "      34146 |   0.020402  |    0.092563     |   2\n",
      "      34147 |   0.185328  |    0.214125     |   1\n",
      "      34148 |   0.169488  |    0.042988     |   0\n",
      "      34149 |   0.165649  |    0.050236     |   0\n",
      "      34150 |   0.189871  |    0.052613     |   0\n",
      "      34151 |   0.145440  |    0.177757     |   1\n",
      "      34152 |   0.158143  |    0.051358     |   0\n",
      "      34153 |   0.173994  |    0.226662     |   1\n",
      "      34154 |   0.000013  |    0.131965     |   2\n",
      "      34155 |   0.224078  |    0.172330     |   1\n",
      "      34156 |   0.000013  |    0.069576     |   2\n",
      "      34157 |   0.172644  |    0.077644     |   0\n",
      "      34158 |   0.000013  |    0.066229     |   2\n",
      "      34159 |   0.124212  |    0.068441     |   0\n",
      "      34160 |   0.113488  |    0.045978     |   0\n",
      "      34161 |   0.177110  |    0.233715     |   1\n",
      "      34162 |   0.150942  |    0.240489     |   1\n",
      "      34163 |   0.194863  |    0.029458     |   0\n",
      "      34164 |   0.173555  |    0.185836     |   1\n",
      "      34165 |   0.000013  |    0.115357     |   2\n",
      "      34166 |   0.145770  |    0.067579     |   0\n",
      "      34167 |   0.000013  |    0.008510     |   2\n",
      "      34168 |   0.174876  |    0.292874     |   1\n",
      "      34169 |   0.000013  |    0.050363     |   2\n",
      "      34170 |   0.182931  |    0.211726     |   1\n",
      "      34171 |   0.183351  |    0.057843     |   0\n",
      "      34172 |   0.038483  |    0.074564     |   2\n",
      "      34173 |   0.137381  |    0.093186     |   0\n",
      "      34174 |   0.180409  |    0.047636     |   0\n",
      "      34175 |   0.039331  |    0.100510     |   2\n",
      "      34176 |   0.156914  |    0.205886     |   1\n",
      "      34177 |   0.166184  |    0.030794     |   0\n",
      "      34178 |   0.150157  |    0.105210     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 34179: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      34179 |   0.040310  |    0.044853     |   2\n",
      "      34180 |   0.141357  |    0.244323     |   1\n",
      "      34181 |   0.167474  |    0.027781     |   0\n",
      "      34182 |   0.177819  |    0.283963     |   1\n",
      "      34183 |   0.159803  |    0.226734     |   1\n",
      "      34184 |   0.027095  |    0.025548     |   2\n",
      "      34185 |   0.031240  |    0.079161     |   2\n",
      "      34186 |   0.161413  |    0.042828     |   0\n",
      "      34187 |   0.032366  |    0.091069     |   2\n",
      "      34188 |   0.149780  |    0.179409     |   1\n",
      "      34189 |   0.022152  |    0.075497     |   2\n",
      "      34190 |   0.125221  |    0.062222     |   0\n",
      "      34191 |   0.158782  |    0.061006     |   0\n",
      "      34192 |   0.172976  |    0.204994     |   1\n",
      "      34193 |   0.095108  |    0.061456     |   0\n",
      "      34194 |   0.030290  |    0.060832     |   2\n",
      "      34195 |   0.168856  |    0.236580     |   1\n",
      "      34196 |   0.170224  |    0.273710     |   1\n",
      "      34197 |   0.044124  |    0.027737     |   2\n",
      "      34198 |   0.157380  |    0.077191     |   0\n",
      "      34199 |   0.039899  |    0.075064     |   2\n",
      "      34200 |   0.123161  |    0.277662     |   1\n",
      "      34201 |   0.135516  |    0.020204     |   0\n",
      "      34202 |   0.163055  |    0.298441     |   1\n",
      "      34203 |   0.195188  |    0.275854     |   1\n",
      "      34204 |   0.037878  |    0.006698     |   2\n",
      "      34205 |   0.018783  |    0.092596     |   2\n",
      "      34206 |   0.131560  |    0.052355     |   0\n",
      "      34207 |   0.179247  |    0.214178     |   1\n",
      "      34208 |   0.000013  |    0.013134     |   2\n",
      "      34209 |   0.004022  |    0.105732     |   2\n",
      "      34210 |   0.049250  |    0.023845     |   2\n",
      "      34211 |   0.170594  |    0.115891     |   0\n",
      "      34212 |   0.210156  |    0.198938     |   1\n",
      "      34213 |   0.029066  |    0.088194     |   2\n",
      "      34214 |   0.197902  |    0.186356     |   1\n",
      "      34215 |   0.150085  |    0.350761     |   1\n",
      "      34216 |   0.048972  |    0.014690     |   2\n",
      "      34217 |   0.177501  |    0.285690     |   1\n",
      "      34218 |   0.032052  |    0.007267     |   2\n",
      "      34219 |   0.011672  |    0.098725     |   2\n",
      "      34220 |   0.239142  |    0.209858     |   1\n",
      "      34221 |   0.310121  |    0.050086     |   0\n",
      "      34222 |   0.122607  |    0.070378     |   0\n",
      "      34223 |   0.133962  |    0.041794     |   0\n",
      "      34224 |   0.179135  |    0.075686     |   0\n",
      "      34225 |   0.028771  |    0.043930     |   2\n",
      "      34226 |   0.206006  |    0.049276     |   0\n",
      "      34227 |   0.164022  |    0.259382     |   1\n",
      "      34228 |   0.021856  |    0.066645     |   2\n",
      "      34229 |   0.143337  |    0.096086     |   0\n",
      "      34230 |   0.000013  |    0.071295     |   2\n",
      "      34231 |   0.000013  |    0.061541     |   2\n",
      "      34232 |   0.000013  |    0.125072     |   2\n",
      "      34233 |   0.165775  |    0.195480     |   1\n",
      "      34234 |   0.165141  |    0.008997     |   0\n",
      "      34235 |   0.160191  |    0.259140     |   1\n",
      "      34236 |   0.146765  |    0.270535     |   1\n",
      "      34237 |   0.163621  |    0.172100     |   1\n",
      "      34238 |   0.000013  |    0.045257     |   2\n",
      "      34239 |   0.161382  |    0.212998     |   1\n",
      "      34240 |   0.000013  |    0.066421     |   2\n",
      "      34241 |   0.121579  |    0.244583     |   1\n",
      "      34242 |   0.151755  |    0.210962     |   1\n",
      "      34243 |   0.158856  |    0.088171     |   0\n",
      "      34244 |   0.000013  |    0.020625     |   2\n",
      "      34245 |   0.196933  |    0.279848     |   1\n",
      "      34246 |   0.038355  |    0.077525     |   2\n",
      "      34247 |   0.039646  |    0.139344     |   2\n",
      "      34248 |   0.221449  |    0.155336     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 34249: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      34249 |   0.037629  |    0.011035     |   2\n",
      "      34250 |   0.233820  |    0.100161     |   0\n",
      "      34251 |   0.025977  |    0.039163     |   2\n",
      "      34252 |   0.189774  |    0.128234     |   0\n",
      "      34253 |   0.195063  |    0.144018     |   0\n",
      "      34254 |   0.031161  |    0.099023     |   2\n",
      "      34255 |   0.029586  |    0.215375     |   2\n",
      "      34256 |   0.022667  |    0.249901     |   2\n",
      "      34257 |   0.140946  |    0.681729     |   1\n",
      "      34258 |   0.164682  |    0.350082     |   1\n",
      "      34259 |   0.138470  |    0.065291     |   0\n",
      "      34260 |   0.142005  |    0.067939     |   0\n",
      "      34261 |   0.155017  |    0.100566     |   0\n",
      "      34262 |   0.165949  |    0.438588     |   1\n",
      "      34263 |   0.174387  |    0.413960     |   1\n",
      "      34264 |   0.030942  |    0.086456     |   2\n",
      "      34265 |   0.042437  |    0.136779     |   2\n",
      "      34266 |   0.148007  |    0.541181     |   1\n",
      "      34267 |   0.221645  |    0.102139     |   0\n",
      "      34268 |   0.042997  |    0.085236     |   2\n",
      "      34269 |   0.171061  |    0.400049     |   1\n",
      "      34270 |   0.143995  |    0.474802     |   1\n",
      "      34271 |   0.198736  |    0.422300     |   1\n",
      "      34272 |   0.167053  |    0.400686     |   1\n",
      "      34273 |   0.038938  |    0.121052     |   2\n",
      "      34274 |   0.170578  |    0.145381     |   0\n",
      "      34275 |   0.017337  |    0.145163     |   2\n",
      "      34276 |   0.170527  |    0.059162     |   0\n",
      "      34277 |   0.221543  |    0.447426     |   1\n",
      "      34278 |   0.000012  |    0.075879     |   2\n",
      "      34279 |   0.202587  |    0.422657     |   1\n",
      "      34280 |   0.131760  |    0.442376     |   1\n",
      "      34281 |   0.137679  |    0.069173     |   0\n",
      "      34282 |   0.180201  |    0.086120     |   0\n",
      "      34283 |   0.149291  |    0.451558     |   1\n",
      "      34284 |   0.137255  |    0.064400     |   0\n",
      "      34285 |   0.004201  |    0.118751     |   2\n",
      "      34286 |   0.051062  |    0.128385     |   2\n",
      "      34287 |   0.218939  |    0.407049     |   1\n",
      "      34288 |   0.031013  |    0.095577     |   2\n",
      "      34289 |   0.050289  |    0.040406     |   2\n",
      "      34290 |   0.237930  |    0.291316     |   1\n",
      "      34291 |   0.036123  |    0.080480     |   2\n",
      "      34292 |   0.283014  |    0.098535     |   0\n",
      "      34293 |   0.184762  |    0.119800     |   0\n",
      "      34294 |   0.010806  |    0.099200     |   2\n",
      "      34295 |   0.191625  |    0.268068     |   1\n",
      "      34296 |   0.144780  |    0.066939     |   0\n",
      "      34297 |   0.174562  |    0.362521     |   1\n",
      "      34298 |   0.151174  |    0.311448     |   1\n",
      "      34299 |   0.182537  |    0.032551     |   0\n",
      "      34300 |   0.030626  |    0.110896     |   2\n",
      "      34301 |   0.165354  |    0.076176     |   0\n",
      "      34302 |   0.020268  |    0.052712     |   2\n",
      "      34303 |   0.000012  |    0.092035     |   2\n",
      "      34304 |   0.190890  |    0.342313     |   1\n",
      "      34305 |   0.153542  |    0.139297     |   0\n",
      "      34306 |   0.000012  |    0.024567     |   2\n",
      "      34307 |   0.224954  |    0.283931     |   1\n",
      "      34308 |   0.181347  |    0.026308     |   0\n",
      "      34309 |   0.174014  |    0.352402     |   1\n",
      "      34310 |   0.193999  |    0.060952     |   0\n",
      "      34311 |   0.000012  |    0.018221     |   2\n",
      "      34312 |   0.171638  |    0.077233     |   0\n",
      "      34313 |   0.000012  |    0.096519     |   2\n",
      "      34314 |   0.000012  |    0.026953     |   2\n",
      "      34315 |   0.159910  |    0.077294     |   0\n",
      "      34316 |   0.000012  |    0.083882     |   2\n",
      "      34317 |   0.039640  |    0.157290     |   2\n",
      "      34318 |   0.040573  |    0.020175     |   2\n",
      "      34319 |   0.180912  |    0.386599     |   1\n",
      "      34320 |   0.204448  |    0.154096     |   0\n",
      "      34321 |   0.146325  |    0.037928     |   0\n",
      "      34322 |   0.149402  |    0.324736     |   1\n",
      "      34323 |   0.146404  |    0.088019     |   0\n",
      "      34324 |   0.151194  |    0.026555     |   0\n",
      "      34325 |   0.172545  |    0.046646     |   0\n",
      "      34326 |   0.122973  |    0.069485     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 34327: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      34327 |   0.118333  |    0.275513     |   1\n",
      "      34328 |   0.167256  |    0.091150     |   0\n",
      "      34329 |   0.170644  |    0.196818     |   1\n",
      "      34330 |   0.206679  |    0.029167     |   0\n",
      "      34331 |   0.127753  |    0.288008     |   1\n",
      "      34332 |   0.038234  |    0.091848     |   2\n",
      "      34333 |   0.165295  |    0.405893     |   1\n",
      "      34334 |   0.194295  |    0.350603     |   1\n",
      "      34335 |   0.027153  |    0.165858     |   2\n",
      "      34336 |   0.175105  |    0.297220     |   1\n",
      "      34337 |   0.198331  |    0.378752     |   1\n",
      "      34338 |   0.181474  |    0.133275     |   0\n",
      "      34339 |   0.173636  |    0.386134     |   1\n",
      "      34340 |   0.249313  |    0.349146     |   1\n",
      "      34341 |   0.151995  |    0.078070     |   0\n",
      "      34342 |   0.030851  |    0.149322     |   2\n",
      "      34343 |   0.188687  |    0.288032     |   1\n",
      "      34344 |   0.192184  |    0.314918     |   1\n",
      "      34345 |   0.198846  |    0.338767     |   1\n",
      "      34346 |   0.028936  |    0.051717     |   2\n",
      "      34347 |   0.160876  |    0.131042     |   0\n",
      "      34348 |   0.166373  |    0.179374     |   1\n",
      "      34349 |   0.156421  |    0.290994     |   1\n",
      "      34350 |   0.145728  |    0.470208     |   1\n",
      "      34351 |   0.114038  |    0.477570     |   1\n",
      "      34352 |   0.181244  |    0.153917     |   0\n",
      "      34353 |   0.185212  |    0.066352     |   0\n",
      "      34354 |   0.146633  |    0.505561     |   1\n",
      "      34355 |   0.224680  |    0.392032     |   1\n",
      "      34356 |   0.159031  |    0.458269     |   1\n",
      "      34357 |   0.173166  |    0.022850     |   0\n",
      "      34358 |   0.126560  |    0.079295     |   0\n",
      "      34359 |   0.202295  |    0.139712     |   0\n",
      "      34360 |   0.178594  |    0.389349     |   1\n",
      "      34361 |   0.136457  |    0.068856     |   0\n",
      "      34362 |   0.196421  |    0.259657     |   1\n",
      "      34363 |   0.022956  |    0.127954     |   2\n",
      "      34364 |   0.187413  |    0.065863     |   0\n",
      "      34365 |   0.155612  |    0.078710     |   0\n",
      "      34366 |   0.146886  |    0.088961     |   0\n",
      "      34367 |   0.030459  |    0.069829     |   2\n",
      "      34368 |   0.211220  |    0.081418     |   0\n",
      "      34369 |   0.045961  |    0.069606     |   2\n",
      "      34370 |   0.116836  |    0.460452     |   1\n",
      "      34371 |   0.153714  |    0.339435     |   1\n",
      "      34372 |   0.042011  |    0.067684     |   2\n",
      "      34373 |   0.185243  |    0.344789     |   1\n",
      "      34374 |   0.158401  |    0.091145     |   0\n",
      "      34375 |   0.037841  |    0.144537     |   2\n",
      "      34376 |   0.174808  |    0.069042     |   0\n",
      "      34377 |   0.153464  |    0.102003     |   0\n",
      "      34378 |   0.017486  |    0.069440     |   2\n",
      "      34379 | \u001b[94m  0.000012\u001b[0m  |    0.131305     |   2\n",
      "      34380 |   0.205598  |    0.310342     |   1\n",
      "      34381 |   0.150893  |    0.121240     |   0\n",
      "      34382 |   0.185464  |    0.386920     |   1\n",
      "      34383 |   0.159753  |    0.073161     |   0\n",
      "      34384 |   0.255257  |    0.321046     |   1\n",
      "      34385 |   0.003804  |    0.084192     |   2\n",
      "      34386 |   0.137312  |    0.296595     |   1\n",
      "      34387 |   0.191305  |    0.165703     |   0\n",
      "      34388 |   0.141176  |    0.018806     |   0\n",
      "      34389 |   0.149449  |    0.159843     |   0\n",
      "      34390 |   0.146697  |    0.315881     |   1\n",
      "      34391 |   0.201744  |    0.326112     |   1\n",
      "      34392 |   0.166783  |    0.328061     |   1\n",
      "      34393 |   0.051966  |    0.065316     |   2\n",
      "      34394 |   0.030674  |    0.140001     |   2\n",
      "      34395 |   0.196830  |    0.053952     |   0\n",
      "      34396 |   0.140650  |    0.383487     |   1\n",
      "      34397 |   0.216540  |    0.039598     |   0\n",
      "      34398 |   0.153567  |    0.175185     |   0\n",
      "      34399 |   0.156478  |    0.036576     |   0\n",
      "      34400 |   0.052924  |    0.131205     |   2\n",
      "      34401 |   0.150009  |    0.068950     |   0\n",
      "      34402 |   0.033713  |    0.134509     |   2\n",
      "      34403 |   0.174875  |    0.072575     |   0\n",
      "      34404 |   0.166782  |    0.380870     |   1\n",
      "      34405 |   0.192530  |    0.070768     |   0\n",
      "      34406 |   0.012494  |    0.074712     |   2\n",
      "      34407 |   0.032379  |    0.133422     |   2\n",
      "      34408 |   0.176726  |    0.007030     |   0\n",
      "      34409 |   0.022346  |    0.091502     |   2\n",
      "      34410 |   0.172404  |    0.258899     |   1\n",
      "      34411 |   0.191830  |    0.251298     |   1\n",
      "      34412 |   0.158465  |    0.234315     |   1\n",
      "      34413 |   0.135295  |    0.297214     |   1\n",
      "      34414 |   0.209785  |    0.008025     |   0\n",
      "      34415 |   0.164548  |    0.073150     |   0\n",
      "      34416 |   0.175544  |    0.223509     |   1\n",
      "      34417 |   0.195654  |    0.042277     |   0\n",
      "      34418 |   0.155097  |    0.054944     |   0\n",
      "      34419 |   0.152092  |    0.087327     |   0\n",
      "      34420 |   0.176066  |    0.238569     |   1\n",
      "      34421 |   0.000012  |    0.119813     |   2\n",
      "      34422 |   0.151222  |    0.222565     |   1\n",
      "      34423 |   0.000012  |    0.040346     |   2\n",
      "      34424 |   0.000012  |    0.105379     |   2\n",
      "      34425 |   0.123389  |    0.188499     |   1\n",
      "      34426 |   0.000012  |    0.028955     |   2\n",
      "      34427 |   0.195100  |    0.128787     |   0\n",
      "      34428 |   0.221976  |    0.196308     |   1\n",
      "      34429 |   0.148987  |    0.062234     |   0\n",
      "      34430 |   0.000012  |    0.065584     |   2\n",
      "      34431 |   0.224505  |    0.057165     |   0\n",
      "      34432 |   0.179646  |    0.297015     |   1\n",
      "      34433 |   0.151930  |    0.012940     |   0\n",
      "      34434 |   0.000012  |    0.073803     |   2\n",
      "      34435 |   0.037191  |    0.065780     |   2\n",
      "      34436 |   0.201041  |    0.268536     |   1\n",
      "      34437 |   0.188832  |    0.011554     |   0\n",
      "      34438 |   0.041002  |    0.083196     |   2\n",
      "      34439 |   0.195215  |    0.269370     |   1\n",
      "      34440 |   0.133072  |    0.254517     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 34441: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      34441 |   0.037249  |    0.067073     |   2\n",
      "      34442 |   0.025599  |    0.066482     |   2\n",
      "      34443 |   0.132448  |    0.051555     |   0\n",
      "      34444 |   0.031166  |    0.070166     |   2\n",
      "      34445 |   0.030410  |    0.130159     |   2\n",
      "      34446 |   0.145037  |    0.006982     |   0\n",
      "      34447 |   0.139333  |    0.059690     |   0\n",
      "      34448 |   0.021969  |    0.104336     |   2\n",
      "      34449 |   0.135528  |    0.245515     |   1\n",
      "      34450 |   0.031113  |    0.006898     |   2\n",
      "      34451 |   0.039812  |    0.119603     |   2\n",
      "      34452 |   0.043101  |    0.046005     |   2\n",
      "      34453 |   0.156368  |    0.229723     |   1\n",
      "      34454 |   0.176522  |    0.313697     |   1\n",
      "      34455 |   0.180524  |    0.193587     |   1\n",
      "      34456 |   0.233803  |    0.225285     |   1\n",
      "      34457 |   0.190420  |    0.209417     |   1\n",
      "      34458 |   0.036398  |    0.064034     |   2\n",
      "      34459 |   0.142713  |    0.054714     |   0\n",
      "      34460 |   0.016518  |    0.068899     |   2\n",
      "      34461 |   0.000012  |    0.054747     |   2\n",
      "      34462 |   0.173733  |    0.289077     |   1\n",
      "      34463 |   0.216987  |    0.171969     |   1\n",
      "      34464 |   0.151920  |    0.007081     |   0\n",
      "      34465 |   0.199273  |    0.221999     |   1\n",
      "      34466 |   0.003631  |    0.096304     |   2\n",
      "      34467 |   0.122961  |    0.201016     |   1\n",
      "      34468 |   0.050464  |    0.070884     |   2\n",
      "      34469 |   0.196798  |    0.101900     |   0\n",
      "      34470 |   0.027733  |    0.026807     |   2\n",
      "      34471 |   0.048789  |    0.117872     |   2\n",
      "      34472 |   0.034322  |    0.026251     |   2\n",
      "      34473 |   0.010365  |    0.077854     |   2\n",
      "      34474 |   0.221149  |    0.232019     |   1\n",
      "      34475 |   0.029341  |    0.017589     |   2\n",
      "      34476 |   0.154796  |    0.102825     |   0\n",
      "      34477 |   0.172493  |    0.233403     |   1\n",
      "      34478 |   0.023866  |    0.150586     |   2\n",
      "      34479 |   0.000012  |    0.005449     |   2\n",
      "      34480 | \u001b[94m  0.000012\u001b[0m  |    0.092327     |   2\n",
      "      34481 |   0.149478  |    0.053178     |   0\n",
      "      34482 |   0.220068  |    0.225027     |   1\n",
      "      34483 |   0.166400  |    0.020593     |   0\n",
      "      34484 | \u001b[94m  0.000012\u001b[0m  |    0.079550     |   2\n",
      "      34485 |   0.000012  |    0.073881     |   2\n",
      "      34486 | \u001b[94m  0.000012\u001b[0m  |    0.046494     |   2\n",
      "      34487 | \u001b[94m  0.000012\u001b[0m  |    0.041801     |   2\n",
      "      34488 |   0.165705  |    0.122510     |   0\n",
      "      34489 |   0.036868  |    0.023310     |   2\n",
      "      34490 |   0.170127  |    0.089218     |   0\n",
      "      34491 |   0.220387  |    0.225450     |   1\n",
      "      34492 |   0.039554  |    0.052735     |   2\n",
      "      34493 |   0.205830  |    0.101146     |   0\n",
      "      34494 |   0.107574  |    0.160220     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 34495: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      34495 |   0.150106  |    0.042285     |   0\n",
      "      34496 |   0.216828  |    0.232539     |   1\n",
      "      34497 |   0.037235  |    0.040312     |   2\n",
      "      34498 |   0.026506  |    0.085637     |   2\n",
      "      34499 |   0.213541  |    0.077047     |   0\n",
      "      34500 |   0.157167  |    0.253373     |   1\n",
      "      34501 |   0.143427  |    0.312746     |   1\n",
      "      34502 |   0.207676  |    0.208887     |   1\n",
      "      34503 |   0.221056  |    0.081128     |   0\n",
      "      34504 |   0.037212  |    0.033242     |   2\n",
      "      34505 |   0.025895  |    0.153120     |   2\n",
      "      34506 |   0.030491  |    0.014421     |   2\n",
      "      34507 |   0.166313  |    0.101462     |   0\n",
      "      34508 |   0.031192  |    0.029920     |   2\n",
      "      34509 |   0.173657  |    0.283810     |   1\n",
      "      34510 |   0.170320  |    0.249200     |   1\n",
      "      34511 |   0.137303  |    0.084319     |   0\n",
      "      34512 |   0.133357  |    0.217987     |   1\n",
      "      34513 |   0.200537  |    0.288938     |   1\n",
      "      34514 |   0.023107  |    0.032430     |   2\n",
      "      34515 |   0.211463  |    0.083879     |   0\n",
      "      34516 |   0.180998  |    0.216983     |   1\n",
      "      34517 |   0.155678  |    0.005816     |   0\n",
      "      34518 |   0.156262  |    0.228522     |   1\n",
      "      34519 |   0.175974  |    0.216633     |   1\n",
      "      34520 |   0.029775  |    0.011371     |   2\n",
      "      34521 |   0.192687  |    0.264916     |   1\n",
      "      34522 |   0.174342  |    0.052621     |   0\n",
      "      34523 |   0.154986  |    0.214087     |   1\n",
      "      34524 |   0.175777  |    0.087112     |   0\n",
      "      34525 |   0.044254  |    0.102049     |   2\n",
      "      34526 |   0.185788  |    0.172531     |   1\n",
      "      34527 |   0.199664  |    0.244219     |   1\n",
      "      34528 |   0.168845  |    0.116518     |   0\n",
      "      34529 |   0.045485  |    0.045979     |   2\n",
      "      34530 |   0.134037  |    0.232817     |   1\n",
      "      34531 |   0.130679  |    0.073793     |   0\n",
      "      34532 |   0.197753  |    0.262882     |   1\n",
      "      34533 |   0.159157  |    0.273669     |   1\n",
      "      34534 |   0.195267  |    0.035256     |   0\n",
      "      34535 |   0.224250  |    0.236032     |   1\n",
      "      34536 |   0.212412  |    0.160341     |   1\n",
      "      34537 |   0.159414  |    0.064954     |   0\n",
      "      34538 |   0.035957  |    0.044213     |   2\n",
      "      34539 |   0.189258  |    0.083659     |   0\n",
      "      34540 |   0.215367  |    0.203892     |   1\n",
      "      34541 |   0.201984  |    0.068259     |   0\n",
      "      34542 |   0.166774  |    0.280155     |   1\n",
      "      34543 |   0.016695  |    0.015718     |   2\n",
      "      34544 |   0.178527  |    0.283945     |   1\n",
      "      34545 | \u001b[94m  0.000012\u001b[0m  |    0.011138     |   2\n",
      "      34546 |   0.239557  |    0.282118     |   1\n",
      "      34547 |   0.173990  |    0.083272     |   0\n",
      "      34548 |   0.227343  |    0.176994     |   1\n",
      "      34549 |   0.003708  |    0.027411     |   2\n",
      "      34550 |   0.106660  |    0.072501     |   0\n",
      "      34551 |   0.052055  |    0.070043     |   2\n",
      "      34552 |   0.145302  |    0.254379     |   1\n",
      "      34553 |   0.208903  |    0.015462     |   0\n",
      "      34554 |   0.031942  |    0.123423     |   2\n",
      "      34555 |   0.052772  |    0.021374     |   2\n",
      "      34556 |   0.145971  |    0.085778     |   0\n",
      "      34557 |   0.128042  |    0.210091     |   1\n",
      "      34558 |   0.124968  |    0.293865     |   1\n",
      "      34559 |   0.215222  |    0.180524     |   1\n",
      "      34560 |   0.187690  |    0.030917     |   0\n",
      "      34561 |   0.032004  |    0.116185     |   2\n",
      "      34562 |   0.246349  |    0.220607     |   1\n",
      "      34563 |   0.244793  |    0.174229     |   1\n",
      "      34564 |   0.013476  |    0.069895     |   2\n",
      "      34565 |   0.198911  |    0.095242     |   0\n",
      "      34566 |   0.192434  |    0.174391     |   1\n",
      "      34567 |   0.030589  |    0.013651     |   2\n",
      "      34568 |   0.206109  |    0.137263     |   0\n",
      "      34569 |   0.161481  |    0.004053     |   0\n",
      "      34570 |   0.183952  |    0.319259     |   1\n",
      "      34571 |   0.177605  |    0.202754     |   1\n",
      "      34572 |   0.185844  |    0.013859     |   0\n",
      "      34573 |   0.020561  |    0.084152     |   2\n",
      "      34574 | \u001b[94m  0.000012\u001b[0m  |    0.073960     |   2\n",
      "      34575 | \u001b[94m  0.000012\u001b[0m  |    0.030891     |   2\n",
      "      34576 |   0.155653  |    0.071108     |   0\n",
      "      34577 |   0.178124  |    0.250557     |   1\n",
      "      34578 |   0.158527  |    0.009775     |   0\n",
      "      34579 |   0.155824  |    0.097493     |   0\n",
      "      34580 | \u001b[94m  0.000012\u001b[0m  |    0.035799     |   2\n",
      "      34581 |   0.000012  |    0.083129     |   2\n",
      "      34582 |   0.180005  |    0.214998     |   1\n",
      "      34583 |   0.172971  |    0.089227     |   0\n",
      "      34584 | \u001b[94m  0.000012\u001b[0m  |    0.021820     |   2\n",
      "      34585 |   0.245083  |    0.134514     |   0\n",
      "      34586 |   0.207389  |    0.270743     |   1\n",
      "      34587 |   0.184416  |    0.031236     |   0\n",
      "      34588 |   0.186986  |    0.096079     |   0\n",
      "      34589 |   0.134583  |    0.208888     |   1\n",
      "      34590 | \u001b[94m  0.000012\u001b[0m  |    0.040847     |   2\n",
      "      34591 |   0.193478  |    0.240778     |   1\n",
      "      34592 |   0.172698  |    0.027035     |   0\n",
      "      34593 |   0.180275  |    0.241020     |   1\n",
      "      34594 |   0.154922  |    0.099520     |   0\n",
      "      34595 |   0.119848  |    0.200815     |   1\n",
      "      34596 |   0.037299  |    0.077559     |   2\n",
      "      34597 |   0.040335  |    0.094771     |   2\n",
      "      34598 |   0.165896  |    0.045356     |   0\n",
      "      34599 |   0.158787  |    0.258745     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 34600: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      34600 |   0.177082  |    0.162749     |   1\n",
      "      34601 |   0.176382  |    0.206616     |   1\n",
      "      34602 |   0.038679  |    0.039712     |   2\n",
      "      34603 |   0.169691  |    0.075851     |   0\n",
      "      34604 |   0.160469  |    0.050755     |   0\n",
      "      34605 |   0.173959  |    0.077184     |   0\n",
      "      34606 |   0.027096  |    0.046394     |   2\n",
      "      34607 |   0.139980  |    0.041807     |   0\n",
      "      34608 |   0.032266  |    0.077999     |   2\n",
      "      34609 |   0.145431  |    0.228506     |   1\n",
      "      34610 |   0.031632  |    0.014072     |   2\n",
      "      34611 |   0.191058  |    0.292848     |   1\n",
      "      34612 |   0.173324  |    0.216098     |   1\n",
      "      34613 |   0.164194  |    0.096361     |   0\n",
      "      34614 |   0.189608  |    0.260432     |   1\n",
      "      34615 |   0.204681  |    0.021898     |   0\n",
      "      34616 |   0.178090  |    0.273936     |   1\n",
      "      34617 |   0.131093  |    0.162501     |   1\n",
      "      34618 |   0.022539  |    0.042910     |   2\n",
      "      34619 |   0.141599  |    0.044600     |   0\n",
      "      34620 |   0.029307  |    0.098108     |   2\n",
      "      34621 |   0.042845  |    0.023503     |   2\n",
      "      34622 |   0.043379  |    0.115969     |   2\n",
      "      34623 |   0.157836  |    0.009703     |   0\n",
      "      34624 |   0.207088  |    0.092438     |   0\n",
      "      34625 |   0.133404  |    0.046180     |   0\n",
      "      34626 |   0.034801  |    0.042180     |   2\n",
      "      34627 |   0.162243  |    0.072137     |   0\n",
      "      34628 |   0.196417  |    0.253958     |   1\n",
      "      34629 |   0.204395  |    0.195320     |   1\n",
      "      34630 |   0.171731  |    0.090349     |   0\n",
      "      34631 |   0.138916  |    0.077764     |   0\n",
      "      34632 |   0.165521  |    0.234465     |   1\n",
      "      34633 |   0.176049  |    0.074374     |   0\n",
      "      34634 |   0.170861  |    0.204156     |   1\n",
      "      34635 |   0.227239  |    0.199405     |   1\n",
      "      34636 |   0.151418  |    0.051826     |   0\n",
      "      34637 |   0.019276  |    0.091684     |   2\n",
      "      34638 |   0.229136  |    0.244882     |   1\n",
      "      34639 |   0.168811  |    0.166071     |   0\n",
      "      34640 |   0.000012  |    0.021337     |   2\n",
      "      34641 |   0.003842  |    0.198468     |   2\n",
      "      34642 |   0.131298  |    0.041024     |   0\n",
      "      34643 |   0.152259  |    0.188071     |   0\n",
      "      34644 |   0.181770  |    0.393542     |   1\n",
      "      34645 |   0.167499  |    0.369780     |   1\n",
      "      34646 |   0.048260  |    0.103639     |   2\n",
      "      34647 |   0.186615  |    0.320310     |   1\n",
      "      34648 |   0.153733  |    0.146761     |   0\n",
      "      34649 |   0.160839  |    0.091349     |   0\n",
      "      34650 |   0.131272  |    0.067446     |   0\n",
      "      34651 |   0.029549  |    0.118916     |   2\n",
      "      34652 |   0.051873  |    0.078331     |   2\n",
      "      34653 |   0.179075  |    0.391022     |   1\n",
      "      34654 |   0.184682  |    0.151619     |   0\n",
      "      34655 |   0.128508  |    0.020499     |   0\n",
      "      34656 |   0.165120  |    0.134282     |   0\n",
      "      34657 |   0.192264  |    0.071952     |   0\n",
      "      34658 |   0.132347  |    0.412600     |   1\n",
      "      34659 |   0.133136  |    0.407579     |   1\n",
      "      34660 |   0.164466  |    0.085135     |   0\n",
      "      34661 |   0.206050  |    0.467177     |   1\n",
      "      34662 |   0.036881  |    0.125092     |   2\n",
      "      34663 |   0.014578  |    0.019541     |   2\n",
      "      34664 |   0.128934  |    0.127986     |   0\n",
      "      34665 |   0.201876  |    0.382117     |   1\n",
      "      34666 |   0.032172  |    0.010391     |   2\n",
      "      34667 |   0.151533  |    0.131576     |   0\n",
      "      34668 |   0.023082  |    0.102832     |   2\n",
      "      34669 |   0.140173  |    0.214138     |   1\n",
      "      34670 |   0.197769  |    0.288498     |   1\n",
      "      34671 |   0.163849  |    0.006121     |   0\n",
      "      34672 |   0.000012  |    0.060648     |   2\n",
      "      34673 |   0.171863  |    0.256553     |   1\n",
      "      34674 |   0.000012  |    0.013866     |   2\n",
      "      34675 |   0.164341  |    0.078674     |   0\n",
      "      34676 |   0.163700  |    0.224189     |   1\n",
      "      34677 |   0.157612  |    0.240576     |   1\n",
      "      34678 |   0.186519  |    0.050024     |   0\n",
      "      34679 |   0.233217  |    0.239566     |   1\n",
      "      34680 |   0.172189  |    0.007391     |   0\n",
      "      34681 |   0.169426  |    0.124006     |   0\n",
      "      34682 |   0.000012  |    0.068619     |   2\n",
      "      34683 |   0.246426  |    0.149189     |   1\n",
      "      34684 |   0.177910  |    0.320664     |   1\n",
      "      34685 |   0.000012  |    0.011761     |   2\n",
      "      34686 |   0.164231  |    0.304204     |   1\n",
      "      34687 |   0.195006  |    0.191624     |   1\n",
      "      34688 |   0.166487  |    0.269627     |   1\n",
      "      34689 |   0.189984  |    0.099318     |   0\n",
      "      34690 |   0.261862  |    0.032753     |   0\n",
      "      34691 |   0.141068  |    0.222928     |   1\n",
      "      34692 |   0.000012  |    0.079823     |   2\n",
      "      34693 |   0.000012  |    0.047142     |   2\n",
      "      34694 |   0.162300  |    0.276850     |   1\n",
      "      34695 |   0.037780  |    0.068986     |   2\n",
      "      34696 |   0.161377  |    0.209314     |   1\n",
      "      34697 |   0.040548  |    0.097199     |   2\n",
      "      34698 |   0.155861  |    0.257299     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 34699: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      34699 |   0.127884  |    0.007998     |   0\n",
      "      34700 |   0.038569  |    0.084316     |   2\n",
      "      34701 |   0.209347  |    0.241328     |   1\n",
      "      34702 |   0.147752  |    0.011171     |   0\n",
      "      34703 |   0.179005  |    0.269040     |   1\n",
      "      34704 |   0.246215  |    0.235781     |   1\n",
      "      34705 |   0.026073  |    0.011367     |   2\n",
      "      34706 |   0.153795  |    0.294394     |   1\n",
      "      34707 |   0.190531  |    0.071737     |   0\n",
      "      34708 |   0.149021  |    0.225910     |   1\n",
      "      34709 |   0.172612  |    0.027274     |   0\n",
      "      34710 |   0.210999  |    0.112965     |   0\n",
      "      34711 |   0.030114  |    0.058138     |   2\n",
      "      34712 |   0.031461  |    0.028596     |   2\n",
      "      34713 |   0.151362  |    0.261959     |   1\n",
      "      34714 |   0.133775  |    0.273435     |   1\n",
      "      34715 |   0.022165  |    0.023056     |   2\n",
      "      34716 |   0.155608  |    0.073920     |   0\n",
      "      34717 |   0.198163  |    0.219844     |   1\n",
      "      34718 |   0.200640  |    0.284206     |   1\n",
      "      34719 |   0.240574  |    0.003809     |   0\n",
      "      34720 |   0.189848  |    0.074037     |   0\n",
      "      34721 |   0.029774  |    0.093644     |   2\n",
      "      34722 |   0.039655  |    0.023989     |   2\n",
      "      34723 |   0.043707  |    0.104346     |   2\n",
      "      34724 |   0.120467  |    0.067643     |   0\n",
      "      34725 |   0.170695  |    0.216913     |   1\n",
      "      34726 |   0.175435  |    0.202515     |   1\n",
      "      34727 |   0.199162  |    0.015991     |   0\n",
      "      34728 |   0.195585  |    0.306150     |   1\n",
      "      34729 |   0.152029  |    0.056132     |   0\n",
      "      34730 |   0.155707  |    0.217036     |   1\n",
      "      34731 |   0.169005  |    0.233923     |   1\n",
      "      34732 |   0.035769  |    0.074047     |   2\n",
      "      34733 |   0.203112  |    0.203081     |   1\n",
      "      34734 |   0.145080  |    0.210273     |   1\n",
      "      34735 |   0.138115  |    0.221597     |   1\n",
      "      34736 |   0.185631  |    0.220788     |   1\n",
      "      34737 |   0.153779  |    0.268030     |   1\n",
      "      34738 |   0.016814  |    0.092058     |   2\n",
      "      34739 |   0.149211  |    0.075700     |   0\n",
      "      34740 |   0.000012  |    0.147562     |   2\n",
      "      34741 |   0.199228  |    0.275774     |   1\n",
      "      34742 |   0.157068  |    0.095751     |   0\n",
      "      34743 |   0.119966  |    0.168084     |   0\n",
      "      34744 |   0.192624  |    0.403810     |   1\n",
      "      34745 |   0.186725  |    0.529874     |   1\n",
      "      34746 |   0.003838  |    0.158788     |   2\n",
      "      34747 |   0.168004  |    0.376263     |   1\n",
      "      34748 |   0.178539  |    0.057625     |   0\n",
      "      34749 |   0.049581  |    0.124042     |   2\n",
      "      34750 |   0.154960  |    0.120949     |   0\n",
      "      34751 |   0.030770  |    0.040707     |   2\n",
      "      34752 |   0.144405  |    0.082744     |   0\n",
      "      34753 |   0.144053  |    0.117148     |   0\n",
      "      34754 |   0.168294  |    0.387596     |   1\n",
      "      34755 |   0.203903  |    0.324249     |   1\n",
      "      34756 |   0.108294  |    0.060827     |   0\n",
      "      34757 |   0.049274  |    0.119949     |   2\n",
      "      34758 |   0.189712  |    0.124851     |   0\n",
      "      34759 |   0.033073  |    0.040123     |   2\n",
      "      34760 |   0.171166  |    0.141799     |   0\n",
      "      34761 |   0.118449  |    0.465660     |   1\n",
      "      34762 |   0.231134  |    0.267432     |   1\n",
      "      34763 |   0.175721  |    0.341027     |   1\n",
      "      34764 |   0.170500  |    0.182878     |   0\n",
      "      34765 |   0.013876  |    0.070954     |   2\n",
      "      34766 |   0.157098  |    0.072069     |   0\n",
      "      34767 |   0.033443  |    0.127940     |   2\n",
      "      34768 |   0.140359  |    0.342435     |   1\n",
      "      34769 |   0.136530  |    0.121018     |   0\n",
      "      34770 |   0.149966  |    0.412086     |   1\n",
      "      34771 |   0.212138  |    0.076517     |   0\n",
      "      34772 |   0.154366  |    0.145843     |   0\n",
      "      34773 |   0.020858  |    0.141540     |   2\n",
      "      34774 |   0.172319  |    0.344712     |   1\n",
      "      34775 |   0.000012  |    0.094448     |   2\n",
      "      34776 |   0.000012  |    0.143343     |   2\n",
      "      34777 |   0.000012  |    0.106180     |   2\n",
      "      34778 |   0.171587  |    0.151190     |   0\n",
      "      34779 |   0.000012  |    0.097473     |   2\n",
      "      34780 |   0.130101  |    0.066686     |   0\n",
      "      34781 |   0.000012  |    0.129086     |   2\n",
      "      34782 |   0.000012  |    0.044855     |   2\n",
      "      34783 |   0.038191  |    0.093008     |   2\n",
      "      34784 |   0.040374  |    0.076112     |   2\n",
      "      34785 |   0.181479  |    0.094065     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 34786: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      34786 |   0.040439  |    0.078586     |   2\n",
      "      34787 |   0.205354  |    0.094448     |   0\n",
      "      34788 |   0.164317  |    0.126758     |   0\n",
      "      34789 |   0.146814  |    0.037790     |   0\n",
      "      34790 |   0.151455  |    0.116707     |   0\n",
      "      34791 |   0.178029  |    0.329643     |   1\n",
      "      34792 |   0.028637  |    0.084655     |   2\n",
      "      34793 |   0.032171  |    0.139454     |   2\n",
      "      34794 |   0.175675  |    0.078762     |   0\n",
      "      34795 |   0.139343  |    0.087911     |   0\n",
      "      34796 |   0.170915  |    0.091981     |   0\n",
      "      34797 |   0.165574  |    0.123008     |   0\n",
      "      34798 |   0.196978  |    0.036598     |   0\n",
      "      34799 |   0.149487  |    0.442419     |   1\n",
      "      34800 |   0.157288  |    0.020524     |   0\n",
      "      34801 |   0.210759  |    0.346721     |   1\n",
      "      34802 |   0.220761  |    0.330280     |   1\n",
      "      34803 |   0.243886  |    0.367644     |   1\n",
      "      34804 |   0.207474  |    0.331664     |   1\n",
      "      34805 |   0.140336  |    0.147428     |   0\n",
      "      34806 |   0.185240  |    0.334450     |   1\n",
      "      34807 |   0.129068  |    0.377550     |   1\n",
      "      34808 |   0.210301  |    0.090472     |   0\n",
      "      34809 |   0.156357  |    0.162323     |   0\n",
      "      34810 |   0.149829  |    0.062049     |   0\n",
      "      34811 |   0.029752  |    0.153879     |   2\n",
      "      34812 |   0.169269  |    0.335831     |   1\n",
      "      34813 |   0.233271  |    0.441071     |   1\n",
      "      34814 |   0.150881  |    0.083565     |   0\n",
      "      34815 |   0.171167  |    0.350719     |   1\n",
      "      34816 |   0.225763  |    0.120005     |   0\n",
      "      34817 |   0.185956  |    0.447091     |   1\n",
      "      34818 |   0.022999  |    0.159064     |   2\n",
      "      34819 |   0.203185  |    0.046045     |   0\n",
      "      34820 |   0.032891  |    0.149845     |   2\n",
      "      34821 |   0.040751  |    0.004850     |   2\n",
      "      34822 |   0.151859  |    0.085629     |   0\n",
      "      34823 |   0.044770  |    0.036993     |   2\n",
      "      34824 |   0.236534  |    0.095507     |   0\n",
      "      34825 |   0.157452  |    0.075725     |   0\n",
      "      34826 |   0.195541  |    0.213292     |   1\n",
      "      34827 |   0.036708  |    0.068508     |   2\n",
      "      34828 |   0.124953  |    0.229120     |   1\n",
      "      34829 |   0.134369  |    0.368119     |   1\n",
      "      34830 |   0.223518  |    0.289142     |   1\n",
      "      34831 |   0.162728  |    0.314827     |   1\n",
      "      34832 |   0.155570  |    0.031681     |   0\n",
      "      34833 |   0.176617  |    0.150208     |   0\n",
      "      34834 |   0.200326  |    0.229479     |   1\n",
      "      34835 |   0.019402  |    0.022718     |   2\n",
      "      34836 |   0.000012  |    0.189474     |   2\n",
      "      34837 |   0.003859  |    0.004608     |   2\n",
      "      34838 |   0.190801  |    0.155081     |   0\n",
      "      34839 |   0.119621  |    0.212681     |   1\n",
      "      34840 |   0.145605  |    0.287160     |   1\n",
      "      34841 |   0.050687  |    0.008869     |   2\n",
      "      34842 |   0.166988  |    0.132499     |   0\n",
      "      34843 |   0.160153  |    0.034547     |   0\n",
      "      34844 |   0.180648  |    0.285717     |   1\n",
      "      34845 |   0.031127  |    0.067972     |   2\n",
      "      34846 |   0.052153  |    0.067608     |   2\n",
      "      34847 |   0.033592  |    0.066600     |   2\n",
      "      34848 |   0.127261  |    0.083661     |   0\n",
      "      34849 |   0.173384  |    0.288022     |   1\n",
      "      34850 |   0.011842  |    0.063433     |   2\n",
      "      34851 |   0.029650  |    0.059461     |   2\n",
      "      34852 |   0.175350  |    0.082967     |   0\n",
      "      34853 |   0.240035  |    0.360089     |   1\n",
      "      34854 |   0.184554  |    0.333778     |   1\n",
      "      34855 |   0.019690  |    0.095721     |   2\n",
      "      34856 |   0.147082  |    0.461342     |   1\n",
      "      34857 |   0.000012  |    0.106299     |   2\n",
      "      34858 |   0.000012  |    0.081122     |   2\n",
      "      34859 |   0.198031  |    0.274229     |   1\n",
      "      34860 |   0.000012  |    0.153371     |   2\n",
      "      34861 |   0.179426  |    0.005909     |   0\n",
      "      34862 |   0.152021  |    0.107335     |   0\n",
      "      34863 |   0.193895  |    0.090320     |   0\n",
      "      34864 |   0.148882  |    0.187621     |   0\n",
      "      34865 |   0.188061  |    0.047809     |   0\n",
      "      34866 |   0.190378  |    0.289054     |   1\n",
      "      34867 |   0.171557  |    0.040298     |   0\n",
      "      34868 |   0.000012  |    0.047055     |   2\n",
      "      34869 |   0.173579  |    0.286397     |   1\n",
      "      34870 |   0.000012  |    0.009942     |   2\n",
      "      34871 |   0.182931  |    0.337124     |   1\n",
      "      34872 |   0.176240  |    0.467555     |   1\n",
      "      34873 |   0.000012  |    0.041313     |   2\n",
      "      34874 |   0.174531  |    0.374084     |   1\n",
      "      34875 |   0.038474  |    0.129726     |   2\n",
      "      34876 |   0.229595  |    0.089218     |   0\n",
      "      34877 |   0.173649  |    0.100913     |   0\n",
      "      34878 |   0.150209  |    0.069465     |   0\n",
      "      34879 |   0.039890  |    0.125462     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 34880: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      34880 |   0.125845  |    0.476618     |   1\n",
      "      34881 |   0.039554  |    0.171803     |   2\n",
      "      34882 |   0.025532  |    0.032716     |   2\n",
      "      34883 |   0.032220  |    0.103395     |   2\n",
      "      34884 |   0.030488  |    0.122458     |   2\n",
      "      34885 |   0.211591  |    0.471989     |   1\n",
      "      34886 |   0.187743  |    0.037781     |   0\n",
      "      34887 |   0.023075  |    0.135863     |   2\n",
      "      34888 |   0.030344  |    0.070358     |   2\n",
      "      34889 |   0.201912  |    0.070005     |   0\n",
      "      34890 |   0.045244  |    0.096640     |   2\n",
      "      34891 |   0.214504  |    0.138552     |   0\n",
      "      34892 |   0.134384  |    0.125587     |   0\n",
      "      34893 |   0.041103  |    0.118772     |   2\n",
      "      34894 |   0.035368  |    0.037521     |   2\n",
      "      34895 |   0.143842  |    0.386421     |   1\n",
      "      34896 |   0.168502  |    0.285498     |   1\n",
      "      34897 |   0.171017  |    0.403894     |   1\n",
      "      34898 |   0.019246  |    0.079116     |   2\n",
      "      34899 |   0.000012  |    0.052987     |   2\n",
      "      34900 |   0.185993  |    0.218045     |   1\n",
      "      34901 |   0.004371  |    0.095319     |   2\n",
      "      34902 |   0.177627  |    0.034516     |   0\n",
      "      34903 |   0.175754  |    0.364413     |   1\n",
      "      34904 |   0.154812  |    0.096452     |   0\n",
      "      34905 |   0.161374  |    0.040468     |   0\n",
      "      34906 |   0.139543  |    0.072784     |   0\n",
      "      34907 |   0.149905  |    0.452984     |   1\n",
      "      34908 |   0.200625  |    0.023862     |   0\n",
      "      34909 |   0.177692  |    0.128117     |   0\n",
      "      34910 |   0.124889  |    0.024711     |   0\n",
      "      34911 |   0.128228  |    0.074342     |   0\n",
      "      34912 |   0.052220  |    0.084932     |   2\n",
      "      34913 |   0.135283  |    0.091328     |   0\n",
      "      34914 |   0.151266  |    0.287051     |   1\n",
      "      34915 |   0.171956  |    0.094818     |   0\n",
      "      34916 |   0.150208  |    0.072978     |   0\n",
      "      34917 |   0.033326  |    0.071705     |   2\n",
      "      34918 |   0.170524  |    0.273553     |   1\n",
      "      34919 |   0.177394  |    0.330873     |   1\n",
      "      34920 |   0.051814  |    0.063796     |   2\n",
      "      34921 |   0.167051  |    0.133537     |   0\n",
      "      34922 |   0.155558  |    0.293947     |   1\n",
      "      34923 |   0.185089  |    0.089871     |   0\n",
      "      34924 |   0.036311  |    0.071682     |   2\n",
      "      34925 |   0.014763  |    0.084023     |   2\n",
      "      34926 |   0.158708  |    0.073611     |   0\n",
      "      34927 |   0.164148  |    0.380284     |   1\n",
      "      34928 |   0.032903  |    0.147438     |   2\n",
      "      34929 |   0.183308  |    0.447973     |   1\n",
      "      34930 |   0.205137  |    0.460262     |   1\n",
      "      34931 |   0.160996  |    0.311215     |   1\n",
      "      34932 |   0.022366  |    0.117345     |   2\n",
      "      34933 |   0.000012  |    0.074435     |   2\n",
      "      34934 |   0.198668  |    0.134522     |   0\n",
      "      34935 |   0.143338  |    0.095086     |   0\n",
      "      34936 |   0.000012  |    0.147870     |   2\n",
      "      34937 |   0.194062  |    0.345044     |   1\n",
      "      34938 |   0.163315  |    0.214713     |   1\n",
      "      34939 |   0.119635  |    0.043367     |   0\n",
      "      34940 |   0.000012  |    0.096458     |   2\n",
      "      34941 |   0.000012  |    0.064972     |   2\n",
      "      34942 |   0.000012  |    0.059432     |   2\n",
      "      34943 |   0.000012  |    0.070376     |   2\n",
      "      34944 |   0.184702  |    0.257618     |   1\n",
      "      34945 |   0.037493  |    0.021376     |   2\n",
      "      34946 |   0.188798  |    0.095294     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 34948: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      34947 |   0.039742  |    0.017861     |   2\n",
      "      34948 |   0.135526  |    0.079924     |   0\n",
      "      34949 |   0.184340  |    0.198231     |   1\n",
      "      34950 |   0.204702  |    0.015727     |   0\n",
      "      34951 |   0.040692  |    0.072134     |   2\n",
      "      34952 |   0.214525  |    0.087252     |   0\n",
      "      34953 |   0.152054  |    0.074268     |   0\n",
      "      34954 |   0.026991  |    0.043156     |   2\n",
      "      34955 |   0.156512  |    0.070111     |   0\n",
      "      34956 |   0.174297  |    0.222330     |   1\n",
      "      34957 |   0.198823  |    0.249624     |   1\n",
      "      34958 |   0.167136  |    0.037200     |   0\n",
      "      34959 |   0.221795  |    0.231681     |   1\n",
      "      34960 |   0.032302  |    0.093142     |   2\n",
      "      34961 |   0.031397  |    0.075479     |   2\n",
      "      34962 |   0.177754  |    0.043482     |   0\n",
      "      34963 |   0.023063  |    0.043825     |   2\n",
      "      34964 |   0.223671  |    0.088637     |   0\n",
      "      34965 |   0.142099  |    0.063902     |   0\n",
      "      34966 |   0.142189  |    0.089815     |   0\n",
      "      34967 |   0.175845  |    0.189485     |   1\n",
      "      34968 |   0.030031  |    0.064238     |   2\n",
      "      34969 |   0.199548  |    0.067993     |   0\n",
      "      34970 |   0.046333  |    0.097186     |   2\n",
      "      34971 |   0.187143  |    0.022558     |   0\n",
      "      34972 |   0.041779  |    0.129502     |   2\n",
      "      34973 |   0.196195  |    0.207473     |   1\n",
      "      34974 |   0.160506  |    0.226077     |   1\n",
      "      34975 |   0.129385  |    0.266200     |   1\n",
      "      34976 |   0.145578  |    0.182557     |   1\n",
      "      34977 |   0.231742  |    0.125429     |   1\n",
      "      34978 |   0.158241  |    0.242776     |   1\n",
      "      34979 |   0.035427  |    0.071680     |   2\n",
      "      34980 |   0.168250  |    0.098301     |   0\n",
      "      34981 |   0.016363  |    0.043921     |   2\n",
      "      34982 |   0.202846  |    0.132877     |   0\n",
      "      34983 |   0.153706  |    0.027983     |   0\n",
      "      34984 |   0.000012  |    0.038915     |   2\n",
      "      34985 |   0.180759  |    0.071232     |   0\n",
      "      34986 |   0.004491  |    0.075319     |   2\n",
      "      34987 |   0.050386  |    0.058974     |   2\n",
      "      34988 |   0.028332  |    0.039524     |   2\n",
      "      34989 |   0.195871  |    0.089755     |   0\n",
      "      34990 |   0.178360  |    0.286702     |   1\n",
      "      34991 |   0.144275  |    0.198430     |   1\n",
      "      34992 |   0.050317  |    0.061765     |   2\n",
      "      34993 |   0.147520  |    0.190746     |   1\n",
      "      34994 |   0.153459  |    0.100530     |   0\n",
      "      34995 |   0.036043  |    0.066198     |   2\n",
      "      34996 |   0.150594  |    0.055911     |   0\n",
      "      34997 |   0.173725  |    0.282393     |   1\n",
      "      34998 |   0.152239  |    0.163184     |   1\n",
      "      34999 |   0.190238  |    0.229654     |   1\n",
      "      35000 |   0.011966  |    0.098516     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 35000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 35000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      35001 |   0.108882  |    0.306450     |   1\n",
      "      35002 |   0.039192  |    0.012636     |   2\n",
      "      35003 |   0.147491  |    0.126506     |   0\n",
      "      35004 |   0.024237  |    0.012882     |   2\n",
      "      35005 |   0.100705  |    0.077973     |   0\n",
      "      35006 |   0.182042  |    0.169420     |   1\n",
      "      35007 |   0.119670  |    0.230805     |   1\n",
      "      35008 |   0.146522  |    0.282783     |   1\n",
      "      35009 |   0.031586  |    0.040123     |   2\n",
      "      35010 |   0.178788  |    0.078061     |   0\n",
      "      35011 |   0.194732  |    0.196673     |   1\n",
      "      35012 |   0.028918  |    0.072164     |   2\n",
      "      35013 |   0.022467  |    0.061771     |   2\n",
      "      35014 |   0.187615  |    0.127259     |   0\n",
      "      35015 |   0.180812  |    0.003064     |   0\n",
      "      35016 |   0.031507  |    0.082518     |   2\n",
      "      35017 |   0.037941  |    0.098797     |   2\n",
      "      35018 |   0.044104  |    0.024337     |   2\n",
      "      35019 |   0.177250  |    0.069650     |   0\n",
      "      35020 |   0.036615  |    0.111784     |   2\n",
      "      35021 |   0.178695  |    0.221116     |   1\n",
      "      35022 |   0.164204  |    0.022285     |   0\n",
      "      35023 |   0.016674  |    0.099050     |   2\n",
      "      35024 |   0.000012  |    0.077565     |   2\n",
      "      35025 |   0.004369  |    0.066019     |   2\n",
      "      35026 |   0.160148  |    0.273889     |   1\n",
      "      35027 |   0.049557  |    0.014403     |   2\n",
      "      35028 |   0.167854  |    0.270894     |   1\n",
      "      35029 |   0.029739  |    0.076482     |   2\n",
      "      35030 |   0.159919  |    0.277901     |   1\n",
      "      35031 |   0.212443  |    0.205011     |   1\n",
      "      35032 |   0.048623  |    0.012886     |   2\n",
      "      35033 |   0.189850  |    0.277572     |   1\n",
      "      35034 |   0.166225  |    0.019111     |   0\n",
      "      35035 |   0.034713  |    0.118431     |   2\n",
      "      35036 |   0.011105  |    0.012783     |   2\n",
      "      35037 |   0.173554  |    0.112777     |   0\n",
      "      35038 |   0.026130  |    0.077335     |   2\n",
      "      35039 |   0.172754  |    0.065822     |   0\n",
      "      35040 |   0.159262  |    0.097108     |   0\n",
      "      35041 |   0.019607  |    0.042116     |   2\n",
      "      35042 |   0.164896  |    0.238489     |   1\n",
      "      35043 |   0.156026  |    0.211448     |   1\n",
      "      35044 |   0.000012  |    0.072503     |   2\n",
      "      35045 |   0.000012  |    0.111980     |   2\n",
      "      35046 |   0.157726  |    0.218702     |   1\n",
      "      35047 |   0.136651  |    0.040997     |   0\n",
      "      35048 |   0.000012  |    0.066714     |   2\n",
      "      35049 |   0.000012  |    0.045671     |   2\n",
      "      35050 |   0.145061  |    0.081556     |   0\n",
      "      35051 |   0.142800  |    0.068507     |   0\n",
      "      35052 |   0.165195  |    0.180239     |   1\n",
      "      35053 |   0.000012  |    0.065519     |   2\n",
      "      35054 |   0.000012  |    0.050085     |   2\n",
      "      35055 |   0.190957  |    0.244507     |   1\n",
      "      35056 |   0.197228  |    0.228197     |   1\n",
      "      35057 |   0.188982  |    0.083934     |   0\n",
      "      35058 |   0.209319  |    0.182159     |   1\n",
      "      35059 |   0.037207  |    0.065271     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 35061: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      35060 |   0.039481  |    0.042267     |   2\n",
      "      35061 |   0.156979  |    0.210062     |   1\n",
      "      35062 |   0.183811  |    0.149081     |   0\n",
      "      35063 |   0.154963  |    0.226855     |   1\n",
      "      35064 |   0.038575  |    0.028195     |   2\n",
      "      35065 |   0.025685  |    0.103770     |   2\n",
      "      35066 |   0.208199  |    0.070986     |   0\n",
      "      35067 |   0.032200  |    0.007633     |   2\n",
      "      35068 |   0.169127  |    0.097726     |   0\n",
      "      35069 |   0.207594  |    0.223166     |   1\n",
      "      35070 |   0.136589  |    0.216008     |   1\n",
      "      35071 |   0.190575  |    0.259391     |   1\n",
      "      35072 |   0.184463  |    0.016865     |   0\n",
      "      35073 |   0.165741  |    0.121035     |   0\n",
      "      35074 |   0.196277  |    0.212584     |   1\n",
      "      35075 |   0.132732  |    0.290595     |   1\n",
      "      35076 |   0.029904  |    0.048717     |   2\n",
      "      35077 |   0.021964  |    0.066725     |   2\n",
      "      35078 |   0.155463  |    0.096837     |   0\n",
      "      35079 |   0.031324  |    0.045014     |   2\n",
      "      35080 |   0.117835  |    0.084322     |   0\n",
      "      35081 |   0.039528  |    0.030965     |   2\n",
      "      35082 |   0.160072  |    0.051288     |   0\n",
      "      35083 |   0.174172  |    0.086902     |   0\n",
      "      35084 |   0.184718  |    0.069470     |   0\n",
      "      35085 |   0.150207  |    0.066151     |   0\n",
      "      35086 |   0.151686  |    0.210212     |   1\n",
      "      35087 |   0.171208  |    0.229365     |   1\n",
      "      35088 |   0.186147  |    0.226801     |   1\n",
      "      35089 |   0.043587  |    0.019383     |   2\n",
      "      35090 |   0.231509  |    0.280216     |   1\n",
      "      35091 |   0.174237  |    0.212816     |   1\n",
      "      35092 |   0.180609  |    0.201808     |   1\n",
      "      35093 |   0.035057  |    0.058438     |   2\n",
      "      35094 |   0.017388  |    0.075227     |   2\n",
      "      35095 |   0.000012  |    0.096406     |   2\n",
      "      35096 |   0.179611  |    0.236779     |   1\n",
      "      35097 |   0.175711  |    0.009842     |   0\n",
      "      35098 |   0.191310  |    0.283966     |   1\n",
      "      35099 |   0.167179  |    0.212458     |   1\n",
      "      35100 |   0.124687  |    0.022444     |   0\n",
      "      35101 |   0.176777  |    0.276379     |   1\n",
      "      35102 |   0.003787  |    0.079451     |   2\n",
      "      35103 |   0.049058  |    0.032504     |   2\n",
      "      35104 |   0.182230  |    0.064495     |   0\n",
      "      35105 |   0.132364  |    0.073185     |   0\n",
      "      35106 |   0.028891  |    0.025721     |   2\n",
      "      35107 |   0.145714  |    0.296913     |   1\n",
      "      35108 |   0.129012  |    0.015624     |   0\n",
      "      35109 |   0.051948  |    0.069758     |   2\n",
      "      35110 |   0.033352  |    0.110762     |   2\n",
      "      35111 |   0.012459  |    0.059204     |   2\n",
      "      35112 |   0.027326  |    0.022846     |   2\n",
      "      35113 |   0.128724  |    0.234178     |   1\n",
      "      35114 |   0.169155  |    0.075869     |   0\n",
      "      35115 |   0.023386  |    0.054398     |   2\n",
      "      35116 |   0.162888  |    0.045444     |   0\n",
      "      35117 |   0.000012  |    0.092121     |   2\n",
      "      35118 |   0.153111  |    0.192420     |   1\n",
      "      35119 |   0.000012  |    0.036033     |   2\n",
      "      35120 |   0.156178  |    0.283171     |   1\n",
      "      35121 |   0.125029  |    0.012363     |   0\n",
      "      35122 |   0.188216  |    0.255251     |   1\n",
      "      35123 |   0.000012  |    0.026946     |   2\n",
      "      35124 |   0.188969  |    0.077820     |   0\n",
      "      35125 |   0.000012  |    0.079509     |   2\n",
      "      35126 |   0.192094  |    0.226660     |   1\n",
      "      35127 |   0.000012  |    0.060093     |   2\n",
      "      35128 |   0.000012  |    0.075253     |   2\n",
      "      35129 |   0.169893  |    0.087489     |   0\n",
      "      35130 |   0.141090  |    0.220059     |   1\n",
      "      35131 |   0.036189  |    0.105530     |   2\n",
      "      35132 |   0.159934  |    0.022149     |   0\n",
      "      35133 |   0.039731  |    0.123280     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 35135: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      35134 |   0.135440  |    0.030214     |   0\n",
      "      35135 |   0.159129  |    0.261834     |   1\n",
      "      35136 |   0.038172  |    0.094290     |   2\n",
      "      35137 |   0.025387  |    0.060207     |   2\n",
      "      35138 |   0.160302  |    0.228382     |   1\n",
      "      35139 |   0.120381  |    0.237138     |   1\n",
      "      35140 |   0.192168  |    0.258921     |   1\n",
      "      35141 |   0.176952  |    0.163724     |   1\n",
      "      35142 |   0.032391  |    0.116169     |   2\n",
      "      35143 |   0.182720  |    0.027027     |   0\n",
      "      35144 |   0.143998  |    0.079490     |   0\n",
      "      35145 |   0.030543  |    0.049630     |   2\n",
      "      35146 |   0.021781  |    0.028451     |   2\n",
      "      35147 |   0.110155  |    0.101138     |   0\n",
      "      35148 |   0.180530  |    0.213632     |   1\n",
      "      35149 |   0.029617  |    0.049698     |   2\n",
      "      35150 |   0.153319  |    0.258374     |   1\n",
      "      35151 |   0.147314  |    0.030338     |   0\n",
      "      35152 |   0.192429  |    0.119977     |   0\n",
      "      35153 |   0.214838  |    0.170214     |   1\n",
      "      35154 |   0.185084  |    0.170319     |   1\n",
      "      35155 |   0.218136  |    0.039811     |   0\n",
      "      35156 |   0.160263  |    0.122404     |   0\n",
      "      35157 |   0.210401  |    0.025953     |   0\n",
      "      35158 |   0.237759  |    0.198852     |   1\n",
      "      35159 |   0.158937  |    0.075504     |   0\n",
      "      35160 |   0.179916  |    0.217749     |   1\n",
      "      35161 |   0.169639  |    0.062683     |   0\n",
      "      35162 |   0.038831  |    0.058039     |   2\n",
      "      35163 |   0.170949  |    0.087038     |   0\n",
      "      35164 |   0.264037  |    0.232817     |   1\n",
      "      35165 |   0.151084  |    0.043207     |   0\n",
      "      35166 |   0.214853  |    0.123413     |   0\n",
      "      35167 |   0.176713  |    0.245138     |   1\n",
      "      35168 |   0.042970  |    0.007749     |   2\n",
      "      35169 |   0.177148  |    0.072399     |   0\n",
      "      35170 |   0.202498  |    0.239784     |   1\n",
      "      35171 |   0.170321  |    0.006023     |   0\n",
      "      35172 |   0.214569  |    0.090702     |   0\n",
      "      35173 |   0.035590  |    0.047789     |   2\n",
      "      35174 |   0.153861  |    0.094528     |   0\n",
      "      35175 |   0.164264  |    0.236035     |   1\n",
      "      35176 |   0.182476  |    0.217984     |   1\n",
      "      35177 |   0.200812  |    0.204473     |   1\n",
      "      35178 |   0.139966  |    0.032411     |   0\n",
      "      35179 |   0.150283  |    0.215683     |   1\n",
      "      35180 |   0.153236  |    0.279654     |   1\n",
      "      35181 |   0.158844  |    0.223263     |   1\n",
      "      35182 |   0.161597  |    0.210681     |   1\n",
      "      35183 |   0.018091  |    0.005911     |   2\n",
      "      35184 |   0.000012  |    0.089809     |   2\n",
      "      35185 |   0.213299  |    0.205583     |   1\n",
      "      35186 |   0.180486  |    0.022912     |   0\n",
      "      35187 |   0.198137  |    0.274618     |   1\n",
      "      35188 |   0.003656  |    0.023689     |   2\n",
      "      35189 |   0.046244  |    0.110990     |   2\n",
      "      35190 |   0.172724  |    0.204924     |   1\n",
      "      35191 |   0.147831  |    0.077450     |   0\n",
      "      35192 |   0.160104  |    0.063844     |   0\n",
      "      35193 |   0.166521  |    0.259209     |   1\n",
      "      35194 |   0.125010  |    0.008496     |   0\n",
      "      35195 |   0.127644  |    0.287957     |   1\n",
      "      35196 |   0.028394  |    0.063777     |   2\n",
      "      35197 |   0.048891  |    0.063517     |   2\n",
      "      35198 |   0.195106  |    0.090595     |   0\n",
      "      35199 |   0.145822  |    0.073199     |   0\n",
      "      35200 |   0.138202  |    0.050809     |   0\n",
      "      35201 |   0.234579  |    0.090763     |   0\n",
      "      35202 |   0.034406  |    0.024562     |   2\n",
      "      35203 |   0.146079  |    0.265460     |   1\n",
      "      35204 |   0.012101  |    0.101513     |   2\n",
      "      35205 |   0.146274  |    0.239126     |   1\n",
      "      35206 |   0.149346  |    0.046468     |   0\n",
      "      35207 |   0.028972  |    0.096325     |   2\n",
      "      35208 |   0.022340  |    0.014796     |   2\n",
      "      35209 |   0.000012  |    0.087012     |   2\n",
      "      35210 |   0.000012  |    0.079775     |   2\n",
      "      35211 |   0.223189  |    0.077046     |   0\n",
      "      35212 |   0.000012  |    0.022348     |   2\n",
      "      35213 |   0.155473  |    0.100863     |   0\n",
      "      35214 |   0.000012  |    0.022543     |   2\n",
      "      35215 |   0.169425  |    0.121397     |   0\n",
      "      35216 |   0.250784  |    0.218899     |   1\n",
      "      35217 |   0.000012  |    0.074526     |   2\n",
      "      35218 |   0.223403  |    0.220965     |   1\n",
      "      35219 |   0.169679  |    0.147078     |   1\n",
      "      35220 |   0.209835  |    0.090130     |   0\n",
      "      35221 |   0.189735  |    0.028894     |   0\n",
      "      35222 |   0.192953  |    0.083856     |   0\n",
      "      35223 |   0.000012  |    0.078133     |   2\n",
      "      35224 |   0.164202  |    0.190684     |   1\n",
      "      35225 |   0.114372  |    0.273143     |   1\n",
      "      35226 |   0.172725  |    0.100593     |   0\n",
      "      35227 |   0.039015  |    0.023901     |   2\n",
      "      35228 |   0.041997  |    0.078961     |   2\n",
      "      35229 |   0.176546  |    0.088426     |   0\n",
      "      35230 |   0.141936  |    0.020350     |   0\n",
      "      35231 |   0.144270  |    0.070055     |   0\n",
      "      35232 |   0.206509  |    0.285921     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 35233: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      35233 |   0.037889  |    0.003394     |   2\n",
      "      35234 |   0.194320  |    0.086457     |   0\n",
      "      35235 |   0.027492  |    0.027589     |   2\n",
      "      35236 |   0.204495  |    0.269046     |   1\n",
      "      35237 |   0.139429  |    0.287378     |   1\n",
      "      35238 |   0.177389  |    0.157025     |   1\n",
      "      35239 |   0.032169  |    0.047532     |   2\n",
      "      35240 |   0.158059  |    0.216745     |   1\n",
      "      35241 |   0.188721  |    0.226457     |   1\n",
      "      35242 |   0.031227  |    0.113736     |   2\n",
      "      35243 |   0.170135  |    0.068337     |   0\n",
      "      35244 |   0.181397  |    0.296275     |   1\n",
      "      35245 |   0.198357  |    0.210320     |   1\n",
      "      35246 |   0.021947  |    0.074370     |   2\n",
      "      35247 |   0.175987  |    0.032228     |   0\n",
      "      35248 |   0.192468  |    0.198613     |   1\n",
      "      35249 |   0.172947  |    0.214450     |   1\n",
      "      35250 |   0.185721  |    0.241037     |   1\n",
      "      35251 |   0.159998  |    0.014950     |   0\n",
      "      35252 |   0.131611  |    0.088472     |   0\n",
      "      35253 |   0.171365  |    0.053495     |   0\n",
      "      35254 |   0.131176  |    0.073575     |   0\n",
      "      35255 |   0.029515  |    0.091741     |   2\n",
      "      35256 |   0.043166  |    0.041614     |   2\n",
      "      35257 |   0.041731  |    0.086138     |   2\n",
      "      35258 |   0.033678  |    0.040439     |   2\n",
      "      35259 |   0.141307  |    0.267859     |   1\n",
      "      35260 |   0.171341  |    0.208021     |   1\n",
      "      35261 |   0.156807  |    0.010998     |   0\n",
      "      35262 |   0.015325  |    0.104269     |   2\n",
      "      35263 |   0.190884  |    0.041724     |   0\n",
      "      35264 |   0.129222  |    0.069826     |   0\n",
      "      35265 |   0.191211  |    0.098070     |   0\n",
      "      35266 |   0.000012  |    0.090437     |   2\n",
      "      35267 |   0.141189  |    0.229918     |   1\n",
      "      35268 |   0.003291  |    0.071121     |   2\n",
      "      35269 |   0.166147  |    0.043034     |   0\n",
      "      35270 |   0.148957  |    0.226114     |   1\n",
      "      35271 |   0.046224  |    0.081929     |   2\n",
      "      35272 |   0.029010  |    0.076666     |   2\n",
      "      35273 |   0.051743  |    0.099223     |   2\n",
      "      35274 |   0.145101  |    0.062368     |   0\n",
      "      35275 |   0.036388  |    0.067729     |   2\n",
      "      35276 |   0.164936  |    0.221096     |   1\n",
      "      35277 |   0.140486  |    0.022884     |   0\n",
      "      35278 |   0.014177  |    0.085333     |   2\n",
      "      35279 |   0.030874  |    0.042987     |   2\n",
      "      35280 |   0.161821  |    0.228950     |   1\n",
      "      35281 |   0.197964  |    0.286271     |   1\n",
      "      35282 |   0.021759  |    0.020354     |   2\n",
      "      35283 |   0.160672  |    0.261071     |   1\n",
      "      35284 |   0.124533  |    0.071234     |   0\n",
      "      35285 |   0.000012  |    0.095326     |   2\n",
      "      35286 |   0.209739  |    0.012167     |   0\n",
      "      35287 |   0.148375  |    0.107472     |   0\n",
      "      35288 |   0.207097  |    0.142739     |   1\n",
      "      35289 |   0.199104  |    0.103668     |   0\n",
      "      35290 |   0.192149  |    0.037045     |   0\n",
      "      35291 |   0.161803  |    0.275985     |   1\n",
      "      35292 |   0.000012  |    0.024200     |   2\n",
      "      35293 |   0.000012  |    0.084436     |   2\n",
      "      35294 |   0.000012  |    0.065570     |   2\n",
      "      35295 |   0.145365  |    0.074037     |   0\n",
      "      35296 |   0.148240  |    0.263709     |   1\n",
      "      35297 |   0.152473  |    0.251065     |   1\n",
      "      35298 |   0.142625  |    0.021607     |   0\n",
      "      35299 |   0.161554  |    0.287755     |   1\n",
      "      35300 |   0.178263  |    0.071854     |   0\n",
      "      35301 |   0.204286  |    0.173505     |   1\n",
      "      35302 |   0.000012  |    0.051505     |   2\n",
      "      35303 |   0.220835  |    0.286070     |   1\n",
      "      35304 |   0.178424  |    0.029143     |   0\n",
      "      35305 |   0.116269  |    0.094593     |   0\n",
      "      35306 |   0.164510  |    0.026241     |   0\n",
      "      35307 |   0.232757  |    0.282476     |   1\n",
      "      35308 |   0.194973  |    0.161901     |   1\n",
      "      35309 |   0.000012  |    0.074648     |   2\n",
      "      35310 |   0.039111  |    0.055499     |   2\n",
      "      35311 |   0.164650  |    0.065640     |   0\n",
      "      35312 |   0.039899  |    0.101459     |   2\n",
      "      35313 |   0.158352  |    0.027457     |   0\n",
      "      35314 |   0.131406  |    0.052649     |   0\n",
      "      35315 |   0.196340  |    0.216949     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 35317: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      35316 |   0.169442  |    0.009944     |   0\n",
      "      35317 |   0.175552  |    0.116070     |   0\n",
      "      35318 |   0.167052  |    0.241035     |   1\n",
      "      35319 |   0.206945  |    0.205789     |   1\n",
      "      35320 |   0.149047  |    0.017969     |   0\n",
      "      35321 |   0.188844  |    0.246898     |   1\n",
      "      35322 |   0.156875  |    0.007745     |   0\n",
      "      35323 |   0.039609  |    0.116151     |   2\n",
      "      35324 |   0.025627  |    0.025698     |   2\n",
      "      35325 |   0.164152  |    0.112887     |   0\n",
      "      35326 |   0.146441  |    0.206159     |   1\n",
      "      35327 |   0.157900  |    0.245149     |   1\n",
      "      35328 |   0.179221  |    0.049510     |   0\n",
      "      35329 |   0.033671  |    0.065464     |   2\n",
      "      35330 |   0.160789  |    0.233980     |   1\n",
      "      35331 |   0.167678  |    0.025210     |   0\n",
      "      35332 |   0.173566  |    0.056725     |   0\n",
      "      35333 |   0.032100  |    0.122923     |   2\n",
      "      35334 |   0.112455  |    0.022707     |   0\n",
      "      35335 |   0.169955  |    0.078801     |   0\n",
      "      35336 |   0.126559  |    0.026247     |   0\n",
      "      35337 |   0.022370  |    0.114399     |   2\n",
      "      35338 |   0.175704  |    0.038179     |   0\n",
      "      35339 |   0.168592  |    0.222761     |   1\n",
      "      35340 |   0.153017  |    0.235053     |   1\n",
      "      35341 |   0.230976  |    0.231140     |   1\n",
      "      35342 |   0.161317  |    0.024535     |   0\n",
      "      35343 |   0.196940  |    0.074847     |   0\n",
      "      35344 |   0.030578  |    0.066525     |   2\n",
      "      35345 |   0.046005  |    0.071028     |   2\n",
      "      35346 |   0.041028  |    0.101996     |   2\n",
      "      35347 |   0.165644  |    0.036362     |   0\n",
      "      35348 |   0.154151  |    0.174385     |   1\n",
      "      35349 |   0.218222  |    0.202035     |   1\n",
      "      35350 |   0.178931  |    0.215447     |   1\n",
      "      35351 |   0.108614  |    0.175191     |   1\n",
      "      35352 |   0.034795  |    0.051001     |   2\n",
      "      35353 |   0.152819  |    0.242637     |   1\n",
      "      35354 |   0.186712  |    0.238682     |   1\n",
      "      35355 |   0.156283  |    0.279418     |   1\n",
      "      35356 |   0.157796  |    0.070149     |   0\n",
      "      35357 |   0.192203  |    0.296369     |   1\n",
      "      35358 |   0.148139  |    0.173262     |   1\n",
      "      35359 |   0.163930  |    0.205096     |   1\n",
      "      35360 |   0.017417  |    0.041559     |   2\n",
      "      35361 |   0.153860  |    0.268994     |   1\n",
      "      35362 |   0.153094  |    0.051348     |   0\n",
      "      35363 |   0.197748  |    0.227704     |   1\n",
      "      35364 |   0.152393  |    0.218523     |   1\n",
      "      35365 |   0.179409  |    0.109511     |   0\n",
      "      35366 |   0.172789  |    0.016108     |   0\n",
      "      35367 |   0.128931  |    0.167868     |   0\n",
      "      35368 |   0.129472  |    0.009745     |   0\n",
      "      35369 |   0.212261  |    0.262956     |   1\n",
      "      35370 |   0.203678  |    0.209107     |   1\n",
      "      35371 |   0.000012  |    0.046841     |   2\n",
      "      35372 |   0.162748  |    0.074738     |   0\n",
      "      35373 |   0.215644  |    0.012956     |   0\n",
      "      35374 |   0.162554  |    0.127968     |   0\n",
      "      35375 |   0.163753  |    0.003907     |   0\n",
      "      35376 |   0.150401  |    0.069126     |   0\n",
      "      35377 |   0.148138  |    0.050415     |   0\n",
      "      35378 |   0.003937  |    0.047014     |   2\n",
      "      35379 |   0.049154  |    0.038259     |   2\n",
      "      35380 |   0.167583  |    0.111220     |   0\n",
      "      35381 |   0.149612  |    0.038373     |   0\n",
      "      35382 |   0.135052  |    0.250430     |   1\n",
      "      35383 |   0.029668  |    0.010185     |   2\n",
      "      35384 |   0.049720  |    0.127776     |   2\n",
      "      35385 |   0.190926  |    0.005937     |   0\n",
      "      35386 |   0.140711  |    0.270621     |   1\n",
      "      35387 |   0.038207  |    0.067939     |   2\n",
      "      35388 |   0.013430  |    0.074716     |   2\n",
      "      35389 |   0.173055  |    0.048877     |   0\n",
      "      35390 |   0.217852  |    0.231404     |   1\n",
      "      35391 |   0.244716  |    0.176239     |   1\n",
      "      35392 |   0.153970  |    0.074940     |   0\n",
      "      35393 |   0.162161  |    0.069985     |   0\n",
      "      35394 |   0.186821  |    0.055097     |   0\n",
      "      35395 |   0.178788  |    0.282017     |   1\n",
      "      35396 |   0.201719  |    0.032597     |   0\n",
      "      35397 |   0.177215  |    0.075224     |   0\n",
      "      35398 |   0.170789  |    0.128469     |   0\n",
      "      35399 |   0.178457  |    0.159795     |   1\n",
      "      35400 |   0.191788  |    0.277121     |   1\n",
      "      35401 |   0.200630  |    0.212861     |   1\n",
      "      35402 |   0.203952  |    0.213448     |   1\n",
      "      35403 |   0.031903  |    0.016499     |   2\n",
      "      35404 |   0.144577  |    0.111304     |   0\n",
      "      35405 |   0.185467  |    0.071489     |   0\n",
      "      35406 |   0.022321  |    0.059364     |   2\n",
      "      35407 |   0.000012  |    0.072669     |   2\n",
      "      35408 |   0.156356  |    0.227747     |   1\n",
      "      35409 |   0.189399  |    0.094246     |   0\n",
      "      35410 |   0.167147  |    0.200305     |   1\n",
      "      35411 |   0.149298  |    0.285218     |   1\n",
      "      35412 |   0.135865  |    0.060144     |   0\n",
      "      35413 |   0.000012  |    0.052465     |   2\n",
      "      35414 |   0.192221  |    0.286810     |   1\n",
      "      35415 |   0.172754  |    0.224740     |   1\n",
      "      35416 |   0.000012  |    0.021670     |   2\n",
      "      35417 |   0.159209  |    0.070251     |   0\n",
      "      35418 |   0.163172  |    0.027211     |   0\n",
      "      35419 |   0.198021  |    0.247440     |   1\n",
      "      35420 |   0.000012  |    0.045575     |   2\n",
      "      35421 |   0.142611  |    0.063403     |   0\n",
      "      35422 |   0.000012  |    0.105892     |   2\n",
      "      35423 |   0.000012  |    0.008005     |   2\n",
      "      35424 |   0.149708  |    0.072222     |   0\n",
      "      35425 |   0.038605  |    0.152906     |   2\n",
      "      35426 |   0.145651  |    0.165999     |   1\n",
      "      35427 |   0.040714  |    0.051934     |   2\n",
      "      35428 |   0.184283  |    0.136500     |   0\n",
      "      35429 |   0.173204  |    0.220339     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 35430: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      35430 |   0.098829  |    0.054952     |   0\n",
      "      35431 |   0.038058  |    0.057814     |   2\n",
      "      35432 |   0.026619  |    0.090861     |   2\n",
      "      35433 |   0.031665  |    0.022160     |   2\n",
      "      35434 |   0.128064  |    0.053843     |   0\n",
      "      35435 |   0.122039  |    0.246612     |   1\n",
      "      35436 |   0.134699  |    0.230125     |   1\n",
      "      35437 |   0.029992  |    0.043113     |   2\n",
      "      35438 |   0.022443  |    0.116760     |   2\n",
      "      35439 |   0.027733  |    0.065540     |   2\n",
      "      35440 |   0.196813  |    0.071340     |   0\n",
      "      35441 |   0.206482  |    0.246295     |   1\n",
      "      35442 |   0.141877  |    0.007049     |   0\n",
      "      35443 |   0.043821  |    0.088242     |   2\n",
      "      35444 |   0.043031  |    0.043109     |   2\n",
      "      35445 |   0.189955  |    0.225149     |   1\n",
      "      35446 |   0.035687  |    0.031530     |   2\n",
      "      35447 |   0.166692  |    0.224101     |   1\n",
      "      35448 |   0.136633  |    0.003473     |   0\n",
      "      35449 |   0.184059  |    0.236520     |   1\n",
      "      35450 |   0.218060  |    0.091049     |   0\n",
      "      35451 |   0.015895  |    0.015013     |   2\n",
      "      35452 |   0.202525  |    0.230621     |   1\n",
      "      35453 |   0.139606  |    0.097516     |   0\n",
      "      35454 |   0.205047  |    0.050310     |   0\n",
      "      35455 |   0.233821  |    0.205571     |   1\n",
      "      35456 |   0.172295  |    0.173175     |   1\n",
      "      35457 |   0.200961  |    0.295601     |   1\n",
      "      35458 |   0.198079  |    0.025782     |   0\n",
      "      35459 |   0.169043  |    0.118147     |   0\n",
      "      35460 |   0.000012  |    0.019353     |   2\n",
      "      35461 |   0.162790  |    0.215656     |   1\n",
      "      35462 |   0.183295  |    0.295494     |   1\n",
      "      35463 |   0.003947  |    0.006305     |   2\n",
      "      35464 |   0.160749  |    0.079034     |   0\n",
      "      35465 |   0.148587  |    0.054789     |   0\n",
      "      35466 |   0.208149  |    0.232675     |   1\n",
      "      35467 |   0.050629  |    0.024763     |   2\n",
      "      35468 |   0.164026  |    0.113933     |   0\n",
      "      35469 |   0.025161  |    0.023816     |   2\n",
      "      35470 |   0.153499  |    0.098573     |   0\n",
      "      35471 |   0.171375  |    0.194141     |   1\n",
      "      35472 |   0.049202  |    0.039214     |   2\n",
      "      35473 |   0.156001  |    0.280369     |   1\n",
      "      35474 |   0.120067  |    0.052506     |   0\n",
      "      35475 |   0.175067  |    0.074174     |   0\n",
      "      35476 |   0.034324  |    0.016626     |   2\n",
      "      35477 |   0.146831  |    0.111343     |   0\n",
      "      35478 |   0.182407  |    0.065266     |   0\n",
      "      35479 |   0.174262  |    0.215094     |   1\n",
      "      35480 |   0.164530  |    0.271874     |   1\n",
      "      35481 |   0.014236  |    0.010231     |   2\n",
      "      35482 |   0.028736  |    0.069689     |   2\n",
      "      35483 |   0.206365  |    0.040194     |   0\n",
      "      35484 |   0.203478  |    0.221659     |   1\n",
      "      35485 |   0.212817  |    0.237184     |   1\n",
      "      35486 |   0.023790  |    0.020768     |   2\n",
      "      35487 |   0.153046  |    0.110403     |   0\n",
      "      35488 |   0.000012  |    0.041838     |   2\n",
      "      35489 |   0.000012  |    0.072020     |   2\n",
      "      35490 |   0.000012  |    0.065599     |   2\n",
      "      35491 |   0.147517  |    0.226824     |   1\n",
      "      35492 |   0.218775  |    0.092354     |   0\n",
      "      35493 |   0.000012  |    0.070171     |   2\n",
      "      35494 |   0.000012  |    0.137799     |   2\n",
      "      35495 |   0.145951  |    0.025145     |   0\n",
      "      35496 |   0.159406  |    0.075071     |   0\n",
      "      35497 |   0.000012  |    0.112914     |   2\n",
      "      35498 |   0.232213  |    0.285280     |   1\n",
      "      35499 |   0.039033  |    0.022282     |   2\n",
      "      35500 |   0.042193  |    0.138401     |   2\n",
      "      35501 |   0.142019  |    0.383490     |   1\n",
      "      35502 |   0.039510  |    0.070243     |   2\n",
      "      35503 |   0.026283  |    0.105613     |   2\n",
      "      35504 |   0.033962  |    0.062473     |   2\n",
      "      35505 |   0.196648  |    0.252146     |   1\n",
      "      35506 |   0.031090  |    0.049317     |   2\n",
      "      35507 |   0.022219  |    0.133424     |   2\n",
      "      35508 |   0.147696  |    0.049192     |   0\n",
      "      35509 |   0.172744  |    0.097225     |   0\n",
      "      35510 |   0.145825  |    0.105439     |   0\n",
      "      35511 |   0.178980  |    0.276772     |   1\n",
      "      35512 |   0.166665  |    0.043167     |   0\n",
      "      35513 |   0.178130  |    0.065482     |   0\n",
      "      35514 |   0.145144  |    0.074783     |   0\n",
      "      35515 |   0.138111  |    0.226083     |   1\n",
      "      35516 |   0.028487  |    0.097503     |   2\n",
      "      35517 |   0.135836  |    0.227969     |   1\n",
      "      35518 |   0.184338  |    0.251528     |   1\n",
      "      35519 |   0.159089  |    0.313386     |   1\n",
      "      35520 |   0.199385  |    0.232520     |   1\n",
      "      35521 |   0.149521  |    0.042734     |   0\n",
      "      35522 |   0.041083  |    0.102813     |   2\n",
      "      35523 |   0.041545  |    0.034621     |   2\n",
      "      35524 |   0.129941  |    0.112232     |   0\n",
      "      35525 |   0.125151  |    0.065822     |   0\n",
      "      35526 |   0.173202  |    0.243727     |   1\n",
      "      35527 |   0.181248  |    0.281499     |   1\n",
      "      35528 |   0.184761  |    0.030710     |   0\n",
      "      35529 |   0.193012  |    0.074527     |   0\n",
      "      35530 |   0.146666  |    0.089544     |   0\n",
      "      35531 |   0.164149  |    0.275310     |   1\n",
      "      35532 |   0.140629  |    0.209211     |   1\n",
      "      35533 |   0.033604  |    0.019072     |   2\n",
      "      35534 |   0.165100  |    0.250263     |   1\n",
      "      35535 |   0.149003  |    0.012470     |   0\n",
      "      35536 |   0.166505  |    0.043207     |   0\n",
      "      35537 |   0.129360  |    0.079410     |   0\n",
      "      35538 |   0.017602  |    0.095767     |   2\n",
      "      35539 |   0.000012  |    0.035783     |   2\n",
      "      35540 |   0.127116  |    0.079389     |   0\n",
      "      35541 |   0.177096  |    0.213332     |   1\n",
      "      35542 |   0.003552  |    0.027467     |   2\n",
      "      35543 |   0.145011  |    0.121851     |   0\n",
      "      35544 |   0.146772  |    0.209337     |   1\n",
      "      35545 |   0.195431  |    0.204087     |   1\n",
      "      35546 |   0.154500  |    0.215391     |   1\n",
      "      35547 |   0.050116  |    0.027813     |   2\n",
      "      35548 |   0.205166  |    0.273047     |   1\n",
      "      35549 |   0.159151  |    0.007156     |   0\n",
      "      35550 |   0.028224  |    0.072036     |   2\n",
      "      35551 |   0.118152  |    0.086315     |   0\n",
      "      35552 |   0.153303  |    0.035921     |   0\n",
      "      35553 |   0.050288  |    0.067368     |   2\n",
      "      35554 |   0.036358  |    0.080737     |   2\n",
      "      35555 |   0.014656  |    0.066381     |   2\n",
      "      35556 |   0.030383  |    0.073254     |   2\n",
      "      35557 |   0.146688  |    0.046288     |   0\n",
      "      35558 |   0.020422  |    0.084696     |   2\n",
      "      35559 |   0.154960  |    0.216196     |   1\n",
      "      35560 |   0.000012  |    0.036549     |   2\n",
      "      35561 |   0.170718  |    0.073151     |   0\n",
      "      35562 |   0.000012  |    0.064260     |   2\n",
      "      35563 |   0.000012  |    0.089697     |   2\n",
      "      35564 |   0.000012  |    0.038669     |   2\n",
      "      35565 |   0.139154  |    0.071031     |   0\n",
      "      35566 |   0.161547  |    0.274952     |   1\n",
      "      35567 |   0.000012  |    0.025840     |   2\n",
      "      35568 |   0.000012  |    0.105464     |   2\n",
      "      35569 |   0.143119  |    0.025984     |   0\n",
      "      35570 |   0.039805  |    0.064392     |   2\n",
      "      35571 |   0.040675  |    0.079196     |   2\n",
      "      35572 |   0.140920  |    0.211725     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 35573: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      35573 |   0.040390  |    0.007330     |   2\n",
      "      35574 |   0.025740  |    0.106207     |   2\n",
      "      35575 |   0.148210  |    0.227648     |   1\n",
      "      35576 |   0.032776  |    0.005632     |   2\n",
      "      35577 |   0.165119  |    0.099817     |   0\n",
      "      35578 |   0.029543  |    0.048181     |   2\n",
      "      35579 |   0.022197  |    0.051542     |   2\n",
      "      35580 |   0.179097  |    0.261312     |   1\n",
      "      35581 |   0.028601  |    0.043718     |   2\n",
      "      35582 |   0.043307  |    0.050198     |   2\n",
      "      35583 |   0.041583  |    0.047262     |   2\n",
      "      35584 |   0.176228  |    0.277135     |   1\n",
      "      35585 |   0.035403  |    0.026365     |   2\n",
      "      35586 |   0.016979  |    0.076956     |   2\n",
      "      35587 |   0.195777  |    0.260873     |   1\n",
      "      35588 |   0.000012  |    0.013894     |   2\n",
      "      35589 |   0.139419  |    0.217651     |   1\n",
      "      35590 |   0.193321  |    0.025705     |   0\n",
      "      35591 |   0.003542  |    0.127259     |   2\n",
      "      35592 |   0.049611  |    0.008567     |   2\n",
      "      35593 |   0.140279  |    0.089686     |   0\n",
      "      35594 |   0.111079  |    0.251373     |   1\n",
      "      35595 |   0.026548  |    0.033566     |   2\n",
      "      35596 |   0.049538  |    0.083091     |   2\n",
      "      35597 |   0.033446  |    0.041154     |   2\n",
      "      35598 |   0.012227  |    0.072934     |   2\n",
      "      35599 |   0.027983  |    0.027538     |   2\n",
      "      35600 |   0.150115  |    0.247793     |   1\n",
      "      35601 |   0.019449  |    0.062175     |   2\n",
      "      35602 |   0.000012  |    0.049493     |   2\n",
      "      35603 |   0.143945  |    0.044376     |   0\n",
      "      35604 |   0.000012  |    0.078054     |   2\n",
      "      35605 |   0.159231  |    0.027753     |   0\n",
      "      35606 |   0.157766  |    0.080021     |   0\n",
      "      35607 |   0.189678  |    0.032518     |   0\n",
      "      35608 |   0.000012  |    0.102505     |   2\n",
      "      35609 |   0.000012  |    0.031451     |   2\n",
      "      35610 |   0.000012  |    0.059286     |   2\n",
      "      35611 |   0.145217  |    0.260957     |   1\n",
      "      35612 |   0.144908  |    0.133724     |   1\n",
      "      35613 |   0.000012  |    0.009057     |   2\n",
      "      35614 |   0.177791  |    0.098249     |   0\n",
      "      35615 |   0.037237  |    0.049485     |   2\n",
      "      35616 |   0.122948  |    0.232373     |   1\n",
      "      35617 |   0.162384  |    0.197180     |   1\n",
      "      35618 |   0.117749  |    0.150684     |   1\n",
      "      35619 |   0.152229  |    0.199915     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 35621: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      35620 |   0.039581  |    0.015631     |   2\n",
      "      35621 |   0.113703  |    0.059475     |   0\n",
      "      35622 |   0.136842  |    0.037056     |   0\n",
      "      35623 |   0.152677  |    0.081701     |   0\n",
      "      35624 |   0.124498  |    0.025859     |   0\n",
      "      35625 |   0.037601  |    0.057852     |   2\n",
      "      35626 |   0.187900  |    0.226256     |   1\n",
      "      35627 |   0.023903  |    0.005087     |   2\n",
      "      35628 |   0.115377  |    0.096645     |   0\n",
      "      35629 |   0.236076  |    0.191203     |   1\n",
      "      35630 |   0.184672  |    0.122479     |   1\n",
      "      35631 |   0.033296  |    0.042087     |   2\n",
      "      35632 |   0.030659  |    0.054940     |   2\n",
      "      35633 |   0.189697  |    0.208054     |   1\n",
      "      35634 |   0.108735  |    0.019740     |   0\n",
      "      35635 |   0.022179  |    0.090969     |   2\n",
      "      35636 |   0.153816  |    0.196527     |   1\n",
      "      35637 |   0.169402  |    0.142096     |   1\n",
      "      35638 |   0.181177  |    0.202321     |   1\n",
      "      35639 |   0.029165  |    0.006088     |   2\n",
      "      35640 |   0.167572  |    0.052607     |   0\n",
      "      35641 |   0.158314  |    0.069704     |   0\n",
      "      35642 |   0.043782  |    0.048657     |   2\n",
      "      35643 |   0.249019  |    0.070325     |   0\n",
      "      35644 |   0.039724  |    0.036212     |   2\n",
      "      35645 |   0.033273  |    0.078697     |   2\n",
      "      35646 |   0.016466  |    0.007196     |   2\n",
      "      35647 |   0.000012  |    0.090476     |   2\n",
      "      35648 |   0.003622  |    0.043825     |   2\n",
      "      35649 |   0.192887  |    0.159812     |   1\n",
      "      35650 |   0.140197  |    0.075479     |   0\n",
      "      35651 |   0.046466  |    0.024901     |   2\n",
      "      35652 |   0.182395  |    0.201797     |   1\n",
      "      35653 |   0.028004  |    0.005792     |   2\n",
      "      35654 |   0.177570  |    0.049902     |   0\n",
      "      35655 |   0.047727  |    0.037539     |   2\n",
      "      35656 |   0.034081  |    0.076977     |   2\n",
      "      35657 |   0.012064  |    0.039638     |   2\n",
      "      35658 |   0.028406  |    0.038737     |   2\n",
      "      35659 |   0.178448  |    0.207104     |   1\n",
      "      35660 |   0.022777  |    0.025370     |   2\n",
      "      35661 |   0.000012  |    0.090675     |   2\n",
      "      35662 |   0.150015  |    0.143417     |   1\n",
      "      35663 |   0.178117  |    0.038039     |   0\n",
      "      35664 |   0.000012  |    0.086052     |   2\n",
      "      35665 |   0.000012  |    0.017964     |   2\n",
      "      35666 |   0.163752  |    0.077086     |   0\n",
      "      35667 |   0.000012  |    0.049120     |   2\n",
      "      35668 |   0.170204  |    0.148271     |   1\n",
      "      35669 |   0.138462  |    0.046495     |   0\n",
      "      35670 |   0.177807  |    0.193776     |   1\n",
      "      35671 |   0.217027  |    0.135975     |   1\n",
      "      35672 |   0.161996  |    0.030366     |   0\n",
      "      35673 |   0.123640  |    0.046771     |   0\n",
      "      35674 |   0.148317  |    0.058589     |   0\n",
      "      35675 |   0.182316  |    0.178722     |   1\n",
      "      35676 |   0.000012  |    0.026644     |   2\n",
      "      35677 |   0.158548  |    0.186794     |   1\n",
      "      35678 |   0.000012  |    0.023303     |   2\n",
      "      35679 |   0.037205  |    0.085714     |   2\n",
      "      35680 |   0.041690  |    0.009205     |   2\n",
      "      35681 |   0.175211  |    0.220486     |   1\n",
      "      35682 |   0.182097  |    0.161890     |   1\n",
      "      35683 |   0.123110  |    0.207727     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 35684: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      35684 |   0.141425  |    0.106592     |   1\n",
      "      35685 |   0.035776  |    0.024473     |   2\n",
      "      35686 |   0.023962  |    0.049847     |   2\n",
      "      35687 |   0.033944  |    0.077570     |   2\n",
      "      35688 |   0.181482  |    0.148125     |   1\n",
      "      35689 |   0.192546  |    0.151945     |   1\n",
      "      35690 |   0.028763  |    0.049206     |   2\n",
      "      35691 |   0.170642  |    0.184502     |   1\n",
      "      35692 |   0.153462  |    0.180222     |   1\n",
      "      35693 |   0.188359  |    0.159069     |   1\n",
      "      35694 |   0.164621  |    0.101719     |   1\n",
      "      35695 |   0.114324  |    0.194217     |   1\n",
      "      35696 |   0.177105  |    0.042067     |   0\n",
      "      35697 |   0.156766  |    0.026658     |   0\n",
      "      35698 |   0.126048  |    0.048693     |   0\n",
      "      35699 |   0.021921  |    0.041417     |   2\n",
      "      35700 |   0.028339  |    0.073191     |   2\n",
      "      35701 |   0.038601  |    0.037464     |   2\n",
      "      35702 |   0.041463  |    0.048379     |   2\n",
      "      35703 |   0.190572  |    0.048075     |   0\n",
      "      35704 |   0.182930  |    0.038911     |   0\n",
      "      35705 |   0.140828  |    0.208725     |   1\n",
      "      35706 |   0.182816  |    0.158640     |   1\n",
      "      35707 |   0.196486  |    0.030081     |   0\n",
      "      35708 |   0.034917  |    0.077594     |   2\n",
      "      35709 |   0.132725  |    0.204134     |   1\n",
      "      35710 |   0.164110  |    0.014475     |   0\n",
      "      35711 |   0.151709  |    0.091149     |   0\n",
      "      35712 |   0.015583  |    0.008636     |   2\n",
      "      35713 |   0.183421  |    0.079999     |   0\n",
      "      35714 |   0.131483  |    0.163540     |   1\n",
      "      35715 | \u001b[94m  0.000012\u001b[0m  |    0.026131     |   2\n",
      "      35716 |   0.130893  |    0.200371     |   1\n",
      "      35717 |   0.003808  |    0.047481     |   2\n",
      "      35718 |   0.045609  |    0.040406     |   2\n",
      "      35719 |   0.029303  |    0.079407     |   2\n",
      "      35720 |   0.168532  |    0.026233     |   0\n",
      "      35721 |   0.196868  |    0.073599     |   0\n",
      "      35722 |   0.123310  |    0.025416     |   0\n",
      "      35723 |   0.050621  |    0.084005     |   2\n",
      "      35724 |   0.225913  |    0.141581     |   1\n",
      "      35725 |   0.160432  |    0.072165     |   0\n",
      "      35726 |   0.166220  |    0.030442     |   0\n",
      "      35727 |   0.240517  |    0.197785     |   1\n",
      "      35728 |   0.237311  |    0.138370     |   1\n",
      "      35729 |   0.034221  |    0.010433     |   2\n",
      "      35730 |   0.138138  |    0.209200     |   1\n",
      "      35731 |   0.209774  |    0.148023     |   1\n",
      "      35732 |   0.151789  |    0.075521     |   0\n",
      "      35733 |   0.012780  |    0.021541     |   2\n",
      "      35734 |   0.160058  |    0.077371     |   0\n",
      "      35735 |   0.161113  |    0.039229     |   0\n",
      "      35736 |   0.175649  |    0.230373     |   1\n",
      "      35737 |   0.030634  |    0.070731     |   2\n",
      "      35738 |   0.019298  |    0.072633     |   2\n",
      "      35739 |   0.000012  |    0.079352     |   2\n",
      "      35740 |   0.000012  |    0.078588     |   2\n",
      "      35741 |   0.230277  |    0.281583     |   1\n",
      "      35742 |   0.151897  |    0.038539     |   0\n",
      "      35743 |   0.157511  |    0.076946     |   0\n",
      "      35744 |   0.119073  |    0.271285     |   1\n",
      "      35745 |   0.157690  |    0.219895     |   1\n",
      "      35746 |   0.156756  |    0.070004     |   0\n",
      "      35747 |   0.000012  |    0.046949     |   2\n",
      "      35748 |   0.166495  |    0.276426     |   1\n",
      "      35749 |   0.000012  |    0.072248     |   2\n",
      "      35750 |   0.161594  |    0.199260     |   1\n",
      "      35751 |   0.153718  |    0.163951     |   1\n",
      "      35752 |   0.180702  |    0.211877     |   1\n",
      "      35753 |   0.166918  |    0.005378     |   0\n",
      "      35754 |   0.000012  |    0.024223     |   2\n",
      "      35755 |   0.000012  |    0.081679     |   2\n",
      "      35756 |   0.206211  |    0.040699     |   0\n",
      "      35757 |   0.173999  |    0.046620     |   0\n",
      "      35758 |   0.196505  |    0.070542     |   0\n",
      "      35759 |   0.126059  |    0.029181     |   0\n",
      "      35760 |   0.130595  |    0.231239     |   1\n",
      "      35761 |   0.136584  |    0.183816     |   1\n",
      "      35762 |   0.188949  |    0.022230     |   0\n",
      "      35763 |   0.037787  |    0.086183     |   2\n",
      "      35764 |   0.171598  |    0.046668     |   0\n",
      "      35765 |   0.183035  |    0.200111     |   1\n",
      "      35766 |   0.149745  |    0.199671     |   1\n",
      "      35767 |   0.041282  |    0.010914     |   2\n",
      "      35768 |   0.140016  |    0.074901     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 35769: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      35769 |   0.035108  |    0.012082     |   2\n",
      "      35770 |   0.147835  |    0.218600     |   1\n",
      "      35771 |   0.136250  |    0.030827     |   0\n",
      "      35772 |   0.163248  |    0.236929     |   1\n",
      "      35773 |   0.025678  |    0.016264     |   2\n",
      "      35774 |   0.153183  |    0.255674     |   1\n",
      "      35775 |   0.160579  |    0.138322     |   1\n",
      "      35776 |   0.187724  |    0.044768     |   0\n",
      "      35777 |   0.183847  |    0.094503     |   0\n",
      "      35778 |   0.163019  |    0.052217     |   0\n",
      "      35779 |   0.030934  |    0.047777     |   2\n",
      "      35780 |   0.132682  |    0.057578     |   0\n",
      "      35781 |   0.169729  |    0.040343     |   0\n",
      "      35782 |   0.172220  |    0.047914     |   0\n",
      "      35783 |   0.159134  |    0.185156     |   1\n",
      "      35784 |   0.227564  |    0.200242     |   1\n",
      "      35785 |   0.119183  |    0.006723     |   0\n",
      "      35786 |   0.029714  |    0.076931     |   2\n",
      "      35787 |   0.230756  |    0.044480     |   0\n",
      "      35788 |   0.022705  |    0.081183     |   2\n",
      "      35789 |   0.029893  |    0.013197     |   2\n",
      "      35790 |   0.044360  |    0.129285     |   2\n",
      "      35791 |   0.041411  |    0.024278     |   2\n",
      "      35792 |   0.147989  |    0.074731     |   0\n",
      "      35793 |   0.034048  |    0.040077     |   2\n",
      "      35794 |   0.176258  |    0.055288     |   0\n",
      "      35795 |   0.197407  |    0.031723     |   0\n",
      "      35796 |   0.233640  |    0.078090     |   0\n",
      "      35797 |   0.136810  |    0.207628     |   1\n",
      "      35798 |   0.204775  |    0.151744     |   1\n",
      "      35799 |   0.191235  |    0.157561     |   1\n",
      "      35800 |   0.245179  |    0.081844     |   0\n",
      "      35801 |   0.014557  |    0.055510     |   2\n",
      "      35802 |   0.145932  |    0.010329     |   0\n",
      "      35803 |   0.000012  |    0.086209     |   2\n",
      "      35804 |   0.149024  |    0.021712     |   0\n",
      "      35805 |   0.234837  |    0.229840     |   1\n",
      "      35806 |   0.154323  |    0.144238     |   1\n",
      "      35807 |   0.003802  |    0.050941     |   2\n",
      "      35808 |   0.134091  |    0.248399     |   1\n",
      "      35809 |   0.198788  |    0.157004     |   1\n",
      "      35810 |   0.194132  |    0.148945     |   1\n",
      "      35811 |   0.184040  |    0.170196     |   1\n",
      "      35812 |   0.213895  |    0.141056     |   1\n",
      "      35813 |   0.047789  |    0.009257     |   2\n",
      "      35814 |   0.193307  |    0.085235     |   0\n",
      "      35815 |   0.231440  |    0.154331     |   1\n",
      "      35816 |   0.028300  |    0.045353     |   2\n",
      "      35817 |   0.191883  |    0.214226     |   1\n",
      "      35818 |   0.158888  |    0.009555     |   0\n",
      "      35819 |   0.050248  |    0.053600     |   2\n",
      "      35820 |   0.153800  |    0.244708     |   1\n",
      "      35821 |   0.151461  |    0.198659     |   1\n",
      "      35822 |   0.191310  |    0.082410     |   0\n",
      "      35823 |   0.169880  |    0.192572     |   1\n",
      "      35824 |   0.033473  |    0.038986     |   2\n",
      "      35825 |   0.218895  |    0.181694     |   1\n",
      "      35826 |   0.011209  |    0.017925     |   2\n",
      "      35827 |   0.213201  |    0.232256     |   1\n",
      "      35828 |   0.141579  |    0.040182     |   0\n",
      "      35829 |   0.247746  |    0.086711     |   0\n",
      "      35830 |   0.027301  |    0.040496     |   2\n",
      "      35831 |   0.020896  |    0.072706     |   2\n",
      "      35832 |   0.000012  |    0.041383     |   2\n",
      "      35833 |   0.190797  |    0.047681     |   0\n",
      "      35834 |   0.000012  |    0.056884     |   2\n",
      "      35835 |   0.177328  |    0.207105     |   1\n",
      "      35836 |   0.152894  |    0.005245     |   0\n",
      "      35837 |   0.213237  |    0.075135     |   0\n",
      "      35838 |   0.156955  |    0.026174     |   0\n",
      "      35839 |   0.154615  |    0.077986     |   0\n",
      "      35840 |   0.156584  |    0.198949     |   1\n",
      "      35841 |   0.126385  |    0.007103     |   0\n",
      "      35842 |   0.169478  |    0.046293     |   0\n",
      "      35843 |   0.000012  |    0.072476     |   2\n",
      "      35844 |   0.158633  |    0.025217     |   0\n",
      "      35845 |   0.000012  |    0.077199     |   2\n",
      "      35846 |   0.152765  |    0.143873     |   1\n",
      "      35847 | \u001b[94m  0.000012\u001b[0m  |    0.018483     |   2\n",
      "      35848 |   0.152702  |    0.078691     |   0\n",
      "      35849 | \u001b[94m  0.000012\u001b[0m  |    0.054218     |   2\n",
      "      35850 |   0.155692  |    0.197393     |   1\n",
      "      35851 |   0.158905  |    0.155550     |   1\n",
      "      35852 |   0.159106  |    0.009850     |   0\n",
      "      35853 |   0.181365  |    0.186366     |   1\n",
      "      35854 |   0.040496  |    0.091390     |   2\n",
      "      35855 |   0.131868  |    0.153933     |   1\n",
      "      35856 |   0.041316  |    0.040219     |   2\n",
      "      35857 |   0.204096  |    0.074010     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 35858: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      35858 |   0.038993  |    0.071599     |   2\n",
      "      35859 |   0.126639  |    0.036206     |   0\n",
      "      35860 |   0.143642  |    0.188020     |   1\n",
      "      35861 |   0.148475  |    0.009597     |   0\n",
      "      35862 |   0.026018  |    0.042081     |   2\n",
      "      35863 |   0.033197  |    0.071517     |   2\n",
      "      35864 |   0.029769  |    0.040562     |   2\n",
      "      35865 |   0.229387  |    0.087988     |   0\n",
      "      35866 |   0.122090  |    0.136398     |   1\n",
      "      35867 |   0.023825  |    0.049168     |   2\n",
      "      35868 |   0.157316  |    0.043621     |   0\n",
      "      35869 |   0.143558  |    0.073566     |   0\n",
      "      35870 |   0.196908  |    0.142127     |   1\n",
      "      35871 |   0.029965  |    0.043412     |   2\n",
      "      35872 |   0.141574  |    0.185168     |   1\n",
      "      35873 |   0.040451  |    0.044284     |   2\n",
      "      35874 |   0.148177  |    0.050082     |   0\n",
      "      35875 |   0.144050  |    0.057483     |   0\n",
      "      35876 |   0.218256  |    0.139840     |   1\n",
      "      35877 |   0.042236  |    0.024450     |   2\n",
      "      35878 |   0.215523  |    0.076599     |   0\n",
      "      35879 |   0.033930  |    0.014870     |   2\n",
      "      35880 |   0.014268  |    0.080006     |   2\n",
      "      35881 |   0.213098  |    0.023835     |   0\n",
      "      35882 |   0.157903  |    0.082902     |   0\n",
      "      35883 |   0.000012  |    0.009178     |   2\n",
      "      35884 |   0.223846  |    0.073278     |   0\n",
      "      35885 |   0.003764  |    0.028339     |   2\n",
      "      35886 |   0.145190  |    0.199138     |   1\n",
      "      35887 |   0.116540  |    0.010982     |   0\n",
      "      35888 |   0.197132  |    0.090396     |   0\n",
      "      35889 |   0.047770  |    0.017701     |   2\n",
      "      35890 |   0.190834  |    0.087347     |   0\n",
      "      35891 |   0.178130  |    0.141613     |   1\n",
      "      35892 |   0.135092  |    0.076367     |   0\n",
      "      35893 |   0.151480  |    0.037261     |   0\n",
      "      35894 |   0.189488  |    0.191090     |   1\n",
      "      35895 |   0.029061  |    0.014567     |   2\n",
      "      35896 |   0.052116  |    0.081245     |   2\n",
      "      35897 |   0.035379  |    0.021350     |   2\n",
      "      35898 |   0.125450  |    0.248037     |   1\n",
      "      35899 |   0.169425  |    0.007378     |   0\n",
      "      35900 |   0.173733  |    0.083679     |   0\n",
      "      35901 |   0.180368  |    0.210025     |   1\n",
      "      35902 |   0.013939  |    0.003629     |   2\n",
      "      35903 |   0.028779  |    0.058045     |   2\n",
      "      35904 |   0.127663  |    0.208909     |   1\n",
      "      35905 |   0.171639  |    0.136540     |   1\n",
      "      35906 |   0.130408  |    0.033717     |   0\n",
      "      35907 |   0.177173  |    0.195133     |   1\n",
      "      35908 |   0.021663  |    0.028702     |   2\n",
      "      35909 |   0.000012  |    0.088319     |   2\n",
      "      35910 |   0.232808  |    0.025797     |   0\n",
      "      35911 |   0.141807  |    0.046608     |   0\n",
      "      35912 |   0.198545  |    0.084317     |   0\n",
      "      35913 |   0.224849  |    0.142169     |   1\n",
      "      35914 |   0.167787  |    0.177654     |   1\n",
      "      35915 |   0.188222  |    0.146184     |   1\n",
      "      35916 |   0.000012  |    0.059775     |   2\n",
      "      35917 |   0.165002  |    0.043659     |   0\n",
      "      35918 |   0.000012  |    0.047469     |   2\n",
      "      35919 |   0.000012  |    0.042892     |   2\n",
      "      35920 |   0.000012  |    0.045417     |   2\n",
      "      35921 |   0.162861  |    0.043461     |   0\n",
      "      35922 |   0.189835  |    0.205590     |   1\n",
      "      35923 |   0.000012  |    0.005592     |   2\n",
      "      35924 |   0.035727  |    0.084626     |   2\n",
      "      35925 |   0.039914  |    0.040214     |   2\n",
      "      35926 |   0.133708  |    0.044994     |   0\n",
      "      35927 |   0.209238  |    0.195364     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 35928: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      35928 |   0.039228  |    0.003761     |   2\n",
      "      35929 |   0.024328  |    0.075700     |   2\n",
      "      35930 |   0.138724  |    0.013925     |   0\n",
      "      35931 |   0.140283  |    0.197989     |   1\n",
      "      35932 |   0.202698  |    0.013008     |   0\n",
      "      35933 |   0.033043  |    0.073126     |   2\n",
      "      35934 |   0.151826  |    0.088417     |   0\n",
      "      35935 |   0.165715  |    0.135964     |   1\n",
      "      35936 |   0.028905  |    0.047574     |   2\n",
      "      35937 |   0.021972  |    0.042569     |   2\n",
      "      35938 |   0.030474  |    0.040388     |   2\n",
      "      35939 |   0.177389  |    0.202528     |   1\n",
      "      35940 |   0.041386  |    0.027457     |   2\n",
      "      35941 |   0.042793  |    0.083748     |   2\n",
      "      35942 |   0.140409  |    0.193958     |   1\n",
      "      35943 |   0.034752  |    0.011794     |   2\n",
      "      35944 |   0.175534  |    0.202949     |   1\n",
      "      35945 |   0.015356  |    0.009488     |   2\n",
      "      35946 |   0.128150  |    0.076107     |   0\n",
      "      35947 |   0.139905  |    0.165538     |   1\n",
      "      35948 |   0.000012  |    0.032583     |   2\n",
      "      35949 |   0.004462  |    0.053103     |   2\n",
      "      35950 |   0.045089  |    0.026458     |   2\n",
      "      35951 |   0.175383  |    0.064384     |   0\n",
      "      35952 |   0.134867  |    0.215802     |   1\n",
      "      35953 |   0.156973  |    0.146976     |   1\n",
      "      35954 |   0.200140  |    0.035598     |   0\n",
      "      35955 |   0.205303  |    0.207456     |   1\n",
      "      35956 |   0.180440  |    0.018275     |   0\n",
      "      35957 |   0.180975  |    0.195945     |   1\n",
      "      35958 |   0.163036  |    0.160036     |   1\n",
      "      35959 |   0.026872  |    0.005899     |   2\n",
      "      35960 |   0.205340  |    0.088248     |   0\n",
      "      35961 |   0.181565  |    0.182475     |   1\n",
      "      35962 |   0.047945  |    0.014685     |   2\n",
      "      35963 |   0.230391  |    0.202331     |   1\n",
      "      35964 |   0.035745  |    0.007292     |   2\n",
      "      35965 |   0.013495  |    0.074599     |   2\n",
      "      35966 |   0.215376  |    0.053626     |   0\n",
      "      35967 |   0.181589  |    0.202428     |   1\n",
      "      35968 |   0.172842  |    0.017474     |   0\n",
      "      35969 |   0.136888  |    0.187519     |   1\n",
      "      35970 |   0.217788  |    0.205475     |   1\n",
      "      35971 |   0.198411  |    0.141840     |   1\n",
      "      35972 |   0.256169  |    0.160758     |   1\n",
      "      35973 |   0.028360  |    0.012740     |   2\n",
      "      35974 |   0.148457  |    0.192382     |   1\n",
      "      35975 |   0.020795  |    0.043878     |   2\n",
      "      35976 |   0.206956  |    0.079819     |   0\n",
      "      35977 |   0.199101  |    0.147910     |   1\n",
      "      35978 |   0.168784  |    0.194273     |   1\n",
      "      35979 |   0.000012  |    0.020134     |   2\n",
      "      35980 |   0.119370  |    0.207721     |   1\n",
      "      35981 |   0.000012  |    0.047376     |   2\n",
      "      35982 |   0.182511  |    0.047964     |   0\n",
      "      35983 |   0.193410  |    0.074431     |   0\n",
      "      35984 |   0.183165  |    0.014380     |   0\n",
      "      35985 |   0.163559  |    0.058787     |   0\n",
      "      35986 |   0.000012  |    0.029776     |   2\n",
      "      35987 |   0.000012  |    0.081076     |   2\n",
      "      35988 |   0.199396  |    0.018160     |   0\n",
      "      35989 |   0.126645  |    0.061309     |   0\n",
      "      35990 |   0.158399  |    0.159237     |   1\n",
      "      35991 |   0.176040  |    0.043021     |   0\n",
      "      35992 |   0.122497  |    0.036224     |   0\n",
      "      35993 | \u001b[94m  0.000012\u001b[0m  |    0.048366     |   2\n",
      "      35994 | \u001b[94m  0.000012\u001b[0m  |    0.049301     |   2\n",
      "      35995 |   0.146857  |    0.196916     |   1\n",
      "      35996 |   0.178656  |    0.039947     |   0\n",
      "      35997 |   0.211366  |    0.189532     |   1\n",
      "      35998 |   0.161453  |    0.017949     |   0\n",
      "      35999 |   0.039472  |    0.043501     |   2\n",
      "      36000 |   0.158264  |    0.186307     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 36000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 36000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      36001 |   0.040183  |    0.089943     |   2\n",
      "      36002 |   0.166876  |    0.195184     |   1\n",
      "      36003 |   0.154710  |    0.008720     |   0\n",
      "      36004 |   0.171280  |    0.077233     |   0\n",
      "      36005 |   0.158494  |    0.210405     |   1\n",
      "      36006 |   0.145342  |    0.145157     |   1\n",
      "      36007 |   0.180020  |    0.045781     |   0\n",
      "      36008 |   0.147223  |    0.048729     |   0\n",
      "      36009 |   0.025634  |    0.097317     |   2\n",
      "      36010 |   0.156444  |    0.260266     |   1\n",
      "      36011 |   0.190091  |    0.190599     |   1\n",
      "      36012 |   0.031762  |    0.023337     |   2\n",
      "      36013 |   0.238523  |    0.159546     |   1\n",
      "      36014 |   0.148955  |    0.086202     |   0\n",
      "      36015 |   0.028947  |    0.009069     |   2\n",
      "      36016 |   0.022258  |    0.073887     |   2\n",
      "      36017 |   0.129376  |    0.214463     |   1\n",
      "      36018 |   0.192558  |    0.073647     |   0\n",
      "      36019 |   0.139331  |    0.213073     |   1\n",
      "      36020 |   0.135218  |    0.272349     |   1\n",
      "      36021 |   0.179072  |    0.071552     |   0\n",
      "      36022 |   0.193638  |    0.037190     |   0\n",
      "      36023 |   0.143312  |    0.197199     |   1\n",
      "      36024 |   0.027850  |    0.036308     |   2\n",
      "      36025 |   0.226704  |    0.169745     |   1\n",
      "      36026 |   0.135188  |    0.195780     |   1\n",
      "      36027 |   0.037623  |    0.076704     |   2\n",
      "      36028 |   0.040019  |    0.019246     |   2\n",
      "      36029 |   0.035385  |    0.075414     |   2\n",
      "      36030 |   0.144001  |    0.183342     |   1\n",
      "      36031 |   0.215748  |    0.200809     |   1\n",
      "      36032 |   0.211577  |    0.014483     |   0\n",
      "      36033 |   0.140306  |    0.204714     |   1\n",
      "      36034 |   0.014081  |    0.004263     |   2\n",
      "      36035 |   0.184005  |    0.079099     |   0\n",
      "      36036 |   0.187412  |    0.173965     |   1\n",
      "      36037 |   0.108759  |    0.156887     |   1\n",
      "      36038 |   0.203199  |    0.045697     |   0\n",
      "      36039 |   0.173527  |    0.198230     |   1\n",
      "      36040 |   0.000012  |    0.013005     |   2\n",
      "      36041 |   0.003836  |    0.085664     |   2\n",
      "      36042 |   0.181262  |    0.044387     |   0\n",
      "      36043 |   0.046856  |    0.051956     |   2\n",
      "      36044 |   0.206447  |    0.039544     |   0\n",
      "      36045 |   0.152384  |    0.208169     |   1\n",
      "      36046 |   0.209305  |    0.006321     |   0\n",
      "      36047 |   0.026333  |    0.088389     |   2\n",
      "      36048 |   0.169017  |    0.192349     |   1\n",
      "      36049 |   0.191099  |    0.159164     |   1\n",
      "      36050 |   0.049333  |    0.040643     |   2\n",
      "      36051 |   0.153513  |    0.038045     |   0\n",
      "      36052 |   0.033706  |    0.081043     |   2\n",
      "      36053 |   0.206382  |    0.031429     |   0\n",
      "      36054 |   0.013928  |    0.056536     |   2\n",
      "      36055 |   0.124198  |    0.201590     |   1\n",
      "      36056 |   0.201970  |    0.146972     |   1\n",
      "      36057 |   0.188331  |    0.156378     |   1\n",
      "      36058 |   0.192748  |    0.135627     |   1\n",
      "      36059 |   0.160227  |    0.165168     |   1\n",
      "      36060 |   0.026286  |    0.044139     |   2\n",
      "      36061 |   0.210931  |    0.199951     |   1\n",
      "      36062 |   0.180560  |    0.133058     |   1\n",
      "      36063 |   0.021552  |    0.080043     |   2\n",
      "      36064 |   0.000012  |    0.017191     |   2\n",
      "      36065 |   0.200905  |    0.199790     |   1\n",
      "      36066 |   0.167383  |    0.052031     |   0\n",
      "      36067 |   0.150890  |    0.148157     |   1\n",
      "      36068 |   0.151648  |    0.172722     |   1\n",
      "      36069 |   0.171038  |    0.138232     |   1\n",
      "      36070 | \u001b[94m  0.000012\u001b[0m  |    0.024712     |   2\n",
      "      36071 |   0.207170  |    0.075809     |   0\n",
      "      36072 |   0.145662  |    0.145071     |   1\n",
      "      36073 | \u001b[94m  0.000012\u001b[0m  |    0.080825     |   2\n",
      "      36074 |   0.139236  |    0.139124     |   1\n",
      "      36075 |   0.144123  |    0.015873     |   0\n",
      "      36076 | \u001b[94m  0.000012\u001b[0m  |    0.074858     |   2\n",
      "      36077 |   0.175036  |    0.134119     |   1\n",
      "      36078 |   0.177891  |    0.229211     |   1\n",
      "      36079 |   0.144086  |    0.156560     |   1\n",
      "      36080 |   0.171185  |    0.030344     |   0\n",
      "      36081 |   0.155439  |    0.216455     |   1\n",
      "      36082 |   0.178398  |    0.161208     |   1\n",
      "      36083 |   0.173946  |    0.145815     |   1\n",
      "      36084 |   0.180607  |    0.266379     |   1\n",
      "      36085 |   0.199345  |    0.213348     |   1\n",
      "      36086 |   0.162832  |    0.145199     |   1\n",
      "      36087 |   0.000012  |    0.014437     |   2\n",
      "      36088 |   0.147945  |    0.209909     |   1\n",
      "      36089 |   0.000012  |    0.005077     |   2\n",
      "      36090 |   0.033413  |    0.079446     |   2\n",
      "      36091 |   0.183834  |    0.078934     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 36093: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      36092 |   0.040190  |    0.012985     |   2\n",
      "      36093 |   0.190933  |    0.189562     |   1\n",
      "      36094 |   0.037682  |    0.039995     |   2\n",
      "      36095 |   0.163364  |    0.203766     |   1\n",
      "      36096 |   0.139917  |    0.156013     |   1\n",
      "      36097 |   0.167171  |    0.186581     |   1\n",
      "      36098 |   0.025221  |    0.073480     |   2\n",
      "      36099 |   0.032244  |    0.049226     |   2\n",
      "      36100 |   0.174705  |    0.041410     |   0\n",
      "      36101 |   0.195768  |    0.073256     |   0\n",
      "      36102 |   0.174629  |    0.148284     |   1\n",
      "      36103 |   0.140248  |    0.042840     |   0\n",
      "      36104 |   0.030377  |    0.050094     |   2\n",
      "      36105 |   0.022248  |    0.046342     |   2\n",
      "      36106 |   0.204872  |    0.076841     |   0\n",
      "      36107 |   0.026716  |    0.023779     |   2\n",
      "      36108 |   0.147920  |    0.244533     |   1\n",
      "      36109 |   0.038686  |    0.004928     |   2\n",
      "      36110 |   0.038981  |    0.038817     |   2\n",
      "      36111 |   0.112142  |    0.203693     |   1\n",
      "      36112 |   0.184529  |    0.141582     |   1\n",
      "      36113 |   0.168901  |    0.046383     |   0\n",
      "      36114 |   0.036457  |    0.047101     |   2\n",
      "      36115 |   0.017757  |    0.037837     |   2\n",
      "      36116 |   0.123651  |    0.083841     |   0\n",
      "      36117 |   0.184036  |    0.022097     |   0\n",
      "      36118 | \u001b[94m  0.000012\u001b[0m  |    0.075900     |   2\n",
      "      36119 |   0.184519  |    0.039750     |   0\n",
      "      36120 |   0.003444  |    0.074031     |   2\n",
      "      36121 |   0.045942  |    0.041087     |   2\n",
      "      36122 |   0.026726  |    0.047565     |   2\n",
      "      36123 |   0.127254  |    0.222364     |   1\n",
      "      36124 |   0.179000  |    0.140330     |   1\n",
      "      36125 |   0.216907  |    0.162904     |   1\n",
      "      36126 |   0.194555  |    0.202039     |   1\n",
      "      36127 |   0.147939  |    0.020621     |   0\n",
      "      36128 |   0.128864  |    0.086161     |   0\n",
      "      36129 |   0.205998  |    0.137760     |   1\n",
      "      36130 |   0.131806  |    0.207152     |   1\n",
      "      36131 |   0.200450  |    0.160202     |   1\n",
      "      36132 |   0.050135  |    0.010091     |   2\n",
      "      36133 |   0.034230  |    0.054225     |   2\n",
      "      36134 |   0.234797  |    0.080561     |   0\n",
      "      36135 |   0.174309  |    0.167242     |   1\n",
      "      36136 |   0.204123  |    0.188799     |   1\n",
      "      36137 |   0.117033  |    0.009260     |   0\n",
      "      36138 |   0.205569  |    0.204301     |   1\n",
      "      36139 |   0.131105  |    0.152250     |   1\n",
      "      36140 |   0.012860  |    0.040522     |   2\n",
      "      36141 |   0.164225  |    0.194988     |   1\n",
      "      36142 |   0.179198  |    0.151569     |   1\n",
      "      36143 |   0.026594  |    0.024178     |   2\n",
      "      36144 |   0.188929  |    0.049947     |   0\n",
      "      36145 |   0.132755  |    0.071878     |   0\n",
      "      36146 |   0.022262  |    0.059128     |   2\n",
      "      36147 |   0.190043  |    0.160327     |   1\n",
      "      36148 |   0.166764  |    0.010068     |   0\n",
      "      36149 | \u001b[94m  0.000011\u001b[0m  |    0.073921     |   2\n",
      "      36150 |   0.212832  |    0.221254     |   1\n",
      "      36151 | \u001b[94m  0.000011\u001b[0m  |    0.007364     |   2\n",
      "      36152 |   0.130657  |    0.081336     |   0\n",
      "      36153 |   0.176214  |    0.166437     |   1\n",
      "      36154 |   0.153656  |    0.048353     |   0\n",
      "      36155 | \u001b[94m  0.000011\u001b[0m  |    0.054560     |   2\n",
      "      36156 |   0.173343  |    0.078809     |   0\n",
      "      36157 |   0.166214  |    0.043021     |   0\n",
      "      36158 | \u001b[94m  0.000011\u001b[0m  |    0.078885     |   2\n",
      "      36159 |   0.159977  |    0.050414     |   0\n",
      "      36160 |   0.162503  |    0.051705     |   0\n",
      "      36161 |   0.177730  |    0.074593     |   0\n",
      "      36162 |   0.239248  |    0.048737     |   0\n",
      "      36163 | \u001b[94m  0.000011\u001b[0m  |    0.047941     |   2\n",
      "      36164 |   0.199298  |    0.199157     |   1\n",
      "      36165 | \u001b[94m  0.000011\u001b[0m  |    0.009549     |   2\n",
      "      36166 |   0.131896  |    0.070903     |   0\n",
      "      36167 |   0.037688  |    0.023349     |   2\n",
      "      36168 |   0.174990  |    0.072579     |   0\n",
      "      36169 |   0.148575  |    0.022361     |   0\n",
      "      36170 |   0.041711  |    0.078525     |   2\n",
      "      36171 |   0.172757  |    0.059174     |   0\n",
      "      36172 |   0.169830  |    0.148771     |   1\n",
      "      36173 |   0.139674  |    0.233647     |   1\n",
      "      36174 |   0.179288  |    0.072510     |   0\n",
      "      36175 |   0.155889  |    0.297676     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 36176: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      36176 |   0.045288  |    0.016005     |   2\n",
      "      36177 |   0.029867  |    0.042337     |   2\n",
      "      36178 |   0.196483  |    0.084199     |   0\n",
      "      36179 |   0.175368  |    0.150133     |   1\n",
      "      36180 |   0.124389  |    0.136871     |   1\n",
      "      36181 |   0.204176  |    0.185159     |   1\n",
      "      36182 |   0.210877  |    0.043058     |   0\n",
      "      36183 |   0.156838  |    0.056744     |   0\n",
      "      36184 |   0.218273  |    0.199371     |   1\n",
      "      36185 |   0.173739  |    0.196216     |   1\n",
      "      36186 |   0.154074  |    0.007904     |   0\n",
      "      36187 |   0.170149  |    0.046617     |   0\n",
      "      36188 |   0.030894  |    0.081936     |   2\n",
      "      36189 |   0.169996  |    0.022309     |   0\n",
      "      36190 |   0.199188  |    0.204429     |   1\n",
      "      36191 |   0.164728  |    0.011681     |   0\n",
      "      36192 |   0.128904  |    0.221118     |   1\n",
      "      36193 |   0.149203  |    0.004423     |   0\n",
      "      36194 |   0.157575  |    0.045411     |   0\n",
      "      36195 |   0.137081  |    0.080547     |   0\n",
      "      36196 |   0.030240  |    0.021050     |   2\n",
      "      36197 |   0.170062  |    0.058720     |   0\n",
      "      36198 |   0.103792  |    0.212001     |   1\n",
      "      36199 |   0.177064  |    0.298810     |   1\n",
      "      36200 |   0.023790  |    0.015122     |   2\n",
      "      36201 |   0.179104  |    0.083935     |   0\n",
      "      36202 |   0.170941  |    0.038545     |   0\n",
      "      36203 |   0.157646  |    0.054593     |   0\n",
      "      36204 |   0.154926  |    0.202798     |   1\n",
      "      36205 |   0.262889  |    0.191813     |   1\n",
      "      36206 |   0.028485  |    0.006873     |   2\n",
      "      36207 |   0.045488  |    0.092159     |   2\n",
      "      36208 |   0.153683  |    0.039276     |   0\n",
      "      36209 |   0.133538  |    0.073193     |   0\n",
      "      36210 |   0.040843  |    0.044312     |   2\n",
      "      36211 |   0.170639  |    0.079843     |   0\n",
      "      36212 |   0.181209  |    0.029600     |   0\n",
      "      36213 |   0.037716  |    0.079518     |   2\n",
      "      36214 |   0.017181  |    0.048780     |   2\n",
      "      36215 |   0.000012  |    0.046151     |   2\n",
      "      36216 |   0.003652  |    0.073441     |   2\n",
      "      36217 |   0.050218  |    0.042423     |   2\n",
      "      36218 |   0.027486  |    0.053084     |   2\n",
      "      36219 |   0.052994  |    0.049615     |   2\n",
      "      36220 |   0.140413  |    0.207151     |   1\n",
      "      36221 |   0.035612  |    0.046528     |   2\n",
      "      36222 |   0.015421  |    0.049243     |   2\n",
      "      36223 |   0.026091  |    0.045646     |   2\n",
      "      36224 |   0.197225  |    0.046427     |   0\n",
      "      36225 |   0.022062  |    0.042467     |   2\n",
      "      36226 |   0.135900  |    0.079350     |   0\n",
      "      36227 |   0.189207  |    0.031179     |   0\n",
      "      36228 |   0.151857  |    0.211875     |   1\n",
      "      36229 |   0.124007  |    0.164315     |   1\n",
      "      36230 |   0.148785  |    0.194711     |   1\n",
      "      36231 |   0.000012  |    0.052174     |   2\n",
      "      36232 |   0.214549  |    0.191939     |   1\n",
      "      36233 |   0.000012  |    0.015914     |   2\n",
      "      36234 |   0.000012  |    0.075543     |   2\n",
      "      36235 |   0.132384  |    0.043151     |   0\n",
      "      36236 |   0.131348  |    0.210748     |   1\n",
      "      36237 |   0.193711  |    0.026899     |   0\n",
      "      36238 |   0.000012  |    0.045751     |   2\n",
      "      36239 |   0.000012  |    0.079475     |   2\n",
      "      36240 |   0.145673  |    0.026857     |   0\n",
      "      36241 |   0.000012  |    0.086864     |   2\n",
      "      36242 |   0.036876  |    0.037517     |   2\n",
      "      36243 |   0.125682  |    0.237199     |   1\n",
      "      36244 |   0.040837  |    0.020345     |   2\n",
      "      36245 |   0.218486  |    0.075560     |   0\n",
      "      36246 |   0.150936  |    0.044152     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 36247: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      36247 |   0.038619  |    0.060895     |   2\n",
      "      36248 |   0.151588  |    0.185871     |   1\n",
      "      36249 |   0.025037  |    0.008654     |   2\n",
      "      36250 |   0.197123  |    0.198565     |   1\n",
      "      36251 |   0.033436  |    0.042716     |   2\n",
      "      36252 |   0.030572  |    0.041745     |   2\n",
      "      36253 |   0.188951  |    0.046843     |   0\n",
      "      36254 |   0.135054  |    0.189645     |   1\n",
      "      36255 |   0.219183  |    0.040481     |   0\n",
      "      36256 |   0.116893  |    0.029625     |   0\n",
      "      36257 |   0.023078  |    0.085344     |   2\n",
      "      36258 |   0.165470  |    0.005020     |   0\n",
      "      36259 |   0.128926  |    0.079751     |   0\n",
      "      36260 |   0.153649  |    0.032551     |   0\n",
      "      36261 |   0.181752  |    0.080466     |   0\n",
      "      36262 |   0.144824  |    0.034053     |   0\n",
      "      36263 |   0.176138  |    0.204206     |   1\n",
      "      36264 |   0.028511  |    0.008894     |   2\n",
      "      36265 |   0.131184  |    0.205352     |   1\n",
      "      36266 |   0.047548  |    0.079821     |   2\n",
      "      36267 |   0.218616  |    0.139137     |   1\n",
      "      36268 |   0.043550  |    0.040749     |   2\n",
      "      36269 |   0.166719  |    0.136906     |   1\n",
      "      36270 |   0.219903  |    0.092519     |   0\n",
      "      36271 |   0.035679  |    0.014720     |   2\n",
      "      36272 |   0.140784  |    0.074096     |   0\n",
      "      36273 |   0.159894  |    0.195193     |   1\n",
      "      36274 |   0.147728  |    0.161360     |   1\n",
      "      36275 |   0.017106  |    0.049185     |   2\n",
      "      36276 |   0.142146  |    0.190699     |   1\n",
      "      36277 |   0.141726  |    0.047019     |   0\n",
      "      36278 |   0.000012  |    0.058586     |   2\n",
      "      36279 |   0.163404  |    0.219672     |   1\n",
      "      36280 |   0.186714  |    0.205211     |   1\n",
      "      36281 |   0.127291  |    0.004825     |   0\n",
      "      36282 |   0.003718  |    0.043127     |   2\n",
      "      36283 |   0.193344  |    0.149918     |   1\n",
      "      36284 |   0.205199  |    0.188584     |   1\n",
      "      36285 |   0.170402  |    0.049447     |   0\n",
      "      36286 |   0.048137  |    0.041501     |   2\n",
      "      36287 |   0.213234  |    0.219003     |   1\n",
      "      36288 |   0.232526  |    0.214949     |   1\n",
      "      36289 |   0.183969  |    0.031308     |   0\n",
      "      36290 |   0.026257  |    0.075454     |   2\n",
      "      36291 |   0.049966  |    0.072419     |   2\n",
      "      36292 |   0.032664  |    0.041812     |   2\n",
      "      36293 |   0.144498  |    0.077418     |   0\n",
      "      36294 |   0.176095  |    0.204370     |   1\n",
      "      36295 |   0.013891  |    0.046318     |   2\n",
      "      36296 |   0.165998  |    0.192377     |   1\n",
      "      36297 |   0.197216  |    0.044011     |   0\n",
      "      36298 |   0.025827  |    0.044341     |   2\n",
      "      36299 |   0.187057  |    0.074690     |   0\n",
      "      36300 |   0.022118  |    0.045349     |   2\n",
      "      36301 |   0.000012  |    0.046832     |   2\n",
      "      36302 |   0.207336  |    0.132346     |   1\n",
      "      36303 |   0.000012  |    0.039450     |   2\n",
      "      36304 |   0.161313  |    0.079091     |   0\n",
      "      36305 |   0.000012  |    0.030633     |   2\n",
      "      36306 |   0.143146  |    0.208323     |   1\n",
      "      36307 |   0.172066  |    0.157381     |   1\n",
      "      36308 |   0.000012  |    0.051124     |   2\n",
      "      36309 |   0.118593  |    0.043757     |   0\n",
      "      36310 |   0.000012  |    0.055408     |   2\n",
      "      36311 |   0.153042  |    0.186496     |   1\n",
      "      36312 |   0.000012  |    0.021768     |   2\n",
      "      36313 |   0.136565  |    0.199180     |   1\n",
      "      36314 |   0.035480  |    0.082416     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 36316: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      36315 |   0.040116  |    0.019763     |   2\n",
      "      36316 |   0.197484  |    0.090585     |   0\n",
      "      36317 |   0.173620  |    0.154866     |   1\n",
      "      36318 |   0.143275  |    0.160014     |   1\n",
      "      36319 |   0.132804  |    0.168420     |   1\n",
      "      36320 |   0.034553  |    0.005457     |   2\n",
      "      36321 |   0.215886  |    0.074214     |   0\n",
      "      36322 |   0.157461  |    0.026837     |   0\n",
      "      36323 |   0.197494  |    0.211850     |   1\n",
      "      36324 |   0.135701  |    0.003451     |   0\n",
      "      36325 |   0.166957  |    0.082665     |   0\n",
      "      36326 |   0.178718  |    0.134135     |   1\n",
      "      36327 |   0.172862  |    0.079923     |   0\n",
      "      36328 |   0.161630  |    0.202649     |   1\n",
      "      36329 |   0.182600  |    0.131188     |   1\n",
      "      36330 |   0.024585  |    0.076839     |   2\n",
      "      36331 |   0.125669  |    0.041432     |   0\n",
      "      36332 |   0.132646  |    0.049510     |   0\n",
      "      36333 |   0.215667  |    0.074287     |   0\n",
      "      36334 |   0.161178  |    0.192066     |   1\n",
      "      36335 |   0.031022  |    0.004031     |   2\n",
      "      36336 |   0.030619  |    0.046457     |   2\n",
      "      36337 |   0.175365  |    0.211129     |   1\n",
      "      36338 |   0.209796  |    0.192879     |   1\n",
      "      36339 |   0.173270  |    0.138202     |   1\n",
      "      36340 |   0.147657  |    0.038902     |   0\n",
      "      36341 |   0.181221  |    0.205888     |   1\n",
      "      36342 |   0.022774  |    0.024597     |   2\n",
      "      36343 |   0.028296  |    0.076179     |   2\n",
      "      36344 |   0.043864  |    0.080230     |   2\n",
      "      36345 |   0.040551  |    0.025350     |   2\n",
      "      36346 |   0.190483  |    0.201027     |   1\n",
      "      36347 |   0.033765  |    0.044159     |   2\n",
      "      36348 |   0.016881  |    0.080016     |   2\n",
      "      36349 |   0.208287  |    0.151493     |   1\n",
      "      36350 |   0.149763  |    0.044728     |   0\n",
      "      36351 |   0.000012  |    0.082141     |   2\n",
      "      36352 |   0.112703  |    0.209725     |   1\n",
      "      36353 |   0.003655  |    0.005969     |   2\n",
      "      36354 |   0.050796  |    0.102276     |   2\n",
      "      36355 |   0.181076  |    0.169326     |   1\n",
      "      36356 |   0.127520  |    0.243674     |   1\n",
      "      36357 |   0.177722  |    0.010328     |   0\n",
      "      36358 |   0.027715  |    0.073086     |   2\n",
      "      36359 |   0.045475  |    0.045140     |   2\n",
      "      36360 |   0.154231  |    0.196836     |   1\n",
      "      36361 |   0.204881  |    0.138316     |   1\n",
      "      36362 |   0.137106  |    0.200006     |   1\n",
      "      36363 |   0.033991  |    0.022310     |   2\n",
      "      36364 |   0.146401  |    0.241754     |   1\n",
      "      36365 |   0.011907  |    0.052192     |   2\n",
      "      36366 |   0.025341  |    0.048799     |   2\n",
      "      36367 |   0.193780  |    0.206229     |   1\n",
      "      36368 |   0.139674  |    0.142081     |   1\n",
      "      36369 |   0.021832  |    0.052999     |   2\n",
      "      36370 |   0.131929  |    0.046364     |   0\n",
      "      36371 |   0.125290  |    0.206190     |   1\n",
      "      36372 |   0.140218  |    0.022694     |   0\n",
      "      36373 |   0.000011  |    0.077991     |   2\n",
      "      36374 |   0.132116  |    0.041284     |   0\n",
      "      36375 |   0.000011  |    0.075727     |   2\n",
      "      36376 |   0.147781  |    0.056427     |   0\n",
      "      36377 |   0.187807  |    0.197124     |   1\n",
      "      36378 |   0.148344  |    0.164465     |   1\n",
      "      36379 |   0.189979  |    0.156737     |   1\n",
      "      36380 |   0.000011  |    0.040539     |   2\n",
      "      36381 |   0.143270  |    0.082136     |   0\n",
      "      36382 |   0.146466  |    0.017825     |   0\n",
      "      36383 |   0.173863  |    0.079185     |   0\n",
      "      36384 |   0.000011  |    0.029486     |   2\n",
      "      36385 |   0.139685  |    0.078770     |   0\n",
      "      36386 |   0.000011  |    0.043102     |   2\n",
      "      36387 |   0.000011  |    0.018311     |   2\n",
      "      36388 |   0.036069  |    0.080535     |   2\n",
      "      36389 |   0.148854  |    0.024712     |   0\n",
      "      36390 |   0.039361  |    0.083667     |   2\n",
      "      36391 |   0.134244  |    0.022654     |   0\n",
      "      36392 |   0.165122  |    0.077846     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 36393: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      36393 |   0.038510  |    0.032358     |   2\n",
      "      36394 |   0.216365  |    0.201878     |   1\n",
      "      36395 |   0.149075  |    0.025493     |   0\n",
      "      36396 |   0.139409  |    0.078000     |   0\n",
      "      36397 |   0.025408  |    0.017545     |   2\n",
      "      36398 |   0.160186  |    0.080680     |   0\n",
      "      36399 |   0.184274  |    0.203808     |   1\n",
      "      36400 |   0.173802  |    0.023809     |   0\n",
      "      36401 |   0.124710  |    0.076339     |   0\n",
      "      36402 |   0.158959  |    0.048499     |   0\n",
      "      36403 |   0.033239  |    0.042183     |   2\n",
      "      36404 |   0.031111  |    0.074501     |   2\n",
      "      36405 |   0.022298  |    0.031079     |   2\n",
      "      36406 |   0.111606  |    0.206969     |   1\n",
      "      36407 |   0.196434  |    0.008268     |   0\n",
      "      36408 |   0.153255  |    0.075894     |   0\n",
      "      36409 |   0.028445  |    0.042559     |   2\n",
      "      36410 |   0.042375  |    0.046234     |   2\n",
      "      36411 |   0.145356  |    0.082289     |   0\n",
      "      36412 |   0.216834  |    0.132518     |   1\n",
      "      36413 |   0.179846  |    0.191395     |   1\n",
      "      36414 |   0.145213  |    0.073487     |   0\n",
      "      36415 |   0.042388  |    0.005663     |   2\n",
      "      36416 |   0.035007  |    0.150110     |   2\n",
      "      36417 |   0.198923  |    0.153681     |   1\n",
      "      36418 |   0.165408  |    0.019287     |   0\n",
      "      36419 |   0.180165  |    0.131389     |   1\n",
      "      36420 |   0.166211  |    0.083341     |   0\n",
      "      36421 |   0.017246  |    0.009265     |   2\n",
      "      36422 |   0.221681  |    0.208526     |   1\n",
      "      36423 |   0.000012  |    0.029951     |   2\n",
      "      36424 |   0.155114  |    0.046895     |   0\n",
      "      36425 |   0.003447  |    0.083261     |   2\n",
      "      36426 |   0.047398  |    0.036631     |   2\n",
      "      36427 |   0.026730  |    0.047113     |   2\n",
      "      36428 |   0.050870  |    0.070804     |   2\n",
      "      36429 |   0.032594  |    0.019563     |   2\n",
      "      36430 |   0.190977  |    0.204434     |   1\n",
      "      36431 |   0.175452  |    0.033514     |   0\n",
      "      36432 |   0.149463  |    0.249210     |   1\n",
      "      36433 |   0.186685  |    0.086630     |   1\n",
      "      36434 |   0.187235  |    0.199478     |   1\n",
      "      36435 |   0.013255  |    0.017567     |   2\n",
      "      36436 |   0.161553  |    0.197377     |   1\n",
      "      36437 |   0.141068  |    0.044927     |   0\n",
      "      36438 |   0.203519  |    0.079706     |   0\n",
      "      36439 |   0.147442  |    0.030309     |   0\n",
      "      36440 |   0.203223  |    0.204938     |   1\n",
      "      36441 |   0.185314  |    0.208114     |   1\n",
      "      36442 |   0.143132  |    0.021047     |   0\n",
      "      36443 |   0.169258  |    0.147892     |   1\n",
      "      36444 |   0.027480  |    0.041131     |   2\n",
      "      36445 |   0.022846  |    0.079164     |   2\n",
      "      36446 |   0.248597  |    0.148997     |   1\n",
      "      36447 |   0.168987  |    0.023191     |   0\n",
      "      36448 |   0.162263  |    0.086578     |   0\n",
      "      36449 |   0.000012  |    0.042740     |   2\n",
      "      36450 |   0.154656  |    0.213783     |   1\n",
      "      36451 |   0.000012  |    0.026542     |   2\n",
      "      36452 |   0.000012  |    0.081660     |   2\n",
      "      36453 |   0.201553  |    0.046403     |   0\n",
      "      36454 |   0.000012  |    0.025755     |   2\n",
      "      36455 |   0.155274  |    0.196848     |   1\n",
      "      36456 |   0.121367  |    0.055753     |   0\n",
      "      36457 |   0.182597  |    0.046003     |   0\n",
      "      36458 |   0.161190  |    0.204688     |   1\n",
      "      36459 |   0.000012  |    0.013599     |   2\n",
      "      36460 |   0.149039  |    0.092470     |   0\n",
      "      36461 |   0.156197  |    0.116206     |   1\n",
      "      36462 |   0.000012  |    0.096971     |   2\n",
      "      36463 |   0.206405  |    0.152478     |   1\n",
      "      36464 |   0.035019  |    0.042997     |   2\n",
      "      36465 |   0.203785  |    0.198540     |   1\n",
      "      36466 |   0.240942  |    0.136054     |   1\n",
      "      36467 |   0.039997  |    0.006926     |   2\n",
      "      36468 |   0.180066  |    0.074332     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 36469: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      36469 |   0.178794  |    0.153370     |   1\n",
      "      36470 |   0.202623  |    0.140749     |   1\n",
      "      36471 |   0.174732  |    0.022808     |   0\n",
      "      36472 |   0.035215  |    0.081882     |   2\n",
      "      36473 |   0.148886  |    0.028094     |   0\n",
      "      36474 |   0.023654  |    0.079487     |   2\n",
      "      36475 |   0.167062  |    0.016904     |   0\n",
      "      36476 |   0.172503  |    0.077331     |   0\n",
      "      36477 |   0.032542  |    0.030072     |   2\n",
      "      36478 |   0.193158  |    0.076632     |   0\n",
      "      36479 |   0.160770  |    0.041082     |   0\n",
      "      36480 |   0.133288  |    0.042193     |   0\n",
      "      36481 |   0.187943  |    0.042935     |   0\n",
      "      36482 |   0.028960  |    0.055272     |   2\n",
      "      36483 |   0.180829  |    0.192769     |   1\n",
      "      36484 |   0.138341  |    0.004986     |   0\n",
      "      36485 |   0.022296  |    0.052303     |   2\n",
      "      36486 |   0.134430  |    0.050516     |   0\n",
      "      36487 |   0.027959  |    0.034872     |   2\n",
      "      36488 |   0.047002  |    0.038667     |   2\n",
      "      36489 |   0.162785  |    0.077375     |   0\n",
      "      36490 |   0.201460  |    0.164950     |   1\n",
      "      36491 |   0.171700  |    0.160801     |   1\n",
      "      36492 |   0.115942  |    0.025222     |   0\n",
      "      36493 |   0.172819  |    0.078017     |   0\n",
      "      36494 |   0.171825  |    0.013334     |   0\n",
      "      36495 |   0.044529  |    0.074031     |   2\n",
      "      36496 |   0.035403  |    0.047980     |   2\n",
      "      36497 |   0.200152  |    0.183554     |   1\n",
      "      36498 |   0.014426  |    0.041798     |   2\n",
      "      36499 |   0.159705  |    0.072040     |   0\n",
      "      36500 |   0.000012  |    0.033365     |   2\n",
      "      36501 |   0.146334  |    0.251689     |   1\n",
      "      36502 |   0.173529  |    0.006110     |   0\n",
      "      36503 |   0.157138  |    0.080629     |   0\n",
      "      36504 |   0.117706  |    0.015295     |   0\n",
      "      36505 |   0.129865  |    0.079496     |   0\n",
      "      36506 |   0.198480  |    0.022552     |   0\n",
      "      36507 |   0.179584  |    0.182842     |   1\n",
      "      36508 |   0.112093  |    0.015436     |   0\n",
      "      36509 |   0.187017  |    0.216933     |   1\n",
      "      36510 |   0.196049  |    0.194416     |   1\n",
      "      36511 |   0.152154  |    0.006889     |   0\n",
      "      36512 |   0.226463  |    0.198744     |   1\n",
      "      36513 |   0.183377  |    0.004062     |   0\n",
      "      36514 |   0.036272  |    0.076272     |   2\n",
      "      36515 |   0.193005  |    0.038545     |   0\n",
      "      36516 |   0.025138  |    0.055298     |   2\n",
      "      36517 |   0.157908  |    0.215724     |   1\n",
      "      36518 |   0.180045  |    0.013335     |   0\n",
      "      36519 |   0.031375  |    0.076680     |   2\n",
      "      36520 |   0.177014  |    0.018874     |   0\n",
      "      36521 |   0.031920  |    0.083388     |   2\n",
      "      36522 |   0.022178  |    0.024897     |   2\n",
      "      36523 |   0.173892  |    0.243145     |   1\n",
      "      36524 |   0.028130  |    0.014339     |   2\n",
      "      36525 |   0.196406  |    0.077477     |   0\n",
      "      36526 |   0.160062  |    0.020801     |   0\n",
      "      36527 |   0.210740  |    0.082147     |   0\n",
      "      36528 |   0.119887  |    0.189729     |   1\n",
      "      36529 |   0.203637  |    0.047598     |   0\n",
      "      36530 |   0.190833  |    0.189371     |   1\n",
      "      36531 |   0.037424  |    0.005113     |   2\n",
      "      36532 |   0.186918  |    0.073641     |   0\n",
      "      36533 |   0.040196  |    0.065865     |   2\n",
      "      36534 |   0.216485  |    0.140914     |   1\n",
      "      36535 |   0.104698  |    0.049089     |   0\n",
      "      36536 |   0.184513  |    0.039457     |   0\n",
      "      36537 |   0.033671  |    0.047052     |   2\n",
      "      36538 |   0.219468  |    0.050455     |   0\n",
      "      36539 |   0.013573  |    0.079459     |   2\n",
      "      36540 |   0.146598  |    0.016226     |   0\n",
      "      36541 |   0.199125  |    0.207519     |   1\n",
      "      36542 |   0.000012  |    0.015470     |   2\n",
      "      36543 |   0.203205  |    0.192993     |   1\n",
      "      36544 |   0.003784  |    0.046840     |   2\n",
      "      36545 |   0.159936  |    0.193169     |   1\n",
      "      36546 |   0.200058  |    0.049014     |   0\n",
      "      36547 |   0.193516  |    0.200164     |   1\n",
      "      36548 |   0.165074  |    0.041974     |   0\n",
      "      36549 |   0.050482  |    0.080718     |   2\n",
      "      36550 |   0.027900  |    0.031915     |   2\n",
      "      36551 |   0.049929  |    0.072400     |   2\n",
      "      36552 |   0.193752  |    0.031745     |   0\n",
      "      36553 |   0.135315  |    0.043873     |   0\n",
      "      36554 |   0.034478  |    0.036786     |   2\n",
      "      36555 |   0.013318  |    0.074691     |   2\n",
      "      36556 |   0.027462  |    0.015815     |   2\n",
      "      36557 |   0.133976  |    0.051077     |   0\n",
      "      36558 |   0.022535  |    0.053078     |   2\n",
      "      36559 |   0.147887  |    0.088342     |   0\n",
      "      36560 |   0.152843  |    0.140789     |   1\n",
      "      36561 |   0.176389  |    0.156631     |   1\n",
      "      36562 |   0.112764  |    0.189303     |   1\n",
      "      36563 |   0.000012  |    0.036933     |   2\n",
      "      36564 |   0.156814  |    0.194567     |   1\n",
      "      36565 |   0.147136  |    0.004833     |   0\n",
      "      36566 |   0.111639  |    0.082033     |   0\n",
      "      36567 |   0.147496  |    0.039873     |   0\n",
      "      36568 |   0.179345  |    0.047056     |   0\n",
      "      36569 |   0.172846  |    0.057371     |   0\n",
      "      36570 |   0.000012  |    0.040807     |   2\n",
      "      36571 |   0.191129  |    0.238926     |   1\n",
      "      36572 |   0.000012  |    0.013873     |   2\n",
      "      36573 |   0.128299  |    0.057274     |   0\n",
      "      36574 |   0.175861  |    0.039624     |   0\n",
      "      36575 |   0.000012  |    0.078055     |   2\n",
      "      36576 |   0.183066  |    0.157621     |   1\n",
      "      36577 |   0.197870  |    0.027195     |   0\n",
      "      36578 |   0.132547  |    0.194020     |   1\n",
      "      36579 |   0.157321  |    0.040766     |   0\n",
      "      36580 |   0.000012  |    0.077791     |   2\n",
      "      36581 |   0.000012  |    0.024482     |   2\n",
      "      36582 |   0.170642  |    0.043626     |   0\n",
      "      36583 |   0.181753  |    0.204771     |   1\n",
      "      36584 |   0.145238  |    0.155169     |   1\n",
      "      36585 |   0.162871  |    0.138754     |   1\n",
      "      36586 |   0.162579  |    0.046021     |   0\n",
      "      36587 |   0.211264  |    0.207845     |   1\n",
      "      36588 |   0.146960  |    0.144306     |   1\n",
      "      36589 |   0.038187  |    0.024956     |   2\n",
      "      36590 |   0.191994  |    0.075216     |   0\n",
      "      36591 |   0.125800  |    0.042606     |   0\n",
      "      36592 |   0.140942  |    0.211377     |   1\n",
      "      36593 |   0.164296  |    0.005202     |   0\n",
      "      36594 |   0.119453  |    0.073054     |   0\n",
      "      36595 |   0.041788  |    0.039927     |   2\n",
      "      36596 |   0.146272  |    0.076107     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 36597: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      36597 |   0.040741  |    0.013419     |   2\n",
      "      36598 |   0.125690  |    0.081839     |   0\n",
      "      36599 |   0.255242  |    0.155832     |   1\n",
      "      36600 |   0.236844  |    0.178900     |   1\n",
      "      36601 |   0.246804  |    0.075656     |   0\n",
      "      36602 |   0.128113  |    0.042110     |   0\n",
      "      36603 |   0.158765  |    0.040206     |   0\n",
      "      36604 |   0.143281  |    0.076641     |   0\n",
      "      36605 |   0.026302  |    0.016556     |   2\n",
      "      36606 |   0.032035  |    0.090685     |   2\n",
      "      36607 |   0.227122  |    0.043046     |   0\n",
      "      36608 |   0.166309  |    0.226869     |   1\n",
      "      36609 |   0.169659  |    0.020465     |   0\n",
      "      36610 |   0.180829  |    0.264857     |   1\n",
      "      36611 |   0.196298  |    0.147566     |   1\n",
      "      36612 |   0.143491  |    0.196777     |   1\n",
      "      36613 |   0.029557  |    0.006059     |   2\n",
      "      36614 |   0.179786  |    0.197073     |   1\n",
      "      36615 |   0.212773  |    0.148283     |   1\n",
      "      36616 |   0.160094  |    0.185122     |   1\n",
      "      36617 |   0.171413  |    0.050284     |   0\n",
      "      36618 |   0.178433  |    0.187966     |   1\n",
      "      36619 |   0.021803  |    0.009216     |   2\n",
      "      36620 |   0.166436  |    0.199221     |   1\n",
      "      36621 |   0.175990  |    0.187982     |   1\n",
      "      36622 |   0.194548  |    0.043295     |   0\n",
      "      36623 |   0.027471  |    0.045589     |   2\n",
      "      36624 |   0.042829  |    0.060244     |   2\n",
      "      36625 |   0.266767  |    0.215953     |   1\n",
      "      36626 |   0.145238  |    0.138818     |   1\n",
      "      36627 |   0.213548  |    0.158835     |   1\n",
      "      36628 |   0.038390  |    0.046659     |   2\n",
      "      36629 |   0.160469  |    0.186225     |   1\n",
      "      36630 |   0.140955  |    0.023172     |   0\n",
      "      36631 |   0.034033  |    0.048292     |   2\n",
      "      36632 |   0.017208  |    0.047563     |   2\n",
      "      36633 |   0.161985  |    0.095238     |   0\n",
      "      36634 |   0.209934  |    0.105765     |   1\n",
      "      36635 |   0.128686  |    0.044843     |   0\n",
      "      36636 |   0.114629  |    0.206483     |   1\n",
      "      36637 |   0.199261  |    0.139781     |   1\n",
      "      36638 |   0.167850  |    0.047029     |   0\n",
      "      36639 |   0.215883  |    0.075748     |   0\n",
      "      36640 |   0.182520  |    0.017393     |   0\n",
      "      36641 |   0.000012  |    0.046188     |   2\n",
      "      36642 |   0.129518  |    0.076551     |   0\n",
      "      36643 |   0.170685  |    0.044375     |   0\n",
      "      36644 |   0.136501  |    0.199706     |   1\n",
      "      36645 |   0.003464  |    0.016462     |   2\n",
      "      36646 |   0.263935  |    0.196580     |   1\n",
      "      36647 |   0.138790  |    0.020944     |   0\n",
      "      36648 |   0.187543  |    0.162915     |   1\n",
      "      36649 |   0.186722  |    0.201260     |   1\n",
      "      36650 |   0.142269  |    0.010530     |   0\n",
      "      36651 |   0.050180  |    0.099316     |   2\n",
      "      36652 |   0.192126  |    0.170536     |   1\n",
      "      36653 |   0.226785  |    0.197165     |   1\n",
      "      36654 |   0.026507  |    0.025609     |   2\n",
      "      36655 |   0.051791  |    0.086463     |   2\n",
      "      36656 |   0.094375  |    0.151875     |   1\n",
      "      36657 |   0.034898  |    0.024781     |   2\n",
      "      36658 |   0.013656  |    0.074408     |   2\n",
      "      36659 |   0.156086  |    0.032852     |   0\n",
      "      36660 |   0.138599  |    0.144729     |   1\n",
      "      36661 |   0.179655  |    0.221674     |   1\n",
      "      36662 |   0.138955  |    0.153300     |   1\n",
      "      36663 |   0.025192  |    0.006710     |   2\n",
      "      36664 |   0.023691  |    0.072352     |   2\n",
      "      36665 |   0.000012  |    0.040773     |   2\n",
      "      36666 |   0.174274  |    0.089519     |   0\n",
      "      36667 |   0.166626  |    0.183529     |   1\n",
      "      36668 |   0.183661  |    0.006947     |   0\n",
      "      36669 |   0.000012  |    0.081512     |   2\n",
      "      36670 |   0.000012  |    0.044131     |   2\n",
      "      36671 |   0.000012  |    0.042652     |   2\n",
      "      36672 |   0.150946  |    0.216319     |   1\n",
      "      36673 |   0.165270  |    0.149592     |   1\n",
      "      36674 |   0.171216  |    0.172183     |   1\n",
      "      36675 |   0.171231  |    0.023644     |   0\n",
      "      36676 |   0.185325  |    0.088339     |   0\n",
      "      36677 |   0.143014  |    0.194362     |   1\n",
      "      36678 |   0.000012  |    0.007610     |   2\n",
      "      36679 |   0.167202  |    0.083503     |   0\n",
      "      36680 |   0.000012  |    0.093704     |   2\n",
      "      36681 |   0.189543  |    0.168806     |   1\n",
      "      36682 |   0.148796  |    0.038696     |   0\n",
      "      36683 |   0.180155  |    0.074719     |   0\n",
      "      36684 |   0.210307  |    0.044698     |   0\n",
      "      36685 |   0.154010  |    0.208110     |   1\n",
      "      36686 |   0.038424  |    0.013733     |   2\n",
      "      36687 |   0.186926  |    0.215043     |   1\n",
      "      36688 |   0.040953  |    0.016172     |   2\n",
      "      36689 |   0.177320  |    0.075847     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 36690: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      36690 |   0.112094  |    0.042119     |   0\n",
      "      36691 |   0.037541  |    0.029629     |   2\n",
      "      36692 |   0.148814  |    0.076776     |   0\n",
      "      36693 |   0.171457  |    0.146761     |   1\n",
      "      36694 |   0.025243  |    0.044816     |   2\n",
      "      36695 |   0.184420  |    0.044571     |   0\n",
      "      36696 |   0.135718  |    0.086073     |   0\n",
      "      36697 |   0.153466  |    0.215738     |   1\n",
      "      36698 |   0.152214  |    0.006889     |   0\n",
      "      36699 |   0.161310  |    0.046239     |   0\n",
      "      36700 |   0.161081  |    0.216065     |   1\n",
      "      36701 |   0.200906  |    0.142376     |   1\n",
      "      36702 |   0.196533  |    0.138707     |   1\n",
      "      36703 |   0.031155  |    0.043780     |   2\n",
      "      36704 |   0.030187  |    0.085664     |   2\n",
      "      36705 |   0.022168  |    0.021969     |   2\n",
      "      36706 |   0.178543  |    0.082051     |   0\n",
      "      36707 |   0.028809  |    0.042125     |   2\n",
      "      36708 |   0.164151  |    0.066696     |   0\n",
      "      36709 |   0.177006  |    0.192512     |   1\n",
      "      36710 |   0.171112  |    0.028949     |   0\n",
      "      36711 |   0.190765  |    0.082497     |   0\n",
      "      36712 |   0.147021  |    0.024931     |   0\n",
      "      36713 |   0.166677  |    0.075004     |   0\n",
      "      36714 |   0.223595  |    0.040817     |   0\n",
      "      36715 |   0.225763  |    0.055907     |   0\n",
      "      36716 |   0.170130  |    0.213229     |   1\n",
      "      36717 |   0.160930  |    0.141671     |   1\n",
      "      36718 |   0.044005  |    0.028204     |   2\n",
      "      36719 |   0.043361  |    0.073971     |   2\n",
      "      36720 |   0.036661  |    0.003607     |   2\n",
      "      36721 |   0.232984  |    0.195637     |   1\n",
      "      36722 |   0.226888  |    0.220412     |   1\n",
      "      36723 |   0.016722  |    0.009423     |   2\n",
      "      36724 |   0.160995  |    0.075524     |   0\n",
      "      36725 |   0.210141  |    0.041033     |   0\n",
      "      36726 |   0.168746  |    0.134923     |   1\n",
      "      36727 |   0.149055  |    0.028078     |   0\n",
      "      36728 |   0.130054  |    0.072374     |   0\n",
      "      36729 | \u001b[94m  0.000011\u001b[0m  |    0.043362     |   2\n",
      "      36730 |   0.003812  |    0.027809     |   2\n",
      "      36731 |   0.047776  |    0.087200     |   2\n",
      "      36732 |   0.159187  |    0.144195     |   1\n",
      "      36733 |   0.119257  |    0.039686     |   0\n",
      "      36734 |   0.156312  |    0.047787     |   0\n",
      "      36735 |   0.028218  |    0.037416     |   2\n",
      "      36736 |   0.114485  |    0.049886     |   0\n",
      "      36737 |   0.052043  |    0.048213     |   2\n",
      "      36738 |   0.129200  |    0.049082     |   0\n",
      "      36739 |   0.156071  |    0.159053     |   1\n",
      "      36740 |   0.036825  |    0.042944     |   2\n",
      "      36741 |   0.013489  |    0.047105     |   2\n",
      "      36742 |   0.215538  |    0.199498     |   1\n",
      "      36743 |   0.239678  |    0.130860     |   1\n",
      "      36744 |   0.026911  |    0.041616     |   2\n",
      "      36745 |   0.152863  |    0.041523     |   0\n",
      "      36746 |   0.142478  |    0.075872     |   0\n",
      "      36747 |   0.021129  |    0.041657     |   2\n",
      "      36748 |   0.000012  |    0.072148     |   2\n",
      "      36749 |   0.181843  |    0.024499     |   0\n",
      "      36750 |   0.174518  |    0.250770     |   1\n",
      "      36751 |   0.000012  |    0.010253     |   2\n",
      "      36752 |   0.128251  |    0.081864     |   0\n",
      "      36753 |   0.177625  |    0.009239     |   0\n",
      "      36754 |   0.000012  |    0.081382     |   2\n",
      "      36755 |   0.000011  |    0.052736     |   2\n",
      "      36756 |   0.000011  |    0.044530     |   2\n",
      "      36757 |   0.000011  |    0.044627     |   2\n",
      "      36758 |   0.184451  |    0.199138     |   1\n",
      "      36759 |   0.187035  |    0.040736     |   0\n",
      "      36760 |   0.157331  |    0.046982     |   0\n",
      "      36761 |   0.191916  |    0.053237     |   0\n",
      "      36762 |   0.157664  |    0.042902     |   0\n",
      "      36763 |   0.145932  |    0.076902     |   0\n",
      "      36764 |   0.162447  |    0.026347     |   0\n",
      "      36765 |   0.164281  |    0.061729     |   0\n",
      "      36766 |   0.130048  |    0.182083     |   1\n",
      "      36767 |   0.039903  |    0.033625     |   2\n",
      "      36768 |   0.156408  |    0.077688     |   0\n",
      "      36769 |   0.153752  |    0.030804     |   0\n",
      "      36770 |   0.159524  |    0.079646     |   0\n",
      "      36771 |   0.040812  |    0.085187     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 36772: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      36772 |   0.155576  |    0.141729     |   1\n",
      "      36773 |   0.217189  |    0.184962     |   1\n",
      "      36774 |   0.117224  |    0.016267     |   0\n",
      "      36775 |   0.196675  |    0.079659     |   0\n",
      "      36776 |   0.040032  |    0.019336     |   2\n",
      "      36777 |   0.134785  |    0.086569     |   0\n",
      "      36778 |   0.027691  |    0.048383     |   2\n",
      "      36779 |   0.196420  |    0.188480     |   1\n",
      "      36780 |   0.139498  |    0.006205     |   0\n",
      "      36781 |   0.173415  |    0.156108     |   1\n",
      "      36782 |   0.122310  |    0.199322     |   1\n",
      "      36783 |   0.107358  |    0.159174     |   1\n",
      "      36784 |   0.032679  |    0.013993     |   2\n",
      "      36785 |   0.158701  |    0.203663     |   1\n",
      "      36786 |   0.225489  |    0.193546     |   1\n",
      "      36787 |   0.229089  |    0.085666     |   1\n",
      "      36788 |   0.151785  |    0.076820     |   0\n",
      "      36789 |   0.181386  |    0.022722     |   0\n",
      "      36790 |   0.170119  |    0.072756     |   0\n",
      "      36791 |   0.262879  |    0.152295     |   1\n",
      "      36792 |   0.174723  |    0.025041     |   0\n",
      "      36793 |   0.202937  |    0.205006     |   1\n",
      "      36794 |   0.030006  |    0.025151     |   2\n",
      "      36795 |   0.021834  |    0.083999     |   2\n",
      "      36796 |   0.195380  |    0.165572     |   1\n",
      "      36797 |   0.174990  |    0.013257     |   0\n",
      "      36798 |   0.028386  |    0.075257     |   2\n",
      "      36799 |   0.159241  |    0.081312     |   0\n",
      "      36800 |   0.168403  |    0.043575     |   0\n",
      "      36801 |   0.041828  |    0.076484     |   2\n",
      "      36802 |   0.206618  |    0.213370     |   1\n",
      "      36803 |   0.174705  |    0.127016     |   1\n",
      "      36804 |   0.038952  |    0.088972     |   2\n",
      "      36805 |   0.258104  |    0.174997     |   1\n",
      "      36806 |   0.164761  |    0.022446     |   0\n",
      "      36807 |   0.150610  |    0.078224     |   0\n",
      "      36808 |   0.132323  |    0.046490     |   0\n",
      "      36809 |   0.148875  |    0.209590     |   1\n",
      "      36810 |   0.150714  |    0.209239     |   1\n",
      "      36811 |   0.118817  |    0.162784     |   1\n",
      "      36812 |   0.201079  |    0.149001     |   1\n",
      "      36813 |   0.158109  |    0.006036     |   0\n",
      "      36814 |   0.035763  |    0.089480     |   2\n",
      "      36815 |   0.223366  |    0.149882     |   1\n",
      "      36816 |   0.147008  |    0.224981     |   1\n",
      "      36817 |   0.017026  |    0.004240     |   2\n",
      "      36818 |   0.000011  |    0.080110     |   2\n",
      "      36819 |   0.129511  |    0.188814     |   1\n",
      "      36820 |   0.004247  |    0.006398     |   2\n",
      "      36821 |   0.190250  |    0.212995     |   1\n",
      "      36822 |   0.049119  |    0.008158     |   2\n",
      "      36823 |   0.163196  |    0.087418     |   0\n",
      "      36824 |   0.026349  |    0.006370     |   2\n",
      "      36825 |   0.149783  |    0.053128     |   0\n",
      "      36826 |   0.156136  |    0.194264     |   1\n",
      "      36827 |   0.195232  |    0.005163     |   0\n",
      "      36828 |   0.160837  |    0.077939     |   0\n",
      "      36829 |   0.158197  |    0.140375     |   1\n",
      "      36830 |   0.142321  |    0.079239     |   0\n",
      "      36831 |   0.216007  |    0.154570     |   1\n",
      "      36832 |   0.151701  |    0.181519     |   1\n",
      "      36833 |   0.198738  |    0.076549     |   0\n",
      "      36834 |   0.137508  |    0.025055     |   0\n",
      "      36835 |   0.144777  |    0.089384     |   0\n",
      "      36836 |   0.153423  |    0.188964     |   1\n",
      "      36837 |   0.051177  |    0.016175     |   2\n",
      "      36838 |   0.036439  |    0.078065     |   2\n",
      "      36839 |   0.011471  |    0.054326     |   2\n",
      "      36840 |   0.211167  |    0.043498     |   0\n",
      "      36841 |   0.166770  |    0.075885     |   0\n",
      "      36842 |   0.144896  |    0.015138     |   0\n",
      "      36843 |   0.027721  |    0.080542     |   2\n",
      "      36844 |   0.022195  |    0.047508     |   2\n",
      "      36845 |   0.000011  |    0.050313     |   2\n",
      "      36846 |   0.154682  |    0.053458     |   0\n",
      "      36847 |   0.172152  |    0.193641     |   1\n",
      "      36848 |   0.187156  |    0.167464     |   1\n",
      "      36849 |   0.169851  |    0.194343     |   1\n",
      "      36850 |   0.221619  |    0.011271     |   0\n",
      "      36851 |   0.234388  |    0.204611     |   1\n",
      "      36852 |   0.000011  |    0.018739     |   2\n",
      "      36853 |   0.141748  |    0.204144     |   1\n",
      "      36854 |   0.122032  |    0.047005     |   0\n",
      "      36855 |   0.000011  |    0.045214     |   2\n",
      "      36856 |   0.162100  |    0.046272     |   0\n",
      "      36857 |   0.000011  |    0.083440     |   2\n",
      "      36858 |   0.159876  |    0.172376     |   1\n",
      "      36859 |   0.175740  |    0.156640     |   1\n",
      "      36860 |   0.256640  |    0.097783     |   1\n",
      "      36861 |   0.000011  |    0.071605     |   2\n",
      "      36862 |   0.176420  |    0.202574     |   1\n",
      "      36863 |   0.000011  |    0.009516     |   2\n",
      "      36864 |   0.037950  |    0.031842     |   2\n",
      "      36865 |   0.039416  |    0.052077     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 36866: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      36866 |   0.193294  |    0.083588     |   0\n",
      "      36867 |   0.135762  |    0.008740     |   0\n",
      "      36868 |   0.034457  |    0.074516     |   2\n",
      "      36869 |   0.025831  |    0.051239     |   2\n",
      "      36870 |   0.031108  |    0.054979     |   2\n",
      "      36871 |   0.215136  |    0.150713     |   1\n",
      "      36872 |   0.030021  |    0.040615     |   2\n",
      "      36873 |   0.021715  |    0.082581     |   2\n",
      "      36874 |   0.147306  |    0.019093     |   0\n",
      "      36875 |   0.029065  |    0.077137     |   2\n",
      "      36876 |   0.045629  |    0.051572     |   2\n",
      "      36877 |   0.191325  |    0.198644     |   1\n",
      "      36878 |   0.041715  |    0.009356     |   2\n",
      "      36879 |   0.036401  |    0.091128     |   2\n",
      "      36880 |   0.170658  |    0.023549     |   0\n",
      "      36881 |   0.148090  |    0.051934     |   0\n",
      "      36882 |   0.167046  |    0.074999     |   0\n",
      "      36883 |   0.157318  |    0.039408     |   0\n",
      "      36884 |   0.205666  |    0.195250     |   1\n",
      "      36885 |   0.016847  |    0.075789     |   2\n",
      "      36886 | \u001b[94m  0.000011\u001b[0m  |    0.059900     |   2\n",
      "      36887 |   0.252506  |    0.145408     |   1\n",
      "      36888 |   0.003200  |    0.045580     |   2\n",
      "      36889 |   0.164529  |    0.045964     |   0\n",
      "      36890 |   0.114900  |    0.022978     |   0\n",
      "      36891 |   0.217493  |    0.077062     |   0\n",
      "      36892 |   0.118040  |    0.041334     |   0\n",
      "      36893 |   0.162236  |    0.163567     |   1\n",
      "      36894 |   0.046131  |    0.045469     |   2\n",
      "      36895 |   0.026561  |    0.048284     |   2\n",
      "      36896 |   0.049391  |    0.041450     |   2\n",
      "      36897 |   0.172590  |    0.049761     |   0\n",
      "      36898 |   0.205260  |    0.144224     |   1\n",
      "      36899 |   0.036242  |    0.045281     |   2\n",
      "      36900 |   0.012915  |    0.051612     |   2\n",
      "      36901 |   0.189576  |    0.243479     |   1\n",
      "      36902 |   0.207034  |    0.016999     |   0\n",
      "      36903 |   0.156445  |    0.060224     |   0\n",
      "      36904 |   0.150772  |    0.043365     |   0\n",
      "      36905 |   0.157113  |    0.077612     |   0\n",
      "      36906 |   0.160429  |    0.032235     |   0\n",
      "      36907 |   0.231219  |    0.226849     |   1\n",
      "      36908 |   0.028261  |    0.010399     |   2\n",
      "      36909 |   0.020658  |    0.083932     |   2\n",
      "      36910 |   0.249835  |    0.189513     |   1\n",
      "      36911 |   0.166830  |    0.012339     |   0\n",
      "      36912 |   0.168831  |    0.153902     |   1\n",
      "      36913 | \u001b[94m  0.000011\u001b[0m  |    0.015377     |   2\n",
      "      36914 |   0.151252  |    0.193955     |   1\n",
      "      36915 |   0.180353  |    0.145595     |   1\n",
      "      36916 |   0.157871  |    0.075250     |   0\n",
      "      36917 |   0.000011  |    0.022114     |   2\n",
      "      36918 |   0.189593  |    0.059619     |   0\n",
      "      36919 |   0.174744  |    0.190889     |   1\n",
      "      36920 |   0.000011  |    0.031800     |   2\n",
      "      36921 |   0.146094  |    0.063795     |   0\n",
      "      36922 |   0.000011  |    0.043730     |   2\n",
      "      36923 |   0.182836  |    0.194906     |   1\n",
      "      36924 |   0.114186  |    0.042393     |   0\n",
      "      36925 |   0.176223  |    0.156668     |   1\n",
      "      36926 |   0.140223  |    0.146256     |   1\n",
      "      36927 |   0.156268  |    0.043572     |   0\n",
      "      36928 |   0.171512  |    0.081913     |   0\n",
      "      36929 |   0.147812  |    0.007013     |   0\n",
      "      36930 |   0.000011  |    0.080777     |   2\n",
      "      36931 |   0.159276  |    0.189965     |   1\n",
      "      36932 |   0.000011  |    0.055884     |   2\n",
      "      36933 |   0.161957  |    0.042693     |   0\n",
      "      36934 |   0.037638  |    0.072518     |   2\n",
      "      36935 |   0.039322  |    0.073321     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 36937: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      36936 |   0.158456  |    0.032924     |   0\n",
      "      36937 |   0.150591  |    0.173543     |   1\n",
      "      36938 |   0.137568  |    0.029944     |   0\n",
      "      36939 |   0.191617  |    0.196435     |   1\n",
      "      36940 |   0.190572  |    0.204076     |   1\n",
      "      36941 |   0.165700  |    0.013738     |   0\n",
      "      36942 |   0.165639  |    0.079582     |   0\n",
      "      36943 |   0.038021  |    0.023935     |   2\n",
      "      36944 |   0.027138  |    0.076182     |   2\n",
      "      36945 |   0.109253  |    0.014898     |   0\n",
      "      36946 |   0.162503  |    0.076370     |   0\n",
      "      36947 |   0.032208  |    0.047737     |   2\n",
      "      36948 |   0.133185  |    0.058353     |   0\n",
      "      36949 |   0.124982  |    0.203895     |   1\n",
      "      36950 |   0.129177  |    0.007765     |   0\n",
      "      36951 |   0.139756  |    0.083149     |   0\n",
      "      36952 |   0.030478  |    0.009727     |   2\n",
      "      36953 |   0.190944  |    0.085651     |   0\n",
      "      36954 |   0.145988  |    0.022335     |   0\n",
      "      36955 |   0.022344  |    0.074898     |   2\n",
      "      36956 |   0.027761  |    0.030561     |   2\n",
      "      36957 |   0.210595  |    0.192861     |   1\n",
      "      36958 |   0.214114  |    0.147332     |   1\n",
      "      36959 |   0.041798  |    0.054544     |   2\n",
      "      36960 |   0.041603  |    0.080228     |   2\n",
      "      36961 |   0.141597  |    0.197465     |   1\n",
      "      36962 |   0.128977  |    0.047851     |   0\n",
      "      36963 |   0.175685  |    0.083803     |   0\n",
      "      36964 |   0.188651  |    0.009947     |   0\n",
      "      36965 |   0.032914  |    0.082680     |   2\n",
      "      36966 |   0.183618  |    0.209883     |   1\n",
      "      36967 |   0.182277  |    0.129161     |   1\n",
      "      36968 |   0.015519  |    0.044753     |   2\n",
      "      36969 |   0.124073  |    0.235969     |   1\n",
      "      36970 |   0.146984  |    0.006727     |   0\n",
      "      36971 |   0.120382  |    0.075535     |   0\n",
      "      36972 |   0.176398  |    0.007116     |   0\n",
      "      36973 |   0.160184  |    0.075053     |   0\n",
      "      36974 |   0.000011  |    0.027616     |   2\n",
      "      36975 |   0.115157  |    0.082382     |   0\n",
      "      36976 |   0.158988  |    0.138845     |   1\n",
      "      36977 |   0.003543  |    0.041160     |   2\n",
      "      36978 |   0.195872  |    0.152397     |   1\n",
      "      36979 |   0.104880  |    0.204324     |   1\n",
      "      36980 |   0.164630  |    0.042257     |   0\n",
      "      36981 |   0.153444  |    0.201657     |   1\n",
      "      36982 |   0.145460  |    0.039300     |   0\n",
      "      36983 |   0.203142  |    0.076467     |   0\n",
      "      36984 |   0.047895  |    0.024103     |   2\n",
      "      36985 |   0.183115  |    0.078838     |   0\n",
      "      36986 |   0.153854  |    0.037472     |   0\n",
      "      36987 |   0.137628  |    0.074162     |   0\n",
      "      36988 |   0.152335  |    0.040739     |   0\n",
      "      36989 |   0.212219  |    0.082141     |   0\n",
      "      36990 |   0.160944  |    0.160544     |   1\n",
      "      36991 |   0.224724  |    0.222581     |   1\n",
      "      36992 |   0.030685  |    0.044043     |   2\n",
      "      36993 |   0.053300  |    0.044368     |   2\n",
      "      36994 |   0.162790  |    0.083871     |   0\n",
      "      36995 |   0.035950  |    0.028650     |   2\n",
      "      36996 |   0.014116  |    0.079186     |   2\n",
      "      36997 |   0.156600  |    0.012522     |   0\n",
      "      36998 |   0.032001  |    0.076428     |   2\n",
      "      36999 |   0.124922  |    0.188062     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 37000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 37000: Plotting estimates.\n",
      "Exception in thread neuralnilm-data-process:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 810, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/jack/workspace/python/neuralnilm/neuralnilm/data/datathread.py\", line 16, in run\n",
      "    batch = self.data_pipeline.get_batch(**self._get_batch_kwargs)\n",
      "  File \"/home/jack/workspace/python/neuralnilm/neuralnilm/data/datapipeline.py\", line 46, in get_batch\n",
      "    batch = self._source_iterators[source_id].next()\n",
      "ValueError: generator already executing\n",
      "\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      37000 |   0.116717  |    0.010391     |   0\n",
      "      37001 |   0.163431  |    0.249860     |   1\n",
      "      37002 |   0.040977  |    0.012656     |   2\n",
      "      37003 |   0.158831  |    0.078705     |   0\n",
      "      37004 |   0.142717  |    0.025112     |   0\n",
      "      37005 |   0.175444  |    0.076286     |   0\n",
      "      37006 |   0.027141  |    0.031438     |   2\n",
      "      37007 |   0.032404  |    0.082446     |   2\n",
      "      37008 |   0.029312  |    0.025238     |   2\n",
      "      37009 |   0.022175  |    0.087494     |   2\n",
      "      37010 |   0.148726  |    0.189508     |   1\n",
      "      37011 |   0.028653  |    0.024053     |   2\n",
      "      37012 |   0.042779  |    0.075532     |   2\n",
      "      37013 |   0.147686  |    0.027137     |   0\n",
      "      37014 |   0.168385  |    0.215617     |   1\n",
      "      37015 |   0.186073  |    0.148821     |   1\n",
      "      37016 |   0.042025  |    0.035069     |   2\n",
      "      37017 |   0.125529  |    0.185843     |   1\n",
      "      37018 |   0.036996  |    0.026440     |   2\n",
      "      37019 |   0.167248  |    0.212714     |   1\n",
      "      37020 |   0.181973  |    0.143979     |   1\n",
      "      37021 |   0.208900  |    0.007675     |   0\n",
      "      37022 |   0.194019  |    0.191357     |   1\n",
      "      37023 |   0.175601  |    0.026178     |   0\n",
      "      37024 |   0.015967  |    0.078365     |   2\n",
      "      37025 |   0.193423  |    0.031410     |   0\n",
      "      37026 |   0.215655  |    0.079248     |   0\n",
      "      37027 |   0.000011  |    0.006047     |   2\n",
      "      37028 |   0.164177  |    0.080864     |   0\n",
      "      37029 |   0.116941  |    0.037854     |   0\n",
      "      37030 |   0.143658  |    0.153276     |   1\n",
      "      37031 |   0.174799  |    0.182871     |   1\n",
      "      37032 |   0.135106  |    0.003615     |   0\n",
      "      37033 |   0.185089  |    0.027671     |   0\n",
      "      37034 |   0.177661  |    0.037495     |   0\n",
      "      37035 |   0.003259  |    0.083084     |   2\n",
      "      37036 |   0.212807  |    0.040969     |   0\n",
      "      37037 |   0.174415  |    0.145413     |   1\n",
      "      37038 |   0.183437  |    0.028346     |   0\n",
      "      37039 |   0.047469  |    0.076856     |   2\n",
      "      37040 |   0.028553  |    0.040309     |   2\n",
      "      37041 |   0.173708  |    0.204049     |   1\n",
      "      37042 |   0.052208  |    0.026270     |   2\n",
      "      37043 |   0.195056  |    0.208521     |   1\n",
      "      37044 |   0.195676  |    0.221487     |   1\n",
      "      37045 |   0.181705  |    0.139671     |   1\n",
      "      37046 |   0.190589  |    0.144749     |   1\n",
      "      37047 |   0.033260  |    0.046968     |   2\n",
      "      37048 |   0.185194  |    0.160568     |   1\n",
      "      37049 |   0.013040  |    0.053654     |   2\n",
      "      37050 |   0.136336  |    0.074274     |   0\n",
      "      37051 |   0.155031  |    0.019693     |   0\n",
      "      37052 |   0.026233  |    0.047341     |   2\n",
      "      37053 |   0.154467  |    0.205851     |   1\n",
      "      37054 |   0.021480  |    0.049612     |   2\n",
      "      37055 |   0.000011  |    0.023774     |   2\n",
      "      37056 |   0.000011  |    0.073492     |   2\n",
      "      37057 |   0.000011  |    0.018161     |   2\n",
      "      37058 |   0.152126  |    0.186791     |   1\n",
      "      37059 |   0.000011  |    0.071345     |   2\n",
      "      37060 |   0.151691  |    0.009916     |   0\n",
      "      37061 |   0.000011  |    0.080388     |   2\n",
      "      37062 |   0.000011  |    0.020512     |   2\n",
      "      37063 |   0.038140  |    0.080887     |   2\n",
      "      37064 |   0.041241  |    0.016688     |   2\n",
      "      37065 |   0.148194  |    0.079110     |   0\n",
      "      37066 |   0.191598  |    0.142606     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 37067: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      37067 |   0.212197  |    0.078824     |   0\n",
      "      37068 |   0.244426  |    0.200913     |   1\n",
      "      37069 |   0.173408  |    0.204688     |   1\n",
      "      37070 |   0.176375  |    0.044852     |   0\n",
      "      37071 |   0.156250  |    0.044152     |   0\n",
      "      37072 |   0.179639  |    0.169925     |   1\n",
      "      37073 |   0.184503  |    0.148068     |   1\n",
      "      37074 |   0.147714  |    0.069802     |   0\n",
      "      37075 |   0.034802  |    0.038633     |   2\n",
      "      37076 |   0.172260  |    0.202621     |   1\n",
      "      37077 |   0.172658  |    0.016582     |   0\n",
      "      37078 |   0.024989  |    0.083335     |   2\n",
      "      37079 |   0.204669  |    0.187087     |   1\n",
      "      37080 |   0.032087  |    0.021811     |   2\n",
      "      37081 |   0.240672  |    0.188924     |   1\n",
      "      37082 |   0.156444  |    0.012702     |   0\n",
      "      37083 |   0.030298  |    0.086145     |   2\n",
      "      37084 |   0.185515  |    0.043948     |   0\n",
      "      37085 |   0.021556  |    0.031207     |   2\n",
      "      37086 |   0.169097  |    0.234838     |   1\n",
      "      37087 |   0.170297  |    0.152824     |   1\n",
      "      37088 |   0.162100  |    0.212810     |   1\n",
      "      37089 |   0.165924  |    0.144182     |   1\n",
      "      37090 |   0.160990  |    0.189169     |   1\n",
      "      37091 |   0.028886  |    0.017871     |   2\n",
      "      37092 |   0.038152  |    0.080106     |   2\n",
      "      37093 |   0.170527  |    0.020749     |   0\n",
      "      37094 |   0.194954  |    0.187077     |   1\n",
      "      37095 |   0.150911  |    0.082804     |   0\n",
      "      37096 |   0.039227  |    0.014864     |   2\n",
      "      37097 |   0.034146  |    0.072579     |   2\n",
      "      37098 |   0.149489  |    0.031182     |   0\n",
      "      37099 |   0.137341  |    0.218161     |   1\n",
      "      37100 |   0.013320  |    0.006215     |   2\n",
      "      37101 |   0.156177  |    0.176998     |   1\n",
      "      37102 |   0.000011  |    0.084326     |   2\n",
      "      37103 |   0.157862  |    0.152696     |   1\n",
      "      37104 |   0.140592  |    0.159806     |   1\n",
      "      37105 |   0.003476  |    0.018044     |   2\n",
      "      37106 |   0.141548  |    0.050285     |   0\n",
      "      37107 |   0.148635  |    0.191555     |   1\n",
      "      37108 |   0.050311  |    0.025399     |   2\n",
      "      37109 |   0.027659  |    0.082514     |   2\n",
      "      37110 |   0.050371  |    0.021885     |   2\n",
      "      37111 |   0.154157  |    0.213102     |   1\n",
      "      37112 |   0.167383  |    0.026969     |   0\n",
      "      37113 |   0.034026  |    0.071992     |   2\n",
      "      37114 |   0.012771  |    0.039893     |   2\n",
      "      37115 |   0.026054  |    0.077192     |   2\n",
      "      37116 |   0.020854  |    0.043158     |   2\n",
      "      37117 |   0.000011  |    0.052842     |   2\n",
      "      37118 |   0.150787  |    0.051430     |   0\n",
      "      37119 |   0.176210  |    0.047299     |   0\n",
      "      37120 |   0.162305  |    0.055527     |   0\n",
      "      37121 |   0.172304  |    0.206738     |   1\n",
      "      37122 |   0.183124  |    0.175679     |   1\n",
      "      37123 |   0.128063  |    0.004558     |   0\n",
      "      37124 |   0.158942  |    0.204628     |   1\n",
      "      37125 |   0.000011  |    0.015180     |   2\n",
      "      37126 |   0.217177  |    0.070199     |   0\n",
      "      37127 |   0.148957  |    0.026472     |   0\n",
      "      37128 |   0.134570  |    0.202249     |   1\n",
      "      37129 |   0.128907  |    0.008877     |   0\n",
      "      37130 |   0.222655  |    0.086781     |   0\n",
      "      37131 |   0.145680  |    0.036771     |   0\n",
      "      37132 |   0.189417  |    0.205520     |   1\n",
      "      37133 |   0.186120  |    0.020197     |   0\n",
      "      37134 |   0.173476  |    0.077529     |   0\n",
      "      37135 |   0.000011  |    0.018827     |   2\n",
      "      37136 |   0.236784  |    0.212269     |   1\n",
      "      37137 | \u001b[94m  0.000011\u001b[0m  |    0.017211     |   2\n",
      "      37138 |   0.115952  |    0.210755     |   1\n",
      "      37139 |   0.139324  |    0.062252     |   0\n",
      "      37140 |   0.197570  |    0.157414     |   1\n",
      "      37141 |   0.205113  |    0.157226     |   1\n",
      "      37142 |   0.176032  |    0.052710     |   0\n",
      "      37143 | \u001b[94m  0.000011\u001b[0m  |    0.041059     |   2\n",
      "      37144 |   0.162864  |    0.085111     |   0\n",
      "      37145 |   0.134228  |    0.011180     |   0\n",
      "      37146 |   0.169914  |    0.075715     |   0\n",
      "      37147 |   0.182817  |    0.196564     |   1\n",
      "      37148 |   0.184713  |    0.142284     |   1\n",
      "      37149 | \u001b[94m  0.000011\u001b[0m  |    0.059433     |   2\n",
      "      37150 |   0.147726  |    0.284841     |   1\n",
      "      37151 |   0.197130  |    0.168735     |   1\n",
      "      37152 |   0.162495  |    0.026146     |   0\n",
      "      37153 |   0.169607  |    0.077052     |   0\n",
      "      37154 |   0.191677  |    0.031698     |   0\n",
      "      37155 |   0.039599  |    0.039822     |   2\n",
      "      37156 |   0.134492  |    0.078124     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 37158: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      37157 |   0.041830  |    0.015930     |   2\n",
      "      37158 |   0.197501  |    0.267189     |   1\n",
      "      37159 |   0.173375  |    0.143389     |   1\n",
      "      37160 |   0.140143  |    0.140309     |   1\n",
      "      37161 |   0.184627  |    0.046992     |   0\n",
      "      37162 |   0.217627  |    0.209751     |   1\n",
      "      37163 |   0.038290  |    0.005287     |   2\n",
      "      37164 |   0.158882  |    0.199768     |   1\n",
      "      37165 |   0.024779  |    0.045078     |   2\n",
      "      37166 |   0.147395  |    0.171825     |   1\n",
      "      37167 |   0.161985  |    0.147976     |   1\n",
      "      37168 |   0.170386  |    0.192297     |   1\n",
      "      37169 |   0.032528  |    0.041780     |   2\n",
      "      37170 |   0.180123  |    0.194046     |   1\n",
      "      37171 |   0.139132  |    0.141165     |   1\n",
      "      37172 |   0.163024  |    0.187616     |   1\n",
      "      37173 |   0.173152  |    0.197996     |   1\n",
      "      37174 |   0.029520  |    0.011869     |   2\n",
      "      37175 |   0.021380  |    0.046529     |   2\n",
      "      37176 |   0.245906  |    0.047109     |   0\n",
      "      37177 |   0.028704  |    0.077095     |   2\n",
      "      37178 |   0.169913  |    0.028499     |   0\n",
      "      37179 |   0.037955  |    0.077216     |   2\n",
      "      37180 |   0.038606  |    0.041062     |   2\n",
      "      37181 |   0.189452  |    0.138736     |   1\n",
      "      37182 |   0.192145  |    0.090663     |   0\n",
      "      37183 |   0.215353  |    0.142739     |   1\n",
      "      37184 |   0.114267  |    0.026106     |   0\n",
      "      37185 |   0.178409  |    0.188650     |   1\n",
      "      37186 |   0.213172  |    0.194951     |   1\n",
      "      37187 |   0.031584  |    0.005070     |   2\n",
      "      37188 |   0.229813  |    0.151887     |   1\n",
      "      37189 |   0.168264  |    0.075888     |   0\n",
      "      37190 |   0.233100  |    0.037873     |   0\n",
      "      37191 |   0.179843  |    0.196087     |   1\n",
      "      37192 |   0.183281  |    0.024686     |   0\n",
      "      37193 |   0.189854  |    0.248698     |   1\n",
      "      37194 |   0.014937  |    0.017478     |   2\n",
      "      37195 |   0.145182  |    0.080782     |   0\n",
      "      37196 |   0.145544  |    0.150875     |   1\n",
      "      37197 |   0.000011  |    0.073571     |   2\n",
      "      37198 |   0.172817  |    0.132418     |   1\n",
      "      37199 |   0.003861  |    0.072232     |   2\n",
      "      37200 |   0.047577  |    0.023630     |   2\n",
      "      37201 |   0.165722  |    0.078714     |   0\n",
      "      37202 |   0.027938  |    0.034171     |   2\n",
      "      37203 |   0.052151  |    0.034835     |   2\n",
      "      37204 |   0.146986  |    0.241269     |   1\n",
      "      37205 |   0.188034  |    0.007662     |   0\n",
      "      37206 |   0.034099  |    0.090037     |   2\n",
      "      37207 |   0.012466  |    0.009077     |   2\n",
      "      37208 |   0.027376  |    0.087762     |   2\n",
      "      37209 |   0.020800  |    0.018126     |   2\n",
      "      37210 |   0.189261  |    0.077901     |   0\n",
      "      37211 |   0.108531  |    0.158359     |   1\n",
      "      37212 |   0.167892  |    0.155702     |   1\n",
      "      37213 |   0.150719  |    0.077860     |   0\n",
      "      37214 |   0.123519  |    0.025403     |   0\n",
      "      37215 |   0.193889  |    0.149631     |   1\n",
      "      37216 |   0.145456  |    0.058990     |   0\n",
      "      37217 |   0.137431  |    0.184623     |   1\n",
      "      37218 |   0.166495  |    0.017963     |   0\n",
      "      37219 |   0.000011  |    0.081695     |   2\n",
      "      37220 |   0.149766  |    0.154827     |   1\n",
      "      37221 |   0.183770  |    0.009721     |   0\n",
      "      37222 |   0.179357  |    0.197292     |   1\n",
      "      37223 |   0.000011  |    0.019771     |   2\n",
      "      37224 |   0.255783  |    0.203435     |   1\n",
      "      37225 |   0.000011  |    0.014216     |   2\n",
      "      37226 |   0.148815  |    0.085026     |   0\n",
      "      37227 |   0.142293  |    0.199095     |   1\n",
      "      37228 |   0.149803  |    0.147153     |   1\n",
      "      37229 |   0.000011  |    0.008057     |   2\n",
      "      37230 |   0.190982  |    0.078955     |   0\n",
      "      37231 |   0.158307  |    0.045287     |   0\n",
      "      37232 |   0.000011  |    0.038676     |   2\n",
      "      37233 |   0.193480  |    0.052040     |   0\n",
      "      37234 |   0.174252  |    0.144799     |   1\n",
      "      37235 |   0.177526  |    0.035694     |   0\n",
      "      37236 |   0.000011  |    0.082557     |   2\n",
      "      37237 |   0.037222  |    0.016611     |   2\n",
      "      37238 |   0.179625  |    0.075677     |   0\n",
      "      37239 |   0.114498  |    0.023925     |   0\n",
      "      37240 |   0.150008  |    0.196130     |   1\n",
      "      37241 |   0.160374  |    0.164301     |   1\n",
      "      37242 |   0.187814  |    0.005107     |   0\n",
      "      37243 |   0.039534  |    0.046177     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 37244: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      37244 |   0.128064  |    0.194356     |   1\n",
      "      37245 |   0.034555  |    0.042770     |   2\n",
      "      37246 |   0.185106  |    0.042720     |   0\n",
      "      37247 |   0.205282  |    0.164975     |   1\n",
      "      37248 |   0.219900  |    0.177244     |   1\n",
      "      37249 |   0.144154  |    0.134134     |   1\n",
      "      37250 |   0.023592  |    0.008014     |   2\n",
      "      37251 |   0.184502  |    0.082008     |   0\n",
      "      37252 |   0.180838  |    0.022072     |   0\n",
      "      37253 |   0.032257  |    0.056870     |   2\n",
      "      37254 |   0.029461  |    0.038296     |   2\n",
      "      37255 |   0.130816  |    0.209376     |   1\n",
      "      37256 |   0.022140  |    0.007838     |   2\n",
      "      37257 |   0.193250  |    0.078300     |   0\n",
      "      37258 |   0.131667  |    0.045611     |   0\n",
      "      37259 |   0.140330  |    0.205175     |   1\n",
      "      37260 |   0.204051  |    0.148542     |   1\n",
      "      37261 |   0.205315  |    0.145589     |   1\n",
      "      37262 |   0.113371  |    0.048710     |   0\n",
      "      37263 |   0.029684  |    0.048525     |   2\n",
      "      37264 |   0.042542  |    0.048963     |   2\n",
      "      37265 |   0.130881  |    0.036364     |   0\n",
      "      37266 |   0.168754  |    0.076251     |   0\n",
      "      37267 |   0.038914  |    0.005691     |   2\n",
      "      37268 |   0.195640  |    0.075850     |   0\n",
      "      37269 |   0.035203  |    0.044300     |   2\n",
      "      37270 |   0.167741  |    0.206182     |   1\n",
      "      37271 |   0.014902  |    0.029929     |   2\n",
      "      37272 |   0.135917  |    0.192411     |   1\n",
      "      37273 |   0.191925  |    0.199830     |   1\n",
      "      37274 |   0.169499  |    0.149020     |   1\n",
      "      37275 |   0.000011  |    0.055537     |   2\n",
      "      37276 |   0.156417  |    0.045494     |   0\n",
      "      37277 |   0.184437  |    0.050783     |   0\n",
      "      37278 |   0.164991  |    0.042796     |   0\n",
      "      37279 |   0.206376  |    0.083884     |   0\n",
      "      37280 |   0.151683  |    0.194892     |   1\n",
      "      37281 |   0.003816  |    0.027304     |   2\n",
      "      37282 |   0.155619  |    0.201138     |   1\n",
      "      37283 |   0.047588  |    0.003805     |   2\n",
      "      37284 |   0.028261  |    0.086184     |   2\n",
      "      37285 |   0.052415  |    0.015736     |   2\n",
      "      37286 |   0.124286  |    0.076256     |   0\n",
      "      37287 |   0.175751  |    0.024846     |   0\n",
      "      37288 |   0.035691  |    0.056680     |   2\n",
      "      37289 |   0.165842  |    0.051472     |   0\n",
      "      37290 |   0.186431  |    0.195785     |   1\n",
      "      37291 |   0.175170  |    0.026698     |   0\n",
      "      37292 |   0.177631  |    0.076317     |   0\n",
      "      37293 |   0.171786  |    0.164362     |   1\n",
      "      37294 |   0.163208  |    0.222450     |   1\n",
      "      37295 |   0.013856  |    0.004252     |   2\n",
      "      37296 |   0.211444  |    0.199913     |   1\n",
      "      37297 |   0.201208  |    0.144057     |   1\n",
      "      37298 |   0.028099  |    0.046332     |   2\n",
      "      37299 |   0.126316  |    0.041289     |   0\n",
      "      37300 |   0.135428  |    0.254300     |   1\n",
      "      37301 |   0.167752  |    0.134927     |   1\n",
      "      37302 |   0.020559  |    0.015189     |   2\n",
      "      37303 |   0.000011  |    0.079843     |   2\n",
      "      37304 |   0.000011  |    0.046998     |   2\n",
      "      37305 |   0.000011  |    0.041794     |   2\n",
      "      37306 |   0.000011  |    0.050997     |   2\n",
      "      37307 |   0.000011  |    0.080725     |   2\n",
      "      37308 |   0.167361  |    0.040301     |   0\n",
      "      37309 |   0.196741  |    0.046346     |   0\n",
      "      37310 |   0.000011  |    0.046548     |   2\n",
      "      37311 |   0.035720  |    0.072125     |   2\n",
      "      37312 |   0.184239  |    0.029913     |   0\n",
      "      37313 |   0.178372  |    0.210598     |   1\n",
      "      37314 |   0.127609  |    0.195630     |   1\n",
      "      37315 |   0.038801  |    0.004873     |   2\n",
      "      37316 |   0.183599  |    0.090291     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 37317: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      37317 |   0.181858  |    0.138468     |   1\n",
      "      37318 |   0.195193  |    0.052979     |   0\n",
      "      37319 |   0.037339  |    0.038310     |   2\n",
      "      37320 |   0.165742  |    0.266341     |   1\n",
      "      37321 |   0.146540  |    0.042251     |   0\n",
      "      37322 |   0.166171  |    0.047235     |   0\n",
      "      37323 |   0.024786  |    0.079207     |   2\n",
      "      37324 |   0.156174  |    0.043478     |   0\n",
      "      37325 |   0.171094  |    0.250973     |   1\n",
      "      37326 |   0.031596  |    0.025326     |   2\n",
      "      37327 |   0.029200  |    0.089668     |   2\n",
      "      37328 |   0.193969  |    0.186969     |   1\n",
      "      37329 |   0.021950  |    0.015021     |   2\n",
      "      37330 |   0.180116  |    0.089242     |   0\n",
      "      37331 |   0.208358  |    0.195043     |   1\n",
      "      37332 |   0.180737  |    0.151272     |   1\n",
      "      37333 |   0.148396  |    0.024201     |   0\n",
      "      37334 |   0.028828  |    0.072912     |   2\n",
      "      37335 |   0.039969  |    0.040954     |   2\n",
      "      37336 |   0.040370  |    0.083649     |   2\n",
      "      37337 |   0.183631  |    0.160982     |   1\n",
      "      37338 |   0.134990  |    0.007435     |   0\n",
      "      37339 |   0.132358  |    0.136273     |   1\n",
      "      37340 |   0.138593  |    0.047039     |   0\n",
      "      37341 |   0.165981  |    0.075766     |   0\n",
      "      37342 |   0.036011  |    0.025470     |   2\n",
      "      37343 |   0.015573  |    0.049236     |   2\n",
      "      37344 |   0.136985  |    0.212454     |   1\n",
      "      37345 |   0.000011  |    0.036628     |   2\n",
      "      37346 |   0.172583  |    0.050897     |   0\n",
      "      37347 |   0.003294  |    0.049038     |   2\n",
      "      37348 |   0.216928  |    0.076933     |   0\n",
      "      37349 |   0.048392  |    0.042043     |   2\n",
      "      37350 |   0.209850  |    0.212632     |   1\n",
      "      37351 |   0.121602  |    0.224024     |   1\n",
      "      37352 |   0.179008  |    0.086444     |   1\n",
      "      37353 |   0.191627  |    0.192411     |   1\n",
      "      37354 |   0.191378  |    0.189966     |   1\n",
      "      37355 |   0.183407  |    0.004466     |   0\n",
      "      37356 |   0.183399  |    0.201387     |   1\n",
      "      37357 |   0.172088  |    0.028705     |   0\n",
      "      37358 |   0.160876  |    0.080641     |   0\n",
      "      37359 |   0.027664  |    0.023428     |   2\n",
      "      37360 |   0.048782  |    0.082291     |   2\n",
      "      37361 |   0.179917  |    0.080023     |   0\n",
      "      37362 |   0.149126  |    0.044318     |   0\n",
      "      37363 |   0.032005  |    0.046087     |   2\n",
      "      37364 |   0.159677  |    0.093345     |   0\n",
      "      37365 |   0.170963  |    0.176805     |   1\n",
      "      37366 |   0.148567  |    0.008394     |   0\n",
      "      37367 |   0.014857  |    0.077143     |   2\n",
      "      37368 |   0.030259  |    0.043389     |   2\n",
      "      37369 |   0.144761  |    0.058472     |   0\n",
      "      37370 |   0.171785  |    0.159715     |   1\n",
      "      37371 |   0.193183  |    0.045166     |   0\n",
      "      37372 |   0.153708  |    0.025971     |   0\n",
      "      37373 |   0.165830  |    0.086968     |   0\n",
      "      37374 |   0.021716  |    0.025909     |   2\n",
      "      37375 |   0.000011  |    0.087055     |   2\n",
      "      37376 |   0.161627  |    0.076111     |   0\n",
      "      37377 |   0.176810  |    0.042890     |   0\n",
      "      37378 |   0.188475  |    0.196734     |   1\n",
      "      37379 |   0.119876  |    0.165611     |   1\n",
      "      37380 |   0.000011  |    0.021233     |   2\n",
      "      37381 |   0.167517  |    0.249462     |   1\n",
      "      37382 |   0.158005  |    0.159100     |   1\n",
      "      37383 |   0.129403  |    0.080813     |   0\n",
      "      37384 |   0.000011  |    0.028349     |   2\n",
      "      37385 |   0.160561  |    0.158520     |   1\n",
      "      37386 |   0.191352  |    0.136886     |   1\n",
      "      37387 |   0.129584  |    0.057943     |   0\n",
      "      37388 |   0.151455  |    0.198249     |   1\n",
      "      37389 |   0.145683  |    0.139755     |   1\n",
      "      37390 |   0.000011  |    0.052377     |   2\n",
      "      37391 |   0.000011  |    0.079930     |   2\n",
      "      37392 |   0.212766  |    0.136739     |   1\n",
      "      37393 |   0.000011  |    0.038900     |   2\n",
      "      37394 |   0.148315  |    0.040983     |   0\n",
      "      37395 |   0.249938  |    0.078622     |   0\n",
      "      37396 |   0.039072  |    0.040551     |   2\n",
      "      37397 |   0.183155  |    0.076996     |   0\n",
      "      37398 |   0.230522  |    0.155973     |   1\n",
      "      37399 |   0.171147  |    0.024779     |   0\n",
      "      37400 |   0.211635  |    0.226751     |   1\n",
      "      37401 |   0.159130  |    0.004150     |   0\n",
      "      37402 |   0.181789  |    0.308155     |   1\n",
      "      37403 |   0.164333  |    0.167559     |   1\n",
      "      37404 |   0.040252  |    0.027909     |   2\n",
      "      37405 |   0.124729  |    0.080759     |   0\n",
      "      37406 |   0.192641  |    0.168731     |   1\n",
      "      37407 |   0.190264  |    0.147488     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 37408: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      37408 |   0.167656  |    0.052564     |   0\n",
      "      37409 |   0.041506  |    0.055309     |   2\n",
      "      37410 |   0.026902  |    0.052898     |   2\n",
      "      37411 |   0.192918  |    0.170295     |   1\n",
      "      37412 |   0.209077  |    0.144099     |   1\n",
      "      37413 |   0.111658  |    0.047042     |   0\n",
      "      37414 |   0.219314  |    0.105746     |   0\n",
      "      37415 |   0.197060  |    0.149220     |   1\n",
      "      37416 |   0.176975  |    0.198789     |   1\n",
      "      37417 |   0.162161  |    0.010888     |   0\n",
      "      37418 |   0.144671  |    0.219809     |   1\n",
      "      37419 |   0.208452  |    0.153126     |   1\n",
      "      37420 |   0.145691  |    0.026336     |   0\n",
      "      37421 |   0.145689  |    0.191809     |   1\n",
      "      37422 |   0.172717  |    0.220469     |   1\n",
      "      37423 |   0.031988  |    0.010816     |   2\n",
      "      37424 |   0.193212  |    0.162061     |   1\n",
      "      37425 |   0.029948  |    0.026455     |   2\n",
      "      37426 |   0.159229  |    0.184115     |   1\n",
      "      37427 |   0.198572  |    0.083715     |   0\n",
      "      37428 |   0.180423  |    0.029006     |   0\n",
      "      37429 |   0.126855  |    0.030979     |   0\n",
      "      37430 |   0.196984  |    0.221481     |   1\n",
      "      37431 |   0.218588  |    0.205914     |   1\n",
      "      37432 |   0.022104  |    0.024684     |   2\n",
      "      37433 |   0.029025  |    0.082532     |   2\n",
      "      37434 |   0.039319  |    0.057054     |   2\n",
      "      37435 |   0.159021  |    0.053208     |   0\n",
      "      37436 |   0.040756  |    0.079349     |   2\n",
      "      37437 |   0.037187  |    0.063030     |   2\n",
      "      37438 |   0.232086  |    0.310792     |   1\n",
      "      37439 |   0.016778  |    0.088817     |   2\n",
      "      37440 |   0.158812  |    0.313949     |   1\n",
      "      37441 |   0.000011  |    0.036104     |   2\n",
      "      37442 |   0.204513  |    0.280864     |   1\n",
      "      37443 |   0.160646  |    0.004847     |   0\n",
      "      37444 |   0.003713  |    0.127511     |   2\n",
      "      37445 |   0.049750  |    0.048757     |   2\n",
      "      37446 |   0.028107  |    0.081432     |   2\n",
      "      37447 |   0.184527  |    0.210071     |   1\n",
      "      37448 |   0.159942  |    0.030159     |   0\n",
      "      37449 |   0.130804  |    0.212695     |   1\n",
      "      37450 |   0.170628  |    0.042994     |   0\n",
      "      37451 |   0.190369  |    0.044790     |   0\n",
      "      37452 |   0.185961  |    0.062908     |   0\n",
      "      37453 |   0.161072  |    0.188414     |   1\n",
      "      37454 |   0.049121  |    0.003665     |   2\n",
      "      37455 |   0.034783  |    0.086669     |   2\n",
      "      37456 |   0.135504  |    0.033113     |   0\n",
      "      37457 |   0.146698  |    0.054291     |   0\n",
      "      37458 |   0.156562  |    0.186433     |   1\n",
      "      37459 |   0.141239  |    0.024915     |   0\n",
      "      37460 |   0.182552  |    0.075793     |   0\n",
      "      37461 |   0.166594  |    0.039177     |   0\n",
      "      37462 |   0.122894  |    0.204244     |   1\n",
      "      37463 |   0.012642  |    0.040596     |   2\n",
      "      37464 |   0.115685  |    0.079527     |   0\n",
      "      37465 |   0.026254  |    0.007806     |   2\n",
      "      37466 |   0.019731  |    0.070864     |   2\n",
      "      37467 |   0.195438  |    0.238953     |   1\n",
      "      37468 |   0.000011  |    0.006647     |   2\n",
      "      37469 |   0.174343  |    0.193422     |   1\n",
      "      37470 |   0.164133  |    0.155217     |   1\n",
      "      37471 |   0.000011  |    0.076553     |   2\n",
      "      37472 |   0.209372  |    0.145169     |   1\n",
      "      37473 |   0.163012  |    0.047267     |   0\n",
      "      37474 |   0.000011  |    0.031435     |   2\n",
      "      37475 |   0.000011  |    0.047793     |   2\n",
      "      37476 |   0.177025  |    0.188225     |   1\n",
      "      37477 |   0.143241  |    0.043847     |   0\n",
      "      37478 |   0.167463  |    0.045912     |   0\n",
      "      37479 |   0.132672  |    0.041586     |   0\n",
      "      37480 |   0.000011  |    0.072688     |   2\n",
      "      37481 |   0.151878  |    0.191435     |   1\n",
      "      37482 |   0.213750  |    0.006874     |   0\n",
      "      37483 |   0.000011  |    0.041994     |   2\n",
      "      37484 |   0.250280  |    0.222512     |   1\n",
      "      37485 |   0.227063  |    0.150433     |   1\n",
      "      37486 |   0.035839  |    0.022792     |   2\n",
      "      37487 |   0.039061  |    0.070686     |   2\n",
      "      37488 |   0.167120  |    0.047201     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 37489: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      37489 |   0.037503  |    0.043574     |   2\n",
      "      37490 |   0.193118  |    0.075840     |   0\n",
      "      37491 |   0.025146  |    0.022216     |   2\n",
      "      37492 |   0.199174  |    0.075212     |   0\n",
      "      37493 |   0.221184  |    0.067192     |   0\n",
      "      37494 |   0.149899  |    0.147874     |   1\n",
      "      37495 |   0.219101  |    0.186856     |   1\n",
      "      37496 |   0.180152  |    0.009759     |   0\n",
      "      37497 |   0.159958  |    0.079924     |   0\n",
      "      37498 |   0.157116  |    0.024256     |   0\n",
      "      37499 |   0.171547  |    0.202226     |   1\n",
      "      37500 |   0.149952  |    0.011687     |   0\n",
      "      37501 |   0.139272  |    0.074406     |   0\n",
      "      37502 |   0.169347  |    0.066742     |   0\n",
      "      37503 |   0.194830  |    0.154945     |   1\n",
      "      37504 |   0.134968  |    0.080984     |   0\n",
      "      37505 |   0.177116  |    0.022435     |   0\n",
      "      37506 |   0.181406  |    0.081617     |   0\n",
      "      37507 |   0.038786  |    0.029546     |   2\n",
      "      37508 |   0.025691  |    0.081831     |   2\n",
      "      37509 |   0.177516  |    0.147553     |   1\n",
      "      37510 |   0.221484  |    0.148069     |   1\n",
      "      37511 |   0.172344  |    0.144685     |   1\n",
      "      37512 |   0.186643  |    0.192353     |   1\n",
      "      37513 |   0.170720  |    0.019508     |   0\n",
      "      37514 |   0.129858  |    0.045922     |   0\n",
      "      37515 |   0.127792  |    0.213300     |   1\n",
      "      37516 |   0.154776  |    0.015574     |   0\n",
      "      37517 |   0.124900  |    0.074407     |   0\n",
      "      37518 |   0.032616  |    0.040244     |   2\n",
      "      37519 |   0.030023  |    0.042637     |   2\n",
      "      37520 |   0.209903  |    0.200242     |   1\n",
      "      37521 |   0.021786  |    0.008193     |   2\n",
      "      37522 |   0.150776  |    0.076062     |   0\n",
      "      37523 |   0.180933  |    0.043232     |   0\n",
      "      37524 |   0.028613  |    0.075942     |   2\n",
      "      37525 |   0.041323  |    0.020898     |   2\n",
      "      37526 |   0.158194  |    0.225508     |   1\n",
      "      37527 |   0.041635  |    0.013860     |   2\n",
      "      37528 |   0.034372  |    0.106116     |   2\n",
      "      37529 |   0.155599  |    0.172678     |   1\n",
      "      37530 |   0.015956  |    0.082050     |   2\n",
      "      37531 |   0.182544  |    0.196611     |   1\n",
      "      37532 |   0.137395  |    0.007751     |   0\n",
      "      37533 |   0.273605  |    0.147392     |   1\n",
      "      37534 |   0.173903  |    0.155832     |   1\n",
      "      37535 |   0.172131  |    0.057818     |   0\n",
      "      37536 |   0.000011  |    0.080119     |   2\n",
      "      37537 |   0.124394  |    0.186258     |   1\n",
      "      37538 |   0.140643  |    0.032885     |   0\n",
      "      37539 |   0.158675  |    0.082026     |   0\n",
      "      37540 |   0.273026  |    0.033549     |   0\n",
      "      37541 |   0.003237  |    0.085754     |   2\n",
      "      37542 |   0.153032  |    0.050618     |   0\n",
      "      37543 |   0.045777  |    0.088336     |   2\n",
      "      37544 |   0.164526  |    0.164760     |   1\n",
      "      37545 |   0.172425  |    0.154495     |   1\n",
      "      37546 |   0.177920  |    0.167397     |   1\n",
      "      37547 |   0.138736  |    0.237906     |   1\n",
      "      37548 |   0.238282  |    0.208347     |   1\n",
      "      37549 |   0.170168  |    0.211068     |   1\n",
      "      37550 |   0.184908  |    0.032526     |   0\n",
      "      37551 |   0.026498  |    0.137784     |   2\n",
      "      37552 |   0.139737  |    0.209389     |   1\n",
      "      37553 |   0.126696  |    0.139107     |   1\n",
      "      37554 |   0.125998  |    0.027685     |   0\n",
      "      37555 |   0.046842  |    0.079761     |   2\n",
      "      37556 |   0.186578  |    0.190429     |   1\n",
      "      37557 |   0.175068  |    0.020675     |   0\n",
      "      37558 |   0.160496  |    0.073424     |   0\n",
      "      37559 |   0.033947  |    0.026339     |   2\n",
      "      37560 |   0.174211  |    0.182394     |   1\n",
      "      37561 |   0.014369  |    0.089283     |   2\n",
      "      37562 |   0.145587  |    0.208244     |   1\n",
      "      37563 |   0.137058  |    0.011260     |   0\n",
      "      37564 |   0.027574  |    0.075304     |   2\n",
      "      37565 |   0.020923  |    0.123810     |   2\n",
      "      37566 |   0.133693  |    0.016813     |   0\n",
      "      37567 |   0.159122  |    0.218800     |   1\n",
      "      37568 | \u001b[94m  0.000011\u001b[0m  |    0.030018     |   2\n",
      "      37569 |   0.146968  |    0.088739     |   0\n",
      "      37570 |   0.230283  |    0.038228     |   0\n",
      "      37571 |   0.180666  |    0.230409     |   1\n",
      "      37572 |   0.195898  |    0.013131     |   0\n",
      "      37573 | \u001b[94m  0.000011\u001b[0m  |    0.084130     |   2\n",
      "      37574 |   0.169613  |    0.151699     |   1\n",
      "      37575 |   0.184358  |    0.063490     |   0\n",
      "      37576 |   0.230217  |    0.168574     |   1\n",
      "      37577 |   0.000011  |    0.062110     |   2\n",
      "      37578 |   0.190798  |    0.173899     |   1\n",
      "      37579 |   0.150882  |    0.198477     |   1\n",
      "      37580 |   0.168997  |    0.082037     |   0\n",
      "      37581 |   0.121901  |    0.032170     |   0\n",
      "      37582 |   0.179122  |    0.218207     |   1\n",
      "      37583 |   0.160327  |    0.176670     |   1\n",
      "      37584 |   0.162896  |    0.191079     |   1\n",
      "      37585 |   0.000011  |    0.048070     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Keyboard interrupt at iteration 37587.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      37586 |   0.000011  |    0.032582     |   2\n",
      "\n",
      "------------------ OPTIONS ------------------\n",
      "d: Enter debugger.\n",
      "s: Save plots and params.\n",
      "q: Quit all experiments.\n",
      "e: Change number of epochs to train this net (currently 50000).\n",
      "c: Continue training.\n",
      "\n",
      "Please enter one or more letters: q\n",
      "Are you sure you want to quit [Y/n]? \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-e9bfd69949c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/jack/workspace/python/neuralnilm/neuralnilm/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, num_iterations)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_menu\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_menu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_training_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jack/workspace/python/neuralnilm/neuralnilm/trainer.py\u001b[0m in \u001b[0;36m_menu\u001b[1;34m(self, epochs)\u001b[0m\n\u001b[0;32m    364\u001b[0m                 \u001b[0msure\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mraw_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Are you sure you want to quit [Y/n]? \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0msure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'n'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 366\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mselection\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'e'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m                 \u001b[0mnew_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mraw_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"New number of epochs (or 'None'): \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.fit(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.train_iterations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
