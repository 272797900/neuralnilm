{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from neuralnilm.data.loadactivations import load_nilmtk_activations\n",
    "from neuralnilm.data.syntheticaggregatesource import SyntheticAggregateSource\n",
    "from neuralnilm.data.datapipeline import DataPipeline\n",
    "from neuralnilm.data.processing import DivideBy, IndependentlyCenter\n",
    "from neuralnilm.data.datathread import DataThread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NILMTK_FILENAME = '/data/mine/vadeec/merged/ukdale.h5'\n",
    "TARGET_APPLIANCE = 'kettle'\n",
    "SEQ_LENGTH = 256\n",
    "SAMPLE_PERIOD = 6\n",
    "STRIDE = SEQ_LENGTH\n",
    "WINDOWS = {\n",
    "    'train': {\n",
    "        1: (\"2014-01-01\", \"2014-02-01\")\n",
    "    },\n",
    "    'unseen_activations_of_seen_appliances': {\n",
    "        1: (\"2014-02-02\", \"2014-02-08\")                \n",
    "    },\n",
    "    'unseen_appliances': {\n",
    "        2: (\"2013-06-01\", \"2013-06-07\")\n",
    "    }\n",
    "}\n",
    "\n",
    "LOADER_CONFIG = {\n",
    "    'nilmtk_activations': dict(\n",
    "        appliances=['kettle', 'microwave', 'washing machine'],\n",
    "        filename=NILMTK_FILENAME,\n",
    "        sample_period=SAMPLE_PERIOD,\n",
    "        windows=WINDOWS\n",
    "    )\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from neuralnilm.data.stridesource import StrideSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.data.stridesource:Loading NILMTK data...\n",
      "INFO:neuralnilm.data.stridesource:Loading data for UK-DALE_building_1...\n",
      "INFO:neuralnilm.data.stridesource:Loaded data from building UK-DALE_building_1 for fold train from 2014-01-01 00:00:06+00:00 to 2014-01-31 23:59:54+00:00.\n",
      "INFO:neuralnilm.data.stridesource:Loading data for UK-DALE_building_2...\n",
      "INFO:neuralnilm.data.stridesource:Loaded data from building UK-DALE_building_2 for fold unseen_appliances from 2013-06-01 00:00:00+01:00 to 2013-06-06 23:59:54+01:00.\n",
      "INFO:neuralnilm.data.stridesource:Loading data for UK-DALE_building_1...\n",
      "INFO:neuralnilm.data.stridesource:Loaded data from building UK-DALE_building_1 for fold unseen_activations_of_seen_appliances from 2014-02-02 00:00:00+00:00 to 2014-02-07 23:59:54+00:00.\n",
      "INFO:neuralnilm.data.stridesource:Done loading NILMTK mains data.\n"
     ]
    }
   ],
   "source": [
    "stride_source = StrideSource(\n",
    "    target_appliance=TARGET_APPLIANCE,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    filename=NILMTK_FILENAME,\n",
    "    windows=WINDOWS,\n",
    "    sample_period=SAMPLE_PERIOD,\n",
    "    stride=STRIDE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.data.loadactivations:Loading NILMTK activations...\n",
      "INFO:neuralnilm.data.loadactivations:Loading kettle for UK-DALE_building_1...\n",
      "INFO:neuralnilm.data.loadactivations:Loaded 111 kettle activations from UK-DALE_building_1.\n",
      "INFO:neuralnilm.data.loadactivations:Loading microwave for UK-DALE_building_1...\n",
      "INFO:neuralnilm.data.loadactivations:Loaded 114 microwave activations from UK-DALE_building_1.\n",
      "INFO:neuralnilm.data.loadactivations:Loading washing machine for UK-DALE_building_1...\n",
      "INFO:neuralnilm.data.loadactivations:Loaded 23 washing machine activations from UK-DALE_building_1.\n",
      "INFO:neuralnilm.data.loadactivations:Loading kettle for UK-DALE_building_2...\n",
      "INFO:neuralnilm.data.loadactivations:Loaded 31 kettle activations from UK-DALE_building_2.\n",
      "INFO:neuralnilm.data.loadactivations:Loading microwave for UK-DALE_building_2...\n",
      "INFO:neuralnilm.data.loadactivations:Loaded 31 microwave activations from UK-DALE_building_2.\n",
      "INFO:neuralnilm.data.loadactivations:Loading washing machine for UK-DALE_building_2...\n",
      "INFO:neuralnilm.data.loadactivations:Loaded 2 washing machine activations from UK-DALE_building_2.\n",
      "INFO:neuralnilm.data.loadactivations:Loading kettle for UK-DALE_building_1...\n",
      "INFO:neuralnilm.data.loadactivations:Loaded 28 kettle activations from UK-DALE_building_1.\n",
      "INFO:neuralnilm.data.loadactivations:Loading microwave for UK-DALE_building_1...\n",
      "INFO:neuralnilm.data.loadactivations:Loaded 30 microwave activations from UK-DALE_building_1.\n",
      "INFO:neuralnilm.data.loadactivations:Loading washing machine for UK-DALE_building_1...\n",
      "INFO:neuralnilm.data.loadactivations:Loaded 5 washing machine activations from UK-DALE_building_1.\n",
      "INFO:neuralnilm.data.loadactivations:Done loading NILMTK activations.\n"
     ]
    }
   ],
   "source": [
    "nilmtk_activations = load_nilmtk_activations(**LOADER_CONFIG['nilmtk_activations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train', 'unseen_activations_of_seen_appliances', 'unseen_appliances']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nilmtk_activations.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from neuralnilm.data.realaggregatesource import RealAggregateSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.data.realaggregatesource:Loading NILMTK mains...\n",
      "INFO:neuralnilm.data.realaggregatesource:Loading mains for UK-DALE_building_1...\n",
      "INFO:neuralnilm.data.realaggregatesource:Loaded mains data from building UK-DALE_building_1 for fold train from 2014-01-01 00:00:00+00:00 to 2014-01-31 23:59:54+00:00.\n",
      "INFO:neuralnilm.data.realaggregatesource:Loading mains for UK-DALE_building_2...\n",
      "INFO:neuralnilm.data.realaggregatesource:Loaded mains data from building UK-DALE_building_2 for fold unseen_appliances from 2013-06-01 00:00:00+01:00 to 2013-06-06 23:59:54+01:00.\n",
      "INFO:neuralnilm.data.realaggregatesource:Loading mains for UK-DALE_building_1...\n",
      "INFO:neuralnilm.data.realaggregatesource:Loaded mains data from building UK-DALE_building_1 for fold unseen_activations_of_seen_appliances from 2014-02-02 00:00:00+00:00 to 2014-02-07 23:59:54+00:00.\n",
      "INFO:neuralnilm.data.realaggregatesource:Done loading NILMTK mains data.\n",
      "INFO:neuralnilm.data.realaggregatesource:Found 89 sections without target for train UK-DALE_building_1.\n",
      "INFO:neuralnilm.data.realaggregatesource:Found 20 sections without target for unseen_activations_of_seen_appliances UK-DALE_building_1.\n",
      "INFO:neuralnilm.data.realaggregatesource:Found 24 sections without target for unseen_appliances UK-DALE_building_2.\n"
     ]
    }
   ],
   "source": [
    "ras = RealAggregateSource(\n",
    "    activations=nilmtk_activations,\n",
    "    target_appliance=TARGET_APPLIANCE,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    filename=NILMTK_FILENAME,\n",
    "    windows=WINDOWS,\n",
    "    sample_period=SAMPLE_PERIOD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ras.target_inclusion_prob = 0.5\n",
    "for i in range(50):\n",
    "    seq = ras.get_sequence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fig, axes = plt.subplots(2)\n",
    "#axes[0].plot(seq.input)\n",
    "#axes[1].plot(seq.target)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name', 'building', 'appliance', 'fold']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nilmtk_activations['train']['kettle']['UK-DALE_building_1'][0]._metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source = SyntheticAggregateSource(\n",
    "    activations=nilmtk_activations,\n",
    "    target_appliance=TARGET_APPLIANCE,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    allow_incomplete_target=False,\n",
    "    sample_period=SAMPLE_PERIOD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FOLD = 'train'\n",
    "#FOLD = 'unseen_activations_of_seen_appliances'\n",
    "#FOLD = 'unseen_appliances'\n",
    "seq = source.get_sequence(enable_all_appliances=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#all(seq.all_appliances.sum(axis=1) == seq.input[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fig, axes = plt.subplots(2, sharex=True)\n",
    "#seq.all_appliances.plot(ax=axes[0])\n",
    "#axes[1].plot(seq.input)\n",
    "#fig.suptitle(FOLD)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = source.get_batch(num_seq_per_batch=1024).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = DataPipeline(\n",
    "    sources=[source, ras, stride_source],\n",
    "    num_seq_per_batch=64,\n",
    "    input_processing=[DivideBy(sample.before_processing.input.flatten().std()), IndependentlyCenter()],\n",
    "    target_processing=[DivideBy(sample.before_processing.target.flatten().std())]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disaggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "nilmtk_disag_source = NILMTKDisagSource(\n",
    "    filename=NILMTK_FILENAME,\n",
    "    target_appliance=TARGET_APPLIANCE,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    buildings=[5],\n",
    "    window_per_building={},\n",
    "    stride=STRIDE,\n",
    "    sample_period=SAMPLE_PERIOD\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "disag_pipeline = deepcopy(pipeline)\n",
    "disag_pipeline.source = nilmtk_disag_source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "disaggregator = Disaggregator(\n",
    "    pipeline=disag_pipeline,\n",
    "    output_path=PATH  # \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disagregator ideas:\n",
    "\n",
    "* make a copy of pipeline but swap source for a NILMTKDisagSource\n",
    "* NILMTKDisagSource loads all data into memory (?) and iterates over chunks of it (get seq_length from pipeline.source.seq_length)\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lasagne.layers import InputLayer, RecurrentLayer, DenseLayer, ReshapeLayer\n",
    "\n",
    "def get_net_0(input_shape, target_shape=None):\n",
    "    NUM_UNITS = {\n",
    "        'dense_layer_0': 100,\n",
    "        'dense_layer_1':  50,\n",
    "        'dense_layer_2': 100\n",
    "    }\n",
    "\n",
    "    if target_shape is None:\n",
    "        target_shape = input_shape\n",
    "    \n",
    "    # Define layers\n",
    "    input_layer = InputLayer(\n",
    "        shape=input_shape\n",
    "    )\n",
    "    \n",
    "    # Dense layers\n",
    "    dense_layer_0 = DenseLayer(\n",
    "        input_layer, \n",
    "        num_units=NUM_UNITS['dense_layer_0']\n",
    "    )\n",
    "    dense_layer_1 = DenseLayer(\n",
    "        dense_layer_0, \n",
    "        num_units=NUM_UNITS['dense_layer_1']\n",
    "    )\n",
    "    dense_layer_2 = DenseLayer(\n",
    "        dense_layer_1, \n",
    "        num_units=NUM_UNITS['dense_layer_2']\n",
    "    )\n",
    "    \n",
    "    # Output\n",
    "    final_dense_layer = DenseLayer(\n",
    "        dense_layer_2,\n",
    "        num_units=target_shape[1] * target_shape[2],\n",
    "        nonlinearity=None\n",
    "    )\n",
    "    output_layer = ReshapeLayer(\n",
    "        final_dense_layer,\n",
    "        shape=target_shape\n",
    "    )\n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from neuralnilm.net import Net\n",
    "\n",
    "batch = pipeline.get_batch()\n",
    "output_layer = get_net_0(\n",
    "    batch.after_processing.input.shape, \n",
    "    batch.after_processing.target.shape\n",
    ")\n",
    "net = Net(output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database already has an experiment with _id == 3. Should the old experiment be deleted (both from the database and from disk)? Or quit? [Q/d] d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Deleting documents for old experiment.\n",
      "INFO:neuralnilm.trainer:Directory exists = '/home/dk3810/temp/neural_nilm/output/3'\n",
      "INFO:neuralnilm.trainer:  Deleting directory.\n"
     ]
    }
   ],
   "source": [
    "from neuralnilm.trainer import Trainer\n",
    "from neuralnilm.metrics import Metrics\n",
    "\n",
    "trainer = Trainer(\n",
    "    net=net,\n",
    "    data_pipeline=pipeline,\n",
    "    experiment_id=[\"3\"],\n",
    "    metrics=Metrics(state_boundaries=[4]),\n",
    "    requested_learning_rates={0: 1E-2},\n",
    "    repeat_callbacks=[\n",
    "        (1000, Trainer.save_params),\n",
    "        (1000, Trainer.plot_estimates),\n",
    "        ( 500, Trainer.validate)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '3',\n",
       " 'data': {'activations': {'nilmtk_activations': {'appliances': ['kettle',\n",
       "     'microwave',\n",
       "     'washing machine'],\n",
       "    'filename': '/data/mine/vadeec/merged/ukdale.h5',\n",
       "    'sample_period': 6,\n",
       "    'windows': {'train': {'1': ('2014-01-01', '2014-02-01')},\n",
       "     'unseen_activations_of_seen_appliances': {'1': ('2014-02-02',\n",
       "       '2014-02-08')},\n",
       "     'unseen_appliances': {'2': ('2013-06-01', '2013-06-07')}}}},\n",
       "  'pipeline': {'input_processing': [{'divisor': 630.8582153320312,\n",
       "     'name': 'DivideBy'},\n",
       "    {'name': 'IndependentlyCenter'}],\n",
       "   'num_seq_per_batch': 64,\n",
       "   'rng_seed': None,\n",
       "   'source_probabilities': [0.3333333333333333,\n",
       "    0.3333333333333333,\n",
       "    0.3333333333333333],\n",
       "   'sources': {'0': {'allow_incomplete_distractors': True,\n",
       "     'allow_incomplete_target': False,\n",
       "     'distractor_inclusion_prob': 0.25,\n",
       "     'include_incomplete_target_in_output': True,\n",
       "     'name': 'SyntheticAggregateSource',\n",
       "     'num_batches_for_validation': 16,\n",
       "     'rng_seed': None,\n",
       "     'sample_period': 6,\n",
       "     'seq_length': 256,\n",
       "     'target_appliance': 'kettle',\n",
       "     'target_inclusion_prob': 0.5,\n",
       "     'uniform_prob_of_selecting_each_building': True},\n",
       "    '1': {'allow_incomplete_target': True,\n",
       "     'allow_multiple_target_activations_in_aggregate': False,\n",
       "     'filename': '/data/mine/vadeec/merged/ukdale.h5',\n",
       "     'include_incomplete_target_in_output': True,\n",
       "     'include_multiple_targets_in_output': False,\n",
       "     'name': 'RealAggregateSource',\n",
       "     'num_batches_for_validation': 16,\n",
       "     'rng_seed': None,\n",
       "     'sample_period': 6,\n",
       "     'seq_length': 256,\n",
       "     'target_appliance': 'kettle',\n",
       "     'target_inclusion_prob': 0.5,\n",
       "     'uniform_prob_of_selecting_each_building': True,\n",
       "     'windows': {'train': {'1': ('2014-01-01', '2014-02-01')},\n",
       "      'unseen_activations_of_seen_appliances': {'1': ('2014-02-02',\n",
       "        '2014-02-08')},\n",
       "      'unseen_appliances': {'2': ('2013-06-01', '2013-06-07')}}},\n",
       "    '2': {'filename': '/data/mine/vadeec/merged/ukdale.h5',\n",
       "     'name': 'StrideSource',\n",
       "     'num_batches_for_validation': None,\n",
       "     'rng_seed': None,\n",
       "     'sample_period': 6,\n",
       "     'seq_length': 256,\n",
       "     'stride': 256,\n",
       "     'target_appliance': 'kettle',\n",
       "     'windows': {'train': {'1': ('2014-01-01', '2014-02-01')},\n",
       "      'unseen_activations_of_seen_appliances': {'1': ('2014-02-02',\n",
       "        '2014-02-08')},\n",
       "      'unseen_appliances': {'2': ('2013-06-01', '2013-06-07')}}}},\n",
       "   'target_processing': [{'divisor': 442.0741271972656, 'name': 'DivideBy'}]}},\n",
       " 'trainer': {'loss_aggregation_mode': 'mean',\n",
       "  'loss_func_name': 'squared_error',\n",
       "  'metrics': {'clip_to_zero': False,\n",
       "   'name': 'Metrics',\n",
       "   'state_boundaries': [4]},\n",
       "  'min_train_cost': inf,\n",
       "  'output_path': '/home/dk3810/temp/neural_nilm/output/3',\n",
       "  'requested_learning_rates': {'0': 0.01},\n",
       "  'updates_func_kwards': {},\n",
       "  'updates_func_name': 'nesterov_momentum'}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = trainer.report()\n",
    "report['data']['activations'] = LOADER_CONFIG\n",
    "from neuralnilm.utils import sanitise_dict_for_mongo\n",
    "sanitise_dict_for_mongo(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Starting training for 50000 iterations.\n",
      "INFO:neuralnilm.trainer:Iteration 0: Change learning rate to 1.0E-02\n",
      "INFO:neuralnilm.trainer:Compiling train cost function...\n",
      "INFO:neuralnilm.trainer:Done compiling cost function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Update # |  Train cost  | Secs per update | Source ID\n",
      "------------|--------------|-----------------|-----------\n",
      "          0 | \u001b[94m  1.429827\u001b[0m  |    1.248209     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 0: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 0: Plotting estimates.\n",
      "INFO:neuralnilm.net:Compiling deterministic output function...\n",
      "INFO:neuralnilm.net:Done compiling deterministic output function.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "          1 | \u001b[94m  0.962788\u001b[0m  |    0.167474     |   1\n",
      "          2 |   1.147048  |    0.011550     |   0\n",
      "          3 |   1.226706  |    0.047219     |   0\n",
      "          4 | \u001b[94m  0.161934\u001b[0m  |    0.021605     |   2\n",
      "          5 |   0.815449  |    0.142963     |   1\n",
      "          6 |   1.271263  |    0.009346     |   0\n",
      "          7 |   0.867317  |    0.138651     |   1\n",
      "          8 |   1.111317  |    0.015524     |   0\n",
      "          9 |   0.944497  |    0.095673     |   1\n",
      "         10 |   0.184636  |    0.016405     |   2\n",
      "         11 |   0.248021  |    0.040122     |   2\n",
      "         12 |   1.035424  |    0.019694     |   0\n",
      "         13 |   0.223985  |    0.029904     |   2\n",
      "         14 |   0.814798  |    0.137157     |   1\n",
      "         15 | \u001b[94m  0.112299\u001b[0m  |    0.007988     |   2\n",
      "         16 |   1.006038  |    0.137333     |   1\n",
      "         17 |   0.804864  |    0.007316     |   0\n",
      "         18 |   1.058033  |    0.027261     |   0\n",
      "         19 |   1.091661  |    0.031806     |   0\n",
      "         20 |   0.235815  |    0.013456     |   2\n",
      "         21 |   1.058510  |    0.150248     |   1\n",
      "         22 |   1.027962  |    0.002994     |   0\n",
      "         23 |   1.039522  |    0.015590     |   0\n",
      "         24 |   1.008492  |    0.147679     |   1\n",
      "         25 |   1.036836  |    0.082819     |   1\n",
      "         26 |   0.979780  |    0.005825     |   0\n",
      "         27 |   1.076582  |    0.043843     |   0\n",
      "         28 |   1.095682  |    0.006999     |   0\n",
      "         29 |   1.109145  |    0.053940     |   0\n",
      "         30 |   0.935754  |    0.081571     |   1\n",
      "         31 |   0.993197  |    0.014215     |   0\n",
      "         32 |   0.176945  |    0.038735     |   2\n",
      "         33 |   0.912572  |    0.027507     |   0\n",
      "         34 |   0.925130  |    0.147434     |   1\n",
      "         35 |   0.885318  |    0.006192     |   0\n",
      "         36 |   0.267314  |    0.008287     |   2\n",
      "         37 |   0.859858  |    0.056210     |   0\n",
      "         38 |   1.061343  |    0.091062     |   1\n",
      "         39 |   0.871710  |    0.137615     |   1\n",
      "         40 |   0.230957  |    0.003187     |   2\n",
      "         41 |   1.259801  |    0.007117     |   0\n",
      "         42 | \u001b[94m  0.053918\u001b[0m  |    0.056266     |   2\n",
      "         43 |   0.925694  |    0.137843     |   1\n",
      "         44 | \u001b[94m  0.000060\u001b[0m  |    0.012065     |   2\n",
      "         45 |   0.048871  |    0.046527     |   2\n",
      "         46 |   0.901536  |    0.136136     |   1\n",
      "         47 |   0.844080  |    0.085606     |   1\n",
      "         48 |   0.902535  |    0.091415     |   1\n",
      "         49 |   0.391050  |    0.013430     |   2\n",
      "         50 |   1.112541  |    0.047118     |   0\n",
      "         51 |   0.201990  |    0.021170     |   2\n",
      "         52 |   0.202489  |    0.034640     |   2\n",
      "         53 |   0.804884  |    0.092623     |   1\n",
      "         54 |   0.712122  |    0.014509     |   0\n",
      "         55 |   1.084159  |    0.145118     |   1\n",
      "         56 |   1.166926  |    0.004670     |   0\n",
      "         57 |   1.240011  |    0.020201     |   0\n",
      "         58 |   1.124926  |    0.127681     |   1\n",
      "         59 |   1.169264  |    0.014865     |   0\n",
      "         60 |   1.022688  |    0.045157     |   0\n",
      "         61 |   0.985460  |    0.013092     |   0\n",
      "         62 |   1.047758  |    0.052705     |   0\n",
      "         63 |   0.146186  |    0.016542     |   2\n",
      "         64 |   0.832293  |    0.142276     |   1\n",
      "         65 |   0.044931  |    0.002923     |   2\n",
      "         66 |   0.912307  |    0.017707     |   0\n",
      "         67 |   1.184722  |    0.139764     |   1\n",
      "         68 |   0.085770  |    0.002889     |   2\n",
      "         69 |   1.051438  |    0.010778     |   0\n",
      "         70 |   0.835688  |    0.132895     |   1\n",
      "         71 |   0.953798  |    0.009984     |   0\n",
      "         72 |   0.132358  |    0.043800     |   2\n",
      "         73 |   0.000097  |    0.017174     |   2\n",
      "         74 |   1.082291  |    0.144680     |   1\n",
      "         75 |   0.000088  |    0.009156     |   2\n",
      "         76 |   1.071500  |    0.022892     |   0\n",
      "         77 |   0.792182  |    0.130121     |   1\n",
      "         78 |   0.000090  |    0.008072     |   2\n",
      "         79 |   0.000097  |    0.017790     |   2\n",
      "         80 |   0.000108  |    0.036903     |   2\n",
      "         81 |   0.926986  |    0.013056     |   0\n",
      "         82 |   0.000104  |    0.047880     |   2\n",
      "         83 |   1.189136  |    0.015476     |   0\n",
      "         84 |   0.957636  |    0.142973     |   1\n",
      "         85 |   0.266582  |    0.011640     |   2\n",
      "         86 |   0.742972  |    0.098050     |   1\n",
      "         87 |   0.194705  |    0.011632     |   2\n",
      "         88 |   0.997802  |    0.155853     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "INFO:neuralnilm.trainer:Iteration 89: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         89 |   0.999462  |    0.013891     |   0\n",
      "         90 |   1.102320  |    0.065712     |   1\n",
      "         91 |   1.156187  |    0.104042     |   1\n",
      "         92 |   1.096733  |    0.049679     |   1\n",
      "         93 |   0.931191  |    0.131096     |   1\n",
      "         94 |   0.906818  |    0.007515     |   0\n",
      "         95 |   0.145224  |    0.012172     |   2\n",
      "         96 |   1.121036  |    0.045255     |   0\n",
      "         97 |   1.285840  |    0.016921     |   0\n",
      "         98 |   0.954128  |    0.039633     |   0\n",
      "         99 |   1.003412  |    0.024831     |   0\n",
      "        100 |   0.901691  |    0.063015     |   0\n",
      "        101 |   0.926366  |    0.094003     |   1\n",
      "        102 |   0.830372  |    0.094678     |   1\n",
      "        103 |   0.164601  |    0.007315     |   2\n",
      "        104 |   0.817331  |    0.045249     |   0\n",
      "        105 |   0.950307  |    0.017717     |   0\n",
      "        106 |   0.232837  |    0.045304     |   2\n",
      "        107 |   0.915247  |    0.012896     |   0\n",
      "        108 |   0.208492  |    0.045814     |   2\n",
      "        109 |   0.101993  |    0.005621     |   2\n",
      "        110 |   0.999460  |    0.046381     |   0\n",
      "        111 |   0.964297  |    0.035500     |   0\n",
      "        112 |   0.225379  |    0.017165     |   2\n",
      "        113 |   0.917832  |    0.030523     |   0\n",
      "        114 |   0.170294  |    0.029381     |   2\n",
      "        115 |   0.771742  |    0.135211     |   1\n",
      "        116 |   0.257329  |    0.017761     |   2\n",
      "        117 |   0.911397  |    0.085035     |   1\n",
      "        118 |   1.015634  |    0.012763     |   0\n",
      "        119 |   0.903218  |    0.152040     |   1\n",
      "        120 |   1.005582  |    0.047956     |   1\n",
      "        121 |   0.222610  |    0.019426     |   2\n",
      "        122 |   1.033800  |    0.136733     |   1\n",
      "        123 |   0.962232  |    0.009422     |   0\n",
      "        124 |   0.980010  |    0.014517     |   0\n",
      "        125 |   0.052868  |    0.029890     |   2\n",
      "        126 |   0.000200  |    0.013177     |   2\n",
      "        127 |   0.883870  |    0.153685     |   1\n",
      "        128 |   0.822380  |    0.049275     |   1\n",
      "        129 |   0.711319  |    0.135322     |   1\n",
      "        130 |   0.045741  |    0.007445     |   2\n",
      "        131 |   0.995855  |    0.010781     |   0\n",
      "        132 |   1.008271  |    0.053425     |   0\n",
      "        133 |   1.029359  |    0.092648     |   1\n",
      "        134 |   1.034962  |    0.012741     |   0\n",
      "        135 |   0.684980  |    0.138721     |   1\n",
      "        136 |   0.750504  |    0.110844     |   1\n",
      "        137 |   1.151351  |    0.103422     |   1\n",
      "        138 |   1.183586  |    0.094163     |   1\n",
      "        139 |   0.822260  |    0.012338     |   0\n",
      "        140 |   0.378887  |    0.043704     |   2\n",
      "        141 |   0.766244  |    0.144808     |   1\n",
      "        142 |   1.169574  |    0.011888     |   0\n",
      "        143 |   0.949662  |    0.089795     |   1\n",
      "        144 |   0.763437  |    0.097988     |   1\n",
      "        145 |   1.024548  |    0.010772     |   0\n",
      "        146 |   0.990016  |    0.049133     |   0\n",
      "        147 |   1.050177  |    0.081455     |   1\n",
      "        148 |   0.998733  |    0.020658     |   0\n",
      "        149 |   0.194905  |    0.031621     |   2\n",
      "        150 |   0.193038  |    0.018069     |   2\n",
      "        151 |   0.516012  |    0.028474     |   0\n",
      "        152 |   0.141816  |    0.028878     |   2\n",
      "        153 |   1.216344  |    0.027011     |   0\n",
      "        154 |   0.841735  |    0.144352     |   1\n",
      "        155 |   1.056058  |    0.036458     |   1\n",
      "        156 |   0.804171  |    0.024836     |   0\n",
      "        157 |   0.959331  |    0.034554     |   0\n",
      "        158 |   0.823711  |    0.147533     |   1\n",
      "        159 |   0.872199  |    0.011651     |   0\n",
      "        160 |   0.894458  |    0.089875     |   1\n",
      "        161 |   0.928247  |    0.135201     |   1\n",
      "        162 |   1.040511  |    0.051772     |   1\n",
      "        163 |   1.074831  |    0.032832     |   0\n",
      "        164 |   0.905699  |    0.165979     |   1\n",
      "        165 |   0.687536  |    0.087161     |   1\n",
      "        166 |   0.044367  |    0.010429     |   2\n",
      "        167 |   0.849367  |    0.128475     |   1\n",
      "        168 |   1.055556  |    0.009142     |   0\n",
      "        169 |   0.085067  |    0.062020     |   2\n",
      "        170 |   0.827285  |    0.042233     |   1\n",
      "        171 |   0.989834  |    0.038414     |   0\n",
      "        172 |   1.091929  |    0.106610     |   1\n",
      "        173 |   1.070581  |    0.049987     |   1\n",
      "        174 |   1.039801  |    0.166226     |   1\n",
      "        175 |   1.005879  |    0.033935     |   1\n",
      "        176 |   0.892527  |    0.048253     |   0\n",
      "        177 |   0.129477  |    0.016277     |   2\n",
      "        178 |   1.017115  |    0.141627     |   1\n",
      "        179 |   0.736849  |    0.083757     |   1\n",
      "        180 |   0.658458  |    0.011175     |   0\n",
      "        181 |   0.813844  |    0.016924     |   0\n",
      "        182 |   0.926877  |    0.139468     |   1\n",
      "        183 |   0.913090  |    0.088390     |   1\n",
      "        184 |   0.000490  |    0.012544     |   2\n",
      "        185 |   1.044735  |    0.106890     |   1\n",
      "        186 |   0.928863  |    0.093864     |   1\n",
      "        187 |   0.986660  |    0.008899     |   0\n",
      "        188 |   0.914247  |    0.143256     |   1\n",
      "        189 |   0.861240  |    0.046741     |   1\n",
      "        190 |   0.744530  |    0.141253     |   1\n",
      "        191 |   0.998269  |    0.083493     |   1\n",
      "        192 |   0.981190  |    0.003049     |   0\n",
      "        193 |   1.076075  |    0.041028     |   0\n",
      "        194 |   0.809997  |    0.029310     |   0\n",
      "        195 |   1.060373  |    0.029839     |   0\n",
      "        196 |   1.044461  |    0.137709     |   1\n",
      "        197 |   0.000562  |    0.003502     |   2\n",
      "        198 |   0.000536  |    0.007629     |   2\n",
      "        199 |   1.000134  |    0.066512     |   0\n",
      "        200 |   0.867930  |    0.086116     |   1\n",
      "        201 |   0.776010  |    0.005882     |   0\n",
      "        202 |   0.742562  |    0.031983     |   0\n",
      "        203 |   0.000597  |    0.027469     |   2\n",
      "        204 |   0.895871  |    0.023418     |   0\n",
      "        205 |   0.930849  |    0.138612     |   1\n",
      "        206 |   1.061859  |    0.055254     |   1\n",
      "        207 |   0.932875  |    0.019506     |   0\n",
      "        208 |   0.000657  |    0.034359     |   2\n",
      "        209 |   0.908083  |    0.153247     |   1\n",
      "        210 |   0.800512  |    0.049909     |   1\n",
      "        211 |   0.000668  |    0.013206     |   2\n",
      "        212 |   0.252340  |    0.038528     |   2\n",
      "        213 |   0.194120  |    0.012519     |   2\n",
      "        214 |   0.894532  |    0.055184     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 215: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        215 |   0.598639  |    0.085955     |   1\n",
      "        216 |   0.145711  |    0.011624     |   2\n",
      "        217 |   0.932057  |    0.048816     |   0\n",
      "        218 |   0.160359  |    0.021385     |   2\n",
      "        219 |   1.182996  |    0.024532     |   0\n",
      "        220 |   0.225690  |    0.047559     |   2\n",
      "        221 |   0.204425  |    0.010636     |   2\n",
      "        222 |   0.099687  |    0.049134     |   2\n",
      "        223 |   1.008533  |    0.144754     |   1\n",
      "        224 |   1.069515  |    0.011962     |   0\n",
      "        225 |   0.217647  |    0.006320     |   2\n",
      "        226 |   0.974194  |    0.081057     |   1\n",
      "        227 |   0.648221  |    0.015534     |   0\n",
      "        228 |   0.935983  |    0.150973     |   1\n",
      "        229 |   1.037219  |    0.003257     |   0\n",
      "        230 |   0.167023  |    0.009001     |   2\n",
      "        231 |   0.244076  |    0.062016     |   2\n",
      "        232 |   0.754606  |    0.086659     |   1\n",
      "        233 |   0.215219  |    0.008969     |   2\n",
      "        234 |   1.008347  |    0.135850     |   1\n",
      "        235 |   0.842363  |    0.082247     |   1\n",
      "        236 |   0.864393  |    0.022748     |   0\n",
      "        237 |   1.041443  |    0.139356     |   1\n",
      "        238 |   1.088103  |    0.004853     |   0\n",
      "        239 |   0.055422  |    0.008348     |   2\n",
      "        240 |   0.000746  |    0.035031     |   2\n",
      "        241 |   0.890188  |    0.154625     |   1\n",
      "        242 |   0.809514  |    0.023174     |   1\n",
      "        243 |   1.096701  |    0.090012     |   1\n",
      "        244 |   0.616145  |    0.045831     |   0\n",
      "        245 |   0.705644  |    0.013666     |   0\n",
      "        246 |   0.895797  |    0.130989     |   1\n",
      "        247 |   0.039349  |    0.005191     |   2\n",
      "        248 |   0.730507  |    0.027753     |   0\n",
      "        249 |   0.365541  |    0.048238     |   2\n",
      "        250 |   0.924174  |    0.089534     |   1\n",
      "        251 |   0.186151  |    0.043712     |   2\n",
      "        252 |   0.725105  |    0.032338     |   0\n",
      "        253 |   0.185000  |    0.022010     |   2\n",
      "        254 |   0.601412  |    0.140507     |   1\n",
      "        255 |   1.106655  |    0.017687     |   0\n",
      "        256 |   0.808051  |    0.152459     |   1\n",
      "        257 |   0.949770  |    0.005524     |   0\n",
      "        258 |   0.138943  |    0.009910     |   2\n",
      "        259 |   1.009846  |    0.048404     |   0\n",
      "        260 |   0.044611  |    0.006146     |   2\n",
      "        261 |   0.767380  |    0.064103     |   0\n",
      "        262 |   0.892028  |    0.050321     |   1\n",
      "        263 |   0.912152  |    0.107706     |   1\n",
      "        264 |   0.087397  |    0.007325     |   2\n",
      "        265 |   0.999062  |    0.052913     |   0\n",
      "        266 |   0.897858  |    0.008843     |   0\n",
      "        267 |   0.127547  |    0.042823     |   2\n",
      "        268 |   0.790653  |    0.120368     |   1\n",
      "        269 |   1.074443  |    0.086473     |   1\n",
      "        270 |   0.645540  |    0.090366     |   1\n",
      "        271 |   0.790772  |    0.089871     |   1\n",
      "        272 |   0.000974  |    0.005966     |   2\n",
      "        273 |   0.793566  |    0.037819     |   0\n",
      "        274 |   0.715253  |    0.081418     |   1\n",
      "        275 |   0.837136  |    0.016926     |   0\n",
      "        276 |   0.913252  |    0.110792     |   1\n",
      "        277 |   1.233578  |    0.031010     |   0\n",
      "        278 |   0.000995  |    0.029907     |   2\n",
      "        279 |   0.727986  |    0.100661     |   1\n",
      "        280 |   0.000941  |    0.012389     |   2\n",
      "        281 |   0.905316  |    0.146951     |   1\n",
      "        282 |   0.780119  |    0.090700     |   1\n",
      "        283 |   0.001008  |    0.009035     |   2\n",
      "        284 |   0.639409  |    0.014250     |   0\n",
      "        285 |   0.717926  |    0.141663     |   1\n",
      "        286 |   0.001070  |    0.005724     |   2\n",
      "        287 |   0.001061  |    0.013171     |   2\n",
      "        288 |   0.891307  |    0.048551     |   0\n",
      "        289 |   0.245447  |    0.010991     |   2\n",
      "        290 |   0.786055  |    0.160778     |   1\n",
      "        291 |   1.107213  |    0.048960     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 293: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        292 |   0.195852  |    0.015531     |   2\n",
      "        293 |   0.979517  |    0.028092     |   0\n",
      "        294 |   0.888583  |    0.028529     |   0\n",
      "        295 |   0.913402  |    0.049356     |   0\n",
      "        296 |   1.023292  |    0.097884     |   1\n",
      "        297 |   0.149058  |    0.007905     |   2\n",
      "        298 |   0.674713  |    0.033858     |   0\n",
      "        299 |   0.158487  |    0.015757     |   2\n",
      "        300 |   0.220315  |    0.040089     |   2\n",
      "        301 |   1.010812  |    0.083322     |   1\n",
      "        302 |   0.785692  |    0.100615     |   1\n",
      "        303 |   0.915322  |    0.084111     |   1\n",
      "        304 |   0.951442  |    0.013774     |   0\n",
      "        305 |   0.870890  |    0.148843     |   1\n",
      "        306 |   0.827480  |    0.007895     |   0\n",
      "        307 |   1.022751  |    0.090482     |   1\n",
      "        308 |   0.203175  |    0.015596     |   2\n",
      "        309 |   1.043349  |    0.081381     |   1\n",
      "        310 |   0.098710  |    0.005686     |   2\n",
      "        311 |   0.211365  |    0.060945     |   2\n",
      "        312 |   0.923628  |    0.077838     |   1\n",
      "        313 |   0.856637  |    0.026542     |   0\n",
      "        314 |   0.595290  |    0.043813     |   0\n",
      "        315 |   1.011067  |    0.017268     |   0\n",
      "        316 |   0.927441  |    0.042973     |   0\n",
      "        317 |   0.756531  |    0.011629     |   0\n",
      "        318 |   0.165196  |    0.036911     |   2\n",
      "        319 |   0.232998  |    0.008904     |   2\n",
      "        320 |   0.210628  |    0.047471     |   2\n",
      "        321 |   0.968761  |    0.082110     |   1\n",
      "        322 |   0.997460  |    0.019181     |   0\n",
      "        323 |   0.989594  |    0.149596     |   1\n",
      "        324 |   0.058858  |    0.024568     |   2\n",
      "        325 |   0.642670  |    0.042959     |   1\n",
      "        326 |   0.793395  |    0.095280     |   1\n",
      "        327 |   0.913839  |    0.011935     |   0\n",
      "        328 |   0.906633  |    0.040608     |   0\n",
      "        329 |   0.863963  |    0.094622     |   1\n",
      "        330 |   0.001201  |    0.010778     |   2\n",
      "        331 |   0.034230  |    0.059223     |   2\n",
      "        332 |   0.355634  |    0.011672     |   2\n",
      "        333 |   0.798722  |    0.135671     |   1\n",
      "        334 |   0.739875  |    0.007694     |   0\n",
      "        335 |   0.975923  |    0.024120     |   0\n",
      "        336 |   0.808862  |    0.030512     |   0\n",
      "        337 |   0.615399  |    0.022492     |   0\n",
      "        338 |   0.821873  |    0.026998     |   0\n",
      "        339 |   0.178893  |    0.034115     |   2\n",
      "        340 |   0.785043  |    0.101542     |   1\n",
      "        341 |   0.871690  |    0.092736     |   1\n",
      "        342 |   0.733736  |    0.136388     |   1\n",
      "        343 |   0.816429  |    0.046288     |   1\n",
      "        344 |   0.176685  |    0.027879     |   2\n",
      "        345 |   0.842562  |    0.025600     |   0\n",
      "        346 |   0.139734  |    0.046287     |   2\n",
      "        347 |   1.079039  |    0.016399     |   0\n",
      "        348 |   0.620332  |    0.028362     |   0\n",
      "        349 |   0.937904  |    0.039526     |   0\n",
      "        350 |   0.045150  |    0.018149     |   2\n",
      "        351 |   0.908155  |    0.030043     |   0\n",
      "        352 |   0.091100  |    0.027519     |   2\n",
      "        353 |   0.126383  |    0.022519     |   2\n",
      "        354 |   0.001370  |    0.045637     |   2\n",
      "        355 |   1.077002  |    0.084591     |   1\n",
      "        356 |   0.001357  |    0.007703     |   2\n",
      "        357 |   1.045653  |    0.092509     |   1\n",
      "        358 |   0.001281  |    0.010112     |   2\n",
      "        359 |   0.001342  |    0.052830     |   2\n",
      "        360 |   0.783652  |    0.089191     |   1\n",
      "        361 |   0.807156  |    0.081396     |   1\n",
      "        362 |   0.001426  |    0.020381     |   2\n",
      "        363 |   0.942638  |    0.155118     |   1\n",
      "        364 |   0.001391  |    0.004786     |   2\n",
      "        365 |   0.878178  |    0.079559     |   1\n",
      "        366 |   0.237454  |    0.009659     |   2\n",
      "        367 |   0.198829  |    0.042088     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 369: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        368 |   0.889282  |    0.031025     |   0\n",
      "        369 |   0.152532  |    0.027116     |   2\n",
      "        370 |   0.827890  |    0.085458     |   1\n",
      "        371 |   0.759434  |    0.019022     |   0\n",
      "        372 |   1.024529  |    0.033018     |   0\n",
      "        373 |   0.762334  |    0.116314     |   1\n",
      "        374 |   0.926618  |    0.080252     |   1\n",
      "        375 |   0.917378  |    0.037907     |   0\n",
      "        376 |   0.951833  |    0.110762     |   1\n",
      "        377 |   0.797319  |    0.081332     |   1\n",
      "        378 |   0.155554  |    0.005732     |   2\n",
      "        379 |   0.214011  |    0.043917     |   2\n",
      "        380 |   0.938340  |    0.014576     |   0\n",
      "        381 |   0.953855  |    0.037879     |   0\n",
      "        382 |   0.889215  |    0.137602     |   1\n",
      "        383 |   0.202375  |    0.006301     |   2\n",
      "        384 |   0.787334  |    0.011936     |   0\n",
      "        385 |   0.097824  |    0.043377     |   2\n",
      "        386 |   0.205411  |    0.008247     |   2\n",
      "        387 |   0.164218  |    0.048335     |   2\n",
      "        388 |   0.221641  |    0.008621     |   2\n",
      "        389 |   0.206721  |    0.049175     |   2\n",
      "        390 |   0.723343  |    0.082214     |   1\n",
      "        391 |   0.849590  |    0.025953     |   0\n",
      "        392 |   0.936467  |    0.046507     |   0\n",
      "        393 |   0.060742  |    0.008729     |   2\n",
      "        394 |   0.001358  |    0.042495     |   2\n",
      "        395 |   0.820670  |    0.035386     |   0\n",
      "        396 |   0.029997  |    0.026669     |   2\n",
      "        397 |   0.346593  |    0.014801     |   2\n",
      "        398 |   0.714427  |    0.027085     |   0\n",
      "        399 |   0.800815  |    0.025491     |   0\n",
      "        400 |   0.786208  |    0.037581     |   0\n",
      "        401 |   0.788822  |    0.083723     |   1\n",
      "        402 |   0.172645  |    0.010042     |   2\n",
      "        403 |   0.851150  |    0.157114     |   1\n",
      "        404 |   0.864365  |    0.012191     |   0\n",
      "        405 |   0.882440  |    0.005223     |   0\n",
      "        406 |   0.786850  |    0.045273     |   0\n",
      "        407 |   0.682036  |    0.082066     |   1\n",
      "        408 |   0.801740  |    0.029396     |   0\n",
      "        409 |   0.789532  |    0.150079     |   1\n",
      "        410 |   0.170923  |    0.008236     |   2\n",
      "        411 |   0.922318  |    0.087745     |   1\n",
      "        412 |   0.624633  |    0.011054     |   0\n",
      "        413 |   0.735724  |    0.083304     |   1\n",
      "        414 |   0.889590  |    0.008260     |   0\n",
      "        415 |   0.553129  |    0.147667     |   1\n",
      "        416 |   0.687992  |    0.085693     |   1\n",
      "        417 |   0.811520  |    0.016864     |   0\n",
      "        418 |   0.851875  |    0.148046     |   1\n",
      "        419 |   0.881678  |    0.011554     |   0\n",
      "        420 |   0.834573  |    0.030477     |   0\n",
      "        421 |   0.590175  |    0.097245     |   1\n",
      "        422 |   0.780668  |    0.013539     |   0\n",
      "        423 |   0.710905  |    0.113789     |   1\n",
      "        424 |   0.138927  |    0.003186     |   2\n",
      "        425 |   0.788844  |    0.020630     |   0\n",
      "        426 |   0.900563  |    0.146855     |   1\n",
      "        427 |   0.778359  |    0.020382     |   0\n",
      "        428 |   0.861580  |    0.007400     |   0\n",
      "        429 |   0.045467  |    0.013147     |   2\n",
      "        430 |   0.096352  |    0.055521     |   2\n",
      "        431 |   0.810994  |    0.109016     |   1\n",
      "        432 |   0.640554  |    0.062889     |   1\n",
      "        433 |   0.650678  |    0.069632     |   1\n",
      "        434 |   0.793036  |    0.104639     |   1\n",
      "        435 |   0.958170  |    0.090071     |   1\n",
      "        436 |   0.124101  |    0.013681     |   2\n",
      "        437 |   0.001609  |    0.048669     |   2\n",
      "        438 |   0.894578  |    0.144191     |   1\n",
      "        439 |   0.635307  |    0.083370     |   1\n",
      "        440 |   0.795763  |    0.005686     |   0\n",
      "        441 |   0.691232  |    0.060701     |   0\n",
      "        442 |   0.835521  |    0.074478     |   1\n",
      "        443 |   0.001608  |    0.007335     |   2\n",
      "        444 |   0.001478  |    0.032092     |   2\n",
      "        445 |   0.001594  |    0.026574     |   2\n",
      "        446 |   0.639817  |    0.137283     |   1\n",
      "        447 |   0.001699  |    0.004479     |   2\n",
      "        448 |   0.731980  |    0.037027     |   0\n",
      "        449 |   0.675374  |    0.143675     |   1\n",
      "        450 |   0.778367  |    0.010867     |   0\n",
      "        451 |   0.891681  |    0.084247     |   1\n",
      "        452 |   0.001647  |    0.006740     |   2\n",
      "        453 |   0.709837  |    0.045541     |   0\n",
      "        454 |   0.225837  |    0.011988     |   2\n",
      "        455 |   0.863886  |    0.047008     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 457: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        456 |   0.203186  |    0.007985     |   2\n",
      "        457 |   0.158845  |    0.032430     |   2\n",
      "        458 |   0.153304  |    0.006357     |   2\n",
      "        459 |   0.205684  |    0.044778     |   2\n",
      "        460 |   0.890741  |    0.026646     |   0\n",
      "        461 |   0.680369  |    0.023411     |   0\n",
      "        462 |   0.869418  |    0.031752     |   0\n",
      "        463 |   0.834219  |    0.083931     |   1\n",
      "        464 |   0.201559  |    0.029972     |   2\n",
      "        465 |   0.847508  |    0.046737     |   0\n",
      "        466 |   0.095791  |    0.012210     |   2\n",
      "        467 |   0.801245  |    0.141957     |   1\n",
      "        468 |   0.860785  |    0.082697     |   1\n",
      "        469 |   0.196992  |    0.009235     |   2\n",
      "        470 |   0.716626  |    0.123454     |   1\n",
      "        471 |   0.161304  |    0.004542     |   2\n",
      "        472 |   0.811758  |    0.041073     |   0\n",
      "        473 |   0.981705  |    0.011176     |   0\n",
      "        474 |   0.207512  |    0.038998     |   2\n",
      "        475 |   0.199385  |    0.013150     |   2\n",
      "        476 |   0.062956  |    0.030842     |   2\n",
      "        477 |   0.689187  |    0.029649     |   0\n",
      "        478 |   0.759214  |    0.104885     |   1\n",
      "        479 |   0.701283  |    0.118300     |   1\n",
      "        480 |   1.034413  |    0.030949     |   1\n",
      "        481 |   0.001453  |    0.029922     |   2\n",
      "        482 |   0.395431  |    0.011271     |   0\n",
      "        483 |   0.724932  |    0.090331     |   0\n",
      "        484 |   0.762554  |    0.046948     |   1\n",
      "        485 |   0.024913  |    0.008868     |   2\n",
      "        486 |   0.332551  |    0.062997     |   2\n",
      "        487 |   0.901877  |    0.054537     |   1\n",
      "        488 |   0.710402  |    0.032973     |   0\n",
      "        489 |   0.799047  |    0.030677     |   0\n",
      "        490 |   0.657961  |    0.024040     |   0\n",
      "        491 |   0.812948  |    0.053635     |   0\n",
      "        492 |   0.161877  |    0.008863     |   2\n",
      "        493 |   0.162901  |    0.035233     |   2\n",
      "        494 |   0.134485  |    0.040952     |   2\n",
      "        495 |   0.890003  |    0.080981     |   1\n",
      "        496 |   0.671670  |    0.013279     |   0\n",
      "        497 |   0.787252  |    0.050010     |   0\n",
      "        498 |   0.044154  |    0.014407     |   2\n",
      "        499 |   0.548488  |    0.137702     |   1\n",
      "        500 |   0.844604  |    0.078153     |   1\n",
      "        501 |   0.157799  |    0.046978     |   2\n",
      "        502 |   0.148651  |    0.021664     |   2\n",
      "        503 |   0.715512  |    0.125132     |   1\n",
      "        504 |   0.828691  |    0.020013     |   0\n",
      "        505 |   0.825886  |    0.106479     |   1\n",
      "        506 |   0.767827  |    0.012979     |   0\n",
      "        507 |   0.876009  |    0.026971     |   0\n",
      "        508 |   0.896814  |    0.054805     |   0\n",
      "        509 |   0.199331  |    0.022412     |   2\n",
      "        510 |   0.445273  |    0.152203     |   1\n",
      "        511 |   0.639386  |    0.003672     |   0\n",
      "        512 |   0.725327  |    0.016422     |   0\n",
      "        513 |   0.199806  |    0.035815     |   2\n",
      "        514 |   0.092662  |    0.016546     |   2\n",
      "        515 |   0.746048  |    0.048609     |   0\n",
      "        516 |   0.191620  |    0.011060     |   2\n",
      "        517 |   0.158921  |    0.042861     |   2\n",
      "        518 |   0.774473  |    0.029411     |   0\n",
      "        519 |   0.872389  |    0.067377     |   0\n",
      "        520 |   0.853408  |    0.082881     |   1\n",
      "        521 |   0.814854  |    0.004962     |   0\n",
      "        522 |   0.609348  |    0.159369     |   1\n",
      "        523 |   0.836719  |    0.012633     |   0\n",
      "        524 |   0.614662  |    0.014319     |   0\n",
      "        525 |   0.768446  |    0.103262     |   1\n",
      "        526 |   0.708200  |    0.054443     |   1\n",
      "        527 |   0.873702  |    0.085481     |   1\n",
      "        528 |   0.645466  |    0.025416     |   0\n",
      "        529 |   0.195788  |    0.031787     |   2\n",
      "        530 |   0.195214  |    0.011681     |   2\n",
      "        531 |   0.062895  |    0.051735     |   2\n",
      "        532 |   0.001457  |    0.007683     |   2\n",
      "        533 |   0.584561  |    0.054598     |   0\n",
      "        534 |   0.651322  |    0.089207     |   1\n",
      "        535 |   0.866269  |    0.112169     |   1\n",
      "        536 |   0.594215  |    0.092578     |   1\n",
      "        537 |   0.863786  |    0.010113     |   0\n",
      "        538 |   0.022246  |    0.046187     |   2\n",
      "        539 |   0.319998  |    0.015946     |   2\n",
      "        540 |   0.652409  |    0.028988     |   0\n",
      "        541 |   0.155768  |    0.015224     |   2\n",
      "        542 |   0.567900  |    0.040937     |   0\n",
      "        543 |   0.159050  |    0.009541     |   2\n",
      "        544 |   0.847332  |    0.042387     |   0\n",
      "        545 |   0.129836  |    0.008556     |   2\n",
      "        546 |   0.042975  |    0.046907     |   2\n",
      "        547 |   0.754071  |    0.017319     |   0\n",
      "        548 |   0.716982  |    0.132230     |   1\n",
      "        549 |   0.669733  |    0.012095     |   0\n",
      "        550 |   0.722428  |    0.080141     |   1\n",
      "        551 |   0.652267  |    0.034324     |   0\n",
      "        552 |   0.099076  |    0.024079     |   2\n",
      "        553 |   0.877946  |    0.034660     |   0\n",
      "        554 |   0.774539  |    0.076676     |   1\n",
      "        555 |   0.751905  |    0.017893     |   0\n",
      "        556 |   0.752296  |    0.026090     |   0\n",
      "        557 |   0.864743  |    0.044069     |   0\n",
      "        558 |   0.968339  |    0.029345     |   0\n",
      "        559 |   0.689216  |    0.023916     |   0\n",
      "        560 |   0.595911  |    0.014841     |   0\n",
      "        561 |   0.876436  |    0.045436     |   0\n",
      "        562 |   0.692798  |    0.009150     |   0\n",
      "        563 |   0.120015  |    0.042494     |   2\n",
      "        564 |   0.617324  |    0.018292     |   0\n",
      "        565 |   0.637213  |    0.048807     |   0\n",
      "        566 |   0.713223  |    0.014946     |   0\n",
      "        567 |   0.780968  |    0.142937     |   1\n",
      "        568 |   0.749628  |    0.039159     |   1\n",
      "        569 |   0.001612  |    0.055529     |   2\n",
      "        570 |   0.665315  |    0.091611     |   1\n",
      "        571 |   0.001660  |    0.011281     |   2\n",
      "        572 |   0.640559  |    0.139754     |   1\n",
      "        573 |   0.650377  |    0.002983     |   0\n",
      "        574 |   0.001517  |    0.009786     |   2\n",
      "        575 |   0.001668  |    0.042701     |   2\n",
      "        576 |   0.617891  |    0.016016     |   0\n",
      "        577 |   0.720819  |    0.035640     |   0\n",
      "        578 |   0.001780  |    0.028106     |   2\n",
      "        579 |   0.636270  |    0.117505     |   1\n",
      "        580 |   0.655979  |    0.158841     |   1\n",
      "        581 |   0.001696  |    0.004836     |   2\n",
      "        582 |   0.691487  |    0.057062     |   1\n",
      "        583 |   0.750095  |    0.152791     |   1\n",
      "        584 |   0.693259  |    0.056557     |   1\n",
      "        585 |   0.547456  |    0.023673     |   0\n",
      "        586 |   0.807246  |    0.043081     |   0\n",
      "        587 |   0.208150  |    0.012968     |   2\n",
      "        588 |   0.211755  |    0.044197     |   2\n",
      "        589 |   0.800977  |    0.012943     |   0\n",
      "        590 |   0.628148  |    0.040892     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 591: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        591 |   0.634411  |    0.009866     |   0\n",
      "        592 |   0.170311  |    0.033551     |   2\n",
      "        593 |   0.679521  |    0.135928     |   1\n",
      "        594 |   0.520848  |    0.079618     |   1\n",
      "        595 |   0.841890  |    0.016443     |   0\n",
      "        596 |   0.829254  |    0.132792     |   1\n",
      "        597 |   0.665255  |    0.008155     |   0\n",
      "        598 |   0.706454  |    0.044421     |   0\n",
      "        599 |   0.148128  |    0.018477     |   2\n",
      "        600 |   0.593591  |    0.024288     |   0\n",
      "        601 |   0.577134  |    0.043726     |   0\n",
      "        602 |   0.749257  |    0.009561     |   0\n",
      "        603 |   0.190449  |    0.044407     |   2\n",
      "        604 |   0.646879  |    0.141465     |   1\n",
      "        605 |   0.745850  |    0.014101     |   0\n",
      "        606 |   0.666592  |    0.072697     |   1\n",
      "        607 |   0.618213  |    0.011789     |   0\n",
      "        608 |   0.496730  |    0.046090     |   0\n",
      "        609 |   0.787716  |    0.018391     |   0\n",
      "        610 |   0.203908  |    0.031988     |   2\n",
      "        611 |   0.092332  |    0.010232     |   2\n",
      "        612 |   0.533228  |    0.043481     |   0\n",
      "        613 |   0.186062  |    0.010800     |   2\n",
      "        614 |   0.617773  |    0.156977     |   1\n",
      "        615 |   0.641722  |    0.087672     |   1\n",
      "        616 |   0.757181  |    0.080023     |   1\n",
      "        617 |   0.760147  |    0.008395     |   0\n",
      "        618 |   0.650269  |    0.136891     |   1\n",
      "        619 |   0.800465  |    0.098903     |   1\n",
      "        620 |   1.059947  |    0.078469     |   1\n",
      "        621 |   0.155844  |    0.008938     |   2\n",
      "        622 |   0.556330  |    0.061520     |   0\n",
      "        623 |   0.602735  |    0.084119     |   1\n",
      "        624 |   0.178184  |    0.013774     |   2\n",
      "        625 |   0.573265  |    0.157440     |   1\n",
      "        626 |   0.577011  |    0.011691     |   0\n",
      "        627 |   0.589902  |    0.079610     |   1\n",
      "        628 |   0.185052  |    0.015971     |   2\n",
      "        629 |   0.500885  |    0.153728     |   1\n",
      "        630 |   0.698273  |    0.085548     |   1\n",
      "        631 |   0.639930  |    0.136591     |   1\n",
      "        632 |   0.612919  |    0.005621     |   0\n",
      "        633 |   0.746748  |    0.014335     |   0\n",
      "        634 |   0.548973  |    0.166240     |   1\n",
      "        635 |   0.062612  |    0.010123     |   2\n",
      "        636 |   0.542934  |    0.081438     |   1\n",
      "        637 |   0.809939  |    0.079248     |   1\n",
      "        638 |   0.624275  |    0.164691     |   1\n",
      "        639 |   0.612326  |    0.058095     |   1\n",
      "        640 |   0.001506  |    0.006288     |   2\n",
      "        641 |   0.018256  |    0.038586     |   2\n",
      "        642 |   0.306462  |    0.026609     |   2\n",
      "        643 |   0.142019  |    0.020887     |   2\n",
      "        644 |   0.698146  |    0.020219     |   0\n",
      "        645 |   0.718998  |    0.045706     |   0\n",
      "        646 |   0.153495  |    0.011933     |   2\n",
      "        647 |   0.646292  |    0.138557     |   1\n",
      "        648 |   0.123660  |    0.009373     |   2\n",
      "        649 |   0.616538  |    0.123147     |   1\n",
      "        650 |   0.042755  |    0.012424     |   2\n",
      "        651 |   0.110791  |    0.044521     |   2\n",
      "        652 |   0.116919  |    0.018569     |   2\n",
      "        653 |   0.001509  |    0.031650     |   2\n",
      "        654 |   0.639409  |    0.094009     |   1\n",
      "        655 |   0.001561  |    0.014334     |   2\n",
      "        656 |   0.001381  |    0.031110     |   2\n",
      "        657 |   0.638108  |    0.073403     |   0\n",
      "        658 |   0.558583  |    0.081906     |   1\n",
      "        659 |   0.001548  |    0.006428     |   2\n",
      "        660 |   0.720259  |    0.145483     |   1\n",
      "        661 |   0.568185  |    0.003186     |   0\n",
      "        662 |   0.503583  |    0.011901     |   0\n",
      "        663 |   0.626805  |    0.048248     |   0\n",
      "        664 |   0.649511  |    0.135376     |   1\n",
      "        665 |   0.001644  |    0.004327     |   2\n",
      "        666 |   0.479163  |    0.044106     |   0\n",
      "        667 |   0.685114  |    0.016997     |   0\n",
      "        668 |   0.717445  |    0.039956     |   0\n",
      "        669 |   0.736242  |    0.020471     |   0\n",
      "        670 |   0.602771  |    0.034330     |   0\n",
      "        671 |   0.001593  |    0.014043     |   2\n",
      "        672 |   0.192717  |    0.045287     |   2\n",
      "        673 |   0.213705  |    0.012749     |   2\n",
      "        674 |   0.648161  |    0.057622     |   0\n",
      "        675 |   0.674910  |    0.078848     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 677: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        676 |   0.571436  |    0.045838     |   0\n",
      "        677 |   0.573355  |    0.010085     |   0\n",
      "        678 |   0.173385  |    0.016010     |   2\n",
      "        679 |   0.531078  |    0.037420     |   0\n",
      "        680 |   0.669083  |    0.048255     |   0\n",
      "        681 |   0.147075  |    0.016400     |   2\n",
      "        682 |   0.181809  |    0.025414     |   2\n",
      "        683 |   0.652067  |    0.054944     |   0\n",
      "        684 |   0.531964  |    0.083196     |   1\n",
      "        685 |   0.627759  |    0.046890     |   0\n",
      "        686 |   0.729803  |    0.086726     |   1\n",
      "        687 |   0.510140  |    0.009191     |   0\n",
      "        688 |   0.202053  |    0.013046     |   2\n",
      "        689 |   0.088802  |    0.042355     |   2\n",
      "        690 |   0.638160  |    0.023986     |   0\n",
      "        691 |   0.178216  |    0.029589     |   2\n",
      "        692 |   0.152333  |    0.017278     |   2\n",
      "        693 |   0.168657  |    0.031647     |   2\n",
      "        694 |   0.177144  |    0.030362     |   2\n",
      "        695 |   0.060349  |    0.031030     |   2\n",
      "        696 |   0.881623  |    0.103853     |   1\n",
      "        697 |   0.001420  |    0.017223     |   2\n",
      "        698 |   0.512173  |    0.044870     |   0\n",
      "        699 |   0.676119  |    0.127941     |   1\n",
      "        700 |   0.477424  |    0.009148     |   0\n",
      "        701 |   0.016422  |    0.028459     |   2\n",
      "        702 |   0.568652  |    0.032762     |   0\n",
      "        703 |   0.295533  |    0.008911     |   2\n",
      "        704 |   0.444044  |    0.048872     |   0\n",
      "        705 |   0.138199  |    0.016226     |   2\n",
      "        706 |   0.470176  |    0.025989     |   0\n",
      "        707 |   0.579725  |    0.028569     |   0\n",
      "        708 |   0.713069  |    0.038911     |   0\n",
      "        709 |   0.151359  |    0.007414     |   2\n",
      "        710 |   0.118441  |    0.056136     |   2\n",
      "        711 |   0.500919  |    0.006982     |   0\n",
      "        712 |   0.617664  |    0.049355     |   0\n",
      "        713 |   0.612384  |    0.083652     |   1\n",
      "        714 |   0.452914  |    0.149273     |   1\n",
      "        715 |   0.042627  |    0.008395     |   2\n",
      "        716 |   0.726567  |    0.095494     |   1\n",
      "        717 |   0.605052  |    0.084149     |   1\n",
      "        718 |   0.114334  |    0.009733     |   2\n",
      "        719 |   0.720267  |    0.136473     |   1\n",
      "        720 |   0.537097  |    0.131618     |   1\n",
      "        721 |   0.619956  |    0.003018     |   0\n",
      "        722 |   0.114664  |    0.014366     |   2\n",
      "        723 |   0.400537  |    0.138477     |   1\n",
      "        724 |   0.665328  |    0.009793     |   0\n",
      "        725 |   0.001386  |    0.029267     |   2\n",
      "        726 |   0.452454  |    0.029551     |   0\n",
      "        727 |   0.480073  |    0.014475     |   0\n",
      "        728 |   0.001467  |    0.053316     |   2\n",
      "        729 |   0.557708  |    0.086723     |   1\n",
      "        730 |   0.528418  |    0.027541     |   0\n",
      "        731 |   0.001270  |    0.042070     |   2\n",
      "        732 |   0.608705  |    0.141075     |   1\n",
      "        733 |   0.001456  |    0.005231     |   2\n",
      "        734 |   0.665853  |    0.007186     |   0\n",
      "        735 |   0.727599  |    0.058890     |   0\n",
      "        736 |   0.001547  |    0.009159     |   2\n",
      "        737 |   0.519025  |    0.039224     |   0\n",
      "        738 |   0.568865  |    0.025827     |   0\n",
      "        739 |   0.583098  |    0.151224     |   1\n",
      "        740 |   0.001462  |    0.002999     |   2\n",
      "        741 |   0.180859  |    0.015452     |   2\n",
      "        742 |   0.210867  |    0.021414     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 743: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        743 |   0.590916  |    0.027768     |   0\n",
      "        744 |   0.508117  |    0.044551     |   0\n",
      "        745 |   0.178989  |    0.018702     |   2\n",
      "        746 |   0.139898  |    0.029349     |   2\n",
      "        747 |   0.693618  |    0.036390     |   0\n",
      "        748 |   0.751636  |    0.095931     |   1\n",
      "        749 |   0.486729  |    0.021357     |   0\n",
      "        750 |   0.606099  |    0.046368     |   0\n",
      "        751 |   0.176215  |    0.008723     |   2\n",
      "        752 |   0.532907  |    0.048562     |   0\n",
      "        753 |   0.197625  |    0.009082     |   2\n",
      "        754 |   0.513768  |    0.152808     |   1\n",
      "        755 |   0.085616  |    0.006561     |   2\n",
      "        756 |   0.503433  |    0.008437     |   0\n",
      "        757 |   0.581077  |    0.063322     |   0\n",
      "        758 |   0.557059  |    0.090777     |   1\n",
      "        759 |   0.170777  |    0.027536     |   2\n",
      "        760 |   0.147573  |    0.041245     |   2\n",
      "        761 |   0.657476  |    0.128993     |   1\n",
      "        762 |   0.572857  |    0.010269     |   0\n",
      "        763 |   0.473999  |    0.021060     |   0\n",
      "        764 |   0.420995  |    0.026137     |   0\n",
      "        765 |   0.158202  |    0.031734     |   2\n",
      "        766 |   0.636580  |    0.137698     |   1\n",
      "        767 |   0.795018  |    0.052016     |   1\n",
      "        768 |   0.501158  |    0.022433     |   0\n",
      "        769 |   0.167902  |    0.028296     |   2\n",
      "        770 |   0.499740  |    0.156310     |   1\n",
      "        771 |   0.059232  |    0.008878     |   2\n",
      "        772 |   0.594099  |    0.165090     |   1\n",
      "        773 |   0.597095  |    0.025182     |   1\n",
      "        774 |   0.633478  |    0.155383     |   1\n",
      "        775 |   0.661686  |    0.050149     |   1\n",
      "        776 |   0.423123  |    0.029635     |   0\n",
      "        777 |   0.682901  |    0.043337     |   0\n",
      "        778 |   0.656386  |    0.019724     |   0\n",
      "        779 |   0.001261  |    0.042124     |   2\n",
      "        780 |   0.017670  |    0.012032     |   2\n",
      "        781 |   0.572612  |    0.131926     |   1\n",
      "        782 |   0.543326  |    0.022297     |   0\n",
      "        783 |   0.473637  |    0.142900     |   1\n",
      "        784 |   0.576790  |    0.096439     |   1\n",
      "        785 |   0.460217  |    0.099709     |   1\n",
      "        786 |   0.454837  |    0.104658     |   1\n",
      "        787 |   0.287104  |    0.004222     |   2\n",
      "        788 |   0.542118  |    0.144209     |   1\n",
      "        789 |   0.135457  |    0.004846     |   2\n",
      "        790 |   0.641976  |    0.004682     |   0\n",
      "        791 |   0.144792  |    0.059281     |   2\n",
      "        792 |   0.606842  |    0.088373     |   1\n",
      "        793 |   0.585571  |    0.020411     |   0\n",
      "        794 |   0.609531  |    0.143427     |   1\n",
      "        795 |   0.586934  |    0.007070     |   0\n",
      "        796 |   0.631074  |    0.062257     |   1\n",
      "        797 |   0.468262  |    0.017113     |   0\n",
      "        798 |   0.486969  |    0.110927     |   1\n",
      "        799 |   0.604178  |    0.074154     |   1\n",
      "        800 |   0.575995  |    0.095437     |   1\n",
      "        801 |   0.114435  |    0.013664     |   2\n",
      "        802 |   0.420261  |    0.140825     |   1\n",
      "        803 |   0.041077  |    0.009689     |   2\n",
      "        804 |   0.554932  |    0.136549     |   1\n",
      "        805 |   0.584948  |    0.130141     |   1\n",
      "        806 |   0.555928  |    0.003260     |   0\n",
      "        807 |   0.449221  |    0.008378     |   0\n",
      "        808 |   0.121281  |    0.043484     |   2\n",
      "        809 |   0.531713  |    0.016784     |   0\n",
      "        810 |   0.113634  |    0.045619     |   2\n",
      "        811 |   0.526272  |    0.011492     |   0\n",
      "        812 |   0.001319  |    0.033273     |   2\n",
      "        813 |   0.665757  |    0.143635     |   1\n",
      "        814 |   0.524321  |    0.059719     |   1\n",
      "        815 |   0.001430  |    0.021232     |   2\n",
      "        816 |   0.001223  |    0.027577     |   2\n",
      "        817 |   0.591843  |    0.037265     |   0\n",
      "        818 |   0.581388  |    0.138981     |   1\n",
      "        819 |   0.001447  |    0.010129     |   2\n",
      "        820 |   0.623181  |    0.078240     |   1\n",
      "        821 |   0.548372  |    0.033675     |   0\n",
      "        822 |   0.001526  |    0.021674     |   2\n",
      "        823 |   0.516813  |    0.034066     |   0\n",
      "        824 |   0.684376  |    0.031234     |   0\n",
      "        825 |   0.433581  |    0.033586     |   0\n",
      "        826 |   0.659043  |    0.158781     |   1\n",
      "        827 |   0.648872  |    0.005173     |   0\n",
      "        828 |   0.548033  |    0.063472     |   1\n",
      "        829 |   0.456382  |    0.018349     |   0\n",
      "        830 |   0.001456  |    0.043333     |   2\n",
      "        831 |   0.174430  |    0.016147     |   2\n",
      "        832 |   0.525228  |    0.131305     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 834: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        833 |   0.209091  |    0.004724     |   2\n",
      "        834 |   0.183663  |    0.036558     |   2\n",
      "        835 |   0.488890  |    0.096575     |   1\n",
      "        836 |   0.472578  |    0.141548     |   1\n",
      "        837 |   0.579122  |    0.047877     |   1\n",
      "        838 |   0.140514  |    0.019851     |   2\n",
      "        839 |   0.491564  |    0.140531     |   1\n",
      "        840 |   0.566229  |    0.084404     |   1\n",
      "        841 |   0.169016  |    0.006268     |   2\n",
      "        842 |   0.585498  |    0.031085     |   0\n",
      "        843 |   0.622930  |    0.144019     |   1\n",
      "        844 |   0.194577  |    0.004362     |   2\n",
      "        845 |   0.546661  |    0.015867     |   0\n",
      "        846 |   0.462249  |    0.137492     |   1\n",
      "        847 |   0.598589  |    0.007185     |   0\n",
      "        848 |   0.497612  |    0.048373     |   0\n",
      "        849 |   0.446870  |    0.012124     |   0\n",
      "        850 |   0.662455  |    0.128112     |   1\n",
      "        851 |   0.083337  |    0.004782     |   2\n",
      "        852 |   0.163100  |    0.043498     |   2\n",
      "        853 |   0.448995  |    0.017712     |   0\n",
      "        854 |   0.144658  |    0.066270     |   2\n",
      "        855 |   0.557201  |    0.063123     |   1\n",
      "        856 |   0.147706  |    0.016911     |   2\n",
      "        857 |   0.158817  |    0.041770     |   2\n",
      "        858 |   0.493406  |    0.014797     |   0\n",
      "        859 |   0.496884  |    0.156975     |   1\n",
      "        860 |   0.056274  |    0.006229     |   2\n",
      "        861 |   0.001206  |    0.006354     |   2\n",
      "        862 |   0.017308  |    0.050456     |   2\n",
      "        863 |   0.278560  |    0.013397     |   2\n",
      "        864 |   0.128971  |    0.039021     |   2\n",
      "        865 |   0.499709  |    0.017922     |   0\n",
      "        866 |   0.580743  |    0.151435     |   1\n",
      "        867 |   0.532157  |    0.076835     |   1\n",
      "        868 |   0.471920  |    0.022777     |   0\n",
      "        869 |   0.410162  |    0.043965     |   0\n",
      "        870 |   0.601289  |    0.143806     |   1\n",
      "        871 |   0.527087  |    0.054718     |   1\n",
      "        872 |   0.141332  |    0.006220     |   2\n",
      "        873 |   0.490712  |    0.042244     |   0\n",
      "        874 |   0.529283  |    0.026064     |   0\n",
      "        875 |   0.110373  |    0.035997     |   2\n",
      "        876 |   0.041882  |    0.021638     |   2\n",
      "        877 |   0.499048  |    0.027943     |   0\n",
      "        878 |   0.584550  |    0.093100     |   1\n",
      "        879 |   0.117948  |    0.030480     |   2\n",
      "        880 |   0.497023  |    0.111357     |   1\n",
      "        881 |   0.503379  |    0.145716     |   1\n",
      "        882 |   0.625231  |    0.050248     |   1\n",
      "        883 |   0.593394  |    0.106911     |   1\n",
      "        884 |   0.465133  |    0.142382     |   1\n",
      "        885 |   0.583576  |    0.086430     |   1\n",
      "        886 |   0.600813  |    0.062671     |   1\n",
      "        887 |   0.436879  |    0.094934     |   1\n",
      "        888 |   0.110027  |    0.003468     |   2\n",
      "        889 |   0.001096  |    0.024802     |   2\n",
      "        890 |   0.536482  |    0.028685     |   0\n",
      "        891 |   0.001212  |    0.025684     |   2\n",
      "        892 |   0.590397  |    0.167718     |   1\n",
      "        893 |   0.525256  |    0.020115     |   0\n",
      "        894 |   0.680091  |    0.054290     |   1\n",
      "        895 |   0.550426  |    0.146931     |   1\n",
      "        896 |   0.593432  |    0.048418     |   1\n",
      "        897 |   0.507899  |    0.024000     |   0\n",
      "        898 |   0.501348  |    0.048012     |   0\n",
      "        899 |   0.513180  |    0.015721     |   0\n",
      "        900 |   0.596101  |    0.047056     |   0\n",
      "        901 |   0.001063  |    0.011575     |   2\n",
      "        902 |   0.001280  |    0.033651     |   2\n",
      "        903 |   0.472233  |    0.025865     |   0\n",
      "        904 |   0.610767  |    0.140723     |   1\n",
      "        905 |   0.400425  |    0.083645     |   1\n",
      "        906 |   0.452567  |    0.007462     |   0\n",
      "        907 |   0.625835  |    0.042723     |   0\n",
      "        908 |   0.513682  |    0.104285     |   1\n",
      "        909 |   0.430373  |    0.091733     |   1\n",
      "        910 |   0.558446  |    0.068590     |   1\n",
      "        911 |   0.525734  |    0.139978     |   1\n",
      "        912 |   0.452670  |    0.089511     |   1\n",
      "        913 |   0.508049  |    0.006916     |   0\n",
      "        914 |   0.445703  |    0.033635     |   0\n",
      "        915 |   0.497251  |    0.095092     |   1\n",
      "        916 |   0.516027  |    0.034954     |   0\n",
      "        917 |   0.001478  |    0.042749     |   2\n",
      "        918 |   0.512439  |    0.083684     |   1\n",
      "        919 |   0.494400  |    0.030680     |   0\n",
      "        920 |   0.514218  |    0.136413     |   1\n",
      "        921 |   0.493906  |    0.031036     |   1\n",
      "        922 |   0.483509  |    0.133205     |   1\n",
      "        923 |   0.399108  |    0.010947     |   0\n",
      "        924 |   0.659699  |    0.049251     |   1\n",
      "        925 |   0.428998  |    0.027679     |   0\n",
      "        926 |   0.473422  |    0.041712     |   0\n",
      "        927 |   0.433845  |    0.017563     |   0\n",
      "        928 |   0.511717  |    0.141407     |   1\n",
      "        929 |   0.485776  |    0.026094     |   0\n",
      "        930 |   0.564971  |    0.148559     |   1\n",
      "        931 |   0.001394  |    0.005082     |   2\n",
      "        932 |   0.165161  |    0.013360     |   2\n",
      "        933 |   0.494536  |    0.038429     |   0\n",
      "        934 |   0.207260  |    0.011050     |   2\n",
      "        935 |   0.462321  |    0.028911     |   0\n",
      "        936 |   0.363389  |    0.048480     |   0\n",
      "        937 |   0.532522  |    0.087176     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 938: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        938 |   0.553087  |    0.013905     |   0\n",
      "        939 |   0.566828  |    0.082060     |   1\n",
      "        940 |   0.182837  |    0.006091     |   2\n",
      "        941 |   0.418250  |    0.049757     |   0\n",
      "        942 |   0.148120  |    0.014636     |   2\n",
      "        943 |   0.165411  |    0.022188     |   2\n",
      "        944 |   0.485528  |    0.049512     |   0\n",
      "        945 |   0.453499  |    0.009260     |   0\n",
      "        946 |   0.388398  |    0.046636     |   0\n",
      "        947 |   0.424437  |    0.013847     |   0\n",
      "        948 |   0.446796  |    0.043950     |   0\n",
      "        949 |   0.476916  |    0.017516     |   0\n",
      "        950 |   0.414997  |    0.048838     |   0\n",
      "        951 |   0.191835  |    0.008859     |   2\n",
      "        952 |   0.520592  |    0.145162     |   1\n",
      "        953 |   0.523609  |    0.105301     |   1\n",
      "        954 |   0.379775  |    0.086278     |   1\n",
      "        955 |   0.084520  |    0.011042     |   2\n",
      "        956 |   0.460240  |    0.133783     |   1\n",
      "        957 |   0.158601  |    0.008537     |   2\n",
      "        958 |   0.574745  |    0.142212     |   1\n",
      "        959 |   0.474224  |    0.097238     |   1\n",
      "        960 |   0.534894  |    0.006442     |   0\n",
      "        961 |   0.143854  |    0.036602     |   2\n",
      "        962 |   0.141151  |    0.017843     |   2\n",
      "        963 |   0.146724  |    0.045491     |   2\n",
      "        964 |   0.517953  |    0.086636     |   1\n",
      "        965 |   0.500167  |    0.139529     |   1\n",
      "        966 |   0.437457  |    0.011840     |   0\n",
      "        967 |   0.593522  |    0.082736     |   1\n",
      "        968 |   0.053589  |    0.005065     |   2\n",
      "        969 |   0.001114  |    0.018273     |   2\n",
      "        970 |   0.465050  |    0.118153     |   1\n",
      "        971 |   0.628099  |    0.052577     |   1\n",
      "        972 |   0.016174  |    0.024733     |   2\n",
      "        973 |   0.606076  |    0.121419     |   1\n",
      "        974 |   0.270120  |    0.009574     |   2\n",
      "        975 |   0.362502  |    0.048557     |   0\n",
      "        976 |   0.123350  |    0.017741     |   2\n",
      "        977 |   0.483213  |    0.042238     |   0\n",
      "        978 |   0.150839  |    0.013200     |   2\n",
      "        979 |   0.434233  |    0.048200     |   0\n",
      "        980 |   0.649578  |    0.087562     |   1\n",
      "        981 |   0.109570  |    0.015451     |   2\n",
      "        982 |   0.467590  |    0.148083     |   1\n",
      "        983 |   0.493450  |    0.007050     |   0\n",
      "        984 |   0.506525  |    0.021543     |   0\n",
      "        985 |   0.042376  |    0.042050     |   2\n",
      "        986 |   0.510683  |    0.028485     |   0\n",
      "        987 |   0.121602  |    0.036194     |   2\n",
      "        988 |   0.484748  |    0.126168     |   1\n",
      "        989 |   0.479887  |    0.009088     |   0\n",
      "        990 |   0.415939  |    0.011310     |   0\n",
      "        991 |   0.506554  |    0.086653     |   1\n",
      "        992 |   0.450813  |    0.026419     |   0\n",
      "        993 |   0.107326  |    0.047543     |   2\n",
      "        994 |   0.547289  |    0.085203     |   1\n",
      "        995 |   0.475138  |    0.010803     |   0\n",
      "        996 |   0.463927  |    0.049507     |   0\n",
      "        997 |   0.001137  |    0.020620     |   2\n",
      "        998 |   0.546521  |    0.127800     |   1\n",
      "        999 |   0.495386  |    0.010879     |   0\n",
      "       1000 |   0.001307  |    0.036222     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 1000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 1000: Plotting estimates.\n",
      "Exception in thread neuralnilm-data-process:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 810, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/dk3810/workspace/python/neuralnilm/neuralnilm/data/datathread.py\", line 16, in run\n",
      "    batch = self.data_pipeline.get_batch(**self._get_batch_kwargs)\n",
      "  File \"/home/dk3810/workspace/python/neuralnilm/neuralnilm/data/datapipeline.py\", line 46, in get_batch\n",
      "    batch = self._source_iterators[source_id].next()\n",
      "ValueError: generator already executing\n",
      "\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       1001 |   0.446250  |    0.182582     |   1\n",
      "       1002 |   0.423614  |    0.024938     |   0\n",
      "       1003 |   0.582585  |    0.039315     |   0\n",
      "       1004 |   0.531758  |    0.029664     |   0\n",
      "       1005 |   0.565679  |    0.152124     |   1\n",
      "       1006 |   0.421410  |    0.019437     |   0\n",
      "       1007 |   0.489581  |    0.087209     |   1\n",
      "       1008 |   0.387490  |    0.085739     |   1\n",
      "       1009 |   0.440247  |    0.024371     |   0\n",
      "       1010 |   0.464464  |    0.152735     |   1\n",
      "       1011 |   0.574378  |    0.040627     |   1\n",
      "       1012 |   0.458423  |    0.137832     |   1\n",
      "       1013 |   0.186365  |    0.004847     |   2\n",
      "       1014 |   0.392764  |    0.043709     |   0\n",
      "       1015 |   0.408334  |    0.018619     |   0\n",
      "       1016 |   0.307351  |    0.022913     |   0\n",
      "       1017 |   0.423605  |    0.039598     |   0\n",
      "       1018 |   0.357530  |    0.133279     |   1\n",
      "       1019 |   0.594434  |    0.089974     |   1\n",
      "       1020 |   0.532302  |    0.087736     |   1\n",
      "       1021 |   0.145905  |    0.009830     |   2\n",
      "       1022 |   0.366351  |    0.040542     |   0\n",
      "       1023 |   0.444523  |    0.014180     |   0\n",
      "       1024 |   0.451356  |    0.060311     |   0\n",
      "       1025 |   0.385508  |    0.132512     |   1\n",
      "       1026 |   0.376698  |    0.047913     |   1\n",
      "       1027 |   0.353794  |    0.040049     |   0\n",
      "       1028 |   0.507922  |    0.101448     |   1\n",
      "       1029 |   0.161532  |    0.021235     |   2\n",
      "       1030 |   0.297951  |    0.033204     |   0\n",
      "       1031 |   0.185549  |    0.028074     |   2\n",
      "       1032 |   0.451621  |    0.039100     |   0\n",
      "       1033 |   0.527219  |    0.136316     |   1\n",
      "       1034 |   0.405225  |    0.095787     |   1\n",
      "       1035 |   0.535500  |    0.085809     |   1\n",
      "       1036 |   0.363532  |    0.011495     |   0\n",
      "       1037 |   0.434490  |    0.053505     |   0\n",
      "       1038 |   0.531754  |    0.091343     |   1\n",
      "       1039 |   0.381983  |    0.137799     |   1\n",
      "       1040 |   0.505815  |    0.039630     |   1\n",
      "       1041 |   0.422688  |    0.040735     |   0\n",
      "       1042 |   0.416610  |    0.147996     |   1\n",
      "       1043 |   0.447287  |    0.009964     |   0\n",
      "       1044 |   0.581032  |    0.054171     |   1\n",
      "       1045 |   0.392756  |    0.134495     |   1\n",
      "       1046 |   0.479374  |    0.008069     |   0\n",
      "       1047 |   0.390132  |    0.019335     |   0\n",
      "       1048 |   0.082554  |    0.030055     |   2\n",
      "       1049 |   0.443449  |    0.032951     |   0\n",
      "       1050 |   0.424653  |    0.029357     |   0\n",
      "       1051 |   0.153873  |    0.015436     |   2\n",
      "       1052 |   0.476512  |    0.144447     |   1\n",
      "       1053 |   0.345852  |    0.012657     |   0\n",
      "       1054 |   0.582636  |    0.098468     |   1\n",
      "       1055 |   0.608898  |    0.085595     |   1\n",
      "       1056 |   0.411620  |    0.007285     |   0\n",
      "       1057 |   0.138498  |    0.026003     |   2\n",
      "       1058 |   0.426537  |    0.028544     |   0\n",
      "       1059 |   0.464669  |    0.025016     |   0\n",
      "       1060 |   0.136420  |    0.018690     |   2\n",
      "       1061 |   0.401899  |    0.048747     |   0\n",
      "       1062 |   0.137927  |    0.012267     |   2\n",
      "       1063 |   0.474784  |    0.102421     |   1\n",
      "       1064 |   0.052744  |    0.013396     |   2\n",
      "       1065 |   0.001010  |    0.034444     |   2\n",
      "       1066 |   0.451905  |    0.174436     |   1\n",
      "       1067 |   0.018611  |    0.005717     |   2\n",
      "       1068 |   0.477419  |    0.073318     |   1\n",
      "       1069 |   0.264418  |    0.004180     |   2\n",
      "       1070 |   0.553785  |    0.047964     |   0\n",
      "       1071 |   0.328094  |    0.102634     |   1\n",
      "       1072 |   0.475816  |    0.140773     |   1\n",
      "       1073 |   0.117047  |    0.004748     |   2\n",
      "       1074 |   0.143434  |    0.020205     |   2\n",
      "       1075 |   0.433865  |    0.091005     |   1\n",
      "       1076 |   0.458572  |    0.135193     |   1\n",
      "       1077 |   0.421157  |    0.066363     |   1\n",
      "       1078 |   0.509640  |    0.137144     |   1\n",
      "       1079 |   0.403445  |    0.010959     |   0\n",
      "       1080 |   0.359569  |    0.139352     |   1\n",
      "       1081 |   0.430374  |    0.007947     |   0\n",
      "       1082 |   0.396495  |    0.097374     |   1\n",
      "       1083 |   0.111828  |    0.006420     |   2\n",
      "       1084 |   0.438311  |    0.062266     |   0\n",
      "       1085 |   0.491501  |    0.083073     |   1\n",
      "       1086 |   0.042095  |    0.017061     |   2\n",
      "       1087 |   0.420873  |    0.142759     |   1\n",
      "       1088 |   0.451997  |    0.066054     |   1\n",
      "       1089 |   0.385481  |    0.157989     |   1\n",
      "       1090 |   0.454260  |    0.028721     |   1\n",
      "       1091 |   0.478364  |    0.140594     |   1\n",
      "       1092 |   0.123989  |    0.004705     |   2\n",
      "       1093 |   0.449708  |    0.013577     |   0\n",
      "       1094 |   0.424198  |    0.036370     |   0\n",
      "       1095 |   0.551114  |    0.142211     |   1\n",
      "       1096 |   0.415358  |    0.055548     |   1\n",
      "       1097 |   0.105952  |    0.027789     |   2\n",
      "       1098 |   0.422089  |    0.145610     |   1\n",
      "       1099 |   0.415837  |    0.085439     |   1\n",
      "       1100 |   0.308931  |    0.009176     |   0\n",
      "       1101 |   0.000941  |    0.032661     |   2\n",
      "       1102 |   0.404696  |    0.051485     |   0\n",
      "       1103 |   0.544793  |    0.088557     |   1\n",
      "       1104 |   0.361282  |    0.006754     |   0\n",
      "       1105 |   0.001072  |    0.041117     |   2\n",
      "       1106 |   0.413691  |    0.035655     |   0\n",
      "       1107 |   0.441343  |    0.145884     |   1\n",
      "       1108 |   0.442446  |    0.110756     |   1\n",
      "       1109 |   0.428784  |    0.010810     |   0\n",
      "       1110 |   0.585063  |    0.105040     |   1\n",
      "       1111 |   0.431578  |    0.008368     |   0\n",
      "       1112 |   0.398746  |    0.084160     |   1\n",
      "       1113 |   0.328061  |    0.029299     |   0\n",
      "       1114 |   0.000909  |    0.036615     |   2\n",
      "       1115 |   0.001077  |    0.010139     |   2\n",
      "       1116 |   0.504787  |    0.136174     |   1\n",
      "       1117 |   0.001151  |    0.007785     |   2\n",
      "       1118 |   0.495240  |    0.136391     |   1\n",
      "       1119 |   0.502441  |    0.082169     |   1\n",
      "       1120 |   0.427954  |    0.032912     |   0\n",
      "       1121 |   0.001046  |    0.031086     |   2\n",
      "       1122 |   0.421105  |    0.031723     |   0\n",
      "       1123 |   0.472810  |    0.153123     |   1\n",
      "       1124 |   0.571782  |    0.058557     |   1\n",
      "       1125 |   0.426962  |    0.097168     |   1\n",
      "       1126 |   0.480060  |    0.078065     |   1\n",
      "       1127 |   0.389194  |    0.012473     |   0\n",
      "       1128 |   0.146619  |    0.031520     |   2\n",
      "       1129 |   0.419730  |    0.028750     |   0\n",
      "       1130 |   0.189696  |    0.018777     |   2\n",
      "       1131 |   0.371399  |    0.028207     |   0\n",
      "       1132 |   0.476412  |    0.145225     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 1133: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       1133 |   0.395038  |    0.022568     |   0\n",
      "       1134 |   0.591818  |    0.053119     |   1\n",
      "       1135 |   0.429820  |    0.018659     |   0\n",
      "       1136 |   0.501488  |    0.147225     |   1\n",
      "       1137 |   0.364975  |    0.092466     |   1\n",
      "       1138 |   0.520806  |    0.078270     |   1\n",
      "       1139 |   0.394322  |    0.006526     |   0\n",
      "       1140 |   0.376065  |    0.030558     |   0\n",
      "       1141 |   0.496491  |    0.041265     |   0\n",
      "       1142 |   0.337016  |    0.017865     |   0\n",
      "       1143 |   0.454570  |    0.145337     |   1\n",
      "       1144 |   0.363711  |    0.012993     |   0\n",
      "       1145 |   0.448193  |    0.092471     |   1\n",
      "       1146 |   0.502043  |    0.085466     |   1\n",
      "       1147 |   0.172010  |    0.013528     |   2\n",
      "       1148 |   0.130749  |    0.053276     |   2\n",
      "       1149 |   0.152846  |    0.013866     |   2\n",
      "       1150 |   0.171440  |    0.025833     |   2\n",
      "       1151 |   0.077392  |    0.028592     |   2\n",
      "       1152 |   0.446276  |    0.026193     |   0\n",
      "       1153 |   0.145357  |    0.020992     |   2\n",
      "       1154 |   0.423624  |    0.043013     |   0\n",
      "       1155 |   0.131654  |    0.008903     |   2\n",
      "       1156 |   0.445661  |    0.061019     |   0\n",
      "       1157 |   0.131098  |    0.009356     |   2\n",
      "       1158 |   0.478889  |    0.159676     |   1\n",
      "       1159 |   0.129113  |    0.003231     |   2\n",
      "       1160 |   0.051843  |    0.012404     |   2\n",
      "       1161 |   0.291390  |    0.049653     |   0\n",
      "       1162 |   0.000867  |    0.011316     |   2\n",
      "       1163 |   0.492027  |    0.147010     |   1\n",
      "       1164 |   0.416197  |    0.020100     |   0\n",
      "       1165 |   0.449540  |    0.088949     |   1\n",
      "       1166 |   0.015822  |    0.006304     |   2\n",
      "       1167 |   0.414147  |    0.033134     |   0\n",
      "       1168 |   0.249974  |    0.009974     |   2\n",
      "       1169 |   0.110520  |    0.059937     |   2\n",
      "       1170 |   0.139148  |    0.005563     |   2\n",
      "       1171 |   0.108138  |    0.033570     |   2\n",
      "       1172 |   0.464900  |    0.033944     |   0\n",
      "       1173 |   0.475294  |    0.124015     |   1\n",
      "       1174 |   0.492956  |    0.131916     |   1\n",
      "       1175 |   0.042031  |    0.003105     |   2\n",
      "       1176 |   0.365747  |    0.009897     |   0\n",
      "       1177 |   0.117156  |    0.050441     |   2\n",
      "       1178 |   0.436531  |    0.083440     |   1\n",
      "       1179 |   0.355338  |    0.036718     |   0\n",
      "       1180 |   0.420253  |    0.102170     |   1\n",
      "       1181 |   0.435136  |    0.098039     |   1\n",
      "       1182 |   0.449654  |    0.097566     |   1\n",
      "       1183 |   0.102362  |    0.007694     |   2\n",
      "       1184 |   0.000870  |    0.042056     |   2\n",
      "       1185 |   0.371504  |    0.041376     |   0\n",
      "       1186 |   0.000999  |    0.038384     |   2\n",
      "       1187 |   0.000816  |    0.039083     |   2\n",
      "       1188 |   0.394004  |    0.058736     |   0\n",
      "       1189 |   0.417146  |    0.089778     |   1\n",
      "       1190 |   0.415858  |    0.006459     |   0\n",
      "       1191 |   0.001004  |    0.023549     |   2\n",
      "       1192 |   0.001087  |    0.034479     |   2\n",
      "       1193 |   0.382921  |    0.138510     |   1\n",
      "       1194 |   0.421385  |    0.013136     |   0\n",
      "       1195 |   0.417198  |    0.080460     |   1\n",
      "       1196 |   0.378437  |    0.017911     |   0\n",
      "       1197 |   0.001042  |    0.049654     |   2\n",
      "       1198 |   0.415688  |    0.084513     |   1\n",
      "       1199 |   0.561123  |    0.094948     |   1\n",
      "       1200 |   0.145928  |    0.042823     |   2\n",
      "       1201 |   0.185972  |    0.020166     |   2\n",
      "       1202 |   0.495778  |    0.127259     |   1\n",
      "       1203 |   0.432522  |    0.009092     |   0\n",
      "       1204 |   0.496787  |    0.051311     |   0\n",
      "       1205 |   0.447123  |    0.165322     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 1206: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       1206 |   0.164979  |    0.011421     |   2\n",
      "       1207 |   0.409793  |    0.034650     |   1\n",
      "       1208 |   0.126828  |    0.023081     |   2\n",
      "       1209 |   0.400879  |    0.128815     |   1\n",
      "       1210 |   0.405623  |    0.009429     |   0\n",
      "       1211 |   0.415067  |    0.143737     |   1\n",
      "       1212 |   0.382162  |    0.003120     |   0\n",
      "       1213 |   0.375009  |    0.012041     |   0\n",
      "       1214 |   0.147429  |    0.050908     |   2\n",
      "       1215 |   0.525538  |    0.107748     |   1\n",
      "       1216 |   0.429065  |    0.084090     |   1\n",
      "       1217 |   0.167885  |    0.031222     |   2\n",
      "       1218 |   0.076795  |    0.030567     |   2\n",
      "       1219 |   0.453096  |    0.021902     |   0\n",
      "       1220 |   0.475563  |    0.141645     |   1\n",
      "       1221 |   0.472720  |    0.077343     |   1\n",
      "       1222 |   0.465430  |    0.091083     |   1\n",
      "       1223 |   0.540500  |    0.102036     |   1\n",
      "       1224 |   0.519773  |    0.091051     |   1\n",
      "       1225 |   0.137185  |    0.008403     |   2\n",
      "       1226 |   0.369271  |    0.032540     |   0\n",
      "       1227 |   0.495679  |    0.141365     |   1\n",
      "       1228 |   0.467251  |    0.013321     |   0\n",
      "       1229 |   0.435390  |    0.057910     |   1\n",
      "       1230 |   0.376325  |    0.013377     |   0\n",
      "       1231 |   0.360369  |    0.061971     |   0\n",
      "       1232 |   0.477925  |    0.089259     |   1\n",
      "       1233 |   0.397261  |    0.008041     |   0\n",
      "       1234 |   0.401782  |    0.041833     |   0\n",
      "       1235 |   0.363215  |    0.024067     |   0\n",
      "       1236 |   0.316937  |    0.041381     |   0\n",
      "       1237 |   0.524932  |    0.108721     |   1\n",
      "       1238 |   0.374562  |    0.084588     |   1\n",
      "       1239 |   0.125539  |    0.025425     |   2\n",
      "       1240 |   0.128992  |    0.033005     |   2\n",
      "       1241 |   0.385619  |    0.030433     |   0\n",
      "       1242 |   0.125570  |    0.031471     |   2\n",
      "       1243 |   0.515828  |    0.141088     |   1\n",
      "       1244 |   0.366660  |    0.097310     |   1\n",
      "       1245 |   0.050205  |    0.005644     |   2\n",
      "       1246 |   0.000822  |    0.068745     |   2\n",
      "       1247 |   0.376854  |    0.090084     |   1\n",
      "       1248 |   0.016147  |    0.006178     |   2\n",
      "       1249 |   0.345464  |    0.041734     |   0\n",
      "       1250 |   0.237483  |    0.025595     |   2\n",
      "       1251 |   0.432352  |    0.159459     |   1\n",
      "       1252 |   0.394251  |    0.007569     |   0\n",
      "       1253 |   0.353307  |    0.026103     |   1\n",
      "       1254 |   0.424077  |    0.044502     |   0\n",
      "       1255 |   0.107618  |    0.014405     |   2\n",
      "       1256 |   0.520431  |    0.145873     |   1\n",
      "       1257 |   0.135170  |    0.002989     |   2\n",
      "       1258 |   0.105760  |    0.006946     |   2\n",
      "       1259 |   0.042542  |    0.042223     |   2\n",
      "       1260 |   0.325909  |    0.024257     |   0\n",
      "       1261 |   0.114206  |    0.041681     |   2\n",
      "       1262 |   0.099583  |    0.012350     |   2\n",
      "       1263 |   0.000812  |    0.025035     |   2\n",
      "       1264 |   0.319313  |    0.027729     |   0\n",
      "       1265 |   0.349726  |    0.031834     |   0\n",
      "       1266 |   0.000911  |    0.025333     |   2\n",
      "       1267 |   0.000745  |    0.028961     |   2\n",
      "       1268 |   0.334678  |    0.021473     |   0\n",
      "       1269 |   0.517095  |    0.041378     |   0\n",
      "       1270 |   0.508042  |    0.086837     |   1\n",
      "       1271 |   0.000922  |    0.011530     |   2\n",
      "       1272 |   0.365331  |    0.062570     |   0\n",
      "       1273 |   0.487719  |    0.085932     |   1\n",
      "       1274 |   0.403122  |    0.010847     |   0\n",
      "       1275 |   0.001016  |    0.033927     |   2\n",
      "       1276 |   0.000953  |    0.014580     |   2\n",
      "       1277 |   0.408476  |    0.045373     |   0\n",
      "       1278 |   0.140876  |    0.008003     |   2\n",
      "       1279 |   0.394240  |    0.047519     |   0\n",
      "       1280 |   0.579706  |    0.100344     |   1\n",
      "       1281 |   0.445272  |    0.076875     |   1\n",
      "       1282 |   0.497179  |    0.024743     |   0\n",
      "       1283 |   0.363795  |    0.026857     |   0\n",
      "       1284 |   0.176650  |    0.019583     |   2\n",
      "       1285 |   0.321151  |    0.046628     |   0\n",
      "       1286 |   0.451662  |    0.081975     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 1287: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       1287 |   0.365477  |    0.013104     |   0\n",
      "       1288 |   0.288462  |    0.066446     |   0\n",
      "       1289 |   0.342426  |    0.060984     |   1\n",
      "       1290 |   0.162782  |    0.008922     |   2\n",
      "       1291 |   0.414772  |    0.038612     |   0\n",
      "       1292 |   0.386504  |    0.164283     |   1\n",
      "       1293 |   0.373599  |    0.021275     |   1\n",
      "       1294 |   0.414134  |    0.034349     |   0\n",
      "       1295 |   0.339409  |    0.012471     |   0\n",
      "       1296 |   0.552206  |    0.151975     |   1\n",
      "       1297 |   0.124002  |    0.008236     |   2\n",
      "       1298 |   0.451474  |    0.086385     |   1\n",
      "       1299 |   0.144041  |    0.027347     |   2\n",
      "       1300 |   0.314163  |    0.027861     |   0\n",
      "       1301 |   0.347667  |    0.017170     |   0\n",
      "       1302 |   0.509510  |    0.151465     |   1\n",
      "       1303 |   0.169139  |    0.007151     |   2\n",
      "       1304 |   0.443599  |    0.136028     |   1\n",
      "       1305 |   0.355756  |    0.090480     |   1\n",
      "       1306 |   0.076592  |    0.004388     |   2\n",
      "       1307 |   0.136833  |    0.027904     |   2\n",
      "       1308 |   0.126173  |    0.031591     |   2\n",
      "       1309 |   0.443317  |    0.139946     |   1\n",
      "       1310 |   0.392336  |    0.008299     |   0\n",
      "       1311 |   0.125630  |    0.013051     |   2\n",
      "       1312 |   0.432050  |    0.089292     |   1\n",
      "       1313 |   0.122870  |    0.026062     |   2\n",
      "       1314 |   0.336543  |    0.027213     |   0\n",
      "       1315 |   0.482260  |    0.142754     |   1\n",
      "       1316 |   0.489526  |    0.088933     |   1\n",
      "       1317 |   0.354907  |    0.032428     |   0\n",
      "       1318 |   0.436849  |    0.138837     |   1\n",
      "       1319 |   0.391718  |    0.013540     |   0\n",
      "       1320 |   0.327641  |    0.099651     |   1\n",
      "       1321 |   0.277384  |    0.087794     |   1\n",
      "       1322 |   0.047329  |    0.031650     |   2\n",
      "       1323 |   0.339251  |    0.034018     |   0\n",
      "       1324 |   0.451697  |    0.088697     |   1\n",
      "       1325 |   0.437847  |    0.042998     |   0\n",
      "       1326 |   0.400273  |    0.028225     |   0\n",
      "       1327 |   0.410384  |    0.159528     |   1\n",
      "       1328 |   0.000719  |    0.005303     |   2\n",
      "       1329 |   0.532527  |    0.051162     |   1\n",
      "       1330 |   0.017487  |    0.039822     |   2\n",
      "       1331 |   0.236158  |    0.012760     |   2\n",
      "       1332 |   0.323106  |    0.029206     |   0\n",
      "       1333 |   0.110299  |    0.032184     |   2\n",
      "       1334 |   0.129206  |    0.011055     |   2\n",
      "       1335 |   0.360884  |    0.139124     |   1\n",
      "       1336 |   0.106679  |    0.007959     |   2\n",
      "       1337 |   0.043781  |    0.047277     |   2\n",
      "       1338 |   0.113492  |    0.011006     |   2\n",
      "       1339 |   0.099817  |    0.056504     |   2\n",
      "       1340 |   0.516402  |    0.101635     |   1\n",
      "       1341 |   0.370789  |    0.087709     |   1\n",
      "       1342 |   0.000687  |    0.011376     |   2\n",
      "       1343 |   0.000779  |    0.051017     |   2\n",
      "       1344 |   0.453338  |    0.081244     |   1\n",
      "       1345 |   0.403361  |    0.018011     |   0\n",
      "       1346 |   0.428447  |    0.137149     |   1\n",
      "       1347 |   0.000654  |    0.003273     |   2\n",
      "       1348 |   0.000782  |    0.009485     |   2\n",
      "       1349 |   0.000894  |    0.030455     |   2\n",
      "       1350 |   0.000821  |    0.040633     |   2\n",
      "       1351 |   0.405216  |    0.139913     |   1\n",
      "       1352 |   0.471173  |    0.081942     |   1\n",
      "       1353 |   0.133610  |    0.006808     |   2\n",
      "       1354 |   0.378497  |    0.007909     |   0\n",
      "       1355 |   0.169637  |    0.041823     |   2\n",
      "       1356 |   0.313056  |    0.016475     |   0\n",
      "       1357 |   0.565745  |    0.150061     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 1358: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       1358 |   0.370211  |    0.081300     |   1\n",
      "       1359 |   0.391368  |    0.010460     |   0\n",
      "       1360 |   0.369050  |    0.048387     |   0\n",
      "       1361 |   0.152936  |    0.007864     |   2\n",
      "       1362 |   0.115341  |    0.041822     |   2\n",
      "       1363 |   0.364243  |    0.023199     |   0\n",
      "       1364 |   0.455036  |    0.136773     |   1\n",
      "       1365 |   0.437288  |    0.067923     |   1\n",
      "       1366 |   0.140722  |    0.007623     |   2\n",
      "       1367 |   0.344133  |    0.055248     |   0\n",
      "       1368 |   0.422619  |    0.095268     |   1\n",
      "       1369 |   0.469934  |    0.077482     |   1\n",
      "       1370 |   0.364072  |    0.007919     |   0\n",
      "       1371 |   0.375590  |    0.020916     |   0\n",
      "       1372 |   0.380701  |    0.047719     |   0\n",
      "       1373 |   0.164461  |    0.010526     |   2\n",
      "       1374 |   0.322174  |    0.042681     |   0\n",
      "       1375 |   0.435905  |    0.022173     |   0\n",
      "       1376 |   0.075024  |    0.028638     |   2\n",
      "       1377 |   0.129211  |    0.025537     |   2\n",
      "       1378 |   0.325471  |    0.046638     |   0\n",
      "       1379 |   0.556989  |    0.083317     |   1\n",
      "       1380 |   0.508520  |    0.010974     |   0\n",
      "       1381 |   0.322551  |    0.052584     |   0\n",
      "       1382 |   0.475968  |    0.083951     |   1\n",
      "       1383 |   0.124311  |    0.006179     |   2\n",
      "       1384 |   0.120278  |    0.017773     |   2\n",
      "       1385 |   0.473773  |    0.159120     |   1\n",
      "       1386 |   0.325081  |    0.135109     |   1\n",
      "       1387 |   0.446882  |    0.065214     |   1\n",
      "       1388 |   0.118608  |    0.011837     |   2\n",
      "       1389 |   0.380104  |    0.134741     |   1\n",
      "       1390 |   0.459443  |    0.081024     |   1\n",
      "       1391 |   0.400511  |    0.141941     |   1\n",
      "       1392 |   0.384655  |    0.091879     |   1\n",
      "       1393 |   0.362759  |    0.102054     |   1\n",
      "       1394 |   0.434164  |    0.100061     |   1\n",
      "       1395 |   0.350189  |    0.138425     |   1\n",
      "       1396 |   0.047259  |    0.002903     |   2\n",
      "       1397 |   0.000690  |    0.009915     |   2\n",
      "       1398 |   0.016539  |    0.027399     |   2\n",
      "       1399 |   0.381139  |    0.142177     |   1\n",
      "       1400 |   0.228840  |    0.003033     |   2\n",
      "       1401 |   0.104839  |    0.006539     |   2\n",
      "       1402 |   0.350444  |    0.052657     |   0\n",
      "       1403 |   0.124486  |    0.008283     |   2\n",
      "       1404 |   0.098446  |    0.042393     |   2\n",
      "       1405 |   0.318137  |    0.019390     |   0\n",
      "       1406 |   0.041287  |    0.029511     |   2\n",
      "       1407 |   0.384957  |    0.027007     |   0\n",
      "       1408 |   0.112090  |    0.026102     |   2\n",
      "       1409 |   0.531785  |    0.146587     |   1\n",
      "       1410 |   0.380889  |    0.066939     |   1\n",
      "       1411 |   0.098244  |    0.008379     |   2\n",
      "       1412 |   0.371393  |    0.153938     |   1\n",
      "       1413 |   0.379451  |    0.008786     |   0\n",
      "       1414 |   0.461021  |    0.097521     |   1\n",
      "       1415 |   0.378131  |    0.017779     |   0\n",
      "       1416 |   0.412682  |    0.090468     |   1\n",
      "       1417 |   0.398976  |    0.116727     |   1\n",
      "       1418 |   0.480260  |    0.091857     |   1\n",
      "       1419 |   0.486133  |    0.051219     |   1\n",
      "       1420 |   0.000615  |    0.017003     |   2\n",
      "       1421 |   0.000705  |    0.034484     |   2\n",
      "       1422 |   0.395697  |    0.027282     |   0\n",
      "       1423 |   0.000598  |    0.032751     |   2\n",
      "       1424 |   0.345829  |    0.142908     |   1\n",
      "       1425 |   0.540921  |    0.011587     |   1\n",
      "       1426 |   0.309526  |    0.051084     |   0\n",
      "       1427 |   0.000712  |    0.015548     |   2\n",
      "       1428 |   0.420933  |    0.166818     |   1\n",
      "       1429 |   0.427642  |    0.051561     |   1\n",
      "       1430 |   0.000795  |    0.029093     |   2\n",
      "       1431 |   0.353894  |    0.039922     |   0\n",
      "       1432 |   0.512638  |    0.101902     |   1\n",
      "       1433 |   0.446348  |    0.097728     |   1\n",
      "       1434 |   0.000768  |    0.011333     |   2\n",
      "       1435 |   0.387405  |    0.157725     |   1\n",
      "       1436 |   0.126407  |    0.006239     |   2\n",
      "       1437 |   0.475660  |    0.066671     |   1\n",
      "       1438 |   0.481691  |    0.082895     |   1\n",
      "       1439 |   0.371229  |    0.018386     |   0\n",
      "       1440 |   0.164977  |    0.035901     |   2\n",
      "       1441 |   0.492453  |    0.086958     |   1\n",
      "       1442 |   0.388548  |    0.086856     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 1443: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       1443 |   0.452425  |    0.085934     |   1\n",
      "       1444 |   0.485445  |    0.096890     |   1\n",
      "       1445 |   0.408981  |    0.015832     |   0\n",
      "       1446 |   0.278792  |    0.146897     |   1\n",
      "       1447 |   0.350681  |    0.080379     |   1\n",
      "       1448 |   0.145238  |    0.008792     |   2\n",
      "       1449 |   0.369638  |    0.141310     |   1\n",
      "       1450 |   0.477374  |    0.080851     |   1\n",
      "       1451 |   0.112512  |    0.008504     |   2\n",
      "       1452 |   0.318096  |    0.029256     |   0\n",
      "       1453 |   0.427814  |    0.030158     |   0\n",
      "       1454 |   0.132870  |    0.017822     |   2\n",
      "       1455 |   0.158761  |    0.030654     |   2\n",
      "       1456 |   0.070945  |    0.011252     |   2\n",
      "       1457 |   0.127335  |    0.045783     |   2\n",
      "       1458 |   0.118903  |    0.006363     |   2\n",
      "       1459 |   0.290022  |    0.045059     |   0\n",
      "       1460 |   0.119242  |    0.022034     |   2\n",
      "       1461 |   0.324175  |    0.151125     |   1\n",
      "       1462 |   0.373535  |    0.082390     |   1\n",
      "       1463 |   0.392477  |    0.098362     |   1\n",
      "       1464 |   0.356702  |    0.020457     |   0\n",
      "       1465 |   0.112811  |    0.027808     |   2\n",
      "       1466 |   0.354549  |    0.033932     |   0\n",
      "       1467 |   0.343592  |    0.139487     |   1\n",
      "       1468 |   0.358773  |    0.015145     |   0\n",
      "       1469 |   0.396221  |    0.103682     |   1\n",
      "       1470 |   0.417762  |    0.098285     |   1\n",
      "       1471 |   0.518091  |    0.078302     |   1\n",
      "       1472 |   0.370984  |    0.017426     |   0\n",
      "       1473 |   0.320772  |    0.034675     |   0\n",
      "       1474 |   0.493183  |    0.137960     |   1\n",
      "       1475 |   0.408697  |    0.003227     |   0\n",
      "       1476 |   0.050916  |    0.009599     |   2\n",
      "       1477 |   0.336385  |    0.035909     |   0\n",
      "       1478 |   0.411125  |    0.138491     |   1\n",
      "       1479 |   0.430243  |    0.086611     |   1\n",
      "       1480 |   0.000643  |    0.008204     |   2\n",
      "       1481 |   0.016172  |    0.027167     |   2\n",
      "       1482 |   0.392569  |    0.142035     |   1\n",
      "       1483 |   0.351983  |    0.003453     |   0\n",
      "       1484 |   0.375392  |    0.012746     |   0\n",
      "       1485 |   0.306189  |    0.068346     |   0\n",
      "       1486 |   0.401152  |    0.064730     |   1\n",
      "       1487 |   0.363211  |    0.091221     |   0\n",
      "       1488 |   0.346116  |    0.067478     |   1\n",
      "       1489 |   0.440187  |    0.069751     |   1\n",
      "       1490 |   0.525706  |    0.095076     |   1\n",
      "       1491 |   0.225209  |    0.007668     |   2\n",
      "       1492 |   0.107300  |    0.029334     |   2\n",
      "       1493 |   0.453759  |    0.165028     |   1\n",
      "       1494 |   0.123910  |    0.017643     |   2\n",
      "       1495 |   0.431797  |    0.015126     |   1\n",
      "       1496 |   0.345996  |    0.030928     |   0\n",
      "       1497 |   0.359339  |    0.141579     |   1\n",
      "       1498 |   0.103830  |    0.006643     |   2\n",
      "       1499 |   0.290534  |    0.008754     |   0\n",
      "       1500 |   0.346679  |    0.026262     |   0\n",
      "       1501 |   0.149397  |    0.062674     |   2\n",
      "       1502 |   0.346454  |    0.089897     |   1\n",
      "       1503 |   0.115649  |    0.007221     |   2\n",
      "       1504 |   0.377895  |    0.152669     |   1\n",
      "       1505 |   0.353020  |    0.011114     |   0\n",
      "       1506 |   0.134284  |    0.010287     |   2\n",
      "       1507 |   0.157594  |    0.025635     |   2\n",
      "       1508 |   0.293881  |    0.037663     |   0\n",
      "       1509 |   0.347775  |    0.014888     |   0\n",
      "       1510 |   0.072390  |    0.022941     |   2\n",
      "       1511 |   0.374044  |    0.026540     |   0\n",
      "       1512 |   0.361439  |    0.046381     |   0\n",
      "       1513 |   0.369861  |    0.099127     |   1\n",
      "       1514 |   0.353917  |    0.009317     |   0\n",
      "       1515 |   0.275346  |    0.091351     |   1\n",
      "       1516 |   0.288678  |    0.010025     |   0\n",
      "       1517 |   0.125776  |    0.046909     |   2\n",
      "       1518 |   0.124682  |    0.011033     |   2\n",
      "       1519 |   0.443196  |    0.142371     |   1\n",
      "       1520 |   0.311909  |    0.002967     |   0\n",
      "       1521 |   0.299022  |    0.009465     |   0\n",
      "       1522 |   0.279508  |    0.033041     |   0\n",
      "       1523 |   0.118936  |    0.005739     |   2\n",
      "       1524 |   0.294939  |    0.049449     |   0\n",
      "       1525 |   0.112249  |    0.008091     |   2\n",
      "       1526 |   0.363119  |    0.043092     |   0\n",
      "       1527 |   0.291958  |    0.022659     |   0\n",
      "       1528 |   0.049890  |    0.030781     |   2\n",
      "       1529 |   0.324874  |    0.031646     |   0\n",
      "       1530 |   0.386945  |    0.152329     |   1\n",
      "       1531 |   0.396922  |    0.079059     |   1\n",
      "       1532 |   0.445910  |    0.074254     |   1\n",
      "       1533 |   0.275189  |    0.093896     |   1\n",
      "       1534 |   0.000631  |    0.008847     |   2\n",
      "       1535 |   0.330944  |    0.056038     |   0\n",
      "       1536 |   0.377110  |    0.055390     |   1\n",
      "       1537 |   0.015576  |    0.021701     |   2\n",
      "       1538 |   0.350341  |    0.137288     |   1\n",
      "       1539 |   0.404763  |    0.095992     |   1\n",
      "       1540 |   0.400200  |    0.014841     |   0\n",
      "       1541 |   0.300734  |    0.026610     |   0\n",
      "       1542 |   0.337677  |    0.012937     |   0\n",
      "       1543 |   0.379136  |    0.030494     |   0\n",
      "       1544 |   0.334535  |    0.153002     |   1\n",
      "       1545 |   0.372298  |    0.046991     |   1\n",
      "       1546 |   0.409875  |    0.087980     |   1\n",
      "       1547 |   0.493884  |    0.063321     |   1\n",
      "       1548 |   0.397340  |    0.100187     |   1\n",
      "       1549 |   0.262383  |    0.019633     |   0\n",
      "       1550 |   0.551107  |    0.079618     |   1\n",
      "       1551 |   0.416030  |    0.078480     |   0\n",
      "       1552 |   0.343079  |    0.046377     |   1\n",
      "       1553 |   0.380769  |    0.092882     |   1\n",
      "       1554 |   0.222828  |    0.007142     |   2\n",
      "       1555 |   0.437578  |    0.106738     |   1\n",
      "       1556 |   0.103011  |    0.023807     |   2\n",
      "       1557 |   0.421179  |    0.102608     |   1\n",
      "       1558 |   0.315742  |    0.097558     |   1\n",
      "       1559 |   0.294479  |    0.004571     |   0\n",
      "       1560 |   0.337095  |    0.020848     |   0\n",
      "       1561 |   0.369349  |    0.151293     |   1\n",
      "       1562 |   0.124984  |    0.009149     |   2\n",
      "       1563 |   0.314573  |    0.090319     |   1\n",
      "       1564 |   0.428946  |    0.147219     |   1\n",
      "       1565 |   0.101885  |    0.009539     |   2\n",
      "       1566 |   0.429097  |    0.084600     |   1\n",
      "       1567 |   0.044673  |    0.013656     |   2\n",
      "       1568 |   0.313242  |    0.023517     |   0\n",
      "       1569 |   0.302717  |    0.041872     |   0\n",
      "       1570 |   0.382650  |    0.034583     |   0\n",
      "       1571 |   0.365204  |    0.138527     |   1\n",
      "       1572 |   0.114449  |    0.003007     |   2\n",
      "       1573 |   0.314088  |    0.007196     |   0\n",
      "       1574 |   0.095766  |    0.033476     |   2\n",
      "       1575 |   0.363034  |    0.041895     |   0\n",
      "       1576 |   0.418781  |    0.088150     |   1\n",
      "       1577 |   0.304067  |    0.014608     |   0\n",
      "       1578 |   0.355821  |    0.022000     |   0\n",
      "       1579 |   0.375634  |    0.099056     |   1\n",
      "       1580 |   0.349882  |    0.084982     |   1\n",
      "       1581 |   0.437432  |    0.111530     |   1\n",
      "       1582 |   0.390283  |    0.069846     |   1\n",
      "       1583 |   0.000581  |    0.015328     |   2\n",
      "       1584 |   0.000679  |    0.050100     |   2\n",
      "       1585 |   0.389081  |    0.091989     |   1\n",
      "       1586 |   0.406000  |    0.020337     |   0\n",
      "       1587 |   0.378522  |    0.106624     |   1\n",
      "       1588 |   0.000552  |    0.005462     |   2\n",
      "       1589 |   0.000699  |    0.050076     |   2\n",
      "       1590 |   0.000804  |    0.010459     |   2\n",
      "       1591 |   0.385942  |    0.025564     |   0\n",
      "       1592 |   0.249444  |    0.064316     |   0\n",
      "       1593 |   0.363586  |    0.087429     |   1\n",
      "       1594 |   0.297965  |    0.008986     |   0\n",
      "       1595 |   0.000801  |    0.021568     |   2\n",
      "       1596 |   0.401996  |    0.135662     |   1\n",
      "       1597 |   0.280908  |    0.009334     |   0\n",
      "       1598 |   0.431799  |    0.079303     |   1\n",
      "       1599 |   0.384851  |    0.012070     |   0\n",
      "       1600 |   0.352428  |    0.028591     |   0\n",
      "       1601 |   0.332001  |    0.050337     |   0\n",
      "       1602 |   0.345669  |    0.011507     |   0\n",
      "       1603 |   0.437824  |    0.149694     |   1\n",
      "       1604 |   0.415789  |    0.041695     |   1\n",
      "       1605 |   0.129947  |    0.032942     |   2\n",
      "       1606 |   0.420325  |    0.083039     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 1608: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       1607 |   0.155401  |    0.011934     |   2\n",
      "       1608 |   0.340302  |    0.049830     |   0\n",
      "       1609 |   0.147236  |    0.012980     |   2\n",
      "       1610 |   0.114902  |    0.049681     |   2\n",
      "       1611 |   0.255577  |    0.109872     |   1\n",
      "       1612 |   0.454471  |    0.085122     |   1\n",
      "       1613 |   0.131768  |    0.036225     |   2\n",
      "       1614 |   0.324342  |    0.086894     |   1\n",
      "       1615 |   0.150749  |    0.012086     |   2\n",
      "       1616 |   0.338176  |    0.041731     |   0\n",
      "       1617 |   0.069802  |    0.012520     |   2\n",
      "       1618 |   0.326547  |    0.146452     |   1\n",
      "       1619 |   0.369865  |    0.049026     |   1\n",
      "       1620 |   0.345208  |    0.013859     |   0\n",
      "       1621 |   0.376457  |    0.148438     |   1\n",
      "       1622 |   0.126721  |    0.005498     |   2\n",
      "       1623 |   0.435627  |    0.052450     |   1\n",
      "       1624 |   0.399108  |    0.039259     |   0\n",
      "       1625 |   0.299031  |    0.015428     |   0\n",
      "       1626 |   0.296582  |    0.057617     |   0\n",
      "       1627 |   0.459967  |    0.071400     |   1\n",
      "       1628 |   0.420131  |    0.084859     |   1\n",
      "       1629 |   0.304120  |    0.014591     |   0\n",
      "       1630 |   0.410981  |    0.151768     |   1\n",
      "       1631 |   0.462440  |    0.063306     |   1\n",
      "       1632 |   0.124583  |    0.034481     |   2\n",
      "       1633 |   0.117523  |    0.017265     |   2\n",
      "       1634 |   0.394480  |    0.027029     |   0\n",
      "       1635 |   0.461470  |    0.114211     |   1\n",
      "       1636 |   0.111077  |    0.008352     |   2\n",
      "       1637 |   0.353211  |    0.043874     |   0\n",
      "       1638 |   0.050519  |    0.011263     |   2\n",
      "       1639 |   0.272237  |    0.046872     |   0\n",
      "       1640 |   0.265093  |    0.011788     |   0\n",
      "       1641 |   0.000579  |    0.046139     |   2\n",
      "       1642 |   0.472803  |    0.094400     |   1\n",
      "       1643 |   0.337513  |    0.106318     |   1\n",
      "       1644 |   0.016255  |    0.018008     |   2\n",
      "       1645 |   0.372586  |    0.154872     |   1\n",
      "       1646 |   0.214020  |    0.003117     |   2\n",
      "       1647 |   0.346571  |    0.025044     |   0\n",
      "       1648 |   0.370575  |    0.155560     |   1\n",
      "       1649 |   0.341013  |    0.031356     |   0\n",
      "       1650 |   0.400112  |    0.017046     |   1\n",
      "       1651 |   0.097991  |    0.010073     |   2\n",
      "       1652 |   0.343882  |    0.061484     |   0\n",
      "       1653 |   0.370476  |    0.071369     |   1\n",
      "       1654 |   0.410384  |    0.144476     |   1\n",
      "       1655 |   0.404395  |    0.043948     |   1\n",
      "       1656 |   0.445197  |    0.103489     |   1\n",
      "       1657 |   0.394520  |    0.066717     |   1\n",
      "       1658 |   0.245383  |    0.017875     |   0\n",
      "       1659 |   0.119557  |    0.059749     |   2\n",
      "       1660 |   0.467544  |    0.112731     |   1\n",
      "       1661 |   0.243609  |    0.049543     |   1\n",
      "       1662 |   0.274161  |    0.061618     |   0\n",
      "       1663 |   0.617501  |    0.063144     |   1\n",
      "       1664 |   0.331545  |    0.021737     |   0\n",
      "       1665 |   0.445974  |    0.096168     |   1\n",
      "       1666 |   0.096889  |    0.009927     |   2\n",
      "       1667 |   0.399939  |    0.158469     |   1\n",
      "       1668 |   0.428871  |    0.044682     |   1\n",
      "       1669 |   0.039445  |    0.010772     |   2\n",
      "       1670 |   0.304997  |    0.049229     |   0\n",
      "       1671 |   0.104274  |    0.009880     |   2\n",
      "       1672 |   0.342673  |    0.050279     |   0\n",
      "       1673 |   0.091727  |    0.006650     |   2\n",
      "       1674 |   0.374320  |    0.042819     |   0\n",
      "       1675 |   0.000498  |    0.027796     |   2\n",
      "       1676 |   0.328689  |    0.096281     |   1\n",
      "       1677 |   0.345657  |    0.029373     |   0\n",
      "       1678 |   0.000578  |    0.023761     |   2\n",
      "       1679 |   0.326998  |    0.036449     |   0\n",
      "       1680 |   0.499527  |    0.096991     |   1\n",
      "       1681 |   0.353504  |    0.057703     |   0\n",
      "       1682 |   0.375509  |    0.063401     |   1\n",
      "       1683 |   0.279710  |    0.107472     |   1\n",
      "       1684 |   0.000490  |    0.007648     |   2\n",
      "       1685 |   0.000600  |    0.031712     |   2\n",
      "       1686 |   0.338105  |    0.033712     |   0\n",
      "       1687 |   0.000672  |    0.036408     |   2\n",
      "       1688 |   0.378247  |    0.115089     |   1\n",
      "       1689 |   0.000701  |    0.024439     |   2\n",
      "       1690 |   0.401557  |    0.036717     |   1\n",
      "       1691 |   0.124249  |    0.016697     |   2\n",
      "       1692 |   0.149434  |    0.023434     |   2\n",
      "       1693 |   0.365401  |    0.047787     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 1694: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       1694 |   0.341765  |    0.029685     |   1\n",
      "       1695 |   0.347801  |    0.028161     |   0\n",
      "       1696 |   0.469491  |    0.155445     |   1\n",
      "       1697 |   0.377039  |    0.074426     |   1\n",
      "       1698 |   0.390735  |    0.051117     |   1\n",
      "       1699 |   0.334786  |    0.111080     |   1\n",
      "       1700 |   0.400110  |    0.085337     |   1\n",
      "       1701 |   0.133979  |    0.009638     |   2\n",
      "       1702 |   0.313196  |    0.033008     |   0\n",
      "       1703 |   0.269958  |    0.091089     |   1\n",
      "       1704 |   0.370108  |    0.012254     |   0\n",
      "       1705 |   0.377589  |    0.033014     |   0\n",
      "       1706 |   0.360171  |    0.039614     |   0\n",
      "       1707 |   0.333661  |    0.137621     |   1\n",
      "       1708 |   0.429305  |    0.036012     |   1\n",
      "       1709 |   0.398562  |    0.036071     |   0\n",
      "       1710 |   0.327058  |    0.080931     |   1\n",
      "       1711 |   0.333916  |    0.015002     |   0\n",
      "       1712 |   0.319402  |    0.046291     |   0\n",
      "       1713 |   0.103201  |    0.021232     |   2\n",
      "       1714 |   0.124619  |    0.028903     |   2\n",
      "       1715 |   0.152311  |    0.026034     |   2\n",
      "       1716 |   0.326851  |    0.040869     |   0\n",
      "       1717 |   0.068918  |    0.011756     |   2\n",
      "       1718 |   0.318504  |    0.160305     |   1\n",
      "       1719 |   0.306791  |    0.005608     |   0\n",
      "       1720 |   0.355903  |    0.098119     |   1\n",
      "       1721 |   0.415558  |    0.040516     |   1\n",
      "       1722 |   0.118753  |    0.042208     |   2\n",
      "       1723 |   0.319774  |    0.010179     |   0\n",
      "       1724 |   0.116437  |    0.053199     |   2\n",
      "       1725 |   0.351314  |    0.080171     |   1\n",
      "       1726 |   0.329433  |    0.023371     |   0\n",
      "       1727 |   0.114722  |    0.024843     |   2\n",
      "       1728 |   0.113312  |    0.031976     |   2\n",
      "       1729 |   0.053473  |    0.033595     |   2\n",
      "       1730 |   0.338757  |    0.103492     |   1\n",
      "       1731 |   0.432175  |    0.065260     |   1\n",
      "       1732 |   0.352580  |    0.136250     |   1\n",
      "       1733 |   0.379792  |    0.063252     |   1\n",
      "       1734 |   0.000533  |    0.022138     |   2\n",
      "       1735 |   0.329510  |    0.035928     |   0\n",
      "       1736 |   0.421060  |    0.084093     |   1\n",
      "       1737 |   0.014914  |    0.032979     |   2\n",
      "       1738 |   0.277889  |    0.094864     |   1\n",
      "       1739 |   0.381886  |    0.012985     |   0\n",
      "       1740 |   0.293575  |    0.031041     |   0\n",
      "       1741 |   0.295705  |    0.023707     |   0\n",
      "       1742 |   0.207443  |    0.027388     |   2\n",
      "       1743 |   0.097125  |    0.020302     |   2\n",
      "       1744 |   0.475371  |    0.106748     |   1\n",
      "       1745 |   0.118540  |    0.027387     |   2\n",
      "       1746 |   0.464789  |    0.106918     |   1\n",
      "       1747 |   0.372553  |    0.096659     |   1\n",
      "       1748 |   0.096619  |    0.012314     |   2\n",
      "       1749 |   0.350548  |    0.158061     |   1\n",
      "       1750 |   0.041822  |    0.007634     |   2\n",
      "       1751 |   0.339783  |    0.092373     |   1\n",
      "       1752 |   0.333011  |    0.009111     |   0\n",
      "       1753 |   0.403778  |    0.115850     |   1\n",
      "       1754 |   0.331589  |    0.092611     |   1\n",
      "       1755 |   0.381796  |    0.061466     |   1\n",
      "       1756 |   0.346329  |    0.028116     |   0\n",
      "       1757 |   0.325179  |    0.025234     |   0\n",
      "       1758 |   0.305689  |    0.123946     |   1\n",
      "       1759 |   0.348455  |    0.086997     |   1\n",
      "       1760 |   0.440636  |    0.086094     |   1\n",
      "       1761 |   0.368976  |    0.110057     |   1\n",
      "       1762 |   0.111435  |    0.006070     |   2\n",
      "       1763 |   0.340756  |    0.130767     |   1\n",
      "       1764 |   0.345448  |    0.010333     |   0\n",
      "       1765 |   0.443552  |    0.051813     |   1\n",
      "       1766 |   0.091951  |    0.007777     |   2\n",
      "       1767 |   0.282350  |    0.039595     |   0\n",
      "       1768 |   0.385191  |    0.032666     |   0\n",
      "       1769 |   0.298754  |    0.131744     |   1\n",
      "       1770 |   0.400572  |    0.060250     |   1\n",
      "       1771 |   0.293973  |    0.033885     |   0\n",
      "       1772 |   0.000458  |    0.023634     |   2\n",
      "       1773 |   0.364337  |    0.033276     |   0\n",
      "       1774 |   0.367345  |    0.138558     |   1\n",
      "       1775 |   0.000538  |    0.007528     |   2\n",
      "       1776 |   0.338442  |    0.074791     |   1\n",
      "       1777 |   0.339726  |    0.019799     |   0\n",
      "       1778 |   0.431556  |    0.150694     |   1\n",
      "       1779 |   0.320188  |    0.012727     |   0\n",
      "       1780 |   0.429754  |    0.048404     |   1\n",
      "       1781 |   0.000466  |    0.008427     |   2\n",
      "       1782 |   0.273679  |    0.029364     |   0\n",
      "       1783 |   0.352180  |    0.095266     |   1\n",
      "       1784 |   0.000575  |    0.011629     |   2\n",
      "       1785 |   0.376412  |    0.045743     |   0\n",
      "       1786 |   0.000635  |    0.007443     |   2\n",
      "       1787 |   0.302883  |    0.043605     |   0\n",
      "       1788 |   0.364366  |    0.086958     |   1\n",
      "       1789 |   0.000685  |    0.039813     |   2\n",
      "       1790 |   0.310642  |    0.170805     |   1\n",
      "       1791 |   0.124396  |    0.006708     |   2\n",
      "       1792 |   0.337117  |    0.086388     |   1\n",
      "       1793 |   0.150985  |    0.012937     |   2\n",
      "       1794 |   0.284424  |    0.140804     |   1\n",
      "       1795 |   0.472590  |    0.067075     |   1\n",
      "       1796 |   0.334239  |    0.099062     |   1\n",
      "       1797 |   0.423895  |    0.092345     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 1798: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       1798 |   0.397833  |    0.090110     |   1\n",
      "       1799 |   0.294711  |    0.012378     |   0\n",
      "       1800 |   0.133226  |    0.029285     |   2\n",
      "       1801 |   0.359480  |    0.093897     |   1\n",
      "       1802 |   0.103987  |    0.019951     |   2\n",
      "       1803 |   0.406488  |    0.101435     |   1\n",
      "       1804 |   0.284802  |    0.025181     |   0\n",
      "       1805 |   0.120375  |    0.035104     |   2\n",
      "       1806 |   0.373290  |    0.076348     |   1\n",
      "       1807 |   0.363497  |    0.049434     |   0\n",
      "       1808 |   0.317999  |    0.074882     |   1\n",
      "       1809 |   0.143372  |    0.011648     |   2\n",
      "       1810 |   0.249736  |    0.034414     |   0\n",
      "       1811 |   0.065199  |    0.021023     |   2\n",
      "       1812 |   0.115004  |    0.045569     |   2\n",
      "       1813 |   0.110747  |    0.008652     |   2\n",
      "       1814 |   0.114414  |    0.053194     |   2\n",
      "       1815 |   0.106709  |    0.008906     |   2\n",
      "       1816 |   0.049245  |    0.038030     |   2\n",
      "       1817 |   0.334145  |    0.107326     |   1\n",
      "       1818 |   0.000461  |    0.018588     |   2\n",
      "       1819 |   0.412621  |    0.135224     |   1\n",
      "       1820 |   0.315336  |    0.010747     |   0\n",
      "       1821 |   0.379479  |    0.133953     |   1\n",
      "       1822 |   0.014702  |    0.006905     |   2\n",
      "       1823 |   0.326909  |    0.044515     |   0\n",
      "       1824 |   0.203071  |    0.011527     |   2\n",
      "       1825 |   0.089951  |    0.030937     |   2\n",
      "       1826 |   0.344969  |    0.014232     |   0\n",
      "       1827 |   0.373387  |    0.052205     |   0\n",
      "       1828 |   0.392988  |    0.081068     |   1\n",
      "       1829 |   0.323164  |    0.021106     |   0\n",
      "       1830 |   0.116048  |    0.027822     |   2\n",
      "       1831 |   0.305139  |    0.081010     |   1\n",
      "       1832 |   0.267360  |    0.023792     |   0\n",
      "       1833 |   0.093016  |    0.025119     |   2\n",
      "       1834 |   0.363520  |    0.146949     |   1\n",
      "       1835 |   0.415593  |    0.049429     |   1\n",
      "       1836 |   0.241459  |    0.024920     |   0\n",
      "       1837 |   0.038719  |    0.024286     |   2\n",
      "       1838 |   0.409669  |    0.031078     |   0\n",
      "       1839 |   0.409397  |    0.094280     |   1\n",
      "       1840 |   0.331140  |    0.029400     |   0\n",
      "       1841 |   0.103066  |    0.030325     |   2\n",
      "       1842 |   0.088537  |    0.027112     |   2\n",
      "       1843 |   0.370349  |    0.166698     |   1\n",
      "       1844 |   0.307346  |    0.034327     |   1\n",
      "       1845 |   0.247572  |    0.008537     |   0\n",
      "       1846 |   0.293951  |    0.028081     |   0\n",
      "       1847 |   0.000439  |    0.036140     |   2\n",
      "       1848 |   0.000524  |    0.013243     |   2\n",
      "       1849 |   0.377064  |    0.039448     |   0\n",
      "       1850 |   0.336308  |    0.037153     |   0\n",
      "       1851 |   0.295164  |    0.094311     |   1\n",
      "       1852 |   0.000441  |    0.021009     |   2\n",
      "       1853 |   0.231212  |    0.031044     |   0\n",
      "       1854 |   0.293967  |    0.095959     |   1\n",
      "       1855 |   0.000554  |    0.021931     |   2\n",
      "       1856 |   0.000610  |    0.038258     |   2\n",
      "       1857 |   0.427962  |    0.091443     |   1\n",
      "       1858 |   0.436305  |    0.086014     |   1\n",
      "       1859 |   0.323793  |    0.015906     |   0\n",
      "       1860 |   0.000664  |    0.029478     |   2\n",
      "       1861 |   0.288073  |    0.032069     |   0\n",
      "       1862 |   0.301738  |    0.020880     |   0\n",
      "       1863 |   0.122406  |    0.020512     |   2\n",
      "       1864 |   0.337742  |    0.040089     |   0\n",
      "       1865 |   0.307742  |    0.025576     |   0\n",
      "       1866 |   0.145040  |    0.034223     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 1867: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       1867 |   0.312797  |    0.093314     |   1\n",
      "       1868 |   0.138693  |    0.004627     |   2\n",
      "       1869 |   0.106613  |    0.011369     |   2\n",
      "       1870 |   0.309514  |    0.145902     |   1\n",
      "       1871 |   0.122739  |    0.009478     |   2\n",
      "       1872 |   0.309789  |    0.013990     |   0\n",
      "       1873 |   0.406293  |    0.149533     |   1\n",
      "       1874 |   0.338117  |    0.084076     |   1\n",
      "       1875 |   0.292428  |    0.074569     |   1\n",
      "       1876 |   0.342423  |    0.090241     |   1\n",
      "       1877 |   0.268049  |    0.009030     |   0\n",
      "       1878 |   0.340109  |    0.017869     |   0\n",
      "       1879 |   0.314140  |    0.057564     |   0\n",
      "       1880 |   0.294590  |    0.100217     |   1\n",
      "       1881 |   0.145623  |    0.009553     |   2\n",
      "       1882 |   0.334021  |    0.042892     |   0\n",
      "       1883 |   0.068380  |    0.011933     |   2\n",
      "       1884 |   0.456732  |    0.145596     |   1\n",
      "       1885 |   0.114944  |    0.003417     |   2\n",
      "       1886 |   0.114119  |    0.010076     |   2\n",
      "       1887 |   0.387003  |    0.032727     |   0\n",
      "       1888 |   0.111052  |    0.015252     |   2\n",
      "       1889 |   0.300716  |    0.048987     |   0\n",
      "       1890 |   0.310220  |    0.014738     |   0\n",
      "       1891 |   0.108936  |    0.031042     |   2\n",
      "       1892 |   0.287458  |    0.033442     |   0\n",
      "       1893 |   0.389963  |    0.136428     |   1\n",
      "       1894 |   0.048609  |    0.003662     |   2\n",
      "       1895 |   0.000450  |    0.010505     |   2\n",
      "       1896 |   0.285589  |    0.047301     |   0\n",
      "       1897 |   0.323580  |    0.016415     |   0\n",
      "       1898 |   0.358139  |    0.047189     |   0\n",
      "       1899 |   0.016600  |    0.006162     |   2\n",
      "       1900 |   0.202944  |    0.049845     |   2\n",
      "       1901 |   0.265559  |    0.094628     |   1\n",
      "       1902 |   0.384596  |    0.079886     |   1\n",
      "       1903 |   0.091822  |    0.006367     |   2\n",
      "       1904 |   0.118301  |    0.028345     |   2\n",
      "       1905 |   0.446602  |    0.142438     |   1\n",
      "       1906 |   0.368724  |    0.086052     |   1\n",
      "       1907 |   0.272999  |    0.066075     |   1\n",
      "       1908 |   0.290457  |    0.031768     |   0\n",
      "       1909 |   0.300618  |    0.032761     |   0\n",
      "       1910 |   0.400179  |    0.092496     |   1\n",
      "       1911 |   0.278964  |    0.037755     |   0\n",
      "       1912 |   0.306248  |    0.141401     |   1\n",
      "       1913 |   0.349715  |    0.067328     |   1\n",
      "       1914 |   0.096312  |    0.026728     |   2\n",
      "       1915 |   0.274668  |    0.103269     |   1\n",
      "       1916 |   0.039352  |    0.014854     |   2\n",
      "       1917 |   0.106553  |    0.030756     |   2\n",
      "       1918 |   0.087819  |    0.036956     |   2\n",
      "       1919 |   0.000391  |    0.023442     |   2\n",
      "       1920 |   0.322434  |    0.026658     |   0\n",
      "       1921 |   0.257220  |    0.040336     |   0\n",
      "       1922 |   0.389077  |    0.088734     |   1\n",
      "       1923 |   0.000457  |    0.016058     |   2\n",
      "       1924 |   0.331999  |    0.133280     |   1\n",
      "       1925 |   0.352844  |    0.082839     |   1\n",
      "       1926 |   0.000397  |    0.007296     |   2\n",
      "       1927 |   0.000487  |    0.030687     |   2\n",
      "       1928 |   0.000532  |    0.008774     |   2\n",
      "       1929 |   0.277246  |    0.041197     |   0\n",
      "       1930 |   0.262877  |    0.015530     |   0\n",
      "       1931 |   0.000570  |    0.037406     |   2\n",
      "       1932 |   0.115554  |    0.008905     |   2\n",
      "       1933 |   0.141412  |    0.060458     |   2\n",
      "       1934 |   0.385478  |    0.094611     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 1935: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       1935 |   0.385442  |    0.060333     |   1\n",
      "       1936 |   0.348850  |    0.026673     |   0\n",
      "       1937 |   0.320165  |    0.035024     |   0\n",
      "       1938 |   0.423136  |    0.087190     |   1\n",
      "       1939 |   0.134804  |    0.016523     |   2\n",
      "       1940 |   0.102855  |    0.033503     |   2\n",
      "       1941 |   0.368990  |    0.152229     |   1\n",
      "       1942 |   0.120973  |    0.011212     |   2\n",
      "       1943 |   0.341228  |    0.082822     |   1\n",
      "       1944 |   0.343205  |    0.030075     |   0\n",
      "       1945 |   0.375400  |    0.085227     |   1\n",
      "       1946 |   0.139665  |    0.030035     |   2\n",
      "       1947 |   0.309317  |    0.033743     |   0\n",
      "       1948 |   0.333159  |    0.028593     |   0\n",
      "       1949 |   0.065166  |    0.025850     |   2\n",
      "       1950 |   0.354486  |    0.057012     |   0\n",
      "       1951 |   0.358533  |    0.089192     |   1\n",
      "       1952 |   0.331086  |    0.010464     |   0\n",
      "       1953 |   0.113683  |    0.050720     |   2\n",
      "       1954 |   0.371200  |    0.081864     |   1\n",
      "       1955 |   0.113156  |    0.024386     |   2\n",
      "       1956 |   0.337388  |    0.025045     |   0\n",
      "       1957 |   0.110023  |    0.027184     |   2\n",
      "       1958 |   0.104887  |    0.039309     |   2\n",
      "       1959 |   0.442697  |    0.092584     |   1\n",
      "       1960 |   0.294193  |    0.139652     |   1\n",
      "       1961 |   0.047176  |    0.003126     |   2\n",
      "       1962 |   0.000420  |    0.008123     |   2\n",
      "       1963 |   0.015130  |    0.038971     |   2\n",
      "       1964 |   0.336705  |    0.011983     |   0\n",
      "       1965 |   0.272727  |    0.048859     |   0\n",
      "       1966 |   0.198178  |    0.012217     |   2\n",
      "       1967 |   0.091283  |    0.055436     |   2\n",
      "       1968 |   0.399272  |    0.100313     |   1\n",
      "       1969 |   0.301203  |    0.008451     |   0\n",
      "       1970 |   0.315823  |    0.109824     |   1\n",
      "       1971 |   0.398320  |    0.056514     |   1\n",
      "       1972 |   0.396519  |    0.094181     |   1\n",
      "       1973 |   0.441876  |    0.086738     |   1\n",
      "       1974 |   0.112795  |    0.004223     |   2\n",
      "       1975 |   0.312946  |    0.043584     |   0\n",
      "       1976 |   0.337193  |    0.018878     |   0\n",
      "       1977 |   0.092197  |    0.024104     |   2\n",
      "       1978 |   0.312716  |    0.051401     |   0\n",
      "       1979 |   0.352122  |    0.114944     |   1\n",
      "       1980 |   0.339890  |    0.060198     |   1\n",
      "       1981 |   0.038522  |    0.027305     |   2\n",
      "       1982 |   0.347933  |    0.137672     |   1\n",
      "       1983 |   0.323177  |    0.003456     |   0\n",
      "       1984 |   0.105271  |    0.023722     |   2\n",
      "       1985 |   0.352586  |    0.104660     |   1\n",
      "       1986 |   0.086826  |    0.013499     |   2\n",
      "       1987 |   0.000384  |    0.033213     |   2\n",
      "       1988 |   0.339955  |    0.033512     |   0\n",
      "       1989 |   0.322451  |    0.145565     |   1\n",
      "       1990 |   0.335654  |    0.008100     |   0\n",
      "       1991 |   0.353060  |    0.007640     |   0\n",
      "       1992 |   0.322814  |    0.168123     |   1\n",
      "       1993 |   0.327385  |    0.042053     |   1\n",
      "       1994 |   0.320578  |    0.083288     |   1\n",
      "       1995 |   0.000456  |    0.006903     |   2\n",
      "       1996 |   0.290798  |    0.042770     |   0\n",
      "       1997 |   0.322266  |    0.016268     |   0\n",
      "       1998 |   0.000385  |    0.055420     |   2\n",
      "       1999 |   0.331182  |    0.077259     |   1\n",
      "       2000 |   0.352551  |    0.166183     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 2000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 2000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       2001 |   0.129087  |    0.050928     |   2\n",
      "       2002 |   0.250846  |    0.021143     |   0\n",
      "       2003 |   0.380947  |    0.126730     |   1\n",
      "       2004 |   0.280466  |    0.024929     |   0\n",
      "       2005 |   0.335788  |    0.146130     |   1\n",
      "       2006 |   0.293517  |    0.028003     |   0\n",
      "       2007 |   0.105710  |    0.043232     |   2\n",
      "       2008 |   0.282993  |    0.040751     |   0\n",
      "       2009 |   0.113309  |    0.016961     |   2\n",
      "       2010 |   0.137119  |    0.034979     |   2\n",
      "       2011 |   0.314934  |    0.132667     |   1\n",
      "       2012 |   0.307117  |    0.007658     |   0\n",
      "       2013 |   0.268629  |    0.098415     |   1\n",
      "       2014 |   0.206406  |    0.006242     |   0\n",
      "       2015 |   0.400548  |    0.042462     |   0\n",
      "       2016 |   0.249841  |    0.025422     |   0\n",
      "       2017 |   0.336461  |    0.046858     |   0\n",
      "       2018 |   0.063822  |    0.016876     |   2\n",
      "       2019 |   0.307545  |    0.130342     |   1\n",
      "       2020 |   0.114520  |    0.024637     |   2\n",
      "       2021 |   0.398467  |    0.136988     |   1\n",
      "       2022 |   0.115782  |    0.008169     |   2\n",
      "       2023 |   0.108476  |    0.010127     |   2\n",
      "       2024 |   0.361766  |    0.145629     |   1\n",
      "       2025 |   0.328475  |    0.082569     |   1\n",
      "       2026 |   0.309419  |    0.007251     |   0\n",
      "       2027 |   0.319909  |    0.046548     |   0\n",
      "       2028 |   0.104962  |    0.015930     |   2\n",
      "       2029 |   0.048024  |    0.045134     |   2\n",
      "       2030 |   0.271454  |    0.019669     |   0\n",
      "       2031 |   0.294113  |    0.036726     |   0\n",
      "       2032 |   0.000423  |    0.009927     |   2\n",
      "       2033 |   0.231280  |    0.048725     |   0\n",
      "       2034 |   0.013436  |    0.007126     |   2\n",
      "       2035 |   0.195384  |    0.052607     |   2\n",
      "       2036 |   0.312549  |    0.011064     |   0\n",
      "       2037 |   0.089558  |    0.041892     |   2\n",
      "       2038 |   0.364361  |    0.145068     |   1\n",
      "       2039 |   0.387759  |    0.086928     |   1\n",
      "       2040 |   0.244729  |    0.010293     |   0\n",
      "       2041 |   0.319984  |    0.015570     |   0\n",
      "       2042 |   0.115547  |    0.048411     |   2\n",
      "       2043 |   0.091485  |    0.012364     |   2\n",
      "       2044 |   0.277124  |    0.135342     |   1\n",
      "       2045 |   0.459984  |    0.137289     |   1\n",
      "       2046 |   0.244965  |    0.003780     |   0\n",
      "       2047 |   0.038730  |    0.006452     |   2\n",
      "       2048 |   0.109360  |    0.040857     |   2\n",
      "       2049 |   0.086748  |    0.017910     |   2\n",
      "       2050 |   0.000358  |    0.066089     |   2\n",
      "       2051 |   0.341347  |    0.085866     |   1\n",
      "       2052 |   0.000425  |    0.006171     |   2\n",
      "       2053 |   0.278168  |    0.043192     |   0\n",
      "       2054 |   0.000362  |    0.025649     |   2\n",
      "       2055 |   0.342524  |    0.052274     |   0\n",
      "       2056 |   0.286681  |    0.062238     |   1\n",
      "       2057 |   0.304905  |    0.029636     |   0\n",
      "       2058 |   0.000448  |    0.020401     |   2\n",
      "       2059 |   0.289726  |    0.031681     |   0\n",
      "       2060 |   0.271671  |    0.029017     |   0\n",
      "       2061 |   0.288090  |    0.025650     |   0\n",
      "       2062 |   0.285834  |    0.032472     |   0\n",
      "       2063 |   0.278365  |    0.016297     |   0\n",
      "       2064 |   0.000487  |    0.044742     |   2\n",
      "       2065 |   0.000557  |    0.015415     |   2\n",
      "       2066 |   0.123431  |    0.034555     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 2068: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       2067 |   0.139228  |    0.042908     |   2\n",
      "       2068 |   0.128923  |    0.007007     |   2\n",
      "       2069 |   0.278494  |    0.048051     |   0\n",
      "       2070 |   0.338348  |    0.080728     |   1\n",
      "       2071 |   0.318726  |    0.024812     |   0\n",
      "       2072 |   0.340368  |    0.136324     |   1\n",
      "       2073 |   0.374093  |    0.101247     |   1\n",
      "       2074 |   0.297614  |    0.091650     |   1\n",
      "       2075 |   0.280910  |    0.030351     |   0\n",
      "       2076 |   0.343033  |    0.149893     |   1\n",
      "       2077 |   0.297013  |    0.010131     |   0\n",
      "       2078 |   0.325616  |    0.055241     |   1\n",
      "       2079 |   0.098153  |    0.035323     |   2\n",
      "       2080 |   0.111435  |    0.027435     |   2\n",
      "       2081 |   0.141195  |    0.028605     |   2\n",
      "       2082 |   0.305817  |    0.038504     |   0\n",
      "       2083 |   0.290117  |    0.021291     |   0\n",
      "       2084 |   0.063636  |    0.042783     |   2\n",
      "       2085 |   0.113346  |    0.038996     |   2\n",
      "       2086 |   0.360231  |    0.134740     |   1\n",
      "       2087 |   0.112075  |    0.006906     |   2\n",
      "       2088 |   0.106669  |    0.058479     |   2\n",
      "       2089 |   0.297045  |    0.087798     |   1\n",
      "       2090 |   0.429682  |    0.130447     |   1\n",
      "       2091 |   0.323365  |    0.072546     |   1\n",
      "       2092 |   0.104490  |    0.013935     |   2\n",
      "       2093 |   0.326892  |    0.049561     |   0\n",
      "       2094 |   0.047117  |    0.008194     |   2\n",
      "       2095 |   0.231496  |    0.049554     |   0\n",
      "       2096 |   0.364815  |    0.084452     |   1\n",
      "       2097 |   0.308853  |    0.009497     |   0\n",
      "       2098 |   0.234807  |    0.039349     |   0\n",
      "       2099 |   0.288822  |    0.141413     |   1\n",
      "       2100 |   0.311991  |    0.005231     |   0\n",
      "       2101 |   0.213107  |    0.005649     |   0\n",
      "       2102 |   0.305564  |    0.046269     |   0\n",
      "       2103 |   0.293709  |    0.009703     |   0\n",
      "       2104 |   0.229736  |    0.045096     |   0\n",
      "       2105 |   0.000382  |    0.005176     |   2\n",
      "       2106 |   0.285805  |    0.041909     |   0\n",
      "       2107 |   0.260684  |    0.014900     |   0\n",
      "       2108 |   0.367401  |    0.039412     |   0\n",
      "       2109 |   0.014540  |    0.020432     |   2\n",
      "       2110 |   0.325388  |    0.153618     |   1\n",
      "       2111 |   0.294963  |    0.012097     |   0\n",
      "       2112 |   0.375300  |    0.081778     |   1\n",
      "       2113 |   0.190439  |    0.033286     |   2\n",
      "       2114 |   0.246749  |    0.160958     |   1\n",
      "       2115 |   0.087522  |    0.003627     |   2\n",
      "       2116 |   0.399102  |    0.089174     |   1\n",
      "       2117 |   0.118343  |    0.005014     |   2\n",
      "       2118 |   0.307450  |    0.041343     |   0\n",
      "       2119 |   0.304543  |    0.023530     |   0\n",
      "       2120 |   0.335274  |    0.139540     |   1\n",
      "       2121 |   0.258072  |    0.002935     |   0\n",
      "       2122 |   0.090707  |    0.009838     |   2\n",
      "       2123 |   0.039641  |    0.042010     |   2\n",
      "       2124 |   0.320908  |    0.017420     |   0\n",
      "       2125 |   0.109146  |    0.056864     |   2\n",
      "       2126 |   0.291495  |    0.073280     |   1\n",
      "       2127 |   0.389387  |    0.088818     |   1\n",
      "       2128 |   0.085206  |    0.003419     |   2\n",
      "       2129 |   0.000326  |    0.026448     |   2\n",
      "       2130 |   0.337015  |    0.042675     |   0\n",
      "       2131 |   0.282473  |    0.041382     |   0\n",
      "       2132 |   0.322624  |    0.025232     |   0\n",
      "       2133 |   0.372764  |    0.142176     |   1\n",
      "       2134 |   0.304567  |    0.002947     |   0\n",
      "       2135 |   0.352013  |    0.015789     |   0\n",
      "       2136 |   0.000391  |    0.027507     |   2\n",
      "       2137 |   0.445941  |    0.129644     |   1\n",
      "       2138 |   0.363823  |    0.002895     |   0\n",
      "       2139 |   0.270631  |    0.007037     |   0\n",
      "       2140 |   0.343986  |    0.046823     |   0\n",
      "       2141 |   0.291719  |    0.019899     |   0\n",
      "       2142 |   0.322083  |    0.052596     |   0\n",
      "       2143 |   0.000340  |    0.011190     |   2\n",
      "       2144 |   0.000418  |    0.031180     |   2\n",
      "       2145 |   0.391561  |    0.130677     |   1\n",
      "       2146 |   0.000457  |    0.007774     |   2\n",
      "       2147 |   0.305786  |    0.025156     |   0\n",
      "       2148 |   0.256139  |    0.030200     |   0\n",
      "       2149 |   0.225227  |    0.028139     |   0\n",
      "       2150 |   0.307769  |    0.050345     |   0\n",
      "       2151 |   0.266974  |    0.008711     |   0\n",
      "       2152 |   0.281624  |    0.065854     |   0\n",
      "       2153 |   0.320241  |    0.086285     |   1\n",
      "       2154 |   0.426225  |    0.143256     |   1\n",
      "       2155 |   0.000516  |    0.020699     |   2\n",
      "       2156 |   0.472926  |    0.098500     |   1\n",
      "       2157 |   0.118235  |    0.017498     |   2\n",
      "       2158 |   0.140717  |    0.026505     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 2160: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       2159 |   0.240107  |    0.031733     |   0\n",
      "       2160 |   0.129617  |    0.022457     |   2\n",
      "       2161 |   0.100253  |    0.020232     |   2\n",
      "       2162 |   0.108544  |    0.033316     |   2\n",
      "       2163 |   0.267079  |    0.036368     |   0\n",
      "       2164 |   0.138994  |    0.024520     |   2\n",
      "       2165 |   0.240380  |    0.022940     |   0\n",
      "       2166 |   0.269827  |    0.040268     |   0\n",
      "       2167 |   0.061050  |    0.018735     |   2\n",
      "       2168 |   0.369735  |    0.112452     |   1\n",
      "       2169 |   0.390366  |    0.085453     |   1\n",
      "       2170 |   0.330554  |    0.019478     |   0\n",
      "       2171 |   0.113821  |    0.031996     |   2\n",
      "       2172 |   0.356959  |    0.026580     |   0\n",
      "       2173 |   0.311860  |    0.044834     |   0\n",
      "       2174 |   0.112690  |    0.013385     |   2\n",
      "       2175 |   0.332783  |    0.132959     |   1\n",
      "       2176 |   0.271191  |    0.006939     |   0\n",
      "       2177 |   0.279378  |    0.021004     |   0\n",
      "       2178 |   0.107596  |    0.026782     |   2\n",
      "       2179 |   0.099374  |    0.025451     |   2\n",
      "       2180 |   0.320270  |    0.139212     |   1\n",
      "       2181 |   0.045134  |    0.008045     |   2\n",
      "       2182 |   0.323048  |    0.075038     |   1\n",
      "       2183 |   0.319821  |    0.028277     |   0\n",
      "       2184 |   0.287892  |    0.154037     |   1\n",
      "       2185 |   0.405524  |    0.050107     |   1\n",
      "       2186 |   0.328184  |    0.100437     |   1\n",
      "       2187 |   0.325886  |    0.145717     |   1\n",
      "       2188 |   0.414510  |    0.089509     |   1\n",
      "       2189 |   0.266142  |    0.089280     |   1\n",
      "       2190 |   0.271883  |    0.152651     |   1\n",
      "       2191 |   0.282442  |    0.003182     |   0\n",
      "       2192 |   0.000347  |    0.013913     |   2\n",
      "       2193 |   0.335877  |    0.141064     |   1\n",
      "       2194 |   0.013753  |    0.003503     |   2\n",
      "       2195 |   0.337651  |    0.142318     |   1\n",
      "       2196 |   0.368081  |    0.056583     |   1\n",
      "       2197 |   0.186420  |    0.016351     |   2\n",
      "       2198 |   0.086927  |    0.031693     |   2\n",
      "       2199 |   0.261938  |    0.029990     |   0\n",
      "       2200 |   0.105051  |    0.030305     |   2\n",
      "       2201 |   0.271269  |    0.134180     |   1\n",
      "       2202 |   0.355273  |    0.011499     |   0\n",
      "       2203 |   0.334905  |    0.107408     |   1\n",
      "       2204 |   0.345730  |    0.137147     |   1\n",
      "       2205 |   0.286765  |    0.003219     |   0\n",
      "       2206 |   0.086093  |    0.008151     |   2\n",
      "       2207 |   0.343853  |    0.047658     |   0\n",
      "       2208 |   0.036311  |    0.010855     |   2\n",
      "       2209 |   0.101796  |    0.056809     |   2\n",
      "       2210 |   0.383462  |    0.094478     |   1\n",
      "       2211 |   0.277788  |    0.092134     |   1\n",
      "       2212 |   0.084896  |    0.015162     |   2\n",
      "       2213 |   0.375391  |    0.144984     |   1\n",
      "       2214 |   0.258821  |    0.002901     |   0\n",
      "       2215 |   0.000284  |    0.004926     |   2\n",
      "       2216 |   0.000346  |    0.027103     |   2\n",
      "       2217 |   0.243448  |    0.029058     |   0\n",
      "       2218 |   0.000317  |    0.030471     |   2\n",
      "       2219 |   0.311509  |    0.014287     |   0\n",
      "       2220 |   0.336998  |    0.050938     |   0\n",
      "       2221 |   0.000398  |    0.008213     |   2\n",
      "       2222 |   0.000431  |    0.051004     |   2\n",
      "       2223 |   0.316910  |    0.038042     |   0\n",
      "       2224 |   0.355319  |    0.139431     |   1\n",
      "       2225 |   0.286152  |    0.002893     |   0\n",
      "       2226 |   0.000486  |    0.007959     |   2\n",
      "       2227 |   0.114273  |    0.031277     |   2\n",
      "       2228 |   0.208991  |    0.048483     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 2230: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       2229 |   0.137338  |    0.008559     |   2\n",
      "       2230 |   0.326941  |    0.030207     |   0\n",
      "       2231 |   0.126503  |    0.025845     |   2\n",
      "       2232 |   0.100107  |    0.027983     |   2\n",
      "       2233 |   0.259333  |    0.145130     |   1\n",
      "       2234 |   0.361928  |    0.005721     |   0\n",
      "       2235 |   0.363793  |    0.028147     |   0\n",
      "       2236 |   0.364504  |    0.144209     |   1\n",
      "       2237 |   0.106334  |    0.003249     |   2\n",
      "       2238 |   0.140162  |    0.010110     |   2\n",
      "       2239 |   0.061526  |    0.033648     |   2\n",
      "       2240 |   0.401146  |    0.157870     |   1\n",
      "       2241 |   0.108152  |    0.003180     |   2\n",
      "       2242 |   0.315767  |    0.018876     |   0\n",
      "       2243 |   0.351052  |    0.098727     |   1\n",
      "       2244 |   0.354793  |    0.153239     |   1\n",
      "       2245 |   0.107003  |    0.007960     |   2\n",
      "       2246 |   0.376175  |    0.053015     |   1\n",
      "       2247 |   0.107487  |    0.025443     |   2\n",
      "       2248 |   0.096457  |    0.032936     |   2\n",
      "       2249 |   0.043048  |    0.011621     |   2\n",
      "       2250 |   0.426057  |    0.163799     |   1\n",
      "       2251 |   0.349154  |    0.054324     |   1\n",
      "       2252 |   0.317020  |    0.102073     |   1\n",
      "       2253 |   0.000329  |    0.014804     |   2\n",
      "       2254 |   0.418260  |    0.142512     |   1\n",
      "       2255 |   0.276189  |    0.014498     |   1\n",
      "       2256 |   0.315959  |    0.044483     |   0\n",
      "       2257 |   0.014062  |    0.012107     |   2\n",
      "       2258 |   0.318844  |    0.045359     |   0\n",
      "       2259 |   0.406323  |    0.093809     |   1\n",
      "       2260 |   0.184440  |    0.011893     |   2\n",
      "       2261 |   0.294280  |    0.030204     |   0\n",
      "       2262 |   0.083922  |    0.009531     |   2\n",
      "       2263 |   0.104130  |    0.031792     |   2\n",
      "       2264 |   0.080394  |    0.018438     |   2\n",
      "       2265 |   0.036096  |    0.033087     |   2\n",
      "       2266 |   0.268161  |    0.038274     |   0\n",
      "       2267 |   0.096121  |    0.023941     |   2\n",
      "       2268 |   0.082800  |    0.023833     |   2\n",
      "       2269 |   0.245903  |    0.039619     |   0\n",
      "       2270 |   0.253041  |    0.014387     |   0\n",
      "       2271 |   0.000272  |    0.039672     |   2\n",
      "       2272 |   0.321872  |    0.069706     |   1\n",
      "       2273 |   0.277427  |    0.017548     |   0\n",
      "       2274 |   0.000340  |    0.030764     |   2\n",
      "       2275 |   0.000298  |    0.015391     |   2\n",
      "       2276 |   0.328903  |    0.059218     |   0\n",
      "       2277 |   0.313594  |    0.150215     |   1\n",
      "       2278 |   0.339001  |    0.041118     |   1\n",
      "       2279 |   0.000388  |    0.031674     |   2\n",
      "       2280 |   0.000398  |    0.018146     |   2\n",
      "       2281 |   0.000431  |    0.032044     |   2\n",
      "       2282 |   0.108813  |    0.012080     |   2\n",
      "       2283 |   0.132939  |    0.054165     |   2\n",
      "       2284 |   0.265381  |    0.101546     |   1\n",
      "       2285 |   0.380608  |    0.095974     |   1\n",
      "       2286 |   0.303452  |    0.096302     |   1\n",
      "       2287 |   0.236751  |    0.013336     |   0\n",
      "       2288 |   0.363767  |    0.086796     |   1\n",
      "       2289 |   0.296460  |    0.024745     |   0\n",
      "       2290 |   0.305767  |    0.145798     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 2291: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       2291 |   0.323651  |    0.003477     |   0\n",
      "       2292 |   0.119815  |    0.015712     |   2\n",
      "       2293 |   0.303103  |    0.155285     |   1\n",
      "       2294 |   0.366345  |    0.051669     |   1\n",
      "       2295 |   0.300689  |    0.012683     |   0\n",
      "       2296 |   0.335696  |    0.048980     |   0\n",
      "       2297 |   0.095675  |    0.016519     |   2\n",
      "       2298 |   0.316452  |    0.155182     |   1\n",
      "       2299 |   0.297587  |    0.064657     |   1\n",
      "       2300 |   0.104013  |    0.007345     |   2\n",
      "       2301 |   0.274779  |    0.046141     |   0\n",
      "       2302 |   0.334934  |    0.020893     |   0\n",
      "       2303 |   0.259798  |    0.031900     |   0\n",
      "       2304 |   0.132085  |    0.010379     |   2\n",
      "       2305 |   0.058456  |    0.055621     |   2\n",
      "       2306 |   0.425865  |    0.100231     |   1\n",
      "       2307 |   0.414787  |    0.054406     |   1\n",
      "       2308 |   0.105577  |    0.008980     |   2\n",
      "       2309 |   0.261670  |    0.070644     |   0\n",
      "       2310 |   0.338489  |    0.033265     |   1\n",
      "       2311 |   0.354741  |    0.041583     |   0\n",
      "       2312 |   0.350764  |    0.058621     |   1\n",
      "       2313 |   0.284818  |    0.134849     |   1\n",
      "       2314 |   0.101051  |    0.005021     |   2\n",
      "       2315 |   0.102004  |    0.010078     |   2\n",
      "       2316 |   0.094086  |    0.051717     |   2\n",
      "       2317 |   0.288600  |    0.085319     |   1\n",
      "       2318 |   0.291508  |    0.027658     |   0\n",
      "       2319 |   0.310598  |    0.020392     |   0\n",
      "       2320 |   0.388010  |    0.103274     |   1\n",
      "       2321 |   0.266948  |    0.017117     |   0\n",
      "       2322 |   0.317919  |    0.050792     |   0\n",
      "       2323 |   0.340672  |    0.132332     |   1\n",
      "       2324 |   0.042261  |    0.003931     |   2\n",
      "       2325 |   0.246535  |    0.014932     |   0\n",
      "       2326 |   0.338115  |    0.136364     |   1\n",
      "       2327 |   0.367428  |    0.037039     |   1\n",
      "       2328 |   0.000296  |    0.027572     |   2\n",
      "       2329 |   0.314208  |    0.033017     |   0\n",
      "       2330 |   0.287951  |    0.092006     |   1\n",
      "       2331 |   0.354414  |    0.084859     |   1\n",
      "       2332 |   0.311396  |    0.015617     |   0\n",
      "       2333 |   0.329321  |    0.026690     |   0\n",
      "       2334 |   0.011170  |    0.032758     |   2\n",
      "       2335 |   0.180905  |    0.027561     |   2\n",
      "       2336 |   0.403167  |    0.139541     |   1\n",
      "       2337 |   0.080537  |    0.003240     |   2\n",
      "       2338 |   0.301974  |    0.009587     |   0\n",
      "       2339 |   0.387146  |    0.084207     |   1\n",
      "       2340 |   0.229736  |    0.031451     |   0\n",
      "       2341 |   0.367489  |    0.153701     |   1\n",
      "       2342 |   0.385930  |    0.060387     |   1\n",
      "       2343 |   0.106627  |    0.005992     |   2\n",
      "       2344 |   0.081076  |    0.053326     |   2\n",
      "       2345 |   0.036913  |    0.015322     |   2\n",
      "       2346 |   0.283411  |    0.042962     |   0\n",
      "       2347 |   0.097031  |    0.010768     |   2\n",
      "       2348 |   0.223390  |    0.026956     |   0\n",
      "       2349 |   0.082610  |    0.027453     |   2\n",
      "       2350 |   0.000255  |    0.028533     |   2\n",
      "       2351 |   0.301850  |    0.100068     |   1\n",
      "       2352 |   0.000327  |    0.026856     |   2\n",
      "       2353 |   0.255636  |    0.030625     |   0\n",
      "       2354 |   0.311563  |    0.091178     |   1\n",
      "       2355 |   0.000283  |    0.015136     |   2\n",
      "       2356 |   0.325726  |    0.126608     |   1\n",
      "       2357 |   0.000364  |    0.008314     |   2\n",
      "       2358 |   0.314820  |    0.145982     |   1\n",
      "       2359 |   0.312837  |    0.010237     |   0\n",
      "       2360 |   0.303263  |    0.042770     |   0\n",
      "       2361 |   0.000371  |    0.022627     |   2\n",
      "       2362 |   0.000407  |    0.026528     |   2\n",
      "       2363 |   0.266204  |    0.046613     |   0\n",
      "       2364 |   0.288547  |    0.026645     |   0\n",
      "       2365 |   0.289449  |    0.125431     |   1\n",
      "       2366 |   0.203953  |    0.144327     |   1\n",
      "       2367 |   0.112129  |    0.011768     |   2\n",
      "       2368 |   0.324579  |    0.048023     |   1\n",
      "       2369 |   0.285456  |    0.028154     |   0\n",
      "       2370 |   0.318688  |    0.131225     |   1\n",
      "       2371 |   0.130771  |    0.007101     |   2\n",
      "       2372 |   0.228529  |    0.014396     |   0\n",
      "       2373 |   0.341100  |    0.165822     |   1\n",
      "       2374 |   0.313458  |    0.054094     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 2375: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       2375 |   0.123794  |    0.008368     |   2\n",
      "       2376 |   0.091554  |    0.031036     |   2\n",
      "       2377 |   0.306107  |    0.046589     |   0\n",
      "       2378 |   0.318082  |    0.016907     |   0\n",
      "       2379 |   0.108948  |    0.022261     |   2\n",
      "       2380 |   0.129499  |    0.009144     |   2\n",
      "       2381 |   0.319128  |    0.043932     |   0\n",
      "       2382 |   0.299461  |    0.014406     |   0\n",
      "       2383 |   0.058078  |    0.047791     |   2\n",
      "       2384 |   0.373632  |    0.049042     |   1\n",
      "       2385 |   0.106252  |    0.018617     |   2\n",
      "       2386 |   0.308234  |    0.024185     |   0\n",
      "       2387 |   0.276374  |    0.048625     |   0\n",
      "       2388 |   0.101962  |    0.006943     |   2\n",
      "       2389 |   0.105068  |    0.026538     |   2\n",
      "       2390 |   0.334235  |    0.054548     |   0\n",
      "       2391 |   0.339939  |    0.094430     |   1\n",
      "       2392 |   0.095145  |    0.009219     |   2\n",
      "       2393 |   0.042901  |    0.037842     |   2\n",
      "       2394 |   0.000286  |    0.011636     |   2\n",
      "       2395 |   0.303376  |    0.155919     |   1\n",
      "       2396 |   0.306929  |    0.078262     |   1\n",
      "       2397 |   0.284338  |    0.088835     |   1\n",
      "       2398 |   0.012656  |    0.012338     |   2\n",
      "       2399 |   0.323786  |    0.150175     |   1\n",
      "       2400 |   0.283092  |    0.053587     |   1\n",
      "       2401 |   0.293567  |    0.087671     |   1\n",
      "       2402 |   0.219120  |    0.133623     |   1\n",
      "       2403 |   0.243224  |    0.007104     |   0\n",
      "       2404 |   0.181389  |    0.016452     |   2\n",
      "       2405 |   0.318838  |    0.158194     |   1\n",
      "       2406 |   0.086521  |    0.016125     |   2\n",
      "       2407 |   0.301145  |    0.087179     |   1\n",
      "       2408 |   0.105293  |    0.008411     |   2\n",
      "       2409 |   0.262183  |    0.052549     |   0\n",
      "       2410 |   0.082168  |    0.005842     |   2\n",
      "       2411 |   0.289127  |    0.058974     |   0\n",
      "       2412 |   0.281177  |    0.090989     |   1\n",
      "       2413 |   0.228276  |    0.011317     |   0\n",
      "       2414 |   0.036713  |    0.029998     |   2\n",
      "       2415 |   0.356022  |    0.085324     |   1\n",
      "       2416 |   0.348462  |    0.004740     |   0\n",
      "       2417 |   0.252177  |    0.030581     |   0\n",
      "       2418 |   0.368909  |    0.148083     |   1\n",
      "       2419 |   0.097165  |    0.009536     |   2\n",
      "       2420 |   0.327222  |    0.085184     |   1\n",
      "       2421 |   0.295267  |    0.126311     |   1\n",
      "       2422 |   0.325523  |    0.016372     |   0\n",
      "       2423 |   0.379772  |    0.101359     |   1\n",
      "       2424 |   0.302885  |    0.018155     |   0\n",
      "       2425 |   0.261139  |    0.047784     |   0\n",
      "       2426 |   0.371592  |    0.102223     |   1\n",
      "       2427 |   0.082534  |    0.004688     |   2\n",
      "       2428 |   0.319243  |    0.054105     |   0\n",
      "       2429 |   0.320872  |    0.087395     |   1\n",
      "       2430 |   0.000248  |    0.005686     |   2\n",
      "       2431 |   0.000316  |    0.044358     |   2\n",
      "       2432 |   0.403083  |    0.142131     |   1\n",
      "       2433 |   0.396713  |    0.061098     |   1\n",
      "       2434 |   0.000273  |    0.012001     |   2\n",
      "       2435 |   0.000356  |    0.031500     |   2\n",
      "       2436 |   0.209680  |    0.018687     |   0\n",
      "       2437 |   0.316189  |    0.145247     |   1\n",
      "       2438 |   0.332492  |    0.056173     |   1\n",
      "       2439 |   0.000375  |    0.025578     |   2\n",
      "       2440 |   0.374122  |    0.043566     |   0\n",
      "       2441 |   0.000440  |    0.011094     |   2\n",
      "       2442 |   0.329369  |    0.155825     |   1\n",
      "       2443 |   0.262708  |    0.007355     |   0\n",
      "       2444 |   0.311227  |    0.099860     |   1\n",
      "       2445 |   0.373832  |    0.080293     |   1\n",
      "       2446 |   0.113053  |    0.003585     |   2\n",
      "       2447 |   0.235448  |    0.058776     |   0\n",
      "       2448 |   0.389323  |    0.086664     |   1\n",
      "       2449 |   0.128618  |    0.007083     |   2\n",
      "       2450 |   0.224313  |    0.024813     |   0\n",
      "       2451 |   0.192226  |    0.026757     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 2453: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       2452 |   0.322166  |    0.034380     |   0\n",
      "       2453 |   0.423004  |    0.112921     |   1\n",
      "       2454 |   0.301475  |    0.009661     |   0\n",
      "       2455 |   0.298495  |    0.043613     |   0\n",
      "       2456 |   0.309497  |    0.016822     |   0\n",
      "       2457 |   0.266090  |    0.051113     |   0\n",
      "       2458 |   0.290212  |    0.148638     |   1\n",
      "       2459 |   0.288521  |    0.047481     |   1\n",
      "       2460 |   0.281802  |    0.107985     |   1\n",
      "       2461 |   0.303692  |    0.005576     |   0\n",
      "       2462 |   0.283233  |    0.041756     |   0\n",
      "       2463 |   0.255273  |    0.011827     |   0\n",
      "       2464 |   0.322917  |    0.052819     |   0\n",
      "       2465 |   0.255193  |    0.082853     |   1\n",
      "       2466 |   0.247979  |    0.009873     |   0\n",
      "       2467 |   0.228704  |    0.048558     |   0\n",
      "       2468 |   0.358496  |    0.088935     |   1\n",
      "       2469 |   0.120410  |    0.020777     |   2\n",
      "       2470 |   0.304374  |    0.126260     |   1\n",
      "       2471 |   0.094203  |    0.005182     |   2\n",
      "       2472 |   0.306511  |    0.024544     |   0\n",
      "       2473 |   0.283658  |    0.048240     |   0\n",
      "       2474 |   0.267311  |    0.025596     |   0\n",
      "       2475 |   0.106647  |    0.028304     |   2\n",
      "       2476 |   0.277927  |    0.020235     |   0\n",
      "       2477 |   0.224438  |    0.033624     |   0\n",
      "       2478 |   0.373735  |    0.118304     |   1\n",
      "       2479 |   0.329561  |    0.088739     |   1\n",
      "       2480 |   0.321664  |    0.019255     |   0\n",
      "       2481 |   0.133166  |    0.022907     |   2\n",
      "       2482 |   0.318263  |    0.032838     |   0\n",
      "       2483 |   0.251034  |    0.038772     |   0\n",
      "       2484 |   0.058644  |    0.007931     |   2\n",
      "       2485 |   0.105627  |    0.043932     |   2\n",
      "       2486 |   0.102880  |    0.015313     |   2\n",
      "       2487 |   0.100957  |    0.032061     |   2\n",
      "       2488 |   0.095504  |    0.017421     |   2\n",
      "       2489 |   0.370133  |    0.144781     |   1\n",
      "       2490 |   0.045213  |    0.003034     |   2\n",
      "       2491 |   0.000269  |    0.005274     |   2\n",
      "       2492 |   0.220576  |    0.044043     |   0\n",
      "       2493 |   0.012044  |    0.018080     |   2\n",
      "       2494 |   0.324431  |    0.139543     |   1\n",
      "       2495 |   0.283791  |    0.002960     |   0\n",
      "       2496 |   0.180690  |    0.010392     |   2\n",
      "       2497 |   0.264301  |    0.026211     |   0\n",
      "       2498 |   0.305654  |    0.033425     |   0\n",
      "       2499 |   0.345274  |    0.115359     |   1\n",
      "       2500 |   0.378043  |    0.088495     |   1\n",
      "       2501 |   0.354241  |    0.139782     |   1\n",
      "       2502 |   0.258664  |    0.142981     |   1\n",
      "       2503 |   0.239195  |    0.008514     |   0\n",
      "       2504 |   0.116753  |    0.039057     |   2\n",
      "       2505 |   0.394600  |    0.076725     |   1\n",
      "       2506 |   0.262757  |    0.030546     |   0\n",
      "       2507 |   0.286075  |    0.164522     |   1\n",
      "       2508 |   0.256510  |    0.036072     |   1\n",
      "       2509 |   0.090310  |    0.033242     |   2\n",
      "       2510 |   0.392602  |    0.136823     |   1\n",
      "       2511 |   0.282041  |    0.008569     |   0\n",
      "       2512 |   0.260431  |    0.008152     |   0\n",
      "       2513 |   0.286011  |    0.047466     |   0\n",
      "       2514 |   0.103445  |    0.014501     |   2\n",
      "       2515 |   0.293189  |    0.141258     |   1\n",
      "       2516 |   0.232310  |    0.016501     |   0\n",
      "       2517 |   0.310155  |    0.095810     |   1\n",
      "       2518 |   0.128180  |    0.014704     |   2\n",
      "       2519 |   0.310152  |    0.144635     |   1\n",
      "       2520 |   0.316184  |    0.052372     |   1\n",
      "       2521 |   0.297330  |    0.135423     |   1\n",
      "       2522 |   0.232819  |    0.051155     |   1\n",
      "       2523 |   0.056437  |    0.018201     |   2\n",
      "       2524 |   0.103294  |    0.048294     |   2\n",
      "       2525 |   0.239672  |    0.011259     |   0\n",
      "       2526 |   0.100898  |    0.037182     |   2\n",
      "       2527 |   0.098481  |    0.022731     |   2\n",
      "       2528 |   0.292182  |    0.025530     |   0\n",
      "       2529 |   0.296209  |    0.040664     |   0\n",
      "       2530 |   0.197814  |    0.010489     |   0\n",
      "       2531 |   0.298093  |    0.132282     |   1\n",
      "       2532 |   0.264789  |    0.111900     |   1\n",
      "       2533 |   0.298838  |    0.081389     |   1\n",
      "       2534 |   0.270864  |    0.007292     |   0\n",
      "       2535 |   0.299400  |    0.042373     |   0\n",
      "       2536 |   0.268776  |    0.011498     |   0\n",
      "       2537 |   0.288585  |    0.046690     |   0\n",
      "       2538 |   0.094669  |    0.009173     |   2\n",
      "       2539 |   0.204064  |    0.030996     |   0\n",
      "       2540 |   0.327170  |    0.141940     |   1\n",
      "       2541 |   0.046319  |    0.005031     |   2\n",
      "       2542 |   0.000264  |    0.018674     |   2\n",
      "       2543 |   0.009826  |    0.033576     |   2\n",
      "       2544 |   0.285748  |    0.015540     |   0\n",
      "       2545 |   0.294503  |    0.049346     |   0\n",
      "       2546 |   0.279335  |    0.015255     |   0\n",
      "       2547 |   0.355479  |    0.143923     |   1\n",
      "       2548 |   0.176147  |    0.008785     |   2\n",
      "       2549 |   0.230334  |    0.132821     |   1\n",
      "       2550 |   0.083035  |    0.003618     |   2\n",
      "       2551 |   0.285658  |    0.021420     |   0\n",
      "       2552 |   0.353404  |    0.100655     |   1\n",
      "       2553 |   0.107674  |    0.016838     |   2\n",
      "       2554 |   0.326287  |    0.140378     |   1\n",
      "       2555 |   0.277979  |    0.008230     |   0\n",
      "       2556 |   0.081881  |    0.029564     |   2\n",
      "       2557 |   0.352778  |    0.137025     |   1\n",
      "       2558 |   0.381269  |    0.049166     |   1\n",
      "       2559 |   0.037388  |    0.033150     |   2\n",
      "       2560 |   0.294572  |    0.158040     |   1\n",
      "       2561 |   0.099980  |    0.010577     |   2\n",
      "       2562 |   0.400264  |    0.080714     |   1\n",
      "       2563 |   0.243877  |    0.014885     |   0\n",
      "       2564 |   0.080628  |    0.016896     |   2\n",
      "       2565 |   0.260666  |    0.026135     |   0\n",
      "       2566 |   0.284229  |    0.040527     |   0\n",
      "       2567 |   0.294110  |    0.084700     |   1\n",
      "       2568 |   0.251009  |    0.020653     |   0\n",
      "       2569 |   0.362754  |    0.158891     |   1\n",
      "       2570 |   0.000230  |    0.003847     |   2\n",
      "       2571 |   0.000292  |    0.022241     |   2\n",
      "       2572 |   0.328288  |    0.109618     |   1\n",
      "       2573 |   0.000259  |    0.020327     |   2\n",
      "       2574 |   0.258437  |    0.156503     |   1\n",
      "       2575 |   0.327008  |    0.050933     |   1\n",
      "       2576 |   0.000338  |    0.008084     |   2\n",
      "       2577 |   0.305369  |    0.047815     |   0\n",
      "       2578 |   0.185674  |    0.141537     |   1\n",
      "       2579 |   0.240340  |    0.011277     |   0\n",
      "       2580 |   0.321519  |    0.131955     |   1\n",
      "       2581 |   0.269894  |    0.007988     |   0\n",
      "       2582 |   0.000326  |    0.010589     |   2\n",
      "       2583 |   0.244753  |    0.048461     |   0\n",
      "       2584 |   0.000378  |    0.008468     |   2\n",
      "       2585 |   0.115782  |    0.034864     |   2\n",
      "       2586 |   0.257696  |    0.085159     |   1\n",
      "       2587 |   0.275941  |    0.022759     |   0\n",
      "       2588 |   0.128473  |    0.041228     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 2589: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       2589 |   0.320058  |    0.111982     |   1\n",
      "       2590 |   0.336309  |    0.089407     |   1\n",
      "       2591 |   0.366682  |    0.106091     |   1\n",
      "       2592 |   0.116116  |    0.029735     |   2\n",
      "       2593 |   0.091227  |    0.028052     |   2\n",
      "       2594 |   0.099716  |    0.025523     |   2\n",
      "       2595 |   0.128256  |    0.040614     |   2\n",
      "       2596 |   0.400688  |    0.131263     |   1\n",
      "       2597 |   0.250576  |    0.002988     |   0\n",
      "       2598 |   0.276708  |    0.025874     |   0\n",
      "       2599 |   0.332083  |    0.132066     |   1\n",
      "       2600 |   0.244069  |    0.005962     |   0\n",
      "       2601 |   0.056752  |    0.014513     |   2\n",
      "       2602 |   0.234121  |    0.044632     |   0\n",
      "       2603 |   0.274365  |    0.131202     |   1\n",
      "       2604 |   0.325291  |    0.016805     |   0\n",
      "       2605 |   0.101641  |    0.038699     |   2\n",
      "       2606 |   0.365932  |    0.150433     |   1\n",
      "       2607 |   0.293288  |    0.022189     |   1\n",
      "       2608 |   0.101357  |    0.032116     |   2\n",
      "       2609 |   0.331925  |    0.026105     |   0\n",
      "       2610 |   0.339602  |    0.048353     |   0\n",
      "       2611 |   0.099400  |    0.006089     |   2\n",
      "       2612 |   0.234652  |    0.046114     |   0\n",
      "       2613 |   0.096919  |    0.017252     |   2\n",
      "       2614 |   0.200329  |    0.031773     |   0\n",
      "       2615 |   0.284474  |    0.030827     |   0\n",
      "       2616 |   0.418866  |    0.130527     |   1\n",
      "       2617 |   0.041347  |    0.006965     |   2\n",
      "       2618 |   0.352332  |    0.095128     |   1\n",
      "       2619 |   0.273836  |    0.025212     |   0\n",
      "       2620 |   0.000241  |    0.035013     |   2\n",
      "       2621 |   0.379503  |    0.135343     |   1\n",
      "       2622 |   0.333072  |    0.080499     |   1\n",
      "       2623 |   0.225481  |    0.088756     |   1\n",
      "       2624 |   0.376892  |    0.149665     |   1\n",
      "       2625 |   0.011180  |    0.003905     |   2\n",
      "       2626 |   0.169555  |    0.015230     |   2\n",
      "       2627 |   0.269060  |    0.142445     |   1\n",
      "       2628 |   0.314576  |    0.103400     |   1\n",
      "       2629 |   0.275100  |    0.090439     |   1\n",
      "       2630 |   0.359302  |    0.080937     |   1\n",
      "       2631 |   0.275793  |    0.014943     |   0\n",
      "       2632 |   0.077762  |    0.029680     |   2\n",
      "       2633 |   0.098113  |    0.009244     |   2\n",
      "       2634 |   0.324298  |    0.136121     |   1\n",
      "       2635 |   0.077966  |    0.008812     |   2\n",
      "       2636 |   0.034414  |    0.019743     |   2\n",
      "       2637 |   0.291427  |    0.150143     |   1\n",
      "       2638 |   0.093767  |    0.003118     |   2\n",
      "       2639 |   0.079052  |    0.032716     |   2\n",
      "       2640 |   0.278880  |    0.111751     |   1\n",
      "       2641 |   0.285489  |    0.096180     |   1\n",
      "       2642 |   0.353210  |    0.071710     |   1\n",
      "       2643 |   0.362074  |    0.084992     |   1\n",
      "       2644 |   0.275485  |    0.151994     |   1\n",
      "       2645 |   0.315497  |    0.003236     |   0\n",
      "       2646 |   0.236478  |    0.016386     |   0\n",
      "       2647 |   0.359985  |    0.146055     |   1\n",
      "       2648 |   0.277162  |    0.005199     |   0\n",
      "       2649 |   0.000217  |    0.016120     |   2\n",
      "       2650 |   0.322500  |    0.137594     |   1\n",
      "       2651 |   0.255356  |    0.003235     |   0\n",
      "       2652 |   0.000271  |    0.008467     |   2\n",
      "       2653 |   0.000253  |    0.045044     |   2\n",
      "       2654 |   0.363549  |    0.142977     |   1\n",
      "       2655 |   0.345260  |    0.063338     |   1\n",
      "       2656 |   0.000309  |    0.007201     |   2\n",
      "       2657 |   0.266057  |    0.051865     |   0\n",
      "       2658 |   0.000297  |    0.012600     |   2\n",
      "       2659 |   0.248586  |    0.036940     |   0\n",
      "       2660 |   0.000363  |    0.021312     |   2\n",
      "       2661 |   0.295894  |    0.047279     |   0\n",
      "       2662 |   0.316578  |    0.083625     |   1\n",
      "       2663 |   0.222838  |    0.011056     |   0\n",
      "       2664 |   0.277050  |    0.058412     |   0\n",
      "       2665 |   0.332484  |    0.088922     |   1\n",
      "       2666 |   0.106861  |    0.012140     |   2\n",
      "       2667 |   0.268583  |    0.045463     |   0\n",
      "       2668 |   0.275581  |    0.024077     |   0\n",
      "       2669 |   0.121645  |    0.028564     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 2670: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       2670 |   0.306658  |    0.092226     |   1\n",
      "       2671 |   0.110385  |    0.017812     |   2\n",
      "       2672 |   0.087160  |    0.051085     |   2\n",
      "       2673 |   0.334458  |    0.082182     |   1\n",
      "       2674 |   0.305955  |    0.028211     |   0\n",
      "       2675 |   0.096673  |    0.008055     |   2\n",
      "       2676 |   0.224395  |    0.046855     |   0\n",
      "       2677 |   0.332097  |    0.013530     |   0\n",
      "       2678 |   0.125198  |    0.040972     |   2\n",
      "       2679 |   0.056856  |    0.007367     |   2\n",
      "       2680 |   0.305337  |    0.044090     |   0\n",
      "       2681 |   0.268400  |    0.016420     |   0\n",
      "       2682 |   0.231225  |    0.042988     |   0\n",
      "       2683 |   0.101498  |    0.018309     |   2\n",
      "       2684 |   0.101175  |    0.047754     |   2\n",
      "       2685 |   0.100483  |    0.010803     |   2\n",
      "       2686 |   0.096460  |    0.047998     |   2\n",
      "       2687 |   0.278827  |    0.012944     |   0\n",
      "       2688 |   0.294715  |    0.147736     |   1\n",
      "       2689 |   0.044808  |    0.011147     |   2\n",
      "       2690 |   0.347452  |    0.059932     |   1\n",
      "       2691 |   0.224231  |    0.027577     |   0\n",
      "       2692 |   0.309944  |    0.132436     |   1\n",
      "       2693 |   0.000235  |    0.010805     |   2\n",
      "       2694 |   0.290858  |    0.030010     |   0\n",
      "       2695 |   0.012002  |    0.028246     |   2\n",
      "       2696 |   0.308702  |    0.147497     |   1\n",
      "       2697 |   0.171176  |    0.009156     |   2\n",
      "       2698 |   0.362299  |    0.128713     |   1\n",
      "       2699 |   0.282273  |    0.009648     |   0\n",
      "       2700 |   0.351651  |    0.136836     |   1\n",
      "       2701 |   0.253554  |    0.081508     |   1\n",
      "       2702 |   0.079125  |    0.010511     |   2\n",
      "       2703 |   0.286796  |    0.156214     |   1\n",
      "       2704 |   0.298476  |    0.049366     |   1\n",
      "       2705 |   0.231370  |    0.029401     |   0\n",
      "       2706 |   0.100621  |    0.024484     |   2\n",
      "       2707 |   0.222293  |    0.032455     |   0\n",
      "       2708 |   0.082360  |    0.028411     |   2\n",
      "       2709 |   0.304734  |    0.039073     |   0\n",
      "       2710 |   0.319438  |    0.095341     |   1\n",
      "       2711 |   0.267489  |    0.013183     |   0\n",
      "       2712 |   0.033888  |    0.042232     |   2\n",
      "       2713 |   0.275018  |    0.008788     |   0\n",
      "       2714 |   0.247488  |    0.146121     |   1\n",
      "       2715 |   0.276252  |    0.009027     |   0\n",
      "       2716 |   0.268751  |    0.019825     |   0\n",
      "       2717 |   0.332638  |    0.151217     |   1\n",
      "       2718 |   0.288182  |    0.080960     |   1\n",
      "       2719 |   0.091436  |    0.004558     |   2\n",
      "       2720 |   0.079391  |    0.019672     |   2\n",
      "       2721 |   0.242315  |    0.044024     |   0\n",
      "       2722 |   0.000208  |    0.019155     |   2\n",
      "       2723 |   0.000250  |    0.034859     |   2\n",
      "       2724 |   0.269139  |    0.027398     |   0\n",
      "       2725 |   0.271007  |    0.034438     |   0\n",
      "       2726 |   0.000238  |    0.018925     |   2\n",
      "       2727 |   0.342564  |    0.142467     |   1\n",
      "       2728 |   0.286832  |    0.005695     |   0\n",
      "       2729 |   0.000285  |    0.011028     |   2\n",
      "       2730 |   0.000285  |    0.031651     |   2\n",
      "       2731 |   0.000345  |    0.030794     |   2\n",
      "       2732 |   0.309832  |    0.027702     |   0\n",
      "       2733 |   0.342834  |    0.138489     |   1\n",
      "       2734 |   0.273653  |    0.086158     |   1\n",
      "       2735 |   0.245903  |    0.086653     |   1\n",
      "       2736 |   0.299363  |    0.046651     |   0\n",
      "       2737 |   0.107471  |    0.007812     |   2\n",
      "       2738 |   0.119738  |    0.045497     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 2739: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       2739 |   0.111888  |    0.008734     |   2\n",
      "       2740 |   0.243260  |    0.050381     |   0\n",
      "       2741 |   0.321279  |    0.104962     |   1\n",
      "       2742 |   0.281152  |    0.098136     |   1\n",
      "       2743 |   0.085733  |    0.006634     |   2\n",
      "       2744 |   0.205559  |    0.017467     |   0\n",
      "       2745 |   0.354510  |    0.167678     |   1\n",
      "       2746 |   0.327653  |    0.002940     |   0\n",
      "       2747 |   0.282296  |    0.019100     |   0\n",
      "       2748 |   0.099586  |    0.025789     |   2\n",
      "       2749 |   0.125925  |    0.031717     |   2\n",
      "       2750 |   0.258717  |    0.092151     |   1\n",
      "       2751 |   0.298911  |    0.033771     |   0\n",
      "       2752 |   0.055138  |    0.018886     |   2\n",
      "       2753 |   0.099413  |    0.015136     |   2\n",
      "       2754 |   0.097633  |    0.031607     |   2\n",
      "       2755 |   0.245275  |    0.046715     |   0\n",
      "       2756 |   0.100240  |    0.009696     |   2\n",
      "       2757 |   0.281738  |    0.042106     |   0\n",
      "       2758 |   0.284463  |    0.021083     |   0\n",
      "       2759 |   0.238632  |    0.127103     |   1\n",
      "       2760 |   0.094352  |    0.029384     |   2\n",
      "       2761 |   0.299003  |    0.076212     |   1\n",
      "       2762 |   0.044247  |    0.007715     |   2\n",
      "       2763 |   0.293695  |    0.052957     |   0\n",
      "       2764 |   0.000222  |    0.015376     |   2\n",
      "       2765 |   0.010095  |    0.030009     |   2\n",
      "       2766 |   0.314567  |    0.029955     |   0\n",
      "       2767 |   0.331444  |    0.150307     |   1\n",
      "       2768 |   0.262179  |    0.060015     |   1\n",
      "       2769 |   0.350999  |    0.145439     |   1\n",
      "       2770 |   0.286744  |    0.002887     |   0\n",
      "       2771 |   0.171423  |    0.005052     |   2\n",
      "       2772 |   0.227917  |    0.055025     |   0\n",
      "       2773 |   0.328005  |    0.095180     |   1\n",
      "       2774 |   0.302591  |    0.086633     |   1\n",
      "       2775 |   0.253657  |    0.022396     |   0\n",
      "       2776 |   0.299371  |    0.150499     |   1\n",
      "       2777 |   0.383872  |    0.085574     |   1\n",
      "       2778 |   0.323957  |    0.013624     |   0\n",
      "       2779 |   0.251040  |    0.043319     |   0\n",
      "       2780 |   0.078651  |    0.014625     |   2\n",
      "       2781 |   0.323149  |    0.171382     |   1\n",
      "       2782 |   0.277009  |    0.005386     |   0\n",
      "       2783 |   0.294140  |    0.057947     |   1\n",
      "       2784 |   0.286736  |    0.022953     |   0\n",
      "       2785 |   0.336860  |    0.154735     |   1\n",
      "       2786 |   0.288224  |    0.045764     |   1\n",
      "       2787 |   0.302091  |    0.096320     |   1\n",
      "       2788 |   0.099938  |    0.006762     |   2\n",
      "       2789 |   0.271586  |    0.023760     |   0\n",
      "       2790 |   0.083238  |    0.037350     |   2\n",
      "       2791 |   0.279710  |    0.088979     |   1\n",
      "       2792 |   0.302753  |    0.009453     |   0\n",
      "       2793 |   0.313024  |    0.047930     |   0\n",
      "       2794 |   0.036575  |    0.005589     |   2\n",
      "       2795 |   0.228414  |    0.061788     |   0\n",
      "       2796 |   0.335785  |    0.089591     |   1\n",
      "       2797 |   0.237154  |    0.005423     |   0\n",
      "       2798 |   0.096996  |    0.012424     |   2\n",
      "       2799 |   0.272916  |    0.055919     |   0\n",
      "       2800 |   0.354929  |    0.095112     |   1\n",
      "       2801 |   0.291568  |    0.011753     |   0\n",
      "       2802 |   0.364841  |    0.145736     |   1\n",
      "       2803 |   0.077869  |    0.003081     |   2\n",
      "       2804 |   0.000202  |    0.008626     |   2\n",
      "       2805 |   0.247085  |    0.038843     |   0\n",
      "       2806 |   0.196408  |    0.013861     |   0\n",
      "       2807 |   0.000250  |    0.037555     |   2\n",
      "       2808 |   0.289409  |    0.151765     |   1\n",
      "       2809 |   0.240618  |    0.014389     |   0\n",
      "       2810 |   0.380936  |    0.138513     |   1\n",
      "       2811 |   0.343444  |    0.003905     |   0\n",
      "       2812 |   0.284482  |    0.073740     |   0\n",
      "       2813 |   0.307340  |    0.021499     |   0\n",
      "       2814 |   0.000234  |    0.084724     |   2\n",
      "       2815 |   0.251025  |    0.007432     |   0\n",
      "       2816 |   0.371999  |    0.088173     |   1\n",
      "       2817 |   0.000292  |    0.012101     |   2\n",
      "       2818 |   0.000269  |    0.046188     |   2\n",
      "       2819 |   0.357857  |    0.105313     |   1\n",
      "       2820 |   0.288087  |    0.009891     |   0\n",
      "       2821 |   0.360545  |    0.088397     |   1\n",
      "       2822 |   0.000331  |    0.005003     |   2\n",
      "       2823 |   0.267236  |    0.060155     |   0\n",
      "       2824 |   0.352822  |    0.082662     |   1\n",
      "       2825 |   0.105726  |    0.007003     |   2\n",
      "       2826 |   0.119993  |    0.042483     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 2828: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       2827 |   0.252500  |    0.013616     |   0\n",
      "       2828 |   0.112151  |    0.044261     |   2\n",
      "       2829 |   0.083413  |    0.008768     |   2\n",
      "       2830 |   0.096525  |    0.030818     |   2\n",
      "       2831 |   0.123384  |    0.025453     |   2\n",
      "       2832 |   0.276664  |    0.143069     |   1\n",
      "       2833 |   0.250185  |    0.093118     |   1\n",
      "       2834 |   0.356142  |    0.065618     |   1\n",
      "       2835 |   0.332244  |    0.030666     |   0\n",
      "       2836 |   0.295807  |    0.030769     |   0\n",
      "       2837 |   0.054076  |    0.017472     |   2\n",
      "       2838 |   0.098206  |    0.039564     |   2\n",
      "       2839 |   0.256650  |    0.015176     |   0\n",
      "       2840 |   0.268658  |    0.050954     |   0\n",
      "       2841 |   0.096532  |    0.010188     |   2\n",
      "       2842 |   0.100911  |    0.031527     |   2\n",
      "       2843 |   0.091285  |    0.042707     |   2\n",
      "       2844 |   0.315099  |    0.099565     |   1\n",
      "       2845 |   0.334518  |    0.086442     |   1\n",
      "       2846 |   0.312954  |    0.005563     |   0\n",
      "       2847 |   0.275628  |    0.035928     |   0\n",
      "       2848 |   0.425322  |    0.088465     |   1\n",
      "       2849 |   0.041559  |    0.015589     |   2\n",
      "       2850 |   0.200511  |    0.042030     |   0\n",
      "       2851 |   0.287273  |    0.024526     |   0\n",
      "       2852 |   0.325721  |    0.155524     |   1\n",
      "       2853 |   0.359365  |    0.024624     |   1\n",
      "       2854 |   0.267945  |    0.049506     |   0\n",
      "       2855 |   0.000217  |    0.005602     |   2\n",
      "       2856 |   0.010544  |    0.050986     |   2\n",
      "       2857 |   0.245255  |    0.009067     |   0\n",
      "       2858 |   0.164730  |    0.043502     |   2\n",
      "       2859 |   0.282314  |    0.021196     |   0\n",
      "       2860 |   0.318002  |    0.108767     |   1\n",
      "       2861 |   0.358555  |    0.081874     |   1\n",
      "       2862 |   0.214468  |    0.009438     |   0\n",
      "       2863 |   0.313691  |    0.027178     |   0\n",
      "       2864 |   0.270276  |    0.043156     |   0\n",
      "       2865 |   0.282837  |    0.018768     |   0\n",
      "       2866 |   0.266712  |    0.040175     |   0\n",
      "       2867 |   0.079170  |    0.008274     |   2\n",
      "       2868 |   0.096134  |    0.042066     |   2\n",
      "       2869 |   0.278585  |    0.015606     |   0\n",
      "       2870 |   0.082593  |    0.050836     |   2\n",
      "       2871 |   0.275186  |    0.078992     |   1\n",
      "       2872 |   0.257177  |    0.014313     |   0\n",
      "       2873 |   0.354708  |    0.146818     |   1\n",
      "       2874 |   0.297823  |    0.088815     |   1\n",
      "       2875 |   0.035909  |    0.004191     |   2\n",
      "       2876 |   0.327802  |    0.100759     |   1\n",
      "       2877 |   0.243496  |    0.013693     |   0\n",
      "       2878 |   0.302817  |    0.026209     |   0\n",
      "       2879 |   0.242726  |    0.042611     |   0\n",
      "       2880 |   0.269580  |    0.016553     |   0\n",
      "       2881 |   0.093503  |    0.038191     |   2\n",
      "       2882 |   0.385125  |    0.085150     |   1\n",
      "       2883 |   0.244537  |    0.090806     |   1\n",
      "       2884 |   0.256127  |    0.007776     |   0\n",
      "       2885 |   0.357419  |    0.047056     |   0\n",
      "       2886 |   0.078400  |    0.017521     |   2\n",
      "       2887 |   0.000193  |    0.026923     |   2\n",
      "       2888 |   0.235692  |    0.024485     |   0\n",
      "       2889 |   0.000236  |    0.029776     |   2\n",
      "       2890 |   0.242034  |    0.031666     |   0\n",
      "       2891 |   0.000226  |    0.022516     |   2\n",
      "       2892 |   0.303981  |    0.092527     |   1\n",
      "       2893 |   0.000275  |    0.015853     |   2\n",
      "       2894 |   0.256057  |    0.048848     |   0\n",
      "       2895 |   0.000254  |    0.007047     |   2\n",
      "       2896 |   0.294329  |    0.136373     |   1\n",
      "       2897 |   0.260656  |    0.006613     |   0\n",
      "       2898 |   0.286941  |    0.046560     |   0\n",
      "       2899 |   0.000292  |    0.020898     |   2\n",
      "       2900 |   0.265925  |    0.145514     |   1\n",
      "       2901 |   0.371951  |    0.003843     |   0\n",
      "       2902 |   0.107038  |    0.015030     |   2\n",
      "       2903 |   0.120765  |    0.021251     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 2904: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       2904 |   0.285813  |    0.092612     |   1\n",
      "       2905 |   0.113076  |    0.006676     |   2\n",
      "       2906 |   0.305742  |    0.030114     |   0\n",
      "       2907 |   0.087486  |    0.024519     |   2\n",
      "       2908 |   0.097822  |    0.020030     |   2\n",
      "       2909 |   0.121845  |    0.020051     |   2\n",
      "       2910 |   0.054848  |    0.039895     |   2\n",
      "       2911 |   0.469366  |    0.106246     |   1\n",
      "       2912 |   0.254550  |    0.020685     |   0\n",
      "       2913 |   0.094380  |    0.015372     |   2\n",
      "       2914 |   0.270014  |    0.046084     |   0\n",
      "       2915 |   0.290420  |    0.010265     |   0\n",
      "       2916 |   0.099531  |    0.042163     |   2\n",
      "       2917 |   0.259959  |    0.035950     |   0\n",
      "       2918 |   0.307173  |    0.105496     |   1\n",
      "       2919 |   0.099240  |    0.018218     |   2\n",
      "       2920 |   0.394697  |    0.083612     |   1\n",
      "       2921 |   0.258867  |    0.010614     |   0\n",
      "       2922 |   0.294235  |    0.051659     |   0\n",
      "       2923 |   0.088195  |    0.030087     |   2\n",
      "       2924 |   0.177739  |    0.139547     |   1\n",
      "       2925 |   0.349245  |    0.003066     |   0\n",
      "       2926 |   0.039985  |    0.013543     |   2\n",
      "       2927 |   0.368496  |    0.134030     |   1\n",
      "       2928 |   0.227839  |    0.006969     |   0\n",
      "       2929 |   0.000206  |    0.015779     |   2\n",
      "       2930 |   0.289989  |    0.057920     |   0\n",
      "       2931 |   0.361254  |    0.109906     |   1\n",
      "       2932 |   0.271701  |    0.053520     |   1\n",
      "       2933 |   0.009852  |    0.025661     |   2\n",
      "       2934 |   0.277353  |    0.033660     |   0\n",
      "       2935 |   0.343402  |    0.077795     |   1\n",
      "       2936 |   0.398056  |    0.107269     |   1\n",
      "       2937 |   0.330061  |    0.093916     |   1\n",
      "       2938 |   0.306693  |    0.007328     |   0\n",
      "       2939 |   0.167883  |    0.012754     |   2\n",
      "       2940 |   0.249157  |    0.029741     |   0\n",
      "       2941 |   0.230920  |    0.148562     |   1\n",
      "       2942 |   0.077112  |    0.003340     |   2\n",
      "       2943 |   0.096819  |    0.011838     |   2\n",
      "       2944 |   0.375049  |    0.135646     |   1\n",
      "       2945 |   0.326462  |    0.010500     |   0\n",
      "       2946 |   0.292118  |    0.008563     |   0\n",
      "       2947 |   0.249833  |    0.028897     |   0\n",
      "       2948 |   0.081426  |    0.014391     |   2\n",
      "       2949 |   0.260253  |    0.050501     |   0\n",
      "       2950 |   0.335593  |    0.093832     |   1\n",
      "       2951 |   0.240425  |    0.020232     |   0\n",
      "       2952 |   0.225409  |    0.135595     |   1\n",
      "       2953 |   0.033538  |    0.003748     |   2\n",
      "       2954 |   0.226864  |    0.017290     |   0\n",
      "       2955 |   0.315603  |    0.143522     |   1\n",
      "       2956 |   0.093724  |    0.003532     |   2\n",
      "       2957 |   0.080014  |    0.015917     |   2\n",
      "       2958 |   0.274824  |    0.150680     |   1\n",
      "       2959 |   0.290637  |    0.055219     |   1\n",
      "       2960 |   0.241860  |    0.016466     |   0\n",
      "       2961 |   0.369236  |    0.153942     |   1\n",
      "       2962 |   0.329955  |    0.044025     |   1\n",
      "       2963 |   0.283853  |    0.088901     |   1\n",
      "       2964 |   0.260515  |    0.006603     |   0\n",
      "       2965 |   0.235038  |    0.039740     |   0\n",
      "       2966 |   0.000183  |    0.008537     |   2\n",
      "       2967 |   0.000217  |    0.051801     |   2\n",
      "       2968 |   0.000217  |    0.025662     |   2\n",
      "       2969 |   0.342196  |    0.100643     |   1\n",
      "       2970 |   0.000251  |    0.007149     |   2\n",
      "       2971 |   0.316921  |    0.060035     |   0\n",
      "       2972 |   0.362364  |    0.092718     |   1\n",
      "       2973 |   0.326788  |    0.083543     |   1\n",
      "       2974 |   0.304362  |    0.050449     |   1\n",
      "       2975 |   0.235964  |    0.024640     |   0\n",
      "       2976 |   0.223331  |    0.050549     |   0\n",
      "       2977 |   0.327940  |    0.095986     |   1\n",
      "       2978 |   0.279181  |    0.019303     |   0\n",
      "       2979 |   0.000234  |    0.043505     |   2\n",
      "       2980 |   0.237536  |    0.095311     |   1\n",
      "       2981 |   0.000297  |    0.022569     |   2\n",
      "       2982 |   0.342617  |    0.091837     |   1\n",
      "       2983 |   0.263075  |    0.013954     |   0\n",
      "       2984 |   0.103379  |    0.046100     |   2\n",
      "       2985 |   0.325488  |    0.107191     |   1\n",
      "       2986 |   0.327670  |    0.048465     |   1\n",
      "       2987 |   0.115045  |    0.015295     |   2\n",
      "       2988 |   0.321571  |    0.132173     |   1\n",
      "       2989 |   0.255510  |    0.091022     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 2990: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       2990 |   0.108974  |    0.002965     |   2\n",
      "       2991 |   0.080511  |    0.005544     |   2\n",
      "       2992 |   0.255124  |    0.041165     |   0\n",
      "       2993 |   0.314397  |    0.085251     |   1\n",
      "       2994 |   0.303584  |    0.025481     |   0\n",
      "       2995 |   0.095817  |    0.049392     |   2\n",
      "       2996 |   0.342089  |    0.057551     |   1\n",
      "       2997 |   0.119725  |    0.013892     |   2\n",
      "       2998 |   0.337129  |    0.028830     |   0\n",
      "       2999 |   0.291577  |    0.052449     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 3000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 3000: Plotting estimates.\n",
      "Exception in thread neuralnilm-data-process:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 810, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/dk3810/workspace/python/neuralnilm/neuralnilm/data/datathread.py\", line 16, in run\n",
      "    batch = self.data_pipeline.get_batch(**self._get_batch_kwargs)\n",
      "  File \"/home/dk3810/workspace/python/neuralnilm/neuralnilm/data/datapipeline.py\", line 46, in get_batch\n",
      "    batch = self._source_iterators[source_id].next()\n",
      "ValueError: generator already executing\n",
      "\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       3000 |   0.052544  |    0.009763     |   2\n",
      "       3001 |   0.105118  |    0.064692     |   2\n",
      "       3002 |   0.360350  |    0.084069     |   1\n",
      "       3003 |   0.308107  |    0.090745     |   1\n",
      "       3004 |   0.080130  |    0.016112     |   2\n",
      "       3005 |   0.381916  |    0.129502     |   1\n",
      "       3006 |   0.092165  |    0.006002     |   2\n",
      "       3007 |   0.218792  |    0.020332     |   0\n",
      "       3008 |   0.116503  |    0.031050     |   2\n",
      "       3009 |   0.050994  |    0.017089     |   2\n",
      "       3010 |   0.097347  |    0.046043     |   2\n",
      "       3011 |   0.301585  |    0.089944     |   1\n",
      "       3012 |   0.283274  |    0.096571     |   1\n",
      "       3013 |   0.094006  |    0.019038     |   2\n",
      "       3014 |   0.238938  |    0.164108     |   1\n",
      "       3015 |   0.285827  |    0.051568     |   1\n",
      "       3016 |   0.293169  |    0.079827     |   1\n",
      "       3017 |   0.100615  |    0.025557     |   2\n",
      "       3018 |   0.328542  |    0.163502     |   1\n",
      "       3019 |   0.094049  |    0.011205     |   2\n",
      "       3020 |   0.370399  |    0.041341     |   1\n",
      "       3021 |   0.297196  |    0.031601     |   0\n",
      "       3022 |   0.259263  |    0.028911     |   0\n",
      "       3023 |   0.309067  |    0.026805     |   0\n",
      "       3024 |   0.242555  |    0.035757     |   0\n",
      "       3025 |   0.301106  |    0.029034     |   0\n",
      "       3026 |   0.235212  |    0.118428     |   1\n",
      "       3027 |   0.311006  |    0.017924     |   0\n",
      "       3028 |   0.373523  |    0.107732     |   1\n",
      "       3029 |   0.040549  |    0.021867     |   2\n",
      "       3030 |   0.000202  |    0.023804     |   2\n",
      "       3031 |   0.009158  |    0.026221     |   2\n",
      "       3032 |   0.165304  |    0.033916     |   2\n",
      "       3033 |   0.320722  |    0.033546     |   0\n",
      "       3034 |   0.202873  |    0.042174     |   0\n",
      "       3035 |   0.283190  |    0.122263     |   1\n",
      "       3036 |   0.353409  |    0.025984     |   1\n",
      "       3037 |   0.322694  |    0.092070     |   1\n",
      "       3038 |   0.221310  |    0.115836     |   1\n",
      "       3039 |   0.280406  |    0.088129     |   1\n",
      "       3040 |   0.352962  |    0.060751     |   1\n",
      "       3041 |   0.272264  |    0.021875     |   0\n",
      "       3042 |   0.354756  |    0.124759     |   1\n",
      "       3043 |   0.368864  |    0.078074     |   1\n",
      "       3044 |   0.328492  |    0.013702     |   0\n",
      "       3045 |   0.075094  |    0.026360     |   2\n",
      "       3046 |   0.099249  |    0.027910     |   2\n",
      "       3047 |   0.304210  |    0.098805     |   1\n",
      "       3048 |   0.287247  |    0.004766     |   0\n",
      "       3049 |   0.268768  |    0.026238     |   0\n",
      "       3050 |   0.332345  |    0.102914     |   1\n",
      "       3051 |   0.076710  |    0.017141     |   2\n",
      "       3052 |   0.239017  |    0.179308     |   1\n",
      "       3053 |   0.298405  |    0.008147     |   0\n",
      "       3054 |   0.241504  |    0.072935     |   1\n",
      "       3055 |   0.261952  |    0.011263     |   0\n",
      "       3056 |   0.278130  |    0.055291     |   0\n",
      "       3057 |   0.034677  |    0.009363     |   2\n",
      "       3058 |   0.393136  |    0.108667     |   1\n",
      "       3059 |   0.294833  |    0.041087     |   0\n",
      "       3060 |   0.267143  |    0.141008     |   1\n",
      "       3061 |   0.279627  |    0.003026     |   0\n",
      "       3062 |   0.253303  |    0.014405     |   0\n",
      "       3063 |   0.344540  |    0.124141     |   1\n",
      "       3064 |   0.302938  |    0.041267     |   0\n",
      "       3065 |   0.367778  |    0.090987     |   1\n",
      "       3066 |   0.092267  |    0.005650     |   2\n",
      "       3067 |   0.310521  |    0.032687     |   0\n",
      "       3068 |   0.075076  |    0.035935     |   2\n",
      "       3069 |   0.233742  |    0.098378     |   1\n",
      "       3070 |   0.000181  |    0.007413     |   2\n",
      "       3071 |   0.000224  |    0.057286     |   2\n",
      "       3072 |   0.000223  |    0.011024     |   2\n",
      "       3073 |   0.000278  |    0.045497     |   2\n",
      "       3074 |   0.226534  |    0.022018     |   0\n",
      "       3075 |   0.000240  |    0.022978     |   2\n",
      "       3076 |   0.310695  |    0.104406     |   1\n",
      "       3077 |   0.334537  |    0.083628     |   1\n",
      "       3078 |   0.308772  |    0.011737     |   0\n",
      "       3079 |   0.000278  |    0.047699     |   2\n",
      "       3080 |   0.101195  |    0.021203     |   2\n",
      "       3081 |   0.351777  |    0.106358     |   1\n",
      "       3082 |   0.304987  |    0.102803     |   1\n",
      "       3083 |   0.293431  |    0.016411     |   0\n",
      "       3084 |   0.283579  |    0.140529     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 3086: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       3085 |   0.112632  |    0.004577     |   2\n",
      "       3086 |   0.262568  |    0.021948     |   0\n",
      "       3087 |   0.215220  |    0.127059     |   1\n",
      "       3088 |   0.363201  |    0.091031     |   1\n",
      "       3089 |   0.110237  |    0.012628     |   2\n",
      "       3090 |   0.275989  |    0.127234     |   1\n",
      "       3091 |   0.085912  |    0.003257     |   2\n",
      "       3092 |   0.242695  |    0.048415     |   0\n",
      "       3093 |   0.260927  |    0.016846     |   0\n",
      "       3094 |   0.291859  |    0.157525     |   1\n",
      "       3095 |   0.216887  |    0.100272     |   1\n",
      "       3096 |   0.325254  |    0.058526     |   1\n",
      "       3097 |   0.246444  |    0.083501     |   1\n",
      "       3098 |   0.091850  |    0.008221     |   2\n",
      "       3099 |   0.115155  |    0.048026     |   2\n",
      "       3100 |   0.248548  |    0.011310     |   0\n",
      "       3101 |   0.051673  |    0.039667     |   2\n",
      "       3102 |   0.092042  |    0.006557     |   2\n",
      "       3103 |   0.094959  |    0.045441     |   2\n",
      "       3104 |   0.099060  |    0.009887     |   2\n",
      "       3105 |   0.092229  |    0.045293     |   2\n",
      "       3106 |   0.256344  |    0.149936     |   1\n",
      "       3107 |   0.264853  |    0.031985     |   1\n",
      "       3108 |   0.296115  |    0.025293     |   0\n",
      "       3109 |   0.042055  |    0.024412     |   2\n",
      "       3110 |   0.293127  |    0.022728     |   0\n",
      "       3111 |   0.323435  |    0.153746     |   1\n",
      "       3112 |   0.000190  |    0.006852     |   2\n",
      "       3113 |   0.331993  |    0.108983     |   1\n",
      "       3114 |   0.258246  |    0.085572     |   1\n",
      "       3115 |   0.010305  |    0.008738     |   2\n",
      "       3116 |   0.159509  |    0.047391     |   2\n",
      "       3117 |   0.074181  |    0.007500     |   2\n",
      "       3118 |   0.092942  |    0.033989     |   2\n",
      "       3119 |   0.341260  |    0.147822     |   1\n",
      "       3120 |   0.260379  |    0.019518     |   0\n",
      "       3121 |   0.321804  |    0.052695     |   1\n",
      "       3122 |   0.076778  |    0.006527     |   2\n",
      "       3123 |   0.034364  |    0.049220     |   2\n",
      "       3124 |   0.087481  |    0.017871     |   2\n",
      "       3125 |   0.336529  |    0.143134     |   1\n",
      "       3126 |   0.075381  |    0.003611     |   2\n",
      "       3127 |   0.210503  |    0.017253     |   0\n",
      "       3128 |   0.304834  |    0.140308     |   1\n",
      "       3129 |   0.000177  |    0.017757     |   2\n",
      "       3130 |   0.208579  |    0.139396     |   1\n",
      "       3131 |   0.266589  |    0.084259     |   1\n",
      "       3132 |   0.000210  |    0.014760     |   2\n",
      "       3133 |   0.314195  |    0.090612     |   1\n",
      "       3134 |   0.284196  |    0.012997     |   0\n",
      "       3135 |   0.297918  |    0.147533     |   1\n",
      "       3136 |   0.247294  |    0.002919     |   0\n",
      "       3137 |   0.000216  |    0.008023     |   2\n",
      "       3138 |   0.213412  |    0.032163     |   0\n",
      "       3139 |   0.000259  |    0.026160     |   2\n",
      "       3140 |   0.252195  |    0.055690     |   0\n",
      "       3141 |   0.303074  |    0.152904     |   1\n",
      "       3142 |   0.236475  |    0.037465     |   1\n",
      "       3143 |   0.213914  |    0.027796     |   0\n",
      "       3144 |   0.000228  |    0.032350     |   2\n",
      "       3145 |   0.000286  |    0.025959     |   2\n",
      "       3146 |   0.097403  |    0.025102     |   2\n",
      "       3147 |   0.299228  |    0.035035     |   0\n",
      "       3148 |   0.267614  |    0.031270     |   0\n",
      "       3149 |   0.108831  |    0.043271     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 3150: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       3150 |   0.298641  |    0.059379     |   1\n",
      "       3151 |   0.322065  |    0.134335     |   1\n",
      "       3152 |   0.299289  |    0.008030     |   0\n",
      "       3153 |   0.102111  |    0.014493     |   2\n",
      "       3154 |   0.078691  |    0.024671     |   2\n",
      "       3155 |   0.246935  |    0.032703     |   0\n",
      "       3156 |   0.088609  |    0.029259     |   2\n",
      "       3157 |   0.114209  |    0.029724     |   2\n",
      "       3158 |   0.373149  |    0.099002     |   1\n",
      "       3159 |   0.051339  |    0.012564     |   2\n",
      "       3160 |   0.091008  |    0.031001     |   2\n",
      "       3161 |   0.279063  |    0.049094     |   0\n",
      "       3162 |   0.094317  |    0.010068     |   2\n",
      "       3163 |   0.292761  |    0.024483     |   0\n",
      "       3164 |   0.095086  |    0.046875     |   2\n",
      "       3165 |   0.359102  |    0.081596     |   1\n",
      "       3166 |   0.092482  |    0.010300     |   2\n",
      "       3167 |   0.278695  |    0.039271     |   0\n",
      "       3168 |   0.043076  |    0.015151     |   2\n",
      "       3169 |   0.000188  |    0.051442     |   2\n",
      "       3170 |   0.292902  |    0.088106     |   1\n",
      "       3171 |   0.248567  |    0.017009     |   0\n",
      "       3172 |   0.009683  |    0.044582     |   2\n",
      "       3173 |   0.285433  |    0.014443     |   0\n",
      "       3174 |   0.157439  |    0.034544     |   2\n",
      "       3175 |   0.070886  |    0.022287     |   2\n",
      "       3176 |   0.409444  |    0.083134     |   1\n",
      "       3177 |   0.265089  |    0.031104     |   0\n",
      "       3178 |   0.263002  |    0.155488     |   1\n",
      "       3179 |   0.220550  |    0.081246     |   1\n",
      "       3180 |   0.235826  |    0.004528     |   0\n",
      "       3181 |   0.225810  |    0.043742     |   0\n",
      "       3182 |   0.267080  |    0.031432     |   0\n",
      "       3183 |   0.094201  |    0.045765     |   2\n",
      "       3184 |   0.074198  |    0.024954     |   2\n",
      "       3185 |   0.329302  |    0.143702     |   1\n",
      "       3186 |   0.032629  |    0.012138     |   2\n",
      "       3187 |   0.087591  |    0.041546     |   2\n",
      "       3188 |   0.253822  |    0.147127     |   1\n",
      "       3189 |   0.073984  |    0.004417     |   2\n",
      "       3190 |   0.000172  |    0.009225     |   2\n",
      "       3191 |   0.000203  |    0.044493     |   2\n",
      "       3192 |   0.285412  |    0.009673     |   0\n",
      "       3193 |   0.323726  |    0.062564     |   0\n",
      "       3194 |   0.310543  |    0.093175     |   1\n",
      "       3195 |   0.000209  |    0.013020     |   2\n",
      "       3196 |   0.000259  |    0.034542     |   2\n",
      "       3197 |   0.238092  |    0.093599     |   1\n",
      "       3198 |   0.211430  |    0.018704     |   0\n",
      "       3199 |   0.000220  |    0.058154     |   2\n",
      "       3200 |   0.261366  |    0.057610     |   1\n",
      "       3201 |   0.181537  |    0.012092     |   0\n",
      "       3202 |   0.000258  |    0.047407     |   2\n",
      "       3203 |   0.099790  |    0.010029     |   2\n",
      "       3204 |   0.108099  |    0.034056     |   2\n",
      "       3205 |   0.237182  |    0.019357     |   0\n",
      "       3206 |   0.320464  |    0.144971     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 3207: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       3207 |   0.331046  |    0.044220     |   1\n",
      "       3208 |   0.293156  |    0.012073     |   0\n",
      "       3209 |   0.260052  |    0.045315     |   0\n",
      "       3210 |   0.275738  |    0.017413     |   0\n",
      "       3211 |   0.364879  |    0.162360     |   1\n",
      "       3212 |   0.332605  |    0.057379     |   1\n",
      "       3213 |   0.295695  |    0.033469     |   0\n",
      "       3214 |   0.244862  |    0.097602     |   1\n",
      "       3215 |   0.106539  |    0.005500     |   2\n",
      "       3216 |   0.244947  |    0.037088     |   0\n",
      "       3217 |   0.351855  |    0.082957     |   1\n",
      "       3218 |   0.084389  |    0.014443     |   2\n",
      "       3219 |   0.089161  |    0.030315     |   2\n",
      "       3220 |   0.222416  |    0.020378     |   0\n",
      "       3221 |   0.256883  |    0.030375     |   0\n",
      "       3222 |   0.302101  |    0.024210     |   0\n",
      "       3223 |   0.308128  |    0.024970     |   0\n",
      "       3224 |   0.285555  |    0.043104     |   0\n",
      "       3225 |   0.241872  |    0.024884     |   0\n",
      "       3226 |   0.114087  |    0.024667     |   2\n",
      "       3227 |   0.310731  |    0.153629     |   1\n",
      "       3228 |   0.050612  |    0.002925     |   2\n",
      "       3229 |   0.088683  |    0.010294     |   2\n",
      "       3230 |   0.094238  |    0.024212     |   2\n",
      "       3231 |   0.278077  |    0.032646     |   0\n",
      "       3232 |   0.354464  |    0.127271     |   1\n",
      "       3233 |   0.252279  |    0.006053     |   0\n",
      "       3234 |   0.092615  |    0.010622     |   2\n",
      "       3235 |   0.090036  |    0.032354     |   2\n",
      "       3236 |   0.367465  |    0.113621     |   1\n",
      "       3237 |   0.281321  |    0.058491     |   1\n",
      "       3238 |   0.258972  |    0.032001     |   0\n",
      "       3239 |   0.284537  |    0.030118     |   0\n",
      "       3240 |   0.041876  |    0.019654     |   2\n",
      "       3241 |   0.000185  |    0.042003     |   2\n",
      "       3242 |   0.009817  |    0.004971     |   2\n",
      "       3243 |   0.220496  |    0.056714     |   0\n",
      "       3244 |   0.158259  |    0.007737     |   2\n",
      "       3245 |   0.267023  |    0.034468     |   0\n",
      "       3246 |   0.279415  |    0.112151     |   1\n",
      "       3247 |   0.273963  |    0.008162     |   0\n",
      "       3248 |   0.073894  |    0.021623     |   2\n",
      "       3249 |   0.095214  |    0.030469     |   2\n",
      "       3250 |   0.076148  |    0.017808     |   2\n",
      "       3251 |   0.368949  |    0.152960     |   1\n",
      "       3252 |   0.301564  |    0.082307     |   1\n",
      "       3253 |   0.313261  |    0.007031     |   0\n",
      "       3254 |   0.031519  |    0.014627     |   2\n",
      "       3255 |   0.087486  |    0.044420     |   2\n",
      "       3256 |   0.243341  |    0.025728     |   0\n",
      "       3257 |   0.075454  |    0.020642     |   2\n",
      "       3258 |   0.268485  |    0.028416     |   0\n",
      "       3259 |   0.366272  |    0.142333     |   1\n",
      "       3260 |   0.263020  |    0.008563     |   0\n",
      "       3261 |   0.000167  |    0.015239     |   2\n",
      "       3262 |   0.000190  |    0.022709     |   2\n",
      "       3263 |   0.000196  |    0.018974     |   2\n",
      "       3264 |   0.000233  |    0.037522     |   2\n",
      "       3265 |   0.000208  |    0.023784     |   2\n",
      "       3266 |   0.000258  |    0.025020     |   2\n",
      "       3267 |   0.098077  |    0.018431     |   2\n",
      "       3268 |   0.239211  |    0.042798     |   0\n",
      "       3269 |   0.236363  |    0.025928     |   0\n",
      "       3270 |   0.108781  |    0.026870     |   2\n",
      "       3271 |   0.278181  |    0.055268     |   0\n",
      "       3272 |   0.262934  |    0.085841     |   1\n",
      "       3273 |   0.305552  |    0.137334     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 3274: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       3274 |   0.275060  |    0.002876     |   0\n",
      "       3275 |   0.100254  |    0.003221     |   2\n",
      "       3276 |   0.265625  |    0.048736     |   0\n",
      "       3277 |   0.272773  |    0.084935     |   1\n",
      "       3278 |   0.080157  |    0.044111     |   2\n",
      "       3279 |   0.301212  |    0.149959     |   1\n",
      "       3280 |   0.305962  |    0.057615     |   1\n",
      "       3281 |   0.291388  |    0.113011     |   1\n",
      "       3282 |   0.242039  |    0.097925     |   1\n",
      "       3283 |   0.300122  |    0.008081     |   0\n",
      "       3284 |   0.299783  |    0.142482     |   1\n",
      "       3285 |   0.212895  |    0.003033     |   0\n",
      "       3286 |   0.087046  |    0.007005     |   2\n",
      "       3287 |   0.115462  |    0.048428     |   2\n",
      "       3288 |   0.051878  |    0.019545     |   2\n",
      "       3289 |   0.317562  |    0.038744     |   0\n",
      "       3290 |   0.088567  |    0.029353     |   2\n",
      "       3291 |   0.266580  |    0.042842     |   0\n",
      "       3292 |   0.264815  |    0.011722     |   0\n",
      "       3293 |   0.092928  |    0.048602     |   2\n",
      "       3294 |   0.312942  |    0.099116     |   1\n",
      "       3295 |   0.313362  |    0.092124     |   1\n",
      "       3296 |   0.090481  |    0.013314     |   2\n",
      "       3297 |   0.236404  |    0.024205     |   0\n",
      "       3298 |   0.288258  |    0.045853     |   0\n",
      "       3299 |   0.236247  |    0.021556     |   0\n",
      "       3300 |   0.281469  |    0.097613     |   1\n",
      "       3301 |   0.273030  |    0.137481     |   1\n",
      "       3302 |   0.088363  |    0.012250     |   2\n",
      "       3303 |   0.314106  |    0.063115     |   1\n",
      "       3304 |   0.358248  |    0.058465     |   1\n",
      "       3305 |   0.257966  |    0.064369     |   0\n",
      "       3306 |   0.298804  |    0.086342     |   1\n",
      "       3307 |   0.287391  |    0.145517     |   1\n",
      "       3308 |   0.041082  |    0.009040     |   2\n",
      "       3309 |   0.321525  |    0.089214     |   1\n",
      "       3310 |   0.307599  |    0.100007     |   1\n",
      "       3311 |   0.000182  |    0.023963     |   2\n",
      "       3312 |   0.258042  |    0.151100     |   1\n",
      "       3313 |   0.255305  |    0.011186     |   0\n",
      "       3314 |   0.009666  |    0.011870     |   2\n",
      "       3315 |   0.231700  |    0.032338     |   0\n",
      "       3316 |   0.158106  |    0.041933     |   2\n",
      "       3317 |   0.324629  |    0.025395     |   0\n",
      "       3318 |   0.222226  |    0.037847     |   0\n",
      "       3319 |   0.323589  |    0.084925     |   1\n",
      "       3320 |   0.073227  |    0.024838     |   2\n",
      "       3321 |   0.347565  |    0.136685     |   1\n",
      "       3322 |   0.094426  |    0.013166     |   2\n",
      "       3323 |   0.314697  |    0.097991     |   1\n",
      "       3324 |   0.076884  |    0.015999     |   2\n",
      "       3325 |   0.034178  |    0.022786     |   2\n",
      "       3326 |   0.242205  |    0.025809     |   0\n",
      "       3327 |   0.311439  |    0.038893     |   0\n",
      "       3328 |   0.258774  |    0.017041     |   0\n",
      "       3329 |   0.280225  |    0.028099     |   0\n",
      "       3330 |   0.222355  |    0.022648     |   0\n",
      "       3331 |   0.221033  |    0.029508     |   0\n",
      "       3332 |   0.298719  |    0.026660     |   0\n",
      "       3333 |   0.090359  |    0.015958     |   2\n",
      "       3334 |   0.073234  |    0.043343     |   2\n",
      "       3335 |   0.293780  |    0.093305     |   1\n",
      "       3336 |   0.256114  |    0.004558     |   0\n",
      "       3337 |   0.321939  |    0.040037     |   0\n",
      "       3338 |   0.000162  |    0.028733     |   2\n",
      "       3339 |   0.212981  |    0.028789     |   0\n",
      "       3340 |   0.272363  |    0.143729     |   1\n",
      "       3341 |   0.292270  |    0.077353     |   1\n",
      "       3342 |   0.000188  |    0.003781     |   2\n",
      "       3343 |   0.290990  |    0.029156     |   0\n",
      "       3344 |   0.000198  |    0.029285     |   2\n",
      "       3345 |   0.000233  |    0.017464     |   2\n",
      "       3346 |   0.283525  |    0.042172     |   0\n",
      "       3347 |   0.277521  |    0.024481     |   0\n",
      "       3348 |   0.000200  |    0.027139     |   2\n",
      "       3349 |   0.244305  |    0.026207     |   0\n",
      "       3350 |   0.285782  |    0.039106     |   0\n",
      "       3351 |   0.357951  |    0.084049     |   1\n",
      "       3352 |   0.000239  |    0.029880     |   2\n",
      "       3353 |   0.249233  |    0.044249     |   0\n",
      "       3354 |   0.370825  |    0.122180     |   1\n",
      "       3355 |   0.316891  |    0.088794     |   1\n",
      "       3356 |   0.303927  |    0.144836     |   1\n",
      "       3357 |   0.421631  |    0.078353     |   1\n",
      "       3358 |   0.317900  |    0.005658     |   0\n",
      "       3359 |   0.099854  |    0.030752     |   2\n",
      "       3360 |   0.210490  |    0.051004     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 3362: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       3361 |   0.108610  |    0.009411     |   2\n",
      "       3362 |   0.284712  |    0.046910     |   0\n",
      "       3363 |   0.267798  |    0.014116     |   0\n",
      "       3364 |   0.377376  |    0.140811     |   1\n",
      "       3365 |   0.290800  |    0.084743     |   1\n",
      "       3366 |   0.106743  |    0.013687     |   2\n",
      "       3367 |   0.273314  |    0.143408     |   1\n",
      "       3368 |   0.081422  |    0.022183     |   2\n",
      "       3369 |   0.358725  |    0.040714     |   1\n",
      "       3370 |   0.242532  |    0.134793     |   1\n",
      "       3371 |   0.243429  |    0.013711     |   0\n",
      "       3372 |   0.297226  |    0.009577     |   0\n",
      "       3373 |   0.439021  |    0.092337     |   1\n",
      "       3374 |   0.086511  |    0.013239     |   2\n",
      "       3375 |   0.114519  |    0.045164     |   2\n",
      "       3376 |   0.232538  |    0.021934     |   0\n",
      "       3377 |   0.048750  |    0.034349     |   2\n",
      "       3378 |   0.225259  |    0.096487     |   1\n",
      "       3379 |   0.336404  |    0.137249     |   1\n",
      "       3380 |   0.087570  |    0.003352     |   2\n",
      "       3381 |   0.331888  |    0.010219     |   0\n",
      "       3382 |   0.094235  |    0.035811     |   2\n",
      "       3383 |   0.092239  |    0.011346     |   2\n",
      "       3384 |   0.092601  |    0.052953     |   2\n",
      "       3385 |   0.356963  |    0.092269     |   1\n",
      "       3386 |   0.039822  |    0.005699     |   2\n",
      "       3387 |   0.000174  |    0.007599     |   2\n",
      "       3388 |   0.279468  |    0.043592     |   0\n",
      "       3389 |   0.371744  |    0.131590     |   1\n",
      "       3390 |   0.010813  |    0.003915     |   2\n",
      "       3391 |   0.153434  |    0.016738     |   2\n",
      "       3392 |   0.265996  |    0.151108     |   1\n",
      "       3393 |   0.294750  |    0.015990     |   0\n",
      "       3394 |   0.310802  |    0.054057     |   1\n",
      "       3395 |   0.294188  |    0.055531     |   0\n",
      "       3396 |   0.268398  |    0.097980     |   1\n",
      "       3397 |   0.267915  |    0.074650     |   1\n",
      "       3398 |   0.066948  |    0.011027     |   2\n",
      "       3399 |   0.090071  |    0.046507     |   2\n",
      "       3400 |   0.375319  |    0.098817     |   1\n",
      "       3401 |   0.301075  |    0.091792     |   1\n",
      "       3402 |   0.073978  |    0.005060     |   2\n",
      "       3403 |   0.221195  |    0.042567     |   0\n",
      "       3404 |   0.189442  |    0.010020     |   0\n",
      "       3405 |   0.302794  |    0.041479     |   0\n",
      "       3406 |   0.279837  |    0.022884     |   0\n",
      "       3407 |   0.327119  |    0.148420     |   1\n",
      "       3408 |   0.228866  |    0.012713     |   0\n",
      "       3409 |   0.288581  |    0.085748     |   1\n",
      "       3410 |   0.255227  |    0.009884     |   0\n",
      "       3411 |   0.032507  |    0.035668     |   2\n",
      "       3412 |   0.090563  |    0.007737     |   2\n",
      "       3413 |   0.260307  |    0.058425     |   0\n",
      "       3414 |   0.072637  |    0.015009     |   2\n",
      "       3415 |   0.000163  |    0.034283     |   2\n",
      "       3416 |   0.000185  |    0.039488     |   2\n",
      "       3417 |   0.290855  |    0.098920     |   1\n",
      "       3418 |   0.000198  |    0.016043     |   2\n",
      "       3419 |   0.428546  |    0.133237     |   1\n",
      "       3420 |   0.247644  |    0.006146     |   0\n",
      "       3421 |   0.315215  |    0.010046     |   0\n",
      "       3422 |   0.281698  |    0.038515     |   0\n",
      "       3423 |   0.301570  |    0.142773     |   1\n",
      "       3424 |   0.275946  |    0.003871     |   0\n",
      "       3425 |   0.231248  |    0.011920     |   0\n",
      "       3426 |   0.000231  |    0.046027     |   2\n",
      "       3427 |   0.000202  |    0.018907     |   2\n",
      "       3428 |   0.280840  |    0.127587     |   1\n",
      "       3429 |   0.000247  |    0.025351     |   2\n",
      "       3430 |   0.286996  |    0.028328     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 3433: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       3431 |   0.095878  |    0.022376     |   2\n",
      "       3432 |   0.106342  |    0.015963     |   2\n",
      "       3433 |   0.378303  |    0.099514     |   1\n",
      "       3434 |   0.264391  |    0.027948     |   0\n",
      "       3435 |   0.345882  |    0.088296     |   1\n",
      "       3436 |   0.248437  |    0.110882     |   1\n",
      "       3437 |   0.104905  |    0.013180     |   2\n",
      "       3438 |   0.283736  |    0.127125     |   1\n",
      "       3439 |   0.078431  |    0.009256     |   2\n",
      "       3440 |   0.086525  |    0.030862     |   2\n",
      "       3441 |   0.110984  |    0.018592     |   2\n",
      "       3442 |   0.219944  |    0.027421     |   0\n",
      "       3443 |   0.211783  |    0.024410     |   0\n",
      "       3444 |   0.294542  |    0.028047     |   0\n",
      "       3445 |   0.312474  |    0.133925     |   1\n",
      "       3446 |   0.265322  |    0.003593     |   0\n",
      "       3447 |   0.048991  |    0.013616     |   2\n",
      "       3448 |   0.271259  |    0.137069     |   1\n",
      "       3449 |   0.250792  |    0.061784     |   1\n",
      "       3450 |   0.086375  |    0.032635     |   2\n",
      "       3451 |   0.268109  |    0.026652     |   0\n",
      "       3452 |   0.301486  |    0.032848     |   0\n",
      "       3453 |   0.095345  |    0.028914     |   2\n",
      "       3454 |   0.092919  |    0.022321     |   2\n",
      "       3455 |   0.363955  |    0.138414     |   1\n",
      "       3456 |   0.341110  |    0.068031     |   1\n",
      "       3457 |   0.334010  |    0.099218     |   1\n",
      "       3458 |   0.092666  |    0.013531     |   2\n",
      "       3459 |   0.282257  |    0.145070     |   1\n",
      "       3460 |   0.039992  |    0.004962     |   2\n",
      "       3461 |   0.309863  |    0.016720     |   0\n",
      "       3462 |   0.000172  |    0.040500     |   2\n",
      "       3463 |   0.252431  |    0.082964     |   1\n",
      "       3464 |   0.304322  |    0.027327     |   0\n",
      "       3465 |   0.235175  |    0.045352     |   0\n",
      "       3466 |   0.291519  |    0.087716     |   1\n",
      "       3467 |   0.319566  |    0.008135     |   0\n",
      "       3468 |   0.229828  |    0.030993     |   0\n",
      "       3469 |   0.009869  |    0.042785     |   2\n",
      "       3470 |   0.251917  |    0.017967     |   0\n",
      "       3471 |   0.149653  |    0.027574     |   2\n",
      "       3472 |   0.069554  |    0.021853     |   2\n",
      "       3473 |   0.202221  |    0.155708     |   1\n",
      "       3474 |   0.421637  |    0.038657     |   1\n",
      "       3475 |   0.247850  |    0.137225     |   1\n",
      "       3476 |   0.092110  |    0.010609     |   2\n",
      "       3477 |   0.246121  |    0.114162     |   1\n",
      "       3478 |   0.298010  |    0.056247     |   1\n",
      "       3479 |   0.075798  |    0.015597     |   2\n",
      "       3480 |   0.331224  |    0.135470     |   1\n",
      "       3481 |   0.207697  |    0.026688     |   0\n",
      "       3482 |   0.409605  |    0.085619     |   1\n",
      "       3483 |   0.265773  |    0.012299     |   0\n",
      "       3484 |   0.032547  |    0.038472     |   2\n",
      "       3485 |   0.264694  |    0.014648     |   0\n",
      "       3486 |   0.086124  |    0.045304     |   2\n",
      "       3487 |   0.071256  |    0.016357     |   2\n",
      "       3488 |   0.335961  |    0.147014     |   1\n",
      "       3489 |   0.000161  |    0.010258     |   2\n",
      "       3490 |   0.272067  |    0.084414     |   1\n",
      "       3491 |   0.286869  |    0.003585     |   0\n",
      "       3492 |   0.204496  |    0.023968     |   0\n",
      "       3493 |   0.297243  |    0.033015     |   0\n",
      "       3494 |   0.336193  |    0.146222     |   1\n",
      "       3495 |   0.000181  |    0.002927     |   2\n",
      "       3496 |   0.278086  |    0.005424     |   0\n",
      "       3497 |   0.000197  |    0.048518     |   2\n",
      "       3498 |   0.000217  |    0.009272     |   2\n",
      "       3499 |   0.253665  |    0.053436     |   0\n",
      "       3500 |   0.263189  |    0.090023     |   1\n",
      "       3501 |   0.098560  |    0.044227     |   2\n",
      "       3502 |   0.079640  |    0.029680     |   2\n",
      "       3503 |   0.083478  |    0.028013     |   2\n",
      "       3504 |   0.221036  |    0.028973     |   0\n",
      "       3505 |   0.247138  |    0.136958     |   1\n",
      "       3506 |   0.297397  |    0.017522     |   0\n",
      "       3507 |   0.308836  |    0.138696     |   1\n",
      "       3508 |   0.109465  |    0.007303     |   2\n",
      "       3509 |   0.285579  |    0.138185     |   1\n",
      "       3510 |   0.047790  |    0.014193     |   2\n",
      "       3511 |   0.256416  |    0.141190     |   1\n",
      "       3512 |   0.086473  |    0.002944     |   2\n",
      "       3513 |   0.090557  |    0.007379     |   2\n",
      "       3514 |   0.309526  |    0.034716     |   0\n",
      "       3515 |   0.238161  |    0.020604     |   0\n",
      "       3516 |   0.093797  |    0.043485     |   2\n",
      "       3517 |   0.221337  |    0.016693     |   0\n",
      "       3518 |   0.092707  |    0.034751     |   2\n",
      "       3519 |   0.230827  |    0.033626     |   0\n",
      "       3520 |   0.370710  |    0.137096     |   1\n",
      "       3521 |   0.249697  |    0.002997     |   0\n",
      "       3522 |   0.256956  |    0.015257     |   0\n",
      "       3523 |   0.228632  |    0.104865     |   1\n",
      "       3524 |   0.231533  |    0.025702     |   0\n",
      "       3525 |   0.325109  |    0.143874     |   1\n",
      "       3526 |   0.039866  |    0.007577     |   2\n",
      "       3527 |   0.261458  |    0.082756     |   1\n",
      "       3528 |   0.000172  |    0.013041     |   2\n",
      "       3529 |   0.260122  |    0.049214     |   0\n",
      "       3530 |   0.009527  |    0.005699     |   2\n",
      "       3531 |   0.273836  |    0.051888     |   0\n",
      "       3532 |   0.277074  |    0.137468     |   1\n",
      "       3533 |   0.147999  |    0.005248     |   2\n",
      "       3534 |   0.205842  |    0.013581     |   0\n",
      "       3535 |   0.251505  |    0.034679     |   0\n",
      "       3536 |   0.072106  |    0.020786     |   2\n",
      "       3537 |   0.093491  |    0.026939     |   2\n",
      "       3538 |   0.262438  |    0.024592     |   0\n",
      "       3539 |   0.270545  |    0.023027     |   0\n",
      "       3540 |   0.252165  |    0.031277     |   0\n",
      "       3541 |   0.279074  |    0.144059     |   1\n",
      "       3542 |   0.287644  |    0.068971     |   1\n",
      "       3543 |   0.269993  |    0.083015     |   1\n",
      "       3544 |   0.076891  |    0.042616     |   2\n",
      "       3545 |   0.321007  |    0.141803     |   1\n",
      "       3546 |   0.370006  |    0.050619     |   1\n",
      "       3547 |   0.255524  |    0.037538     |   0\n",
      "       3548 |   0.258635  |    0.091908     |   1\n",
      "       3549 |   0.309748  |    0.153950     |   1\n",
      "       3550 |   0.319164  |    0.009153     |   0\n",
      "       3551 |   0.250815  |    0.109999     |   1\n",
      "       3552 |   0.031304  |    0.023793     |   2\n",
      "       3553 |   0.345451  |    0.080764     |   1\n",
      "       3554 |   0.084544  |    0.012207     |   2\n",
      "       3555 |   0.071511  |    0.045242     |   2\n",
      "       3556 |   0.000157  |    0.017105     |   2\n",
      "       3557 |   0.340434  |    0.100457     |   1\n",
      "       3558 |   0.272901  |    0.084013     |   1\n",
      "       3559 |   0.000174  |    0.029132     |   2\n",
      "       3560 |   0.274303  |    0.138351     |   1\n",
      "       3561 |   0.000194  |    0.007822     |   2\n",
      "       3562 |   0.000218  |    0.046364     |   2\n",
      "       3563 |   0.275350  |    0.015460     |   0\n",
      "       3564 |   0.368067  |    0.136311     |   1\n",
      "       3565 |   0.000201  |    0.005543     |   2\n",
      "       3566 |   0.290000  |    0.017660     |   0\n",
      "       3567 |   0.000248  |    0.024349     |   2\n",
      "       3568 |   0.096092  |    0.025045     |   2\n",
      "       3569 |   0.236789  |    0.026345     |   0\n",
      "       3570 |   0.104496  |    0.030467     |   2\n",
      "       3571 |   0.279988  |    0.153160     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 3572: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       3572 |   0.098891  |    0.010760     |   2\n",
      "       3573 |   0.080702  |    0.009634     |   2\n",
      "       3574 |   0.081666  |    0.016903     |   2\n",
      "       3575 |   0.205806  |    0.035996     |   0\n",
      "       3576 |   0.312450  |    0.093056     |   1\n",
      "       3577 |   0.268074  |    0.003079     |   0\n",
      "       3578 |   0.108980  |    0.010449     |   2\n",
      "       3579 |   0.248343  |    0.139934     |   1\n",
      "       3580 |   0.049014  |    0.005870     |   2\n",
      "       3581 |   0.308456  |    0.024176     |   0\n",
      "       3582 |   0.249809  |    0.049911     |   0\n",
      "       3583 |   0.083595  |    0.016618     |   2\n",
      "       3584 |   0.325451  |    0.146991     |   1\n",
      "       3585 |   0.311536  |    0.056097     |   1\n",
      "       3586 |   0.089073  |    0.007077     |   2\n",
      "       3587 |   0.267738  |    0.059973     |   0\n",
      "       3588 |   0.321053  |    0.085150     |   1\n",
      "       3589 |   0.273704  |    0.062346     |   1\n",
      "       3590 |   0.306260  |    0.048023     |   0\n",
      "       3591 |   0.365949  |    0.058449     |   1\n",
      "       3592 |   0.343444  |    0.110056     |   1\n",
      "       3593 |   0.307233  |    0.084686     |   1\n",
      "       3594 |   0.331571  |    0.032732     |   1\n",
      "       3595 |   0.382592  |    0.156358     |   1\n",
      "       3596 |   0.290461  |    0.028295     |   1\n",
      "       3597 |   0.231214  |    0.030640     |   0\n",
      "       3598 |   0.243792  |    0.020146     |   0\n",
      "       3599 |   0.280839  |    0.039211     |   0\n",
      "       3600 |   0.094362  |    0.024281     |   2\n",
      "       3601 |   0.092162  |    0.032524     |   2\n",
      "       3602 |   0.040160  |    0.017961     |   2\n",
      "       3603 |   0.000169  |    0.045816     |   2\n",
      "       3604 |   0.365496  |    0.090946     |   1\n",
      "       3605 |   0.260821  |    0.028679     |   0\n",
      "       3606 |   0.218918  |    0.109021     |   1\n",
      "       3607 |   0.220755  |    0.013759     |   0\n",
      "       3608 |   0.009671  |    0.034120     |   2\n",
      "       3609 |   0.146816  |    0.012269     |   2\n",
      "       3610 |   0.263562  |    0.051843     |   0\n",
      "       3611 |   0.072119  |    0.008735     |   2\n",
      "       3612 |   0.090820  |    0.041343     |   2\n",
      "       3613 |   0.224712  |    0.029459     |   0\n",
      "       3614 |   0.227174  |    0.043338     |   0\n",
      "       3615 |   0.312930  |    0.074383     |   1\n",
      "       3616 |   0.272740  |    0.023726     |   0\n",
      "       3617 |   0.309691  |    0.148608     |   1\n",
      "       3618 |   0.076475  |    0.002837     |   2\n",
      "       3619 |   0.029025  |    0.007627     |   2\n",
      "       3620 |   0.082691  |    0.049979     |   2\n",
      "       3621 |   0.248376  |    0.087845     |   1\n",
      "       3622 |   0.309234  |    0.066651     |   1\n",
      "       3623 |   0.296442  |    0.092550     |   1\n",
      "       3624 |   0.069880  |    0.028154     |   2\n",
      "       3625 |   0.000156  |    0.022782     |   2\n",
      "       3626 |   0.000173  |    0.009441     |   2\n",
      "       3627 |   0.232082  |    0.048572     |   0\n",
      "       3628 |   0.257966  |    0.078692     |   1\n",
      "       3629 |   0.205090  |    0.029444     |   0\n",
      "       3630 |   0.326340  |    0.030419     |   0\n",
      "       3631 |   0.315942  |    0.139565     |   1\n",
      "       3632 |   0.242829  |    0.053022     |   1\n",
      "       3633 |   0.000196  |    0.010411     |   2\n",
      "       3634 |   0.000222  |    0.045981     |   2\n",
      "       3635 |   0.301728  |    0.010493     |   0\n",
      "       3636 |   0.000196  |    0.072647     |   2\n",
      "       3637 |   0.257835  |    0.084502     |   1\n",
      "       3638 |   0.259940  |    0.084756     |   1\n",
      "       3639 |   0.245043  |    0.017952     |   0\n",
      "       3640 |   0.281636  |    0.142031     |   1\n",
      "       3641 |   0.229593  |    0.094675     |   1\n",
      "       3642 |   0.000232  |    0.005209     |   2\n",
      "       3643 |   0.240505  |    0.046051     |   0\n",
      "       3644 |   0.093801  |    0.006069     |   2\n",
      "       3645 |   0.264897  |    0.043823     |   0\n",
      "       3646 |   0.198083  |    0.015529     |   0\n",
      "       3647 |   0.101752  |    0.042570     |   2\n",
      "       3648 |   0.254908  |    0.020278     |   0\n",
      "       3649 |   0.353292  |    0.153999     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 3650: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       3650 |   0.263664  |    0.031094     |   1\n",
      "       3651 |   0.095861  |    0.012291     |   2\n",
      "       3652 |   0.076323  |    0.029171     |   2\n",
      "       3653 |   0.240954  |    0.127061     |   1\n",
      "       3654 |   0.254665  |    0.016045     |   0\n",
      "       3655 |   0.267845  |    0.161393     |   1\n",
      "       3656 |   0.082111  |    0.005302     |   2\n",
      "       3657 |   0.107583  |    0.004021     |   2\n",
      "       3658 |   0.288491  |    0.046611     |   0\n",
      "       3659 |   0.216397  |    0.011675     |   0\n",
      "       3660 |   0.046171  |    0.024557     |   2\n",
      "       3661 |   0.084839  |    0.040678     |   2\n",
      "       3662 |   0.246903  |    0.008223     |   0\n",
      "       3663 |   0.084826  |    0.047948     |   2\n",
      "       3664 |   0.094218  |    0.025655     |   2\n",
      "       3665 |   0.289847  |    0.145389     |   1\n",
      "       3666 |   0.286428  |    0.053973     |   1\n",
      "       3667 |   0.234307  |    0.097501     |   1\n",
      "       3668 |   0.191942  |    0.026124     |   0\n",
      "       3669 |   0.088745  |    0.027077     |   2\n",
      "       3670 |   0.235960  |    0.158735     |   1\n",
      "       3671 |   0.277681  |    0.007928     |   0\n",
      "       3672 |   0.301749  |    0.071443     |   1\n",
      "       3673 |   0.182901  |    0.121052     |   1\n",
      "       3674 |   0.251989  |    0.096282     |   1\n",
      "       3675 |   0.271526  |    0.087388     |   1\n",
      "       3676 |   0.250100  |    0.016408     |   0\n",
      "       3677 |   0.283449  |    0.137511     |   1\n",
      "       3678 |   0.297852  |    0.082777     |   1\n",
      "       3679 |   0.038722  |    0.016863     |   2\n",
      "       3680 |   0.323620  |    0.098630     |   1\n",
      "       3681 |   0.276680  |    0.045747     |   0\n",
      "       3682 |   0.292091  |    0.132428     |   1\n",
      "       3683 |   0.346570  |    0.068747     |   1\n",
      "       3684 |   0.231142  |    0.089239     |   1\n",
      "       3685 |   0.000162  |    0.015545     |   2\n",
      "       3686 |   0.345276  |    0.152293     |   1\n",
      "       3687 |   0.325720  |    0.093060     |   1\n",
      "       3688 |   0.353689  |    0.063382     |   1\n",
      "       3689 |   0.396099  |    0.090151     |   1\n",
      "       3690 |   0.009346  |    0.009818     |   2\n",
      "       3691 |   0.219260  |    0.037226     |   0\n",
      "       3692 |   0.293933  |    0.085394     |   1\n",
      "       3693 |   0.257143  |    0.148635     |   1\n",
      "       3694 |   0.142176  |    0.006496     |   2\n",
      "       3695 |   0.279609  |    0.108438     |   1\n",
      "       3696 |   0.068236  |    0.009311     |   2\n",
      "       3697 |   0.295658  |    0.130994     |   1\n",
      "       3698 |   0.234273  |    0.002976     |   0\n",
      "       3699 |   0.293674  |    0.010036     |   0\n",
      "       3700 |   0.290898  |    0.041635     |   0\n",
      "       3701 |   0.089892  |    0.011316     |   2\n",
      "       3702 |   0.312704  |    0.045724     |   0\n",
      "       3703 |   0.072310  |    0.008736     |   2\n",
      "       3704 |   0.357800  |    0.156523     |   1\n",
      "       3705 |   0.260145  |    0.015240     |   0\n",
      "       3706 |   0.270185  |    0.049476     |   1\n",
      "       3707 |   0.030051  |    0.008403     |   2\n",
      "       3708 |   0.357378  |    0.040911     |   0\n",
      "       3709 |   0.083312  |    0.021402     |   2\n",
      "       3710 |   0.336882  |    0.139893     |   1\n",
      "       3711 |   0.067611  |    0.002835     |   2\n",
      "       3712 |   0.000154  |    0.011712     |   2\n",
      "       3713 |   0.000175  |    0.035041     |   2\n",
      "       3714 |   0.225325  |    0.058207     |   1\n",
      "       3715 |   0.327380  |    0.041347     |   0\n",
      "       3716 |   0.211093  |    0.021656     |   0\n",
      "       3717 |   0.294787  |    0.100620     |   1\n",
      "       3718 |   0.221086  |    0.094184     |   1\n",
      "       3719 |   0.000195  |    0.010097     |   2\n",
      "       3720 |   0.295149  |    0.110684     |   1\n",
      "       3721 |   0.246320  |    0.014784     |   0\n",
      "       3722 |   0.000235  |    0.046806     |   2\n",
      "       3723 |   0.000194  |    0.012821     |   2\n",
      "       3724 |   0.000234  |    0.032112     |   2\n",
      "       3725 |   0.237581  |    0.042065     |   0\n",
      "       3726 |   0.208707  |    0.139826     |   1\n",
      "       3727 |   0.098011  |    0.002810     |   2\n",
      "       3728 |   0.101767  |    0.010283     |   2\n",
      "       3729 |   0.387325  |    0.066638     |   0\n",
      "       3730 |   0.284131  |    0.072254     |   1\n",
      "       3731 |   0.323644  |    0.085404     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 3733: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       3732 |   0.282826  |    0.003332     |   0\n",
      "       3733 |   0.250042  |    0.028203     |   0\n",
      "       3734 |   0.273427  |    0.046466     |   0\n",
      "       3735 |   0.225564  |    0.014017     |   0\n",
      "       3736 |   0.229411  |    0.167390     |   1\n",
      "       3737 |   0.322390  |    0.016523     |   1\n",
      "       3738 |   0.234538  |    0.051074     |   0\n",
      "       3739 |   0.242277  |    0.013985     |   0\n",
      "       3740 |   0.295102  |    0.158997     |   1\n",
      "       3741 |   0.251392  |    0.019626     |   1\n",
      "       3742 |   0.239510  |    0.058792     |   0\n",
      "       3743 |   0.352576  |    0.096954     |   1\n",
      "       3744 |   0.216944  |    0.086790     |   1\n",
      "       3745 |   0.249701  |    0.011475     |   0\n",
      "       3746 |   0.242204  |    0.030872     |   0\n",
      "       3747 |   0.098949  |    0.016530     |   2\n",
      "       3748 |   0.289355  |    0.030228     |   0\n",
      "       3749 |   0.281374  |    0.022634     |   0\n",
      "       3750 |   0.203982  |    0.029462     |   0\n",
      "       3751 |   0.079090  |    0.010411     |   2\n",
      "       3752 |   0.322609  |    0.148679     |   1\n",
      "       3753 |   0.081011  |    0.004707     |   2\n",
      "       3754 |   0.113611  |    0.014249     |   2\n",
      "       3755 |   0.301371  |    0.028656     |   0\n",
      "       3756 |   0.211394  |    0.039384     |   0\n",
      "       3757 |   0.299887  |    0.100982     |   1\n",
      "       3758 |   0.048630  |    0.014305     |   2\n",
      "       3759 |   0.087508  |    0.036921     |   2\n",
      "       3760 |   0.093382  |    0.015011     |   2\n",
      "       3761 |   0.302233  |    0.162807     |   1\n",
      "       3762 |   0.325820  |    0.083315     |   1\n",
      "       3763 |   0.089888  |    0.004914     |   2\n",
      "       3764 |   0.227930  |    0.027772     |   0\n",
      "       3765 |   0.249638  |    0.151497     |   1\n",
      "       3766 |   0.311406  |    0.054356     |   1\n",
      "       3767 |   0.094345  |    0.008180     |   2\n",
      "       3768 |   0.042286  |    0.045863     |   2\n",
      "       3769 |   0.306017  |    0.017269     |   0\n",
      "       3770 |   0.223075  |    0.041213     |   0\n",
      "       3771 |   0.229544  |    0.018538     |   0\n",
      "       3772 |   0.279043  |    0.142763     |   1\n",
      "       3773 |   0.307773  |    0.002891     |   0\n",
      "       3774 |   0.000166  |    0.010839     |   2\n",
      "       3775 |   0.286338  |    0.050907     |   0\n",
      "       3776 |   0.264482  |    0.099146     |   1\n",
      "       3777 |   0.298822  |    0.063939     |   1\n",
      "       3778 |   0.314308  |    0.135262     |   1\n",
      "       3779 |   0.347198  |    0.058195     |   1\n",
      "       3780 |   0.289245  |    0.102728     |   1\n",
      "       3781 |   0.263956  |    0.064154     |   1\n",
      "       3782 |   0.008413  |    0.022820     |   2\n",
      "       3783 |   0.291363  |    0.096828     |   1\n",
      "       3784 |   0.233955  |    0.023267     |   0\n",
      "       3785 |   0.226238  |    0.028759     |   0\n",
      "       3786 |   0.326180  |    0.142934     |   1\n",
      "       3787 |   0.297971  |    0.050918     |   1\n",
      "       3788 |   0.295520  |    0.015119     |   0\n",
      "       3789 |   0.293483  |    0.143147     |   1\n",
      "       3790 |   0.144123  |    0.008145     |   2\n",
      "       3791 |   0.345293  |    0.076106     |   1\n",
      "       3792 |   0.280771  |    0.026145     |   0\n",
      "       3793 |   0.290007  |    0.033862     |   0\n",
      "       3794 |   0.303415  |    0.078786     |   1\n",
      "       3795 |   0.247487  |    0.023285     |   0\n",
      "       3796 |   0.273980  |    0.142562     |   1\n",
      "       3797 |   0.250270  |    0.026229     |   0\n",
      "       3798 |   0.067840  |    0.071843     |   2\n",
      "       3799 |   0.269580  |    0.013776     |   0\n",
      "       3800 |   0.264483  |    0.105338     |   1\n",
      "       3801 |   0.423222  |    0.149373     |   1\n",
      "       3802 |   0.293184  |    0.031645     |   0\n",
      "       3803 |   0.089672  |    0.017859     |   2\n",
      "       3804 |   0.393694  |    0.091612     |   1\n",
      "       3805 |   0.210395  |    0.006838     |   0\n",
      "       3806 |   0.074133  |    0.046000     |   2\n",
      "       3807 |   0.029706  |    0.013269     |   2\n",
      "       3808 |   0.206259  |    0.031501     |   0\n",
      "       3809 |   0.084078  |    0.026240     |   2\n",
      "       3810 |   0.067727  |    0.048404     |   2\n",
      "       3811 |   0.176360  |    0.147590     |   1\n",
      "       3812 |   0.271656  |    0.004398     |   0\n",
      "       3813 |   0.000152  |    0.009801     |   2\n",
      "       3814 |   0.265666  |    0.134119     |   1\n",
      "       3815 |   0.000164  |    0.012967     |   2\n",
      "       3816 |   0.164799  |    0.131740     |   1\n",
      "       3817 |   0.350021  |    0.088959     |   1\n",
      "       3818 |   0.229838  |    0.150195     |   1\n",
      "       3819 |   0.270433  |    0.089313     |   1\n",
      "       3820 |   0.000190  |    0.008898     |   2\n",
      "       3821 |   0.217964  |    0.042408     |   0\n",
      "       3822 |   0.000208  |    0.020918     |   2\n",
      "       3823 |   0.000182  |    0.045156     |   2\n",
      "       3824 |   0.000212  |    0.016847     |   2\n",
      "       3825 |   0.091342  |    0.029324     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 3827: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       3826 |   0.100747  |    0.030500     |   2\n",
      "       3827 |   0.096040  |    0.011290     |   2\n",
      "       3828 |   0.072323  |    0.031889     |   2\n",
      "       3829 |   0.179626  |    0.017359     |   0\n",
      "       3830 |   0.210364  |    0.030291     |   0\n",
      "       3831 |   0.081339  |    0.029548     |   2\n",
      "       3832 |   0.200184  |    0.134157     |   1\n",
      "       3833 |   0.254264  |    0.010443     |   0\n",
      "       3834 |   0.216089  |    0.019756     |   0\n",
      "       3835 |   0.300472  |    0.031760     |   0\n",
      "       3836 |   0.258774  |    0.026512     |   0\n",
      "       3837 |   0.271459  |    0.026882     |   0\n",
      "       3838 |   0.240549  |    0.032440     |   0\n",
      "       3839 |   0.239898  |    0.030124     |   0\n",
      "       3840 |   0.167963  |    0.023793     |   0\n",
      "       3841 |   0.251904  |    0.131821     |   1\n",
      "       3842 |   0.286803  |    0.007725     |   0\n",
      "       3843 |   0.312671  |    0.020104     |   0\n",
      "       3844 |   0.107783  |    0.030756     |   2\n",
      "       3845 |   0.269140  |    0.028703     |   0\n",
      "       3846 |   0.049032  |    0.022723     |   2\n",
      "       3847 |   0.242194  |    0.025582     |   0\n",
      "       3848 |   0.246166  |    0.031883     |   0\n",
      "       3849 |   0.081717  |    0.028772     |   2\n",
      "       3850 |   0.276789  |    0.032461     |   0\n",
      "       3851 |   0.255529  |    0.102433     |   1\n",
      "       3852 |   0.090925  |    0.024762     |   2\n",
      "       3853 |   0.092754  |    0.038678     |   2\n",
      "       3854 |   0.260452  |    0.017301     |   0\n",
      "       3855 |   0.296020  |    0.029909     |   0\n",
      "       3856 |   0.085605  |    0.032176     |   2\n",
      "       3857 |   0.040448  |    0.016904     |   2\n",
      "       3858 |   0.200761  |    0.032298     |   0\n",
      "       3859 |   0.284103  |    0.096229     |   1\n",
      "       3860 |   0.232434  |    0.015325     |   0\n",
      "       3861 |   0.296500  |    0.046095     |   0\n",
      "       3862 |   0.000164  |    0.007802     |   2\n",
      "       3863 |   0.008578  |    0.046313     |   2\n",
      "       3864 |   0.265716  |    0.007851     |   0\n",
      "       3865 |   0.149740  |    0.037911     |   2\n",
      "       3866 |   0.262514  |    0.151567     |   1\n",
      "       3867 |   0.240699  |    0.002936     |   0\n",
      "       3868 |   0.071492  |    0.012348     |   2\n",
      "       3869 |   0.092090  |    0.029749     |   2\n",
      "       3870 |   0.249874  |    0.029518     |   0\n",
      "       3871 |   0.221865  |    0.045742     |   0\n",
      "       3872 |   0.075574  |    0.006239     |   2\n",
      "       3873 |   0.033816  |    0.044027     |   2\n",
      "       3874 |   0.265520  |    0.090854     |   1\n",
      "       3875 |   0.192803  |    0.022591     |   0\n",
      "       3876 |   0.218764  |    0.031887     |   0\n",
      "       3877 |   0.200928  |    0.025563     |   0\n",
      "       3878 |   0.090981  |    0.027707     |   2\n",
      "       3879 |   0.245493  |    0.082423     |   1\n",
      "       3880 |   0.238423  |    0.029649     |   0\n",
      "       3881 |   0.069233  |    0.030465     |   2\n",
      "       3882 |   0.295808  |    0.087281     |   1\n",
      "       3883 |   0.000146  |    0.025526     |   2\n",
      "       3884 |   0.259648  |    0.141448     |   1\n",
      "       3885 |   0.000161  |    0.002888     |   2\n",
      "       3886 |   0.278617  |    0.012612     |   0\n",
      "       3887 |   0.000177  |    0.046737     |   2\n",
      "       3888 |   0.000199  |    0.017757     |   2\n",
      "       3889 |   0.253446  |    0.144952     |   1\n",
      "       3890 |   0.281416  |    0.082572     |   1\n",
      "       3891 |   0.000178  |    0.012320     |   2\n",
      "       3892 |   0.000205  |    0.048101     |   2\n",
      "       3893 |   0.287408  |    0.081049     |   1\n",
      "       3894 |   0.094654  |    0.017484     |   2\n",
      "       3895 |   0.300038  |    0.143615     |   1\n",
      "       3896 |   0.232302  |    0.002855     |   0\n",
      "       3897 |   0.228642  |    0.016968     |   0\n",
      "       3898 |   0.272185  |    0.090665     |   1\n",
      "       3899 |   0.282153  |    0.128027     |   1\n",
      "       3900 |   0.220317  |    0.007344     |   0\n",
      "       3901 |   0.279674  |    0.080022     |   1\n",
      "       3902 |   0.235286  |    0.016386     |   0\n",
      "       3903 |   0.101063  |    0.075152     |   2\n",
      "       3904 |   0.317430  |    0.033240     |   0\n",
      "       3905 |   0.284162  |    0.148770     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 3907: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       3906 |   0.213229  |    0.021051     |   0\n",
      "       3907 |   0.096416  |    0.013881     |   2\n",
      "       3908 |   0.075311  |    0.044417     |   2\n",
      "       3909 |   0.076860  |    0.013690     |   2\n",
      "       3910 |   0.330939  |    0.145461     |   1\n",
      "       3911 |   0.276812  |    0.027675     |   1\n",
      "       3912 |   0.241846  |    0.030326     |   0\n",
      "       3913 |   0.267945  |    0.024564     |   0\n",
      "       3914 |   0.109106  |    0.022910     |   2\n",
      "       3915 |   0.307925  |    0.137856     |   1\n",
      "       3916 |   0.228807  |    0.104385     |   1\n",
      "       3917 |   0.342256  |    0.085338     |   1\n",
      "       3918 |   0.260673  |    0.007897     |   0\n",
      "       3919 |   0.293001  |    0.090976     |   1\n",
      "       3920 |   0.046837  |    0.013156     |   2\n",
      "       3921 |   0.339579  |    0.151700     |   1\n",
      "       3922 |   0.079781  |    0.011423     |   2\n",
      "       3923 |   0.258861  |    0.059441     |   1\n",
      "       3924 |   0.209042  |    0.018856     |   0\n",
      "       3925 |   0.207499  |    0.131409     |   1\n",
      "       3926 |   0.085791  |    0.006913     |   2\n",
      "       3927 |   0.232581  |    0.031094     |   0\n",
      "       3928 |   0.258711  |    0.048186     |   0\n",
      "       3929 |   0.242592  |    0.097289     |   1\n",
      "       3930 |   0.269491  |    0.086267     |   1\n",
      "       3931 |   0.202745  |    0.011297     |   0\n",
      "       3932 |   0.251578  |    0.051256     |   0\n",
      "       3933 |   0.316323  |    0.093866     |   1\n",
      "       3934 |   0.328152  |    0.090878     |   1\n",
      "       3935 |   0.275280  |    0.091230     |   1\n",
      "       3936 |   0.264651  |    0.016693     |   0\n",
      "       3937 |   0.258629  |    0.075477     |   1\n",
      "       3938 |   0.294390  |    0.037714     |   0\n",
      "       3939 |   0.309489  |    0.095320     |   1\n",
      "       3940 |   0.219207  |    0.029379     |   0\n",
      "       3941 |   0.221181  |    0.027134     |   0\n",
      "       3942 |   0.091727  |    0.011311     |   2\n",
      "       3943 |   0.319380  |    0.144063     |   1\n",
      "       3944 |   0.256089  |    0.080342     |   1\n",
      "       3945 |   0.089418  |    0.005919     |   2\n",
      "       3946 |   0.038891  |    0.055334     |   2\n",
      "       3947 |   0.000160  |    0.018852     |   2\n",
      "       3948 |   0.009541  |    0.027384     |   2\n",
      "       3949 |   0.141422  |    0.020265     |   2\n",
      "       3950 |   0.067592  |    0.033085     |   2\n",
      "       3951 |   0.086845  |    0.017630     |   2\n",
      "       3952 |   0.071981  |    0.051312     |   2\n",
      "       3953 |   0.031890  |    0.021044     |   2\n",
      "       3954 |   0.083139  |    0.027324     |   2\n",
      "       3955 |   0.306219  |    0.141334     |   1\n",
      "       3956 |   0.195421  |    0.010536     |   0\n",
      "       3957 |   0.260600  |    0.075967     |   1\n",
      "       3958 |   0.271883  |    0.107252     |   1\n",
      "       3959 |   0.203149  |    0.011016     |   0\n",
      "       3960 |   0.290799  |    0.034799     |   0\n",
      "       3961 |   0.296806  |    0.128956     |   1\n",
      "       3962 |   0.196990  |    0.006646     |   0\n",
      "       3963 |   0.209786  |    0.011252     |   0\n",
      "       3964 |   0.275151  |    0.016538     |   0\n",
      "       3965 |   0.339799  |    0.152835     |   1\n",
      "       3966 |   0.257133  |    0.003097     |   0\n",
      "       3967 |   0.065933  |    0.005414     |   2\n",
      "       3968 |   0.265262  |    0.047728     |   0\n",
      "       3969 |   0.000146  |    0.019721     |   2\n",
      "       3970 |   0.000160  |    0.031058     |   2\n",
      "       3971 |   0.000180  |    0.021567     |   2\n",
      "       3972 |   0.303054  |    0.036791     |   0\n",
      "       3973 |   0.217730  |    0.142386     |   1\n",
      "       3974 |   0.000205  |    0.003562     |   2\n",
      "       3975 |   0.000173  |    0.012718     |   2\n",
      "       3976 |   0.288385  |    0.143658     |   1\n",
      "       3977 |   0.271503  |    0.007130     |   0\n",
      "       3978 |   0.369059  |    0.083673     |   1\n",
      "       3979 |   0.000206  |    0.004442     |   2\n",
      "       3980 |   0.217956  |    0.042886     |   0\n",
      "       3981 |   0.187243  |    0.035485     |   0\n",
      "       3982 |   0.253422  |    0.140564     |   1\n",
      "       3983 |   0.265095  |    0.102927     |   1\n",
      "       3984 |   0.355021  |    0.095221     |   1\n",
      "       3985 |   0.266074  |    0.005826     |   0\n",
      "       3986 |   0.251412  |    0.017341     |   0\n",
      "       3987 |   0.092553  |    0.030140     |   2\n",
      "       3988 |   0.207052  |    0.084716     |   1\n",
      "       3989 |   0.234931  |    0.137928     |   1\n",
      "       3990 |   0.298071  |    0.004541     |   0\n",
      "       3991 |   0.097695  |    0.009763     |   2\n",
      "       3992 |   0.336710  |    0.157096     |   1\n",
      "       3993 |   0.314639  |    0.102223     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 3994: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       3994 |   0.255377  |    0.147678     |   1\n",
      "       3995 |   0.095628  |    0.008270     |   2\n",
      "       3996 |   0.073373  |    0.048630     |   2\n",
      "       3997 |   0.076741  |    0.011926     |   2\n",
      "       3998 |   0.104913  |    0.032927     |   2\n",
      "       3999 |   0.045727  |    0.022360     |   2\n",
      "       4000 |   0.287250  |    0.030358     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 4000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 4000: Plotting estimates.\n",
      "Exception in thread neuralnilm-data-process:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 810, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/dk3810/workspace/python/neuralnilm/neuralnilm/data/datathread.py\", line 16, in run\n",
      "    batch = self.data_pipeline.get_batch(**self._get_batch_kwargs)\n",
      "  File \"/home/dk3810/workspace/python/neuralnilm/neuralnilm/data/datapipeline.py\", line 46, in get_batch\n",
      "    batch = self._source_iterators[source_id].next()\n",
      "ValueError: generator already executing\n",
      "\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       4001 |   0.090583  |    0.041545     |   2\n",
      "       4002 |   0.069353  |    0.014014     |   2\n",
      "       4003 |   0.289042  |    0.058315     |   0\n",
      "       4004 |   0.247173  |    0.098947     |   1\n",
      "       4005 |   0.270706  |    0.006807     |   0\n",
      "       4006 |   0.286974  |    0.046943     |   0\n",
      "       4007 |   0.242260  |    0.024216     |   0\n",
      "       4008 |   0.073644  |    0.042072     |   2\n",
      "       4009 |   0.267738  |    0.135707     |   1\n",
      "       4010 |   0.235750  |    0.010216     |   0\n",
      "       4011 |   0.177536  |    0.024099     |   0\n",
      "       4012 |   0.231366  |    0.203701     |   1\n",
      "       4013 |   0.104915  |    0.009110     |   2\n",
      "       4014 |   0.256035  |    0.076430     |   1\n",
      "       4015 |   0.243266  |    0.018888     |   0\n",
      "       4016 |   0.294083  |    0.042484     |   0\n",
      "       4017 |   0.282520  |    0.019879     |   0\n",
      "       4018 |   0.319610  |    0.130105     |   1\n",
      "       4019 |   0.045681  |    0.013334     |   2\n",
      "       4020 |   0.269576  |    0.023074     |   0\n",
      "       4021 |   0.265904  |    0.048554     |   0\n",
      "       4022 |   0.286268  |    0.028587     |   0\n",
      "       4023 |   0.331058  |    0.152697     |   1\n",
      "       4024 |   0.082392  |    0.008259     |   2\n",
      "       4025 |   0.303431  |    0.052965     |   1\n",
      "       4026 |   0.241974  |    0.036273     |   0\n",
      "       4027 |   0.303402  |    0.102568     |   1\n",
      "       4028 |   0.354701  |    0.084077     |   1\n",
      "       4029 |   0.090308  |    0.032405     |   2\n",
      "       4030 |   0.092448  |    0.030259     |   2\n",
      "       4031 |   0.233554  |    0.147165     |   1\n",
      "       4032 |   0.306134  |    0.053108     |   1\n",
      "       4033 |   0.232092  |    0.005359     |   0\n",
      "       4034 |   0.259712  |    0.055406     |   0\n",
      "       4035 |   0.369370  |    0.009457     |   0\n",
      "       4036 |   0.185369  |    0.050687     |   0\n",
      "       4037 |   0.091335  |    0.014647     |   2\n",
      "       4038 |   0.041371  |    0.033791     |   2\n",
      "       4039 |   0.296116  |    0.140667     |   1\n",
      "       4040 |   0.346251  |    0.148747     |   1\n",
      "       4041 |   0.179732  |    0.013637     |   0\n",
      "       4042 |   0.297069  |    0.102823     |   1\n",
      "       4043 |   0.221290  |    0.052798     |   1\n",
      "       4044 |   0.273382  |    0.026527     |   0\n",
      "       4045 |   0.000152  |    0.046562     |   2\n",
      "       4046 |   0.259144  |    0.090829     |   1\n",
      "       4047 |   0.008371  |    0.016245     |   2\n",
      "       4048 |   0.143338  |    0.032403     |   2\n",
      "       4049 |   0.352757  |    0.104305     |   1\n",
      "       4050 |   0.307096  |    0.080215     |   1\n",
      "       4051 |   0.068882  |    0.011789     |   2\n",
      "       4052 |   0.088869  |    0.021773     |   2\n",
      "       4053 |   0.072572  |    0.030690     |   2\n",
      "       4054 |   0.205307  |    0.014815     |   0\n",
      "       4055 |   0.212316  |    0.032099     |   0\n",
      "       4056 |   0.284756  |    0.091578     |   1\n",
      "       4057 |   0.031834  |    0.008380     |   2\n",
      "       4058 |   0.079340  |    0.041545     |   2\n",
      "       4059 |   0.066293  |    0.007008     |   2\n",
      "       4060 |   0.000146  |    0.049216     |   2\n",
      "       4061 |   0.000159  |    0.021802     |   2\n",
      "       4062 |   0.000179  |    0.015763     |   2\n",
      "       4063 |   0.000198  |    0.025477     |   2\n",
      "       4064 |   0.289682  |    0.031519     |   0\n",
      "       4065 |   0.000171  |    0.027910     |   2\n",
      "       4066 |   0.000203  |    0.053634     |   2\n",
      "       4067 |   0.259111  |    0.084802     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 4070: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       4068 |   0.089624  |    0.014768     |   2\n",
      "       4069 |   0.094640  |    0.010077     |   2\n",
      "       4070 |   0.091036  |    0.037765     |   2\n",
      "       4071 |   0.300149  |    0.086357     |   1\n",
      "       4072 |   0.255229  |    0.027033     |   0\n",
      "       4073 |   0.071679  |    0.029351     |   2\n",
      "       4074 |   0.251739  |    0.138854     |   1\n",
      "       4075 |   0.249208  |    0.093233     |   1\n",
      "       4076 |   0.316805  |    0.089258     |   1\n",
      "       4077 |   0.338795  |    0.053590     |   1\n",
      "       4078 |   0.076847  |    0.034085     |   2\n",
      "       4079 |   0.317106  |    0.143410     |   1\n",
      "       4080 |   0.099361  |    0.009843     |   2\n",
      "       4081 |   0.044879  |    0.004358     |   2\n",
      "       4082 |   0.264179  |    0.138355     |   1\n",
      "       4083 |   0.079021  |    0.003884     |   2\n",
      "       4084 |   0.270087  |    0.014382     |   0\n",
      "       4085 |   0.236250  |    0.027019     |   0\n",
      "       4086 |   0.287119  |    0.024062     |   0\n",
      "       4087 |   0.236998  |    0.044156     |   0\n",
      "       4088 |   0.082668  |    0.006590     |   2\n",
      "       4089 |   0.323717  |    0.041397     |   0\n",
      "       4090 |   0.291973  |    0.021834     |   0\n",
      "       4091 |   0.092298  |    0.039219     |   2\n",
      "       4092 |   0.087635  |    0.007911     |   2\n",
      "       4093 |   0.246141  |    0.044613     |   0\n",
      "       4094 |   0.315439  |    0.017767     |   0\n",
      "       4095 |   0.293639  |    0.049175     |   0\n",
      "       4096 |   0.254820  |    0.011707     |   0\n",
      "       4097 |   0.231370  |    0.103666     |   1\n",
      "       4098 |   0.040627  |    0.029525     |   2\n",
      "       4099 |   0.000151  |    0.030228     |   2\n",
      "       4100 |   0.244148  |    0.102218     |   1\n",
      "       4101 |   0.008124  |    0.021220     |   2\n",
      "       4102 |   0.141067  |    0.026919     |   2\n",
      "       4103 |   0.281719  |    0.027742     |   0\n",
      "       4104 |   0.288047  |    0.054599     |   0\n",
      "       4105 |   0.241655  |    0.097772     |   1\n",
      "       4106 |   0.276426  |    0.063267     |   1\n",
      "       4107 |   0.218876  |    0.123022     |   1\n",
      "       4108 |   0.211377  |    0.068809     |   1\n",
      "       4109 |   0.241643  |    0.080866     |   1\n",
      "       4110 |   0.067151  |    0.010555     |   2\n",
      "       4111 |   0.285929  |    0.132740     |   1\n",
      "       4112 |   0.089658  |    0.005379     |   2\n",
      "       4113 |   0.222121  |    0.039607     |   0\n",
      "       4114 |   0.250973  |    0.013152     |   0\n",
      "       4115 |   0.245655  |    0.038241     |   0\n",
      "       4116 |   0.269022  |    0.094138     |   1\n",
      "       4117 |   0.256793  |    0.006900     |   0\n",
      "       4118 |   0.233468  |    0.044112     |   0\n",
      "       4119 |   0.331376  |    0.100501     |   1\n",
      "       4120 |   0.310285  |    0.099515     |   1\n",
      "       4121 |   0.318234  |    0.024577     |   0\n",
      "       4122 |   0.228798  |    0.140375     |   1\n",
      "       4123 |   0.252808  |    0.016372     |   0\n",
      "       4124 |   0.254070  |    0.035458     |   1\n",
      "       4125 |   0.072503  |    0.040760     |   2\n",
      "       4126 |   0.256868  |    0.040826     |   0\n",
      "       4127 |   0.259300  |    0.091754     |   1\n",
      "       4128 |   0.266618  |    0.013202     |   0\n",
      "       4129 |   0.235457  |    0.047823     |   0\n",
      "       4130 |   0.033565  |    0.005109     |   2\n",
      "       4131 |   0.089621  |    0.048330     |   2\n",
      "       4132 |   0.229621  |    0.137470     |   1\n",
      "       4133 |   0.066619  |    0.002991     |   2\n",
      "       4134 |   0.000143  |    0.007083     |   2\n",
      "       4135 |   0.265636  |    0.041770     |   0\n",
      "       4136 |   0.288258  |    0.018138     |   0\n",
      "       4137 |   0.270895  |    0.041312     |   0\n",
      "       4138 |   0.299341  |    0.013592     |   0\n",
      "       4139 |   0.000157  |    0.041290     |   2\n",
      "       4140 |   0.373916  |    0.131200     |   1\n",
      "       4141 |   0.309348  |    0.045458     |   1\n",
      "       4142 |   0.274123  |    0.046055     |   0\n",
      "       4143 |   0.262529  |    0.089775     |   1\n",
      "       4144 |   0.000172  |    0.005444     |   2\n",
      "       4145 |   0.318530  |    0.087932     |   1\n",
      "       4146 |   0.000193  |    0.008448     |   2\n",
      "       4147 |   0.247390  |    0.034178     |   0\n",
      "       4148 |   0.213262  |    0.105074     |   1\n",
      "       4149 |   0.000172  |    0.029255     |   2\n",
      "       4150 |   0.284960  |    0.031400     |   0\n",
      "       4151 |   0.304639  |    0.084721     |   1\n",
      "       4152 |   0.271665  |    0.131716     |   1\n",
      "       4153 |   0.219912  |    0.005554     |   0\n",
      "       4154 |   0.294110  |    0.017965     |   0\n",
      "       4155 |   0.000203  |    0.027610     |   2\n",
      "       4156 |   0.258934  |    0.019974     |   0\n",
      "       4157 |   0.096967  |    0.042607     |   2\n",
      "       4158 |   0.096127  |    0.012093     |   2\n",
      "       4159 |   0.239653  |    0.048714     |   0\n",
      "       4160 |   0.297353  |    0.049716     |   1\n",
      "       4161 |   0.204941  |    0.025232     |   0\n",
      "       4162 |   0.279828  |    0.031470     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 4163: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       4163 |   0.098984  |    0.006612     |   2\n",
      "       4164 |   0.077098  |    0.039058     |   2\n",
      "       4165 |   0.194689  |    0.157195     |   1\n",
      "       4166 |   0.347549  |    0.036565     |   1\n",
      "       4167 |   0.251603  |    0.031098     |   0\n",
      "       4168 |   0.077544  |    0.016596     |   2\n",
      "       4169 |   0.339642  |    0.133480     |   1\n",
      "       4170 |   0.195945  |    0.094292     |   1\n",
      "       4171 |   0.099448  |    0.018575     |   2\n",
      "       4172 |   0.262937  |    0.139202     |   1\n",
      "       4173 |   0.234851  |    0.062434     |   1\n",
      "       4174 |   0.045507  |    0.011798     |   2\n",
      "       4175 |   0.236620  |    0.140317     |   1\n",
      "       4176 |   0.254464  |    0.074932     |   1\n",
      "       4177 |   0.080600  |    0.043823     |   2\n",
      "       4178 |   0.285426  |    0.032006     |   0\n",
      "       4179 |   0.087611  |    0.027221     |   2\n",
      "       4180 |   0.288851  |    0.140244     |   1\n",
      "       4181 |   0.093045  |    0.009557     |   2\n",
      "       4182 |   0.280795  |    0.021379     |   0\n",
      "       4183 |   0.250139  |    0.153722     |   1\n",
      "       4184 |   0.083383  |    0.004693     |   2\n",
      "       4185 |   0.266977  |    0.033077     |   0\n",
      "       4186 |   0.040367  |    0.046689     |   2\n",
      "       4187 |   0.259105  |    0.009804     |   0\n",
      "       4188 |   0.300562  |    0.044743     |   0\n",
      "       4189 |   0.243861  |    0.012185     |   0\n",
      "       4190 |   0.329657  |    0.143961     |   1\n",
      "       4191 |   0.242596  |    0.084493     |   1\n",
      "       4192 |   0.199341  |    0.010224     |   0\n",
      "       4193 |   0.226841  |    0.045358     |   0\n",
      "       4194 |   0.209253  |    0.009416     |   0\n",
      "       4195 |   0.000151  |    0.049016     |   2\n",
      "       4196 |   0.008053  |    0.010120     |   2\n",
      "       4197 |   0.278163  |    0.149101     |   1\n",
      "       4198 |   0.284230  |    0.017679     |   0\n",
      "       4199 |   0.190323  |    0.090971     |   1\n",
      "       4200 |   0.254700  |    0.135357     |   1\n",
      "       4201 |   0.143701  |    0.002875     |   2\n",
      "       4202 |   0.207644  |    0.020567     |   0\n",
      "       4203 |   0.270458  |    0.135971     |   1\n",
      "       4204 |   0.217414  |    0.011061     |   0\n",
      "       4205 |   0.339390  |    0.090074     |   1\n",
      "       4206 |   0.294618  |    0.003160     |   0\n",
      "       4207 |   0.273298  |    0.056537     |   0\n",
      "       4208 |   0.277753  |    0.138344     |   1\n",
      "       4209 |   0.065698  |    0.003156     |   2\n",
      "       4210 |   0.305670  |    0.010202     |   0\n",
      "       4211 |   0.274073  |    0.135569     |   1\n",
      "       4212 |   0.084867  |    0.008812     |   2\n",
      "       4213 |   0.228589  |    0.137659     |   1\n",
      "       4214 |   0.295081  |    0.016144     |   0\n",
      "       4215 |   0.252497  |    0.015743     |   0\n",
      "       4216 |   0.075695  |    0.022496     |   2\n",
      "       4217 |   0.233125  |    0.031595     |   0\n",
      "       4218 |   0.030780  |    0.031270     |   2\n",
      "       4219 |   0.077077  |    0.025583     |   2\n",
      "       4220 |   0.067138  |    0.029014     |   2\n",
      "       4221 |   0.000140  |    0.020371     |   2\n",
      "       4222 |   0.000151  |    0.035682     |   2\n",
      "       4223 |   0.000167  |    0.028810     |   2\n",
      "       4224 |   0.310223  |    0.111558     |   1\n",
      "       4225 |   0.000184  |    0.016584     |   2\n",
      "       4226 |   0.204123  |    0.160299     |   1\n",
      "       4227 |   0.198294  |    0.053796     |   1\n",
      "       4228 |   0.266543  |    0.022336     |   0\n",
      "       4229 |   0.000159  |    0.037579     |   2\n",
      "       4230 |   0.314669  |    0.071611     |   1\n",
      "       4231 |   0.233963  |    0.094564     |   1\n",
      "       4232 |   0.291183  |    0.016889     |   0\n",
      "       4233 |   0.340992  |    0.094095     |   1\n",
      "       4234 |   0.000187  |    0.027387     |   2\n",
      "       4235 |   0.256948  |    0.197627     |   1\n",
      "       4236 |   0.298950  |    0.013184     |   0\n",
      "       4237 |   0.318252  |    0.091348     |   1\n",
      "       4238 |   0.274303  |    0.022095     |   0\n",
      "       4239 |   0.251107  |    0.128515     |   1\n",
      "       4240 |   0.086819  |    0.016143     |   2\n",
      "       4241 |   0.314116  |    0.144381     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 4244: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       4242 |   0.239021  |    0.003845     |   0\n",
      "       4243 |   0.094829  |    0.007791     |   2\n",
      "       4244 |   0.094147  |    0.031826     |   2\n",
      "       4245 |   0.181123  |    0.019049     |   0\n",
      "       4246 |   0.072624  |    0.041954     |   2\n",
      "       4247 |   0.284639  |    0.094312     |   1\n",
      "       4248 |   0.233536  |    0.008181     |   0\n",
      "       4249 |   0.075059  |    0.046629     |   2\n",
      "       4250 |   0.254747  |    0.094558     |   1\n",
      "       4251 |   0.286102  |    0.088465     |   1\n",
      "       4252 |   0.220399  |    0.015136     |   0\n",
      "       4253 |   0.319428  |    0.049800     |   0\n",
      "       4254 |   0.281940  |    0.093735     |   1\n",
      "       4255 |   0.252928  |    0.010853     |   0\n",
      "       4256 |   0.231723  |    0.027842     |   0\n",
      "       4257 |   0.248429  |    0.045416     |   0\n",
      "       4258 |   0.095257  |    0.032756     |   2\n",
      "       4259 |   0.224260  |    0.101456     |   1\n",
      "       4260 |   0.238992  |    0.144209     |   1\n",
      "       4261 |   0.043673  |    0.006327     |   2\n",
      "       4262 |   0.324345  |    0.083862     |   1\n",
      "       4263 |   0.077345  |    0.006683     |   2\n",
      "       4264 |   0.240198  |    0.020370     |   0\n",
      "       4265 |   0.085498  |    0.028549     |   2\n",
      "       4266 |   0.306770  |    0.080184     |   1\n",
      "       4267 |   0.093120  |    0.017742     |   2\n",
      "       4268 |   0.259594  |    0.133055     |   1\n",
      "       4269 |   0.263372  |    0.004018     |   0\n",
      "       4270 |   0.245151  |    0.051053     |   0\n",
      "       4271 |   0.268847  |    0.129826     |   1\n",
      "       4272 |   0.278767  |    0.076526     |   1\n",
      "       4273 |   0.305276  |    0.006511     |   0\n",
      "       4274 |   0.325477  |    0.163899     |   1\n",
      "       4275 |   0.083818  |    0.006893     |   2\n",
      "       4276 |   0.285747  |    0.056292     |   1\n",
      "       4277 |   0.274251  |    0.097037     |   1\n",
      "       4278 |   0.038062  |    0.007476     |   2\n",
      "       4279 |   0.263326  |    0.060462     |   0\n",
      "       4280 |   0.271118  |    0.081049     |   1\n",
      "       4281 |   0.000153  |    0.011508     |   2\n",
      "       4282 |   0.280245  |    0.148095     |   1\n",
      "       4283 |   0.260115  |    0.077631     |   1\n",
      "       4284 |   0.240059  |    0.017266     |   0\n",
      "       4285 |   0.202986  |    0.044627     |   0\n",
      "       4286 |   0.286766  |    0.126714     |   1\n",
      "       4287 |   0.262162  |    0.010484     |   0\n",
      "       4288 |   0.008127  |    0.011538     |   2\n",
      "       4289 |   0.218645  |    0.128996     |   1\n",
      "       4290 |   0.195191  |    0.011858     |   0\n",
      "       4291 |   0.292090  |    0.039232     |   0\n",
      "       4292 |   0.247561  |    0.016434     |   0\n",
      "       4293 |   0.318782  |    0.050030     |   0\n",
      "       4294 |   0.230939  |    0.014875     |   0\n",
      "       4295 |   0.295540  |    0.153856     |   1\n",
      "       4296 |   0.139818  |    0.003024     |   2\n",
      "       4297 |   0.063164  |    0.007509     |   2\n",
      "       4298 |   0.254405  |    0.048918     |   0\n",
      "       4299 |   0.226419  |    0.007378     |   0\n",
      "       4300 |   0.280219  |    0.048306     |   0\n",
      "       4301 |   0.255629  |    0.140692     |   1\n",
      "       4302 |   0.235217  |    0.082807     |   1\n",
      "       4303 |   0.088489  |    0.006126     |   2\n",
      "       4304 |   0.303047  |    0.099231     |   1\n",
      "       4305 |   0.341199  |    0.092545     |   1\n",
      "       4306 |   0.074037  |    0.004553     |   2\n",
      "       4307 |   0.274372  |    0.038755     |   0\n",
      "       4308 |   0.369379  |    0.134310     |   1\n",
      "       4309 |   0.314088  |    0.003771     |   0\n",
      "       4310 |   0.205978  |    0.011843     |   0\n",
      "       4311 |   0.032474  |    0.038514     |   2\n",
      "       4312 |   0.277097  |    0.017616     |   0\n",
      "       4313 |   0.083840  |    0.065993     |   2\n",
      "       4314 |   0.291650  |    0.080106     |   1\n",
      "       4315 |   0.065165  |    0.008998     |   2\n",
      "       4316 |   0.249597  |    0.051074     |   0\n",
      "       4317 |   0.244274  |    0.085543     |   1\n",
      "       4318 |   0.000139  |    0.013738     |   2\n",
      "       4319 |   0.237401  |    0.025714     |   0\n",
      "       4320 |   0.246218  |    0.030853     |   0\n",
      "       4321 |   0.304074  |    0.041487     |   0\n",
      "       4322 |   0.000153  |    0.009194     |   2\n",
      "       4323 |   0.225901  |    0.046737     |   0\n",
      "       4324 |   0.000169  |    0.007783     |   2\n",
      "       4325 |   0.000196  |    0.048453     |   2\n",
      "       4326 |   0.000161  |    0.009630     |   2\n",
      "       4327 |   0.269957  |    0.146806     |   1\n",
      "       4328 |   0.000183  |    0.004802     |   2\n",
      "       4329 |   0.212283  |    0.017537     |   0\n",
      "       4330 |   0.087810  |    0.075127     |   2\n",
      "       4331 |   0.094128  |    0.022235     |   2\n",
      "       4332 |   0.274698  |    0.153094     |   1\n",
      "       4333 |   0.238878  |    0.070084     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 4334: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       4334 |   0.095329  |    0.010196     |   2\n",
      "       4335 |   0.253131  |    0.047710     |   0\n",
      "       4336 |   0.074857  |    0.010348     |   2\n",
      "       4337 |   0.073835  |    0.048064     |   2\n",
      "       4338 |   0.224545  |    0.007831     |   0\n",
      "       4339 |   0.096079  |    0.047496     |   2\n",
      "       4340 |   0.044447  |    0.011929     |   2\n",
      "       4341 |   0.334001  |    0.143867     |   1\n",
      "       4342 |   0.077605  |    0.004305     |   2\n",
      "       4343 |   0.284249  |    0.025682     |   0\n",
      "       4344 |   0.277280  |    0.034588     |   0\n",
      "       4345 |   0.250278  |    0.013175     |   0\n",
      "       4346 |   0.086192  |    0.028903     |   2\n",
      "       4347 |   0.092738  |    0.022101     |   2\n",
      "       4348 |   0.084033  |    0.045913     |   2\n",
      "       4349 |   0.371467  |    0.098445     |   1\n",
      "       4350 |   0.252804  |    0.081860     |   1\n",
      "       4351 |   0.241104  |    0.014192     |   0\n",
      "       4352 |   0.035948  |    0.040833     |   2\n",
      "       4353 |   0.214763  |    0.077792     |   1\n",
      "       4354 |   0.292788  |    0.016858     |   0\n",
      "       4355 |   0.000143  |    0.023504     |   2\n",
      "       4356 |   0.007426  |    0.030508     |   2\n",
      "       4357 |   0.241644  |    0.099576     |   1\n",
      "       4358 |   0.285142  |    0.081115     |   1\n",
      "       4359 |   0.208333  |    0.019489     |   0\n",
      "       4360 |   0.196813  |    0.028782     |   0\n",
      "       4361 |   0.344107  |    0.158104     |   1\n",
      "       4362 |   0.139284  |    0.012629     |   2\n",
      "       4363 |   0.218351  |    0.116111     |   1\n",
      "       4364 |   0.064714  |    0.018650     |   2\n",
      "       4365 |   0.226652  |    0.082896     |   1\n",
      "       4366 |   0.311535  |    0.085925     |   1\n",
      "       4367 |   0.227221  |    0.004770     |   0\n",
      "       4368 |   0.244536  |    0.031026     |   0\n",
      "       4369 |   0.085778  |    0.009522     |   2\n",
      "       4370 |   0.277081  |    0.144506     |   1\n",
      "       4371 |   0.276241  |    0.057850     |   1\n",
      "       4372 |   0.211611  |    0.027569     |   0\n",
      "       4373 |   0.214294  |    0.027552     |   0\n",
      "       4374 |   0.071387  |    0.020177     |   2\n",
      "       4375 |   0.281018  |    0.045512     |   0\n",
      "       4376 |   0.030736  |    0.006178     |   2\n",
      "       4377 |   0.327860  |    0.038445     |   0\n",
      "       4378 |   0.226183  |    0.022507     |   0\n",
      "       4379 |   0.322529  |    0.023522     |   0\n",
      "       4380 |   0.235225  |    0.049070     |   0\n",
      "       4381 |   0.321654  |    0.083341     |   1\n",
      "       4382 |   0.079393  |    0.028906     |   2\n",
      "       4383 |   0.222933  |    0.133846     |   1\n",
      "       4384 |   0.064308  |    0.019359     |   2\n",
      "       4385 |   0.000134  |    0.039441     |   2\n",
      "       4386 |   0.245921  |    0.013265     |   0\n",
      "       4387 |   0.241189  |    0.040719     |   0\n",
      "       4388 |   0.268174  |    0.012747     |   0\n",
      "       4389 |   0.000145  |    0.032776     |   2\n",
      "       4390 |   0.303851  |    0.098530     |   1\n",
      "       4391 |   0.271411  |    0.025508     |   0\n",
      "       4392 |   0.247693  |    0.043925     |   0\n",
      "       4393 |   0.339379  |    0.081550     |   1\n",
      "       4394 |   0.199489  |    0.028423     |   0\n",
      "       4395 |   0.000163  |    0.031253     |   2\n",
      "       4396 |   0.256072  |    0.136404     |   1\n",
      "       4397 |   0.237269  |    0.003085     |   0\n",
      "       4398 |   0.281971  |    0.011433     |   0\n",
      "       4399 |   0.000181  |    0.023056     |   2\n",
      "       4400 |   0.217983  |    0.036074     |   0\n",
      "       4401 |   0.000154  |    0.020968     |   2\n",
      "       4402 |   0.275915  |    0.046589     |   0\n",
      "       4403 |   0.244996  |    0.018839     |   0\n",
      "       4404 |   0.000176  |    0.044454     |   2\n",
      "       4405 |   0.279727  |    0.130613     |   1\n",
      "       4406 |   0.090895  |    0.003339     |   2\n",
      "       4407 |   0.262123  |    0.012888     |   0\n",
      "       4408 |   0.097087  |    0.030007     |   2\n",
      "       4409 |   0.309354  |    0.079348     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 4410: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       4410 |   0.102209  |    0.020381     |   2\n",
      "       4411 |   0.244307  |    0.029806     |   0\n",
      "       4412 |   0.208989  |    0.037133     |   0\n",
      "       4413 |   0.271427  |    0.098111     |   1\n",
      "       4414 |   0.214770  |    0.022450     |   0\n",
      "       4415 |   0.273223  |    0.142839     |   1\n",
      "       4416 |   0.075444  |    0.002897     |   2\n",
      "       4417 |   0.277488  |    0.015670     |   0\n",
      "       4418 |   0.077894  |    0.037305     |   2\n",
      "       4419 |   0.098964  |    0.028466     |   2\n",
      "       4420 |   0.259097  |    0.031769     |   0\n",
      "       4421 |   0.045818  |    0.032200     |   2\n",
      "       4422 |   0.229407  |    0.017743     |   0\n",
      "       4423 |   0.266195  |    0.026359     |   0\n",
      "       4424 |   0.298706  |    0.033216     |   0\n",
      "       4425 |   0.388171  |    0.086227     |   1\n",
      "       4426 |   0.170071  |    0.026907     |   0\n",
      "       4427 |   0.246142  |    0.135897     |   1\n",
      "       4428 |   0.288103  |    0.091758     |   1\n",
      "       4429 |   0.338290  |    0.072735     |   1\n",
      "       4430 |   0.254833  |    0.024368     |   0\n",
      "       4431 |   0.306150  |    0.127989     |   1\n",
      "       4432 |   0.077578  |    0.004188     |   2\n",
      "       4433 |   0.306236  |    0.041245     |   0\n",
      "       4434 |   0.089991  |    0.024088     |   2\n",
      "       4435 |   0.300881  |    0.151399     |   1\n",
      "       4436 |   0.093442  |    0.003046     |   2\n",
      "       4437 |   0.085805  |    0.013123     |   2\n",
      "       4438 |   0.279368  |    0.158999     |   1\n",
      "       4439 |   0.037140  |    0.003036     |   2\n",
      "       4440 |   0.000140  |    0.006564     |   2\n",
      "       4441 |   0.307011  |    0.050276     |   0\n",
      "       4442 |   0.008302  |    0.007142     |   2\n",
      "       4443 |   0.257690  |    0.046064     |   0\n",
      "       4444 |   0.230512  |    0.018279     |   0\n",
      "       4445 |   0.275867  |    0.071925     |   0\n",
      "       4446 |   0.287144  |    0.081909     |   1\n",
      "       4447 |   0.278335  |    0.094741     |   1\n",
      "       4448 |   0.140923  |    0.010287     |   2\n",
      "       4449 |   0.271867  |    0.060293     |   0\n",
      "       4450 |   0.274740  |    0.113743     |   1\n",
      "       4451 |   0.260693  |    0.057516     |   1\n",
      "       4452 |   0.062658  |    0.009293     |   2\n",
      "       4453 |   0.268567  |    0.049412     |   0\n",
      "       4454 |   0.084615  |    0.006040     |   2\n",
      "       4455 |   0.229217  |    0.060304     |   0\n",
      "       4456 |   0.070183  |    0.003731     |   2\n",
      "       4457 |   0.029512  |    0.027687     |   2\n",
      "       4458 |   0.291950  |    0.108841     |   1\n",
      "       4459 |   0.259729  |    0.088128     |   1\n",
      "       4460 |   0.075215  |    0.005400     |   2\n",
      "       4461 |   0.318697  |    0.080773     |   1\n",
      "       4462 |   0.272701  |    0.040038     |   1\n",
      "       4463 |   0.242786  |    0.039119     |   0\n",
      "       4464 |   0.241132  |    0.105120     |   1\n",
      "       4465 |   0.065056  |    0.014525     |   2\n",
      "       4466 |   0.000135  |    0.049908     |   2\n",
      "       4467 |   0.248159  |    0.075380     |   1\n",
      "       4468 |   0.231246  |    0.022035     |   0\n",
      "       4469 |   0.230602  |    0.039303     |   0\n",
      "       4470 |   0.000142  |    0.020356     |   2\n",
      "       4471 |   0.283015  |    0.111493     |   1\n",
      "       4472 |   0.249459  |    0.017626     |   0\n",
      "       4473 |   0.000162  |    0.038887     |   2\n",
      "       4474 |   0.253220  |    0.025895     |   0\n",
      "       4475 |   0.000174  |    0.043479     |   2\n",
      "       4476 |   0.000152  |    0.025359     |   2\n",
      "       4477 |   0.241157  |    0.058960     |   0\n",
      "       4478 |   0.209467  |    0.101524     |   1\n",
      "       4479 |   0.247077  |    0.135903     |   1\n",
      "       4480 |   0.286630  |    0.007851     |   0\n",
      "       4481 |   0.239128  |    0.013877     |   0\n",
      "       4482 |   0.256197  |    0.137785     |   1\n",
      "       4483 |   0.261952  |    0.007144     |   0\n",
      "       4484 |   0.000174  |    0.006582     |   2\n",
      "       4485 |   0.202706  |    0.046329     |   0\n",
      "       4486 |   0.216859  |    0.145456     |   1\n",
      "       4487 |   0.086751  |    0.003722     |   2\n",
      "       4488 |   0.094567  |    0.004409     |   2\n",
      "       4489 |   0.284585  |    0.053322     |   0\n",
      "       4490 |   0.278493  |    0.020202     |   0\n",
      "       4491 |   0.254823  |    0.142959     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 4492: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       4492 |   0.283393  |    0.053442     |   1\n",
      "       4493 |   0.095684  |    0.011088     |   2\n",
      "       4494 |   0.288395  |    0.145110     |   1\n",
      "       4495 |   0.246958  |    0.006062     |   0\n",
      "       4496 |   0.073717  |    0.006133     |   2\n",
      "       4497 |   0.257704  |    0.043383     |   0\n",
      "       4498 |   0.274403  |    0.026399     |   0\n",
      "       4499 |   0.319560  |    0.135929     |   1\n",
      "       4500 |   0.073532  |    0.007096     |   2\n",
      "       4501 |   0.173323  |    0.053491     |   0\n",
      "       4502 |   0.094402  |    0.017255     |   2\n",
      "       4503 |   0.229304  |    0.153045     |   1\n",
      "       4504 |   0.223725  |    0.011051     |   0\n",
      "       4505 |   0.280577  |    0.093898     |   1\n",
      "       4506 |   0.071190  |    0.007727     |   2\n",
      "       4507 |   0.249656  |    0.055480     |   0\n",
      "       4508 |   0.071809  |    0.009748     |   2\n",
      "       4509 |   0.370502  |    0.123631     |   1\n",
      "       4510 |   0.098411  |    0.008941     |   2\n",
      "       4511 |   0.211874  |    0.131986     |   1\n",
      "       4512 |   0.274717  |    0.026725     |   0\n",
      "       4513 |   0.189387  |    0.028472     |   0\n",
      "       4514 |   0.044785  |    0.027412     |   2\n",
      "       4515 |   0.078666  |    0.045976     |   2\n",
      "       4516 |   0.238495  |    0.014008     |   0\n",
      "       4517 |   0.254079  |    0.146883     |   1\n",
      "       4518 |   0.370371  |    0.077431     |   1\n",
      "       4519 |   0.197610  |    0.009813     |   0\n",
      "       4520 |   0.259903  |    0.024468     |   0\n",
      "       4521 |   0.198152  |    0.022397     |   0\n",
      "       4522 |   0.214483  |    0.043168     |   0\n",
      "       4523 |   0.193993  |    0.038662     |   0\n",
      "       4524 |   0.309163  |    0.092035     |   1\n",
      "       4525 |   0.275717  |    0.019334     |   0\n",
      "       4526 |   0.309853  |    0.143069     |   1\n",
      "       4527 |   0.228551  |    0.003169     |   0\n",
      "       4528 |   0.090860  |    0.007153     |   2\n",
      "       4529 |   0.247104  |    0.062384     |   0\n",
      "       4530 |   0.299888  |    0.083721     |   1\n",
      "       4531 |   0.090804  |    0.009766     |   2\n",
      "       4532 |   0.250740  |    0.026593     |   0\n",
      "       4533 |   0.284836  |    0.154042     |   1\n",
      "       4534 |   0.237926  |    0.093095     |   1\n",
      "       4535 |   0.293562  |    0.142681     |   1\n",
      "       4536 |   0.253868  |    0.007954     |   0\n",
      "       4537 |   0.301966  |    0.083682     |   1\n",
      "       4538 |   0.378583  |    0.077194     |   1\n",
      "       4539 |   0.285157  |    0.009154     |   0\n",
      "       4540 |   0.241541  |    0.138970     |   1\n",
      "       4541 |   0.295899  |    0.083609     |   1\n",
      "       4542 |   0.088275  |    0.015575     |   2\n",
      "       4543 |   0.038639  |    0.054304     |   2\n",
      "       4544 |   0.000141  |    0.008507     |   2\n",
      "       4545 |   0.242187  |    0.051557     |   0\n",
      "       4546 |   0.008431  |    0.011294     |   2\n",
      "       4547 |   0.239084  |    0.151913     |   1\n",
      "       4548 |   0.231621  |    0.086000     |   1\n",
      "       4549 |   0.136106  |    0.009188     |   2\n",
      "       4550 |   0.257168  |    0.145901     |   1\n",
      "       4551 |   0.060415  |    0.003035     |   2\n",
      "       4552 |   0.229073  |    0.008427     |   0\n",
      "       4553 |   0.256821  |    0.053917     |   0\n",
      "       4554 |   0.301592  |    0.116172     |   1\n",
      "       4555 |   0.218716  |    0.095853     |   1\n",
      "       4556 |   0.231048  |    0.011145     |   0\n",
      "       4557 |   0.274904  |    0.130982     |   1\n",
      "       4558 |   0.085309  |    0.017533     |   2\n",
      "       4559 |   0.218010  |    0.143087     |   1\n",
      "       4560 |   0.212533  |    0.003140     |   0\n",
      "       4561 |   0.070208  |    0.013006     |   2\n",
      "       4562 |   0.268789  |    0.154626     |   1\n",
      "       4563 |   0.235812  |    0.046876     |   1\n",
      "       4564 |   0.028619  |    0.008496     |   2\n",
      "       4565 |   0.073702  |    0.043000     |   2\n",
      "       4566 |   0.186011  |    0.006916     |   0\n",
      "       4567 |   0.225894  |    0.041784     |   0\n",
      "       4568 |   0.254078  |    0.016732     |   0\n",
      "       4569 |   0.264470  |    0.130319     |   1\n",
      "       4570 |   0.062755  |    0.011354     |   2\n",
      "       4571 |   0.000137  |    0.032784     |   2\n",
      "       4572 |   0.237825  |    0.048765     |   0\n",
      "       4573 |   0.323878  |    0.085862     |   1\n",
      "       4574 |   0.187231  |    0.145677     |   1\n",
      "       4575 |   0.234007  |    0.003063     |   0\n",
      "       4576 |   0.203962  |    0.004763     |   0\n",
      "       4577 |   0.269308  |    0.135466     |   1\n",
      "       4578 |   0.272657  |    0.012048     |   0\n",
      "       4579 |   0.000144  |    0.051018     |   2\n",
      "       4580 |   0.225502  |    0.129634     |   1\n",
      "       4581 |   0.253297  |    0.008668     |   0\n",
      "       4582 |   0.282820  |    0.012296     |   0\n",
      "       4583 |   0.000165  |    0.050206     |   2\n",
      "       4584 |   0.266814  |    0.014147     |   0\n",
      "       4585 |   0.000168  |    0.032651     |   2\n",
      "       4586 |   0.251291  |    0.041450     |   0\n",
      "       4587 |   0.269182  |    0.012051     |   0\n",
      "       4588 |   0.275139  |    0.131996     |   1\n",
      "       4589 |   0.250114  |    0.020314     |   0\n",
      "       4590 |   0.268676  |    0.125839     |   1\n",
      "       4591 |   0.000150  |    0.012481     |   2\n",
      "       4592 |   0.000171  |    0.027270     |   2\n",
      "       4593 |   0.235098  |    0.085206     |   1\n",
      "       4594 |   0.284616  |    0.087588     |   1\n",
      "       4595 |   0.339276  |    0.087827     |   1\n",
      "       4596 |   0.090040  |    0.013601     |   2\n",
      "       4597 |   0.317456  |    0.136381     |   1\n",
      "       4598 |   0.242630  |    0.089295     |   1\n",
      "       4599 |   0.242087  |    0.015779     |   0\n",
      "       4600 |   0.091546  |    0.044017     |   2\n",
      "       4601 |   0.210623  |    0.020770     |   0\n",
      "       4602 |   0.165128  |    0.144292     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 4603: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       4603 |   0.229759  |    0.098013     |   1\n",
      "       4604 |   0.240061  |    0.006527     |   0\n",
      "       4605 |   0.225053  |    0.038222     |   0\n",
      "       4606 |   0.090956  |    0.007483     |   2\n",
      "       4607 |   0.282321  |    0.042015     |   0\n",
      "       4608 |   0.251488  |    0.021712     |   0\n",
      "       4609 |   0.235120  |    0.030499     |   0\n",
      "       4610 |   0.200661  |    0.140338     |   1\n",
      "       4611 |   0.297041  |    0.047922     |   1\n",
      "       4612 |   0.274997  |    0.044951     |   0\n",
      "       4613 |   0.250845  |    0.130457     |   1\n",
      "       4614 |   0.210618  |    0.012952     |   0\n",
      "       4615 |   0.071301  |    0.012258     |   2\n",
      "       4616 |   0.266008  |    0.147294     |   1\n",
      "       4617 |   0.325166  |    0.058077     |   1\n",
      "       4618 |   0.073656  |    0.007192     |   2\n",
      "       4619 |   0.100662  |    0.040912     |   2\n",
      "       4620 |   0.044450  |    0.015089     |   2\n",
      "       4621 |   0.077618  |    0.042594     |   2\n",
      "       4622 |   0.214911  |    0.030575     |   0\n",
      "       4623 |   0.260121  |    0.023537     |   0\n",
      "       4624 |   0.083898  |    0.028297     |   2\n",
      "       4625 |   0.088342  |    0.044305     |   2\n",
      "       4626 |   0.080696  |    0.010522     |   2\n",
      "       4627 |   0.038048  |    0.058692     |   2\n",
      "       4628 |   0.230382  |    0.135979     |   1\n",
      "       4629 |   0.188652  |    0.021921     |   0\n",
      "       4630 |   0.239927  |    0.051676     |   1\n",
      "       4631 |   0.000142  |    0.019816     |   2\n",
      "       4632 |   0.007833  |    0.033875     |   2\n",
      "       4633 |   0.136717  |    0.027245     |   2\n",
      "       4634 |   0.263975  |    0.079495     |   1\n",
      "       4635 |   0.236157  |    0.015329     |   0\n",
      "       4636 |   0.229290  |    0.041171     |   0\n",
      "       4637 |   0.061455  |    0.014905     |   2\n",
      "       4638 |   0.269031  |    0.036608     |   0\n",
      "       4639 |   0.232617  |    0.133460     |   1\n",
      "       4640 |   0.187996  |    0.004962     |   0\n",
      "       4641 |   0.227626  |    0.008531     |   0\n",
      "       4642 |   0.086031  |    0.031469     |   2\n",
      "       4643 |   0.071694  |    0.023236     |   2\n",
      "       4644 |   0.032022  |    0.033024     |   2\n",
      "       4645 |   0.270043  |    0.025800     |   0\n",
      "       4646 |   0.081494  |    0.045309     |   2\n",
      "       4647 |   0.212176  |    0.150462     |   1\n",
      "       4648 |   0.294371  |    0.057305     |   1\n",
      "       4649 |   0.062085  |    0.011862     |   2\n",
      "       4650 |   0.248141  |    0.177287     |   1\n",
      "       4651 |   0.322938  |    0.009562     |   1\n",
      "       4652 |   0.000133  |    0.050445     |   2\n",
      "       4653 |   0.000140  |    0.014828     |   2\n",
      "       4654 |   0.324844  |    0.139985     |   1\n",
      "       4655 |   0.215336  |    0.004802     |   0\n",
      "       4656 |   0.251930  |    0.008827     |   0\n",
      "       4657 |   0.262484  |    0.037668     |   0\n",
      "       4658 |   0.192781  |    0.017717     |   0\n",
      "       4659 |   0.000160  |    0.044086     |   2\n",
      "       4660 |   0.278857  |    0.096796     |   1\n",
      "       4661 |   0.000165  |    0.013816     |   2\n",
      "       4662 |   0.000146  |    0.027447     |   2\n",
      "       4663 |   0.000162  |    0.031330     |   2\n",
      "       4664 |   0.265700  |    0.139979     |   1\n",
      "       4665 |   0.238840  |    0.005756     |   0\n",
      "       4666 |   0.262429  |    0.029502     |   0\n",
      "       4667 |   0.228475  |    0.153201     |   1\n",
      "       4668 |   0.253586  |    0.067841     |   1\n",
      "       4669 |   0.295114  |    0.091397     |   1\n",
      "       4670 |   0.085399  |    0.019832     |   2\n",
      "       4671 |   0.297647  |    0.040389     |   0\n",
      "       4672 |   0.209489  |    0.017506     |   0\n",
      "       4673 |   0.090077  |    0.049062     |   2\n",
      "       4674 |   0.316275  |    0.085720     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 4675: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       4675 |   0.090427  |    0.021436     |   2\n",
      "       4676 |   0.243074  |    0.033488     |   0\n",
      "       4677 |   0.304150  |    0.134114     |   1\n",
      "       4678 |   0.323073  |    0.056866     |   1\n",
      "       4679 |   0.279675  |    0.151212     |   1\n",
      "       4680 |   0.181993  |    0.013521     |   0\n",
      "       4681 |   0.249673  |    0.091335     |   1\n",
      "       4682 |   0.069985  |    0.004957     |   2\n",
      "       4683 |   0.272518  |    0.031735     |   0\n",
      "       4684 |   0.239324  |    0.035556     |   0\n",
      "       4685 |   0.073010  |    0.010485     |   2\n",
      "       4686 |   0.095662  |    0.046734     |   2\n",
      "       4687 |   0.241848  |    0.142913     |   1\n",
      "       4688 |   0.232223  |    0.002950     |   0\n",
      "       4689 |   0.043799  |    0.004946     |   2\n",
      "       4690 |   0.243134  |    0.049305     |   0\n",
      "       4691 |   0.195386  |    0.085945     |   1\n",
      "       4692 |   0.237261  |    0.029156     |   0\n",
      "       4693 |   0.348754  |    0.126301     |   1\n",
      "       4694 |   0.078289  |    0.004178     |   2\n",
      "       4695 |   0.250641  |    0.021163     |   0\n",
      "       4696 |   0.299726  |    0.143565     |   1\n",
      "       4697 |   0.278567  |    0.008070     |   0\n",
      "       4698 |   0.210429  |    0.008389     |   0\n",
      "       4699 |   0.085494  |    0.029459     |   2\n",
      "       4700 |   0.088038  |    0.038425     |   2\n",
      "       4701 |   0.234121  |    0.026357     |   0\n",
      "       4702 |   0.280907  |    0.026591     |   0\n",
      "       4703 |   0.235262  |    0.148632     |   1\n",
      "       4704 |   0.288760  |    0.085731     |   1\n",
      "       4705 |   0.084578  |    0.007760     |   2\n",
      "       4706 |   0.039723  |    0.060127     |   2\n",
      "       4707 |   0.286527  |    0.110321     |   1\n",
      "       4708 |   0.236728  |    0.093559     |   1\n",
      "       4709 |   0.288513  |    0.132142     |   1\n",
      "       4710 |   0.000138  |    0.003221     |   2\n",
      "       4711 |   0.008122  |    0.005418     |   2\n",
      "       4712 |   0.137308  |    0.045450     |   2\n",
      "       4713 |   0.294082  |    0.095000     |   1\n",
      "       4714 |   0.060230  |    0.005571     |   2\n",
      "       4715 |   0.226022  |    0.041134     |   0\n",
      "       4716 |   0.082158  |    0.020886     |   2\n",
      "       4717 |   0.182387  |    0.030481     |   0\n",
      "       4718 |   0.264771  |    0.033326     |   0\n",
      "       4719 |   0.267112  |    0.159662     |   1\n",
      "       4720 |   0.206109  |    0.010902     |   0\n",
      "       4721 |   0.232486  |    0.093450     |   1\n",
      "       4722 |   0.282435  |    0.085620     |   1\n",
      "       4723 |   0.211418  |    0.015790     |   0\n",
      "       4724 |   0.313574  |    0.138572     |   1\n",
      "       4725 |   0.234520  |    0.087785     |   1\n",
      "       4726 |   0.068357  |    0.011012     |   2\n",
      "       4727 |   0.029497  |    0.045584     |   2\n",
      "       4728 |   0.213569  |    0.011621     |   0\n",
      "       4729 |   0.074893  |    0.050612     |   2\n",
      "       4730 |   0.059577  |    0.008485     |   2\n",
      "       4731 |   0.249754  |    0.040997     |   0\n",
      "       4732 |   0.232994  |    0.020598     |   0\n",
      "       4733 |   0.243595  |    0.053472     |   0\n",
      "       4734 |   0.292340  |    0.090711     |   1\n",
      "       4735 |   0.144996  |    0.020187     |   0\n",
      "       4736 |   0.212022  |    0.045317     |   0\n",
      "       4737 |   0.318264  |    0.085664     |   1\n",
      "       4738 |   0.242922  |    0.134139     |   1\n",
      "       4739 |   0.000134  |    0.004860     |   2\n",
      "       4740 |   0.000140  |    0.006848     |   2\n",
      "       4741 |   0.242835  |    0.152161     |   1\n",
      "       4742 |   0.216403  |    0.088017     |   1\n",
      "       4743 |   0.292478  |    0.093071     |   1\n",
      "       4744 |   0.223337  |    0.011192     |   0\n",
      "       4745 |   0.000160  |    0.032028     |   2\n",
      "       4746 |   0.254211  |    0.138386     |   1\n",
      "       4747 |   0.240622  |    0.006492     |   0\n",
      "       4748 |   0.345147  |    0.083367     |   1\n",
      "       4749 |   0.299583  |    0.084218     |   1\n",
      "       4750 |   0.000163  |    0.027681     |   2\n",
      "       4751 |   0.209481  |    0.024848     |   0\n",
      "       4752 |   0.000145  |    0.029890     |   2\n",
      "       4753 |   0.000162  |    0.033476     |   2\n",
      "       4754 |   0.084146  |    0.011964     |   2\n",
      "       4755 |   0.311889  |    0.134637     |   1\n",
      "       4756 |   0.086433  |    0.010651     |   2\n",
      "       4757 |   0.280637  |    0.138664     |   1\n",
      "       4758 |   0.212210  |    0.006683     |   0\n",
      "       4759 |   0.251490  |    0.019348     |   0\n",
      "       4760 |   0.253528  |    0.043692     |   0\n",
      "       4761 |   0.350868  |    0.076562     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 4762: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       4762 |   0.086168  |    0.005307     |   2\n",
      "       4763 |   0.246710  |    0.103761     |   1\n",
      "       4764 |   0.065932  |    0.013481     |   2\n",
      "       4765 |   0.074112  |    0.050226     |   2\n",
      "       4766 |   0.292659  |    0.092348     |   1\n",
      "       4767 |   0.268775  |    0.009374     |   0\n",
      "       4768 |   0.235723  |    0.037308     |   0\n",
      "       4769 |   0.364069  |    0.087915     |   1\n",
      "       4770 |   0.244795  |    0.025572     |   0\n",
      "       4771 |   0.093915  |    0.048802     |   2\n",
      "       4772 |   0.261850  |    0.087927     |   1\n",
      "       4773 |   0.228681  |    0.014133     |   0\n",
      "       4774 |   0.043268  |    0.050853     |   2\n",
      "       4775 |   0.326231  |    0.080669     |   1\n",
      "       4776 |   0.239664  |    0.011637     |   0\n",
      "       4777 |   0.209367  |    0.167977     |   1\n",
      "       4778 |   0.195798  |    0.028909     |   1\n",
      "       4779 |   0.225397  |    0.043428     |   0\n",
      "       4780 |   0.076087  |    0.012212     |   2\n",
      "       4781 |   0.081777  |    0.043429     |   2\n",
      "       4782 |   0.331978  |    0.082626     |   1\n",
      "       4783 |   0.088558  |    0.011560     |   2\n",
      "       4784 |   0.082992  |    0.057886     |   2\n",
      "       4785 |   0.351530  |    0.080484     |   1\n",
      "       4786 |   0.249745  |    0.031663     |   0\n",
      "       4787 |   0.305934  |    0.162075     |   1\n",
      "       4788 |   0.228498  |    0.046917     |   1\n",
      "       4789 |   0.322676  |    0.084209     |   1\n",
      "       4790 |   0.320022  |    0.084965     |   1\n",
      "       4791 |   0.037875  |    0.013558     |   2\n",
      "       4792 |   0.000136  |    0.055039     |   2\n",
      "       4793 |   0.280487  |    0.014339     |   0\n",
      "       4794 |   0.285060  |    0.145409     |   1\n",
      "       4795 |   0.286776  |    0.106742     |   1\n",
      "       4796 |   0.204212  |    0.009136     |   0\n",
      "       4797 |   0.313147  |    0.103057     |   1\n",
      "       4798 |   0.296015  |    0.083960     |   1\n",
      "       4799 |   0.008602  |    0.014674     |   2\n",
      "       4800 |   0.266161  |    0.130991     |   1\n",
      "       4801 |   0.248527  |    0.105905     |   1\n",
      "       4802 |   0.293977  |    0.085435     |   1\n",
      "       4803 |   0.208481  |    0.145000     |   1\n",
      "       4804 |   0.217180  |    0.003006     |   0\n",
      "       4805 |   0.132054  |    0.003866     |   2\n",
      "       4806 |   0.254380  |    0.153661     |   1\n",
      "       4807 |   0.297376  |    0.101663     |   1\n",
      "       4808 |   0.258672  |    0.011936     |   0\n",
      "       4809 |   0.273153  |    0.106170     |   1\n",
      "       4810 |   0.244689  |    0.057603     |   1\n",
      "       4811 |   0.224709  |    0.028673     |   0\n",
      "       4812 |   0.062195  |    0.026650     |   2\n",
      "       4813 |   0.238690  |    0.038328     |   0\n",
      "       4814 |   0.236928  |    0.098697     |   1\n",
      "       4815 |   0.081885  |    0.014085     |   2\n",
      "       4816 |   0.072095  |    0.045003     |   2\n",
      "       4817 |   0.276754  |    0.010796     |   0\n",
      "       4818 |   0.029247  |    0.034939     |   2\n",
      "       4819 |   0.258981  |    0.048423     |   0\n",
      "       4820 |   0.073764  |    0.008100     |   2\n",
      "       4821 |   0.244273  |    0.048337     |   0\n",
      "       4822 |   0.059012  |    0.010776     |   2\n",
      "       4823 |   0.196168  |    0.037435     |   0\n",
      "       4824 |   0.245464  |    0.026127     |   0\n",
      "       4825 |   0.000132  |    0.039163     |   2\n",
      "       4826 |   0.225581  |    0.010173     |   0\n",
      "       4827 |   0.000138  |    0.049468     |   2\n",
      "       4828 |   0.293713  |    0.018137     |   0\n",
      "       4829 |   0.303185  |    0.097931     |   1\n",
      "       4830 |   0.000158  |    0.031233     |   2\n",
      "       4831 |   0.000158  |    0.026210     |   2\n",
      "       4832 |   0.284587  |    0.029965     |   0\n",
      "       4833 |   0.000145  |    0.052222     |   2\n",
      "       4834 |   0.313541  |    0.085910     |   1\n",
      "       4835 |   0.265323  |    0.080786     |   1\n",
      "       4836 |   0.000162  |    0.010927     |   2\n",
      "       4837 |   0.278412  |    0.050632     |   0\n",
      "       4838 |   0.086389  |    0.011232     |   2\n",
      "       4839 |   0.227644  |    0.029487     |   0\n",
      "       4840 |   0.211115  |    0.025585     |   0\n",
      "       4841 |   0.205578  |    0.037133     |   0\n",
      "       4842 |   0.276348  |    0.019894     |   0\n",
      "       4843 |   0.233299  |    0.052543     |   0\n",
      "       4844 |   0.285611  |    0.017142     |   0\n",
      "       4845 |   0.087812  |    0.029880     |   2\n",
      "       4846 |   0.252817  |    0.027342     |   0\n",
      "       4847 |   0.319721  |    0.150402     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 4848: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       4848 |   0.264575  |    0.003081     |   0\n",
      "       4849 |   0.285446  |    0.098097     |   1\n",
      "       4850 |   0.280294  |    0.013653     |   0\n",
      "       4851 |   0.193235  |    0.041282     |   0\n",
      "       4852 |   0.091108  |    0.025436     |   2\n",
      "       4853 |   0.071135  |    0.023519     |   2\n",
      "       4854 |   0.262840  |    0.031442     |   0\n",
      "       4855 |   0.305893  |    0.137182     |   1\n",
      "       4856 |   0.233267  |    0.012506     |   0\n",
      "       4857 |   0.071768  |    0.013741     |   2\n",
      "       4858 |   0.203336  |    0.135644     |   1\n",
      "       4859 |   0.096458  |    0.005861     |   2\n",
      "       4860 |   0.043504  |    0.026440     |   2\n",
      "       4861 |   0.260291  |    0.048516     |   0\n",
      "       4862 |   0.316591  |    0.112310     |   1\n",
      "       4863 |   0.326179  |    0.061363     |   1\n",
      "       4864 |   0.190804  |    0.090029     |   1\n",
      "       4865 |   0.310388  |    0.089493     |   1\n",
      "       4866 |   0.077503  |    0.017357     |   2\n",
      "       4867 |   0.194153  |    0.034046     |   0\n",
      "       4868 |   0.201585  |    0.028962     |   0\n",
      "       4869 |   0.206557  |    0.045405     |   0\n",
      "       4870 |   0.250596  |    0.105128     |   1\n",
      "       4871 |   0.294076  |    0.146163     |   1\n",
      "       4872 |   0.265264  |    0.029397     |   1\n",
      "       4873 |   0.083513  |    0.050767     |   2\n",
      "       4874 |   0.222150  |    0.132562     |   1\n",
      "       4875 |   0.210106  |    0.004779     |   0\n",
      "       4876 |   0.254531  |    0.009970     |   0\n",
      "       4877 |   0.347109  |    0.146532     |   1\n",
      "       4878 |   0.090804  |    0.010216     |   2\n",
      "       4879 |   0.261719  |    0.079797     |   1\n",
      "       4880 |   0.285044  |    0.100907     |   1\n",
      "       4881 |   0.225959  |    0.084162     |   1\n",
      "       4882 |   0.220458  |    0.015389     |   0\n",
      "       4883 |   0.089035  |    0.046565     |   2\n",
      "       4884 |   0.039681  |    0.010953     |   2\n",
      "       4885 |   0.275599  |    0.152714     |   1\n",
      "       4886 |   0.250059  |    0.097860     |   1\n",
      "       4887 |   0.000139  |    0.006335     |   2\n",
      "       4888 |   0.188509  |    0.156674     |   1\n",
      "       4889 |   0.008189  |    0.004792     |   2\n",
      "       4890 |   0.196941  |    0.009934     |   0\n",
      "       4891 |   0.272945  |    0.028598     |   0\n",
      "       4892 |   0.257932  |    0.143280     |   1\n",
      "       4893 |   0.128124  |    0.011389     |   2\n",
      "       4894 |   0.290986  |    0.097043     |   1\n",
      "       4895 |   0.273508  |    0.094479     |   1\n",
      "       4896 |   0.237920  |    0.086238     |   1\n",
      "       4897 |   0.061916  |    0.004103     |   2\n",
      "       4898 |   0.283065  |    0.149336     |   1\n",
      "       4899 |   0.349475  |    0.048471     |   1\n",
      "       4900 |   0.226751  |    0.015011     |   0\n",
      "       4901 |   0.260823  |    0.040206     |   0\n",
      "       4902 |   0.163343  |    0.009855     |   0\n",
      "       4903 |   0.084136  |    0.046946     |   2\n",
      "       4904 |   0.071417  |    0.016515     |   2\n",
      "       4905 |   0.244690  |    0.140835     |   1\n",
      "       4906 |   0.316835  |    0.063369     |   1\n",
      "       4907 |   0.243932  |    0.141774     |   1\n",
      "       4908 |   0.030947  |    0.005302     |   2\n",
      "       4909 |   0.076430  |    0.009294     |   2\n",
      "       4910 |   0.266548  |    0.150333     |   1\n",
      "       4911 |   0.254853  |    0.006366     |   0\n",
      "       4912 |   0.232523  |    0.016491     |   0\n",
      "       4913 |   0.057848  |    0.026002     |   2\n",
      "       4914 |   0.000134  |    0.046413     |   2\n",
      "       4915 |   0.000139  |    0.014560     |   2\n",
      "       4916 |   0.230071  |    0.040273     |   0\n",
      "       4917 |   0.294906  |    0.080530     |   1\n",
      "       4918 |   0.000158  |    0.011423     |   2\n",
      "       4919 |   0.243263  |    0.130286     |   1\n",
      "       4920 |   0.252740  |    0.018614     |   0\n",
      "       4921 |   0.000162  |    0.032394     |   2\n",
      "       4922 |   0.000147  |    0.023645     |   2\n",
      "       4923 |   0.279288  |    0.134479     |   1\n",
      "       4924 |   0.000168  |    0.004253     |   2\n",
      "       4925 |   0.086150  |    0.006595     |   2\n",
      "       4926 |   0.275871  |    0.059894     |   0\n",
      "       4927 |   0.275461  |    0.074591     |   1\n",
      "       4928 |   0.187938  |    0.008983     |   0\n",
      "       4929 |   0.309023  |    0.144001     |   1\n",
      "       4930 |   0.083935  |    0.006177     |   2\n",
      "       4931 |   0.259747  |    0.112251     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 4932: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       4932 |   0.217648  |    0.012886     |   0\n",
      "       4933 |   0.231371  |    0.092586     |   1\n",
      "       4934 |   0.291112  |    0.094015     |   1\n",
      "       4935 |   0.085513  |    0.007699     |   2\n",
      "       4936 |   0.253938  |    0.052126     |   0\n",
      "       4937 |   0.228005  |    0.144571     |   1\n",
      "       4938 |   0.177538  |    0.074959     |   1\n",
      "       4939 |   0.068659  |    0.004608     |   2\n",
      "       4940 |   0.280426  |    0.058676     |   0\n",
      "       4941 |   0.186049  |    0.114682     |   1\n",
      "       4942 |   0.258446  |    0.085340     |   1\n",
      "       4943 |   0.068108  |    0.009950     |   2\n",
      "       4944 |   0.096188  |    0.034056     |   2\n",
      "       4945 |   0.043053  |    0.047958     |   2\n",
      "       4946 |   0.075374  |    0.012201     |   2\n",
      "       4947 |   0.260968  |    0.130417     |   1\n",
      "       4948 |   0.080848  |    0.007500     |   2\n",
      "       4949 |   0.087353  |    0.044968     |   2\n",
      "       4950 |   0.201245  |    0.010259     |   0\n",
      "       4951 |   0.089238  |    0.041690     |   2\n",
      "       4952 |   0.253755  |    0.024646     |   0\n",
      "       4953 |   0.040762  |    0.027216     |   2\n",
      "       4954 |   0.000137  |    0.043415     |   2\n",
      "       4955 |   0.257091  |    0.080106     |   1\n",
      "       4956 |   0.240419  |    0.136610     |   1\n",
      "       4957 |   0.274567  |    0.005937     |   0\n",
      "       4958 |   0.246301  |    0.016416     |   0\n",
      "       4959 |   0.256997  |    0.147079     |   1\n",
      "       4960 |   0.008147  |    0.007102     |   2\n",
      "       4961 |   0.130507  |    0.013350     |   2\n",
      "       4962 |   0.060636  |    0.050274     |   2\n",
      "       4963 |   0.206920  |    0.060731     |   1\n",
      "       4964 |   0.082822  |    0.019702     |   2\n",
      "       4965 |   0.197131  |    0.035646     |   0\n",
      "       4966 |   0.069992  |    0.008551     |   2\n",
      "       4967 |   0.208324  |    0.158641     |   1\n",
      "       4968 |   0.309248  |    0.029721     |   1\n",
      "       4969 |   0.181229  |    0.021183     |   0\n",
      "       4970 |   0.230398  |    0.044979     |   0\n",
      "       4971 |   0.263826  |    0.079372     |   1\n",
      "       4972 |   0.030881  |    0.011508     |   2\n",
      "       4973 |   0.073688  |    0.051718     |   2\n",
      "       4974 |   0.058204  |    0.015893     |   2\n",
      "       4975 |   0.000130  |    0.032233     |   2\n",
      "       4976 |   0.258567  |    0.034681     |   0\n",
      "       4977 |   0.000135  |    0.044212     |   2\n",
      "       4978 |   0.284784  |    0.091952     |   1\n",
      "       4979 |   0.000153  |    0.005156     |   2\n",
      "       4980 |   0.234446  |    0.021451     |   0\n",
      "       4981 |   0.236841  |    0.148939     |   1\n",
      "       4982 |   0.240629  |    0.086866     |   1\n",
      "       4983 |   0.000160  |    0.010951     |   2\n",
      "       4984 |   0.269296  |    0.087298     |   1\n",
      "       4985 |   0.000142  |    0.024420     |   2\n",
      "       4986 |   0.257088  |    0.158823     |   1\n",
      "       4987 |   0.000160  |    0.013923     |   2\n",
      "       4988 |   0.218656  |    0.006707     |   0\n",
      "       4989 |   0.228799  |    0.107846     |   1\n",
      "       4990 |   0.216275  |    0.082033     |   1\n",
      "       4991 |   0.080284  |    0.007676     |   2\n",
      "       4992 |   0.081888  |    0.024790     |   2\n",
      "       4993 |   0.247719  |    0.055811     |   0\n",
      "       4994 |   0.231636  |    0.078439     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 4995: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       4995 |   0.291371  |    0.009419     |   0\n",
      "       4996 |   0.086391  |    0.048876     |   2\n",
      "       4997 |   0.064861  |    0.014796     |   2\n",
      "       4998 |   0.238494  |    0.149078     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 5000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 5000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       4999 |   0.309476  |    0.012914     |   0\n",
      "       5000 |   0.068682  |    0.007514     |   2\n",
      "       5001 |   0.244100  |    0.050087     |   0\n",
      "       5002 |   0.321940  |    0.094415     |   1\n",
      "       5003 |   0.203371  |    0.092782     |   1\n",
      "       5004 |   0.217120  |    0.012960     |   0\n",
      "       5005 |   0.235702  |    0.030271     |   0\n",
      "       5006 |   0.201539  |    0.057937     |   0\n",
      "       5007 |   0.267392  |    0.081846     |   1\n",
      "       5008 |   0.084525  |    0.023718     |   2\n",
      "       5009 |   0.063334  |    0.025535     |   2\n",
      "       5010 |   0.067373  |    0.049870     |   2\n",
      "       5011 |   0.324805  |    0.097153     |   1\n",
      "       5012 |   0.269764  |    0.006666     |   0\n",
      "       5013 |   0.264661  |    0.064707     |   0\n",
      "       5014 |   0.319438  |    0.091080     |   1\n",
      "       5015 |   0.290762  |    0.009578     |   0\n",
      "       5016 |   0.095348  |    0.008548     |   2\n",
      "       5017 |   0.337902  |    0.117407     |   1\n",
      "       5018 |   0.266911  |    0.107824     |   1\n",
      "       5019 |   0.042272  |    0.019596     |   2\n",
      "       5020 |   0.073976  |    0.048660     |   2\n",
      "       5021 |   0.275415  |    0.129280     |   1\n",
      "       5022 |   0.217130  |    0.004567     |   0\n",
      "       5023 |   0.200876  |    0.012780     |   0\n",
      "       5024 |   0.262654  |    0.025558     |   0\n",
      "       5025 |   0.279812  |    0.025675     |   0\n",
      "       5026 |   0.199179  |    0.038703     |   0\n",
      "       5027 |   0.078301  |    0.024867     |   2\n",
      "       5028 |   0.255474  |    0.034580     |   0\n",
      "       5029 |   0.197712  |    0.129610     |   1\n",
      "       5030 |   0.090148  |    0.006731     |   2\n",
      "       5031 |   0.246173  |    0.017784     |   0\n",
      "       5032 |   0.198736  |    0.035106     |   0\n",
      "       5033 |   0.261830  |    0.102959     |   1\n",
      "       5034 |   0.248158  |    0.081363     |   1\n",
      "       5035 |   0.082718  |    0.006284     |   2\n",
      "       5036 |   0.037443  |    0.032984     |   2\n",
      "       5037 |   0.228830  |    0.052242     |   0\n",
      "       5038 |   0.268827  |    0.085998     |   1\n",
      "       5039 |   0.000133  |    0.015735     |   2\n",
      "       5040 |   0.342584  |    0.195582     |   1\n",
      "       5041 |   0.007740  |    0.004016     |   2\n",
      "       5042 |   0.213747  |    0.016186     |   0\n",
      "       5043 |   0.240404  |    0.051279     |   0\n",
      "       5044 |   0.292378  |    0.081156     |   1\n",
      "       5045 |   0.208916  |    0.030763     |   0\n",
      "       5046 |   0.268039  |    0.097614     |   1\n",
      "       5047 |   0.260523  |    0.045828     |   0\n",
      "       5048 |   0.134060  |    0.011852     |   2\n",
      "       5049 |   0.060810  |    0.025194     |   2\n",
      "       5050 |   0.082489  |    0.042629     |   2\n",
      "       5051 |   0.071889  |    0.010332     |   2\n",
      "       5052 |   0.027359  |    0.044023     |   2\n",
      "       5053 |   0.234980  |    0.006279     |   0\n",
      "       5054 |   0.072033  |    0.016772     |   2\n",
      "       5055 |   0.179111  |    0.043918     |   0\n",
      "       5056 |   0.250957  |    0.013448     |   0\n",
      "       5057 |   0.058907  |    0.047139     |   2\n",
      "       5058 |   0.211960  |    0.015318     |   0\n",
      "       5059 |   0.289722  |    0.046904     |   0\n",
      "       5060 |   0.242328  |    0.010726     |   0\n",
      "       5061 |   0.341228  |    0.040720     |   0\n",
      "       5062 |   0.270671  |    0.027900     |   0\n",
      "       5063 |   0.000128  |    0.039205     |   2\n",
      "       5064 |   0.255572  |    0.019033     |   0\n",
      "       5065 |   0.253420  |    0.043197     |   0\n",
      "       5066 |   0.226464  |    0.005813     |   0\n",
      "       5067 |   0.234958  |    0.057880     |   0\n",
      "       5068 |   0.226160  |    0.152266     |   1\n",
      "       5069 |   0.000132  |    0.017964     |   2\n",
      "       5070 |   0.289149  |    0.051340     |   1\n",
      "       5071 |   0.295397  |    0.018051     |   0\n",
      "       5072 |   0.246984  |    0.146931     |   1\n",
      "       5073 |   0.248581  |    0.069094     |   1\n",
      "       5074 |   0.000147  |    0.008117     |   2\n",
      "       5075 |   0.000153  |    0.043126     |   2\n",
      "       5076 |   0.269951  |    0.130791     |   1\n",
      "       5077 |   0.242232  |    0.041706     |   1\n",
      "       5078 |   0.219092  |    0.011854     |   0\n",
      "       5079 |   0.299948  |    0.053180     |   0\n",
      "       5080 |   0.000139  |    0.016447     |   2\n",
      "       5081 |   0.000152  |    0.036221     |   2\n",
      "       5082 |   0.278873  |    0.126605     |   1\n",
      "       5083 |   0.251320  |    0.002942     |   0\n",
      "       5084 |   0.087959  |    0.009344     |   2\n",
      "       5085 |   0.251536  |    0.118458     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 5087: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       5086 |   0.086343  |    0.016919     |   2\n",
      "       5087 |   0.281679  |    0.129340     |   1\n",
      "       5088 |   0.252068  |    0.052040     |   1\n",
      "       5089 |   0.090873  |    0.029789     |   2\n",
      "       5090 |   0.069341  |    0.018322     |   2\n",
      "       5091 |   0.248069  |    0.138795     |   1\n",
      "       5092 |   0.275535  |    0.101522     |   1\n",
      "       5093 |   0.066744  |    0.015322     |   2\n",
      "       5094 |   0.239065  |    0.029833     |   0\n",
      "       5095 |   0.093870  |    0.025632     |   2\n",
      "       5096 |   0.042455  |    0.028571     |   2\n",
      "       5097 |   0.070543  |    0.017246     |   2\n",
      "       5098 |   0.276663  |    0.150569     |   1\n",
      "       5099 |   0.234068  |    0.057400     |   1\n",
      "       5100 |   0.306897  |    0.083358     |   1\n",
      "       5101 |   0.207781  |    0.026632     |   0\n",
      "       5102 |   0.238451  |    0.044581     |   0\n",
      "       5103 |   0.080029  |    0.006840     |   2\n",
      "       5104 |   0.085708  |    0.047808     |   2\n",
      "       5105 |   0.079181  |    0.008461     |   2\n",
      "       5106 |   0.264011  |    0.040216     |   0\n",
      "       5107 |   0.266027  |    0.030727     |   0\n",
      "       5108 |   0.260369  |    0.149450     |   1\n",
      "       5109 |   0.036248  |    0.012799     |   2\n",
      "       5110 |   0.260369  |    0.065147     |   1\n",
      "       5111 |   0.289556  |    0.086410     |   1\n",
      "       5112 |   0.000134  |    0.013903     |   2\n",
      "       5113 |   0.246188  |    0.043345     |   0\n",
      "       5114 |   0.266973  |    0.012727     |   0\n",
      "       5115 |   0.008025  |    0.044910     |   2\n",
      "       5116 |   0.126083  |    0.015589     |   2\n",
      "       5117 |   0.260238  |    0.041078     |   0\n",
      "       5118 |   0.212911  |    0.020363     |   0\n",
      "       5119 |   0.200088  |    0.034125     |   0\n",
      "       5120 |   0.059002  |    0.015202     |   2\n",
      "       5121 |   0.326590  |    0.147186     |   1\n",
      "       5122 |   0.210243  |    0.013045     |   0\n",
      "       5123 |   0.167127  |    0.099691     |   1\n",
      "       5124 |   0.240162  |    0.086920     |   1\n",
      "       5125 |   0.216565  |    0.090130     |   1\n",
      "       5126 |   0.209211  |    0.017462     |   0\n",
      "       5127 |   0.219365  |    0.133459     |   1\n",
      "       5128 |   0.303830  |    0.005933     |   0\n",
      "       5129 |   0.189332  |    0.021386     |   0\n",
      "       5130 |   0.082520  |    0.031319     |   2\n",
      "       5131 |   0.070476  |    0.018099     |   2\n",
      "       5132 |   0.031728  |    0.026641     |   2\n",
      "       5133 |   0.078170  |    0.027259     |   2\n",
      "       5134 |   0.057250  |    0.039573     |   2\n",
      "       5135 |   0.000127  |    0.011980     |   2\n",
      "       5136 |   0.252989  |    0.047408     |   0\n",
      "       5137 |   0.000131  |    0.012964     |   2\n",
      "       5138 |   0.000147  |    0.035885     |   2\n",
      "       5139 |   0.260381  |    0.035701     |   0\n",
      "       5140 |   0.254299  |    0.153690     |   1\n",
      "       5141 |   0.321283  |    0.049190     |   1\n",
      "       5142 |   0.000150  |    0.029398     |   2\n",
      "       5143 |   0.000136  |    0.028240     |   2\n",
      "       5144 |   0.000152  |    0.022359     |   2\n",
      "       5145 |   0.084280  |    0.029572     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 5147: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       5146 |   0.083394  |    0.021355     |   2\n",
      "       5147 |   0.088574  |    0.012789     |   2\n",
      "       5148 |   0.231211  |    0.041142     |   0\n",
      "       5149 |   0.067839  |    0.023821     |   2\n",
      "       5150 |   0.287594  |    0.141995     |   1\n",
      "       5151 |   0.067252  |    0.004786     |   2\n",
      "       5152 |   0.091988  |    0.003922     |   2\n",
      "       5153 |   0.197989  |    0.056652     |   0\n",
      "       5154 |   0.289283  |    0.051192     |   1\n",
      "       5155 |   0.262179  |    0.136437     |   1\n",
      "       5156 |   0.041231  |    0.003379     |   2\n",
      "       5157 |   0.272115  |    0.010714     |   0\n",
      "       5158 |   0.265513  |    0.147536     |   1\n",
      "       5159 |   0.215346  |    0.048509     |   1\n",
      "       5160 |   0.072165  |    0.026445     |   2\n",
      "       5161 |   0.078883  |    0.032207     |   2\n",
      "       5162 |   0.254785  |    0.132223     |   1\n",
      "       5163 |   0.292606  |    0.090087     |   1\n",
      "       5164 |   0.253078  |    0.089491     |   1\n",
      "       5165 |   0.086454  |    0.014040     |   2\n",
      "       5166 |   0.202507  |    0.140219     |   1\n",
      "       5167 |   0.220476  |    0.099538     |   1\n",
      "       5168 |   0.080138  |    0.004482     |   2\n",
      "       5169 |   0.274303  |    0.028807     |   0\n",
      "       5170 |   0.216401  |    0.033043     |   0\n",
      "       5171 |   0.035911  |    0.010092     |   2\n",
      "       5172 |   0.000130  |    0.051315     |   2\n",
      "       5173 |   0.008223  |    0.010468     |   2\n",
      "       5174 |   0.238379  |    0.146261     |   1\n",
      "       5175 |   0.256474  |    0.099856     |   1\n",
      "       5176 |   0.238329  |    0.092122     |   1\n",
      "       5177 |   0.265207  |    0.079660     |   1\n",
      "       5178 |   0.126869  |    0.005405     |   2\n",
      "       5179 |   0.209800  |    0.043721     |   0\n",
      "       5180 |   0.057942  |    0.010918     |   2\n",
      "       5181 |   0.080450  |    0.035037     |   2\n",
      "       5182 |   0.067523  |    0.026256     |   2\n",
      "       5183 |   0.028292  |    0.033323     |   2\n",
      "       5184 |   0.241720  |    0.034714     |   0\n",
      "       5185 |   0.070928  |    0.043937     |   2\n",
      "       5186 |   0.055492  |    0.014323     |   2\n",
      "       5187 |   0.000126  |    0.024689     |   2\n",
      "       5188 |   0.000132  |    0.058362     |   2\n",
      "       5189 |   0.275873  |    0.130836     |   1\n",
      "       5190 |   0.265467  |    0.038400     |   1\n",
      "       5191 |   0.287767  |    0.103150     |   1\n",
      "       5192 |   0.235806  |    0.094701     |   1\n",
      "       5193 |   0.216423  |    0.096758     |   1\n",
      "       5194 |   0.300202  |    0.006296     |   0\n",
      "       5195 |   0.000148  |    0.030850     |   2\n",
      "       5196 |   0.000158  |    0.041238     |   2\n",
      "       5197 |   0.000136  |    0.016242     |   2\n",
      "       5198 |   0.000146  |    0.031904     |   2\n",
      "       5199 |   0.301175  |    0.030481     |   0\n",
      "       5200 |   0.283637  |    0.042982     |   0\n",
      "       5201 |   0.085382  |    0.006978     |   2\n",
      "       5202 |   0.081196  |    0.045663     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 5204: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       5203 |   0.203199  |    0.014631     |   0\n",
      "       5204 |   0.287520  |    0.147549     |   1\n",
      "       5205 |   0.294067  |    0.087566     |   1\n",
      "       5206 |   0.293956  |    0.104933     |   1\n",
      "       5207 |   0.340655  |    0.076710     |   1\n",
      "       5208 |   0.282955  |    0.083953     |   1\n",
      "       5209 |   0.313266  |    0.093602     |   1\n",
      "       5210 |   0.329413  |    0.007136     |   0\n",
      "       5211 |   0.180494  |    0.013879     |   0\n",
      "       5212 |   0.219442  |    0.050216     |   0\n",
      "       5213 |   0.086648  |    0.010367     |   2\n",
      "       5214 |   0.066732  |    0.039443     |   2\n",
      "       5215 |   0.260618  |    0.102535     |   1\n",
      "       5216 |   0.065900  |    0.018491     |   2\n",
      "       5217 |   0.086213  |    0.040117     |   2\n",
      "       5218 |   0.309609  |    0.038981     |   0\n",
      "       5219 |   0.210712  |    0.099380     |   1\n",
      "       5220 |   0.246235  |    0.003175     |   0\n",
      "       5221 |   0.041878  |    0.013092     |   2\n",
      "       5222 |   0.071397  |    0.037649     |   2\n",
      "       5223 |   0.079451  |    0.016073     |   2\n",
      "       5224 |   0.228519  |    0.059861     |   0\n",
      "       5225 |   0.210992  |    0.105594     |   1\n",
      "       5226 |   0.322226  |    0.056471     |   1\n",
      "       5227 |   0.267487  |    0.031966     |   0\n",
      "       5228 |   0.265764  |    0.035297     |   0\n",
      "       5229 |   0.246613  |    0.100675     |   1\n",
      "       5230 |   0.209912  |    0.005653     |   0\n",
      "       5231 |   0.087366  |    0.039382     |   2\n",
      "       5232 |   0.283200  |    0.014290     |   0\n",
      "       5233 |   0.263974  |    0.045192     |   0\n",
      "       5234 |   0.080859  |    0.019087     |   2\n",
      "       5235 |   0.304901  |    0.035710     |   0\n",
      "       5236 |   0.249579  |    0.033764     |   0\n",
      "       5237 |   0.247662  |    0.041355     |   0\n",
      "       5238 |   0.271598  |    0.045824     |   1\n",
      "       5239 |   0.223286  |    0.032125     |   0\n",
      "       5240 |   0.037286  |    0.026080     |   2\n",
      "       5241 |   0.280512  |    0.048418     |   0\n",
      "       5242 |   0.000128  |    0.011807     |   2\n",
      "       5243 |   0.229379  |    0.138746     |   1\n",
      "       5244 |   0.250779  |    0.004056     |   0\n",
      "       5245 |   0.284243  |    0.140572     |   1\n",
      "       5246 |   0.261479  |    0.038970     |   1\n",
      "       5247 |   0.210918  |    0.093778     |   1\n",
      "       5248 |   0.007942  |    0.009821     |   2\n",
      "       5249 |   0.247666  |    0.140323     |   1\n",
      "       5250 |   0.249156  |    0.060507     |   1\n",
      "       5251 |   0.196700  |    0.026344     |   0\n",
      "       5252 |   0.246784  |    0.024347     |   0\n",
      "       5253 |   0.128237  |    0.029740     |   2\n",
      "       5254 |   0.059382  |    0.035205     |   2\n",
      "       5255 |   0.197261  |    0.154306     |   1\n",
      "       5256 |   0.083050  |    0.013007     |   2\n",
      "       5257 |   0.277655  |    0.048025     |   1\n",
      "       5258 |   0.275590  |    0.013327     |   0\n",
      "       5259 |   0.283035  |    0.139265     |   1\n",
      "       5260 |   0.189603  |    0.008788     |   0\n",
      "       5261 |   0.243585  |    0.032165     |   0\n",
      "       5262 |   0.264485  |    0.100397     |   1\n",
      "       5263 |   0.069816  |    0.006458     |   2\n",
      "       5264 |   0.240727  |    0.047189     |   0\n",
      "       5265 |   0.030629  |    0.007836     |   2\n",
      "       5266 |   0.324364  |    0.148516     |   1\n",
      "       5267 |   0.076787  |    0.002973     |   2\n",
      "       5268 |   0.208498  |    0.009636     |   0\n",
      "       5269 |   0.057341  |    0.057273     |   2\n",
      "       5270 |   0.245299  |    0.106887     |   1\n",
      "       5271 |   0.273735  |    0.089180     |   1\n",
      "       5272 |   0.000123  |    0.032852     |   2\n",
      "       5273 |   0.248340  |    0.092322     |   1\n",
      "       5274 |   0.210306  |    0.022550     |   0\n",
      "       5275 |   0.285448  |    0.142202     |   1\n",
      "       5276 |   0.248334  |    0.012893     |   0\n",
      "       5277 |   0.204934  |    0.008972     |   0\n",
      "       5278 |   0.000126  |    0.023553     |   2\n",
      "       5279 |   0.000142  |    0.021833     |   2\n",
      "       5280 |   0.253791  |    0.129349     |   1\n",
      "       5281 |   0.270623  |    0.011807     |   0\n",
      "       5282 |   0.246090  |    0.043149     |   0\n",
      "       5283 |   0.258189  |    0.150208     |   1\n",
      "       5284 |   0.000143  |    0.012008     |   2\n",
      "       5285 |   0.387066  |    0.033503     |   1\n",
      "       5286 |   0.194057  |    0.033845     |   0\n",
      "       5287 |   0.334364  |    0.033568     |   0\n",
      "       5288 |   0.000131  |    0.015591     |   2\n",
      "       5289 |   0.262567  |    0.112656     |   1\n",
      "       5290 |   0.226291  |    0.103996     |   1\n",
      "       5291 |   0.237758  |    0.009736     |   0\n",
      "       5292 |   0.264998  |    0.037912     |   0\n",
      "       5293 |   0.290052  |    0.117246     |   1\n",
      "       5294 |   0.273640  |    0.067415     |   1\n",
      "       5295 |   0.000143  |    0.024513     |   2\n",
      "       5296 |   0.314617  |    0.149821     |   1\n",
      "       5297 |   0.302729  |    0.053518     |   1\n",
      "       5298 |   0.081794  |    0.015988     |   2\n",
      "       5299 |   0.081697  |    0.031844     |   2\n",
      "       5300 |   0.287559  |    0.095343     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 5301: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       5301 |   0.219777  |    0.089577     |   1\n",
      "       5302 |   0.194688  |    0.038395     |   1\n",
      "       5303 |   0.266957  |    0.086276     |   1\n",
      "       5304 |   0.253190  |    0.015065     |   0\n",
      "       5305 |   0.296193  |    0.054376     |   0\n",
      "       5306 |   0.081000  |    0.014244     |   2\n",
      "       5307 |   0.065876  |    0.045203     |   2\n",
      "       5308 |   0.062818  |    0.013584     |   2\n",
      "       5309 |   0.089089  |    0.027376     |   2\n",
      "       5310 |   0.256399  |    0.054860     |   0\n",
      "       5311 |   0.302933  |    0.144693     |   1\n",
      "       5312 |   0.276226  |    0.060557     |   1\n",
      "       5313 |   0.041065  |    0.010779     |   2\n",
      "       5314 |   0.069121  |    0.058635     |   2\n",
      "       5315 |   0.079052  |    0.007532     |   2\n",
      "       5316 |   0.260228  |    0.043373     |   0\n",
      "       5317 |   0.325070  |    0.087751     |   1\n",
      "       5318 |   0.083726  |    0.023887     |   2\n",
      "       5319 |   0.199575  |    0.033717     |   0\n",
      "       5320 |   0.077666  |    0.019027     |   2\n",
      "       5321 |   0.036523  |    0.041674     |   2\n",
      "       5322 |   0.178894  |    0.027007     |   0\n",
      "       5323 |   0.241086  |    0.143119     |   1\n",
      "       5324 |   0.000125  |    0.003549     |   2\n",
      "       5325 |   0.006733  |    0.013588     |   2\n",
      "       5326 |   0.252596  |    0.138555     |   1\n",
      "       5327 |   0.127011  |    0.006024     |   2\n",
      "       5328 |   0.286531  |    0.048038     |   0\n",
      "       5329 |   0.259094  |    0.097252     |   1\n",
      "       5330 |   0.055857  |    0.011159     |   2\n",
      "       5331 |   0.249585  |    0.031367     |   0\n",
      "       5332 |   0.079890  |    0.029245     |   2\n",
      "       5333 |   0.065331  |    0.027462     |   2\n",
      "       5334 |   0.244641  |    0.047497     |   0\n",
      "       5335 |   0.217583  |    0.138082     |   1\n",
      "       5336 |   0.381376  |    0.087968     |   1\n",
      "       5337 |   0.227047  |    0.011039     |   0\n",
      "       5338 |   0.402749  |    0.050934     |   1\n",
      "       5339 |   0.248122  |    0.029152     |   0\n",
      "       5340 |   0.220436  |    0.056388     |   0\n",
      "       5341 |   0.029568  |    0.010243     |   2\n",
      "       5342 |   0.203256  |    0.149773     |   1\n",
      "       5343 |   0.069163  |    0.006570     |   2\n",
      "       5344 |   0.308758  |    0.082808     |   1\n",
      "       5345 |   0.328527  |    0.014361     |   0\n",
      "       5346 |   0.057311  |    0.048581     |   2\n",
      "       5347 |   0.000122  |    0.006147     |   2\n",
      "       5348 |   0.216899  |    0.028134     |   0\n",
      "       5349 |   0.000125  |    0.044177     |   2\n",
      "       5350 |   0.257518  |    0.012353     |   0\n",
      "       5351 |   0.229205  |    0.033135     |   0\n",
      "       5352 |   0.000141  |    0.035697     |   2\n",
      "       5353 |   0.000139  |    0.027043     |   2\n",
      "       5354 |   0.000129  |    0.031238     |   2\n",
      "       5355 |   0.000136  |    0.015847     |   2\n",
      "       5356 |   0.291824  |    0.082860     |   1\n",
      "       5357 |   0.236526  |    0.029202     |   0\n",
      "       5358 |   0.081234  |    0.041881     |   2\n",
      "       5359 |   0.081074  |    0.032985     |   2\n",
      "       5360 |   0.286008  |    0.102973     |   1\n",
      "       5361 |   0.219212  |    0.010414     |   0\n",
      "       5362 |   0.173038  |    0.036780     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 5364: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       5363 |   0.202833  |    0.036268     |   0\n",
      "       5364 |   0.302750  |    0.092125     |   1\n",
      "       5365 |   0.205036  |    0.018639     |   0\n",
      "       5366 |   0.315330  |    0.143074     |   1\n",
      "       5367 |   0.239641  |    0.012457     |   0\n",
      "       5368 |   0.267402  |    0.087806     |   1\n",
      "       5369 |   0.080973  |    0.012752     |   2\n",
      "       5370 |   0.064312  |    0.047272     |   2\n",
      "       5371 |   0.250615  |    0.136689     |   1\n",
      "       5372 |   0.272629  |    0.002969     |   0\n",
      "       5373 |   0.066325  |    0.010402     |   2\n",
      "       5374 |   0.289042  |    0.152436     |   1\n",
      "       5375 |   0.265353  |    0.074143     |   1\n",
      "       5376 |   0.088112  |    0.011433     |   2\n",
      "       5377 |   0.258399  |    0.179188     |   1\n",
      "       5378 |   0.308871  |    0.008545     |   1\n",
      "       5379 |   0.194450  |    0.048219     |   0\n",
      "       5380 |   0.040396  |    0.006738     |   2\n",
      "       5381 |   0.070137  |    0.043194     |   2\n",
      "       5382 |   0.275312  |    0.046862     |   0\n",
      "       5383 |   0.260257  |    0.087038     |   1\n",
      "       5384 |   0.079121  |    0.012950     |   2\n",
      "       5385 |   0.224599  |    0.151646     |   1\n",
      "       5386 |   0.200924  |    0.003060     |   0\n",
      "       5387 |   0.082631  |    0.009482     |   2\n",
      "       5388 |   0.080111  |    0.046642     |   2\n",
      "       5389 |   0.298087  |    0.095228     |   1\n",
      "       5390 |   0.037974  |    0.010719     |   2\n",
      "       5391 |   0.238425  |    0.041198     |   0\n",
      "       5392 |   0.239875  |    0.012397     |   0\n",
      "       5393 |   0.252550  |    0.042632     |   0\n",
      "       5394 |   0.241327  |    0.028473     |   0\n",
      "       5395 |   0.000123  |    0.027017     |   2\n",
      "       5396 |   0.007285  |    0.023616     |   2\n",
      "       5397 |   0.237308  |    0.147096     |   1\n",
      "       5398 |   0.123615  |    0.005160     |   2\n",
      "       5399 |   0.315233  |    0.094875     |   1\n",
      "       5400 |   0.054290  |    0.029781     |   2\n",
      "       5401 |   0.081543  |    0.025988     |   2\n",
      "       5402 |   0.238931  |    0.026906     |   0\n",
      "       5403 |   0.341700  |    0.043028     |   0\n",
      "       5404 |   0.216064  |    0.017910     |   0\n",
      "       5405 |   0.236709  |    0.047471     |   0\n",
      "       5406 |   0.066471  |    0.014785     |   2\n",
      "       5407 |   0.029132  |    0.031366     |   2\n",
      "       5408 |   0.071352  |    0.026797     |   2\n",
      "       5409 |   0.261518  |    0.028708     |   0\n",
      "       5410 |   0.276405  |    0.143343     |   1\n",
      "       5411 |   0.282248  |    0.050279     |   1\n",
      "       5412 |   0.056584  |    0.016662     |   2\n",
      "       5413 |   0.280424  |    0.041069     |   0\n",
      "       5414 |   0.264389  |    0.033101     |   0\n",
      "       5415 |   0.000119  |    0.028386     |   2\n",
      "       5416 |   0.206054  |    0.021334     |   0\n",
      "       5417 |   0.275451  |    0.047458     |   0\n",
      "       5418 |   0.316857  |    0.083230     |   1\n",
      "       5419 |   0.199766  |    0.010856     |   0\n",
      "       5420 |   0.262020  |    0.153788     |   1\n",
      "       5421 |   0.000121  |    0.010388     |   2\n",
      "       5422 |   0.261929  |    0.065911     |   1\n",
      "       5423 |   0.311646  |    0.087935     |   1\n",
      "       5424 |   0.000135  |    0.006483     |   2\n",
      "       5425 |   0.203427  |    0.033130     |   0\n",
      "       5426 |   0.261016  |    0.150408     |   1\n",
      "       5427 |   0.210312  |    0.013385     |   0\n",
      "       5428 |   0.305005  |    0.044840     |   1\n",
      "       5429 |   0.000133  |    0.012786     |   2\n",
      "       5430 |   0.290840  |    0.049170     |   0\n",
      "       5431 |   0.000125  |    0.019702     |   2\n",
      "       5432 |   0.261139  |    0.031108     |   0\n",
      "       5433 |   0.283362  |    0.017206     |   0\n",
      "       5434 |   0.200911  |    0.056684     |   0\n",
      "       5435 |   0.241188  |    0.138813     |   1\n",
      "       5436 |   0.299872  |    0.048410     |   1\n",
      "       5437 |   0.254257  |    0.100019     |   1\n",
      "       5438 |   0.257338  |    0.102744     |   1\n",
      "       5439 |   0.248184  |    0.092804     |   1\n",
      "       5440 |   0.317709  |    0.094809     |   1\n",
      "       5441 |   0.000132  |    0.031560     |   2\n",
      "       5442 |   0.245893  |    0.105118     |   1\n",
      "       5443 |   0.226682  |    0.012912     |   0\n",
      "       5444 |   0.250009  |    0.136259     |   1\n",
      "       5445 |   0.211338  |    0.010887     |   0\n",
      "       5446 |   0.080714  |    0.048441     |   2\n",
      "       5447 |   0.387841  |    0.015019     |   0\n",
      "       5448 |   0.333106  |    0.136422     |   1\n",
      "       5449 |   0.232503  |    0.002963     |   0\n",
      "       5450 |   0.081316  |    0.011101     |   2\n",
      "       5451 |   0.238734  |    0.045856     |   0\n",
      "       5452 |   0.268882  |    0.013614     |   0\n",
      "       5453 |   0.203632  |    0.151173     |   1\n",
      "       5454 |   0.308485  |    0.091499     |   1\n",
      "       5455 |   0.221942  |    0.034879     |   1\n",
      "       5456 |   0.217817  |    0.042941     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 5457: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       5457 |   0.087944  |    0.009287     |   2\n",
      "       5458 |   0.069335  |    0.043256     |   2\n",
      "       5459 |   0.239110  |    0.013762     |   0\n",
      "       5460 |   0.264760  |    0.141504     |   1\n",
      "       5461 |   0.068918  |    0.002892     |   2\n",
      "       5462 |   0.088222  |    0.006794     |   2\n",
      "       5463 |   0.041541  |    0.048592     |   2\n",
      "       5464 |   0.226744  |    0.009540     |   0\n",
      "       5465 |   0.258926  |    0.054198     |   0\n",
      "       5466 |   0.071566  |    0.010144     |   2\n",
      "       5467 |   0.080965  |    0.048363     |   2\n",
      "       5468 |   0.267079  |    0.082840     |   1\n",
      "       5469 |   0.087426  |    0.021847     |   2\n",
      "       5470 |   0.285393  |    0.104266     |   1\n",
      "       5471 |   0.078447  |    0.012183     |   2\n",
      "       5472 |   0.196782  |    0.156923     |   1\n",
      "       5473 |   0.037913  |    0.004783     |   2\n",
      "       5474 |   0.236785  |    0.012026     |   0\n",
      "       5475 |   0.000120  |    0.044876     |   2\n",
      "       5476 |   0.008071  |    0.012373     |   2\n",
      "       5477 |   0.301598  |    0.145870     |   1\n",
      "       5478 |   0.126063  |    0.006344     |   2\n",
      "       5479 |   0.252553  |    0.019413     |   0\n",
      "       5480 |   0.058036  |    0.033642     |   2\n",
      "       5481 |   0.078425  |    0.011987     |   2\n",
      "       5482 |   0.306908  |    0.142269     |   1\n",
      "       5483 |   0.213685  |    0.003847     |   0\n",
      "       5484 |   0.069285  |    0.012108     |   2\n",
      "       5485 |   0.302664  |    0.150462     |   1\n",
      "       5486 |   0.304672  |    0.040336     |   1\n",
      "       5487 |   0.028440  |    0.016000     |   2\n",
      "       5488 |   0.066844  |    0.035185     |   2\n",
      "       5489 |   0.232463  |    0.157972     |   1\n",
      "       5490 |   0.236917  |    0.047119     |   1\n",
      "       5491 |   0.055787  |    0.007658     |   2\n",
      "       5492 |   0.269526  |    0.158502     |   1\n",
      "       5493 |   0.242201  |    0.067235     |   1\n",
      "       5494 |   0.280890  |    0.085381     |   1\n",
      "       5495 |   0.255289  |    0.008143     |   0\n",
      "       5496 |   0.259575  |    0.053611     |   0\n",
      "       5497 |   0.000118  |    0.010903     |   2\n",
      "       5498 |   0.199970  |    0.047458     |   0\n",
      "       5499 |   0.000120  |    0.008376     |   2\n",
      "       5500 |   0.000137  |    0.048159     |   2\n",
      "       5501 |   0.224108  |    0.058075     |   0\n",
      "       5502 |   0.230600  |    0.133823     |   1\n",
      "       5503 |   0.325878  |    0.129214     |   1\n",
      "       5504 |   0.081600  |    0.005763     |   2\n",
      "       5505 |   0.303971  |    0.014741     |   0\n",
      "       5506 |   0.179344  |    0.050834     |   0\n",
      "       5507 |   0.204758  |    0.131175     |   1\n",
      "       5508 |   0.267443  |    0.009209     |   0\n",
      "       5509 |   0.062300  |    0.046317     |   2\n",
      "       5510 |   0.241368  |    0.136452     |   1\n",
      "       5511 |   0.263486  |    0.086021     |   1\n",
      "       5512 |   0.066475  |    0.018369     |   2\n",
      "       5513 |   0.242505  |    0.025560     |   0\n",
      "       5514 |   0.214312  |    0.037963     |   0\n",
      "       5515 |   0.226765  |    0.138696     |   1\n",
      "       5516 |   0.221872  |    0.014670     |   0\n",
      "       5517 |   0.246081  |    0.088160     |   1\n",
      "       5518 |   0.258118  |    0.144734     |   1\n",
      "       5519 |   0.261640  |    0.012633     |   0\n",
      "       5520 |   0.320382  |    0.054498     |   1\n",
      "       5521 |   0.088332  |    0.028379     |   2\n",
      "       5522 |   0.040956  |    0.046270     |   2\n",
      "       5523 |   0.068281  |    0.010096     |   2\n",
      "       5524 |   0.273504  |    0.041981     |   0\n",
      "       5525 |   0.184815  |    0.147872     |   1\n",
      "       5526 |   0.226612  |    0.047632     |   1\n",
      "       5527 |   0.208676  |    0.055368     |   0\n",
      "       5528 |   0.224612  |    0.080179     |   1\n",
      "       5529 |   0.244376  |    0.133870     |   1\n",
      "       5530 |   0.254637  |    0.015793     |   0\n",
      "       5531 |   0.313343  |    0.057689     |   1\n",
      "       5532 |   0.203988  |    0.086363     |   1\n",
      "       5533 |   0.074671  |    0.031950     |   2\n",
      "       5534 |   0.086267  |    0.038068     |   2\n",
      "       5535 |   0.238620  |    0.020844     |   0\n",
      "       5536 |   0.081028  |    0.041247     |   2\n",
      "       5537 |   0.274146  |    0.133725     |   1\n",
      "       5538 |   0.035717  |    0.009777     |   2\n",
      "       5539 |   0.292936  |    0.088012     |   1\n",
      "       5540 |   0.226696  |    0.005617     |   0\n",
      "       5541 |   0.244752  |    0.042248     |   0\n",
      "       5542 |   0.277129  |    0.081375     |   1\n",
      "       5543 |   0.226416  |    0.034283     |   0\n",
      "       5544 |   0.246882  |    0.128229     |   1\n",
      "       5545 |   0.255085  |    0.008084     |   0\n",
      "       5546 |   0.261136  |    0.040960     |   0\n",
      "       5547 |   0.216904  |    0.016517     |   0\n",
      "       5548 |   0.218456  |    0.044810     |   0\n",
      "       5549 |   0.000121  |    0.033221     |   2\n",
      "       5550 |   0.006909  |    0.029084     |   2\n",
      "       5551 |   0.271278  |    0.158793     |   1\n",
      "       5552 |   0.327119  |    0.045524     |   1\n",
      "       5553 |   0.122834  |    0.047582     |   2\n",
      "       5554 |   0.201810  |    0.022381     |   0\n",
      "       5555 |   0.237585  |    0.130209     |   1\n",
      "       5556 |   0.237948  |    0.009027     |   0\n",
      "       5557 |   0.337948  |    0.098504     |   1\n",
      "       5558 |   0.201507  |    0.096851     |   1\n",
      "       5559 |   0.287589  |    0.090649     |   1\n",
      "       5560 |   0.238698  |    0.093907     |   1\n",
      "       5561 |   0.314492  |    0.090789     |   1\n",
      "       5562 |   0.259869  |    0.085516     |   1\n",
      "       5563 |   0.271521  |    0.063076     |   1\n",
      "       5564 |   0.265663  |    0.111375     |   1\n",
      "       5565 |   0.256224  |    0.086680     |   1\n",
      "       5566 |   0.262158  |    0.003463     |   0\n",
      "       5567 |   0.056985  |    0.028842     |   2\n",
      "       5568 |   0.234643  |    0.035574     |   0\n",
      "       5569 |   0.363464  |    0.075868     |   1\n",
      "       5570 |   0.210383  |    0.026394     |   0\n",
      "       5571 |   0.268250  |    0.042176     |   0\n",
      "       5572 |   0.078372  |    0.021601     |   2\n",
      "       5573 |   0.273316  |    0.135880     |   1\n",
      "       5574 |   0.294475  |    0.059969     |   1\n",
      "       5575 |   0.338009  |    0.138761     |   1\n",
      "       5576 |   0.211787  |    0.006415     |   0\n",
      "       5577 |   0.192996  |    0.061036     |   1\n",
      "       5578 |   0.067679  |    0.026702     |   2\n",
      "       5579 |   0.276190  |    0.149240     |   1\n",
      "       5580 |   0.299477  |    0.049518     |   1\n",
      "       5581 |   0.028624  |    0.027931     |   2\n",
      "       5582 |   0.283955  |    0.112153     |   1\n",
      "       5583 |   0.264050  |    0.013683     |   0\n",
      "       5584 |   0.068486  |    0.033004     |   2\n",
      "       5585 |   0.053351  |    0.008117     |   2\n",
      "       5586 |   0.000118  |    0.055405     |   2\n",
      "       5587 |   0.189661  |    0.088401     |   1\n",
      "       5588 |   0.000120  |    0.023270     |   2\n",
      "       5589 |   0.332978  |    0.101764     |   1\n",
      "       5590 |   0.293698  |    0.093015     |   1\n",
      "       5591 |   0.194949  |    0.101292     |   1\n",
      "       5592 |   0.290123  |    0.086212     |   1\n",
      "       5593 |   0.225135  |    0.005041     |   0\n",
      "       5594 |   0.208377  |    0.051112     |   0\n",
      "       5595 |   0.000138  |    0.025386     |   2\n",
      "       5596 |   0.218400  |    0.133678     |   1\n",
      "       5597 |   0.276540  |    0.141215     |   1\n",
      "       5598 |   0.307493  |    0.050233     |   1\n",
      "       5599 |   0.274155  |    0.025750     |   0\n",
      "       5600 |   0.000133  |    0.037648     |   2\n",
      "       5601 |   0.277453  |    0.145415     |   1\n",
      "       5602 |   0.270545  |    0.082794     |   1\n",
      "       5603 |   0.193429  |    0.029703     |   0\n",
      "       5604 |   0.278184  |    0.079083     |   1\n",
      "       5605 |   0.202277  |    0.016097     |   0\n",
      "       5606 |   0.198664  |    0.030885     |   0\n",
      "       5607 |   0.000125  |    0.034802     |   2\n",
      "       5608 |   0.000134  |    0.033733     |   2\n",
      "       5609 |   0.293961  |    0.025123     |   0\n",
      "       5610 |   0.079148  |    0.037551     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 5612: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       5611 |   0.079911  |    0.008223     |   2\n",
      "       5612 |   0.079022  |    0.026201     |   2\n",
      "       5613 |   0.220546  |    0.044455     |   0\n",
      "       5614 |   0.062248  |    0.017063     |   2\n",
      "       5615 |   0.248800  |    0.155413     |   1\n",
      "       5616 |   0.222937  |    0.009437     |   0\n",
      "       5617 |   0.258864  |    0.089035     |   1\n",
      "       5618 |   0.329396  |    0.059636     |   1\n",
      "       5619 |   0.290801  |    0.130761     |   1\n",
      "       5620 |   0.062580  |    0.004420     |   2\n",
      "       5621 |   0.319185  |    0.148548     |   1\n",
      "       5622 |   0.087185  |    0.003386     |   2\n",
      "       5623 |   0.040318  |    0.011230     |   2\n",
      "       5624 |   0.243207  |    0.047508     |   0\n",
      "       5625 |   0.069821  |    0.008541     |   2\n",
      "       5626 |   0.315357  |    0.130820     |   1\n",
      "       5627 |   0.074546  |    0.005445     |   2\n",
      "       5628 |   0.231099  |    0.047061     |   0\n",
      "       5629 |   0.087541  |    0.013846     |   2\n",
      "       5630 |   0.079515  |    0.043445     |   2\n",
      "       5631 |   0.265948  |    0.041249     |   0\n",
      "       5632 |   0.035750  |    0.010212     |   2\n",
      "       5633 |   0.367592  |    0.130826     |   1\n",
      "       5634 |   0.261436  |    0.087676     |   1\n",
      "       5635 |   0.213807  |    0.006146     |   0\n",
      "       5636 |   0.183663  |    0.047401     |   0\n",
      "       5637 |   0.245885  |    0.006900     |   0\n",
      "       5638 |   0.279035  |    0.088945     |   0\n",
      "       5639 |   0.232354  |    0.020427     |   1\n",
      "       5640 |   0.227051  |    0.028713     |   0\n",
      "       5641 |   0.213415  |    0.036400     |   0\n",
      "       5642 |   0.262577  |    0.022382     |   0\n",
      "       5643 |   0.000119  |    0.030469     |   2\n",
      "       5644 |   0.215701  |    0.083568     |   1\n",
      "       5645 |   0.007179  |    0.013070     |   2\n",
      "       5646 |   0.263314  |    0.050467     |   0\n",
      "       5647 |   0.123596  |    0.009122     |   2\n",
      "       5648 |   0.235584  |    0.045690     |   0\n",
      "       5649 |   0.236136  |    0.013408     |   0\n",
      "       5650 |   0.217048  |    0.131592     |   1\n",
      "       5651 |   0.057334  |    0.005660     |   2\n",
      "       5652 |   0.081703  |    0.032785     |   2\n",
      "       5653 |   0.220246  |    0.046209     |   0\n",
      "       5654 |   0.224355  |    0.162119     |   1\n",
      "       5655 |   0.282558  |    0.039537     |   1\n",
      "       5656 |   0.233757  |    0.024690     |   0\n",
      "       5657 |   0.069001  |    0.021804     |   2\n",
      "       5658 |   0.228608  |    0.027228     |   0\n",
      "       5659 |   0.028633  |    0.022590     |   2\n",
      "       5660 |   0.196679  |    0.023654     |   0\n",
      "       5661 |   0.216921  |    0.032628     |   0\n",
      "       5662 |   0.072027  |    0.020954     |   2\n",
      "       5663 |   0.264289  |    0.031354     |   0\n",
      "       5664 |   0.242620  |    0.101863     |   1\n",
      "       5665 |   0.053051  |    0.016565     |   2\n",
      "       5666 |   0.248543  |    0.044610     |   0\n",
      "       5667 |   0.288417  |    0.019693     |   0\n",
      "       5668 |   0.208885  |    0.029107     |   0\n",
      "       5669 |   0.246936  |    0.032235     |   0\n",
      "       5670 |   0.000115  |    0.016671     |   2\n",
      "       5671 |   0.237936  |    0.036796     |   0\n",
      "       5672 |   0.225943  |    0.137707     |   1\n",
      "       5673 |   0.000118  |    0.004610     |   2\n",
      "       5674 |   0.201037  |    0.093439     |   1\n",
      "       5675 |   0.000133  |    0.020587     |   2\n",
      "       5676 |   0.000130  |    0.028543     |   2\n",
      "       5677 |   0.270995  |    0.029724     |   0\n",
      "       5678 |   0.260018  |    0.031250     |   0\n",
      "       5679 |   0.237274  |    0.020216     |   0\n",
      "       5680 |   0.259106  |    0.027214     |   0\n",
      "       5681 |   0.291184  |    0.030929     |   0\n",
      "       5682 |   0.000122  |    0.025484     |   2\n",
      "       5683 |   0.000134  |    0.021157     |   2\n",
      "       5684 |   0.092736  |    0.034564     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 5686: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       5685 |   0.080428  |    0.025171     |   2\n",
      "       5686 |   0.258039  |    0.087099     |   1\n",
      "       5687 |   0.091889  |    0.017264     |   2\n",
      "       5688 |   0.070337  |    0.043701     |   2\n",
      "       5689 |   0.207834  |    0.011427     |   0\n",
      "       5690 |   0.207292  |    0.032034     |   0\n",
      "       5691 |   0.065477  |    0.032151     |   2\n",
      "       5692 |   0.091332  |    0.035504     |   2\n",
      "       5693 |   0.245456  |    0.132603     |   1\n",
      "       5694 |   0.043794  |    0.002941     |   2\n",
      "       5695 |   0.212744  |    0.014332     |   0\n",
      "       5696 |   0.290483  |    0.126295     |   1\n",
      "       5697 |   0.236070  |    0.011435     |   0\n",
      "       5698 |   0.320153  |    0.141363     |   1\n",
      "       5699 |   0.196097  |    0.061493     |   1\n",
      "       5700 |   0.070338  |    0.027215     |   2\n",
      "       5701 |   0.237566  |    0.047325     |   0\n",
      "       5702 |   0.079526  |    0.010154     |   2\n",
      "       5703 |   0.087082  |    0.056651     |   2\n",
      "       5704 |   0.215772  |    0.090903     |   1\n",
      "       5705 |   0.076572  |    0.008630     |   2\n",
      "       5706 |   0.035264  |    0.042307     |   2\n",
      "       5707 |   0.000117  |    0.013122     |   2\n",
      "       5708 |   0.007678  |    0.033536     |   2\n",
      "       5709 |   0.218593  |    0.130643     |   1\n",
      "       5710 |   0.126861  |    0.006165     |   2\n",
      "       5711 |   0.247013  |    0.027868     |   0\n",
      "       5712 |   0.275194  |    0.034715     |   0\n",
      "       5713 |   0.238493  |    0.141558     |   1\n",
      "       5714 |   0.228022  |    0.095221     |   1\n",
      "       5715 |   0.284074  |    0.089649     |   1\n",
      "       5716 |   0.059182  |    0.008694     |   2\n",
      "       5717 |   0.247286  |    0.051551     |   0\n",
      "       5718 |   0.202415  |    0.006737     |   0\n",
      "       5719 |   0.315420  |    0.150573     |   1\n",
      "       5720 |   0.079678  |    0.003151     |   2\n",
      "       5721 |   0.066786  |    0.014490     |   2\n",
      "       5722 |   0.273707  |    0.140610     |   1\n",
      "       5723 |   0.227362  |    0.004568     |   0\n",
      "       5724 |   0.207945  |    0.020016     |   0\n",
      "       5725 |   0.254254  |    0.144421     |   1\n",
      "       5726 |   0.268658  |    0.014688     |   0\n",
      "       5727 |   0.299227  |    0.053413     |   1\n",
      "       5728 |   0.299378  |    0.034041     |   0\n",
      "       5729 |   0.257919  |    0.136104     |   1\n",
      "       5730 |   0.028852  |    0.006834     |   2\n",
      "       5731 |   0.268859  |    0.056402     |   1\n",
      "       5732 |   0.304800  |    0.146457     |   1\n",
      "       5733 |   0.253180  |    0.009806     |   0\n",
      "       5734 |   0.236423  |    0.050236     |   1\n",
      "       5735 |   0.071457  |    0.034478     |   2\n",
      "       5736 |   0.218128  |    0.020841     |   0\n",
      "       5737 |   0.220771  |    0.033786     |   0\n",
      "       5738 |   0.177333  |    0.139427     |   1\n",
      "       5739 |   0.183115  |    0.100776     |   1\n",
      "       5740 |   0.284562  |    0.067854     |   1\n",
      "       5741 |   0.053373  |    0.005072     |   2\n",
      "       5742 |   0.000116  |    0.049943     |   2\n",
      "       5743 |   0.263987  |    0.019002     |   0\n",
      "       5744 |   0.399416  |    0.129036     |   1\n",
      "       5745 |   0.000118  |    0.005264     |   2\n",
      "       5746 |   0.283384  |    0.021035     |   0\n",
      "       5747 |   0.000133  |    0.022928     |   2\n",
      "       5748 |   0.000132  |    0.022781     |   2\n",
      "       5749 |   0.207105  |    0.046997     |   0\n",
      "       5750 |   0.000123  |    0.005997     |   2\n",
      "       5751 |   0.239695  |    0.040048     |   0\n",
      "       5752 |   0.266570  |    0.030080     |   0\n",
      "       5753 |   0.191791  |    0.023922     |   0\n",
      "       5754 |   0.253390  |    0.033129     |   0\n",
      "       5755 |   0.000130  |    0.020032     |   2\n",
      "       5756 |   0.228574  |    0.032153     |   0\n",
      "       5757 |   0.088670  |    0.028362     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 5759: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       5758 |   0.079067  |    0.025517     |   2\n",
      "       5759 |   0.216594  |    0.139150     |   1\n",
      "       5760 |   0.089313  |    0.005722     |   2\n",
      "       5761 |   0.068945  |    0.026447     |   2\n",
      "       5762 |   0.218641  |    0.042112     |   0\n",
      "       5763 |   0.064435  |    0.017102     |   2\n",
      "       5764 |   0.229544  |    0.149996     |   1\n",
      "       5765 |   0.088756  |    0.003001     |   2\n",
      "       5766 |   0.041826  |    0.012007     |   2\n",
      "       5767 |   0.301954  |    0.127135     |   1\n",
      "       5768 |   0.248932  |    0.010120     |   0\n",
      "       5769 |   0.281086  |    0.104779     |   1\n",
      "       5770 |   0.068115  |    0.025806     |   2\n",
      "       5771 |   0.243454  |    0.116054     |   1\n",
      "       5772 |   0.216458  |    0.023603     |   0\n",
      "       5773 |   0.079929  |    0.024231     |   2\n",
      "       5774 |   0.251663  |    0.137926     |   1\n",
      "       5775 |   0.337518  |    0.114538     |   1\n",
      "       5776 |   0.218000  |    0.090144     |   1\n",
      "       5777 |   0.082780  |    0.013883     |   2\n",
      "       5778 |   0.316335  |    0.116449     |   1\n",
      "       5779 |   0.077554  |    0.007768     |   2\n",
      "       5780 |   0.261103  |    0.036573     |   0\n",
      "       5781 |   0.263703  |    0.029801     |   0\n",
      "       5782 |   0.037011  |    0.029213     |   2\n",
      "       5783 |   0.203678  |    0.028142     |   0\n",
      "       5784 |   0.199653  |    0.141429     |   1\n",
      "       5785 |   0.000117  |    0.003618     |   2\n",
      "       5786 |   0.007097  |    0.024795     |   2\n",
      "       5787 |   0.183077  |    0.027405     |   0\n",
      "       5788 |   0.176487  |    0.016227     |   0\n",
      "       5789 |   0.264030  |    0.043490     |   0\n",
      "       5790 |   0.285824  |    0.015682     |   0\n",
      "       5791 |   0.184391  |    0.132648     |   1\n",
      "       5792 |   0.202784  |    0.026615     |   0\n",
      "       5793 |   0.251672  |    0.141491     |   1\n",
      "       5794 |   0.277682  |    0.035470     |   1\n",
      "       5795 |   0.122469  |    0.042169     |   2\n",
      "       5796 |   0.057565  |    0.010775     |   2\n",
      "       5797 |   0.080148  |    0.053613     |   2\n",
      "       5798 |   0.065504  |    0.008601     |   2\n",
      "       5799 |   0.030845  |    0.028899     |   2\n",
      "       5800 |   0.232087  |    0.043905     |   0\n",
      "       5801 |   0.266300  |    0.075719     |   1\n",
      "       5802 |   0.069482  |    0.030030     |   2\n",
      "       5803 |   0.247300  |    0.132046     |   1\n",
      "       5804 |   0.053383  |    0.006955     |   2\n",
      "       5805 |   0.261328  |    0.028603     |   0\n",
      "       5806 |   0.000115  |    0.038546     |   2\n",
      "       5807 |   0.000116  |    0.017064     |   2\n",
      "       5808 |   0.212794  |    0.102749     |   1\n",
      "       5809 |   0.207321  |    0.141188     |   1\n",
      "       5810 |   0.000130  |    0.009669     |   2\n",
      "       5811 |   0.217990  |    0.059936     |   1\n",
      "       5812 |   0.360728  |    0.112736     |   1\n",
      "       5813 |   0.284962  |    0.076368     |   1\n",
      "       5814 |   0.191263  |    0.009323     |   0\n",
      "       5815 |   0.305024  |    0.026716     |   0\n",
      "       5816 |   0.000125  |    0.029362     |   2\n",
      "       5817 |   0.000120  |    0.021884     |   2\n",
      "       5818 |   0.000125  |    0.026060     |   2\n",
      "       5819 |   0.079326  |    0.014519     |   2\n",
      "       5820 |   0.269020  |    0.145251     |   1\n",
      "       5821 |   0.251272  |    0.003064     |   0\n",
      "       5822 |   0.079039  |    0.006868     |   2\n",
      "       5823 |   0.205045  |    0.052589     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 5824: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       5824 |   0.083049  |    0.011747     |   2\n",
      "       5825 |   0.064729  |    0.051635     |   2\n",
      "       5826 |   0.064184  |    0.008774     |   2\n",
      "       5827 |   0.084531  |    0.043930     |   2\n",
      "       5828 |   0.039795  |    0.015425     |   2\n",
      "       5829 |   0.220510  |    0.158434     |   1\n",
      "       5830 |   0.272809  |    0.081949     |   1\n",
      "       5831 |   0.278180  |    0.093521     |   1\n",
      "       5832 |   0.283748  |    0.086895     |   1\n",
      "       5833 |   0.214333  |    0.018038     |   0\n",
      "       5834 |   0.265075  |    0.034069     |   0\n",
      "       5835 |   0.247086  |    0.043609     |   0\n",
      "       5836 |   0.225232  |    0.098390     |   1\n",
      "       5837 |   0.252284  |    0.085708     |   1\n",
      "       5838 |   0.201283  |    0.084358     |   1\n",
      "       5839 |   0.065967  |    0.006757     |   2\n",
      "       5840 |   0.077109  |    0.015763     |   2\n",
      "       5841 |   0.220441  |    0.031614     |   0\n",
      "       5842 |   0.080167  |    0.030236     |   2\n",
      "       5843 |   0.077250  |    0.035805     |   2\n",
      "       5844 |   0.037850  |    0.017132     |   2\n",
      "       5845 |   0.000114  |    0.029163     |   2\n",
      "       5846 |   0.250014  |    0.028982     |   0\n",
      "       5847 |   0.008214  |    0.031129     |   2\n",
      "       5848 |   0.239795  |    0.029966     |   0\n",
      "       5849 |   0.257621  |    0.019127     |   0\n",
      "       5850 |   0.117758  |    0.030215     |   2\n",
      "       5851 |   0.288521  |    0.027017     |   0\n",
      "       5852 |   0.052336  |    0.026069     |   2\n",
      "       5853 |   0.078495  |    0.027848     |   2\n",
      "       5854 |   0.066933  |    0.030132     |   2\n",
      "       5855 |   0.196815  |    0.023418     |   0\n",
      "       5856 |   0.270005  |    0.020563     |   0\n",
      "       5857 |   0.212641  |    0.034949     |   0\n",
      "       5858 |   0.028463  |    0.027737     |   2\n",
      "       5859 |   0.065348  |    0.025031     |   2\n",
      "       5860 |   0.053934  |    0.028773     |   2\n",
      "       5861 |   0.266628  |    0.149303     |   1\n",
      "       5862 |   0.000112  |    0.003847     |   2\n",
      "       5863 |   0.000113  |    0.021935     |   2\n",
      "       5864 |   0.269790  |    0.167695     |   1\n",
      "       5865 |   0.000125  |    0.011309     |   2\n",
      "       5866 |   0.190998  |    0.083716     |   1\n",
      "       5867 |   0.167886  |    0.005920     |   0\n",
      "       5868 |   0.000122  |    0.016977     |   2\n",
      "       5869 |   0.223108  |    0.041790     |   0\n",
      "       5870 |   0.208993  |    0.015403     |   0\n",
      "       5871 |   0.228582  |    0.041285     |   0\n",
      "       5872 |   0.245513  |    0.023170     |   0\n",
      "       5873 |   0.303775  |    0.145440     |   1\n",
      "       5874 |   0.000116  |    0.003100     |   2\n",
      "       5875 |   0.000123  |    0.007618     |   2\n",
      "       5876 |   0.077005  |    0.042717     |   2\n",
      "       5877 |   0.076812  |    0.012035     |   2\n",
      "       5878 |   0.270227  |    0.042494     |   0\n",
      "       5879 |   0.241875  |    0.011059     |   0\n",
      "       5880 |   0.271802  |    0.052100     |   0\n",
      "       5881 |   0.249504  |    0.083770     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 5882: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       5882 |   0.263625  |    0.008887     |   0\n",
      "       5883 |   0.083376  |    0.017206     |   2\n",
      "       5884 |   0.227494  |    0.040897     |   0\n",
      "       5885 |   0.195495  |    0.009650     |   0\n",
      "       5886 |   0.065495  |    0.044644     |   2\n",
      "       5887 |   0.060981  |    0.007418     |   2\n",
      "       5888 |   0.280299  |    0.043663     |   0\n",
      "       5889 |   0.230030  |    0.010733     |   0\n",
      "       5890 |   0.087044  |    0.040620     |   2\n",
      "       5891 |   0.235776  |    0.016561     |   0\n",
      "       5892 |   0.041766  |    0.024811     |   2\n",
      "       5893 |   0.066885  |    0.016587     |   2\n",
      "       5894 |   0.239361  |    0.155178     |   1\n",
      "       5895 |   0.077529  |    0.008111     |   2\n",
      "       5896 |   0.252799  |    0.091161     |   1\n",
      "       5897 |   0.254697  |    0.078948     |   1\n",
      "       5898 |   0.170648  |    0.008662     |   0\n",
      "       5899 |   0.082567  |    0.046673     |   2\n",
      "       5900 |   0.239359  |    0.007253     |   0\n",
      "       5901 |   0.077549  |    0.044356     |   2\n",
      "       5902 |   0.275111  |    0.008130     |   0\n",
      "       5903 |   0.036433  |    0.043823     |   2\n",
      "       5904 |   0.243355  |    0.017954     |   0\n",
      "       5905 |   0.249298  |    0.042206     |   0\n",
      "       5906 |   0.338461  |    0.104747     |   1\n",
      "       5907 |   0.291761  |    0.100561     |   1\n",
      "       5908 |   0.000113  |    0.013018     |   2\n",
      "       5909 |   0.241251  |    0.142416     |   1\n",
      "       5910 |   0.284343  |    0.007930     |   0\n",
      "       5911 |   0.006977  |    0.011965     |   2\n",
      "       5912 |   0.115594  |    0.019119     |   2\n",
      "       5913 |   0.380725  |    0.131066     |   1\n",
      "       5914 |   0.276642  |    0.076135     |   1\n",
      "       5915 |   0.055302  |    0.006930     |   2\n",
      "       5916 |   0.077483  |    0.024225     |   2\n",
      "       5917 |   0.219426  |    0.045152     |   0\n",
      "       5918 |   0.247757  |    0.028760     |   0\n",
      "       5919 |   0.190849  |    0.036793     |   0\n",
      "       5920 |   0.184212  |    0.096219     |   1\n",
      "       5921 |   0.066653  |    0.016394     |   2\n",
      "       5922 |   0.241089  |    0.143265     |   1\n",
      "       5923 |   0.028781  |    0.010448     |   2\n",
      "       5924 |   0.260491  |    0.098526     |   1\n",
      "       5925 |   0.256774  |    0.088198     |   1\n",
      "       5926 |   0.068627  |    0.004299     |   2\n",
      "       5927 |   0.229070  |    0.156868     |   1\n",
      "       5928 |   0.274859  |    0.055407     |   1\n",
      "       5929 |   0.210429  |    0.020131     |   0\n",
      "       5930 |   0.055682  |    0.043938     |   2\n",
      "       5931 |   0.245134  |    0.013776     |   0\n",
      "       5932 |   0.000111  |    0.048035     |   2\n",
      "       5933 |   0.000112  |    0.018233     |   2\n",
      "       5934 |   0.272801  |    0.154050     |   1\n",
      "       5935 |   0.268720  |    0.018894     |   0\n",
      "       5936 |   0.194435  |    0.082441     |   1\n",
      "       5937 |   0.399198  |    0.079150     |   1\n",
      "       5938 |   0.273061  |    0.029161     |   0\n",
      "       5939 |   0.181987  |    0.159085     |   1\n",
      "       5940 |   0.247821  |    0.068016     |   1\n",
      "       5941 |   0.277559  |    0.097770     |   1\n",
      "       5942 |   0.286962  |    0.088695     |   1\n",
      "       5943 |   0.238475  |    0.014839     |   0\n",
      "       5944 |   0.214496  |    0.025334     |   0\n",
      "       5945 |   0.000123  |    0.041386     |   2\n",
      "       5946 |   0.342100  |    0.106191     |   1\n",
      "       5947 |   0.360567  |    0.086814     |   1\n",
      "       5948 |   0.283843  |    0.096123     |   1\n",
      "       5949 |   0.222782  |    0.008882     |   0\n",
      "       5950 |   0.000120  |    0.007168     |   2\n",
      "       5951 |   0.000117  |    0.047539     |   2\n",
      "       5952 |   0.000127  |    0.008111     |   2\n",
      "       5953 |   0.077526  |    0.038843     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 5955: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       5954 |   0.075538  |    0.010783     |   2\n",
      "       5955 |   0.329942  |    0.142571     |   1\n",
      "       5956 |   0.077202  |    0.003144     |   2\n",
      "       5957 |   0.060924  |    0.010583     |   2\n",
      "       5958 |   0.251517  |    0.145182     |   1\n",
      "       5959 |   0.060197  |    0.005218     |   2\n",
      "       5960 |   0.224654  |    0.029300     |   0\n",
      "       5961 |   0.085261  |    0.029083     |   2\n",
      "       5962 |   0.298838  |    0.028269     |   0\n",
      "       5963 |   0.221999  |    0.148758     |   1\n",
      "       5964 |   0.039374  |    0.013043     |   2\n",
      "       5965 |   0.331099  |    0.087231     |   1\n",
      "       5966 |   0.233776  |    0.137095     |   1\n",
      "       5967 |   0.280931  |    0.019474     |   0\n",
      "       5968 |   0.261995  |    0.047429     |   1\n",
      "       5969 |   0.231460  |    0.079978     |   1\n",
      "       5970 |   0.063759  |    0.012005     |   2\n",
      "       5971 |   0.074136  |    0.040481     |   2\n",
      "       5972 |   0.199220  |    0.103593     |   1\n",
      "       5973 |   0.294619  |    0.092226     |   1\n",
      "       5974 |   0.363270  |    0.080920     |   1\n",
      "       5975 |   0.248109  |    0.006348     |   0\n",
      "       5976 |   0.079709  |    0.007488     |   2\n",
      "       5977 |   0.275597  |    0.145501     |   1\n",
      "       5978 |   0.230502  |    0.002891     |   0\n",
      "       5979 |   0.080718  |    0.030234     |   2\n",
      "       5980 |   0.229530  |    0.144385     |   1\n",
      "       5981 |   0.310159  |    0.023951     |   1\n",
      "       5982 |   0.038726  |    0.028467     |   2\n",
      "       5983 |   0.233562  |    0.030668     |   0\n",
      "       5984 |   0.000112  |    0.022100     |   2\n",
      "       5985 |   0.272399  |    0.143360     |   1\n",
      "       5986 |   0.212106  |    0.101107     |   1\n",
      "       5987 |   0.247448  |    0.056825     |   1\n",
      "       5988 |   0.226579  |    0.087674     |   1\n",
      "       5989 |   0.197884  |    0.143824     |   1\n",
      "       5990 |   0.008190  |    0.014708     |   2\n",
      "       5991 |   0.300595  |    0.058455     |   1\n",
      "       5992 |   0.280474  |    0.088323     |   1\n",
      "       5993 |   0.280056  |    0.091760     |   1\n",
      "       5994 |   0.114221  |    0.011493     |   2\n",
      "       5995 |   0.198660  |    0.034104     |   0\n",
      "       5996 |   0.296455  |    0.028564     |   0\n",
      "       5997 |   0.053053  |    0.031003     |   2\n",
      "       5998 |   0.255436  |    0.036164     |   0\n",
      "       5999 |   0.271683  |    0.091447     |   1\n",
      "       6000 |   0.232150  |    0.101764     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 6000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 6000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       6001 |   0.285226  |    0.163329     |   1\n",
      "       6002 |   0.075395  |    0.007650     |   2\n",
      "       6003 |   0.256780  |    0.121974     |   1\n",
      "       6004 |   0.236472  |    0.060616     |   0\n",
      "       6005 |   0.255134  |    0.088259     |   1\n",
      "       6006 |   0.201213  |    0.037577     |   0\n",
      "       6007 |   0.266798  |    0.140057     |   1\n",
      "       6008 |   0.060768  |    0.002921     |   2\n",
      "       6009 |   0.060300  |    0.027038     |   2\n",
      "       6010 |   0.082248  |    0.037723     |   2\n",
      "       6011 |   0.235509  |    0.149267     |   1\n",
      "       6012 |   0.267766  |    0.044546     |   1\n",
      "       6013 |   0.039431  |    0.036349     |   2\n",
      "       6014 |   0.301856  |    0.017440     |   0\n",
      "       6015 |   0.251333  |    0.025829     |   0\n",
      "       6016 |   0.206388  |    0.045439     |   0\n",
      "       6017 |   0.064542  |    0.013035     |   2\n",
      "       6018 |   0.218119  |    0.048290     |   0\n",
      "       6019 |   0.182938  |    0.023192     |   0\n",
      "       6020 |   0.242747  |    0.140644     |   1\n",
      "       6021 |   0.225363  |    0.060643     |   1\n",
      "       6022 |   0.299728  |    0.048487     |   0\n",
      "       6023 |   0.070185  |    0.012377     |   2\n",
      "       6024 |   0.079635  |    0.041873     |   2\n",
      "       6025 |   0.074685  |    0.007988     |   2\n",
      "       6026 |   0.202188  |    0.046524     |   0\n",
      "       6027 |   0.035722  |    0.026268     |   2\n",
      "       6028 |   0.291433  |    0.142436     |   1\n",
      "       6029 |   0.249339  |    0.091962     |   1\n",
      "       6030 |   0.218117  |    0.017178     |   0\n",
      "       6031 |   0.322159  |    0.067047     |   1\n",
      "       6032 |   0.231917  |    0.085769     |   1\n",
      "       6033 |   0.252145  |    0.035928     |   0\n",
      "       6034 |   0.285150  |    0.079755     |   1\n",
      "       6035 |   0.265451  |    0.018068     |   0\n",
      "       6036 |   0.245384  |    0.126241     |   1\n",
      "       6037 |   0.000112  |    0.010282     |   2\n",
      "       6038 |   0.270221  |    0.043715     |   0\n",
      "       6039 |   0.269125  |    0.095161     |   1\n",
      "       6040 |   0.189224  |    0.032308     |   0\n",
      "       6041 |   0.008219  |    0.056201     |   2\n",
      "       6042 |   0.116315  |    0.006732     |   2\n",
      "       6043 |   0.055444  |    0.043662     |   2\n",
      "       6044 |   0.075908  |    0.012157     |   2\n",
      "       6045 |   0.069082  |    0.042459     |   2\n",
      "       6046 |   0.027991  |    0.035585     |   2\n",
      "       6047 |   0.203842  |    0.160376     |   1\n",
      "       6048 |   0.274637  |    0.003675     |   0\n",
      "       6049 |   0.218692  |    0.059223     |   1\n",
      "       6050 |   0.063749  |    0.013538     |   2\n",
      "       6051 |   0.303904  |    0.141231     |   1\n",
      "       6052 |   0.274403  |    0.061786     |   1\n",
      "       6053 |   0.225218  |    0.014437     |   0\n",
      "       6054 |   0.239242  |    0.047225     |   0\n",
      "       6055 |   0.053831  |    0.006257     |   2\n",
      "       6056 |   0.240001  |    0.051762     |   0\n",
      "       6057 |   0.000110  |    0.035660     |   2\n",
      "       6058 |   0.238898  |    0.155485     |   1\n",
      "       6059 |   0.000111  |    0.006679     |   2\n",
      "       6060 |   0.296384  |    0.060580     |   1\n",
      "       6061 |   0.241772  |    0.093775     |   1\n",
      "       6062 |   0.000122  |    0.004329     |   2\n",
      "       6063 |   0.332085  |    0.042122     |   0\n",
      "       6064 |   0.292114  |    0.039168     |   0\n",
      "       6065 |   0.216411  |    0.016051     |   0\n",
      "       6066 |   0.000118  |    0.016578     |   2\n",
      "       6067 |   0.299587  |    0.102068     |   1\n",
      "       6068 |   0.212912  |    0.042669     |   0\n",
      "       6069 |   0.000115  |    0.009042     |   2\n",
      "       6070 |   0.000120  |    0.047755     |   2\n",
      "       6071 |   0.082743  |    0.011945     |   2\n",
      "       6072 |   0.251789  |    0.032053     |   0\n",
      "       6073 |   0.194547  |    0.020218     |   0\n",
      "       6074 |   0.076107  |    0.036191     |   2\n",
      "       6075 |   0.231212  |    0.140739     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 6078: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       6076 |   0.291405  |    0.002912     |   0\n",
      "       6077 |   0.198362  |    0.017024     |   0\n",
      "       6078 |   0.078950  |    0.020975     |   2\n",
      "       6079 |   0.238239  |    0.111967     |   1\n",
      "       6080 |   0.254184  |    0.086205     |   1\n",
      "       6081 |   0.282039  |    0.084594     |   1\n",
      "       6082 |   0.061356  |    0.012659     |   2\n",
      "       6083 |   0.293873  |    0.156024     |   1\n",
      "       6084 |   0.246400  |    0.052023     |   1\n",
      "       6085 |   0.061448  |    0.017437     |   2\n",
      "       6086 |   0.084579  |    0.023600     |   2\n",
      "       6087 |   0.039040  |    0.027114     |   2\n",
      "       6088 |   0.064095  |    0.029663     |   2\n",
      "       6089 |   0.290107  |    0.091096     |   1\n",
      "       6090 |   0.206528  |    0.022124     |   0\n",
      "       6091 |   0.216533  |    0.031887     |   0\n",
      "       6092 |   0.072523  |    0.011339     |   2\n",
      "       6093 |   0.251622  |    0.046574     |   0\n",
      "       6094 |   0.080948  |    0.008251     |   2\n",
      "       6095 |   0.073834  |    0.049073     |   2\n",
      "       6096 |   0.232964  |    0.117971     |   1\n",
      "       6097 |   0.289148  |    0.083115     |   1\n",
      "       6098 |   0.313230  |    0.083008     |   1\n",
      "       6099 |   0.254981  |    0.006535     |   0\n",
      "       6100 |   0.205697  |    0.028851     |   0\n",
      "       6101 |   0.232687  |    0.021228     |   0\n",
      "       6102 |   0.232205  |    0.046585     |   0\n",
      "       6103 |   0.265550  |    0.097686     |   1\n",
      "       6104 |   0.034543  |    0.003449     |   2\n",
      "       6105 |   0.189796  |    0.049643     |   0\n",
      "       6106 |   0.273510  |    0.092099     |   1\n",
      "       6107 |   0.276369  |    0.014598     |   0\n",
      "       6108 |   0.252557  |    0.050635     |   0\n",
      "       6109 |   0.253940  |    0.092624     |   1\n",
      "       6110 |   0.345054  |    0.102163     |   1\n",
      "       6111 |   0.322366  |    0.005262     |   0\n",
      "       6112 |   0.000110  |    0.010190     |   2\n",
      "       6113 |   0.007113  |    0.044249     |   2\n",
      "       6114 |   0.115972  |    0.012321     |   2\n",
      "       6115 |   0.056985  |    0.033317     |   2\n",
      "       6116 |   0.274803  |    0.135492     |   1\n",
      "       6117 |   0.079966  |    0.009549     |   2\n",
      "       6118 |   0.311033  |    0.096379     |   1\n",
      "       6119 |   0.065466  |    0.015678     |   2\n",
      "       6120 |   0.210059  |    0.162363     |   1\n",
      "       6121 |   0.233396  |    0.009587     |   0\n",
      "       6122 |   0.261954  |    0.089005     |   1\n",
      "       6123 |   0.229388  |    0.082206     |   1\n",
      "       6124 |   0.030097  |    0.027469     |   2\n",
      "       6125 |   0.209367  |    0.149276     |   1\n",
      "       6126 |   0.228728  |    0.053576     |   1\n",
      "       6127 |   0.279197  |    0.020108     |   0\n",
      "       6128 |   0.301918  |    0.157105     |   1\n",
      "       6129 |   0.278374  |    0.047495     |   1\n",
      "       6130 |   0.308452  |    0.029812     |   0\n",
      "       6131 |   0.228281  |    0.129739     |   1\n",
      "       6132 |   0.242061  |    0.011227     |   0\n",
      "       6133 |   0.068725  |    0.037953     |   2\n",
      "       6134 |   0.052150  |    0.017576     |   2\n",
      "       6135 |   0.000109  |    0.019260     |   2\n",
      "       6136 |   0.000110  |    0.018921     |   2\n",
      "       6137 |   0.000122  |    0.041805     |   2\n",
      "       6138 |   0.000116  |    0.009696     |   2\n",
      "       6139 |   0.278238  |    0.044455     |   0\n",
      "       6140 |   0.165038  |    0.010739     |   0\n",
      "       6141 |   0.242702  |    0.138609     |   1\n",
      "       6142 |   0.000114  |    0.015156     |   2\n",
      "       6143 |   0.294935  |    0.147613     |   1\n",
      "       6144 |   0.000119  |    0.005591     |   2\n",
      "       6145 |   0.235761  |    0.104700     |   1\n",
      "       6146 |   0.202646  |    0.089235     |   1\n",
      "       6147 |   0.255536  |    0.101353     |   1\n",
      "       6148 |   0.230450  |    0.080915     |   1\n",
      "       6149 |   0.076996  |    0.014559     |   2\n",
      "       6150 |   0.242136  |    0.058209     |   0\n",
      "       6151 |   0.250150  |    0.089341     |   1\n",
      "       6152 |   0.075022  |    0.022454     |   2\n",
      "       6153 |   0.284541  |    0.092476     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 6154: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       6154 |   0.230086  |    0.028254     |   0\n",
      "       6155 |   0.182595  |    0.029449     |   0\n",
      "       6156 |   0.224953  |    0.021458     |   0\n",
      "       6157 |   0.077324  |    0.022037     |   2\n",
      "       6158 |   0.277532  |    0.030504     |   0\n",
      "       6159 |   0.062537  |    0.036514     |   2\n",
      "       6160 |   0.219132  |    0.147677     |   1\n",
      "       6161 |   0.061597  |    0.004503     |   2\n",
      "       6162 |   0.083923  |    0.008713     |   2\n",
      "       6163 |   0.263300  |    0.148581     |   1\n",
      "       6164 |   0.257384  |    0.053614     |   1\n",
      "       6165 |   0.320219  |    0.095935     |   1\n",
      "       6166 |   0.222208  |    0.076257     |   1\n",
      "       6167 |   0.039657  |    0.015720     |   2\n",
      "       6168 |   0.270792  |    0.139995     |   1\n",
      "       6169 |   0.064210  |    0.009939     |   2\n",
      "       6170 |   0.309813  |    0.090628     |   1\n",
      "       6171 |   0.072825  |    0.025684     |   2\n",
      "       6172 |   0.265171  |    0.048791     |   0\n",
      "       6173 |   0.288874  |    0.085693     |   1\n",
      "       6174 |   0.213232  |    0.015129     |   0\n",
      "       6175 |   0.229202  |    0.144263     |   1\n",
      "       6176 |   0.270211  |    0.099787     |   1\n",
      "       6177 |   0.199336  |    0.089659     |   1\n",
      "       6178 |   0.083696  |    0.015230     |   2\n",
      "       6179 |   0.228518  |    0.126062     |   1\n",
      "       6180 |   0.246495  |    0.011424     |   0\n",
      "       6181 |   0.241863  |    0.078257     |   1\n",
      "       6182 |   0.074917  |    0.015360     |   2\n",
      "       6183 |   0.208363  |    0.042667     |   0\n",
      "       6184 |   0.245534  |    0.014295     |   0\n",
      "       6185 |   0.035240  |    0.064255     |   2\n",
      "       6186 |   0.297565  |    0.089118     |   1\n",
      "       6187 |   0.000110  |    0.014165     |   2\n",
      "       6188 |   0.212905  |    0.136769     |   1\n",
      "       6189 |   0.007074  |    0.002818     |   2\n",
      "       6190 |   0.262560  |    0.011044     |   0\n",
      "       6191 |   0.249641  |    0.024265     |   0\n",
      "       6192 |   0.259380  |    0.138856     |   1\n",
      "       6193 |   0.218460  |    0.004798     |   0\n",
      "       6194 |   0.246758  |    0.016225     |   0\n",
      "       6195 |   0.115945  |    0.030013     |   2\n",
      "       6196 |   0.302144  |    0.075057     |   1\n",
      "       6197 |   0.199402  |    0.028583     |   0\n",
      "       6198 |   0.310813  |    0.130453     |   1\n",
      "       6199 |   0.175777  |    0.008140     |   0\n",
      "       6200 |   0.229456  |    0.020939     |   0\n",
      "       6201 |   0.253171  |    0.159017     |   1\n",
      "       6202 |   0.053695  |    0.002865     |   2\n",
      "       6203 |   0.079497  |    0.012805     |   2\n",
      "       6204 |   0.286599  |    0.090664     |   1\n",
      "       6205 |   0.281508  |    0.147700     |   1\n",
      "       6206 |   0.065458  |    0.004984     |   2\n",
      "       6207 |   0.264346  |    0.099142     |   1\n",
      "       6208 |   0.297830  |    0.084955     |   1\n",
      "       6209 |   0.028376  |    0.003336     |   2\n",
      "       6210 |   0.205976  |    0.032421     |   0\n",
      "       6211 |   0.267540  |    0.146863     |   1\n",
      "       6212 |   0.221642  |    0.009776     |   0\n",
      "       6213 |   0.287931  |    0.064926     |   1\n",
      "       6214 |   0.275755  |    0.028282     |   0\n",
      "       6215 |   0.199785  |    0.093078     |   1\n",
      "       6216 |   0.066704  |    0.008127     |   2\n",
      "       6217 |   0.052172  |    0.045859     |   2\n",
      "       6218 |   0.000108  |    0.014135     |   2\n",
      "       6219 |   0.247409  |    0.040892     |   0\n",
      "       6220 |   0.337720  |    0.020253     |   0\n",
      "       6221 |   0.271575  |    0.142360     |   1\n",
      "       6222 |   0.000108  |    0.010964     |   2\n",
      "       6223 |   0.287171  |    0.055528     |   1\n",
      "       6224 |   0.000119  |    0.024018     |   2\n",
      "       6225 |   0.241427  |    0.141920     |   1\n",
      "       6226 |   0.000114  |    0.015979     |   2\n",
      "       6227 |   0.241778  |    0.076519     |   1\n",
      "       6228 |   0.227495  |    0.088241     |   1\n",
      "       6229 |   0.239653  |    0.012491     |   0\n",
      "       6230 |   0.000112  |    0.016740     |   2\n",
      "       6231 |   0.264909  |    0.041493     |   0\n",
      "       6232 |   0.215250  |    0.010017     |   0\n",
      "       6233 |   0.228677  |    0.050841     |   0\n",
      "       6234 |   0.202652  |    0.009668     |   0\n",
      "       6235 |   0.205054  |    0.141790     |   1\n",
      "       6236 |   0.268674  |    0.012447     |   0\n",
      "       6237 |   0.256172  |    0.139720     |   1\n",
      "       6238 |   0.236556  |    0.088919     |   1\n",
      "       6239 |   0.000114  |    0.004358     |   2\n",
      "       6240 |   0.229828  |    0.109429     |   1\n",
      "       6241 |   0.279785  |    0.132620     |   1\n",
      "       6242 |   0.228891  |    0.005602     |   0\n",
      "       6243 |   0.076373  |    0.007785     |   2\n",
      "       6244 |   0.202473  |    0.050951     |   0\n",
      "       6245 |   0.316943  |    0.134356     |   1\n",
      "       6246 |   0.212087  |    0.008205     |   0\n",
      "       6247 |   0.162037  |    0.158192     |   1\n",
      "       6248 |   0.199615  |    0.004112     |   0\n",
      "       6249 |   0.073031  |    0.009761     |   2\n",
      "       6250 |   0.220041  |    0.041727     |   0\n",
      "       6251 |   0.205295  |    0.104485     |   1\n",
      "       6252 |   0.265445  |    0.020479     |   0\n",
      "       6253 |   0.247661  |    0.099507     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 6255: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       6254 |   0.219127  |    0.016599     |   0\n",
      "       6255 |   0.190599  |    0.091505     |   1\n",
      "       6256 |   0.220168  |    0.005238     |   0\n",
      "       6257 |   0.285301  |    0.098165     |   1\n",
      "       6258 |   0.290754  |    0.145688     |   1\n",
      "       6259 |   0.227857  |    0.003226     |   0\n",
      "       6260 |   0.079433  |    0.016563     |   2\n",
      "       6261 |   0.222824  |    0.146295     |   1\n",
      "       6262 |   0.235518  |    0.006497     |   0\n",
      "       6263 |   0.208377  |    0.150822     |   1\n",
      "       6264 |   0.061596  |    0.007845     |   2\n",
      "       6265 |   0.156168  |    0.096406     |   1\n",
      "       6266 |   0.256598  |    0.089140     |   1\n",
      "       6267 |   0.226849  |    0.091040     |   1\n",
      "       6268 |   0.213994  |    0.016176     |   0\n",
      "       6269 |   0.256991  |    0.092813     |   1\n",
      "       6270 |   0.204812  |    0.016492     |   0\n",
      "       6271 |   0.060948  |    0.034330     |   2\n",
      "       6272 |   0.085106  |    0.030667     |   2\n",
      "       6273 |   0.040027  |    0.024422     |   2\n",
      "       6274 |   0.240096  |    0.048270     |   0\n",
      "       6275 |   0.246986  |    0.088369     |   1\n",
      "       6276 |   0.239974  |    0.145862     |   1\n",
      "       6277 |   0.284244  |    0.014619     |   1\n",
      "       6278 |   0.271981  |    0.144659     |   1\n",
      "       6279 |   0.283537  |    0.003263     |   0\n",
      "       6280 |   0.061639  |    0.008309     |   2\n",
      "       6281 |   0.268789  |    0.143113     |   1\n",
      "       6282 |   0.226633  |    0.002858     |   0\n",
      "       6283 |   0.250985  |    0.008464     |   0\n",
      "       6284 |   0.070398  |    0.051550     |   2\n",
      "       6285 |   0.215657  |    0.139684     |   1\n",
      "       6286 |   0.227609  |    0.049698     |   1\n",
      "       6287 |   0.292642  |    0.039123     |   0\n",
      "       6288 |   0.078892  |    0.013635     |   2\n",
      "       6289 |   0.305735  |    0.137197     |   1\n",
      "       6290 |   0.265447  |    0.048247     |   1\n",
      "       6291 |   0.274452  |    0.041134     |   0\n",
      "       6292 |   0.252808  |    0.137682     |   1\n",
      "       6293 |   0.222223  |    0.003092     |   0\n",
      "       6294 |   0.239859  |    0.012140     |   0\n",
      "       6295 |   0.289450  |    0.146547     |   1\n",
      "       6296 |   0.255605  |    0.005567     |   0\n",
      "       6297 |   0.237824  |    0.007618     |   0\n",
      "       6298 |   0.213566  |    0.043828     |   0\n",
      "       6299 |   0.235690  |    0.022490     |   0\n",
      "       6300 |   0.334965  |    0.152660     |   1\n",
      "       6301 |   0.211976  |    0.054120     |   1\n",
      "       6302 |   0.073621  |    0.023454     |   2\n",
      "       6303 |   0.034893  |    0.033507     |   2\n",
      "       6304 |   0.000109  |    0.026843     |   2\n",
      "       6305 |   0.008423  |    0.028696     |   2\n",
      "       6306 |   0.276215  |    0.136900     |   1\n",
      "       6307 |   0.277224  |    0.005973     |   0\n",
      "       6308 |   0.117039  |    0.018287     |   2\n",
      "       6309 |   0.054412  |    0.027506     |   2\n",
      "       6310 |   0.237292  |    0.156921     |   1\n",
      "       6311 |   0.079599  |    0.010252     |   2\n",
      "       6312 |   0.280390  |    0.052945     |   1\n",
      "       6313 |   0.201791  |    0.047609     |   0\n",
      "       6314 |   0.068215  |    0.019590     |   2\n",
      "       6315 |   0.241116  |    0.092502     |   1\n",
      "       6316 |   0.261040  |    0.035131     |   0\n",
      "       6317 |   0.240167  |    0.084801     |   1\n",
      "       6318 |   0.299366  |    0.042563     |   0\n",
      "       6319 |   0.028542  |    0.009055     |   2\n",
      "       6320 |   0.065082  |    0.033523     |   2\n",
      "       6321 |   0.050556  |    0.020575     |   2\n",
      "       6322 |   0.278280  |    0.138964     |   1\n",
      "       6323 |   0.223303  |    0.005471     |   0\n",
      "       6324 |   0.219988  |    0.031024     |   0\n",
      "       6325 |   0.196394  |    0.159587     |   1\n",
      "       6326 |   0.284976  |    0.014448     |   0\n",
      "       6327 |   0.228550  |    0.089193     |   1\n",
      "       6328 |   0.000105  |    0.012208     |   2\n",
      "       6329 |   0.000106  |    0.033335     |   2\n",
      "       6330 |   0.000117  |    0.017771     |   2\n",
      "       6331 |   0.267619  |    0.049148     |   0\n",
      "       6332 |   0.303233  |    0.102179     |   1\n",
      "       6333 |   0.303261  |    0.084019     |   1\n",
      "       6334 |   0.191028  |    0.078717     |   1\n",
      "       6335 |   0.249794  |    0.012279     |   0\n",
      "       6336 |   0.236844  |    0.049086     |   0\n",
      "       6337 |   0.348785  |    0.086221     |   1\n",
      "       6338 |   0.000113  |    0.014410     |   2\n",
      "       6339 |   0.000109  |    0.054317     |   2\n",
      "       6340 |   0.000114  |    0.010295     |   2\n",
      "       6341 |   0.249056  |    0.135423     |   1\n",
      "       6342 |   0.261475  |    0.006398     |   0\n",
      "       6343 |   0.080063  |    0.052847     |   2\n",
      "       6344 |   0.309887  |    0.086078     |   1\n",
      "       6345 |   0.237896  |    0.026909     |   0\n",
      "       6346 |   0.222172  |    0.158430     |   1\n",
      "       6347 |   0.302441  |    0.003406     |   0\n",
      "       6348 |   0.252424  |    0.015569     |   0\n",
      "       6349 |   0.073034  |    0.033920     |   2\n",
      "       6350 |   0.227827  |    0.030519     |   0\n",
      "       6351 |   0.189251  |    0.043320     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 6352: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       6352 |   0.228204  |    0.085278     |   1\n",
      "       6353 |   0.230808  |    0.098507     |   1\n",
      "       6354 |   0.227123  |    0.051834     |   1\n",
      "       6355 |   0.247667  |    0.027153     |   0\n",
      "       6356 |   0.332594  |    0.144126     |   1\n",
      "       6357 |   0.238695  |    0.005362     |   0\n",
      "       6358 |   0.085662  |    0.015109     |   2\n",
      "       6359 |   0.181199  |    0.145576     |   1\n",
      "       6360 |   0.280195  |    0.084995     |   1\n",
      "       6361 |   0.068828  |    0.014916     |   2\n",
      "       6362 |   0.061153  |    0.034723     |   2\n",
      "       6363 |   0.277618  |    0.122684     |   1\n",
      "       6364 |   0.082286  |    0.008070     |   2\n",
      "       6365 |   0.219293  |    0.029567     |   0\n",
      "       6366 |   0.261468  |    0.033441     |   0\n",
      "       6367 |   0.236757  |    0.086481     |   1\n",
      "       6368 |   0.038650  |    0.026958     |   2\n",
      "       6369 |   0.249198  |    0.023560     |   0\n",
      "       6370 |   0.243311  |    0.041062     |   0\n",
      "       6371 |   0.289019  |    0.095755     |   1\n",
      "       6372 |   0.176674  |    0.017144     |   0\n",
      "       6373 |   0.261693  |    0.146385     |   1\n",
      "       6374 |   0.063800  |    0.006899     |   2\n",
      "       6375 |   0.200609  |    0.052514     |   1\n",
      "       6376 |   0.192168  |    0.011353     |   0\n",
      "       6377 |   0.075008  |    0.053194     |   2\n",
      "       6378 |   0.081642  |    0.008766     |   2\n",
      "       6379 |   0.076021  |    0.040372     |   2\n",
      "       6380 |   0.204683  |    0.019699     |   0\n",
      "       6381 |   0.034418  |    0.034218     |   2\n",
      "       6382 |   0.269692  |    0.091799     |   1\n",
      "       6383 |   0.259143  |    0.083788     |   1\n",
      "       6384 |   0.190828  |    0.008814     |   0\n",
      "       6385 |   0.250907  |    0.040056     |   0\n",
      "       6386 |   0.193830  |    0.024349     |   0\n",
      "       6387 |   0.295459  |    0.160686     |   1\n",
      "       6388 |   0.000106  |    0.014007     |   2\n",
      "       6389 |   0.145186  |    0.094882     |   1\n",
      "       6390 |   0.208942  |    0.056400     |   1\n",
      "       6391 |   0.264133  |    0.016775     |   0\n",
      "       6392 |   0.215235  |    0.165314     |   1\n",
      "       6393 |   0.312789  |    0.049703     |   1\n",
      "       6394 |   0.259078  |    0.039187     |   0\n",
      "       6395 |   0.240568  |    0.085023     |   1\n",
      "       6396 |   0.258072  |    0.027016     |   0\n",
      "       6397 |   0.007680  |    0.030099     |   2\n",
      "       6398 |   0.257114  |    0.016181     |   0\n",
      "       6399 |   0.114685  |    0.047481     |   2\n",
      "       6400 |   0.169825  |    0.151341     |   1\n",
      "       6401 |   0.243860  |    0.041137     |   1\n",
      "       6402 |   0.202296  |    0.024178     |   0\n",
      "       6403 |   0.263208  |    0.041747     |   0\n",
      "       6404 |   0.184585  |    0.025332     |   0\n",
      "       6405 |   0.054325  |    0.046126     |   2\n",
      "       6406 |   0.073891  |    0.017440     |   2\n",
      "       6407 |   0.070566  |    0.034511     |   2\n",
      "       6408 |   0.210041  |    0.139879     |   1\n",
      "       6409 |   0.030245  |    0.007482     |   2\n",
      "       6410 |   0.223906  |    0.047052     |   0\n",
      "       6411 |   0.216963  |    0.131205     |   1\n",
      "       6412 |   0.067698  |    0.012449     |   2\n",
      "       6413 |   0.165012  |    0.098628     |   1\n",
      "       6414 |   0.051157  |    0.026250     |   2\n",
      "       6415 |   0.237475  |    0.032591     |   0\n",
      "       6416 |   0.228971  |    0.013964     |   0\n",
      "       6417 |   0.215057  |    0.043035     |   0\n",
      "       6418 |   0.000105  |    0.007038     |   2\n",
      "       6419 |   0.240453  |    0.040528     |   0\n",
      "       6420 |   0.240416  |    0.031196     |   0\n",
      "       6421 |   0.000105  |    0.021052     |   2\n",
      "       6422 |   0.262798  |    0.148340     |   1\n",
      "       6423 |   0.000116  |    0.010809     |   2\n",
      "       6424 |   0.000110  |    0.016390     |   2\n",
      "       6425 |   0.256488  |    0.100840     |   1\n",
      "       6426 |   0.203511  |    0.006341     |   0\n",
      "       6427 |   0.199406  |    0.049430     |   0\n",
      "       6428 |   0.000108  |    0.008633     |   2\n",
      "       6429 |   0.000112  |    0.047876     |   2\n",
      "       6430 |   0.195351  |    0.079475     |   1\n",
      "       6431 |   0.211343  |    0.028722     |   0\n",
      "       6432 |   0.197567  |    0.061001     |   0\n",
      "       6433 |   0.238219  |    0.079124     |   1\n",
      "       6434 |   0.208580  |    0.143730     |   1\n",
      "       6435 |   0.292538  |    0.068521     |   1\n",
      "       6436 |   0.256449  |    0.083428     |   1\n",
      "       6437 |   0.235547  |    0.017778     |   0\n",
      "       6438 |   0.318038  |    0.131390     |   1\n",
      "       6439 |   0.282598  |    0.093853     |   1\n",
      "       6440 |   0.282673  |    0.007043     |   0\n",
      "       6441 |   0.077058  |    0.038638     |   2\n",
      "       6442 |   0.213590  |    0.133115     |   1\n",
      "       6443 |   0.317992  |    0.058450     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 6445: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       6444 |   0.074108  |    0.012067     |   2\n",
      "       6445 |   0.221971  |    0.045209     |   0\n",
      "       6446 |   0.241810  |    0.008611     |   0\n",
      "       6447 |   0.197902  |    0.049129     |   0\n",
      "       6448 |   0.228095  |    0.021084     |   0\n",
      "       6449 |   0.201023  |    0.157245     |   1\n",
      "       6450 |   0.262269  |    0.039126     |   1\n",
      "       6451 |   0.081387  |    0.020125     |   2\n",
      "       6452 |   0.061909  |    0.016379     |   2\n",
      "       6453 |   0.260874  |    0.044975     |   0\n",
      "       6454 |   0.253065  |    0.023991     |   0\n",
      "       6455 |   0.250516  |    0.092764     |   1\n",
      "       6456 |   0.061225  |    0.026559     |   2\n",
      "       6457 |   0.211264  |    0.028950     |   0\n",
      "       6458 |   0.081008  |    0.008613     |   2\n",
      "       6459 |   0.236087  |    0.036456     |   0\n",
      "       6460 |   0.197427  |    0.091205     |   1\n",
      "       6461 |   0.199219  |    0.111823     |   1\n",
      "       6462 |   0.212873  |    0.080213     |   1\n",
      "       6463 |   0.258053  |    0.021936     |   0\n",
      "       6464 |   0.038611  |    0.027332     |   2\n",
      "       6465 |   0.210809  |    0.040884     |   0\n",
      "       6466 |   0.268569  |    0.087746     |   1\n",
      "       6467 |   0.224940  |    0.030755     |   0\n",
      "       6468 |   0.062932  |    0.032709     |   2\n",
      "       6469 |   0.193039  |    0.023295     |   0\n",
      "       6470 |   0.321719  |    0.140125     |   1\n",
      "       6471 |   0.249245  |    0.060548     |   1\n",
      "       6472 |   0.073061  |    0.008618     |   2\n",
      "       6473 |   0.082904  |    0.049527     |   2\n",
      "       6474 |   0.280386  |    0.084513     |   1\n",
      "       6475 |   0.073984  |    0.018977     |   2\n",
      "       6476 |   0.036407  |    0.032146     |   2\n",
      "       6477 |   0.246633  |    0.032603     |   0\n",
      "       6478 |   0.228143  |    0.143753     |   1\n",
      "       6479 |   0.000106  |    0.003032     |   2\n",
      "       6480 |   0.007129  |    0.005377     |   2\n",
      "       6481 |   0.237950  |    0.066093     |   0\n",
      "       6482 |   0.236187  |    0.053670     |   1\n",
      "       6483 |   0.183364  |    0.031554     |   0\n",
      "       6484 |   0.305104  |    0.092362     |   1\n",
      "       6485 |   0.115570  |    0.029222     |   2\n",
      "       6486 |   0.259780  |    0.094864     |   1\n",
      "       6487 |   0.241151  |    0.105963     |   1\n",
      "       6488 |   0.201099  |    0.009708     |   0\n",
      "       6489 |   0.228564  |    0.030265     |   0\n",
      "       6490 |   0.237285  |    0.141149     |   1\n",
      "       6491 |   0.259169  |    0.044699     |   1\n",
      "       6492 |   0.245822  |    0.078412     |   1\n",
      "       6493 |   0.239709  |    0.026231     |   0\n",
      "       6494 |   0.323817  |    0.141072     |   1\n",
      "       6495 |   0.273073  |    0.040847     |   1\n",
      "       6496 |   0.200732  |    0.030349     |   0\n",
      "       6497 |   0.225059  |    0.017447     |   0\n",
      "       6498 |   0.211129  |    0.029984     |   0\n",
      "       6499 |   0.052564  |    0.031165     |   2\n",
      "       6500 |   0.075166  |    0.030619     |   2\n",
      "       6501 |   0.266051  |    0.081336     |   0\n",
      "       6502 |   0.076379  |    0.007183     |   2\n",
      "       6503 |   0.252042  |    0.027121     |   0\n",
      "       6504 |   0.200418  |    0.047431     |   0\n",
      "       6505 |   0.269223  |    0.089290     |   1\n",
      "       6506 |   0.222144  |    0.024357     |   0\n",
      "       6507 |   0.236569  |    0.147764     |   1\n",
      "       6508 |   0.273854  |    0.051189     |   1\n",
      "       6509 |   0.233055  |    0.037234     |   0\n",
      "       6510 |   0.271333  |    0.152044     |   1\n",
      "       6511 |   0.059526  |    0.002821     |   2\n",
      "       6512 |   0.058633  |    0.006936     |   2\n",
      "       6513 |   0.287486  |    0.051857     |   0\n",
      "       6514 |   0.082775  |    0.009979     |   2\n",
      "       6515 |   0.038744  |    0.054970     |   2\n",
      "       6516 |   0.061213  |    0.008109     |   2\n",
      "       6517 |   0.269489  |    0.039953     |   0\n",
      "       6518 |   0.208322  |    0.022947     |   0\n",
      "       6519 |   0.194354  |    0.138864     |   1\n",
      "       6520 |   0.232752  |    0.003550     |   0\n",
      "       6521 |   0.193032  |    0.028952     |   0\n",
      "       6522 |   0.238865  |    0.019056     |   0\n",
      "       6523 |   0.310893  |    0.139924     |   1\n",
      "       6524 |   0.269693  |    0.019516     |   0\n",
      "       6525 |   0.249115  |    0.092777     |   1\n",
      "       6526 |   0.069620  |    0.009279     |   2\n",
      "       6527 |   0.204924  |    0.147775     |   1\n",
      "       6528 |   0.081541  |    0.013098     |   2\n",
      "       6529 |   0.196541  |    0.086537     |   1\n",
      "       6530 |   0.073649  |    0.048463     |   2\n",
      "       6531 |   0.035736  |    0.033350     |   2\n",
      "       6532 |   0.298087  |    0.145569     |   1\n",
      "       6533 |   0.220781  |    0.002956     |   0\n",
      "       6534 |   0.000106  |    0.010846     |   2\n",
      "       6535 |   0.172700  |    0.134079     |   1\n",
      "       6536 |   0.245669  |    0.014040     |   0\n",
      "       6537 |   0.007473  |    0.044893     |   2\n",
      "       6538 |   0.237501  |    0.025683     |   0\n",
      "       6539 |   0.245054  |    0.032461     |   0\n",
      "       6540 |   0.112680  |    0.038504     |   2\n",
      "       6541 |   0.213302  |    0.098828     |   1\n",
      "       6542 |   0.211102  |    0.020634     |   0\n",
      "       6543 |   0.272790  |    0.142749     |   1\n",
      "       6544 |   0.308153  |    0.010706     |   0\n",
      "       6545 |   0.051903  |    0.020334     |   2\n",
      "       6546 |   0.077723  |    0.030766     |   2\n",
      "       6547 |   0.312167  |    0.026925     |   0\n",
      "       6548 |   0.217876  |    0.031357     |   0\n",
      "       6549 |   0.275438  |    0.028581     |   0\n",
      "       6550 |   0.067496  |    0.031186     |   2\n",
      "       6551 |   0.029430  |    0.030245     |   2\n",
      "       6552 |   0.195356  |    0.147609     |   1\n",
      "       6553 |   0.063493  |    0.006874     |   2\n",
      "       6554 |   0.206483  |    0.080257     |   1\n",
      "       6555 |   0.053126  |    0.020131     |   2\n",
      "       6556 |   0.000103  |    0.032317     |   2\n",
      "       6557 |   0.000104  |    0.013811     |   2\n",
      "       6558 |   0.215881  |    0.044188     |   0\n",
      "       6559 |   0.266384  |    0.018626     |   0\n",
      "       6560 |   0.000110  |    0.033433     |   2\n",
      "       6561 |   0.000108  |    0.029679     |   2\n",
      "       6562 |   0.258092  |    0.053011     |   0\n",
      "       6563 |   0.190962  |    0.022591     |   0\n",
      "       6564 |   0.250017  |    0.044782     |   0\n",
      "       6565 |   0.228869  |    0.100429     |   1\n",
      "       6566 |   0.000106  |    0.027788     |   2\n",
      "       6567 |   0.000109  |    0.020958     |   2\n",
      "       6568 |   0.082949  |    0.031852     |   2\n",
      "       6569 |   0.175882  |    0.031166     |   0\n",
      "       6570 |   0.246986  |    0.137215     |   1\n",
      "       6571 |   0.265080  |    0.082716     |   1\n",
      "       6572 |   0.190879  |    0.023088     |   0\n",
      "       6573 |   0.075855  |    0.039497     |   2\n",
      "       6574 |   0.257703  |    0.134058     |   1\n",
      "       6575 |   0.203910  |    0.007427     |   0\n",
      "       6576 |   0.219289  |    0.051384     |   0\n",
      "       6577 |   0.254219  |    0.078833     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 6578: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       6578 |   0.081680  |    0.011589     |   2\n",
      "       6579 |   0.251679  |    0.142662     |   1\n",
      "       6580 |   0.200286  |    0.012529     |   0\n",
      "       6581 |   0.265768  |    0.148673     |   1\n",
      "       6582 |   0.219646  |    0.002907     |   0\n",
      "       6583 |   0.249193  |    0.013267     |   0\n",
      "       6584 |   0.065126  |    0.040944     |   2\n",
      "       6585 |   0.349116  |    0.131884     |   1\n",
      "       6586 |   0.061013  |    0.012926     |   2\n",
      "       6587 |   0.242444  |    0.084863     |   1\n",
      "       6588 |   0.232998  |    0.011306     |   0\n",
      "       6589 |   0.083719  |    0.035636     |   2\n",
      "       6590 |   0.296121  |    0.027851     |   0\n",
      "       6591 |   0.039993  |    0.046852     |   2\n",
      "       6592 |   0.061484  |    0.040704     |   2\n",
      "       6593 |   0.251722  |    0.138510     |   1\n",
      "       6594 |   0.221922  |    0.079985     |   1\n",
      "       6595 |   0.075583  |    0.005084     |   2\n",
      "       6596 |   0.228080  |    0.031570     |   0\n",
      "       6597 |   0.252788  |    0.149416     |   1\n",
      "       6598 |   0.223199  |    0.028671     |   1\n",
      "       6599 |   0.083048  |    0.046972     |   2\n",
      "       6600 |   0.215041  |    0.012041     |   0\n",
      "       6601 |   0.072470  |    0.050673     |   2\n",
      "       6602 |   0.203045  |    0.019138     |   0\n",
      "       6603 |   0.234448  |    0.033217     |   0\n",
      "       6604 |   0.292217  |    0.024562     |   0\n",
      "       6605 |   0.243791  |    0.041663     |   0\n",
      "       6606 |   0.205491  |    0.016738     |   0\n",
      "       6607 |   0.213872  |    0.143217     |   1\n",
      "       6608 |   0.265294  |    0.078582     |   1\n",
      "       6609 |   0.228561  |    0.007927     |   0\n",
      "       6610 |   0.034479  |    0.019758     |   2\n",
      "       6611 |   0.000105  |    0.034077     |   2\n",
      "       6612 |   0.249796  |    0.013194     |   0\n",
      "       6613 |   0.253394  |    0.142145     |   1\n",
      "       6614 |   0.315935  |    0.103324     |   1\n",
      "       6615 |   0.007229  |    0.009402     |   2\n",
      "       6616 |   0.185896  |    0.104366     |   1\n",
      "       6617 |   0.240108  |    0.094197     |   1\n",
      "       6618 |   0.168577  |    0.016201     |   0\n",
      "       6619 |   0.113109  |    0.037711     |   2\n",
      "       6620 |   0.289424  |    0.099692     |   1\n",
      "       6621 |   0.275877  |    0.111087     |   1\n",
      "       6622 |   0.258797  |    0.021787     |   0\n",
      "       6623 |   0.221150  |    0.043371     |   0\n",
      "       6624 |   0.316323  |    0.081437     |   1\n",
      "       6625 |   0.052983  |    0.014507     |   2\n",
      "       6626 |   0.078479  |    0.010629     |   2\n",
      "       6627 |   0.322504  |    0.144897     |   1\n",
      "       6628 |   0.296112  |    0.059970     |   1\n",
      "       6629 |   0.065972  |    0.024607     |   2\n",
      "       6630 |   0.028723  |    0.029716     |   2\n",
      "       6631 |   0.262445  |    0.040053     |   0\n",
      "       6632 |   0.261560  |    0.139305     |   1\n",
      "       6633 |   0.252945  |    0.045998     |   1\n",
      "       6634 |   0.067733  |    0.020437     |   2\n",
      "       6635 |   0.200148  |    0.044906     |   0\n",
      "       6636 |   0.262341  |    0.011734     |   0\n",
      "       6637 |   0.053589  |    0.029975     |   2\n",
      "       6638 |   0.219683  |    0.043231     |   0\n",
      "       6639 |   0.000104  |    0.024676     |   2\n",
      "       6640 |   0.267402  |    0.150155     |   1\n",
      "       6641 |   0.249571  |    0.005526     |   0\n",
      "       6642 |   0.267329  |    0.060090     |   1\n",
      "       6643 |   0.202008  |    0.028910     |   0\n",
      "       6644 |   0.000104  |    0.027257     |   2\n",
      "       6645 |   0.251573  |    0.028962     |   0\n",
      "       6646 |   0.000111  |    0.024497     |   2\n",
      "       6647 |   0.183338  |    0.041306     |   0\n",
      "       6648 |   0.261796  |    0.143506     |   1\n",
      "       6649 |   0.000108  |    0.003006     |   2\n",
      "       6650 |   0.230188  |    0.008773     |   0\n",
      "       6651 |   0.209476  |    0.051948     |   0\n",
      "       6652 |   0.243168  |    0.086109     |   1\n",
      "       6653 |   0.260349  |    0.090647     |   1\n",
      "       6654 |   0.223354  |    0.020931     |   0\n",
      "       6655 |   0.000106  |    0.030574     |   2\n",
      "       6656 |   0.236934  |    0.034894     |   0\n",
      "       6657 |   0.000109  |    0.033466     |   2\n",
      "       6658 |   0.266695  |    0.102337     |   1\n",
      "       6659 |   0.076296  |    0.013764     |   2\n",
      "       6660 |   0.225324  |    0.036641     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 6662: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       6661 |   0.076327  |    0.007206     |   2\n",
      "       6662 |   0.204619  |    0.146736     |   1\n",
      "       6663 |   0.222910  |    0.006113     |   0\n",
      "       6664 |   0.250910  |    0.097859     |   1\n",
      "       6665 |   0.242330  |    0.070993     |   1\n",
      "       6666 |   0.291464  |    0.091732     |   1\n",
      "       6667 |   0.295091  |    0.096012     |   1\n",
      "       6668 |   0.078742  |    0.013960     |   2\n",
      "       6669 |   0.262354  |    0.139317     |   1\n",
      "       6670 |   0.252037  |    0.006971     |   0\n",
      "       6671 |   0.060103  |    0.011607     |   2\n",
      "       6672 |   0.228848  |    0.057948     |   0\n",
      "       6673 |   0.060944  |    0.022314     |   2\n",
      "       6674 |   0.080604  |    0.014337     |   2\n",
      "       6675 |   0.037692  |    0.028363     |   2\n",
      "       6676 |   0.302996  |    0.099169     |   1\n",
      "       6677 |   0.064343  |    0.007215     |   2\n",
      "       6678 |   0.179100  |    0.048293     |   0\n",
      "       6679 |   0.069610  |    0.013863     |   2\n",
      "       6680 |   0.208229  |    0.031537     |   0\n",
      "       6681 |   0.238911  |    0.133386     |   1\n",
      "       6682 |   0.218868  |    0.078992     |   1\n",
      "       6683 |   0.080807  |    0.009822     |   2\n",
      "       6684 |   0.078678  |    0.041950     |   2\n",
      "       6685 |   0.179151  |    0.014797     |   0\n",
      "       6686 |   0.036813  |    0.029093     |   2\n",
      "       6687 |   0.204145  |    0.035492     |   0\n",
      "       6688 |   0.000105  |    0.030156     |   2\n",
      "       6689 |   0.230190  |    0.017203     |   0\n",
      "       6690 |   0.007732  |    0.043482     |   2\n",
      "       6691 |   0.296181  |    0.093502     |   1\n",
      "       6692 |   0.110766  |    0.008769     |   2\n",
      "       6693 |   0.051653  |    0.046087     |   2\n",
      "       6694 |   0.227301  |    0.080889     |   1\n",
      "       6695 |   0.201235  |    0.014475     |   0\n",
      "       6696 |   0.232096  |    0.131566     |   1\n",
      "       6697 |   0.164387  |    0.002967     |   0\n",
      "       6698 |   0.074383  |    0.014495     |   2\n",
      "       6699 |   0.063746  |    0.046047     |   2\n",
      "       6700 |   0.217475  |    0.098078     |   1\n",
      "       6701 |   0.201500  |    0.094032     |   1\n",
      "       6702 |   0.025964  |    0.015574     |   2\n",
      "       6703 |   0.281066  |    0.055271     |   0\n",
      "       6704 |   0.212128  |    0.100868     |   1\n",
      "       6705 |   0.242985  |    0.089792     |   1\n",
      "       6706 |   0.061717  |    0.009296     |   2\n",
      "       6707 |   0.053846  |    0.016641     |   2\n",
      "       6708 |   0.000103  |    0.045160     |   2\n",
      "       6709 |   0.251272  |    0.093387     |   1\n",
      "       6710 |   0.216178  |    0.012336     |   0\n",
      "       6711 |   0.324997  |    0.140901     |   1\n",
      "       6712 |   0.297796  |    0.087437     |   1\n",
      "       6713 |   0.241524  |    0.009694     |   0\n",
      "       6714 |   0.205595  |    0.105539     |   1\n",
      "       6715 |   0.254784  |    0.031083     |   0\n",
      "       6716 |   0.248097  |    0.170397     |   1\n",
      "       6717 |   0.272932  |    0.085752     |   1\n",
      "       6718 |   0.000103  |    0.009887     |   2\n",
      "       6719 |   0.271725  |    0.026896     |   0\n",
      "       6720 |   0.182278  |    0.039200     |   0\n",
      "       6721 |   0.194780  |    0.024444     |   0\n",
      "       6722 |   0.202974  |    0.095185     |   1\n",
      "       6723 |   0.000110  |    0.018282     |   2\n",
      "       6724 |   0.307315  |    0.160077     |   1\n",
      "       6725 |   0.000106  |    0.010474     |   2\n",
      "       6726 |   0.188959  |    0.093021     |   1\n",
      "       6727 |   0.231008  |    0.077523     |   1\n",
      "       6728 |   0.208342  |    0.008535     |   0\n",
      "       6729 |   0.000105  |    0.047294     |   2\n",
      "       6730 |   0.262086  |    0.094201     |   1\n",
      "       6731 |   0.195134  |    0.007907     |   0\n",
      "       6732 |   0.000107  |    0.028373     |   2\n",
      "       6733 |   0.254457  |    0.027430     |   0\n",
      "       6734 |   0.237722  |    0.026676     |   0\n",
      "       6735 |   0.252870  |    0.139105     |   1\n",
      "       6736 |   0.256638  |    0.003890     |   0\n",
      "       6737 |   0.074061  |    0.007759     |   2\n",
      "       6738 |   0.207870  |    0.024957     |   0\n",
      "       6739 |   0.232761  |    0.148390     |   1\n",
      "       6740 |   0.073677  |    0.002934     |   2\n",
      "       6741 |   0.222274  |    0.009328     |   0\n",
      "       6742 |   0.240236  |    0.047216     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 6743: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       6743 |   0.080028  |    0.010663     |   2\n",
      "       6744 |   0.215539  |    0.030680     |   0\n",
      "       6745 |   0.061357  |    0.025745     |   2\n",
      "       6746 |   0.305325  |    0.149731     |   1\n",
      "       6747 |   0.272227  |    0.050082     |   1\n",
      "       6748 |   0.216561  |    0.084854     |   1\n",
      "       6749 |   0.059310  |    0.025017     |   2\n",
      "       6750 |   0.201735  |    0.157791     |   1\n",
      "       6751 |   0.187889  |    0.008761     |   0\n",
      "       6752 |   0.278766  |    0.063579     |   1\n",
      "       6753 |   0.078441  |    0.009236     |   2\n",
      "       6754 |   0.322696  |    0.138242     |   1\n",
      "       6755 |   0.250749  |    0.010368     |   0\n",
      "       6756 |   0.181596  |    0.077075     |   1\n",
      "       6757 |   0.191900  |    0.042951     |   0\n",
      "       6758 |   0.257258  |    0.090617     |   1\n",
      "       6759 |   0.282966  |    0.034103     |   0\n",
      "       6760 |   0.039162  |    0.031741     |   2\n",
      "       6761 |   0.185689  |    0.009580     |   0\n",
      "       6762 |   0.192076  |    0.027038     |   0\n",
      "       6763 |   0.267705  |    0.054147     |   0\n",
      "       6764 |   0.241960  |    0.085699     |   1\n",
      "       6765 |   0.268050  |    0.013993     |   0\n",
      "       6766 |   0.275056  |    0.044884     |   0\n",
      "       6767 |   0.309868  |    0.059349     |   1\n",
      "       6768 |   0.243063  |    0.021416     |   0\n",
      "       6769 |   0.263243  |    0.139932     |   1\n",
      "       6770 |   0.061494  |    0.025164     |   2\n",
      "       6771 |   0.219747  |    0.094636     |   1\n",
      "       6772 |   0.296206  |    0.110390     |   1\n",
      "       6773 |   0.297379  |    0.043977     |   1\n",
      "       6774 |   0.210380  |    0.045947     |   0\n",
      "       6775 |   0.225411  |    0.020942     |   0\n",
      "       6776 |   0.255413  |    0.136124     |   1\n",
      "       6777 |   0.071386  |    0.003046     |   2\n",
      "       6778 |   0.081489  |    0.003843     |   2\n",
      "       6779 |   0.077337  |    0.021986     |   2\n",
      "       6780 |   0.203780  |    0.028797     |   0\n",
      "       6781 |   0.172423  |    0.127360     |   1\n",
      "       6782 |   0.274582  |    0.005607     |   0\n",
      "       6783 |   0.246904  |    0.045435     |   0\n",
      "       6784 |   0.203181  |    0.014920     |   0\n",
      "       6785 |   0.264294  |    0.104256     |   1\n",
      "       6786 |   0.241810  |    0.085289     |   1\n",
      "       6787 |   0.240670  |    0.023029     |   0\n",
      "       6788 |   0.248219  |    0.145873     |   1\n",
      "       6789 |   0.254621  |    0.062363     |   1\n",
      "       6790 |   0.188696  |    0.141802     |   1\n",
      "       6791 |   0.222161  |    0.003141     |   0\n",
      "       6792 |   0.034983  |    0.004051     |   2\n",
      "       6793 |   0.252574  |    0.045033     |   0\n",
      "       6794 |   0.000105  |    0.005102     |   2\n",
      "       6795 |   0.204751  |    0.149100     |   1\n",
      "       6796 |   0.007876  |    0.010444     |   2\n",
      "       6797 |   0.111885  |    0.045473     |   2\n",
      "       6798 |   0.052509  |    0.028208     |   2\n",
      "       6799 |   0.285258  |    0.136640     |   1\n",
      "       6800 |   0.270190  |    0.008295     |   0\n",
      "       6801 |   0.217874  |    0.010075     |   0\n",
      "       6802 |   0.272691  |    0.155208     |   1\n",
      "       6803 |   0.212212  |    0.052522     |   1\n",
      "       6804 |   0.329276  |    0.067955     |   1\n",
      "       6805 |   0.076593  |    0.003345     |   2\n",
      "       6806 |   0.298015  |    0.053695     |   0\n",
      "       6807 |   0.065098  |    0.012201     |   2\n",
      "       6808 |   0.322817  |    0.146727     |   1\n",
      "       6809 |   0.220078  |    0.003914     |   0\n",
      "       6810 |   0.224570  |    0.005435     |   0\n",
      "       6811 |   0.263570  |    0.044205     |   0\n",
      "       6812 |   0.286061  |    0.019640     |   0\n",
      "       6813 |   0.257301  |    0.143151     |   1\n",
      "       6814 |   0.211361  |    0.056944     |   1\n",
      "       6815 |   0.264858  |    0.105348     |   1\n",
      "       6816 |   0.292825  |    0.082774     |   1\n",
      "       6817 |   0.028723  |    0.017412     |   2\n",
      "       6818 |   0.064138  |    0.050353     |   2\n",
      "       6819 |   0.267754  |    0.086701     |   1\n",
      "       6820 |   0.051646  |    0.009073     |   2\n",
      "       6821 |   0.192219  |    0.061421     |   0\n",
      "       6822 |   0.224698  |    0.090753     |   1\n",
      "       6823 |   0.340948  |    0.079545     |   1\n",
      "       6824 |   0.000103  |    0.006218     |   2\n",
      "       6825 |   0.000104  |    0.046306     |   2\n",
      "       6826 |   0.191032  |    0.015941     |   0\n",
      "       6827 |   0.172041  |    0.016976     |   0\n",
      "       6828 |   0.213255  |    0.042703     |   0\n",
      "       6829 |   0.256721  |    0.014750     |   0\n",
      "       6830 |   0.208402  |    0.040352     |   0\n",
      "       6831 |   0.000110  |    0.009466     |   2\n",
      "       6832 |   0.249407  |    0.028582     |   0\n",
      "       6833 |   0.219615  |    0.053510     |   0\n",
      "       6834 |   0.000106  |    0.007710     |   2\n",
      "       6835 |   0.000105  |    0.045593     |   2\n",
      "       6836 |   0.226391  |    0.018824     |   0\n",
      "       6837 |   0.000108  |    0.071678     |   2\n",
      "       6838 |   0.322434  |    0.045276     |   1\n",
      "       6839 |   0.238070  |    0.028460     |   0\n",
      "       6840 |   0.203744  |    0.023423     |   0\n",
      "       6841 |   0.250012  |    0.026744     |   0\n",
      "       6842 |   0.234866  |    0.047014     |   0\n",
      "       6843 |   0.219670  |    0.104615     |   1\n",
      "       6844 |   0.269421  |    0.088687     |   1\n",
      "       6845 |   0.077329  |    0.007625     |   2\n",
      "       6846 |   0.072697  |    0.040560     |   2\n",
      "       6847 |   0.262810  |    0.018329     |   0\n",
      "       6848 |   0.219043  |    0.034041     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 6849: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       6849 |   0.077591  |    0.016724     |   2\n",
      "       6850 |   0.242593  |    0.151854     |   1\n",
      "       6851 |   0.060765  |    0.016925     |   2\n",
      "       6852 |   0.243042  |    0.052483     |   1\n",
      "       6853 |   0.174442  |    0.008867     |   0\n",
      "       6854 |   0.296572  |    0.137198     |   1\n",
      "       6855 |   0.181969  |    0.009050     |   0\n",
      "       6856 |   0.234557  |    0.011902     |   0\n",
      "       6857 |   0.247942  |    0.046718     |   0\n",
      "       6858 |   0.060384  |    0.017999     |   2\n",
      "       6859 |   0.226035  |    0.027639     |   0\n",
      "       6860 |   0.079973  |    0.013909     |   2\n",
      "       6861 |   0.214991  |    0.046584     |   0\n",
      "       6862 |   0.038320  |    0.020094     |   2\n",
      "       6863 |   0.063716  |    0.030924     |   2\n",
      "       6864 |   0.215886  |    0.131422     |   1\n",
      "       6865 |   0.209143  |    0.019290     |   0\n",
      "       6866 |   0.219125  |    0.111954     |   1\n",
      "       6867 |   0.077011  |    0.012343     |   2\n",
      "       6868 |   0.233920  |    0.076599     |   1\n",
      "       6869 |   0.202181  |    0.027406     |   0\n",
      "       6870 |   0.080504  |    0.034252     |   2\n",
      "       6871 |   0.248292  |    0.138220     |   1\n",
      "       6872 |   0.074414  |    0.014168     |   2\n",
      "       6873 |   0.206392  |    0.091840     |   1\n",
      "       6874 |   0.195700  |    0.139695     |   1\n",
      "       6875 |   0.180720  |    0.003424     |   0\n",
      "       6876 |   0.234535  |    0.010291     |   0\n",
      "       6877 |   0.034099  |    0.044088     |   2\n",
      "       6878 |   0.265263  |    0.139078     |   1\n",
      "       6879 |   0.235368  |    0.047543     |   1\n",
      "       6880 |   0.214041  |    0.031565     |   0\n",
      "       6881 |   0.302229  |    0.141653     |   1\n",
      "       6882 |   0.236212  |    0.091110     |   1\n",
      "       6883 |   0.182647  |    0.009182     |   0\n",
      "       6884 |   0.000104  |    0.029445     |   2\n",
      "       6885 |   0.007637  |    0.032921     |   2\n",
      "       6886 |   0.276203  |    0.157994     |   1\n",
      "       6887 |   0.223363  |    0.082602     |   1\n",
      "       6888 |   0.161403  |    0.019442     |   0\n",
      "       6889 |   0.342507  |    0.134377     |   1\n",
      "       6890 |   0.114898  |    0.004411     |   2\n",
      "       6891 |   0.289630  |    0.009328     |   0\n",
      "       6892 |   0.214844  |    0.045045     |   0\n",
      "       6893 |   0.052558  |    0.009807     |   2\n",
      "       6894 |   0.073505  |    0.031345     |   2\n",
      "       6895 |   0.215318  |    0.028437     |   0\n",
      "       6896 |   0.063132  |    0.031762     |   2\n",
      "       6897 |   0.027299  |    0.028147     |   2\n",
      "       6898 |   0.060026  |    0.026791     |   2\n",
      "       6899 |   0.053454  |    0.034821     |   2\n",
      "       6900 |   0.223514  |    0.148549     |   1\n",
      "       6901 |   0.216260  |    0.053032     |   1\n",
      "       6902 |   0.237740  |    0.017654     |   0\n",
      "       6903 |   0.203713  |    0.130335     |   1\n",
      "       6904 |   0.257566  |    0.014033     |   0\n",
      "       6905 |   0.000102  |    0.041176     |   2\n",
      "       6906 |   0.000103  |    0.011854     |   2\n",
      "       6907 |   0.186322  |    0.160454     |   1\n",
      "       6908 |   0.286419  |    0.050877     |   1\n",
      "       6909 |   0.000108  |    0.012346     |   2\n",
      "       6910 |   0.000105  |    0.042955     |   2\n",
      "       6911 |   0.000104  |    0.017654     |   2\n",
      "       6912 |   0.235690  |    0.150281     |   1\n",
      "       6913 |   0.000107  |    0.008789     |   2\n",
      "       6914 |   0.233548  |    0.082645     |   1\n",
      "       6915 |   0.244808  |    0.006013     |   0\n",
      "       6916 |   0.320408  |    0.151714     |   1\n",
      "       6917 |   0.283338  |    0.011254     |   0\n",
      "       6918 |   0.262719  |    0.094146     |   1\n",
      "       6919 |   0.247570  |    0.051976     |   1\n",
      "       6920 |   0.243774  |    0.014773     |   0\n",
      "       6921 |   0.203562  |    0.043188     |   0\n",
      "       6922 |   0.202645  |    0.014419     |   0\n",
      "       6923 |   0.210099  |    0.150295     |   1\n",
      "       6924 |   0.192215  |    0.004280     |   0\n",
      "       6925 |   0.279409  |    0.010885     |   0\n",
      "       6926 |   0.211194  |    0.026456     |   0\n",
      "       6927 |   0.073347  |    0.030856     |   2\n",
      "       6928 |   0.070650  |    0.041918     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 6929: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       6929 |   0.245155  |    0.087286     |   1\n",
      "       6930 |   0.077223  |    0.007681     |   2\n",
      "       6931 |   0.266409  |    0.155138     |   1\n",
      "       6932 |   0.258562  |    0.079756     |   1\n",
      "       6933 |   0.058565  |    0.005585     |   2\n",
      "       6934 |   0.059898  |    0.009196     |   2\n",
      "       6935 |   0.077816  |    0.031256     |   2\n",
      "       6936 |   0.036148  |    0.023707     |   2\n",
      "       6937 |   0.238983  |    0.024652     |   0\n",
      "       6938 |   0.264799  |    0.088676     |   1\n",
      "       6939 |   0.233994  |    0.043489     |   0\n",
      "       6940 |   0.230599  |    0.147826     |   1\n",
      "       6941 |   0.202171  |    0.049996     |   1\n",
      "       6942 |   0.240898  |    0.033031     |   0\n",
      "       6943 |   0.236816  |    0.061422     |   0\n",
      "       6944 |   0.220340  |    0.051386     |   1\n",
      "       6945 |   0.254503  |    0.025967     |   0\n",
      "       6946 |   0.226323  |    0.032545     |   0\n",
      "       6947 |   0.062121  |    0.024145     |   2\n",
      "       6948 |   0.198148  |    0.035141     |   0\n",
      "       6949 |   0.067986  |    0.006450     |   2\n",
      "       6950 |   0.212571  |    0.044568     |   0\n",
      "       6951 |   0.229685  |    0.016583     |   0\n",
      "       6952 |   0.271738  |    0.042616     |   0\n",
      "       6953 |   0.244509  |    0.015660     |   0\n",
      "       6954 |   0.078565  |    0.031589     |   2\n",
      "       6955 |   0.075122  |    0.029507     |   2\n",
      "       6956 |   0.244954  |    0.042939     |   0\n",
      "       6957 |   0.227336  |    0.016268     |   0\n",
      "       6958 |   0.034988  |    0.022511     |   2\n",
      "       6959 |   0.252829  |    0.023728     |   0\n",
      "       6960 |   0.233063  |    0.042936     |   0\n",
      "       6961 |   0.000102  |    0.016401     |   2\n",
      "       6962 |   0.286326  |    0.118313     |   1\n",
      "       6963 |   0.007678  |    0.003470     |   2\n",
      "       6964 |   0.331586  |    0.147008     |   1\n",
      "       6965 |   0.209259  |    0.003195     |   0\n",
      "       6966 |   0.114563  |    0.012461     |   2\n",
      "       6967 |   0.052733  |    0.041112     |   2\n",
      "       6968 |   0.079355  |    0.018493     |   2\n",
      "       6969 |   0.238415  |    0.143749     |   1\n",
      "       6970 |   0.221318  |    0.004599     |   0\n",
      "       6971 |   0.065279  |    0.005751     |   2\n",
      "       6972 |   0.262292  |    0.147252     |   1\n",
      "       6973 |   0.029433  |    0.011857     |   2\n",
      "       6974 |   0.213747  |    0.098335     |   1\n",
      "       6975 |   0.064036  |    0.013643     |   2\n",
      "       6976 |   0.218870  |    0.106417     |   1\n",
      "       6977 |   0.051247  |    0.006477     |   2\n",
      "       6978 |   0.240549  |    0.044555     |   0\n",
      "       6979 |   0.286585  |    0.025965     |   0\n",
      "       6980 |   0.222583  |    0.031510     |   0\n",
      "       6981 |   0.000101  |    0.013858     |   2\n",
      "       6982 |   0.282267  |    0.111691     |   1\n",
      "       6983 |   0.231885  |    0.089690     |   1\n",
      "       6984 |   0.214276  |    0.021656     |   0\n",
      "       6985 |   0.198698  |    0.152993     |   1\n",
      "       6986 |   0.276636  |    0.044905     |   1\n",
      "       6987 |   0.000101  |    0.011277     |   2\n",
      "       6988 |   0.000107  |    0.034862     |   2\n",
      "       6989 |   0.000104  |    0.033790     |   2\n",
      "       6990 |   0.262944  |    0.153892     |   1\n",
      "       6991 |   0.000103  |    0.011832     |   2\n",
      "       6992 |   0.221618  |    0.093456     |   1\n",
      "       6993 |   0.270744  |    0.087191     |   1\n",
      "       6994 |   0.218127  |    0.008908     |   0\n",
      "       6995 |   0.229461  |    0.020677     |   0\n",
      "       6996 |   0.187531  |    0.149626     |   1\n",
      "       6997 |   0.216934  |    0.090100     |   1\n",
      "       6998 |   0.339534  |    0.049340     |   1\n",
      "       6999 |   0.213812  |    0.009717     |   0\n",
      "       7000 |   0.233757  |    0.053698     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 7000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 7000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       7001 |   0.203774  |    0.051967     |   0\n",
      "       7002 |   0.076453  |    0.021431     |   2\n",
      "       7003 |   0.057953  |    0.039150     |   2\n",
      "       7004 |   0.147561  |    0.028726     |   0\n",
      "       7005 |   0.208959  |    0.117897     |   1\n",
      "       7006 |   0.231584  |    0.152297     |   1\n",
      "       7007 |   0.059161  |    0.002890     |   2\n",
      "       7008 |   0.077972  |    0.015992     |   2\n",
      "       7009 |   0.190059  |    0.137261     |   1\n",
      "       7010 |   0.159804  |    0.013198     |   0\n",
      "       7011 |   0.228609  |    0.064367     |   1\n",
      "       7012 |   0.038698  |    0.008711     |   2\n",
      "       7013 |   0.259102  |    0.158116     |   1\n",
      "       7014 |   0.228355  |    0.067617     |   1\n",
      "       7015 |   0.295993  |    0.015871     |   0\n",
      "       7016 |   0.281588  |    0.135785     |   1\n",
      "       7017 |   0.060076  |    0.004049     |   2\n",
      "       7018 |   0.249282  |    0.022920     |   0\n",
      "       7019 |   0.214658  |    0.146938     |   1\n",
      "       7020 |   0.212725  |    0.043505     |   1\n",
      "       7021 |   0.256749  |    0.019885     |   0\n",
      "       7022 |   0.069868  |    0.031848     |   2\n",
      "       7023 |   0.204654  |    0.030285     |   0\n",
      "       7024 |   0.194543  |    0.024250     |   0\n",
      "       7025 |   0.254652  |    0.027397     |   0\n",
      "       7026 |   0.222944  |    0.029707     |   0\n",
      "       7027 |   0.078665  |    0.034616     |   2\n",
      "       7028 |   0.223561  |    0.034393     |   0\n",
      "       7029 |   0.072808  |    0.008149     |   2\n",
      "       7030 |   0.035647  |    0.039775     |   2\n",
      "       7031 |   0.000102  |    0.015210     |   2\n",
      "       7032 |   0.212789  |    0.042682     |   0\n",
      "       7033 |   0.007340  |    0.024618     |   2\n",
      "       7034 |   0.200689  |    0.093516     |   1\n",
      "       7035 |   0.192224  |    0.044327     |   0\n",
      "       7036 |   0.232523  |    0.013167     |   0\n",
      "       7037 |   0.200428  |    0.041964     |   0\n",
      "       7038 |   0.203800  |    0.111195     |   1\n",
      "       7039 |   0.272532  |    0.144124     |   1\n",
      "       7040 |   0.111246  |    0.003341     |   2\n",
      "       7041 |   0.298530  |    0.005949     |   0\n",
      "       7042 |   0.050588  |    0.045742     |   2\n",
      "       7043 |   0.215400  |    0.009038     |   0\n",
      "       7044 |   0.229376  |    0.028233     |   0\n",
      "       7045 |   0.248168  |    0.158608     |   1\n",
      "       7046 |   0.242576  |    0.061790     |   1\n",
      "       7047 |   0.238440  |    0.137784     |   1\n",
      "       7048 |   0.077832  |    0.005437     |   2\n",
      "       7049 |   0.063937  |    0.007698     |   2\n",
      "       7050 |   0.256080  |    0.046817     |   0\n",
      "       7051 |   0.211425  |    0.139602     |   1\n",
      "       7052 |   0.234764  |    0.004623     |   0\n",
      "       7053 |   0.210519  |    0.014479     |   0\n",
      "       7054 |   0.281745  |    0.148184     |   1\n",
      "       7055 |   0.029178  |    0.004000     |   2\n",
      "       7056 |   0.063278  |    0.016879     |   2\n",
      "       7057 |   0.247060  |    0.085383     |   1\n",
      "       7058 |   0.266791  |    0.042616     |   0\n",
      "       7059 |   0.256050  |    0.054957     |   1\n",
      "       7060 |   0.270524  |    0.022679     |   0\n",
      "       7061 |   0.052514  |    0.027333     |   2\n",
      "       7062 |   0.240839  |    0.033697     |   0\n",
      "       7063 |   0.000101  |    0.035126     |   2\n",
      "       7064 |   0.227719  |    0.141167     |   1\n",
      "       7065 |   0.253611  |    0.016425     |   0\n",
      "       7066 |   0.179958  |    0.016133     |   0\n",
      "       7067 |   0.232495  |    0.102162     |   1\n",
      "       7068 |   0.235532  |    0.085016     |   1\n",
      "       7069 |   0.000101  |    0.006559     |   2\n",
      "       7070 |   0.000105  |    0.049826     |   2\n",
      "       7071 |   0.238514  |    0.022706     |   0\n",
      "       7072 |   0.000104  |    0.036572     |   2\n",
      "       7073 |   0.000103  |    0.016304     |   2\n",
      "       7074 |   0.000105  |    0.025187     |   2\n",
      "       7075 |   0.078266  |    0.043168     |   2\n",
      "       7076 |   0.245057  |    0.033636     |   0\n",
      "       7077 |   0.072332  |    0.025930     |   2\n",
      "       7078 |   0.214011  |    0.090401     |   1\n",
      "       7079 |   0.255257  |    0.087432     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 7080: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       7080 |   0.080277  |    0.011441     |   2\n",
      "       7081 |   0.199962  |    0.151967     |   1\n",
      "       7082 |   0.279870  |    0.056638     |   1\n",
      "       7083 |   0.349716  |    0.095665     |   1\n",
      "       7084 |   0.268765  |    0.090094     |   1\n",
      "       7085 |   0.270357  |    0.088225     |   1\n",
      "       7086 |   0.055844  |    0.022242     |   2\n",
      "       7087 |   0.202948  |    0.126815     |   1\n",
      "       7088 |   0.058100  |    0.012802     |   2\n",
      "       7089 |   0.244345  |    0.141080     |   1\n",
      "       7090 |   0.078878  |    0.004898     |   2\n",
      "       7091 |   0.263123  |    0.058483     |   1\n",
      "       7092 |   0.206183  |    0.022124     |   0\n",
      "       7093 |   0.221252  |    0.111384     |   1\n",
      "       7094 |   0.036960  |    0.025971     |   2\n",
      "       7095 |   0.222583  |    0.029828     |   0\n",
      "       7096 |   0.061976  |    0.019656     |   2\n",
      "       7097 |   0.195117  |    0.024948     |   0\n",
      "       7098 |   0.229162  |    0.022048     |   0\n",
      "       7099 |   0.243343  |    0.158776     |   1\n",
      "       7100 |   0.067918  |    0.002892     |   2\n",
      "       7101 |   0.206956  |    0.010536     |   0\n",
      "       7102 |   0.080477  |    0.024395     |   2\n",
      "       7103 |   0.074914  |    0.019767     |   2\n",
      "       7104 |   0.034229  |    0.048233     |   2\n",
      "       7105 |   0.233938  |    0.081679     |   1\n",
      "       7106 |   0.247090  |    0.035379     |   0\n",
      "       7107 |   0.000102  |    0.022884     |   2\n",
      "       7108 |   0.250026  |    0.032984     |   0\n",
      "       7109 |   0.007159  |    0.030196     |   2\n",
      "       7110 |   0.108028  |    0.005072     |   2\n",
      "       7111 |   0.051021  |    0.049087     |   2\n",
      "       7112 |   0.203125  |    0.017768     |   0\n",
      "       7113 |   0.074830  |    0.028831     |   2\n",
      "       7114 |   0.274396  |    0.089140     |   1\n",
      "       7115 |   0.167226  |    0.024697     |   0\n",
      "       7116 |   0.062871  |    0.033404     |   2\n",
      "       7117 |   0.197030  |    0.100345     |   1\n",
      "       7118 |   0.205259  |    0.013354     |   0\n",
      "       7119 |   0.222651  |    0.147340     |   1\n",
      "       7120 |   0.028890  |    0.004593     |   2\n",
      "       7121 |   0.061409  |    0.009364     |   2\n",
      "       7122 |   0.050813  |    0.045731     |   2\n",
      "       7123 |   0.314541  |    0.081181     |   1\n",
      "       7124 |   0.246921  |    0.141567     |   1\n",
      "       7125 |   0.204985  |    0.024894     |   0\n",
      "       7126 |   0.318440  |    0.094089     |   1\n",
      "       7127 |   0.222331  |    0.013927     |   0\n",
      "       7128 |   0.293062  |    0.138688     |   1\n",
      "       7129 |   0.000100  |    0.003031     |   2\n",
      "       7130 |   0.204438  |    0.020149     |   0\n",
      "       7131 |   0.316664  |    0.097498     |   1\n",
      "       7132 |   0.176855  |    0.013457     |   0\n",
      "       7133 |   0.250672  |    0.034943     |   0\n",
      "       7134 |   0.185930  |    0.135764     |   1\n",
      "       7135 |   0.228934  |    0.012773     |   0\n",
      "       7136 |   0.268992  |    0.133742     |   1\n",
      "       7137 |   0.000101  |    0.005826     |   2\n",
      "       7138 |   0.227897  |    0.007659     |   0\n",
      "       7139 |   0.235960  |    0.043650     |   0\n",
      "       7140 |   0.233555  |    0.099756     |   1\n",
      "       7141 |   0.259472  |    0.012989     |   0\n",
      "       7142 |   0.317175  |    0.150763     |   1\n",
      "       7143 |   0.237540  |    0.054958     |   1\n",
      "       7144 |   0.250827  |    0.012198     |   0\n",
      "       7145 |   0.000103  |    0.047814     |   2\n",
      "       7146 |   0.000103  |    0.018524     |   2\n",
      "       7147 |   0.233013  |    0.133789     |   1\n",
      "       7148 |   0.000102  |    0.009769     |   2\n",
      "       7149 |   0.214618  |    0.148859     |   1\n",
      "       7150 |   0.236490  |    0.101701     |   1\n",
      "       7151 |   0.216643  |    0.088547     |   1\n",
      "       7152 |   0.000104  |    0.010603     |   2\n",
      "       7153 |   0.073972  |    0.052928     |   2\n",
      "       7154 |   0.211543  |    0.133022     |   1\n",
      "       7155 |   0.170946  |    0.075960     |   1\n",
      "       7156 |   0.072506  |    0.013299     |   2\n",
      "       7157 |   0.252841  |    0.129910     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 7158: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       7158 |   0.264416  |    0.011300     |   0\n",
      "       7159 |   0.259974  |    0.119694     |   1\n",
      "       7160 |   0.075787  |    0.005734     |   2\n",
      "       7161 |   0.059113  |    0.023641     |   2\n",
      "       7162 |   0.254202  |    0.142165     |   1\n",
      "       7163 |   0.056831  |    0.006811     |   2\n",
      "       7164 |   0.200561  |    0.046586     |   0\n",
      "       7165 |   0.274227  |    0.135200     |   1\n",
      "       7166 |   0.194331  |    0.027797     |   0\n",
      "       7167 |   0.267189  |    0.087846     |   1\n",
      "       7168 |   0.233640  |    0.093757     |   1\n",
      "       7169 |   0.212269  |    0.042627     |   0\n",
      "       7170 |   0.224563  |    0.140269     |   1\n",
      "       7171 |   0.251977  |    0.083784     |   1\n",
      "       7172 |   0.236096  |    0.004279     |   0\n",
      "       7173 |   0.251947  |    0.025421     |   0\n",
      "       7174 |   0.076637  |    0.037974     |   2\n",
      "       7175 |   0.037952  |    0.007606     |   2\n",
      "       7176 |   0.059984  |    0.042465     |   2\n",
      "       7177 |   0.203899  |    0.017887     |   0\n",
      "       7178 |   0.066205  |    0.033031     |   2\n",
      "       7179 |   0.269176  |    0.024376     |   0\n",
      "       7180 |   0.157824  |    0.030055     |   0\n",
      "       7181 |   0.254229  |    0.092312     |   1\n",
      "       7182 |   0.274256  |    0.028817     |   0\n",
      "       7183 |   0.252940  |    0.030365     |   0\n",
      "       7184 |   0.218841  |    0.030960     |   0\n",
      "       7185 |   0.078126  |    0.020342     |   2\n",
      "       7186 |   0.075560  |    0.032081     |   2\n",
      "       7187 |   0.240657  |    0.155472     |   1\n",
      "       7188 |   0.213960  |    0.060410     |   1\n",
      "       7189 |   0.034542  |    0.009712     |   2\n",
      "       7190 |   0.256083  |    0.046065     |   0\n",
      "       7191 |   0.229632  |    0.015219     |   0\n",
      "       7192 |   0.284419  |    0.147513     |   1\n",
      "       7193 |   0.207500  |    0.091671     |   1\n",
      "       7194 |   0.233685  |    0.084068     |   1\n",
      "       7195 |   0.193710  |    0.006586     |   0\n",
      "       7196 |   0.241114  |    0.072136     |   0\n",
      "       7197 |   0.247322  |    0.091699     |   1\n",
      "       7198 |   0.238474  |    0.007783     |   0\n",
      "       7199 |   0.000101  |    0.025719     |   2\n",
      "       7200 |   0.300545  |    0.134239     |   1\n",
      "       7201 |   0.008618  |    0.008663     |   2\n",
      "       7202 |   0.110464  |    0.043665     |   2\n",
      "       7203 |   0.220732  |    0.139484     |   1\n",
      "       7204 |   0.053224  |    0.012129     |   2\n",
      "       7205 |   0.299396  |    0.080533     |   1\n",
      "       7206 |   0.076459  |    0.011723     |   2\n",
      "       7207 |   0.187432  |    0.037371     |   0\n",
      "       7208 |   0.213307  |    0.086343     |   1\n",
      "       7209 |   0.223350  |    0.087199     |   1\n",
      "       7210 |   0.064368  |    0.014944     |   2\n",
      "       7211 |   0.212985  |    0.037339     |   0\n",
      "       7212 |   0.027365  |    0.011742     |   2\n",
      "       7213 |   0.312655  |    0.151521     |   1\n",
      "       7214 |   0.198509  |    0.002939     |   0\n",
      "       7215 |   0.060954  |    0.014675     |   2\n",
      "       7216 |   0.313282  |    0.138797     |   1\n",
      "       7217 |   0.195090  |    0.082832     |   1\n",
      "       7218 |   0.244384  |    0.102882     |   1\n",
      "       7219 |   0.316137  |    0.093447     |   1\n",
      "       7220 |   0.220858  |    0.011660     |   0\n",
      "       7221 |   0.048567  |    0.050501     |   2\n",
      "       7222 |   0.202179  |    0.130331     |   1\n",
      "       7223 |   0.189532  |    0.008460     |   0\n",
      "       7224 |   0.245824  |    0.090636     |   1\n",
      "       7225 |   0.295331  |    0.012213     |   0\n",
      "       7226 |   0.234181  |    0.128986     |   1\n",
      "       7227 |   0.000100  |    0.006900     |   2\n",
      "       7228 |   0.000101  |    0.009313     |   2\n",
      "       7229 |   0.238901  |    0.043631     |   0\n",
      "       7230 |   0.000105  |    0.018264     |   2\n",
      "       7231 |   0.214424  |    0.134927     |   1\n",
      "       7232 |   0.000103  |    0.005859     |   2\n",
      "       7233 |   0.190466  |    0.097469     |   1\n",
      "       7234 |   0.000102  |    0.021542     |   2\n",
      "       7235 |   0.000106  |    0.029977     |   2\n",
      "       7236 |   0.075348  |    0.020602     |   2\n",
      "       7237 |   0.222736  |    0.029040     |   0\n",
      "       7238 |   0.070361  |    0.023691     |   2\n",
      "       7239 |   0.162774  |    0.142490     |   1\n",
      "       7240 |   0.202898  |    0.075340     |   1\n",
      "       7241 |   0.258405  |    0.028072     |   0\n",
      "       7242 |   0.231020  |    0.044259     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 7243: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       7243 |   0.075507  |    0.006713     |   2\n",
      "       7244 |   0.060057  |    0.059430     |   2\n",
      "       7245 |   0.233089  |    0.085330     |   1\n",
      "       7246 |   0.196368  |    0.024900     |   0\n",
      "       7247 |   0.243976  |    0.091130     |   1\n",
      "       7248 |   0.057662  |    0.011106     |   2\n",
      "       7249 |   0.275312  |    0.044123     |   0\n",
      "       7250 |   0.078304  |    0.018418     |   2\n",
      "       7251 |   0.205287  |    0.029295     |   0\n",
      "       7252 |   0.038892  |    0.026127     |   2\n",
      "       7253 |   0.059682  |    0.025752     |   2\n",
      "       7254 |   0.264683  |    0.046585     |   0\n",
      "       7255 |   0.067047  |    0.009425     |   2\n",
      "       7256 |   0.270797  |    0.166119     |   1\n",
      "       7257 |   0.218116  |    0.012063     |   0\n",
      "       7258 |   0.232413  |    0.079201     |   1\n",
      "       7259 |   0.200670  |    0.006748     |   0\n",
      "       7260 |   0.077246  |    0.019328     |   2\n",
      "       7261 |   0.228175  |    0.142759     |   1\n",
      "       7262 |   0.227404  |    0.078902     |   1\n",
      "       7263 |   0.209617  |    0.018111     |   0\n",
      "       7264 |   0.267240  |    0.141432     |   1\n",
      "       7265 |   0.073234  |    0.007331     |   2\n",
      "       7266 |   0.035982  |    0.007182     |   2\n",
      "       7267 |   0.000099  |    0.050612     |   2\n",
      "       7268 |   0.239525  |    0.098790     |   1\n",
      "       7269 |   0.210110  |    0.018021     |   0\n",
      "       7270 |   0.200017  |    0.161032     |   1\n",
      "       7271 |   0.258754  |    0.055761     |   1\n",
      "       7272 |   0.256825  |    0.141265     |   1\n",
      "       7273 |   0.236302  |    0.002925     |   0\n",
      "       7274 |   0.237098  |    0.007846     |   0\n",
      "       7275 |   0.008699  |    0.044228     |   2\n",
      "       7276 |   0.240091  |    0.145254     |   1\n",
      "       7277 |   0.236481  |    0.067205     |   1\n",
      "       7278 |   0.289881  |    0.034899     |   0\n",
      "       7279 |   0.241134  |    0.041492     |   0\n",
      "       7280 |   0.107194  |    0.010500     |   2\n",
      "       7281 |   0.256722  |    0.043348     |   0\n",
      "       7282 |   0.194847  |    0.012940     |   0\n",
      "       7283 |   0.050975  |    0.047698     |   2\n",
      "       7284 |   0.080859  |    0.007398     |   2\n",
      "       7285 |   0.230518  |    0.059128     |   0\n",
      "       7286 |   0.226230  |    0.093720     |   1\n",
      "       7287 |   0.067617  |    0.011944     |   2\n",
      "       7288 |   0.028093  |    0.038359     |   2\n",
      "       7289 |   0.236985  |    0.143219     |   1\n",
      "       7290 |   0.284271  |    0.050775     |   1\n",
      "       7291 |   0.288642  |    0.078489     |   1\n",
      "       7292 |   0.244376  |    0.027675     |   0\n",
      "       7293 |   0.201232  |    0.032199     |   0\n",
      "       7294 |   0.224411  |    0.138912     |   1\n",
      "       7295 |   0.064150  |    0.016097     |   2\n",
      "       7296 |   0.318602  |    0.085495     |   1\n",
      "       7297 |   0.194654  |    0.101649     |   1\n",
      "       7298 |   0.046437  |    0.008523     |   2\n",
      "       7299 |   0.274161  |    0.042191     |   0\n",
      "       7300 |   0.226193  |    0.036787     |   0\n",
      "       7301 |   0.222100  |    0.024605     |   0\n",
      "       7302 |   0.000098  |    0.050871     |   2\n",
      "       7303 |   0.000099  |    0.010803     |   2\n",
      "       7304 |   0.206900  |    0.137754     |   1\n",
      "       7305 |   0.199157  |    0.013813     |   0\n",
      "       7306 |   0.274186  |    0.139076     |   1\n",
      "       7307 |   0.000104  |    0.008421     |   2\n",
      "       7308 |   0.000101  |    0.048493     |   2\n",
      "       7309 |   0.268166  |    0.095378     |   1\n",
      "       7310 |   0.000101  |    0.020555     |   2\n",
      "       7311 |   0.202425  |    0.143870     |   1\n",
      "       7312 |   0.000103  |    0.011301     |   2\n",
      "       7313 |   0.275521  |    0.098680     |   1\n",
      "       7314 |   0.249615  |    0.016587     |   0\n",
      "       7315 |   0.249340  |    0.140754     |   1\n",
      "       7316 |   0.199012  |    0.068651     |   1\n",
      "       7317 |   0.235320  |    0.020230     |   0\n",
      "       7318 |   0.236164  |    0.138986     |   1\n",
      "       7319 |   0.223068  |    0.012229     |   0\n",
      "       7320 |   0.070341  |    0.012827     |   2\n",
      "       7321 |   0.068782  |    0.043304     |   2\n",
      "       7322 |   0.176466  |    0.032937     |   0\n",
      "       7323 |   0.260726  |    0.140749     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 7324: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       7324 |   0.260117  |    0.087727     |   1\n",
      "       7325 |   0.075975  |    0.013706     |   2\n",
      "       7326 |   0.235731  |    0.043309     |   0\n",
      "       7327 |   0.299783  |    0.018549     |   0\n",
      "       7328 |   0.235277  |    0.028081     |   0\n",
      "       7329 |   0.267856  |    0.030077     |   0\n",
      "       7330 |   0.197288  |    0.130105     |   1\n",
      "       7331 |   0.057088  |    0.005535     |   2\n",
      "       7332 |   0.220897  |    0.021465     |   0\n",
      "       7333 |   0.208221  |    0.040290     |   0\n",
      "       7334 |   0.058121  |    0.025480     |   2\n",
      "       7335 |   0.212708  |    0.156685     |   1\n",
      "       7336 |   0.271577  |    0.009205     |   0\n",
      "       7337 |   0.190161  |    0.095753     |   1\n",
      "       7338 |   0.075798  |    0.009563     |   2\n",
      "       7339 |   0.216033  |    0.029044     |   0\n",
      "       7340 |   0.174336  |    0.013613     |   0\n",
      "       7341 |   0.206702  |    0.045134     |   0\n",
      "       7342 |   0.252958  |    0.089097     |   1\n",
      "       7343 |   0.288768  |    0.002973     |   0\n",
      "       7344 |   0.037870  |    0.003847     |   2\n",
      "       7345 |   0.227249  |    0.047963     |   0\n",
      "       7346 |   0.186775  |    0.012525     |   0\n",
      "       7347 |   0.061357  |    0.038991     |   2\n",
      "       7348 |   0.284862  |    0.097018     |   1\n",
      "       7349 |   0.068029  |    0.023657     |   2\n",
      "       7350 |   0.184744  |    0.047005     |   0\n",
      "       7351 |   0.079623  |    0.008009     |   2\n",
      "       7352 |   0.182439  |    0.045968     |   0\n",
      "       7353 |   0.075015  |    0.011350     |   2\n",
      "       7354 |   0.287808  |    0.156272     |   1\n",
      "       7355 |   0.245744  |    0.032108     |   1\n",
      "       7356 |   0.268562  |    0.030735     |   0\n",
      "       7357 |   0.234744  |    0.030860     |   0\n",
      "       7358 |   0.033514  |    0.018203     |   2\n",
      "       7359 |   0.203352  |    0.045554     |   0\n",
      "       7360 |   0.304223  |    0.087976     |   1\n",
      "       7361 |   0.000098  |    0.007680     |   2\n",
      "       7362 |   0.213574  |    0.051665     |   0\n",
      "       7363 |   0.312439  |    0.100479     |   1\n",
      "       7364 |   0.286357  |    0.057466     |   1\n",
      "       7365 |   0.236424  |    0.030815     |   0\n",
      "       7366 |   0.007549  |    0.026930     |   2\n",
      "       7367 |   0.196833  |    0.089319     |   1\n",
      "       7368 |   0.270098  |    0.020481     |   0\n",
      "       7369 |   0.219529  |    0.033275     |   0\n",
      "       7370 |   0.208087  |    0.019156     |   0\n",
      "       7371 |   0.296170  |    0.145434     |   1\n",
      "       7372 |   0.257284  |    0.096099     |   1\n",
      "       7373 |   0.190864  |    0.100749     |   1\n",
      "       7374 |   0.109465  |    0.007396     |   2\n",
      "       7375 |   0.212681  |    0.032858     |   0\n",
      "       7376 |   0.051687  |    0.011717     |   2\n",
      "       7377 |   0.212921  |    0.026757     |   0\n",
      "       7378 |   0.189725  |    0.124871     |   1\n",
      "       7379 |   0.239079  |    0.081185     |   1\n",
      "       7380 |   0.196863  |    0.007296     |   0\n",
      "       7381 |   0.212170  |    0.157428     |   1\n",
      "       7382 |   0.221153  |    0.017564     |   0\n",
      "       7383 |   0.216491  |    0.082860     |   1\n",
      "       7384 |   0.246628  |    0.092632     |   1\n",
      "       7385 |   0.075869  |    0.009977     |   2\n",
      "       7386 |   0.063559  |    0.042255     |   2\n",
      "       7387 |   0.205253  |    0.013110     |   0\n",
      "       7388 |   0.189033  |    0.011189     |   0\n",
      "       7389 |   0.027626  |    0.034561     |   2\n",
      "       7390 |   0.064145  |    0.022170     |   2\n",
      "       7391 |   0.048568  |    0.032758     |   2\n",
      "       7392 |   0.284093  |    0.154156     |   1\n",
      "       7393 |   0.000098  |    0.002872     |   2\n",
      "       7394 |   0.000099  |    0.010698     |   2\n",
      "       7395 |   0.000103  |    0.048318     |   2\n",
      "       7396 |   0.000101  |    0.012826     |   2\n",
      "       7397 |   0.240191  |    0.148695     |   1\n",
      "       7398 |   0.287595  |    0.004914     |   0\n",
      "       7399 |   0.000100  |    0.023373     |   2\n",
      "       7400 |   0.000101  |    0.027133     |   2\n",
      "       7401 |   0.208673  |    0.133874     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 7404: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       7402 |   0.072895  |    0.004779     |   2\n",
      "       7403 |   0.069043  |    0.009181     |   2\n",
      "       7404 |   0.186567  |    0.046338     |   0\n",
      "       7405 |   0.073679  |    0.006603     |   2\n",
      "       7406 |   0.054672  |    0.041492     |   2\n",
      "       7407 |   0.057050  |    0.027000     |   2\n",
      "       7408 |   0.072913  |    0.027846     |   2\n",
      "       7409 |   0.342931  |    0.134347     |   1\n",
      "       7410 |   0.241793  |    0.004704     |   0\n",
      "       7411 |   0.198400  |    0.018756     |   0\n",
      "       7412 |   0.037456  |    0.025348     |   2\n",
      "       7413 |   0.193502  |    0.032525     |   0\n",
      "       7414 |   0.057965  |    0.025007     |   2\n",
      "       7415 |   0.231728  |    0.080489     |   1\n",
      "       7416 |   0.198060  |    0.012656     |   0\n",
      "       7417 |   0.227686  |    0.041718     |   0\n",
      "       7418 |   0.266195  |    0.143054     |   1\n",
      "       7419 |   0.205441  |    0.080996     |   1\n",
      "       7420 |   0.334550  |    0.021250     |   0\n",
      "       7421 |   0.203472  |    0.178013     |   1\n",
      "       7422 |   0.204469  |    0.016481     |   1\n",
      "       7423 |   0.067480  |    0.031949     |   2\n",
      "       7424 |   0.077379  |    0.032755     |   2\n",
      "       7425 |   0.251061  |    0.136833     |   1\n",
      "       7426 |   0.234338  |    0.006587     |   0\n",
      "       7427 |   0.067679  |    0.014776     |   2\n",
      "       7428 |   0.197685  |    0.131824     |   1\n",
      "       7429 |   0.166216  |    0.018263     |   0\n",
      "       7430 |   0.232001  |    0.141617     |   1\n",
      "       7431 |   0.330745  |    0.082412     |   1\n",
      "       7432 |   0.227911  |    0.012263     |   0\n",
      "       7433 |   0.235404  |    0.142501     |   1\n",
      "       7434 |   0.220287  |    0.083631     |   1\n",
      "       7435 |   0.218095  |    0.010636     |   0\n",
      "       7436 |   0.031652  |    0.007213     |   2\n",
      "       7437 |   0.229347  |    0.143920     |   1\n",
      "       7438 |   0.260349  |    0.081418     |   1\n",
      "       7439 |   0.171347  |    0.009650     |   0\n",
      "       7440 |   0.000096  |    0.028922     |   2\n",
      "       7441 |   0.257011  |    0.125786     |   1\n",
      "       7442 |   0.203787  |    0.081712     |   1\n",
      "       7443 |   0.007580  |    0.009941     |   2\n",
      "       7444 |   0.264010  |    0.133807     |   1\n",
      "       7445 |   0.108275  |    0.013078     |   2\n",
      "       7446 |   0.264448  |    0.035832     |   0\n",
      "       7447 |   0.210290  |    0.095040     |   1\n",
      "       7448 |   0.219204  |    0.019261     |   0\n",
      "       7449 |   0.352659  |    0.092499     |   1\n",
      "       7450 |   0.048834  |    0.007544     |   2\n",
      "       7451 |   0.261678  |    0.147900     |   1\n",
      "       7452 |   0.297001  |    0.095233     |   1\n",
      "       7453 |   0.214041  |    0.147006     |   1\n",
      "       7454 |   0.074414  |    0.014062     |   2\n",
      "       7455 |   0.256018  |    0.085248     |   1\n",
      "       7456 |   0.288876  |    0.085562     |   1\n",
      "       7457 |   0.250952  |    0.039942     |   0\n",
      "       7458 |   0.061404  |    0.044733     |   2\n",
      "       7459 |   0.260074  |    0.132877     |   1\n",
      "       7460 |   0.211406  |    0.007817     |   0\n",
      "       7461 |   0.026884  |    0.011953     |   2\n",
      "       7462 |   0.250410  |    0.139596     |   1\n",
      "       7463 |   0.298916  |    0.031255     |   0\n",
      "       7464 |   0.056785  |    0.025919     |   2\n",
      "       7465 |   0.227956  |    0.049284     |   0\n",
      "       7466 |   0.047543  |    0.022203     |   2\n",
      "       7467 |   0.203377  |    0.145232     |   1\n",
      "       7468 |   0.260681  |    0.094956     |   1\n",
      "       7469 |   0.000095  |    0.018452     |   2\n",
      "       7470 |   0.000096  |    0.042561     |   2\n",
      "       7471 |   0.000101  |    0.009357     |   2\n",
      "       7472 |   0.253507  |    0.151825     |   1\n",
      "       7473 |   0.202868  |    0.093655     |   1\n",
      "       7474 |   0.000098  |    0.010326     |   2\n",
      "       7475 |   0.000097  |    0.040096     |   2\n",
      "       7476 |   0.241931  |    0.091482     |   1\n",
      "       7477 |   0.257478  |    0.092543     |   1\n",
      "       7478 |   0.253624  |    0.075525     |   1\n",
      "       7479 |   0.000098  |    0.007743     |   2\n",
      "       7480 |   0.205039  |    0.049577     |   0\n",
      "       7481 |   0.227804  |    0.011624     |   0\n",
      "       7482 |   0.069786  |    0.049169     |   2\n",
      "       7483 |   0.234887  |    0.098156     |   1\n",
      "       7484 |   0.224128  |    0.077481     |   1\n",
      "       7485 |   0.248734  |    0.012813     |   0\n",
      "       7486 |   0.066410  |    0.034665     |   2\n",
      "       7487 |   0.286641  |    0.139788     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 7488: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       7488 |   0.226833  |    0.076373     |   1\n",
      "       7489 |   0.072568  |    0.005083     |   2\n",
      "       7490 |   0.056717  |    0.026222     |   2\n",
      "       7491 |   0.208577  |    0.037740     |   0\n",
      "       7492 |   0.175525  |    0.008026     |   0\n",
      "       7493 |   0.054500  |    0.039146     |   2\n",
      "       7494 |   0.238785  |    0.043107     |   0\n",
      "       7495 |   0.231851  |    0.024039     |   0\n",
      "       7496 |   0.240295  |    0.098446     |   1\n",
      "       7497 |   0.072742  |    0.015336     |   2\n",
      "       7498 |   0.037045  |    0.044511     |   2\n",
      "       7499 |   0.056657  |    0.016874     |   2\n",
      "       7500 |   0.063575  |    0.036879     |   2\n",
      "       7501 |   0.070889  |    0.052421     |   2\n",
      "       7502 |   0.276182  |    0.028443     |   0\n",
      "       7503 |   0.240434  |    0.026315     |   0\n",
      "       7504 |   0.217502  |    0.035227     |   0\n",
      "       7505 |   0.269733  |    0.090388     |   1\n",
      "       7506 |   0.162992  |    0.015638     |   0\n",
      "       7507 |   0.207480  |    0.046524     |   0\n",
      "       7508 |   0.055328  |    0.009827     |   2\n",
      "       7509 |   0.239919  |    0.138976     |   1\n",
      "       7510 |   0.259283  |    0.060996     |   1\n",
      "       7511 |   0.266999  |    0.023750     |   0\n",
      "       7512 |   0.053107  |    0.046207     |   2\n",
      "       7513 |   0.239096  |    0.009072     |   0\n",
      "       7514 |   0.073830  |    0.048739     |   2\n",
      "       7515 |   0.036879  |    0.008369     |   2\n",
      "       7516 |   0.213728  |    0.042821     |   0\n",
      "       7517 |   0.178093  |    0.094903     |   1\n",
      "       7518 |   0.056647  |    0.020716     |   2\n",
      "       7519 |   0.212471  |    0.038999     |   0\n",
      "       7520 |   0.273146  |    0.016351     |   0\n",
      "       7521 |   0.290676  |    0.043150     |   0\n",
      "       7522 |   0.063358  |    0.015009     |   2\n",
      "       7523 |   0.213972  |    0.127034     |   1\n",
      "       7524 |   0.271054  |    0.017344     |   0\n",
      "       7525 |   0.078725  |    0.044782     |   2\n",
      "       7526 |   0.072585  |    0.010690     |   2\n",
      "       7527 |   0.033616  |    0.049017     |   2\n",
      "       7528 |   0.000094  |    0.005989     |   2\n",
      "       7529 |   0.216803  |    0.041940     |   0\n",
      "       7530 |   0.203375  |    0.040138     |   0\n",
      "       7531 |   0.235927  |    0.105786     |   1\n",
      "       7532 |   0.006885  |    0.027191     |   2\n",
      "       7533 |   0.249451  |    0.098622     |   1\n",
      "       7534 |   0.221392  |    0.084367     |   1\n",
      "       7535 |   0.176273  |    0.016991     |   0\n",
      "       7536 |   0.182750  |    0.048551     |   0\n",
      "       7537 |   0.224962  |    0.008406     |   0\n",
      "       7538 |   0.178813  |    0.045246     |   0\n",
      "       7539 |   0.161434  |    0.016034     |   0\n",
      "       7540 |   0.255583  |    0.054751     |   0\n",
      "       7541 |   0.106373  |    0.009370     |   2\n",
      "       7542 |   0.049821  |    0.046812     |   2\n",
      "       7543 |   0.197264  |    0.012325     |   0\n",
      "       7544 |   0.190052  |    0.034314     |   0\n",
      "       7545 |   0.227098  |    0.135636     |   1\n",
      "       7546 |   0.212902  |    0.007444     |   0\n",
      "       7547 |   0.264502  |    0.095077     |   1\n",
      "       7548 |   0.075111  |    0.015355     |   2\n",
      "       7549 |   0.243542  |    0.118309     |   1\n",
      "       7550 |   0.265180  |    0.105749     |   1\n",
      "       7551 |   0.062129  |    0.005139     |   2\n",
      "       7552 |   0.162647  |    0.044336     |   0\n",
      "       7553 |   0.289329  |    0.092739     |   1\n",
      "       7554 |   0.261936  |    0.108547     |   1\n",
      "       7555 |   0.215896  |    0.085303     |   1\n",
      "       7556 |   0.028765  |    0.023012     |   2\n",
      "       7557 |   0.229980  |    0.047457     |   0\n",
      "       7558 |   0.062340  |    0.016888     |   2\n",
      "       7559 |   0.234806  |    0.026140     |   0\n",
      "       7560 |   0.208463  |    0.055272     |   0\n",
      "       7561 |   0.232335  |    0.009556     |   0\n",
      "       7562 |   0.048153  |    0.034953     |   2\n",
      "       7563 |   0.323939  |    0.084370     |   1\n",
      "       7564 |   0.247439  |    0.136709     |   1\n",
      "       7565 |   0.263598  |    0.084181     |   1\n",
      "       7566 |   0.164054  |    0.090661     |   1\n",
      "       7567 |   0.000095  |    0.016318     |   2\n",
      "       7568 |   0.168223  |    0.011042     |   0\n",
      "       7569 |   0.000095  |    0.047370     |   2\n",
      "       7570 |   0.275198  |    0.097699     |   1\n",
      "       7571 |   0.000099  |    0.017994     |   2\n",
      "       7572 |   0.277244  |    0.150034     |   1\n",
      "       7573 |   0.268305  |    0.081558     |   1\n",
      "       7574 |   0.000097  |    0.005683     |   2\n",
      "       7575 |   0.170898  |    0.028068     |   0\n",
      "       7576 |   0.000097  |    0.035173     |   2\n",
      "       7577 |   0.220637  |    0.022833     |   0\n",
      "       7578 |   0.183517  |    0.147269     |   1\n",
      "       7579 |   0.231441  |    0.083342     |   1\n",
      "       7580 |   0.223024  |    0.013918     |   0\n",
      "       7581 |   0.000098  |    0.032734     |   2\n",
      "       7582 |   0.249680  |    0.130675     |   1\n",
      "       7583 |   0.311417  |    0.009506     |   0\n",
      "       7584 |   0.072026  |    0.030846     |   2\n",
      "       7585 |   0.176472  |    0.031412     |   0\n",
      "       7586 |   0.068976  |    0.014537     |   2\n",
      "       7587 |   0.305422  |    0.152749     |   1\n",
      "       7588 |   0.204696  |    0.048729     |   1\n",
      "       7589 |   0.206737  |    0.011952     |   0\n",
      "       7590 |   0.187486  |    0.039924     |   0\n",
      "       7591 |   0.201364  |    0.025057     |   0\n",
      "       7592 |   0.283874  |    0.050374     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 7593: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       7593 |   0.266793  |    0.017023     |   0\n",
      "       7594 |   0.229164  |    0.139302     |   1\n",
      "       7595 |   0.075655  |    0.005324     |   2\n",
      "       7596 |   0.058238  |    0.045719     |   2\n",
      "       7597 |   0.261313  |    0.028013     |   0\n",
      "       7598 |   0.244676  |    0.135271     |   1\n",
      "       7599 |   0.055906  |    0.004935     |   2\n",
      "       7600 |   0.210461  |    0.018028     |   0\n",
      "       7601 |   0.073699  |    0.047399     |   2\n",
      "       7602 |   0.241005  |    0.013889     |   0\n",
      "       7603 |   0.037464  |    0.039661     |   2\n",
      "       7604 |   0.059170  |    0.011840     |   2\n",
      "       7605 |   0.065883  |    0.047899     |   2\n",
      "       7606 |   0.226951  |    0.011491     |   0\n",
      "       7607 |   0.293413  |    0.159130     |   1\n",
      "       7608 |   0.283838  |    0.084628     |   1\n",
      "       7609 |   0.228541  |    0.009101     |   0\n",
      "       7610 |   0.188157  |    0.092945     |   1\n",
      "       7611 |   0.276408  |    0.136376     |   1\n",
      "       7612 |   0.234354  |    0.003153     |   0\n",
      "       7613 |   0.078905  |    0.011775     |   2\n",
      "       7614 |   0.200839  |    0.029608     |   0\n",
      "       7615 |   0.077285  |    0.028721     |   2\n",
      "       7616 |   0.036309  |    0.031922     |   2\n",
      "       7617 |   0.248084  |    0.044887     |   0\n",
      "       7618 |   0.000093  |    0.015490     |   2\n",
      "       7619 |   0.252383  |    0.033121     |   0\n",
      "       7620 |   0.007653  |    0.022704     |   2\n",
      "       7621 |   0.163617  |    0.028476     |   0\n",
      "       7622 |   0.106187  |    0.014513     |   2\n",
      "       7623 |   0.051438  |    0.045872     |   2\n",
      "       7624 |   0.215957  |    0.015893     |   0\n",
      "       7625 |   0.074786  |    0.047982     |   2\n",
      "       7626 |   0.061554  |    0.006348     |   2\n",
      "       7627 |   0.284417  |    0.045619     |   0\n",
      "       7628 |   0.028953  |    0.009715     |   2\n",
      "       7629 |   0.064256  |    0.032949     |   2\n",
      "       7630 |   0.200467  |    0.050277     |   0\n",
      "       7631 |   0.045843  |    0.014270     |   2\n",
      "       7632 |   0.248689  |    0.143004     |   1\n",
      "       7633 |   0.000092  |    0.007395     |   2\n",
      "       7634 |   0.272314  |    0.088142     |   1\n",
      "       7635 |   0.000093  |    0.009267     |   2\n",
      "       7636 |   0.306157  |    0.048479     |   0\n",
      "       7637 |   0.213193  |    0.007931     |   0\n",
      "       7638 |   0.227978  |    0.053943     |   0\n",
      "       7639 |   0.000096  |    0.018545     |   2\n",
      "       7640 |   0.267802  |    0.142534     |   1\n",
      "       7641 |   0.000095  |    0.005318     |   2\n",
      "       7642 |   0.225156  |    0.015407     |   0\n",
      "       7643 |   0.217751  |    0.034735     |   0\n",
      "       7644 |   0.245239  |    0.137375     |   1\n",
      "       7645 |   0.236685  |    0.055170     |   1\n",
      "       7646 |   0.000094  |    0.006007     |   2\n",
      "       7647 |   0.223873  |    0.050331     |   0\n",
      "       7648 |   0.000095  |    0.009766     |   2\n",
      "       7649 |   0.079818  |    0.047096     |   2\n",
      "       7650 |   0.069154  |    0.011957     |   2\n",
      "       7651 |   0.255089  |    0.139876     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 7652: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       7652 |   0.075091  |    0.010693     |   2\n",
      "       7653 |   0.254053  |    0.026495     |   1\n",
      "       7654 |   0.233262  |    0.044382     |   0\n",
      "       7655 |   0.304586  |    0.086135     |   1\n",
      "       7656 |   0.245410  |    0.036507     |   0\n",
      "       7657 |   0.227210  |    0.131453     |   1\n",
      "       7658 |   0.276164  |    0.002938     |   0\n",
      "       7659 |   0.213087  |    0.016721     |   0\n",
      "       7660 |   0.230681  |    0.164491     |   1\n",
      "       7661 |   0.231121  |    0.056452     |   1\n",
      "       7662 |   0.222231  |    0.102968     |   1\n",
      "       7663 |   0.278224  |    0.095942     |   1\n",
      "       7664 |   0.054813  |    0.013834     |   2\n",
      "       7665 |   0.233608  |    0.137894     |   1\n",
      "       7666 |   0.228833  |    0.005658     |   0\n",
      "       7667 |   0.056175  |    0.044323     |   2\n",
      "       7668 |   0.075119  |    0.050748     |   2\n",
      "       7669 |   0.260038  |    0.138681     |   1\n",
      "       7670 |   0.190586  |    0.081505     |   1\n",
      "       7671 |   0.036030  |    0.005670     |   2\n",
      "       7672 |   0.252283  |    0.137698     |   1\n",
      "       7673 |   0.058415  |    0.002950     |   2\n",
      "       7674 |   0.256535  |    0.007681     |   0\n",
      "       7675 |   0.232241  |    0.061800     |   0\n",
      "       7676 |   0.190870  |    0.081678     |   1\n",
      "       7677 |   0.208927  |    0.017324     |   0\n",
      "       7678 |   0.062774  |    0.031065     |   2\n",
      "       7679 |   0.076345  |    0.021313     |   2\n",
      "       7680 |   0.069703  |    0.027598     |   2\n",
      "       7681 |   0.244944  |    0.140809     |   1\n",
      "       7682 |   0.268647  |    0.089018     |   1\n",
      "       7683 |   0.180091  |    0.008480     |   0\n",
      "       7684 |   0.034065  |    0.009643     |   2\n",
      "       7685 |   0.199535  |    0.044017     |   0\n",
      "       7686 |   0.204846  |    0.011530     |   0\n",
      "       7687 |   0.259120  |    0.045536     |   0\n",
      "       7688 |   0.247267  |    0.025810     |   0\n",
      "       7689 |   0.194439  |    0.136217     |   1\n",
      "       7690 |   0.000093  |    0.005467     |   2\n",
      "       7691 |   0.265361  |    0.023856     |   0\n",
      "       7692 |   0.007576  |    0.027250     |   2\n",
      "       7693 |   0.103702  |    0.023329     |   2\n",
      "       7694 |   0.049681  |    0.034993     |   2\n",
      "       7695 |   0.072217  |    0.020614     |   2\n",
      "       7696 |   0.190888  |    0.153145     |   1\n",
      "       7697 |   0.177649  |    0.003043     |   0\n",
      "       7698 |   0.250214  |    0.010937     |   0\n",
      "       7699 |   0.220539  |    0.134204     |   1\n",
      "       7700 |   0.061917  |    0.013703     |   2\n",
      "       7701 |   0.208712  |    0.039360     |   0\n",
      "       7702 |   0.028745  |    0.006357     |   2\n",
      "       7703 |   0.200402  |    0.046958     |   0\n",
      "       7704 |   0.268548  |    0.099007     |   1\n",
      "       7705 |   0.061151  |    0.014964     |   2\n",
      "       7706 |   0.197391  |    0.147471     |   1\n",
      "       7707 |   0.048770  |    0.005039     |   2\n",
      "       7708 |   0.000092  |    0.010021     |   2\n",
      "       7709 |   0.000092  |    0.044059     |   2\n",
      "       7710 |   0.295559  |    0.021049     |   0\n",
      "       7711 |   0.217651  |    0.157556     |   1\n",
      "       7712 |   0.254535  |    0.018978     |   1\n",
      "       7713 |   0.116434  |    0.134947     |   1\n",
      "       7714 |   0.000095  |    0.008139     |   2\n",
      "       7715 |   0.189653  |    0.028403     |   0\n",
      "       7716 |   0.000094  |    0.043714     |   2\n",
      "       7717 |   0.000093  |    0.007811     |   2\n",
      "       7718 |   0.204525  |    0.141515     |   1\n",
      "       7719 |   0.000093  |    0.009782     |   2\n",
      "       7720 |   0.074156  |    0.030532     |   2\n",
      "       7721 |   0.247187  |    0.093415     |   1\n",
      "       7722 |   0.233963  |    0.012757     |   0\n",
      "       7723 |   0.069049  |    0.031501     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 7724: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       7724 |   0.072537  |    0.027646     |   2\n",
      "       7725 |   0.215206  |    0.146448     |   1\n",
      "       7726 |   0.250853  |    0.080803     |   1\n",
      "       7727 |   0.055100  |    0.007949     |   2\n",
      "       7728 |   0.219271  |    0.023791     |   0\n",
      "       7729 |   0.183845  |    0.023782     |   0\n",
      "       7730 |   0.056291  |    0.029522     |   2\n",
      "       7731 |   0.252703  |    0.048148     |   0\n",
      "       7732 |   0.221358  |    0.106599     |   1\n",
      "       7733 |   0.186635  |    0.007690     |   0\n",
      "       7734 |   0.074120  |    0.007443     |   2\n",
      "       7735 |   0.241913  |    0.054870     |   0\n",
      "       7736 |   0.260093  |    0.011281     |   0\n",
      "       7737 |   0.037166  |    0.050537     |   2\n",
      "       7738 |   0.055922  |    0.005787     |   2\n",
      "       7739 |   0.064165  |    0.045035     |   2\n",
      "       7740 |   0.074975  |    0.021797     |   2\n",
      "       7741 |   0.293702  |    0.147721     |   1\n",
      "       7742 |   0.273111  |    0.089272     |   1\n",
      "       7743 |   0.066655  |    0.012058     |   2\n",
      "       7744 |   0.237888  |    0.076428     |   1\n",
      "       7745 |   0.169739  |    0.017296     |   0\n",
      "       7746 |   0.031826  |    0.041301     |   2\n",
      "       7747 |   0.171484  |    0.013793     |   0\n",
      "       7748 |   0.292901  |    0.144435     |   1\n",
      "       7749 |   0.188243  |    0.099497     |   1\n",
      "       7750 |   0.240693  |    0.039483     |   1\n",
      "       7751 |   0.205218  |    0.143141     |   1\n",
      "       7752 |   0.215468  |    0.080560     |   1\n",
      "       7753 |   0.267402  |    0.009577     |   0\n",
      "       7754 |   0.000091  |    0.041859     |   2\n",
      "       7755 |   0.007279  |    0.007887     |   2\n",
      "       7756 |   0.104923  |    0.054551     |   2\n",
      "       7757 |   0.050658  |    0.009844     |   2\n",
      "       7758 |   0.070607  |    0.039420     |   2\n",
      "       7759 |   0.058618  |    0.014916     |   2\n",
      "       7760 |   0.257108  |    0.113050     |   1\n",
      "       7761 |   0.213184  |    0.030424     |   0\n",
      "       7762 |   0.026306  |    0.025468     |   2\n",
      "       7763 |   0.236020  |    0.027861     |   0\n",
      "       7764 |   0.273400  |    0.050600     |   0\n",
      "       7765 |   0.280798  |    0.078715     |   1\n",
      "       7766 |   0.194879  |    0.017197     |   0\n",
      "       7767 |   0.059836  |    0.047087     |   2\n",
      "       7768 |   0.045807  |    0.011059     |   2\n",
      "       7769 |   0.000090  |    0.044189     |   2\n",
      "       7770 |   0.202578  |    0.133001     |   1\n",
      "       7771 |   0.233855  |    0.098714     |   1\n",
      "       7772 |   0.222330  |    0.091433     |   1\n",
      "       7773 |   0.253401  |    0.011432     |   0\n",
      "       7774 |   0.201443  |    0.042750     |   0\n",
      "       7775 |   0.157478  |    0.145628     |   1\n",
      "       7776 |   0.273030  |    0.051060     |   1\n",
      "       7777 |   0.219299  |    0.019978     |   0\n",
      "       7778 |   0.000091  |    0.027107     |   2\n",
      "       7779 |   0.000095  |    0.027623     |   2\n",
      "       7780 |   0.363461  |    0.160397     |   1\n",
      "       7781 |   0.222287  |    0.010443     |   0\n",
      "       7782 |   0.248952  |    0.082561     |   1\n",
      "       7783 |   0.193784  |    0.008920     |   0\n",
      "       7784 |   0.282566  |    0.149908     |   1\n",
      "       7785 |   0.286919  |    0.051097     |   1\n",
      "       7786 |   0.230020  |    0.147867     |   1\n",
      "       7787 |   0.264349  |    0.069149     |   1\n",
      "       7788 |   0.211218  |    0.093881     |   1\n",
      "       7789 |   0.244634  |    0.007570     |   0\n",
      "       7790 |   0.213514  |    0.027376     |   0\n",
      "       7791 |   0.185193  |    0.047646     |   0\n",
      "       7792 |   0.000093  |    0.007933     |   2\n",
      "       7793 |   0.248323  |    0.045480     |   0\n",
      "       7794 |   0.284399  |    0.024432     |   0\n",
      "       7795 |   0.000092  |    0.033166     |   2\n",
      "       7796 |   0.227870  |    0.017024     |   0\n",
      "       7797 |   0.271148  |    0.046621     |   0\n",
      "       7798 |   0.264035  |    0.132642     |   1\n",
      "       7799 |   0.000092  |    0.003608     |   2\n",
      "       7800 |   0.213677  |    0.010195     |   0\n",
      "       7801 |   0.072639  |    0.045009     |   2\n",
      "       7802 |   0.067778  |    0.010379     |   2\n",
      "       7803 |   0.202619  |    0.175942     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 7804: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       7804 |   0.379871  |    0.013727     |   1\n",
      "       7805 |   0.274093  |    0.140753     |   1\n",
      "       7806 |   0.071406  |    0.003087     |   2\n",
      "       7807 |   0.057210  |    0.007844     |   2\n",
      "       7808 |   0.233403  |    0.135503     |   1\n",
      "       7809 |   0.056233  |    0.008330     |   2\n",
      "       7810 |   0.263210  |    0.131328     |   1\n",
      "       7811 |   0.074816  |    0.003987     |   2\n",
      "       7812 |   0.037051  |    0.029573     |   2\n",
      "       7813 |   0.227286  |    0.149510     |   1\n",
      "       7814 |   0.058213  |    0.006972     |   2\n",
      "       7815 |   0.206733  |    0.011701     |   0\n",
      "       7816 |   0.194982  |    0.028363     |   0\n",
      "       7817 |   0.062918  |    0.023564     |   2\n",
      "       7818 |   0.075498  |    0.068906     |   2\n",
      "       7819 |   0.216911  |    0.066282     |   1\n",
      "       7820 |   0.208507  |    0.006809     |   0\n",
      "       7821 |   0.068208  |    0.048785     |   2\n",
      "       7822 |   0.276993  |    0.100842     |   1\n",
      "       7823 |   0.285793  |    0.086125     |   1\n",
      "       7824 |   0.030895  |    0.012427     |   2\n",
      "       7825 |   0.265734  |    0.151780     |   1\n",
      "       7826 |   0.000090  |    0.007511     |   2\n",
      "       7827 |   0.237653  |    0.135147     |   1\n",
      "       7828 |   0.007144  |    0.009158     |   2\n",
      "       7829 |   0.185477  |    0.077835     |   1\n",
      "       7830 |   0.247853  |    0.089702     |   1\n",
      "       7831 |   0.105393  |    0.008709     |   2\n",
      "       7832 |   0.189387  |    0.048171     |   0\n",
      "       7833 |   0.242055  |    0.082961     |   1\n",
      "       7834 |   0.216527  |    0.045814     |   0\n",
      "       7835 |   0.216754  |    0.014715     |   0\n",
      "       7836 |   0.290608  |    0.045005     |   0\n",
      "       7837 |   0.242427  |    0.020998     |   0\n",
      "       7838 |   0.047973  |    0.026201     |   2\n",
      "       7839 |   0.229032  |    0.023831     |   0\n",
      "       7840 |   0.251929  |    0.048688     |   0\n",
      "       7841 |   0.222812  |    0.078776     |   1\n",
      "       7842 |   0.071551  |    0.020812     |   2\n",
      "       7843 |   0.230830  |    0.143780     |   1\n",
      "       7844 |   0.221046  |    0.008045     |   0\n",
      "       7845 |   0.201831  |    0.017014     |   0\n",
      "       7846 |   0.171639  |    0.032865     |   0\n",
      "       7847 |   0.207552  |    0.166052     |   1\n",
      "       7848 |   0.061606  |    0.008269     |   2\n",
      "       7849 |   0.239309  |    0.083726     |   1\n",
      "       7850 |   0.242594  |    0.079221     |   1\n",
      "       7851 |   0.025781  |    0.023758     |   2\n",
      "       7852 |   0.267127  |    0.047663     |   0\n",
      "       7853 |   0.230091  |    0.132153     |   1\n",
      "       7854 |   0.231443  |    0.082033     |   1\n",
      "       7855 |   0.244573  |    0.015335     |   0\n",
      "       7856 |   0.186118  |    0.090212     |   1\n",
      "       7857 |   0.060907  |    0.024845     |   2\n",
      "       7858 |   0.045703  |    0.047189     |   2\n",
      "       7859 |   0.000089  |    0.014165     |   2\n",
      "       7860 |   0.265058  |    0.044930     |   0\n",
      "       7861 |   0.224183  |    0.105129     |   1\n",
      "       7862 |   0.197053  |    0.087915     |   1\n",
      "       7863 |   0.234339  |    0.029178     |   0\n",
      "       7864 |   0.000089  |    0.031887     |   2\n",
      "       7865 |   0.224365  |    0.019925     |   0\n",
      "       7866 |   0.000092  |    0.029296     |   2\n",
      "       7867 |   0.258161  |    0.176039     |   1\n",
      "       7868 |   0.202808  |    0.033405     |   1\n",
      "       7869 |   0.000091  |    0.041105     |   2\n",
      "       7870 |   0.274176  |    0.012066     |   0\n",
      "       7871 |   0.222406  |    0.042051     |   0\n",
      "       7872 |   0.217021  |    0.129655     |   1\n",
      "       7873 |   0.000090  |    0.004704     |   2\n",
      "       7874 |   0.197656  |    0.013310     |   0\n",
      "       7875 |   0.289931  |    0.136134     |   1\n",
      "       7876 |   0.000091  |    0.005421     |   2\n",
      "       7877 |   0.070674  |    0.025731     |   2\n",
      "       7878 |   0.065288  |    0.047900     |   2\n",
      "       7879 |   0.205577  |    0.087093     |   1\n",
      "       7880 |   0.251860  |    0.015981     |   0\n",
      "       7881 |   0.231454  |    0.061227     |   0\n",
      "       7882 |   0.191204  |    0.075804     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 7884: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       7883 |   0.166994  |    0.011031     |   0\n",
      "       7884 |   0.285425  |    0.048176     |   0\n",
      "       7885 |   0.075478  |    0.014016     |   2\n",
      "       7886 |   0.059407  |    0.057525     |   2\n",
      "       7887 |   0.273192  |    0.056620     |   1\n",
      "       7888 |   0.056150  |    0.015472     |   2\n",
      "       7889 |   0.204686  |    0.047181     |   0\n",
      "       7890 |   0.077741  |    0.008735     |   2\n",
      "       7891 |   0.201843  |    0.048679     |   0\n",
      "       7892 |   0.037450  |    0.008117     |   2\n",
      "       7893 |   0.056578  |    0.047587     |   2\n",
      "       7894 |   0.232130  |    0.019046     |   0\n",
      "       7895 |   0.213087  |    0.043623     |   0\n",
      "       7896 |   0.275629  |    0.084662     |   1\n",
      "       7897 |   0.065042  |    0.013897     |   2\n",
      "       7898 |   0.219131  |    0.050026     |   0\n",
      "       7899 |   0.197796  |    0.004980     |   0\n",
      "       7900 |   0.183578  |    0.033331     |   0\n",
      "       7901 |   0.189197  |    0.126629     |   1\n",
      "       7902 |   0.241456  |    0.009488     |   0\n",
      "       7903 |   0.270484  |    0.013981     |   0\n",
      "       7904 |   0.261397  |    0.145979     |   1\n",
      "       7905 |   0.249225  |    0.007251     |   0\n",
      "       7906 |   0.223564  |    0.091450     |   1\n",
      "       7907 |   0.075251  |    0.015317     |   2\n",
      "       7908 |   0.070961  |    0.026220     |   2\n",
      "       7909 |   0.031622  |    0.038686     |   2\n",
      "       7910 |   0.231279  |    0.048524     |   0\n",
      "       7911 |   0.261435  |    0.126587     |   1\n",
      "       7912 |   0.208909  |    0.011721     |   0\n",
      "       7913 |   0.000089  |    0.019049     |   2\n",
      "       7914 |   0.186380  |    0.021060     |   0\n",
      "       7915 |   0.189122  |    0.043037     |   0\n",
      "       7916 |   0.189152  |    0.022511     |   0\n",
      "       7917 |   0.178377  |    0.023141     |   0\n",
      "       7918 |   0.242936  |    0.035384     |   0\n",
      "       7919 |   0.006957  |    0.019247     |   2\n",
      "       7920 |   0.104637  |    0.040344     |   2\n",
      "       7921 |   0.248022  |    0.138630     |   1\n",
      "       7922 |   0.051296  |    0.003921     |   2\n",
      "       7923 |   0.074031  |    0.005476     |   2\n",
      "       7924 |   0.062630  |    0.064742     |   2\n",
      "       7925 |   0.193152  |    0.079390     |   1\n",
      "       7926 |   0.028063  |    0.010208     |   2\n",
      "       7927 |   0.234639  |    0.134174     |   1\n",
      "       7928 |   0.241515  |    0.005995     |   0\n",
      "       7929 |   0.257592  |    0.042748     |   0\n",
      "       7930 |   0.062737  |    0.023864     |   2\n",
      "       7931 |   0.291517  |    0.142437     |   1\n",
      "       7932 |   0.205956  |    0.007340     |   0\n",
      "       7933 |   0.258567  |    0.010510     |   0\n",
      "       7934 |   0.048685  |    0.033015     |   2\n",
      "       7935 |   0.000089  |    0.009583     |   2\n",
      "       7936 |   0.224695  |    0.045699     |   0\n",
      "       7937 |   0.000089  |    0.006267     |   2\n",
      "       7938 |   0.258215  |    0.051776     |   0\n",
      "       7939 |   0.225189  |    0.015810     |   0\n",
      "       7940 |   0.215174  |    0.042040     |   0\n",
      "       7941 |   0.248449  |    0.026801     |   0\n",
      "       7942 |   0.178685  |    0.028705     |   0\n",
      "       7943 |   0.000090  |    0.007493     |   2\n",
      "       7944 |   0.199838  |    0.032718     |   0\n",
      "       7945 |   0.223774  |    0.029145     |   0\n",
      "       7946 |   0.251762  |    0.068550     |   0\n",
      "       7947 |   0.238022  |    0.104659     |   1\n",
      "       7948 |   0.269437  |    0.090055     |   1\n",
      "       7949 |   0.203296  |    0.062665     |   1\n",
      "       7950 |   0.203154  |    0.016564     |   0\n",
      "       7951 |   0.000091  |    0.045113     |   2\n",
      "       7952 |   0.200370  |    0.008442     |   0\n",
      "       7953 |   0.000090  |    0.050593     |   2\n",
      "       7954 |   0.204965  |    0.021255     |   0\n",
      "       7955 |   0.000090  |    0.046938     |   2\n",
      "       7956 |   0.081180  |    0.007883     |   2\n",
      "       7957 |   0.068651  |    0.051571     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 7958: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       7958 |   0.080320  |    0.011611     |   2\n",
      "       7959 |   0.060590  |    0.045103     |   2\n",
      "       7960 |   0.056455  |    0.005731     |   2\n",
      "       7961 |   0.075757  |    0.054028     |   2\n",
      "       7962 |   0.273441  |    0.090571     |   1\n",
      "       7963 |   0.205267  |    0.029027     |   0\n",
      "       7964 |   0.200772  |    0.046266     |   0\n",
      "       7965 |   0.038513  |    0.010644     |   2\n",
      "       7966 |   0.056889  |    0.052583     |   2\n",
      "       7967 |   0.068649  |    0.012138     |   2\n",
      "       7968 |   0.264603  |    0.152289     |   1\n",
      "       7969 |   0.264222  |    0.084960     |   1\n",
      "       7970 |   0.078016  |    0.008328     |   2\n",
      "       7971 |   0.183654  |    0.049913     |   0\n",
      "       7972 |   0.064773  |    0.007912     |   2\n",
      "       7973 |   0.219207  |    0.138331     |   1\n",
      "       7974 |   0.230589  |    0.083392     |   1\n",
      "       7975 |   0.249872  |    0.081164     |   1\n",
      "       7976 |   0.030117  |    0.047079     |   2\n",
      "       7977 |   0.000090  |    0.009031     |   2\n",
      "       7978 |   0.008131  |    0.057721     |   2\n",
      "       7979 |   0.244217  |    0.081984     |   1\n",
      "       7980 |   0.192218  |    0.010021     |   0\n",
      "       7981 |   0.104741  |    0.036979     |   2\n",
      "       7982 |   0.048855  |    0.014071     |   2\n",
      "       7983 |   0.192372  |    0.138849     |   1\n",
      "       7984 |   0.214822  |    0.009636     |   0\n",
      "       7985 |   0.216411  |    0.096980     |   1\n",
      "       7986 |   0.071321  |    0.045499     |   2\n",
      "       7987 |   0.217321  |    0.013828     |   0\n",
      "       7988 |   0.204906  |    0.033389     |   0\n",
      "       7989 |   0.242998  |    0.039079     |   0\n",
      "       7990 |   0.167887  |    0.141180     |   1\n",
      "       7991 |   0.326774  |    0.061581     |   1\n",
      "       7992 |   0.226693  |    0.012232     |   0\n",
      "       7993 |   0.251251  |    0.153161     |   1\n",
      "       7994 |   0.268960  |    0.028842     |   1\n",
      "       7995 |   0.059831  |    0.034304     |   2\n",
      "       7996 |   0.317231  |    0.083547     |   1\n",
      "       7997 |   0.025477  |    0.016119     |   2\n",
      "       7998 |   0.226634  |    0.149216     |   1\n",
      "       7999 |   0.295624  |    0.032149     |   1\n",
      "       8000 |   0.226424  |    0.041764     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 8000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 8000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       8001 |   0.241816  |    0.156167     |   1\n",
      "       8002 |   0.261600  |    0.009158     |   0\n",
      "       8003 |   0.272519  |    0.023405     |   0\n",
      "       8004 |   0.230635  |    0.150868     |   1\n",
      "       8005 |   0.211584  |    0.004185     |   0\n",
      "       8006 |   0.225610  |    0.012925     |   0\n",
      "       8007 |   0.264086  |    0.048694     |   0\n",
      "       8008 |   0.217593  |    0.018552     |   0\n",
      "       8009 |   0.245580  |    0.173637     |   1\n",
      "       8010 |   0.071996  |    0.032296     |   2\n",
      "       8011 |   0.281176  |    0.026853     |   1\n",
      "       8012 |   0.187447  |    0.094390     |   1\n",
      "       8013 |   0.317137  |    0.085864     |   1\n",
      "       8014 |   0.209362  |    0.111258     |   1\n",
      "       8015 |   0.246464  |    0.057216     |   1\n",
      "       8016 |   0.054455  |    0.016647     |   2\n",
      "       8017 |   0.208988  |    0.046013     |   0\n",
      "       8018 |   0.204124  |    0.008712     |   0\n",
      "       8019 |   0.315309  |    0.045588     |   0\n",
      "       8020 |   0.056090  |    0.017722     |   2\n",
      "       8021 |   0.072792  |    0.047748     |   2\n",
      "       8022 |   0.184332  |    0.087091     |   1\n",
      "       8023 |   0.035504  |    0.016553     |   2\n",
      "       8024 |   0.234883  |    0.037923     |   0\n",
      "       8025 |   0.204657  |    0.140315     |   1\n",
      "       8026 |   0.312078  |    0.056750     |   1\n",
      "       8027 |   0.226836  |    0.153635     |   1\n",
      "       8028 |   0.190291  |    0.053036     |   1\n",
      "       8029 |   0.054909  |    0.022694     |   2\n",
      "       8030 |   0.064025  |    0.036465     |   2\n",
      "       8031 |   0.242040  |    0.093666     |   1\n",
      "       8032 |   0.074051  |    0.020464     |   2\n",
      "       8033 |   0.064841  |    0.034122     |   2\n",
      "       8034 |   0.230403  |    0.034973     |   0\n",
      "       8035 |   0.237747  |    0.157348     |   1\n",
      "       8036 |   0.221661  |    0.062843     |   1\n",
      "       8037 |   0.192148  |    0.129036     |   1\n",
      "       8038 |   0.030219  |    0.002988     |   2\n",
      "       8039 |   0.157081  |    0.010568     |   0\n",
      "       8040 |   0.302476  |    0.048872     |   0\n",
      "       8041 |   0.000089  |    0.013067     |   2\n",
      "       8042 |   0.211035  |    0.038341     |   0\n",
      "       8043 |   0.202335  |    0.095422     |   1\n",
      "       8044 |   0.246119  |    0.021551     |   0\n",
      "       8045 |   0.276547  |    0.027060     |   0\n",
      "       8046 |   0.285452  |    0.137423     |   1\n",
      "       8047 |   0.257242  |    0.084286     |   1\n",
      "       8048 |   0.208771  |    0.091621     |   1\n",
      "       8049 |   0.252913  |    0.084758     |   1\n",
      "       8050 |   0.297228  |    0.088126     |   1\n",
      "       8051 |   0.227940  |    0.132443     |   1\n",
      "       8052 |   0.228887  |    0.103187     |   1\n",
      "       8053 |   0.172279  |    0.081700     |   1\n",
      "       8054 |   0.233794  |    0.034129     |   0\n",
      "       8055 |   0.212686  |    0.164095     |   1\n",
      "       8056 |   0.253251  |    0.010597     |   0\n",
      "       8057 |   0.221241  |    0.083952     |   1\n",
      "       8058 |   0.008462  |    0.009980     |   2\n",
      "       8059 |   0.225068  |    0.035459     |   0\n",
      "       8060 |   0.270606  |    0.135005     |   1\n",
      "       8061 |   0.103421  |    0.005640     |   2\n",
      "       8062 |   0.266517  |    0.012069     |   0\n",
      "       8063 |   0.167832  |    0.045247     |   0\n",
      "       8064 |   0.220069  |    0.149794     |   1\n",
      "       8065 |   0.276296  |    0.045385     |   1\n",
      "       8066 |   0.254150  |    0.037793     |   0\n",
      "       8067 |   0.243225  |    0.022437     |   0\n",
      "       8068 |   0.314819  |    0.144574     |   1\n",
      "       8069 |   0.048366  |    0.013156     |   2\n",
      "       8070 |   0.311533  |    0.097503     |   1\n",
      "       8071 |   0.069259  |    0.013428     |   2\n",
      "       8072 |   0.222116  |    0.135095     |   1\n",
      "       8073 |   0.062732  |    0.006543     |   2\n",
      "       8074 |   0.217189  |    0.144097     |   1\n",
      "       8075 |   0.222583  |    0.008806     |   0\n",
      "       8076 |   0.212547  |    0.020922     |   0\n",
      "       8077 |   0.264365  |    0.147780     |   1\n",
      "       8078 |   0.227829  |    0.006481     |   0\n",
      "       8079 |   0.026837  |    0.010643     |   2\n",
      "       8080 |   0.169956  |    0.138450     |   1\n",
      "       8081 |   0.227182  |    0.008536     |   0\n",
      "       8082 |   0.059030  |    0.028758     |   2\n",
      "       8083 |   0.207759  |    0.032931     |   0\n",
      "       8084 |   0.284220  |    0.143690     |   1\n",
      "       8085 |   0.201082  |    0.002979     |   0\n",
      "       8086 |   0.201810  |    0.011510     |   0\n",
      "       8087 |   0.241792  |    0.029686     |   0\n",
      "       8088 |   0.238280  |    0.145440     |   1\n",
      "       8089 |   0.252063  |    0.007298     |   0\n",
      "       8090 |   0.219938  |    0.093976     |   1\n",
      "       8091 |   0.046712  |    0.012639     |   2\n",
      "       8092 |   0.000088  |    0.023242     |   2\n",
      "       8093 |   0.000089  |    0.036892     |   2\n",
      "       8094 |   0.000091  |    0.008055     |   2\n",
      "       8095 |   0.286290  |    0.031609     |   0\n",
      "       8096 |   0.236606  |    0.161236     |   1\n",
      "       8097 |   0.000090  |    0.014316     |   2\n",
      "       8098 |   0.219749  |    0.076527     |   1\n",
      "       8099 |   0.199098  |    0.006268     |   0\n",
      "       8100 |   0.000089  |    0.049362     |   2\n",
      "       8101 |   0.262348  |    0.109726     |   1\n",
      "       8102 |   0.216543  |    0.058573     |   1\n",
      "       8103 |   0.000090  |    0.027746     |   2\n",
      "       8104 |   0.216482  |    0.148428     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 8107: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       8105 |   0.074545  |    0.002915     |   2\n",
      "       8106 |   0.066326  |    0.008613     |   2\n",
      "       8107 |   0.073204  |    0.019386     |   2\n",
      "       8108 |   0.224286  |    0.032477     |   0\n",
      "       8109 |   0.206180  |    0.028340     |   0\n",
      "       8110 |   0.054044  |    0.047091     |   2\n",
      "       8111 |   0.057570  |    0.010083     |   2\n",
      "       8112 |   0.074273  |    0.048753     |   2\n",
      "       8113 |   0.036090  |    0.008738     |   2\n",
      "       8114 |   0.057080  |    0.043570     |   2\n",
      "       8115 |   0.203368  |    0.014520     |   0\n",
      "       8116 |   0.064619  |    0.034302     |   2\n",
      "       8117 |   0.325028  |    0.099672     |   1\n",
      "       8118 |   0.225516  |    0.008493     |   0\n",
      "       8119 |   0.224651  |    0.010780     |   0\n",
      "       8120 |   0.222816  |    0.041539     |   0\n",
      "       8121 |   0.075862  |    0.012748     |   2\n",
      "       8122 |   0.169330  |    0.135497     |   1\n",
      "       8123 |   0.248661  |    0.008481     |   0\n",
      "       8124 |   0.068409  |    0.006001     |   2\n",
      "       8125 |   0.274869  |    0.044457     |   0\n",
      "       8126 |   0.246194  |    0.148904     |   1\n",
      "       8127 |   0.235728  |    0.002944     |   0\n",
      "       8128 |   0.032035  |    0.006562     |   2\n",
      "       8129 |   0.000088  |    0.035291     |   2\n",
      "       8130 |   0.137917  |    0.160864     |   1\n",
      "       8131 |   0.218740  |    0.063803     |   1\n",
      "       8132 |   0.008140  |    0.032038     |   2\n",
      "       8133 |   0.101464  |    0.029430     |   2\n",
      "       8134 |   0.210246  |    0.018166     |   0\n",
      "       8135 |   0.048394  |    0.027224     |   2\n",
      "       8136 |   0.267420  |    0.031641     |   0\n",
      "       8137 |   0.263854  |    0.107695     |   1\n",
      "       8138 |   0.150510  |    0.011560     |   0\n",
      "       8139 |   0.069969  |    0.027377     |   2\n",
      "       8140 |   0.184244  |    0.047037     |   0\n",
      "       8141 |   0.202956  |    0.010219     |   0\n",
      "       8142 |   0.061173  |    0.037699     |   2\n",
      "       8143 |   0.027654  |    0.008190     |   2\n",
      "       8144 |   0.059634  |    0.042900     |   2\n",
      "       8145 |   0.046639  |    0.022244     |   2\n",
      "       8146 |   0.210630  |    0.025275     |   0\n",
      "       8147 |   0.207939  |    0.087035     |   1\n",
      "       8148 |   0.000088  |    0.017280     |   2\n",
      "       8149 |   0.270553  |    0.129062     |   1\n",
      "       8150 |   0.261781  |    0.006483     |   0\n",
      "       8151 |   0.000088  |    0.042250     |   2\n",
      "       8152 |   0.000089  |    0.007069     |   2\n",
      "       8153 |   0.294118  |    0.055235     |   0\n",
      "       8154 |   0.253621  |    0.086263     |   1\n",
      "       8155 |   0.000090  |    0.013339     |   2\n",
      "       8156 |   0.226664  |    0.143043     |   1\n",
      "       8157 |   0.263163  |    0.008588     |   0\n",
      "       8158 |   0.217580  |    0.160720     |   1\n",
      "       8159 |   0.201608  |    0.059157     |   1\n",
      "       8160 |   0.174160  |    0.021709     |   0\n",
      "       8161 |   0.000089  |    0.036825     |   2\n",
      "       8162 |   0.181149  |    0.014589     |   0\n",
      "       8163 |   0.171788  |    0.037265     |   0\n",
      "       8164 |   0.195205  |    0.021896     |   0\n",
      "       8165 |   0.336308  |    0.126786     |   1\n",
      "       8166 |   0.231552  |    0.016883     |   0\n",
      "       8167 |   0.315601  |    0.139325     |   1\n",
      "       8168 |   0.000089  |    0.009385     |   2\n",
      "       8169 |   0.240880  |    0.143061     |   1\n",
      "       8170 |   0.178883  |    0.010254     |   0\n",
      "       8171 |   0.291613  |    0.051716     |   1\n",
      "       8172 |   0.227375  |    0.033605     |   0\n",
      "       8173 |   0.238919  |    0.152295     |   1\n",
      "       8174 |   0.073132  |    0.015911     |   2\n",
      "       8175 |   0.195013  |    0.136964     |   1\n",
      "       8176 |   0.067159  |    0.004181     |   2\n",
      "       8177 |   0.253200  |    0.011296     |   0\n",
      "       8178 |   0.247551  |    0.129350     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 8179: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       8179 |   0.279268  |    0.011309     |   0\n",
      "       8180 |   0.071668  |    0.017208     |   2\n",
      "       8181 |   0.054148  |    0.027022     |   2\n",
      "       8182 |   0.259854  |    0.028063     |   0\n",
      "       8183 |   0.219170  |    0.031699     |   0\n",
      "       8184 |   0.238943  |    0.089909     |   1\n",
      "       8185 |   0.190672  |    0.154798     |   1\n",
      "       8186 |   0.056396  |    0.003216     |   2\n",
      "       8187 |   0.176689  |    0.025875     |   0\n",
      "       8188 |   0.246980  |    0.059883     |   0\n",
      "       8189 |   0.263022  |    0.082603     |   1\n",
      "       8190 |   0.239482  |    0.105150     |   1\n",
      "       8191 |   0.242003  |    0.084393     |   1\n",
      "       8192 |   0.074866  |    0.006508     |   2\n",
      "       8193 |   0.281458  |    0.049429     |   0\n",
      "       8194 |   0.036439  |    0.013947     |   2\n",
      "       8195 |   0.058063  |    0.047886     |   2\n",
      "       8196 |   0.341471  |    0.095866     |   1\n",
      "       8197 |   0.290500  |    0.087956     |   1\n",
      "       8198 |   0.061981  |    0.008354     |   2\n",
      "       8199 |   0.243752  |    0.024480     |   0\n",
      "       8200 |   0.078243  |    0.029048     |   2\n",
      "       8201 |   0.168071  |    0.017292     |   0\n",
      "       8202 |   0.067770  |    0.024093     |   2\n",
      "       8203 |   0.256204  |    0.140083     |   1\n",
      "       8204 |   0.032826  |    0.008847     |   2\n",
      "       8205 |   0.331199  |    0.088773     |   1\n",
      "       8206 |   0.187002  |    0.080078     |   1\n",
      "       8207 |   0.175249  |    0.052174     |   0\n",
      "       8208 |   0.273114  |    0.089065     |   1\n",
      "       8209 |   0.000088  |    0.015008     |   2\n",
      "       8210 |   0.007230  |    0.026234     |   2\n",
      "       8211 |   0.227212  |    0.045679     |   0\n",
      "       8212 |   0.283087  |    0.137281     |   1\n",
      "       8213 |   0.245026  |    0.003457     |   0\n",
      "       8214 |   0.217834  |    0.014280     |   0\n",
      "       8215 |   0.099970  |    0.041902     |   2\n",
      "       8216 |   0.237484  |    0.010573     |   0\n",
      "       8217 |   0.157631  |    0.046391     |   0\n",
      "       8218 |   0.259706  |    0.088627     |   1\n",
      "       8219 |   0.049499  |    0.019330     |   2\n",
      "       8220 |   0.258261  |    0.044948     |   0\n",
      "       8221 |   0.068927  |    0.014970     |   2\n",
      "       8222 |   0.190655  |    0.146580     |   1\n",
      "       8223 |   0.243146  |    0.011439     |   0\n",
      "       8224 |   0.278947  |    0.085672     |   1\n",
      "       8225 |   0.180041  |    0.005601     |   0\n",
      "       8226 |   0.180776  |    0.009036     |   0\n",
      "       8227 |   0.240932  |    0.039187     |   0\n",
      "       8228 |   0.209554  |    0.013698     |   0\n",
      "       8229 |   0.298946  |    0.128767     |   1\n",
      "       8230 |   0.060188  |    0.005889     |   2\n",
      "       8231 |   0.217842  |    0.023488     |   0\n",
      "       8232 |   0.290567  |    0.095468     |   1\n",
      "       8233 |   0.207479  |    0.033341     |   0\n",
      "       8234 |   0.289211  |    0.164898     |   1\n",
      "       8235 |   0.208558  |    0.004948     |   0\n",
      "       8236 |   0.254031  |    0.046822     |   1\n",
      "       8237 |   0.027196  |    0.014947     |   2\n",
      "       8238 |   0.154470  |    0.045119     |   0\n",
      "       8239 |   0.205683  |    0.078518     |   1\n",
      "       8240 |   0.266863  |    0.098492     |   1\n",
      "       8241 |   0.278373  |    0.090723     |   1\n",
      "       8242 |   0.197164  |    0.009051     |   0\n",
      "       8243 |   0.296362  |    0.155650     |   1\n",
      "       8244 |   0.198567  |    0.085131     |   1\n",
      "       8245 |   0.058429  |    0.009040     |   2\n",
      "       8246 |   0.212271  |    0.094602     |   1\n",
      "       8247 |   0.286901  |    0.007382     |   0\n",
      "       8248 |   0.044118  |    0.029306     |   2\n",
      "       8249 |   0.223911  |    0.076681     |   1\n",
      "       8250 |   0.293317  |    0.042751     |   0\n",
      "       8251 |   0.241254  |    0.027363     |   0\n",
      "       8252 |   0.237747  |    0.030917     |   0\n",
      "       8253 |   0.000087  |    0.030118     |   2\n",
      "       8254 |   0.000088  |    0.020141     |   2\n",
      "       8255 |   0.246585  |    0.150378     |   1\n",
      "       8256 |   0.214775  |    0.004591     |   0\n",
      "       8257 |   0.223146  |    0.007016     |   0\n",
      "       8258 |   0.000089  |    0.044413     |   2\n",
      "       8259 |   0.211949  |    0.138157     |   1\n",
      "       8260 |   0.211869  |    0.081167     |   1\n",
      "       8261 |   0.000090  |    0.007762     |   2\n",
      "       8262 |   0.184329  |    0.024894     |   0\n",
      "       8263 |   0.000089  |    0.040499     |   2\n",
      "       8264 |   0.242411  |    0.011818     |   0\n",
      "       8265 |   0.000088  |    0.051908     |   2\n",
      "       8266 |   0.168796  |    0.147245     |   1\n",
      "       8267 |   0.277509  |    0.015902     |   1\n",
      "       8268 |   0.243787  |    0.096040     |   1\n",
      "       8269 |   0.224845  |    0.144993     |   1\n",
      "       8270 |   0.075047  |    0.003292     |   2\n",
      "       8271 |   0.066850  |    0.006075     |   2\n",
      "       8272 |   0.220870  |    0.052754     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 8273: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       8273 |   0.271059  |    0.084498     |   1\n",
      "       8274 |   0.071772  |    0.027974     |   2\n",
      "       8275 |   0.054393  |    0.026385     |   2\n",
      "       8276 |   0.197411  |    0.035417     |   0\n",
      "       8277 |   0.235236  |    0.156149     |   1\n",
      "       8278 |   0.053856  |    0.009562     |   2\n",
      "       8279 |   0.287372  |    0.074815     |   1\n",
      "       8280 |   0.073246  |    0.007053     |   2\n",
      "       8281 |   0.035598  |    0.025874     |   2\n",
      "       8282 |   0.289425  |    0.046348     |   0\n",
      "       8283 |   0.259496  |    0.014036     |   0\n",
      "       8284 |   0.253685  |    0.050081     |   0\n",
      "       8285 |   0.276156  |    0.088883     |   1\n",
      "       8286 |   0.056239  |    0.013076     |   2\n",
      "       8287 |   0.172264  |    0.029189     |   0\n",
      "       8288 |   0.063459  |    0.025814     |   2\n",
      "       8289 |   0.218487  |    0.040273     |   0\n",
      "       8290 |   0.216314  |    0.022698     |   0\n",
      "       8291 |   0.267406  |    0.049858     |   0\n",
      "       8292 |   0.230947  |    0.137991     |   1\n",
      "       8293 |   0.149094  |    0.093154     |   1\n",
      "       8294 |   0.230182  |    0.006192     |   0\n",
      "       8295 |   0.212050  |    0.091611     |   1\n",
      "       8296 |   0.176134  |    0.006562     |   0\n",
      "       8297 |   0.078918  |    0.050674     |   2\n",
      "       8298 |   0.152801  |    0.146204     |   1\n",
      "       8299 |   0.070629  |    0.007887     |   2\n",
      "       8300 |   0.254645  |    0.079642     |   1\n",
      "       8301 |   0.032895  |    0.027711     |   2\n",
      "       8302 |   0.185988  |    0.032052     |   0\n",
      "       8303 |   0.281233  |    0.136191     |   1\n",
      "       8304 |   0.201511  |    0.002896     |   0\n",
      "       8305 |   0.202219  |    0.009666     |   0\n",
      "       8306 |   0.183494  |    0.050938     |   0\n",
      "       8307 |   0.205350  |    0.133125     |   1\n",
      "       8308 |   0.000087  |    0.002951     |   2\n",
      "       8309 |   0.181559  |    0.013069     |   0\n",
      "       8310 |   0.195188  |    0.143087     |   1\n",
      "       8311 |   0.250101  |    0.085826     |   1\n",
      "       8312 |   0.180498  |    0.011580     |   0\n",
      "       8313 |   0.259521  |    0.044394     |   0\n",
      "       8314 |   0.252975  |    0.097558     |   1\n",
      "       8315 |   0.210947  |    0.010134     |   0\n",
      "       8316 |   0.226268  |    0.142075     |   1\n",
      "       8317 |   0.007715  |    0.008156     |   2\n",
      "       8318 |   0.244136  |    0.085682     |   1\n",
      "       8319 |   0.265470  |    0.088462     |   1\n",
      "       8320 |   0.290069  |    0.025252     |   0\n",
      "       8321 |   0.222970  |    0.057411     |   0\n",
      "       8322 |   0.250355  |    0.099423     |   1\n",
      "       8323 |   0.222976  |    0.073616     |   1\n",
      "       8324 |   0.307425  |    0.086628     |   1\n",
      "       8325 |   0.101857  |    0.008025     |   2\n",
      "       8326 |   0.048307  |    0.055942     |   2\n",
      "       8327 |   0.071872  |    0.007365     |   2\n",
      "       8328 |   0.189559  |    0.051578     |   0\n",
      "       8329 |   0.059623  |    0.010355     |   2\n",
      "       8330 |   0.187472  |    0.086075     |   1\n",
      "       8331 |   0.026546  |    0.016532     |   2\n",
      "       8332 |   0.242997  |    0.110693     |   1\n",
      "       8333 |   0.059693  |    0.015313     |   2\n",
      "       8334 |   0.278395  |    0.129840     |   1\n",
      "       8335 |   0.043543  |    0.009994     |   2\n",
      "       8336 |   0.264417  |    0.082846     |   1\n",
      "       8337 |   0.000086  |    0.008434     |   2\n",
      "       8338 |   0.228780  |    0.046583     |   0\n",
      "       8339 |   0.215110  |    0.013743     |   0\n",
      "       8340 |   0.265340  |    0.057308     |   0\n",
      "       8341 |   0.279489  |    0.093760     |   1\n",
      "       8342 |   0.000086  |    0.014171     |   2\n",
      "       8343 |   0.202734  |    0.141924     |   1\n",
      "       8344 |   0.000088  |    0.003513     |   2\n",
      "       8345 |   0.213645  |    0.022111     |   0\n",
      "       8346 |   0.000089  |    0.029254     |   2\n",
      "       8347 |   0.212127  |    0.031486     |   0\n",
      "       8348 |   0.251861  |    0.134989     |   1\n",
      "       8349 |   0.144757  |    0.002985     |   0\n",
      "       8350 |   0.181315  |    0.008455     |   0\n",
      "       8351 |   0.277431  |    0.125579     |   1\n",
      "       8352 |   0.161748  |    0.006663     |   0\n",
      "       8353 |   0.000087  |    0.032329     |   2\n",
      "       8354 |   0.000087  |    0.028662     |   2\n",
      "       8355 |   0.190189  |    0.026460     |   0\n",
      "       8356 |   0.254473  |    0.043493     |   0\n",
      "       8357 |   0.072787  |    0.007659     |   2\n",
      "       8358 |   0.231513  |    0.042623     |   0\n",
      "       8359 |   0.066712  |    0.013411     |   2\n",
      "       8360 |   0.187870  |    0.148124     |   1\n",
      "       8361 |   0.192676  |    0.097736     |   1\n",
      "       8362 |   0.254955  |    0.089551     |   1\n",
      "       8363 |   0.227435  |    0.011359     |   0\n",
      "       8364 |   0.254202  |    0.032448     |   0\n",
      "       8365 |   0.211898  |    0.043831     |   0\n",
      "       8366 |   0.280166  |    0.090294     |   1\n",
      "       8367 |   0.259016  |    0.023471     |   0\n",
      "       8368 |   0.265358  |    0.022000     |   0\n",
      "       8369 |   0.305834  |    0.035172     |   0\n",
      "       8370 |   0.190909  |    0.080089     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 8372: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       8371 |   0.232181  |    0.006133     |   0\n",
      "       8372 |   0.231749  |    0.042070     |   0\n",
      "       8373 |   0.078458  |    0.016513     |   2\n",
      "       8374 |   0.198507  |    0.104123     |   1\n",
      "       8375 |   0.246105  |    0.046531     |   0\n",
      "       8376 |   0.057829  |    0.012200     |   2\n",
      "       8377 |   0.286093  |    0.143223     |   1\n",
      "       8378 |   0.055051  |    0.010479     |   2\n",
      "       8379 |   0.072606  |    0.014530     |   2\n",
      "       8380 |   0.230840  |    0.040536     |   0\n",
      "       8381 |   0.264634  |    0.091427     |   1\n",
      "       8382 |   0.036658  |    0.022128     |   2\n",
      "       8383 |   0.236284  |    0.103978     |   1\n",
      "       8384 |   0.060157  |    0.017328     |   2\n",
      "       8385 |   0.290669  |    0.030856     |   0\n",
      "       8386 |   0.066772  |    0.012267     |   2\n",
      "       8387 |   0.211067  |    0.028510     |   0\n",
      "       8388 |   0.233375  |    0.149980     |   1\n",
      "       8389 |   0.077746  |    0.009143     |   2\n",
      "       8390 |   0.243465  |    0.055513     |   1\n",
      "       8391 |   0.186695  |    0.009093     |   0\n",
      "       8392 |   0.068952  |    0.043873     |   2\n",
      "       8393 |   0.194504  |    0.020845     |   0\n",
      "       8394 |   0.240879  |    0.033675     |   0\n",
      "       8395 |   0.033003  |    0.019012     |   2\n",
      "       8396 |   0.000087  |    0.030363     |   2\n",
      "       8397 |   0.007791  |    0.028288     |   2\n",
      "       8398 |   0.205544  |    0.150942     |   1\n",
      "       8399 |   0.102770  |    0.008937     |   2\n",
      "       8400 |   0.264903  |    0.084710     |   1\n",
      "       8401 |   0.278067  |    0.132145     |   1\n",
      "       8402 |   0.267712  |    0.088091     |   1\n",
      "       8403 |   0.241843  |    0.005509     |   0\n",
      "       8404 |   0.225701  |    0.023409     |   0\n",
      "       8405 |   0.047905  |    0.031819     |   2\n",
      "       8406 |   0.069653  |    0.033444     |   2\n",
      "       8407 |   0.059964  |    0.017288     |   2\n",
      "       8408 |   0.027306  |    0.011186     |   2\n",
      "       8409 |   0.258961  |    0.145058     |   1\n",
      "       8410 |   0.059138  |    0.007745     |   2\n",
      "       8411 |   0.225252  |    0.008861     |   0\n",
      "       8412 |   0.216520  |    0.155190     |   1\n",
      "       8413 |   0.044308  |    0.002964     |   2\n",
      "       8414 |   0.000086  |    0.014297     |   2\n",
      "       8415 |   0.228439  |    0.160409     |   1\n",
      "       8416 |   0.327003  |    0.043072     |   1\n",
      "       8417 |   0.256148  |    0.034476     |   0\n",
      "       8418 |   0.201049  |    0.012262     |   0\n",
      "       8419 |   0.329857  |    0.146659     |   1\n",
      "       8420 |   0.000087  |    0.002863     |   2\n",
      "       8421 |   0.206527  |    0.010753     |   0\n",
      "       8422 |   0.232915  |    0.031503     |   0\n",
      "       8423 |   0.000088  |    0.016861     |   2\n",
      "       8424 |   0.249301  |    0.045558     |   0\n",
      "       8425 |   0.217864  |    0.010949     |   0\n",
      "       8426 |   0.000089  |    0.045079     |   2\n",
      "       8427 |   0.264932  |    0.101902     |   1\n",
      "       8428 |   0.259504  |    0.056382     |   1\n",
      "       8429 |   0.000088  |    0.013224     |   2\n",
      "       8430 |   0.226274  |    0.147790     |   1\n",
      "       8431 |   0.210172  |    0.091305     |   1\n",
      "       8432 |   0.323183  |    0.083521     |   1\n",
      "       8433 |   0.205733  |    0.085878     |   1\n",
      "       8434 |   0.000088  |    0.016988     |   2\n",
      "       8435 |   0.065717  |    0.026121     |   2\n",
      "       8436 |   0.171714  |    0.040959     |   0\n",
      "       8437 |   0.187739  |    0.023435     |   0\n",
      "       8438 |   0.337641  |    0.029067     |   0\n",
      "       8439 |   0.340609  |    0.084826     |   1\n",
      "       8440 |   0.234145  |    0.024529     |   0\n",
      "       8441 |   0.310786  |    0.059313     |   0\n",
      "       8442 |   0.220757  |    0.081936     |   1\n",
      "       8443 |   0.229216  |    0.041042     |   0\n",
      "       8444 |   0.064577  |    0.018945     |   2\n",
      "       8445 |   0.238686  |    0.120617     |   1\n",
      "       8446 |   0.321570  |    0.082140     |   1\n",
      "       8447 |   0.209990  |    0.014471     |   0\n",
      "       8448 |   0.261876  |    0.137307     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 8449: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       8449 |   0.071250  |    0.003079     |   2\n",
      "       8450 |   0.052030  |    0.011425     |   2\n",
      "       8451 |   0.254207  |    0.053017     |   0\n",
      "       8452 |   0.053955  |    0.013920     |   2\n",
      "       8453 |   0.232561  |    0.085973     |   1\n",
      "       8454 |   0.189551  |    0.031082     |   0\n",
      "       8455 |   0.248125  |    0.099685     |   1\n",
      "       8456 |   0.240464  |    0.041918     |   0\n",
      "       8457 |   0.241120  |    0.025824     |   0\n",
      "       8458 |   0.261266  |    0.094923     |   1\n",
      "       8459 |   0.070395  |    0.009457     |   2\n",
      "       8460 |   0.035876  |    0.034531     |   2\n",
      "       8461 |   0.247852  |    0.025632     |   0\n",
      "       8462 |   0.251163  |    0.046340     |   0\n",
      "       8463 |   0.214497  |    0.010661     |   0\n",
      "       8464 |   0.220031  |    0.149994     |   1\n",
      "       8465 |   0.185831  |    0.088408     |   1\n",
      "       8466 |   0.054023  |    0.008271     |   2\n",
      "       8467 |   0.063206  |    0.043984     |   2\n",
      "       8468 |   0.219685  |    0.082685     |   1\n",
      "       8469 |   0.163837  |    0.023330     |   0\n",
      "       8470 |   0.260159  |    0.134270     |   1\n",
      "       8471 |   0.281641  |    0.007137     |   0\n",
      "       8472 |   0.074513  |    0.034779     |   2\n",
      "       8473 |   0.253022  |    0.134103     |   1\n",
      "       8474 |   0.206199  |    0.008721     |   0\n",
      "       8475 |   0.066192  |    0.011546     |   2\n",
      "       8476 |   0.031912  |    0.033061     |   2\n",
      "       8477 |   0.213412  |    0.041296     |   0\n",
      "       8478 |   0.246995  |    0.018686     |   0\n",
      "       8479 |   0.206257  |    0.043523     |   0\n",
      "       8480 |   0.000085  |    0.014405     |   2\n",
      "       8481 |   0.221888  |    0.059114     |   0\n",
      "       8482 |   0.230563  |    0.091605     |   1\n",
      "       8483 |   0.205418  |    0.080635     |   1\n",
      "       8484 |   0.007187  |    0.004157     |   2\n",
      "       8485 |   0.256737  |    0.045668     |   0\n",
      "       8486 |   0.239809  |    0.134002     |   1\n",
      "       8487 |   0.207244  |    0.058131     |   1\n",
      "       8488 |   0.286393  |    0.014123     |   0\n",
      "       8489 |   0.208174  |    0.042859     |   0\n",
      "       8490 |   0.103328  |    0.010119     |   2\n",
      "       8491 |   0.297080  |    0.049613     |   0\n",
      "       8492 |   0.283677  |    0.108290     |   1\n",
      "       8493 |   0.047545  |    0.009800     |   2\n",
      "       8494 |   0.273457  |    0.025823     |   0\n",
      "       8495 |   0.271170  |    0.042216     |   0\n",
      "       8496 |   0.212991  |    0.010221     |   0\n",
      "       8497 |   0.075561  |    0.032587     |   2\n",
      "       8498 |   0.261736  |    0.134956     |   1\n",
      "       8499 |   0.175129  |    0.008083     |   0\n",
      "       8500 |   0.200789  |    0.006209     |   0\n",
      "       8501 |   0.075874  |    0.040432     |   2\n",
      "       8502 |   0.265795  |    0.044480     |   0\n",
      "       8503 |   0.058069  |    0.028658     |   2\n",
      "       8504 |   0.056616  |    0.046976     |   2\n",
      "       8505 |   0.245593  |    0.109122     |   1\n",
      "       8506 |   0.255900  |    0.089116     |   1\n",
      "       8507 |   0.241296  |    0.154784     |   1\n",
      "       8508 |   0.073187  |    0.010029     |   2\n",
      "       8509 |   0.240086  |    0.050996     |   1\n",
      "       8510 |   0.192797  |    0.018268     |   0\n",
      "       8511 |   0.036079  |    0.026565     |   2\n",
      "       8512 |   0.187311  |    0.033559     |   0\n",
      "       8513 |   0.209037  |    0.025568     |   0\n",
      "       8514 |   0.173740  |    0.010014     |   0\n",
      "       8515 |   0.195967  |    0.168872     |   1\n",
      "       8516 |   0.057201  |    0.013468     |   2\n",
      "       8517 |   0.214427  |    0.091125     |   1\n",
      "       8518 |   0.213464  |    0.096762     |   1\n",
      "       8519 |   0.067234  |    0.007953     |   2\n",
      "       8520 |   0.074263  |    0.040699     |   2\n",
      "       8521 |   0.230593  |    0.018311     |   0\n",
      "       8522 |   0.237760  |    0.026603     |   0\n",
      "       8523 |   0.065098  |    0.028581     |   2\n",
      "       8524 |   0.180610  |    0.028871     |   0\n",
      "       8525 |   0.258116  |    0.026419     |   0\n",
      "       8526 |   0.030639  |    0.033384     |   2\n",
      "       8527 |   0.000085  |    0.021798     |   2\n",
      "       8528 |   0.007880  |    0.039374     |   2\n",
      "       8529 |   0.283193  |    0.029446     |   0\n",
      "       8530 |   0.101682  |    0.033356     |   2\n",
      "       8531 |   0.214533  |    0.018532     |   0\n",
      "       8532 |   0.255445  |    0.133949     |   1\n",
      "       8533 |   0.048355  |    0.008373     |   2\n",
      "       8534 |   0.071997  |    0.016621     |   2\n",
      "       8535 |   0.275204  |    0.148788     |   1\n",
      "       8536 |   0.170650  |    0.004719     |   0\n",
      "       8537 |   0.063638  |    0.010992     |   2\n",
      "       8538 |   0.027253  |    0.043394     |   2\n",
      "       8539 |   0.208227  |    0.023304     |   0\n",
      "       8540 |   0.255958  |    0.043436     |   0\n",
      "       8541 |   0.217469  |    0.087066     |   1\n",
      "       8542 |   0.059613  |    0.022030     |   2\n",
      "       8543 |   0.211061  |    0.141517     |   1\n",
      "       8544 |   0.260553  |    0.009244     |   0\n",
      "       8545 |   0.201327  |    0.014936     |   0\n",
      "       8546 |   0.258672  |    0.034183     |   0\n",
      "       8547 |   0.237842  |    0.093280     |   1\n",
      "       8548 |   0.044874  |    0.021733     |   2\n",
      "       8549 |   0.256720  |    0.042064     |   0\n",
      "       8550 |   0.217512  |    0.009627     |   0\n",
      "       8551 |   0.000085  |    0.046809     |   2\n",
      "       8552 |   0.262110  |    0.159209     |   1\n",
      "       8553 |   0.000085  |    0.007195     |   2\n",
      "       8554 |   0.180885  |    0.051007     |   1\n",
      "       8555 |   0.000086  |    0.027556     |   2\n",
      "       8556 |   0.231335  |    0.128951     |   1\n",
      "       8557 |   0.000087  |    0.005331     |   2\n",
      "       8558 |   0.000086  |    0.023813     |   2\n",
      "       8559 |   0.194964  |    0.045629     |   0\n",
      "       8560 |   0.182077  |    0.012165     |   0\n",
      "       8561 |   0.000085  |    0.038736     |   2\n",
      "       8562 |   0.070723  |    0.009828     |   2\n",
      "       8563 |   0.177252  |    0.151944     |   1\n",
      "       8564 |   0.190939  |    0.012871     |   0\n",
      "       8565 |   0.066273  |    0.007688     |   2\n",
      "       8566 |   0.189363  |    0.035977     |   0\n",
      "       8567 |   0.193899  |    0.055292     |   1\n",
      "       8568 |   0.184917  |    0.008207     |   0\n",
      "       8569 |   0.212585  |    0.073203     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 8570: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       8570 |   0.246483  |    0.090325     |   1\n",
      "       8571 |   0.073637  |    0.007321     |   2\n",
      "       8572 |   0.272186  |    0.088978     |   1\n",
      "       8573 |   0.052720  |    0.051220     |   2\n",
      "       8574 |   0.266894  |    0.078069     |   1\n",
      "       8575 |   0.052716  |    0.017717     |   2\n",
      "       8576 |   0.069882  |    0.031551     |   2\n",
      "       8577 |   0.234199  |    0.137430     |   1\n",
      "       8578 |   0.316221  |    0.083360     |   1\n",
      "       8579 |   0.261104  |    0.080570     |   1\n",
      "       8580 |   0.246544  |    0.009305     |   0\n",
      "       8581 |   0.184795  |    0.144030     |   1\n",
      "       8582 |   0.237842  |    0.002902     |   0\n",
      "       8583 |   0.194458  |    0.009489     |   0\n",
      "       8584 |   0.035244  |    0.047990     |   2\n",
      "       8585 |   0.255161  |    0.016465     |   0\n",
      "       8586 |   0.198089  |    0.143291     |   1\n",
      "       8587 |   0.216941  |    0.005745     |   0\n",
      "       8588 |   0.175240  |    0.019175     |   0\n",
      "       8589 |   0.203053  |    0.042554     |   0\n",
      "       8590 |   0.206083  |    0.011166     |   0\n",
      "       8591 |   0.056102  |    0.033216     |   2\n",
      "       8592 |   0.062512  |    0.013231     |   2\n",
      "       8593 |   0.076431  |    0.050392     |   2\n",
      "       8594 |   0.218641  |    0.084269     |   1\n",
      "       8595 |   0.065280  |    0.032181     |   2\n",
      "       8596 |   0.259743  |    0.136916     |   1\n",
      "       8597 |   0.225799  |    0.054245     |   1\n",
      "       8598 |   0.251221  |    0.133570     |   1\n",
      "       8599 |   0.033318  |    0.002971     |   2\n",
      "       8600 |   0.239779  |    0.005165     |   0\n",
      "       8601 |   0.198296  |    0.047804     |   0\n",
      "       8602 |   0.248396  |    0.018382     |   0\n",
      "       8603 |   0.255782  |    0.176044     |   1\n",
      "       8604 |   0.216410  |    0.043855     |   1\n",
      "       8605 |   0.256021  |    0.027462     |   0\n",
      "       8606 |   0.000085  |    0.035297     |   2\n",
      "       8607 |   0.007035  |    0.021513     |   2\n",
      "       8608 |   0.181837  |    0.026912     |   0\n",
      "       8609 |   0.100391  |    0.028835     |   2\n",
      "       8610 |   0.228806  |    0.028676     |   0\n",
      "       8611 |   0.047589  |    0.023496     |   2\n",
      "       8612 |   0.201001  |    0.039302     |   0\n",
      "       8613 |   0.068447  |    0.009847     |   2\n",
      "       8614 |   0.171661  |    0.028264     |   0\n",
      "       8615 |   0.061747  |    0.008300     |   2\n",
      "       8616 |   0.260137  |    0.047029     |   0\n",
      "       8617 |   0.273569  |    0.134025     |   1\n",
      "       8618 |   0.315197  |    0.085249     |   1\n",
      "       8619 |   0.225208  |    0.099936     |   1\n",
      "       8620 |   0.223060  |    0.059816     |   1\n",
      "       8621 |   0.243640  |    0.091572     |   1\n",
      "       8622 |   0.209694  |    0.118787     |   1\n",
      "       8623 |   0.173000  |    0.103954     |   1\n",
      "       8624 |   0.240885  |    0.085542     |   1\n",
      "       8625 |   0.237428  |    0.011723     |   0\n",
      "       8626 |   0.026484  |    0.029012     |   2\n",
      "       8627 |   0.057391  |    0.018455     |   2\n",
      "       8628 |   0.199216  |    0.049162     |   0\n",
      "       8629 |   0.234117  |    0.094266     |   1\n",
      "       8630 |   0.236067  |    0.011193     |   0\n",
      "       8631 |   0.264538  |    0.052709     |   1\n",
      "       8632 |   0.265594  |    0.094435     |   1\n",
      "       8633 |   0.291776  |    0.079840     |   1\n",
      "       8634 |   0.277813  |    0.020911     |   0\n",
      "       8635 |   0.045418  |    0.052444     |   2\n",
      "       8636 |   0.245030  |    0.112506     |   1\n",
      "       8637 |   0.200007  |    0.099335     |   1\n",
      "       8638 |   0.226110  |    0.099927     |   1\n",
      "       8639 |   0.279890  |    0.088774     |   1\n",
      "       8640 |   0.000085  |    0.006126     |   2\n",
      "       8641 |   0.189619  |    0.141957     |   1\n",
      "       8642 |   0.208748  |    0.080821     |   1\n",
      "       8643 |   0.000085  |    0.010968     |   2\n",
      "       8644 |   0.298066  |    0.041496     |   0\n",
      "       8645 |   0.172520  |    0.026705     |   0\n",
      "       8646 |   0.228289  |    0.027003     |   0\n",
      "       8647 |   0.000086  |    0.042071     |   2\n",
      "       8648 |   0.256422  |    0.103627     |   1\n",
      "       8649 |   0.238454  |    0.078806     |   1\n",
      "       8650 |   0.261322  |    0.025035     |   0\n",
      "       8651 |   0.203252  |    0.032626     |   0\n",
      "       8652 |   0.290274  |    0.097462     |   1\n",
      "       8653 |   0.220910  |    0.013047     |   0\n",
      "       8654 |   0.000087  |    0.046680     |   2\n",
      "       8655 |   0.000085  |    0.010923     |   2\n",
      "       8656 |   0.201169  |    0.048384     |   0\n",
      "       8657 |   0.000085  |    0.010979     |   2\n",
      "       8658 |   0.225507  |    0.157292     |   1\n",
      "       8659 |   0.067772  |    0.008904     |   2\n",
      "       8660 |   0.297735  |    0.117858     |   1\n",
      "       8661 |   0.064498  |    0.006906     |   2\n",
      "       8662 |   0.218555  |    0.095959     |   1\n",
      "       8663 |   0.163029  |    0.110174     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 8664: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       8664 |   0.194860  |    0.074992     |   1\n",
      "       8665 |   0.211461  |    0.018278     |   0\n",
      "       8666 |   0.218461  |    0.028961     |   0\n",
      "       8667 |   0.189954  |    0.033283     |   0\n",
      "       8668 |   0.220402  |    0.169651     |   1\n",
      "       8669 |   0.071847  |    0.008560     |   2\n",
      "       8670 |   0.283638  |    0.059697     |   1\n",
      "       8671 |   0.216125  |    0.099221     |   1\n",
      "       8672 |   0.239894  |    0.143443     |   1\n",
      "       8673 |   0.186640  |    0.052360     |   1\n",
      "       8674 |   0.251133  |    0.110790     |   1\n",
      "       8675 |   0.185544  |    0.091094     |   1\n",
      "       8676 |   0.258141  |    0.030799     |   0\n",
      "       8677 |   0.055877  |    0.031549     |   2\n",
      "       8678 |   0.053125  |    0.021465     |   2\n",
      "       8679 |   0.067127  |    0.038454     |   2\n",
      "       8680 |   0.257025  |    0.021628     |   0\n",
      "       8681 |   0.337391  |    0.147628     |   1\n",
      "       8682 |   0.034598  |    0.003130     |   2\n",
      "       8683 |   0.056287  |    0.013296     |   2\n",
      "       8684 |   0.062904  |    0.031714     |   2\n",
      "       8685 |   0.241744  |    0.078595     |   1\n",
      "       8686 |   0.075888  |    0.017289     |   2\n",
      "       8687 |   0.269851  |    0.046932     |   0\n",
      "       8688 |   0.241743  |    0.016759     |   0\n",
      "       8689 |   0.242384  |    0.041911     |   0\n",
      "       8690 |   0.067818  |    0.017688     |   2\n",
      "       8691 |   0.033479  |    0.040380     |   2\n",
      "       8692 |   0.210670  |    0.018656     |   0\n",
      "       8693 |   0.216191  |    0.035653     |   0\n",
      "       8694 |   0.259950  |    0.143427     |   1\n",
      "       8695 |   0.198937  |    0.008814     |   0\n",
      "       8696 |   0.313743  |    0.079649     |   1\n",
      "       8697 |   0.000084  |    0.015925     |   2\n",
      "       8698 |   0.275194  |    0.145703     |   1\n",
      "       8699 |   0.277843  |    0.050788     |   1\n",
      "       8700 |   0.007342  |    0.016211     |   2\n",
      "       8701 |   0.235842  |    0.122125     |   1\n",
      "       8702 |   0.212117  |    0.152374     |   1\n",
      "       8703 |   0.100062  |    0.006483     |   2\n",
      "       8704 |   0.239940  |    0.032585     |   0\n",
      "       8705 |   0.260787  |    0.132381     |   1\n",
      "       8706 |   0.045714  |    0.010546     |   2\n",
      "       8707 |   0.228729  |    0.098487     |   1\n",
      "       8708 |   0.068654  |    0.012265     |   2\n",
      "       8709 |   0.194897  |    0.139897     |   1\n",
      "       8710 |   0.061141  |    0.006051     |   2\n",
      "       8711 |   0.243215  |    0.127048     |   1\n",
      "       8712 |   0.024905  |    0.008396     |   2\n",
      "       8713 |   0.052896  |    0.028363     |   2\n",
      "       8714 |   0.197969  |    0.052054     |   0\n",
      "       8715 |   0.183671  |    0.030692     |   0\n",
      "       8716 |   0.226093  |    0.144401     |   1\n",
      "       8717 |   0.042063  |    0.006054     |   2\n",
      "       8718 |   0.282557  |    0.017309     |   0\n",
      "       8719 |   0.000084  |    0.038912     |   2\n",
      "       8720 |   0.303382  |    0.138631     |   1\n",
      "       8721 |   0.243597  |    0.002960     |   0\n",
      "       8722 |   0.267162  |    0.007091     |   0\n",
      "       8723 |   0.000084  |    0.065524     |   2\n",
      "       8724 |   0.206251  |    0.067376     |   1\n",
      "       8725 |   0.309256  |    0.092593     |   1\n",
      "       8726 |   0.000085  |    0.005495     |   2\n",
      "       8727 |   0.147111  |    0.019045     |   0\n",
      "       8728 |   0.000086  |    0.036323     |   2\n",
      "       8729 |   0.000084  |    0.011964     |   2\n",
      "       8730 |   0.000084  |    0.047461     |   2\n",
      "       8731 |   0.067364  |    0.012826     |   2\n",
      "       8732 |   0.062996  |    0.069002     |   2\n",
      "       8733 |   0.223229  |    0.010618     |   1\n",
      "       8734 |   0.302478  |    0.149838     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 8735: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       8735 |   0.213003  |    0.002950     |   0\n",
      "       8736 |   0.223160  |    0.008002     |   0\n",
      "       8737 |   0.070462  |    0.047041     |   2\n",
      "       8738 |   0.053287  |    0.018406     |   2\n",
      "       8739 |   0.246625  |    0.034868     |   0\n",
      "       8740 |   0.276897  |    0.126906     |   1\n",
      "       8741 |   0.220317  |    0.004824     |   0\n",
      "       8742 |   0.051948  |    0.008653     |   2\n",
      "       8743 |   0.067464  |    0.041364     |   2\n",
      "       8744 |   0.192846  |    0.011870     |   0\n",
      "       8745 |   0.171818  |    0.043841     |   0\n",
      "       8746 |   0.242412  |    0.014952     |   0\n",
      "       8747 |   0.232151  |    0.045994     |   0\n",
      "       8748 |   0.035432  |    0.012466     |   2\n",
      "       8749 |   0.055476  |    0.043760     |   2\n",
      "       8750 |   0.182391  |    0.024341     |   0\n",
      "       8751 |   0.240142  |    0.137512     |   1\n",
      "       8752 |   0.271805  |    0.086215     |   1\n",
      "       8753 |   0.060902  |    0.009433     |   2\n",
      "       8754 |   0.247030  |    0.097152     |   1\n",
      "       8755 |   0.250510  |    0.079286     |   1\n",
      "       8756 |   0.212674  |    0.022861     |   0\n",
      "       8757 |   0.075188  |    0.027680     |   2\n",
      "       8758 |   0.141977  |    0.016159     |   0\n",
      "       8759 |   0.215209  |    0.055863     |   0\n",
      "       8760 |   0.061234  |    0.010487     |   2\n",
      "       8761 |   0.306693  |    0.046956     |   0\n",
      "       8762 |   0.304474  |    0.018773     |   0\n",
      "       8763 |   0.300041  |    0.153805     |   1\n",
      "       8764 |   0.213924  |    0.009807     |   0\n",
      "       8765 |   0.282043  |    0.090785     |   1\n",
      "       8766 |   0.030971  |    0.012287     |   2\n",
      "       8767 |   0.000083  |    0.031954     |   2\n",
      "       8768 |   0.188449  |    0.043460     |   0\n",
      "       8769 |   0.280206  |    0.081086     |   1\n",
      "       8770 |   0.277009  |    0.082338     |   1\n",
      "       8771 |   0.006637  |    0.006961     |   2\n",
      "       8772 |   0.191023  |    0.025112     |   0\n",
      "       8773 |   0.233890  |    0.056796     |   0\n",
      "       8774 |   0.098313  |    0.008940     |   2\n",
      "       8775 |   0.231097  |    0.050592     |   0\n",
      "       8776 |   0.047309  |    0.034350     |   2\n",
      "       8777 |   0.069959  |    0.019866     |   2\n",
      "       8778 |   0.277423  |    0.059090     |   0\n",
      "       8779 |   0.255412  |    0.069749     |   1\n",
      "       8780 |   0.178159  |    0.010527     |   0\n",
      "       8781 |   0.234576  |    0.045810     |   0\n",
      "       8782 |   0.223642  |    0.018981     |   0\n",
      "       8783 |   0.061460  |    0.034352     |   2\n",
      "       8784 |   0.188610  |    0.028759     |   0\n",
      "       8785 |   0.027686  |    0.033212     |   2\n",
      "       8786 |   0.057363  |    0.026421     |   2\n",
      "       8787 |   0.043367  |    0.031516     |   2\n",
      "       8788 |   0.193355  |    0.134588     |   1\n",
      "       8789 |   0.221236  |    0.097682     |   1\n",
      "       8790 |   0.308096  |    0.084231     |   1\n",
      "       8791 |   0.237344  |    0.011136     |   0\n",
      "       8792 |   0.000083  |    0.027275     |   2\n",
      "       8793 |   0.000083  |    0.033764     |   2\n",
      "       8794 |   0.203607  |    0.139201     |   1\n",
      "       8795 |   0.000084  |    0.002882     |   2\n",
      "       8796 |   0.199541  |    0.007358     |   0\n",
      "       8797 |   0.262399  |    0.046449     |   0\n",
      "       8798 |   0.277774  |    0.023282     |   0\n",
      "       8799 |   0.253983  |    0.147168     |   1\n",
      "       8800 |   0.000084  |    0.002946     |   2\n",
      "       8801 |   0.000083  |    0.009948     |   2\n",
      "       8802 |   0.310450  |    0.144316     |   1\n",
      "       8803 |   0.252474  |    0.089064     |   1\n",
      "       8804 |   0.176929  |    0.013332     |   0\n",
      "       8805 |   0.281352  |    0.077852     |   1\n",
      "       8806 |   0.207751  |    0.009246     |   0\n",
      "       8807 |   0.182695  |    0.048831     |   0\n",
      "       8808 |   0.000083  |    0.009597     |   2\n",
      "       8809 |   0.070401  |    0.058295     |   2\n",
      "       8810 |   0.065603  |    0.012183     |   2\n",
      "       8811 |   0.212763  |    0.087938     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 8812: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       8812 |   0.070115  |    0.007003     |   2\n",
      "       8813 |   0.257356  |    0.133581     |   1\n",
      "       8814 |   0.287963  |    0.012703     |   0\n",
      "       8815 |   0.270373  |    0.060607     |   0\n",
      "       8816 |   0.052390  |    0.006371     |   2\n",
      "       8817 |   0.140769  |    0.031888     |   0\n",
      "       8818 |   0.326866  |    0.030743     |   0\n",
      "       8819 |   0.207798  |    0.042787     |   0\n",
      "       8820 |   0.169660  |    0.141135     |   1\n",
      "       8821 |   0.053293  |    0.007010     |   2\n",
      "       8822 |   0.195295  |    0.088753     |   1\n",
      "       8823 |   0.252589  |    0.137162     |   1\n",
      "       8824 |   0.228781  |    0.009054     |   0\n",
      "       8825 |   0.256741  |    0.010404     |   0\n",
      "       8826 |   0.199360  |    0.045524     |   0\n",
      "       8827 |   0.070445  |    0.019651     |   2\n",
      "       8828 |   0.035801  |    0.035356     |   2\n",
      "       8829 |   0.229135  |    0.095814     |   1\n",
      "       8830 |   0.251392  |    0.017329     |   0\n",
      "       8831 |   0.201231  |    0.030344     |   0\n",
      "       8832 |   0.053978  |    0.028150     |   2\n",
      "       8833 |   0.228023  |    0.040054     |   0\n",
      "       8834 |   0.062756  |    0.015631     |   2\n",
      "       8835 |   0.249627  |    0.148324     |   1\n",
      "       8836 |   0.214612  |    0.101745     |   1\n",
      "       8837 |   0.076099  |    0.018485     |   2\n",
      "       8838 |   0.290462  |    0.143920     |   1\n",
      "       8839 |   0.283937  |    0.020574     |   1\n",
      "       8840 |   0.173726  |    0.034879     |   0\n",
      "       8841 |   0.063522  |    0.022721     |   2\n",
      "       8842 |   0.177995  |    0.043705     |   0\n",
      "       8843 |   0.030928  |    0.014382     |   2\n",
      "       8844 |   0.281478  |    0.143585     |   1\n",
      "       8845 |   0.273662  |    0.006487     |   0\n",
      "       8846 |   0.243017  |    0.019793     |   0\n",
      "       8847 |   0.000083  |    0.049772     |   2\n",
      "       8848 |   0.006797  |    0.011431     |   2\n",
      "       8849 |   0.244400  |    0.138367     |   1\n",
      "       8850 |   0.215715  |    0.092460     |   1\n",
      "       8851 |   0.210447  |    0.089310     |   1\n",
      "       8852 |   0.100199  |    0.013529     |   2\n",
      "       8853 |   0.228269  |    0.045702     |   0\n",
      "       8854 |   0.047677  |    0.010756     |   2\n",
      "       8855 |   0.239018  |    0.038870     |   0\n",
      "       8856 |   0.213930  |    0.034124     |   0\n",
      "       8857 |   0.203108  |    0.134207     |   1\n",
      "       8858 |   0.070287  |    0.006121     |   2\n",
      "       8859 |   0.209230  |    0.018654     |   0\n",
      "       8860 |   0.057765  |    0.029399     |   2\n",
      "       8861 |   0.239711  |    0.029210     |   0\n",
      "       8862 |   0.026375  |    0.050654     |   2\n",
      "       8863 |   0.185110  |    0.099055     |   1\n",
      "       8864 |   0.232286  |    0.014190     |   0\n",
      "       8865 |   0.198523  |    0.047762     |   0\n",
      "       8866 |   0.305654  |    0.088605     |   1\n",
      "       8867 |   0.292380  |    0.141263     |   1\n",
      "       8868 |   0.214582  |    0.097573     |   1\n",
      "       8869 |   0.229971  |    0.078617     |   1\n",
      "       8870 |   0.267678  |    0.134666     |   1\n",
      "       8871 |   0.258505  |    0.003093     |   0\n",
      "       8872 |   0.058035  |    0.004178     |   2\n",
      "       8873 |   0.274393  |    0.054873     |   0\n",
      "       8874 |   0.251644  |    0.142925     |   1\n",
      "       8875 |   0.246671  |    0.049148     |   1\n",
      "       8876 |   0.206326  |    0.015479     |   0\n",
      "       8877 |   0.196145  |    0.145722     |   1\n",
      "       8878 |   0.191478  |    0.007731     |   0\n",
      "       8879 |   0.043858  |    0.016954     |   2\n",
      "       8880 |   0.250553  |    0.047158     |   0\n",
      "       8881 |   0.000082  |    0.008884     |   2\n",
      "       8882 |   0.230105  |    0.096019     |   1\n",
      "       8883 |   0.225353  |    0.025011     |   0\n",
      "       8884 |   0.270246  |    0.056740     |   0\n",
      "       8885 |   0.000082  |    0.004183     |   2\n",
      "       8886 |   0.197008  |    0.052675     |   0\n",
      "       8887 |   0.237199  |    0.094459     |   1\n",
      "       8888 |   0.000082  |    0.006249     |   2\n",
      "       8889 |   0.177988  |    0.149859     |   1\n",
      "       8890 |   0.158237  |    0.010512     |   0\n",
      "       8891 |   0.220236  |    0.089452     |   1\n",
      "       8892 |   0.000083  |    0.011046     |   2\n",
      "       8893 |   0.269261  |    0.135472     |   1\n",
      "       8894 |   0.256311  |    0.017545     |   0\n",
      "       8895 |   0.179665  |    0.096235     |   1\n",
      "       8896 |   0.296281  |    0.084106     |   1\n",
      "       8897 |   0.226977  |    0.086459     |   1\n",
      "       8898 |   0.000082  |    0.009072     |   2\n",
      "       8899 |   0.268707  |    0.128546     |   1\n",
      "       8900 |   0.175794  |    0.005276     |   0\n",
      "       8901 |   0.206580  |    0.007392     |   0\n",
      "       8902 |   0.000083  |    0.034954     |   2\n",
      "       8903 |   0.207029  |    0.132032     |   1\n",
      "       8904 |   0.219193  |    0.080163     |   1\n",
      "       8905 |   0.264557  |    0.033222     |   0\n",
      "       8906 |   0.215322  |    0.143242     |   1\n",
      "       8907 |   0.239210  |    0.103933     |   1\n",
      "       8908 |   0.203215  |    0.083569     |   1\n",
      "       8909 |   0.180524  |    0.105927     |   1\n",
      "       8910 |   0.230503  |    0.055562     |   1\n",
      "       8911 |   0.068646  |    0.018339     |   2\n",
      "       8912 |   0.064302  |    0.039145     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 8914: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       8913 |   0.217143  |    0.014927     |   0\n",
      "       8914 |   0.276387  |    0.140459     |   1\n",
      "       8915 |   0.071925  |    0.011259     |   2\n",
      "       8916 |   0.173702  |    0.084707     |   1\n",
      "       8917 |   0.237845  |    0.095076     |   1\n",
      "       8918 |   0.263950  |    0.061831     |   1\n",
      "       8919 |   0.275630  |    0.144193     |   1\n",
      "       8920 |   0.234709  |    0.052360     |   1\n",
      "       8921 |   0.053704  |    0.015198     |   2\n",
      "       8922 |   0.053034  |    0.025601     |   2\n",
      "       8923 |   0.186403  |    0.067141     |   0\n",
      "       8924 |   0.169945  |    0.089102     |   1\n",
      "       8925 |   0.066815  |    0.009867     |   2\n",
      "       8926 |   0.205431  |    0.050645     |   0\n",
      "       8927 |   0.252890  |    0.140311     |   1\n",
      "       8928 |   0.202710  |    0.002975     |   0\n",
      "       8929 |   0.036099  |    0.010637     |   2\n",
      "       8930 |   0.053701  |    0.043141     |   2\n",
      "       8931 |   0.206393  |    0.011020     |   0\n",
      "       8932 |   0.059588  |    0.056755     |   2\n",
      "       8933 |   0.076871  |    0.006816     |   2\n",
      "       8934 |   0.233741  |    0.148926     |   1\n",
      "       8935 |   0.065150  |    0.003120     |   2\n",
      "       8936 |   0.032552  |    0.013034     |   2\n",
      "       8937 |   0.000083  |    0.027104     |   2\n",
      "       8938 |   0.007899  |    0.031519     |   2\n",
      "       8939 |   0.228497  |    0.075280     |   1\n",
      "       8940 |   0.097469  |    0.008074     |   2\n",
      "       8941 |   0.186557  |    0.125638     |   1\n",
      "       8942 |   0.203766  |    0.015999     |   0\n",
      "       8943 |   0.044783  |    0.061619     |   2\n",
      "       8944 |   0.231705  |    0.083972     |   1\n",
      "       8945 |   0.177335  |    0.013929     |   0\n",
      "       8946 |   0.257996  |    0.139636     |   1\n",
      "       8947 |   0.067753  |    0.007376     |   2\n",
      "       8948 |   0.060137  |    0.008515     |   2\n",
      "       8949 |   0.188569  |    0.037691     |   0\n",
      "       8950 |   0.206826  |    0.144859     |   1\n",
      "       8951 |   0.204363  |    0.007661     |   0\n",
      "       8952 |   0.023885  |    0.010902     |   2\n",
      "       8953 |   0.054072  |    0.039304     |   2\n",
      "       8954 |   0.205605  |    0.140789     |   1\n",
      "       8955 |   0.221477  |    0.003322     |   0\n",
      "       8956 |   0.043285  |    0.010083     |   2\n",
      "       8957 |   0.270254  |    0.138432     |   1\n",
      "       8958 |   0.000083  |    0.023882     |   2\n",
      "       8959 |   0.294990  |    0.155544     |   1\n",
      "       8960 |   0.000083  |    0.003003     |   2\n",
      "       8961 |   0.000083  |    0.007971     |   2\n",
      "       8962 |   0.236813  |    0.049693     |   0\n",
      "       8963 |   0.239300  |    0.024404     |   0\n",
      "       8964 |   0.000084  |    0.018784     |   2\n",
      "       8965 |   0.262986  |    0.036057     |   0\n",
      "       8966 |   0.000083  |    0.032854     |   2\n",
      "       8967 |   0.000083  |    0.024060     |   2\n",
      "       8968 |   0.224289  |    0.155601     |   1\n",
      "       8969 |   0.064093  |    0.010438     |   2\n",
      "       8970 |   0.216640  |    0.052242     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 8972: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       8971 |   0.062245  |    0.009456     |   2\n",
      "       8972 |   0.189944  |    0.032039     |   0\n",
      "       8973 |   0.070133  |    0.023684     |   2\n",
      "       8974 |   0.239311  |    0.157332     |   1\n",
      "       8975 |   0.053069  |    0.008797     |   2\n",
      "       8976 |   0.222364  |    0.082415     |   1\n",
      "       8977 |   0.242046  |    0.014933     |   0\n",
      "       8978 |   0.239554  |    0.043994     |   0\n",
      "       8979 |   0.218838  |    0.031767     |   0\n",
      "       8980 |   0.229453  |    0.087846     |   1\n",
      "       8981 |   0.205586  |    0.025704     |   0\n",
      "       8982 |   0.050830  |    0.032519     |   2\n",
      "       8983 |   0.221104  |    0.148905     |   1\n",
      "       8984 |   0.199092  |    0.077872     |   1\n",
      "       8985 |   0.063442  |    0.006133     |   2\n",
      "       8986 |   0.314395  |    0.140927     |   1\n",
      "       8987 |   0.237615  |    0.086170     |   1\n",
      "       8988 |   0.034991  |    0.006188     |   2\n",
      "       8989 |   0.257325  |    0.028076     |   0\n",
      "       8990 |   0.270118  |    0.145286     |   1\n",
      "       8991 |   0.054580  |    0.002930     |   2\n",
      "       8992 |   0.263982  |    0.009696     |   0\n",
      "       8993 |   0.230604  |    0.050211     |   0\n",
      "       8994 |   0.190386  |    0.145233     |   1\n",
      "       8995 |   0.225022  |    0.011431     |   0\n",
      "       8996 |   0.285800  |    0.054948     |   1\n",
      "       8997 |   0.244286  |    0.136815     |   1\n",
      "       8998 |   0.245769  |    0.002973     |   0\n",
      "       8999 |   0.061673  |    0.006186     |   2\n",
      "       9000 |   0.218146  |    0.050343     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 9000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 9000: Plotting estimates.\n",
      "Exception in thread neuralnilm-data-process:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 810, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/dk3810/workspace/python/neuralnilm/neuralnilm/data/datathread.py\", line 16, in run\n",
      "    batch = self.data_pipeline.get_batch(**self._get_batch_kwargs)\n",
      "  File \"/home/dk3810/workspace/python/neuralnilm/neuralnilm/data/datapipeline.py\", line 46, in get_batch\n",
      "    batch = self._source_iterators[source_id].next()\n",
      "ValueError: generator already executing\n",
      "\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       9001 |   0.220345  |    0.042609     |   0\n",
      "       9002 |   0.215603  |    0.027826     |   0\n",
      "       9003 |   0.160042  |    0.023137     |   0\n",
      "       9004 |   0.258337  |    0.024265     |   0\n",
      "       9005 |   0.209783  |    0.043426     |   0\n",
      "       9006 |   0.228219  |    0.027182     |   0\n",
      "       9007 |   0.232197  |    0.108264     |   1\n",
      "       9008 |   0.288103  |    0.095255     |   1\n",
      "       9009 |   0.071386  |    0.007791     |   2\n",
      "       9010 |   0.228949  |    0.051308     |   0\n",
      "       9011 |   0.052265  |    0.010057     |   2\n",
      "       9012 |   0.180554  |    0.046228     |   0\n",
      "       9013 |   0.176511  |    0.015182     |   0\n",
      "       9014 |   0.052012  |    0.028930     |   2\n",
      "       9015 |   0.201971  |    0.133060     |   1\n",
      "       9016 |   0.251020  |    0.006467     |   0\n",
      "       9017 |   0.201224  |    0.022466     |   0\n",
      "       9018 |   0.065927  |    0.031478     |   2\n",
      "       9019 |   0.241080  |    0.087508     |   1\n",
      "       9020 |   0.166616  |    0.035456     |   0\n",
      "       9021 |   0.201387  |    0.149223     |   1\n",
      "       9022 |   0.217957  |    0.013269     |   0\n",
      "       9023 |   0.196050  |    0.090552     |   1\n",
      "       9024 |   0.234316  |    0.011198     |   0\n",
      "       9025 |   0.269559  |    0.146003     |   1\n",
      "       9026 |   0.228686  |    0.095752     |   1\n",
      "       9027 |   0.035332  |    0.013162     |   2\n",
      "       9028 |   0.247982  |    0.158544     |   1\n",
      "       9029 |   0.185033  |    0.014857     |   0\n",
      "       9030 |   0.055392  |    0.009559     |   2\n",
      "       9031 |   0.063028  |    0.010721     |   2\n",
      "       9032 |   0.074411  |    0.016654     |   2\n",
      "       9033 |   0.248172  |    0.047215     |   0\n",
      "       9034 |   0.218887  |    0.023900     |   0\n",
      "       9035 |   0.065542  |    0.014662     |   2\n",
      "       9036 |   0.240840  |    0.032315     |   0\n",
      "       9037 |   0.031214  |    0.026568     |   2\n",
      "       9038 |   0.213882  |    0.138862     |   1\n",
      "       9039 |   0.285582  |    0.051732     |   1\n",
      "       9040 |   0.265992  |    0.085278     |   1\n",
      "       9041 |   0.000081  |    0.006432     |   2\n",
      "       9042 |   0.173941  |    0.047231     |   0\n",
      "       9043 |   0.204992  |    0.018550     |   0\n",
      "       9044 |   0.007975  |    0.050222     |   2\n",
      "       9045 |   0.337809  |    0.083626     |   1\n",
      "       9046 |   0.235353  |    0.053958     |   1\n",
      "       9047 |   0.097771  |    0.046785     |   2\n",
      "       9048 |   0.205633  |    0.010640     |   0\n",
      "       9049 |   0.201466  |    0.171198     |   1\n",
      "       9050 |   0.260063  |    0.045496     |   1\n",
      "       9051 |   0.192854  |    0.015052     |   0\n",
      "       9052 |   0.174126  |    0.024506     |   0\n",
      "       9053 |   0.266542  |    0.043085     |   0\n",
      "       9054 |   0.293236  |    0.007003     |   0\n",
      "       9055 |   0.260994  |    0.160731     |   1\n",
      "       9056 |   0.285752  |    0.005114     |   0\n",
      "       9057 |   0.047632  |    0.009518     |   2\n",
      "       9058 |   0.069145  |    0.049548     |   2\n",
      "       9059 |   0.219404  |    0.110068     |   1\n",
      "       9060 |   0.231152  |    0.090470     |   1\n",
      "       9061 |   0.233477  |    0.006786     |   0\n",
      "       9062 |   0.252851  |    0.036307     |   0\n",
      "       9063 |   0.231713  |    0.098133     |   1\n",
      "       9064 |   0.192904  |    0.064625     |   1\n",
      "       9065 |   0.229346  |    0.084539     |   1\n",
      "       9066 |   0.220540  |    0.091950     |   1\n",
      "       9067 |   0.062290  |    0.018614     |   2\n",
      "       9068 |   0.203568  |    0.137844     |   1\n",
      "       9069 |   0.230002  |    0.086185     |   1\n",
      "       9070 |   0.256021  |    0.013129     |   0\n",
      "       9071 |   0.027392  |    0.037062     |   2\n",
      "       9072 |   0.057937  |    0.015387     |   2\n",
      "       9073 |   0.043130  |    0.047760     |   2\n",
      "       9074 |   0.190179  |    0.021585     |   0\n",
      "       9075 |   0.253340  |    0.135393     |   1\n",
      "       9076 |   0.223115  |    0.078510     |   1\n",
      "       9077 |   0.189887  |    0.012792     |   0\n",
      "       9078 |   0.000081  |    0.033874     |   2\n",
      "       9079 |   0.000081  |    0.026040     |   2\n",
      "       9080 |   0.000082  |    0.028831     |   2\n",
      "       9081 |   0.187016  |    0.143824     |   1\n",
      "       9082 |   0.223187  |    0.102416     |   1\n",
      "       9083 |   0.253954  |    0.011466     |   0\n",
      "       9084 |   0.285597  |    0.092464     |   1\n",
      "       9085 |   0.000083  |    0.008443     |   2\n",
      "       9086 |   0.214836  |    0.058116     |   0\n",
      "       9087 |   0.000082  |    0.013198     |   2\n",
      "       9088 |   0.000082  |    0.030341     |   2\n",
      "       9089 |   0.292151  |    0.016980     |   0\n",
      "       9090 |   0.069814  |    0.049790     |   2\n",
      "       9091 |   0.198886  |    0.083931     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 9093: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       9092 |   0.062654  |    0.011812     |   2\n",
      "       9093 |   0.070061  |    0.029615     |   2\n",
      "       9094 |   0.193497  |    0.027227     |   0\n",
      "       9095 |   0.050691  |    0.034411     |   2\n",
      "       9096 |   0.050537  |    0.023811     |   2\n",
      "       9097 |   0.207051  |    0.057904     |   0\n",
      "       9098 |   0.238215  |    0.056626     |   1\n",
      "       9099 |   0.065656  |    0.017360     |   2\n",
      "       9100 |   0.218742  |    0.145106     |   1\n",
      "       9101 |   0.035841  |    0.003898     |   2\n",
      "       9102 |   0.054152  |    0.026485     |   2\n",
      "       9103 |   0.061548  |    0.027260     |   2\n",
      "       9104 |   0.229086  |    0.031354     |   0\n",
      "       9105 |   0.137314  |    0.029219     |   0\n",
      "       9106 |   0.074476  |    0.028070     |   2\n",
      "       9107 |   0.257194  |    0.056734     |   0\n",
      "       9108 |   0.266847  |    0.094454     |   1\n",
      "       9109 |   0.256242  |    0.006023     |   0\n",
      "       9110 |   0.281707  |    0.142092     |   1\n",
      "       9111 |   0.228173  |    0.085743     |   1\n",
      "       9112 |   0.063121  |    0.004423     |   2\n",
      "       9113 |   0.177855  |    0.044358     |   0\n",
      "       9114 |   0.227288  |    0.007983     |   0\n",
      "       9115 |   0.171933  |    0.053497     |   0\n",
      "       9116 |   0.192137  |    0.119724     |   1\n",
      "       9117 |   0.182868  |    0.060894     |   1\n",
      "       9118 |   0.204813  |    0.017864     |   0\n",
      "       9119 |   0.272087  |    0.039672     |   0\n",
      "       9120 |   0.234898  |    0.093197     |   1\n",
      "       9121 |   0.029748  |    0.019184     |   2\n",
      "       9122 |   0.217196  |    0.112832     |   1\n",
      "       9123 |   0.153768  |    0.145432     |   1\n",
      "       9124 |   0.211853  |    0.079421     |   1\n",
      "       9125 |   0.000081  |    0.010391     |   2\n",
      "       9126 |   0.250945  |    0.140746     |   1\n",
      "       9127 |   0.007076  |    0.008644     |   2\n",
      "       9128 |   0.186535  |    0.100539     |   1\n",
      "       9129 |   0.213772  |    0.094137     |   1\n",
      "       9130 |   0.225864  |    0.083229     |   1\n",
      "       9131 |   0.097555  |    0.003457     |   2\n",
      "       9132 |   0.229605  |    0.050002     |   0\n",
      "       9133 |   0.212182  |    0.025097     |   0\n",
      "       9134 |   0.262471  |    0.154944     |   1\n",
      "       9135 |   0.223434  |    0.009002     |   0\n",
      "       9136 |   0.197800  |    0.089810     |   1\n",
      "       9137 |   0.046230  |    0.007914     |   2\n",
      "       9138 |   0.183015  |    0.108210     |   1\n",
      "       9139 |   0.179985  |    0.012926     |   0\n",
      "       9140 |   0.262102  |    0.160374     |   1\n",
      "       9141 |   0.267095  |    0.067258     |   1\n",
      "       9142 |   0.198331  |    0.150063     |   1\n",
      "       9143 |   0.065083  |    0.003169     |   2\n",
      "       9144 |   0.186708  |    0.008945     |   0\n",
      "       9145 |   0.057446  |    0.047785     |   2\n",
      "       9146 |   0.192702  |    0.015199     |   0\n",
      "       9147 |   0.272375  |    0.152193     |   1\n",
      "       9148 |   0.200096  |    0.046725     |   1\n",
      "       9149 |   0.156159  |    0.020703     |   0\n",
      "       9150 |   0.153206  |    0.027019     |   0\n",
      "       9151 |   0.205114  |    0.138138     |   1\n",
      "       9152 |   0.211359  |    0.085510     |   1\n",
      "       9153 |   0.271417  |    0.091800     |   1\n",
      "       9154 |   0.025536  |    0.005847     |   2\n",
      "       9155 |   0.054651  |    0.049886     |   2\n",
      "       9156 |   0.042465  |    0.012067     |   2\n",
      "       9157 |   0.285534  |    0.047802     |   0\n",
      "       9158 |   0.175632  |    0.013411     |   0\n",
      "       9159 |   0.250777  |    0.138789     |   1\n",
      "       9160 |   0.259007  |    0.002888     |   0\n",
      "       9161 |   0.187460  |    0.013713     |   0\n",
      "       9162 |   0.000080  |    0.046941     |   2\n",
      "       9163 |   0.231234  |    0.008949     |   0\n",
      "       9164 |   0.000080  |    0.048642     |   2\n",
      "       9165 |   0.206908  |    0.007635     |   0\n",
      "       9166 |   0.000080  |    0.047391     |   2\n",
      "       9167 |   0.000081  |    0.010518     |   2\n",
      "       9168 |   0.163598  |    0.031331     |   0\n",
      "       9169 |   0.000080  |    0.027254     |   2\n",
      "       9170 |   0.000080  |    0.017105     |   2\n",
      "       9171 |   0.173723  |    0.031078     |   0\n",
      "       9172 |   0.246042  |    0.136011     |   1\n",
      "       9173 |   0.194278  |    0.012286     |   0\n",
      "       9174 |   0.070812  |    0.050619     |   2\n",
      "       9175 |   0.230303  |    0.076087     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 9177: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       9176 |   0.063250  |    0.008757     |   2\n",
      "       9177 |   0.203138  |    0.045024     |   0\n",
      "       9178 |   0.071271  |    0.010305     |   2\n",
      "       9179 |   0.233218  |    0.143632     |   1\n",
      "       9180 |   0.268775  |    0.004948     |   0\n",
      "       9181 |   0.161407  |    0.012632     |   0\n",
      "       9182 |   0.178756  |    0.032401     |   0\n",
      "       9183 |   0.051584  |    0.022837     |   2\n",
      "       9184 |   0.238837  |    0.036053     |   0\n",
      "       9185 |   0.052013  |    0.026435     |   2\n",
      "       9186 |   0.194493  |    0.034685     |   0\n",
      "       9187 |   0.199376  |    0.097430     |   1\n",
      "       9188 |   0.069114  |    0.032101     |   2\n",
      "       9189 |   0.272563  |    0.046250     |   0\n",
      "       9190 |   0.036004  |    0.006314     |   2\n",
      "       9191 |   0.278850  |    0.129396     |   1\n",
      "       9192 |   0.192890  |    0.011306     |   0\n",
      "       9193 |   0.264511  |    0.130601     |   1\n",
      "       9194 |   0.162851  |    0.073270     |   1\n",
      "       9195 |   0.261067  |    0.012534     |   0\n",
      "       9196 |   0.055517  |    0.050818     |   2\n",
      "       9197 |   0.220949  |    0.085788     |   1\n",
      "       9198 |   0.236736  |    0.084450     |   1\n",
      "       9199 |   0.193209  |    0.013747     |   0\n",
      "       9200 |   0.220298  |    0.145944     |   1\n",
      "       9201 |   0.212853  |    0.092886     |   1\n",
      "       9202 |   0.256608  |    0.080287     |   1\n",
      "       9203 |   0.063973  |    0.009836     |   2\n",
      "       9204 |   0.275739  |    0.174955     |   1\n",
      "       9205 |   0.073692  |    0.011341     |   2\n",
      "       9206 |   0.205464  |    0.049844     |   1\n",
      "       9207 |   0.194661  |    0.125903     |   1\n",
      "       9208 |   0.062879  |    0.004206     |   2\n",
      "       9209 |   0.281047  |    0.045794     |   0\n",
      "       9210 |   0.031326  |    0.008586     |   2\n",
      "       9211 |   0.179489  |    0.068194     |   0\n",
      "       9212 |   0.224759  |    0.086688     |   1\n",
      "       9213 |   0.253558  |    0.011017     |   0\n",
      "       9214 |   0.243903  |    0.145058     |   1\n",
      "       9215 |   0.232851  |    0.044236     |   1\n",
      "       9216 |   0.000080  |    0.045454     |   2\n",
      "       9217 |   0.211755  |    0.134524     |   1\n",
      "       9218 |   0.276739  |    0.080540     |   1\n",
      "       9219 |   0.214590  |    0.013026     |   0\n",
      "       9220 |   0.227880  |    0.144775     |   1\n",
      "       9221 |   0.006929  |    0.004573     |   2\n",
      "       9222 |   0.098072  |    0.006792     |   2\n",
      "       9223 |   0.230292  |    0.038347     |   0\n",
      "       9224 |   0.239608  |    0.138405     |   1\n",
      "       9225 |   0.224206  |    0.084565     |   1\n",
      "       9226 |   0.191168  |    0.008372     |   0\n",
      "       9227 |   0.180235  |    0.029734     |   0\n",
      "       9228 |   0.045162  |    0.023725     |   2\n",
      "       9229 |   0.229913  |    0.025566     |   0\n",
      "       9230 |   0.068128  |    0.044475     |   2\n",
      "       9231 |   0.056033  |    0.010799     |   2\n",
      "       9232 |   0.236948  |    0.038921     |   0\n",
      "       9233 |   0.236540  |    0.021583     |   0\n",
      "       9234 |   0.025316  |    0.028106     |   2\n",
      "       9235 |   0.057005  |    0.039535     |   2\n",
      "       9236 |   0.238025  |    0.080238     |   1\n",
      "       9237 |   0.182165  |    0.010946     |   0\n",
      "       9238 |   0.204017  |    0.160492     |   1\n",
      "       9239 |   0.042316  |    0.009722     |   2\n",
      "       9240 |   0.191404  |    0.042238     |   1\n",
      "       9241 |   0.225898  |    0.029706     |   0\n",
      "       9242 |   0.237513  |    0.155472     |   1\n",
      "       9243 |   0.213689  |    0.033930     |   1\n",
      "       9244 |   0.258875  |    0.040950     |   0\n",
      "       9245 |   0.000079  |    0.025491     |   2\n",
      "       9246 |   0.254952  |    0.046220     |   0\n",
      "       9247 |   0.223621  |    0.096254     |   1\n",
      "       9248 |   0.234785  |    0.015843     |   0\n",
      "       9249 |   0.217582  |    0.156984     |   1\n",
      "       9250 |   0.230775  |    0.091265     |   1\n",
      "       9251 |   0.201640  |    0.136320     |   1\n",
      "       9252 |   0.256363  |    0.132153     |   1\n",
      "       9253 |   0.000079  |    0.008899     |   2\n",
      "       9254 |   0.189345  |    0.131624     |   1\n",
      "       9255 |   0.231167  |    0.082859     |   1\n",
      "       9256 |   0.000080  |    0.020250     |   2\n",
      "       9257 |   0.000081  |    0.031487     |   2\n",
      "       9258 |   0.216141  |    0.135024     |   1\n",
      "       9259 |   0.000080  |    0.005236     |   2\n",
      "       9260 |   0.000080  |    0.007826     |   2\n",
      "       9261 |   0.188221  |    0.058887     |   0\n",
      "       9262 |   0.222184  |    0.083905     |   1\n",
      "       9263 |   0.221797  |    0.009967     |   0\n",
      "       9264 |   0.207912  |    0.046483     |   0\n",
      "       9265 |   0.066288  |    0.010599     |   2\n",
      "       9266 |   0.194121  |    0.136060     |   1\n",
      "       9267 |   0.184683  |    0.014067     |   0\n",
      "       9268 |   0.230112  |    0.045369     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 9270: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       9269 |   0.062150  |    0.008779     |   2\n",
      "       9270 |   0.235553  |    0.038941     |   0\n",
      "       9271 |   0.228046  |    0.022574     |   0\n",
      "       9272 |   0.216658  |    0.104098     |   1\n",
      "       9273 |   0.067139  |    0.007994     |   2\n",
      "       9274 |   0.050410  |    0.046001     |   2\n",
      "       9275 |   0.241751  |    0.149085     |   1\n",
      "       9276 |   0.236763  |    0.051384     |   1\n",
      "       9277 |   0.050023  |    0.009001     |   2\n",
      "       9278 |   0.199846  |    0.137418     |   1\n",
      "       9279 |   0.067299  |    0.006390     |   2\n",
      "       9280 |   0.231223  |    0.048091     |   0\n",
      "       9281 |   0.230010  |    0.086172     |   1\n",
      "       9282 |   0.035618  |    0.024273     |   2\n",
      "       9283 |   0.236367  |    0.037466     |   0\n",
      "       9284 |   0.219316  |    0.026757     |   0\n",
      "       9285 |   0.054279  |    0.034273     |   2\n",
      "       9286 |   0.181181  |    0.132095     |   1\n",
      "       9287 |   0.062302  |    0.015638     |   2\n",
      "       9288 |   0.186586  |    0.141478     |   1\n",
      "       9289 |   0.071508  |    0.005548     |   2\n",
      "       9290 |   0.233708  |    0.008466     |   0\n",
      "       9291 |   0.216493  |    0.049899     |   0\n",
      "       9292 |   0.178533  |    0.102547     |   1\n",
      "       9293 |   0.064113  |    0.007534     |   2\n",
      "       9294 |   0.228213  |    0.145925     |   1\n",
      "       9295 |   0.229028  |    0.012871     |   0\n",
      "       9296 |   0.031401  |    0.034851     |   2\n",
      "       9297 |   0.218421  |    0.162063     |   1\n",
      "       9298 |   0.213051  |    0.009771     |   0\n",
      "       9299 |   0.222975  |    0.067050     |   1\n",
      "       9300 |   0.201959  |    0.090420     |   1\n",
      "       9301 |   0.277701  |    0.099615     |   1\n",
      "       9302 |   0.234204  |    0.012505     |   0\n",
      "       9303 |   0.000079  |    0.023975     |   2\n",
      "       9304 |   0.189299  |    0.048784     |   0\n",
      "       9305 |   0.007666  |    0.008449     |   2\n",
      "       9306 |   0.169595  |    0.027988     |   0\n",
      "       9307 |   0.208791  |    0.026947     |   0\n",
      "       9308 |   0.224676  |    0.028579     |   0\n",
      "       9309 |   0.242947  |    0.046040     |   0\n",
      "       9310 |   0.095106  |    0.005340     |   2\n",
      "       9311 |   0.241993  |    0.042469     |   0\n",
      "       9312 |   0.227840  |    0.012216     |   0\n",
      "       9313 |   0.046896  |    0.036159     |   2\n",
      "       9314 |   0.220501  |    0.030101     |   0\n",
      "       9315 |   0.071730  |    0.031273     |   2\n",
      "       9316 |   0.235041  |    0.027447     |   0\n",
      "       9317 |   0.255402  |    0.141998     |   1\n",
      "       9318 |   0.235355  |    0.015104     |   0\n",
      "       9319 |   0.260515  |    0.065565     |   1\n",
      "       9320 |   0.063231  |    0.005827     |   2\n",
      "       9321 |   0.028195  |    0.060744     |   2\n",
      "       9322 |   0.286485  |    0.094977     |   1\n",
      "       9323 |   0.059004  |    0.006083     |   2\n",
      "       9324 |   0.198672  |    0.024585     |   0\n",
      "       9325 |   0.043079  |    0.028907     |   2\n",
      "       9326 |   0.273921  |    0.099753     |   1\n",
      "       9327 |   0.195999  |    0.091806     |   1\n",
      "       9328 |   0.247489  |    0.096969     |   1\n",
      "       9329 |   0.241235  |    0.015518     |   0\n",
      "       9330 |   0.242359  |    0.148717     |   1\n",
      "       9331 |   0.300514  |    0.046644     |   1\n",
      "       9332 |   0.210608  |    0.024527     |   0\n",
      "       9333 |   0.000079  |    0.033123     |   2\n",
      "       9334 |   0.227896  |    0.095665     |   1\n",
      "       9335 |   0.210505  |    0.089163     |   1\n",
      "       9336 |   0.183316  |    0.019834     |   0\n",
      "       9337 |   0.280996  |    0.147195     |   1\n",
      "       9338 |   0.000079  |    0.003637     |   2\n",
      "       9339 |   0.202482  |    0.007390     |   0\n",
      "       9340 |   0.237368  |    0.045489     |   0\n",
      "       9341 |   0.235071  |    0.150113     |   1\n",
      "       9342 |   0.000080  |    0.024138     |   2\n",
      "       9343 |   0.237443  |    0.030426     |   1\n",
      "       9344 |   0.228126  |    0.032542     |   0\n",
      "       9345 |   0.000081  |    0.029852     |   2\n",
      "       9346 |   0.000080  |    0.005531     |   2\n",
      "       9347 |   0.000080  |    0.042848     |   2\n",
      "       9348 |   0.066158  |    0.005539     |   2\n",
      "       9349 |   0.216766  |    0.040128     |   0\n",
      "       9350 |   0.283632  |    0.028412     |   0\n",
      "       9351 |   0.063189  |    0.032987     |   2\n",
      "       9352 |   0.146280  |    0.143619     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 9353: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       9353 |   0.231448  |    0.074905     |   1\n",
      "       9354 |   0.203587  |    0.081074     |   1\n",
      "       9355 |   0.219778  |    0.089323     |   1\n",
      "       9356 |   0.276193  |    0.050682     |   0\n",
      "       9357 |   0.254945  |    0.083685     |   1\n",
      "       9358 |   0.195454  |    0.013290     |   0\n",
      "       9359 |   0.229233  |    0.096547     |   1\n",
      "       9360 |   0.283135  |    0.101495     |   1\n",
      "       9361 |   0.231150  |    0.044866     |   1\n",
      "       9362 |   0.066961  |    0.032459     |   2\n",
      "       9363 |   0.049915  |    0.045407     |   2\n",
      "       9364 |   0.305588  |    0.079683     |   1\n",
      "       9365 |   0.235324  |    0.014547     |   0\n",
      "       9366 |   0.198056  |    0.035069     |   0\n",
      "       9367 |   0.051392  |    0.016864     |   2\n",
      "       9368 |   0.066091  |    0.022974     |   2\n",
      "       9369 |   0.237514  |    0.052225     |   0\n",
      "       9370 |   0.035033  |    0.013015     |   2\n",
      "       9371 |   0.301809  |    0.149195     |   1\n",
      "       9372 |   0.054228  |    0.004554     |   2\n",
      "       9373 |   0.262439  |    0.094399     |   1\n",
      "       9374 |   0.237497  |    0.088415     |   1\n",
      "       9375 |   0.247204  |    0.134994     |   1\n",
      "       9376 |   0.233143  |    0.007455     |   0\n",
      "       9377 |   0.058721  |    0.005782     |   2\n",
      "       9378 |   0.193830  |    0.015340     |   0\n",
      "       9379 |   0.260191  |    0.049244     |   0\n",
      "       9380 |   0.073692  |    0.016023     |   2\n",
      "       9381 |   0.065157  |    0.030609     |   2\n",
      "       9382 |   0.263146  |    0.142305     |   1\n",
      "       9383 |   0.201257  |    0.011321     |   0\n",
      "       9384 |   0.219295  |    0.078986     |   1\n",
      "       9385 |   0.030358  |    0.008670     |   2\n",
      "       9386 |   0.277389  |    0.155680     |   1\n",
      "       9387 |   0.252822  |    0.003799     |   0\n",
      "       9388 |   0.291840  |    0.094542     |   1\n",
      "       9389 |   0.213488  |    0.085230     |   1\n",
      "       9390 |   0.000078  |    0.022129     |   2\n",
      "       9391 |   0.289902  |    0.143474     |   1\n",
      "       9392 |   0.168499  |    0.009340     |   0\n",
      "       9393 |   0.217836  |    0.009332     |   0\n",
      "       9394 |   0.285741  |    0.102251     |   1\n",
      "       9395 |   0.007943  |    0.032442     |   2\n",
      "       9396 |   0.094711  |    0.016113     |   2\n",
      "       9397 |   0.202572  |    0.031740     |   0\n",
      "       9398 |   0.175116  |    0.031999     |   0\n",
      "       9399 |   0.191394  |    0.011521     |   0\n",
      "       9400 |   0.043174  |    0.040583     |   2\n",
      "       9401 |   0.176984  |    0.018248     |   0\n",
      "       9402 |   0.069333  |    0.032668     |   2\n",
      "       9403 |   0.227336  |    0.150617     |   1\n",
      "       9404 |   0.057917  |    0.004382     |   2\n",
      "       9405 |   0.024581  |    0.008151     |   2\n",
      "       9406 |   0.177035  |    0.043203     |   0\n",
      "       9407 |   0.210470  |    0.017135     |   0\n",
      "       9408 |   0.182290  |    0.064258     |   0\n",
      "       9409 |   0.275596  |    0.083441     |   1\n",
      "       9410 |   0.233750  |    0.016047     |   0\n",
      "       9411 |   0.225582  |    0.044827     |   0\n",
      "       9412 |   0.058276  |    0.004717     |   2\n",
      "       9413 |   0.274225  |    0.045793     |   0\n",
      "       9414 |   0.222514  |    0.094658     |   1\n",
      "       9415 |   0.196288  |    0.035131     |   0\n",
      "       9416 |   0.219575  |    0.080033     |   1\n",
      "       9417 |   0.042253  |    0.024106     |   2\n",
      "       9418 |   0.206308  |    0.171353     |   1\n",
      "       9419 |   0.245966  |    0.064239     |   1\n",
      "       9420 |   0.251271  |    0.085608     |   1\n",
      "       9421 |   0.000078  |    0.013214     |   2\n",
      "       9422 |   0.205612  |    0.048843     |   0\n",
      "       9423 |   0.260939  |    0.010030     |   0\n",
      "       9424 |   0.196974  |    0.028866     |   0\n",
      "       9425 |   0.251855  |    0.040918     |   0\n",
      "       9426 |   0.000078  |    0.023169     |   2\n",
      "       9427 |   0.287157  |    0.092261     |   1\n",
      "       9428 |   0.253138  |    0.032520     |   0\n",
      "       9429 |   0.239820  |    0.145427     |   1\n",
      "       9430 |   0.212016  |    0.046219     |   1\n",
      "       9431 |   0.000078  |    0.009618     |   2\n",
      "       9432 |   0.000079  |    0.057465     |   2\n",
      "       9433 |   0.000078  |    0.007877     |   2\n",
      "       9434 |   0.000077  |    0.041343     |   2\n",
      "       9435 |   0.203170  |    0.022678     |   0\n",
      "       9436 |   0.183951  |    0.149803     |   1\n",
      "       9437 |   0.066533  |    0.010100     |   2\n",
      "       9438 |   0.170276  |    0.083783     |   1\n",
      "       9439 |   0.062983  |    0.031439     |   2\n",
      "       9440 |   0.228509  |    0.168860     |   1\n",
      "       9441 |   0.250489  |    0.049497     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 9442: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       9442 |   0.235102  |    0.022213     |   0\n",
      "       9443 |   0.192889  |    0.146396     |   1\n",
      "       9444 |   0.069261  |    0.009805     |   2\n",
      "       9445 |   0.228109  |    0.096099     |   1\n",
      "       9446 |   0.050408  |    0.008526     |   2\n",
      "       9447 |   0.256587  |    0.088361     |   0\n",
      "       9448 |   0.225551  |    0.082292     |   1\n",
      "       9449 |   0.238900  |    0.020703     |   0\n",
      "       9450 |   0.209372  |    0.121801     |   1\n",
      "       9451 |   0.167264  |    0.017988     |   0\n",
      "       9452 |   0.052031  |    0.032430     |   2\n",
      "       9453 |   0.064609  |    0.016164     |   2\n",
      "       9454 |   0.274076  |    0.056222     |   0\n",
      "       9455 |   0.239998  |    0.094705     |   1\n",
      "       9456 |   0.034617  |    0.010699     |   2\n",
      "       9457 |   0.271085  |    0.050524     |   0\n",
      "       9458 |   0.055406  |    0.013468     |   2\n",
      "       9459 |   0.176308  |    0.166859     |   1\n",
      "       9460 |   0.235980  |    0.088355     |   1\n",
      "       9461 |   0.194437  |    0.087048     |   1\n",
      "       9462 |   0.065876  |    0.007194     |   2\n",
      "       9463 |   0.170217  |    0.055819     |   0\n",
      "       9464 |   0.201155  |    0.094960     |   1\n",
      "       9465 |   0.236706  |    0.020739     |   0\n",
      "       9466 |   0.274151  |    0.088381     |   1\n",
      "       9467 |   0.071506  |    0.005042     |   2\n",
      "       9468 |   0.205316  |    0.033217     |   0\n",
      "       9469 |   0.063254  |    0.025200     |   2\n",
      "       9470 |   0.032051  |    0.044481     |   2\n",
      "       9471 |   0.000078  |    0.027179     |   2\n",
      "       9472 |   0.292919  |    0.126633     |   1\n",
      "       9473 |   0.173969  |    0.072068     |   1\n",
      "       9474 |   0.243230  |    0.125346     |   1\n",
      "       9475 |   0.228519  |    0.046113     |   1\n",
      "       9476 |   0.007402  |    0.021834     |   2\n",
      "       9477 |   0.094294  |    0.023925     |   2\n",
      "       9478 |   0.244601  |    0.028844     |   0\n",
      "       9479 |   0.043470  |    0.021632     |   2\n",
      "       9480 |   0.185119  |    0.146556     |   1\n",
      "       9481 |   0.195281  |    0.018949     |   0\n",
      "       9482 |   0.261115  |    0.020659     |   0\n",
      "       9483 |   0.164141  |    0.020603     |   1\n",
      "       9484 |   0.067767  |    0.028312     |   2\n",
      "       9485 |   0.193783  |    0.065578     |   1\n",
      "       9486 |   0.058299  |    0.022250     |   2\n",
      "       9487 |   0.024475  |    0.028680     |   2\n",
      "       9488 |   0.054821  |    0.026456     |   2\n",
      "       9489 |   0.187707  |    0.125350     |   1\n",
      "       9490 |   0.238592  |    0.035563     |   1\n",
      "       9491 |   0.040427  |    0.040232     |   2\n",
      "       9492 |   0.224243  |    0.105476     |   1\n",
      "       9493 |   0.000078  |    0.010451     |   2\n",
      "       9494 |   0.249940  |    0.110878     |   1\n",
      "       9495 |   0.207139  |    0.042327     |   1\n",
      "       9496 |   0.000078  |    0.045606     |   2\n",
      "       9497 |   0.226255  |    0.009256     |   0\n",
      "       9498 |   0.158683  |    0.044514     |   0\n",
      "       9499 |   0.000078  |    0.017464     |   2\n",
      "       9500 |   0.268680  |    0.095173     |   1\n",
      "       9501 |   0.220447  |    0.188430     |   1\n",
      "       9502 |   0.065232  |    0.020662     |   2\n",
      "       9503 |   0.255605  |    0.057285     |   1\n",
      "       9504 |   0.293095  |    0.020361     |   0\n",
      "       9505 |   0.210652  |    0.031670     |   0\n",
      "       9506 |   0.048263  |    0.021696     |   2\n",
      "       9507 |   0.049861  |    0.051105     |   2\n",
      "       9508 |   0.315150  |    0.096162     |   1\n",
      "       9509 |   0.255215  |    0.014148     |   0\n",
      "       9510 |   0.063212  |    0.026574     |   2\n",
      "       9511 |   0.235001  |    0.043217     |   0\n",
      "       9512 |   0.170932  |    0.015645     |   0\n",
      "       9513 |   0.034394  |    0.031640     |   2\n",
      "       9514 |   0.207967  |    0.018919     |   0\n",
      "       9515 |   0.214140  |    0.041365     |   0\n",
      "       9516 |   0.052800  |    0.010551     |   2\n",
      "       9517 |   0.166903  |    0.038623     |   0\n",
      "       9518 |   0.063073  |    0.015738     |   2\n",
      "       9519 |   0.219854  |    0.071081     |   0\n",
      "       9520 |   0.194465  |    0.118330     |   1\n",
      "       9521 |   0.254372  |    0.092911     |   1\n",
      "       9522 |   0.073213  |    0.008081     |   2\n",
      "       9523 |   0.060986  |    0.009342     |   2\n",
      "       9524 |   0.187134  |    0.031273     |   0\n",
      "       9525 |   0.145539  |    0.038233     |   0\n",
      "       9526 |   0.236843  |    0.140350     |   1\n",
      "       9527 |   0.227943  |    0.007343     |   0\n",
      "       9528 |   0.186848  |    0.011246     |   0\n",
      "       9529 |   0.030368  |    0.043065     |   2\n",
      "       9530 |   0.164808  |    0.041759     |   0\n",
      "       9531 |   0.232684  |    0.146996     |   1\n",
      "       9532 |   0.204880  |    0.048280     |   1\n",
      "       9533 |   0.000077  |    0.028228     |   2\n",
      "       9534 |   0.256064  |    0.108404     |   1\n",
      "       9535 |   0.157391  |    0.132263     |   1\n",
      "       9536 |   0.229289  |    0.006086     |   0\n",
      "       9537 |   0.237417  |    0.011444     |   0\n",
      "       9538 |   0.247283  |    0.144282     |   1\n",
      "       9539 |   0.007172  |    0.007016     |   2\n",
      "       9540 |   0.091683  |    0.024756     |   2\n",
      "       9541 |   0.224566  |    0.030231     |   0\n",
      "       9542 |   0.274732  |    0.155304     |   1\n",
      "       9543 |   0.229455  |    0.056083     |   1\n",
      "       9544 |   0.236974  |    0.020312     |   0\n",
      "       9545 |   0.045873  |    0.050090     |   2\n",
      "       9546 |   0.067988  |    0.015564     |   2\n",
      "       9547 |   0.210880  |    0.138115     |   1\n",
      "       9548 |   0.191293  |    0.004768     |   0\n",
      "       9549 |   0.200300  |    0.033906     |   0\n",
      "       9550 |   0.191935  |    0.059610     |   0\n",
      "       9551 |   0.231689  |    0.088715     |   1\n",
      "       9552 |   0.214413  |    0.017050     |   0\n",
      "       9553 |   0.061312  |    0.014733     |   2\n",
      "       9554 |   0.025487  |    0.028826     |   2\n",
      "       9555 |   0.056533  |    0.032069     |   2\n",
      "       9556 |   0.041740  |    0.025639     |   2\n",
      "       9557 |   0.228094  |    0.161666     |   1\n",
      "       9558 |   0.236480  |    0.010577     |   1\n",
      "       9559 |   0.187875  |    0.048711     |   0\n",
      "       9560 |   0.175305  |    0.042582     |   0\n",
      "       9561 |   0.143867  |    0.081008     |   1\n",
      "       9562 |   0.189751  |    0.010068     |   0\n",
      "       9563 |   0.281680  |    0.130303     |   1\n",
      "       9564 |   0.000076  |    0.009558     |   2\n",
      "       9565 |   0.000077  |    0.029185     |   2\n",
      "       9566 |   0.263307  |    0.136544     |   1\n",
      "       9567 |   0.000077  |    0.013629     |   2\n",
      "       9568 |   0.194341  |    0.055679     |   1\n",
      "       9569 |   0.177250  |    0.128010     |   1\n",
      "       9570 |   0.000078  |    0.009026     |   2\n",
      "       9571 |   0.275345  |    0.142009     |   1\n",
      "       9572 |   0.185549  |    0.049711     |   1\n",
      "       9573 |   0.246347  |    0.093260     |   1\n",
      "       9574 |   0.166905  |    0.025014     |   0\n",
      "       9575 |   0.207833  |    0.151021     |   1\n",
      "       9576 |   0.000077  |    0.003058     |   2\n",
      "       9577 |   0.000077  |    0.008191     |   2\n",
      "       9578 |   0.203997  |    0.152087     |   1\n",
      "       9579 |   0.281138  |    0.005089     |   0\n",
      "       9580 |   0.066801  |    0.011902     |   2\n",
      "       9581 |   0.239985  |    0.145053     |   1\n",
      "       9582 |   0.060580  |    0.008273     |   2\n",
      "       9583 |   0.255316  |    0.098385     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 9585: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       9584 |   0.212073  |    0.020767     |   0\n",
      "       9585 |   0.211669  |    0.126213     |   1\n",
      "       9586 |   0.067773  |    0.016241     |   2\n",
      "       9587 |   0.210658  |    0.132554     |   1\n",
      "       9588 |   0.049737  |    0.010990     |   2\n",
      "       9589 |   0.051356  |    0.031334     |   2\n",
      "       9590 |   0.213622  |    0.099214     |   1\n",
      "       9591 |   0.067156  |    0.020885     |   2\n",
      "       9592 |   0.257925  |    0.042626     |   0\n",
      "       9593 |   0.147306  |    0.008017     |   0\n",
      "       9594 |   0.035230  |    0.052480     |   2\n",
      "       9595 |   0.230079  |    0.057496     |   1\n",
      "       9596 |   0.212213  |    0.023360     |   0\n",
      "       9597 |   0.054431  |    0.045709     |   2\n",
      "       9598 |   0.059887  |    0.016012     |   2\n",
      "       9599 |   0.219392  |    0.088703     |   1\n",
      "       9600 |   0.074009  |    0.012792     |   2\n",
      "       9601 |   0.188817  |    0.134269     |   1\n",
      "       9602 |   0.204051  |    0.014601     |   0\n",
      "       9603 |   0.065119  |    0.041984     |   2\n",
      "       9604 |   0.169671  |    0.095465     |   1\n",
      "       9605 |   0.032842  |    0.004521     |   2\n",
      "       9606 |   0.000077  |    0.046278     |   2\n",
      "       9607 |   0.007694  |    0.007962     |   2\n",
      "       9608 |   0.171605  |    0.044483     |   0\n",
      "       9609 |   0.090353  |    0.008012     |   2\n",
      "       9610 |   0.211110  |    0.028345     |   0\n",
      "       9611 |   0.235429  |    0.142464     |   1\n",
      "       9612 |   0.250726  |    0.002926     |   0\n",
      "       9613 |   0.043727  |    0.011085     |   2\n",
      "       9614 |   0.216931  |    0.104383     |   1\n",
      "       9615 |   0.284007  |    0.028558     |   0\n",
      "       9616 |   0.138337  |    0.147257     |   1\n",
      "       9617 |   0.268047  |    0.050647     |   1\n",
      "       9618 |   0.202022  |    0.016091     |   0\n",
      "       9619 |   0.150630  |    0.046735     |   0\n",
      "       9620 |   0.238779  |    0.094775     |   1\n",
      "       9621 |   0.258013  |    0.030058     |   0\n",
      "       9622 |   0.287784  |    0.137813     |   1\n",
      "       9623 |   0.251783  |    0.075904     |   1\n",
      "       9624 |   0.237407  |    0.094598     |   1\n",
      "       9625 |   0.067524  |    0.019907     |   2\n",
      "       9626 |   0.209599  |    0.144984     |   1\n",
      "       9627 |   0.236736  |    0.007254     |   0\n",
      "       9628 |   0.213551  |    0.157115     |   1\n",
      "       9629 |   0.224722  |    0.007113     |   0\n",
      "       9630 |   0.186191  |    0.016448     |   0\n",
      "       9631 |   0.266675  |    0.153492     |   1\n",
      "       9632 |   0.056554  |    0.005870     |   2\n",
      "       9633 |   0.221515  |    0.032258     |   0\n",
      "       9634 |   0.161627  |    0.086098     |   1\n",
      "       9635 |   0.195463  |    0.006977     |   0\n",
      "       9636 |   0.200128  |    0.061657     |   0\n",
      "       9637 |   0.243105  |    0.024760     |   1\n",
      "       9638 |   0.191860  |    0.154839     |   1\n",
      "       9639 |   0.201924  |    0.054738     |   1\n",
      "       9640 |   0.228192  |    0.023579     |   0\n",
      "       9641 |   0.258918  |    0.025783     |   0\n",
      "       9642 |   0.219749  |    0.024817     |   0\n",
      "       9643 |   0.248846  |    0.049669     |   0\n",
      "       9644 |   0.195884  |    0.017442     |   0\n",
      "       9645 |   0.254960  |    0.146976     |   1\n",
      "       9646 |   0.216438  |    0.046002     |   1\n",
      "       9647 |   0.197406  |    0.035274     |   0\n",
      "       9648 |   0.026303  |    0.015190     |   2\n",
      "       9649 |   0.223043  |    0.041675     |   0\n",
      "       9650 |   0.240389  |    0.020940     |   0\n",
      "       9651 |   0.269727  |    0.016976     |   0\n",
      "       9652 |   0.060984  |    0.032113     |   2\n",
      "       9653 |   0.238242  |    0.040439     |   0\n",
      "       9654 |   0.202922  |    0.141034     |   1\n",
      "       9655 |   0.039212  |    0.014468     |   2\n",
      "       9656 |   0.269998  |    0.089532     |   1\n",
      "       9657 |   0.277107  |    0.005386     |   0\n",
      "       9658 |   0.148274  |    0.138311     |   1\n",
      "       9659 |   0.000075  |    0.003069     |   2\n",
      "       9660 |   0.000076  |    0.008383     |   2\n",
      "       9661 |   0.244046  |    0.046459     |   0\n",
      "       9662 |   0.281492  |    0.094026     |   1\n",
      "       9663 |   0.000076  |    0.017383     |   2\n",
      "       9664 |   0.262057  |    0.139047     |   1\n",
      "       9665 |   0.281027  |    0.035703     |   1\n",
      "       9666 |   0.153165  |    0.129474     |   1\n",
      "       9667 |   0.229399  |    0.008783     |   0\n",
      "       9668 |   0.000077  |    0.024229     |   2\n",
      "       9669 |   0.249497  |    0.035194     |   0\n",
      "       9670 |   0.000076  |    0.020591     |   2\n",
      "       9671 |   0.246457  |    0.032241     |   0\n",
      "       9672 |   0.200993  |    0.027689     |   0\n",
      "       9673 |   0.000076  |    0.039778     |   2\n",
      "       9674 |   0.247642  |    0.074688     |   1\n",
      "       9675 |   0.229428  |    0.143636     |   1\n",
      "       9676 |   0.071247  |    0.009186     |   2\n",
      "       9677 |   0.062035  |    0.004006     |   2\n",
      "       9678 |   0.259393  |    0.096671     |   1\n",
      "       9679 |   0.179037  |    0.019008     |   0\n",
      "       9680 |   0.166581  |    0.034548     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 9682: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       9681 |   0.277753  |    0.023280     |   0\n",
      "       9682 |   0.230270  |    0.020539     |   0\n",
      "       9683 |   0.209497  |    0.031324     |   0\n",
      "       9684 |   0.069653  |    0.026342     |   2\n",
      "       9685 |   0.051546  |    0.034148     |   2\n",
      "       9686 |   0.050891  |    0.024746     |   2\n",
      "       9687 |   0.317480  |    0.093375     |   1\n",
      "       9688 |   0.207064  |    0.142739     |   1\n",
      "       9689 |   0.069706  |    0.003122     |   2\n",
      "       9690 |   0.180373  |    0.012876     |   0\n",
      "       9691 |   0.249657  |    0.099105     |   1\n",
      "       9692 |   0.199275  |    0.140316     |   1\n",
      "       9693 |   0.177496  |    0.077350     |   1\n",
      "       9694 |   0.247775  |    0.008658     |   0\n",
      "       9695 |   0.190426  |    0.023974     |   0\n",
      "       9696 |   0.034916  |    0.025922     |   2\n",
      "       9697 |   0.156118  |    0.138279     |   1\n",
      "       9698 |   0.055251  |    0.006418     |   2\n",
      "       9699 |   0.241789  |    0.022246     |   0\n",
      "       9700 |   0.064636  |    0.023987     |   2\n",
      "       9701 |   0.075207  |    0.019614     |   2\n",
      "       9702 |   0.060063  |    0.039021     |   2\n",
      "       9703 |   0.031017  |    0.009389     |   2\n",
      "       9704 |   0.000075  |    0.046147     |   2\n",
      "       9705 |   0.183429  |    0.014109     |   0\n",
      "       9706 |   0.006705  |    0.031052     |   2\n",
      "       9707 |   0.238531  |    0.036037     |   0\n",
      "       9708 |   0.185971  |    0.149818     |   1\n",
      "       9709 |   0.142939  |    0.015685     |   0\n",
      "       9710 |   0.152821  |    0.004676     |   0\n",
      "       9711 |   0.095002  |    0.033413     |   2\n",
      "       9712 |   0.273854  |    0.084670     |   1\n",
      "       9713 |   0.047891  |    0.044985     |   2\n",
      "       9714 |   0.190419  |    0.032174     |   0\n",
      "       9715 |   0.281296  |    0.151576     |   1\n",
      "       9716 |   0.241006  |    0.019713     |   0\n",
      "       9717 |   0.211291  |    0.057113     |   1\n",
      "       9718 |   0.220540  |    0.006451     |   0\n",
      "       9719 |   0.232437  |    0.044437     |   0\n",
      "       9720 |   0.258186  |    0.102486     |   1\n",
      "       9721 |   0.067482  |    0.005338     |   2\n",
      "       9722 |   0.176366  |    0.036418     |   0\n",
      "       9723 |   0.174214  |    0.167593     |   1\n",
      "       9724 |   0.206833  |    0.007697     |   0\n",
      "       9725 |   0.220622  |    0.074349     |   1\n",
      "       9726 |   0.266107  |    0.004297     |   0\n",
      "       9727 |   0.196875  |    0.040394     |   0\n",
      "       9728 |   0.194223  |    0.007445     |   0\n",
      "       9729 |   0.058327  |    0.048947     |   2\n",
      "       9730 |   0.236313  |    0.011382     |   0\n",
      "       9731 |   0.207317  |    0.048593     |   0\n",
      "       9732 |   0.027129  |    0.018907     |   2\n",
      "       9733 |   0.283565  |    0.105062     |   1\n",
      "       9734 |   0.058928  |    0.007048     |   2\n",
      "       9735 |   0.041407  |    0.041369     |   2\n",
      "       9736 |   0.270627  |    0.027101     |   0\n",
      "       9737 |   0.258191  |    0.068660     |   0\n",
      "       9738 |   0.236993  |    0.052549     |   1\n",
      "       9739 |   0.000075  |    0.034258     |   2\n",
      "       9740 |   0.262308  |    0.144303     |   1\n",
      "       9741 |   0.000075  |    0.002954     |   2\n",
      "       9742 |   0.221684  |    0.007084     |   0\n",
      "       9743 |   0.230032  |    0.135905     |   1\n",
      "       9744 |   0.000075  |    0.002853     |   2\n",
      "       9745 |   0.239659  |    0.004275     |   0\n",
      "       9746 |   0.000076  |    0.040644     |   2\n",
      "       9747 |   0.266948  |    0.028390     |   0\n",
      "       9748 |   0.000075  |    0.044961     |   2\n",
      "       9749 |   0.271879  |    0.082779     |   1\n",
      "       9750 |   0.000075  |    0.006201     |   2\n",
      "       9751 |   0.255246  |    0.047908     |   0\n",
      "       9752 |   0.070844  |    0.009348     |   2\n",
      "       9753 |   0.238580  |    0.037364     |   0\n",
      "       9754 |   0.190888  |    0.022337     |   0\n",
      "       9755 |   0.251856  |    0.029986     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 9757: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       9756 |   0.061277  |    0.014357     |   2\n",
      "       9757 |   0.152481  |    0.028563     |   0\n",
      "       9758 |   0.071847  |    0.027798     |   2\n",
      "       9759 |   0.053007  |    0.040129     |   2\n",
      "       9760 |   0.156720  |    0.017962     |   0\n",
      "       9761 |   0.051660  |    0.042009     |   2\n",
      "       9762 |   0.177779  |    0.101185     |   1\n",
      "       9763 |   0.205008  |    0.010927     |   0\n",
      "       9764 |   0.068399  |    0.041041     |   2\n",
      "       9765 |   0.247415  |    0.025811     |   0\n",
      "       9766 |   0.208977  |    0.143946     |   1\n",
      "       9767 |   0.173371  |    0.008395     |   0\n",
      "       9768 |   0.036003  |    0.009665     |   2\n",
      "       9769 |   0.053572  |    0.027096     |   2\n",
      "       9770 |   0.217078  |    0.116942     |   1\n",
      "       9771 |   0.281594  |    0.083514     |   1\n",
      "       9772 |   0.065032  |    0.005344     |   2\n",
      "       9773 |   0.074506  |    0.047744     |   2\n",
      "       9774 |   0.258677  |    0.088014     |   1\n",
      "       9775 |   0.060953  |    0.014159     |   2\n",
      "       9776 |   0.165504  |    0.031708     |   0\n",
      "       9777 |   0.031088  |    0.028720     |   2\n",
      "       9778 |   0.182543  |    0.027327     |   0\n",
      "       9779 |   0.323592  |    0.051485     |   0\n",
      "       9780 |   0.000075  |    0.006608     |   2\n",
      "       9781 |   0.189376  |    0.045977     |   0\n",
      "       9782 |   0.211780  |    0.015115     |   0\n",
      "       9783 |   0.263466  |    0.045650     |   0\n",
      "       9784 |   0.213458  |    0.088004     |   1\n",
      "       9785 |   0.262587  |    0.081036     |   1\n",
      "       9786 |   0.007250  |    0.008884     |   2\n",
      "       9787 |   0.281293  |    0.141503     |   1\n",
      "       9788 |   0.242390  |    0.003538     |   0\n",
      "       9789 |   0.091423  |    0.021512     |   2\n",
      "       9790 |   0.274357  |    0.147901     |   1\n",
      "       9791 |   0.043568  |    0.003505     |   2\n",
      "       9792 |   0.066019  |    0.011708     |   2\n",
      "       9793 |   0.290777  |    0.083766     |   1\n",
      "       9794 |   0.057262  |    0.007990     |   2\n",
      "       9795 |   0.274776  |    0.149404     |   1\n",
      "       9796 |   0.026687  |    0.003862     |   2\n",
      "       9797 |   0.052667  |    0.011113     |   2\n",
      "       9798 |   0.196936  |    0.040060     |   0\n",
      "       9799 |   0.242638  |    0.028703     |   0\n",
      "       9800 |   0.233642  |    0.028113     |   0\n",
      "       9801 |   0.040237  |    0.022068     |   2\n",
      "       9802 |   0.000074  |    0.043028     |   2\n",
      "       9803 |   0.173885  |    0.083439     |   1\n",
      "       9804 |   0.164167  |    0.084950     |   1\n",
      "       9805 |   0.215774  |    0.040667     |   0\n",
      "       9806 |   0.000075  |    0.026700     |   2\n",
      "       9807 |   0.000075  |    0.016893     |   2\n",
      "       9808 |   0.202968  |    0.049281     |   0\n",
      "       9809 |   0.254060  |    0.097082     |   1\n",
      "       9810 |   0.203591  |    0.018458     |   0\n",
      "       9811 |   0.226250  |    0.081651     |   1\n",
      "       9812 |   0.186217  |    0.011081     |   0\n",
      "       9813 |   0.159005  |    0.008433     |   0\n",
      "       9814 |   0.266104  |    0.039167     |   0\n",
      "       9815 |   0.249082  |    0.015456     |   0\n",
      "       9816 |   0.000076  |    0.048103     |   2\n",
      "       9817 |   0.191096  |    0.010164     |   0\n",
      "       9818 |   0.000075  |    0.047278     |   2\n",
      "       9819 |   0.000074  |    0.010055     |   2\n",
      "       9820 |   0.065544  |    0.029706     |   2\n",
      "       9821 |   0.235936  |    0.137948     |   1\n",
      "       9822 |   0.062484  |    0.002891     |   2\n",
      "       9823 |   0.188993  |    0.006866     |   0\n",
      "       9824 |   0.248711  |    0.042957     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 9826: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       9825 |   0.219523  |    0.015582     |   0\n",
      "       9826 |   0.069666  |    0.053587     |   2\n",
      "       9827 |   0.205968  |    0.086647     |   1\n",
      "       9828 |   0.051697  |    0.024262     |   2\n",
      "       9829 |   0.248458  |    0.152012     |   1\n",
      "       9830 |   0.233732  |    0.003726     |   0\n",
      "       9831 |   0.222806  |    0.021450     |   0\n",
      "       9832 |   0.220320  |    0.148938     |   1\n",
      "       9833 |   0.050463  |    0.002908     |   2\n",
      "       9834 |   0.213323  |    0.009773     |   0\n",
      "       9835 |   0.197434  |    0.048645     |   0\n",
      "       9836 |   0.275388  |    0.094336     |   1\n",
      "       9837 |   0.285124  |    0.192011     |   1\n",
      "       9838 |   0.066619  |    0.018913     |   2\n",
      "       9839 |   0.034227  |    0.033820     |   2\n",
      "       9840 |   0.052460  |    0.044909     |   2\n",
      "       9841 |   0.251465  |    0.193018     |   1\n",
      "       9842 |   0.230097  |    0.143013     |   1\n",
      "       9843 |   0.289440  |    0.076502     |   0\n",
      "       9844 |   0.231963  |    0.142701     |   1\n",
      "       9845 |   0.061614  |    0.040485     |   2\n",
      "       9846 |   0.208988  |    0.071991     |   0\n",
      "       9847 |   0.234197  |    0.039026     |   0\n",
      "       9848 |   0.233334  |    0.244438     |   1\n",
      "       9849 |   0.225885  |    0.137317     |   1\n",
      "       9850 |   0.215570  |    0.087466     |   1\n",
      "       9851 |   0.252484  |    0.008034     |   0\n",
      "       9852 |   0.073513  |    0.046027     |   2\n",
      "       9853 |   0.245939  |    0.134124     |   1\n",
      "       9854 |   0.219674  |    0.043876     |   1\n",
      "       9855 |   0.295318  |    0.144034     |   1\n",
      "       9856 |   0.165338  |    0.154699     |   1\n",
      "       9857 |   0.060556  |    0.009504     |   2\n",
      "       9858 |   0.220065  |    0.132173     |   1\n",
      "       9859 |   0.236283  |    0.050756     |   1\n",
      "       9860 |   0.196665  |    0.026381     |   0\n",
      "       9861 |   0.142933  |    0.034823     |   0\n",
      "       9862 |   0.032020  |    0.007648     |   2\n",
      "       9863 |   0.200991  |    0.043793     |   0\n",
      "       9864 |   0.237017  |    0.010349     |   0\n",
      "       9865 |   0.236995  |    0.045614     |   0\n",
      "       9866 |   0.258953  |    0.158578     |   1\n",
      "       9867 |   0.128890  |    0.006677     |   0\n",
      "       9868 |   0.229962  |    0.093091     |   1\n",
      "       9869 |   0.000074  |    0.003184     |   2\n",
      "       9870 |   0.006952  |    0.008537     |   2\n",
      "       9871 |   0.199812  |    0.087226     |   0\n",
      "       9872 |   0.158048  |    0.093739     |   1\n",
      "       9873 |   0.224918  |    0.084293     |   1\n",
      "       9874 |   0.094364  |    0.032554     |   2\n",
      "       9875 |   0.197846  |    0.135086     |   1\n",
      "       9876 |   0.278388  |    0.085132     |   1\n",
      "       9877 |   0.231195  |    0.020377     |   0\n",
      "       9878 |   0.271186  |    0.136072     |   1\n",
      "       9879 |   0.045791  |    0.004617     |   2\n",
      "       9880 |   0.244512  |    0.030544     |   0\n",
      "       9881 |   0.206196  |    0.040617     |   0\n",
      "       9882 |   0.220079  |    0.140655     |   1\n",
      "       9883 |   0.066504  |    0.002935     |   2\n",
      "       9884 |   0.056623  |    0.021037     |   2\n",
      "       9885 |   0.024848  |    0.020427     |   2\n",
      "       9886 |   0.053130  |    0.033767     |   2\n",
      "       9887 |   0.041151  |    0.025644     |   2\n",
      "       9888 |   0.228656  |    0.017016     |   0\n",
      "       9889 |   0.225248  |    0.135506     |   1\n",
      "       9890 |   0.000074  |    0.003739     |   2\n",
      "       9891 |   0.198248  |    0.082696     |   1\n",
      "       9892 |   0.000074  |    0.008271     |   2\n",
      "       9893 |   0.238125  |    0.055195     |   0\n",
      "       9894 |   0.226641  |    0.087194     |   1\n",
      "       9895 |   0.227886  |    0.029402     |   0\n",
      "       9896 |   0.283775  |    0.153312     |   1\n",
      "       9897 |   0.000074  |    0.010359     |   2\n",
      "       9898 |   0.226390  |    0.089458     |   1\n",
      "       9899 |   0.000075  |    0.012891     |   2\n",
      "       9900 |   0.243507  |    0.128524     |   1\n",
      "       9901 |   0.000074  |    0.009897     |   2\n",
      "       9902 |   0.000074  |    0.006776     |   2\n",
      "       9903 |   0.166129  |    0.046929     |   0\n",
      "       9904 |   0.068063  |    0.012604     |   2\n",
      "       9905 |   0.165804  |    0.134392     |   1\n",
      "       9906 |   0.229136  |    0.013788     |   0\n",
      "       9907 |   0.227845  |    0.150682     |   1\n",
      "       9908 |   0.225744  |    0.004214     |   0\n",
      "       9909 |   0.163612  |    0.093578     |   1\n",
      "       9910 |   0.235424  |    0.018390     |   0\n",
      "       9911 |   0.060090  |    0.044448     |   2\n",
      "       9912 |   0.190679  |    0.008548     |   0\n",
      "       9913 |   0.214724  |    0.023434     |   0\n",
      "       9914 |   0.273677  |    0.061194     |   0\n",
      "       9915 |   0.202917  |    0.133056     |   1\n",
      "       9916 |   0.142837  |    0.086708     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 9918: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       9917 |   0.209177  |    0.020228     |   0\n",
      "       9918 |   0.069293  |    0.019565     |   2\n",
      "       9919 |   0.052525  |    0.011552     |   2\n",
      "       9920 |   0.051497  |    0.036473     |   2\n",
      "       9921 |   0.216501  |    0.100673     |   1\n",
      "       9922 |   0.233413  |    0.017360     |   0\n",
      "       9923 |   0.184230  |    0.039669     |   0\n",
      "       9924 |   0.222603  |    0.020532     |   0\n",
      "       9925 |   0.066314  |    0.033799     |   2\n",
      "       9926 |   0.036208  |    0.025814     |   2\n",
      "       9927 |   0.197619  |    0.028001     |   0\n",
      "       9928 |   0.052340  |    0.015874     |   2\n",
      "       9929 |   0.302945  |    0.149553     |   1\n",
      "       9930 |   0.297211  |    0.049901     |   1\n",
      "       9931 |   0.211404  |    0.093608     |   1\n",
      "       9932 |   0.250283  |    0.099418     |   1\n",
      "       9933 |   0.063008  |    0.008616     |   2\n",
      "       9934 |   0.195851  |    0.083911     |   1\n",
      "       9935 |   0.074636  |    0.008793     |   2\n",
      "       9936 |   0.165276  |    0.042767     |   0\n",
      "       9937 |   0.221069  |    0.137161     |   1\n",
      "       9938 |   0.059419  |    0.003208     |   2\n",
      "       9939 |   0.031187  |    0.018843     |   2\n",
      "       9940 |   0.249702  |    0.142152     |   1\n",
      "       9941 |   0.195629  |    0.088486     |   1\n",
      "       9942 |   0.000073  |    0.008315     |   2\n",
      "       9943 |   0.263036  |    0.134424     |   1\n",
      "       9944 |   0.258349  |    0.007845     |   0\n",
      "       9945 |   0.007139  |    0.029305     |   2\n",
      "       9946 |   0.286292  |    0.154368     |   1\n",
      "       9947 |   0.234916  |    0.055430     |   1\n",
      "       9948 |   0.212012  |    0.016417     |   0\n",
      "       9949 |   0.196949  |    0.135936     |   1\n",
      "       9950 |   0.091498  |    0.006015     |   2\n",
      "       9951 |   0.274884  |    0.056435     |   0\n",
      "       9952 |   0.216664  |    0.043112     |   0\n",
      "       9953 |   0.218620  |    0.087633     |   1\n",
      "       9954 |   0.224265  |    0.019701     |   0\n",
      "       9955 |   0.263721  |    0.095513     |   1\n",
      "       9956 |   0.044087  |    0.030674     |   2\n",
      "       9957 |   0.244027  |    0.041092     |   0\n",
      "       9958 |   0.065705  |    0.023011     |   2\n",
      "       9959 |   0.195423  |    0.151197     |   1\n",
      "       9960 |   0.219219  |    0.088246     |   1\n",
      "       9961 |   0.163484  |    0.005649     |   0\n",
      "       9962 |   0.218891  |    0.138682     |   1\n",
      "       9963 |   0.252840  |    0.086457     |   1\n",
      "       9964 |   0.189469  |    0.138784     |   1\n",
      "       9965 |   0.207559  |    0.003237     |   0\n",
      "       9966 |   0.199592  |    0.007745     |   0\n",
      "       9967 |   0.279491  |    0.140830     |   1\n",
      "       9968 |   0.234810  |    0.079625     |   1\n",
      "       9969 |   0.232459  |    0.021254     |   0\n",
      "       9970 |   0.058611  |    0.028596     |   2\n",
      "       9971 |   0.210944  |    0.129807     |   1\n",
      "       9972 |   0.196717  |    0.089106     |   1\n",
      "       9973 |   0.296411  |    0.099203     |   1\n",
      "       9974 |   0.132470  |    0.092099     |   1\n",
      "       9975 |   0.262565  |    0.152296     |   1\n",
      "       9976 |   0.193972  |    0.037259     |   1\n",
      "       9977 |   0.151667  |    0.040914     |   0\n",
      "       9978 |   0.279212  |    0.028764     |   0\n",
      "       9979 |   0.237407  |    0.026348     |   0\n",
      "       9980 |   0.024259  |    0.010420     |   2\n",
      "       9981 |   0.244859  |    0.044430     |   0\n",
      "       9982 |   0.222026  |    0.103241     |   1\n",
      "       9983 |   0.052488  |    0.008809     |   2\n",
      "       9984 |   0.041305  |    0.042241     |   2\n",
      "       9985 |   0.173051  |    0.015228     |   0\n",
      "       9986 |   0.217114  |    0.038498     |   0\n",
      "       9987 |   0.219538  |    0.015414     |   0\n",
      "       9988 |   0.254843  |    0.046105     |   0\n",
      "       9989 |   0.000072  |    0.020032     |   2\n",
      "       9990 |   0.182429  |    0.159493     |   1\n",
      "       9991 |   0.195060  |    0.021691     |   1\n",
      "       9992 |   0.000072  |    0.039329     |   2\n",
      "       9993 |   0.000072  |    0.015991     |   2\n",
      "       9994 |   0.234507  |    0.138758     |   1\n",
      "       9995 |   0.000073  |    0.004605     |   2\n",
      "       9996 |   0.220750  |    0.021128     |   0\n",
      "       9997 |   0.000072  |    0.042885     |   2\n",
      "       9998 |   0.158145  |    0.102791     |   1\n",
      "       9999 |   0.247076  |    0.090963     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 10000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 10000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      10000 |   0.000072  |    0.008297     |   2\n",
      "      10001 |   0.068824  |    0.043433     |   2\n",
      "      10002 |   0.219959  |    0.026027     |   0\n",
      "      10003 |   0.248238  |    0.039634     |   0\n",
      "      10004 |   0.171783  |    0.013990     |   0\n",
      "      10005 |   0.191571  |    0.036802     |   0\n",
      "      10006 |   0.273636  |    0.101249     |   1\n",
      "      10007 |   0.216759  |    0.063466     |   1\n",
      "      10008 |   0.181076  |    0.030983     |   0\n",
      "      10009 |   0.212969  |    0.101293     |   1\n",
      "      10010 |   0.219367  |    0.090295     |   1\n",
      "      10011 |   0.271759  |    0.102789     |   1\n",
      "      10012 |   0.224293  |    0.106663     |   1\n",
      "      10013 |   0.205120  |    0.049904     |   1\n",
      "      10014 |   0.052055  |    0.025292     |   2\n",
      "      10015 |   0.129104  |    0.128620     |   1\n",
      "      10016 |   0.050205  |    0.012421     |   2\n",
      "      10017 |   0.205036  |    0.044163     |   0\n",
      "      10018 |   0.247276  |    0.010449     |   0\n",
      "      10019 |   0.223583  |    0.050142     |   0\n",
      "      10020 |   0.290383  |    0.136276     |   1\n",
      "      10021 |   0.206856  |    0.082217     |   1\n",
      "      10022 |   0.065426  |    0.014022     |   2\n",
      "      10023 |   0.247021  |    0.149986     |   1\n",
      "      10024 |   0.212798  |    0.040527     |   1\n",
      "      10025 |   0.034435  |    0.021923     |   2\n",
      "      10026 |   0.051144  |    0.036010     |   2\n",
      "      10027 |   0.062998  |    0.022849     |   2\n",
      "      10028 |   0.193669  |    0.151125     |   1\n",
      "      10029 |   0.210215  |    0.007047     |   0\n",
      "      10030 |   0.239756  |    0.010158     |   0\n",
      "      10031 |   0.216485  |    0.051159     |   0\n",
      "      10032 |   0.270967  |    0.079194     |   1\n",
      "      10033 |   0.199535  |    0.043238     |   0\n",
      "      10034 |   0.071651  |    0.010353     |   2\n",
      "      10035 |   0.230790  |    0.142160     |   1\n",
      "      10036 |   0.060121  |    0.003684     |   2\n",
      "      10037 |   0.225112  |    0.023442     |   0\n",
      "      10038 |   0.032079  |    0.052939     |   2\n",
      "      10039 |   0.200903  |    0.103542     |   1\n",
      "      10040 |   0.185956  |    0.096544     |   1\n",
      "      10041 |   0.000072  |    0.005778     |   2\n",
      "      10042 |   0.006620  |    0.032494     |   2\n",
      "      10043 |   0.093771  |    0.030364     |   2\n",
      "      10044 |   0.242228  |    0.095867     |   1\n",
      "      10045 |   0.293564  |    0.012300     |   0\n",
      "      10046 |   0.043949  |    0.043979     |   2\n",
      "      10047 |   0.230331  |    0.019268     |   0\n",
      "      10048 |   0.297454  |    0.134503     |   1\n",
      "      10049 |   0.183222  |    0.007806     |   0\n",
      "      10050 |   0.219203  |    0.077541     |   1\n",
      "      10051 |   0.212670  |    0.038558     |   0\n",
      "      10052 |   0.227852  |    0.087534     |   1\n",
      "      10053 |   0.248145  |    0.088560     |   1\n",
      "      10054 |   0.069927  |    0.020435     |   2\n",
      "      10055 |   0.058871  |    0.039514     |   2\n",
      "      10056 |   0.192364  |    0.082621     |   1\n",
      "      10057 |   0.208566  |    0.045484     |   0\n",
      "      10058 |   0.224513  |    0.017706     |   0\n",
      "      10059 |   0.176783  |    0.028272     |   0\n",
      "      10060 |   0.022725  |    0.021442     |   2\n",
      "      10061 |   0.260946  |    0.046111     |   0\n",
      "      10062 |   0.229942  |    0.180332     |   1\n",
      "      10063 |   0.239371  |    0.045155     |   0\n",
      "      10064 |   0.052953  |    0.005380     |   2\n",
      "      10065 |   0.041091  |    0.047438     |   2\n",
      "      10066 |   0.252927  |    0.028718     |   0\n",
      "      10067 |   0.256821  |    0.137090     |   1\n",
      "      10068 |   0.279071  |    0.049477     |   1\n",
      "      10069 |   0.000071  |    0.019185     |   2\n",
      "      10070 |   0.000071  |    0.055482     |   2\n",
      "      10071 |   0.197410  |    0.109909     |   1\n",
      "      10072 |   0.284301  |    0.145079     |   1\n",
      "      10073 |   0.226297  |    0.096841     |   1\n",
      "      10074 |   0.251016  |    0.083744     |   1\n",
      "      10075 |   0.211561  |    0.006682     |   0\n",
      "      10076 |   0.167506  |    0.045700     |   0\n",
      "      10077 |   0.000071  |    0.007491     |   2\n",
      "      10078 |   0.214795  |    0.041695     |   0\n",
      "      10079 |   0.278515  |    0.028768     |   0\n",
      "      10080 |   0.197900  |    0.150831     |   1\n",
      "      10081 |   0.248392  |    0.061043     |   1\n",
      "      10082 |   0.212841  |    0.013876     |   0\n",
      "      10083 |   0.166983  |    0.155414     |   1\n",
      "      10084 |   0.000072  |    0.003868     |   2\n",
      "      10085 |   0.000071  |    0.019154     |   2\n",
      "      10086 |   0.000071  |    0.032183     |   2\n",
      "      10087 |   0.067912  |    0.019322     |   2\n",
      "      10088 |   0.208023  |    0.049237     |   0\n",
      "      10089 |   0.204144  |    0.007225     |   0\n",
      "      10090 |   0.061025  |    0.034616     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 10092: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      10091 |   0.183480  |    0.030033     |   0\n",
      "      10092 |   0.311815  |    0.084744     |   1\n",
      "      10093 |   0.066145  |    0.008434     |   2\n",
      "      10094 |   0.321216  |    0.150506     |   1\n",
      "      10095 |   0.230447  |    0.054648     |   1\n",
      "      10096 |   0.128396  |    0.022383     |   0\n",
      "      10097 |   0.052442  |    0.026080     |   2\n",
      "      10098 |   0.048975  |    0.023445     |   2\n",
      "      10099 |   0.065782  |    0.029239     |   2\n",
      "      10100 |   0.034159  |    0.010538     |   2\n",
      "      10101 |   0.051533  |    0.039448     |   2\n",
      "      10102 |   0.187902  |    0.016456     |   0\n",
      "      10103 |   0.066003  |    0.023844     |   2\n",
      "      10104 |   0.237413  |    0.030950     |   0\n",
      "      10105 |   0.071357  |    0.045752     |   2\n",
      "      10106 |   0.061047  |    0.027443     |   2\n",
      "      10107 |   0.030752  |    0.025762     |   2\n",
      "      10108 |   0.220274  |    0.034853     |   0\n",
      "      10109 |   0.183850  |    0.068043     |   0\n",
      "      10110 |   0.192891  |    0.099588     |   1\n",
      "      10111 |   0.252083  |    0.096975     |   1\n",
      "      10112 |   0.215784  |    0.102491     |   1\n",
      "      10113 |   0.252680  |    0.095982     |   1\n",
      "      10114 |   0.209605  |    0.114594     |   1\n",
      "      10115 |   0.293528  |    0.033352     |   1\n",
      "      10116 |   0.223298  |    0.036976     |   0\n",
      "      10117 |   0.000070  |    0.010578     |   2\n",
      "      10118 |   0.189260  |    0.050164     |   0\n",
      "      10119 |   0.007716  |    0.013084     |   2\n",
      "      10120 |   0.093213  |    0.056616     |   2\n",
      "      10121 |   0.043884  |    0.006827     |   2\n",
      "      10122 |   0.186091  |    0.034543     |   0\n",
      "      10123 |   0.066472  |    0.010150     |   2\n",
      "      10124 |   0.220156  |    0.044565     |   0\n",
      "      10125 |   0.058223  |    0.010820     |   2\n",
      "      10126 |   0.184760  |    0.129155     |   1\n",
      "      10127 |   0.024141  |    0.020302     |   2\n",
      "      10128 |   0.253399  |    0.101058     |   1\n",
      "      10129 |   0.227987  |    0.092315     |   1\n",
      "      10130 |   0.149232  |    0.047546     |   0\n",
      "      10131 |   0.263688  |    0.077372     |   1\n",
      "      10132 |   0.239390  |    0.066456     |   1\n",
      "      10133 |   0.214477  |    0.023025     |   0\n",
      "      10134 |   0.182009  |    0.115796     |   1\n",
      "      10135 |   0.209675  |    0.121619     |   1\n",
      "      10136 |   0.233427  |    0.063139     |   1\n",
      "      10137 |   0.053157  |    0.014904     |   2\n",
      "      10138 |   0.040254  |    0.042359     |   2\n",
      "      10139 |   0.214806  |    0.020534     |   0\n",
      "      10140 |   0.264844  |    0.029916     |   0\n",
      "      10141 |   0.220397  |    0.102868     |   1\n",
      "      10142 |   0.210217  |    0.063394     |   0\n",
      "      10143 |   0.164044  |    0.102237     |   1\n",
      "      10144 |   0.196929  |    0.005997     |   0\n",
      "      10145 |   0.000070  |    0.021584     |   2\n",
      "      10146 |   0.000070  |    0.028983     |   2\n",
      "      10147 |   0.000070  |    0.021046     |   2\n",
      "      10148 |   0.000071  |    0.047397     |   2\n",
      "      10149 |   0.234944  |    0.092621     |   1\n",
      "      10150 |   0.000070  |    0.018217     |   2\n",
      "      10151 |   0.000070  |    0.042591     |   2\n",
      "      10152 |   0.066632  |    0.027584     |   2\n",
      "      10153 |   0.060226  |    0.020411     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 10154: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      10154 |   0.067127  |    0.017313     |   2\n",
      "      10155 |   0.216067  |    0.094217     |   1\n",
      "      10156 |   0.050784  |    0.010238     |   2\n",
      "      10157 |   0.051432  |    0.044472     |   2\n",
      "      10158 |   0.268956  |    0.092199     |   1\n",
      "      10159 |   0.065693  |    0.021396     |   2\n",
      "      10160 |   0.253662  |    0.157851     |   1\n",
      "      10161 |   0.219565  |    0.073183     |   1\n",
      "      10162 |   0.236690  |    0.078327     |   1\n",
      "      10163 |   0.290777  |    0.081187     |   1\n",
      "      10164 |   0.271820  |    0.032167     |   0\n",
      "      10165 |   0.034467  |    0.035191     |   2\n",
      "      10166 |   0.049781  |    0.025584     |   2\n",
      "      10167 |   0.245873  |    0.053243     |   0\n",
      "      10168 |   0.056977  |    0.015167     |   2\n",
      "      10169 |   0.073500  |    0.029552     |   2\n",
      "      10170 |   0.164177  |    0.034670     |   0\n",
      "      10171 |   0.060348  |    0.049259     |   2\n",
      "      10172 |   0.213265  |    0.061935     |   1\n",
      "      10173 |   0.030669  |    0.016917     |   2\n",
      "      10174 |   0.000069  |    0.033919     |   2\n",
      "      10175 |   0.264981  |    0.118955     |   1\n",
      "      10176 |   0.186672  |    0.066184     |   1\n",
      "      10177 |   0.007178  |    0.035389     |   2\n",
      "      10178 |   0.089918  |    0.030374     |   2\n",
      "      10179 |   0.042563  |    0.049705     |   2\n",
      "      10180 |   0.272741  |    0.089751     |   1\n",
      "      10181 |   0.219891  |    0.064526     |   1\n",
      "      10182 |   0.062181  |    0.010604     |   2\n",
      "      10183 |   0.283120  |    0.043724     |   0\n",
      "      10184 |   0.187908  |    0.009892     |   0\n",
      "      10185 |   0.261113  |    0.047762     |   0\n",
      "      10186 |   0.054407  |    0.014038     |   2\n",
      "      10187 |   0.022540  |    0.027334     |   2\n",
      "      10188 |   0.213981  |    0.022231     |   0\n",
      "      10189 |   0.162010  |    0.030529     |   0\n",
      "      10190 |   0.052618  |    0.034760     |   2\n",
      "      10191 |   0.040298  |    0.030825     |   2\n",
      "      10192 |   0.238708  |    0.103433     |   1\n",
      "      10193 |   0.205886  |    0.091092     |   1\n",
      "      10194 |   0.304702  |    0.101046     |   1\n",
      "      10195 |   0.265894  |    0.057014     |   1\n",
      "      10196 |   0.204413  |    0.024080     |   0\n",
      "      10197 |   0.000069  |    0.025531     |   2\n",
      "      10198 |   0.273954  |    0.041665     |   0\n",
      "      10199 |   0.201997  |    0.027970     |   0\n",
      "      10200 |   0.235801  |    0.012475     |   0\n",
      "      10201 |   0.239180  |    0.045971     |   0\n",
      "      10202 |   0.000068  |    0.008998     |   2\n",
      "      10203 |   0.000069  |    0.036869     |   2\n",
      "      10204 |   0.235599  |    0.051661     |   0\n",
      "      10205 |   0.000070  |    0.018862     |   2\n",
      "      10206 |   0.146360  |    0.151558     |   1\n",
      "      10207 |   0.291300  |    0.008166     |   0\n",
      "      10208 |   0.248313  |    0.021869     |   0\n",
      "      10209 |   0.228048  |    0.146239     |   1\n",
      "      10210 |   0.236558  |    0.005604     |   0\n",
      "      10211 |   0.234297  |    0.077677     |   1\n",
      "      10212 |   0.000068  |    0.013850     |   2\n",
      "      10213 |   0.239787  |    0.142265     |   1\n",
      "      10214 |   0.000068  |    0.004362     |   2\n",
      "      10215 |   0.066448  |    0.008058     |   2\n",
      "      10216 |   0.233272  |    0.052254     |   0\n",
      "      10217 |   0.061177  |    0.011551     |   2\n",
      "      10218 |   0.235710  |    0.037253     |   0\n",
      "      10219 |   0.195985  |    0.147183     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 10220: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      10220 |   0.162609  |    0.038281     |   0\n",
      "      10221 |   0.226962  |    0.008189     |   0\n",
      "      10222 |   0.226958  |    0.028515     |   1\n",
      "      10223 |   0.069498  |    0.040214     |   2\n",
      "      10224 |   0.256450  |    0.136172     |   1\n",
      "      10225 |   0.207696  |    0.049529     |   1\n",
      "      10226 |   0.053244  |    0.005835     |   2\n",
      "      10227 |   0.049224  |    0.034095     |   2\n",
      "      10228 |   0.064336  |    0.038733     |   2\n",
      "      10229 |   0.233742  |    0.023510     |   0\n",
      "      10230 |   0.035228  |    0.040712     |   2\n",
      "      10231 |   0.226652  |    0.065444     |   0\n",
      "      10232 |   0.252444  |    0.065187     |   1\n",
      "      10233 |   0.204811  |    0.098752     |   1\n",
      "      10234 |   0.205037  |    0.136856     |   1\n",
      "      10235 |   0.260681  |    0.004088     |   0\n",
      "      10236 |   0.231799  |    0.015593     |   0\n",
      "      10237 |   0.052062  |    0.033770     |   2\n",
      "      10238 |   0.060801  |    0.024680     |   2\n",
      "      10239 |   0.184691  |    0.027550     |   0\n",
      "      10240 |   0.073245  |    0.032341     |   2\n",
      "      10241 |   0.205673  |    0.030056     |   0\n",
      "      10242 |   0.060303  |    0.025480     |   2\n",
      "      10243 |   0.205884  |    0.118408     |   1\n",
      "      10244 |   0.179483  |    0.091241     |   1\n",
      "      10245 |   0.210506  |    0.087591     |   1\n",
      "      10246 |   0.233177  |    0.007767     |   0\n",
      "      10247 |   0.175045  |    0.057279     |   0\n",
      "      10248 |   0.271146  |    0.077183     |   1\n",
      "      10249 |   0.217848  |    0.082004     |   1\n",
      "      10250 |   0.257206  |    0.028691     |   0\n",
      "      10251 |   0.203207  |    0.137534     |   1\n",
      "      10252 |   0.198082  |    0.003232     |   0\n",
      "      10253 |   0.028483  |    0.007284     |   2\n",
      "      10254 |   0.000068  |    0.049534     |   2\n",
      "      10255 |   0.006702  |    0.018436     |   2\n",
      "      10256 |   0.089309  |    0.026826     |   2\n",
      "      10257 |   0.182666  |    0.030443     |   0\n",
      "      10258 |   0.204443  |    0.154552     |   1\n",
      "      10259 |   0.044942  |    0.007004     |   2\n",
      "      10260 |   0.199827  |    0.089164     |   1\n",
      "      10261 |   0.221112  |    0.034491     |   0\n",
      "      10262 |   0.249512  |    0.152922     |   1\n",
      "      10263 |   0.226320  |    0.058293     |   1\n",
      "      10264 |   0.182996  |    0.010940     |   0\n",
      "      10265 |   0.066833  |    0.049720     |   2\n",
      "      10266 |   0.055343  |    0.005074     |   2\n",
      "      10267 |   0.235757  |    0.046767     |   0\n",
      "      10268 |   0.207019  |    0.137809     |   1\n",
      "      10269 |   0.191379  |    0.047619     |   1\n",
      "      10270 |   0.242595  |    0.025518     |   0\n",
      "      10271 |   0.026233  |    0.041644     |   2\n",
      "      10272 |   0.232521  |    0.026459     |   0\n",
      "      10273 |   0.229979  |    0.039737     |   0\n",
      "      10274 |   0.162103  |    0.023243     |   0\n",
      "      10275 |   0.172176  |    0.155289     |   1\n",
      "      10276 |   0.237365  |    0.054554     |   1\n",
      "      10277 |   0.055369  |    0.023977     |   2\n",
      "      10278 |   0.038159  |    0.041343     |   2\n",
      "      10279 |   0.213732  |    0.024887     |   0\n",
      "      10280 |   0.197373  |    0.043416     |   0\n",
      "      10281 |   0.242145  |    0.030747     |   0\n",
      "      10282 |   0.294047  |    0.132621     |   1\n",
      "      10283 |   0.000068  |    0.006830     |   2\n",
      "      10284 |   0.000068  |    0.042007     |   2\n",
      "      10285 |   0.187491  |    0.011549     |   0\n",
      "      10286 |   0.000068  |    0.045771     |   2\n",
      "      10287 |   0.222448  |    0.135861     |   1\n",
      "      10288 |   0.289557  |    0.086298     |   1\n",
      "      10289 |   0.252596  |    0.098088     |   1\n",
      "      10290 |   0.000070  |    0.016390     |   2\n",
      "      10291 |   0.194856  |    0.105735     |   1\n",
      "      10292 |   0.000069  |    0.026587     |   2\n",
      "      10293 |   0.000068  |    0.033752     |   2\n",
      "      10294 |   0.390804  |    0.104758     |   1\n",
      "      10295 |   0.213266  |    0.077314     |   1\n",
      "      10296 |   0.059859  |    0.012244     |   2\n",
      "      10297 |   0.059341  |    0.056944     |   2\n",
      "      10298 |   0.221886  |    0.081810     |   1\n",
      "      10299 |   0.168755  |    0.009503     |   0\n",
      "      10300 |   0.210967  |    0.052483     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 10301: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      10301 |   0.257858  |    0.063827     |   1\n",
      "      10302 |   0.230099  |    0.040316     |   0\n",
      "      10303 |   0.259481  |    0.056166     |   1\n",
      "      10304 |   0.065037  |    0.026091     |   2\n",
      "      10305 |   0.198916  |    0.030765     |   0\n",
      "      10306 |   0.224799  |    0.032903     |   0\n",
      "      10307 |   0.232798  |    0.142952     |   1\n",
      "      10308 |   0.187235  |    0.005999     |   0\n",
      "      10309 |   0.221876  |    0.010367     |   0\n",
      "      10310 |   0.274727  |    0.152988     |   1\n",
      "      10311 |   0.173366  |    0.073349     |   1\n",
      "      10312 |   0.246822  |    0.112298     |   1\n",
      "      10313 |   0.048033  |    0.006931     |   2\n",
      "      10314 |   0.221272  |    0.098601     |   1\n",
      "      10315 |   0.237977  |    0.056479     |   1\n",
      "      10316 |   0.049341  |    0.010707     |   2\n",
      "      10317 |   0.164322  |    0.058191     |   0\n",
      "      10318 |   0.246468  |    0.068471     |   1\n",
      "      10319 |   0.219962  |    0.106578     |   1\n",
      "      10320 |   0.065053  |    0.013980     |   2\n",
      "      10321 |   0.033633  |    0.042370     |   2\n",
      "      10322 |   0.050163  |    0.016869     |   2\n",
      "      10323 |   0.199217  |    0.130651     |   1\n",
      "      10324 |   0.221327  |    0.010058     |   0\n",
      "      10325 |   0.155805  |    0.131573     |   1\n",
      "      10326 |   0.157891  |    0.008064     |   0\n",
      "      10327 |   0.185496  |    0.043098     |   0\n",
      "      10328 |   0.189377  |    0.009905     |   0\n",
      "      10329 |   0.272671  |    0.049426     |   0\n",
      "      10330 |   0.212940  |    0.019923     |   0\n",
      "      10331 |   0.194130  |    0.153842     |   1\n",
      "      10332 |   0.229758  |    0.078191     |   1\n",
      "      10333 |   0.320562  |    0.008638     |   0\n",
      "      10334 |   0.287476  |    0.143512     |   1\n",
      "      10335 |   0.236622  |    0.032212     |   1\n",
      "      10336 |   0.197901  |    0.038356     |   0\n",
      "      10337 |   0.064020  |    0.019252     |   2\n",
      "      10338 |   0.268616  |    0.050136     |   0\n",
      "      10339 |   0.069823  |    0.012300     |   2\n",
      "      10340 |   0.057200  |    0.035349     |   2\n",
      "      10341 |   0.236853  |    0.147975     |   1\n",
      "      10342 |   0.234708  |    0.061443     |   1\n",
      "      10343 |   0.237088  |    0.045627     |   0\n",
      "      10344 |   0.188779  |    0.107622     |   1\n",
      "      10345 |   0.029394  |    0.025106     |   2\n",
      "      10346 |   0.000067  |    0.033361     |   2\n",
      "      10347 |   0.307480  |    0.128009     |   1\n",
      "      10348 |   0.007205  |    0.006419     |   2\n",
      "      10349 |   0.199660  |    0.029181     |   0\n",
      "      10350 |   0.091700  |    0.032517     |   2\n",
      "      10351 |   0.210583  |    0.024455     |   0\n",
      "      10352 |   0.198528  |    0.152780     |   1\n",
      "      10353 |   0.178131  |    0.080431     |   1\n",
      "      10354 |   0.044662  |    0.006907     |   2\n",
      "      10355 |   0.205614  |    0.101317     |   1\n",
      "      10356 |   0.276713  |    0.080474     |   1\n",
      "      10357 |   0.065036  |    0.036393     |   2\n",
      "      10358 |   0.057262  |    0.024753     |   2\n",
      "      10359 |   0.200068  |    0.025458     |   0\n",
      "      10360 |   0.155135  |    0.044922     |   0\n",
      "      10361 |   0.190581  |    0.088375     |   1\n",
      "      10362 |   0.022850  |    0.022271     |   2\n",
      "      10363 |   0.194341  |    0.141374     |   1\n",
      "      10364 |   0.257640  |    0.097163     |   1\n",
      "      10365 |   0.163278  |    0.083571     |   1\n",
      "      10366 |   0.048571  |    0.019787     |   2\n",
      "      10367 |   0.270401  |    0.135185     |   1\n",
      "      10368 |   0.228657  |    0.003011     |   0\n",
      "      10369 |   0.040959  |    0.010215     |   2\n",
      "      10370 |   0.000067  |    0.038491     |   2\n",
      "      10371 |   0.000067  |    0.021265     |   2\n",
      "      10372 |   0.227607  |    0.047222     |   0\n",
      "      10373 |   0.207970  |    0.097776     |   1\n",
      "      10374 |   0.257235  |    0.138205     |   1\n",
      "      10375 |   0.195712  |    0.072011     |   1\n",
      "      10376 |   0.000067  |    0.017345     |   2\n",
      "      10377 |   0.205823  |    0.108781     |   1\n",
      "      10378 |   0.000068  |    0.018640     |   2\n",
      "      10379 |   0.000067  |    0.047542     |   2\n",
      "      10380 |   0.000067  |    0.016111     |   2\n",
      "      10381 |   0.064074  |    0.046932     |   2\n",
      "      10382 |   0.289454  |    0.009851     |   0\n",
      "      10383 |   0.208362  |    0.042657     |   0\n",
      "      10384 |   0.217026  |    0.020286     |   0\n",
      "      10385 |   0.059270  |    0.052270     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 10386: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      10386 |   0.232829  |    0.080220     |   1\n",
      "      10387 |   0.193752  |    0.016406     |   0\n",
      "      10388 |   0.290908  |    0.132018     |   1\n",
      "      10389 |   0.238672  |    0.006011     |   0\n",
      "      10390 |   0.065074  |    0.043304     |   2\n",
      "      10391 |   0.049948  |    0.023612     |   2\n",
      "      10392 |   0.050027  |    0.046416     |   2\n",
      "      10393 |   0.063910  |    0.028105     |   2\n",
      "      10394 |   0.231446  |    0.149548     |   1\n",
      "      10395 |   0.034399  |    0.003532     |   2\n",
      "      10396 |   0.052143  |    0.016821     |   2\n",
      "      10397 |   0.059456  |    0.021861     |   2\n",
      "      10398 |   0.074099  |    0.036406     |   2\n",
      "      10399 |   0.223901  |    0.147877     |   1\n",
      "      10400 |   0.209119  |    0.004211     |   0\n",
      "      10401 |   0.059853  |    0.019386     |   2\n",
      "      10402 |   0.234283  |    0.145048     |   1\n",
      "      10403 |   0.206373  |    0.020973     |   0\n",
      "      10404 |   0.241989  |    0.089554     |   1\n",
      "      10405 |   0.199864  |    0.097987     |   1\n",
      "      10406 |   0.204790  |    0.084967     |   1\n",
      "      10407 |   0.028144  |    0.013575     |   2\n",
      "      10408 |   0.000066  |    0.035314     |   2\n",
      "      10409 |   0.006543  |    0.031161     |   2\n",
      "      10410 |   0.088867  |    0.025164     |   2\n",
      "      10411 |   0.232255  |    0.140845     |   1\n",
      "      10412 |   0.043384  |    0.003067     |   2\n",
      "      10413 |   0.063995  |    0.016422     |   2\n",
      "      10414 |   0.167039  |    0.030695     |   0\n",
      "      10415 |   0.054469  |    0.020338     |   2\n",
      "      10416 |   0.023613  |    0.045354     |   2\n",
      "      10417 |   0.246803  |    0.020743     |   0\n",
      "      10418 |   0.220497  |    0.027301     |   0\n",
      "      10419 |   0.048646  |    0.020900     |   2\n",
      "      10420 |   0.040087  |    0.030024     |   2\n",
      "      10421 |   0.000066  |    0.030733     |   2\n",
      "      10422 |   0.000066  |    0.036426     |   2\n",
      "      10423 |   0.195366  |    0.027674     |   0\n",
      "      10424 |   0.149018  |    0.141271     |   1\n",
      "      10425 |   0.224055  |    0.013556     |   0\n",
      "      10426 |   0.000066  |    0.035679     |   2\n",
      "      10427 |   0.000067  |    0.018413     |   2\n",
      "      10428 |   0.211991  |    0.045026     |   0\n",
      "      10429 |   0.000066  |    0.028761     |   2\n",
      "      10430 |   0.226219  |    0.146852     |   1\n",
      "      10431 |   0.188774  |    0.014326     |   0\n",
      "      10432 |   0.279713  |    0.048790     |   1\n",
      "      10433 |   0.248872  |    0.022266     |   0\n",
      "      10434 |   0.217192  |    0.035986     |   0\n",
      "      10435 |   0.000066  |    0.009098     |   2\n",
      "      10436 |   0.207529  |    0.035598     |   0\n",
      "      10437 |   0.261148  |    0.087743     |   1\n",
      "      10438 |   0.198982  |    0.023388     |   0\n",
      "      10439 |   0.270917  |    0.144023     |   1\n",
      "      10440 |   0.061699  |    0.011967     |   2\n",
      "      10441 |   0.199579  |    0.077602     |   1\n",
      "      10442 |   0.169942  |    0.021641     |   0\n",
      "      10443 |   0.191452  |    0.036287     |   0\n",
      "      10444 |   0.059938  |    0.013385     |   2\n",
      "      10445 |   0.186771  |    0.044661     |   0\n",
      "      10446 |   0.242730  |    0.032371     |   0\n",
      "      10447 |   0.271138  |    0.138764     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 10449: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      10448 |   0.198982  |    0.020010     |   0\n",
      "      10449 |   0.276101  |    0.054925     |   1\n",
      "      10450 |   0.229240  |    0.027352     |   0\n",
      "      10451 |   0.066034  |    0.034266     |   2\n",
      "      10452 |   0.180218  |    0.144833     |   1\n",
      "      10453 |   0.271233  |    0.062080     |   1\n",
      "      10454 |   0.047946  |    0.017345     |   2\n",
      "      10455 |   0.048423  |    0.050025     |   2\n",
      "      10456 |   0.064006  |    0.015035     |   2\n",
      "      10457 |   0.034644  |    0.039085     |   2\n",
      "      10458 |   0.204647  |    0.021989     |   0\n",
      "      10459 |   0.211592  |    0.045338     |   0\n",
      "      10460 |   0.243642  |    0.146300     |   1\n",
      "      10461 |   0.050208  |    0.005210     |   2\n",
      "      10462 |   0.061737  |    0.010751     |   2\n",
      "      10463 |   0.072011  |    0.034425     |   2\n",
      "      10464 |   0.057365  |    0.030046     |   2\n",
      "      10465 |   0.229346  |    0.140025     |   1\n",
      "      10466 |   0.258588  |    0.080429     |   1\n",
      "      10467 |   0.250386  |    0.084707     |   1\n",
      "      10468 |   0.026838  |    0.006000     |   2\n",
      "      10469 |   0.170687  |    0.048023     |   0\n",
      "      10470 |   0.233175  |    0.089142     |   1\n",
      "      10471 |   0.211387  |    0.034465     |   0\n",
      "      10472 |   0.000066  |    0.014694     |   2\n",
      "      10473 |   0.189569  |    0.144515     |   1\n",
      "      10474 |   0.006925  |    0.008546     |   2\n",
      "      10475 |   0.264202  |    0.020625     |   0\n",
      "      10476 |   0.268803  |    0.125482     |   1\n",
      "      10477 |   0.168688  |    0.013862     |   0\n",
      "      10478 |   0.222564  |    0.133209     |   1\n",
      "      10479 |   0.181973  |    0.004504     |   0\n",
      "      10480 |   0.146566  |    0.031366     |   0\n",
      "      10481 |   0.276719  |    0.014927     |   0\n",
      "      10482 |   0.275941  |    0.031556     |   0\n",
      "      10483 |   0.213582  |    0.024664     |   0\n",
      "      10484 |   0.209844  |    0.013862     |   0\n",
      "      10485 |   0.248264  |    0.042065     |   0\n",
      "      10486 |   0.205261  |    0.019444     |   0\n",
      "      10487 |   0.283017  |    0.156001     |   1\n",
      "      10488 |   0.174570  |    0.021047     |   1\n",
      "      10489 |   0.232339  |    0.060067     |   0\n",
      "      10490 |   0.255143  |    0.088337     |   1\n",
      "      10491 |   0.223891  |    0.005954     |   0\n",
      "      10492 |   0.180456  |    0.044912     |   0\n",
      "      10493 |   0.221714  |    0.089030     |   1\n",
      "      10494 |   0.177832  |    0.010795     |   0\n",
      "      10495 |   0.179167  |    0.042066     |   0\n",
      "      10496 |   0.090226  |    0.015053     |   2\n",
      "      10497 |   0.257550  |    0.142269     |   1\n",
      "      10498 |   0.180127  |    0.004447     |   0\n",
      "      10499 |   0.218747  |    0.022525     |   0\n",
      "      10500 |   0.044854  |    0.025931     |   2\n",
      "      10501 |   0.068195  |    0.044331     |   2\n",
      "      10502 |   0.051028  |    0.020436     |   2\n",
      "      10503 |   0.211612  |    0.109365     |   1\n",
      "      10504 |   0.231435  |    0.029990     |   0\n",
      "      10505 |   0.049667  |    0.042889     |   2\n",
      "      10506 |   0.137447  |    0.134093     |   1\n",
      "      10507 |   0.063703  |    0.002859     |   2\n",
      "      10508 |   0.183242  |    0.012063     |   0\n",
      "      10509 |   0.216888  |    0.126018     |   1\n",
      "      10510 |   0.248699  |    0.006897     |   0\n",
      "      10511 |   0.034878  |    0.028243     |   2\n",
      "      10512 |   0.250680  |    0.030911     |   0\n",
      "      10513 |   0.168666  |    0.031674     |   0\n",
      "      10514 |   0.052205  |    0.014197     |   2\n",
      "      10515 |   0.060162  |    0.029170     |   2\n",
      "      10516 |   0.069899  |    0.048969     |   2\n",
      "      10517 |   0.220179  |    0.008834     |   0\n",
      "      10518 |   0.226981  |    0.144706     |   1\n",
      "      10519 |   0.225025  |    0.108924     |   1\n",
      "      10520 |   0.268984  |    0.057899     |   1\n",
      "      10521 |   0.058342  |    0.007152     |   2\n",
      "      10522 |   0.028871  |    0.065220     |   2\n",
      "      10523 |   0.324706  |    0.080732     |   1\n",
      "      10524 |   0.000066  |    0.007271     |   2\n",
      "      10525 |   0.200082  |    0.049100     |   0\n",
      "      10526 |   0.221105  |    0.016060     |   0\n",
      "      10527 |   0.167965  |    0.031306     |   0\n",
      "      10528 |   0.231437  |    0.096800     |   1\n",
      "      10529 |   0.007093  |    0.009960     |   2\n",
      "      10530 |   0.213010  |    0.040462     |   0\n",
      "      10531 |   0.261141  |    0.027985     |   0\n",
      "      10532 |   0.225247  |    0.028866     |   0\n",
      "      10533 |   0.088224  |    0.012025     |   2\n",
      "      10534 |   0.209349  |    0.044930     |   0\n",
      "      10535 |   0.256374  |    0.012432     |   0\n",
      "      10536 |   0.204072  |    0.029764     |   0\n",
      "      10537 |   0.226724  |    0.039199     |   0\n",
      "      10538 |   0.177242  |    0.015243     |   0\n",
      "      10539 |   0.044954  |    0.040850     |   2\n",
      "      10540 |   0.210994  |    0.138319     |   1\n",
      "      10541 |   0.195243  |    0.011203     |   0\n",
      "      10542 |   0.272930  |    0.067936     |   1\n",
      "      10543 |   0.193179  |    0.150847     |   1\n",
      "      10544 |   0.070482  |    0.007762     |   2\n",
      "      10545 |   0.220616  |    0.048018     |   1\n",
      "      10546 |   0.227129  |    0.020824     |   0\n",
      "      10547 |   0.055655  |    0.028988     |   2\n",
      "      10548 |   0.249785  |    0.030347     |   0\n",
      "      10549 |   0.215688  |    0.030887     |   0\n",
      "      10550 |   0.204434  |    0.103265     |   1\n",
      "      10551 |   0.025671  |    0.007624     |   2\n",
      "      10552 |   0.219757  |    0.039399     |   0\n",
      "      10553 |   0.177104  |    0.014174     |   0\n",
      "      10554 |   0.231858  |    0.041660     |   0\n",
      "      10555 |   0.238937  |    0.036178     |   0\n",
      "      10556 |   0.192761  |    0.086283     |   1\n",
      "      10557 |   0.222554  |    0.013540     |   0\n",
      "      10558 |   0.224823  |    0.151471     |   1\n",
      "      10559 |   0.196645  |    0.057604     |   1\n",
      "      10560 |   0.253743  |    0.136673     |   1\n",
      "      10561 |   0.250058  |    0.007638     |   0\n",
      "      10562 |   0.194798  |    0.013346     |   0\n",
      "      10563 |   0.235379  |    0.150001     |   1\n",
      "      10564 |   0.055508  |    0.005259     |   2\n",
      "      10565 |   0.212649  |    0.015432     |   0\n",
      "      10566 |   0.251525  |    0.050505     |   0\n",
      "      10567 |   0.040093  |    0.011464     |   2\n",
      "      10568 |   0.255723  |    0.043233     |   0\n",
      "      10569 |   0.238279  |    0.019729     |   0\n",
      "      10570 |   0.000066  |    0.030018     |   2\n",
      "      10571 |   0.209858  |    0.034810     |   0\n",
      "      10572 |   0.000066  |    0.015000     |   2\n",
      "      10573 |   0.223291  |    0.053873     |   0\n",
      "      10574 |   0.362011  |    0.089799     |   1\n",
      "      10575 |   0.000066  |    0.028251     |   2\n",
      "      10576 |   0.000067  |    0.049811     |   2\n",
      "      10577 |   0.000066  |    0.009661     |   2\n",
      "      10578 |   0.000066  |    0.034829     |   2\n",
      "      10579 |   0.304061  |    0.157818     |   1\n",
      "      10580 |   0.272451  |    0.046847     |   1\n",
      "      10581 |   0.068750  |    0.025023     |   2\n",
      "      10582 |   0.201866  |    0.035066     |   0\n",
      "      10583 |   0.215195  |    0.097461     |   1\n",
      "      10584 |   0.060575  |    0.028452     |   2\n",
      "      10585 |   0.253820  |    0.034344     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 10586: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      10586 |   0.189734  |    0.019579     |   0\n",
      "      10587 |   0.248466  |    0.035836     |   0\n",
      "      10588 |   0.234911  |    0.022294     |   0\n",
      "      10589 |   0.225613  |    0.053349     |   0\n",
      "      10590 |   0.260609  |    0.083007     |   1\n",
      "      10591 |   0.245546  |    0.084441     |   1\n",
      "      10592 |   0.068953  |    0.025041     |   2\n",
      "      10593 |   0.050338  |    0.041974     |   2\n",
      "      10594 |   0.049223  |    0.024356     |   2\n",
      "      10595 |   0.208132  |    0.040103     |   0\n",
      "      10596 |   0.062886  |    0.049877     |   2\n",
      "      10597 |   0.311687  |    0.095274     |   1\n",
      "      10598 |   0.034500  |    0.005697     |   2\n",
      "      10599 |   0.227068  |    0.044042     |   0\n",
      "      10600 |   0.266372  |    0.143137     |   1\n",
      "      10601 |   0.235094  |    0.006095     |   0\n",
      "      10602 |   0.052259  |    0.008585     |   2\n",
      "      10603 |   0.060193  |    0.055084     |   2\n",
      "      10604 |   0.073173  |    0.013065     |   2\n",
      "      10605 |   0.289013  |    0.162636     |   1\n",
      "      10606 |   0.166125  |    0.061624     |   1\n",
      "      10607 |   0.058635  |    0.012730     |   2\n",
      "      10608 |   0.240344  |    0.150757     |   1\n",
      "      10609 |   0.027826  |    0.003718     |   2\n",
      "      10610 |   0.241079  |    0.030824     |   0\n",
      "      10611 |   0.303052  |    0.147617     |   1\n",
      "      10612 |   0.000067  |    0.004939     |   2\n",
      "      10613 |   0.194521  |    0.080130     |   1\n",
      "      10614 |   0.283879  |    0.028295     |   0\n",
      "      10615 |   0.006719  |    0.045997     |   2\n",
      "      10616 |   0.182519  |    0.013911     |   0\n",
      "      10617 |   0.264973  |    0.135226     |   1\n",
      "      10618 |   0.088422  |    0.019383     |   2\n",
      "      10619 |   0.283311  |    0.140614     |   1\n",
      "      10620 |   0.204091  |    0.017941     |   0\n",
      "      10621 |   0.262656  |    0.068373     |   1\n",
      "      10622 |   0.044042  |    0.015967     |   2\n",
      "      10623 |   0.064807  |    0.044985     |   2\n",
      "      10624 |   0.055205  |    0.010987     |   2\n",
      "      10625 |   0.193856  |    0.039473     |   0\n",
      "      10626 |   0.188943  |    0.099081     |   1\n",
      "      10627 |   0.024238  |    0.032488     |   2\n",
      "      10628 |   0.051195  |    0.045429     |   2\n",
      "      10629 |   0.235830  |    0.103763     |   1\n",
      "      10630 |   0.293148  |    0.047437     |   1\n",
      "      10631 |   0.265383  |    0.115651     |   1\n",
      "      10632 |   0.039236  |    0.020466     |   2\n",
      "      10633 |   0.000066  |    0.012416     |   2\n",
      "      10634 |   0.207884  |    0.036844     |   0\n",
      "      10635 |   0.222647  |    0.108375     |   1\n",
      "      10636 |   0.177951  |    0.099311     |   1\n",
      "      10637 |   0.328201  |    0.107852     |   1\n",
      "      10638 |   0.233420  |    0.050516     |   1\n",
      "      10639 |   0.000066  |    0.010660     |   2\n",
      "      10640 |   0.000066  |    0.054179     |   2\n",
      "      10641 |   0.000067  |    0.021945     |   2\n",
      "      10642 |   0.000066  |    0.022367     |   2\n",
      "      10643 |   0.206001  |    0.023134     |   0\n",
      "      10644 |   0.248812  |    0.028068     |   0\n",
      "      10645 |   0.000066  |    0.032409     |   2\n",
      "      10646 |   0.196879  |    0.157935     |   1\n",
      "      10647 |   0.200835  |    0.008667     |   0\n",
      "      10648 |   0.252450  |    0.091375     |   1\n",
      "      10649 |   0.210905  |    0.094394     |   1\n",
      "      10650 |   0.280640  |    0.086619     |   1\n",
      "      10651 |   0.208140  |    0.031641     |   0\n",
      "      10652 |   0.198901  |    0.140172     |   1\n",
      "      10653 |   0.221997  |    0.062613     |   1\n",
      "      10654 |   0.313912  |    0.101123     |   1\n",
      "      10655 |   0.261134  |    0.094208     |   1\n",
      "      10656 |   0.059225  |    0.013533     |   2\n",
      "      10657 |   0.244985  |    0.047205     |   0\n",
      "      10658 |   0.224860  |    0.012302     |   0\n",
      "      10659 |   0.209736  |    0.045199     |   0\n",
      "      10660 |   0.057087  |    0.008814     |   2\n",
      "      10661 |   0.233795  |    0.169726     |   1\n",
      "      10662 |   0.185778  |    0.018533     |   0\n",
      "      10663 |   0.237067  |    0.047411     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 10664: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      10664 |   0.200403  |    0.021651     |   0\n",
      "      10665 |   0.259995  |    0.033984     |   0\n",
      "      10666 |   0.070731  |    0.021802     |   2\n",
      "      10667 |   0.193355  |    0.048421     |   0\n",
      "      10668 |   0.266651  |    0.092331     |   1\n",
      "      10669 |   0.207415  |    0.144541     |   1\n",
      "      10670 |   0.050351  |    0.005743     |   2\n",
      "      10671 |   0.048779  |    0.009347     |   2\n",
      "      10672 |   0.212734  |    0.140217     |   1\n",
      "      10673 |   0.063083  |    0.007552     |   2\n",
      "      10674 |   0.034740  |    0.051547     |   2\n",
      "      10675 |   0.050831  |    0.010068     |   2\n",
      "      10676 |   0.064439  |    0.054514     |   2\n",
      "      10677 |   0.284653  |    0.112534     |   1\n",
      "      10678 |   0.294194  |    0.012226     |   0\n",
      "      10679 |   0.223394  |    0.087784     |   1\n",
      "      10680 |   0.295529  |    0.069815     |   1\n",
      "      10681 |   0.202709  |    0.136311     |   1\n",
      "      10682 |   0.198577  |    0.003010     |   0\n",
      "      10683 |   0.072709  |    0.008046     |   2\n",
      "      10684 |   0.058981  |    0.051039     |   2\n",
      "      10685 |   0.200048  |    0.103387     |   1\n",
      "      10686 |   0.030007  |    0.004989     |   2\n",
      "      10687 |   0.241037  |    0.026872     |   0\n",
      "      10688 |   0.000064  |    0.030648     |   2\n",
      "      10689 |   0.007997  |    0.021941     |   2\n",
      "      10690 |   0.223762  |    0.033711     |   0\n",
      "      10691 |   0.219255  |    0.093565     |   1\n",
      "      10692 |   0.185964  |    0.050368     |   0\n",
      "      10693 |   0.090225  |    0.020918     |   2\n",
      "      10694 |   0.243243  |    0.098922     |   1\n",
      "      10695 |   0.045037  |    0.019270     |   2\n",
      "      10696 |   0.230495  |    0.049342     |   0\n",
      "      10697 |   0.178085  |    0.085252     |   1\n",
      "      10698 |   0.066323  |    0.011601     |   2\n",
      "      10699 |   0.235138  |    0.126999     |   1\n",
      "      10700 |   0.221167  |    0.009902     |   0\n",
      "      10701 |   0.176286  |    0.031368     |   0\n",
      "      10702 |   0.057855  |    0.016679     |   2\n",
      "      10703 |   0.254611  |    0.044900     |   0\n",
      "      10704 |   0.191628  |    0.013586     |   0\n",
      "      10705 |   0.198456  |    0.042173     |   0\n",
      "      10706 |   0.201857  |    0.026514     |   0\n",
      "      10707 |   0.240070  |    0.047342     |   0\n",
      "      10708 |   0.170387  |    0.101396     |   1\n",
      "      10709 |   0.246512  |    0.153182     |   1\n",
      "      10710 |   0.240382  |    0.027930     |   1\n",
      "      10711 |   0.190956  |    0.040840     |   0\n",
      "      10712 |   0.165727  |    0.013580     |   0\n",
      "      10713 |   0.026078  |    0.042306     |   2\n",
      "      10714 |   0.055315  |    0.012655     |   2\n",
      "      10715 |   0.245735  |    0.130652     |   1\n",
      "      10716 |   0.269643  |    0.092867     |   1\n",
      "      10717 |   0.253146  |    0.085892     |   1\n",
      "      10718 |   0.040021  |    0.013284     |   2\n",
      "      10719 |   0.170148  |    0.023609     |   0\n",
      "      10720 |   0.176360  |    0.047281     |   0\n",
      "      10721 |   0.000064  |    0.010012     |   2\n",
      "      10722 |   0.164336  |    0.136389     |   1\n",
      "      10723 |   0.000065  |    0.005817     |   2\n",
      "      10724 |   0.250869  |    0.139187     |   1\n",
      "      10725 |   0.000065  |    0.012040     |   2\n",
      "      10726 |   0.185291  |    0.048533     |   0\n",
      "      10727 |   0.240987  |    0.097896     |   1\n",
      "      10728 |   0.187240  |    0.018338     |   0\n",
      "      10729 |   0.218473  |    0.136665     |   1\n",
      "      10730 |   0.000066  |    0.012554     |   2\n",
      "      10731 |   0.240018  |    0.091368     |   1\n",
      "      10732 |   0.139994  |    0.090562     |   1\n",
      "      10733 |   0.225042  |    0.092119     |   1\n",
      "      10734 |   0.250039  |    0.090000     |   1\n",
      "      10735 |   0.303768  |    0.077390     |   1\n",
      "      10736 |   0.197092  |    0.032812     |   0\n",
      "      10737 |   0.000065  |    0.027901     |   2\n",
      "      10738 |   0.000065  |    0.023394     |   2\n",
      "      10739 |   0.061718  |    0.026136     |   2\n",
      "      10740 |   0.251645  |    0.138403     |   1\n",
      "      10741 |   0.056624  |    0.008648     |   2\n",
      "      10742 |   0.266978  |    0.011309     |   0\n",
      "      10743 |   0.194397  |    0.044648     |   0\n",
      "      10744 |   0.211651  |    0.084373     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 10745: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      10745 |   0.269521  |    0.081346     |   1\n",
      "      10746 |   0.200660  |    0.039530     |   0\n",
      "      10747 |   0.064746  |    0.030286     |   2\n",
      "      10748 |   0.050471  |    0.015770     |   2\n",
      "      10749 |   0.048245  |    0.026716     |   2\n",
      "      10750 |   0.215160  |    0.033186     |   0\n",
      "      10751 |   0.060455  |    0.015825     |   2\n",
      "      10752 |   0.033919  |    0.027110     |   2\n",
      "      10753 |   0.050253  |    0.023801     |   2\n",
      "      10754 |   0.059957  |    0.049527     |   2\n",
      "      10755 |   0.235777  |    0.007709     |   0\n",
      "      10756 |   0.284405  |    0.043294     |   0\n",
      "      10757 |   0.077808  |    0.020642     |   2\n",
      "      10758 |   0.056085  |    0.049920     |   2\n",
      "      10759 |   0.027192  |    0.019694     |   2\n",
      "      10760 |   0.239311  |    0.134859     |   1\n",
      "      10761 |   0.233569  |    0.066438     |   1\n",
      "      10762 |   0.000065  |    0.033368     |   2\n",
      "      10763 |   0.267348  |    0.028303     |   0\n",
      "      10764 |   0.269128  |    0.031894     |   0\n",
      "      10765 |   0.179411  |    0.015199     |   0\n",
      "      10766 |   0.006992  |    0.038728     |   2\n",
      "      10767 |   0.192844  |    0.013682     |   0\n",
      "      10768 |   0.199452  |    0.044123     |   0\n",
      "      10769 |   0.089718  |    0.014746     |   2\n",
      "      10770 |   0.047015  |    0.031996     |   2\n",
      "      10771 |   0.226964  |    0.104695     |   1\n",
      "      10772 |   0.256480  |    0.098530     |   1\n",
      "      10773 |   0.197540  |    0.104254     |   1\n",
      "      10774 |   0.210378  |    0.080306     |   1\n",
      "      10775 |   0.206306  |    0.052009     |   0\n",
      "      10776 |   0.066427  |    0.005518     |   2\n",
      "      10777 |   0.199812  |    0.024412     |   0\n",
      "      10778 |   0.055964  |    0.044947     |   2\n",
      "      10779 |   0.183117  |    0.134833     |   1\n",
      "      10780 |   0.025103  |    0.007766     |   2\n",
      "      10781 |   0.051548  |    0.016922     |   2\n",
      "      10782 |   0.256183  |    0.111956     |   1\n",
      "      10783 |   0.040339  |    0.027132     |   2\n",
      "      10784 |   0.188941  |    0.140477     |   1\n",
      "      10785 |   0.000064  |    0.011623     |   2\n",
      "      10786 |   0.157199  |    0.084093     |   1\n",
      "      10787 |   0.255451  |    0.092614     |   1\n",
      "      10788 |   0.000064  |    0.018150     |   2\n",
      "      10789 |   0.000064  |    0.028970     |   2\n",
      "      10790 |   0.000066  |    0.040609     |   2\n",
      "      10791 |   0.260687  |    0.093152     |   1\n",
      "      10792 |   0.266371  |    0.090428     |   1\n",
      "      10793 |   0.000064  |    0.011897     |   2\n",
      "      10794 |   0.317659  |    0.154740     |   1\n",
      "      10795 |   0.000064  |    0.019188     |   2\n",
      "      10796 |   0.200441  |    0.089880     |   1\n",
      "      10797 |   0.220422  |    0.013945     |   0\n",
      "      10798 |   0.058197  |    0.046209     |   2\n",
      "      10799 |   0.182859  |    0.087997     |   1\n",
      "      10800 |   0.057451  |    0.019359     |   2\n",
      "      10801 |   0.243627  |    0.134981     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 10802: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      10802 |   0.061866  |    0.006660     |   2\n",
      "      10803 |   0.214452  |    0.011019     |   1\n",
      "      10804 |   0.252466  |    0.112608     |   1\n",
      "      10805 |   0.197545  |    0.096230     |   1\n",
      "      10806 |   0.201255  |    0.019158     |   0\n",
      "      10807 |   0.259358  |    0.132645     |   1\n",
      "      10808 |   0.225301  |    0.076184     |   1\n",
      "      10809 |   0.230779  |    0.008622     |   0\n",
      "      10810 |   0.170175  |    0.024488     |   0\n",
      "      10811 |   0.215672  |    0.059629     |   0\n",
      "      10812 |   0.189855  |    0.098386     |   1\n",
      "      10813 |   0.263628  |    0.061098     |   1\n",
      "      10814 |   0.048016  |    0.021758     |   2\n",
      "      10815 |   0.180177  |    0.043555     |   0\n",
      "      10816 |   0.213831  |    0.041902     |   0\n",
      "      10817 |   0.197989  |    0.083937     |   1\n",
      "      10818 |   0.180498  |    0.017350     |   0\n",
      "      10819 |   0.046967  |    0.050373     |   2\n",
      "      10820 |   0.206332  |    0.093304     |   1\n",
      "      10821 |   0.215536  |    0.012503     |   0\n",
      "      10822 |   0.185666  |    0.117956     |   1\n",
      "      10823 |   0.062861  |    0.012767     |   2\n",
      "      10824 |   0.269292  |    0.161116     |   1\n",
      "      10825 |   0.223842  |    0.048902     |   1\n",
      "      10826 |   0.161617  |    0.025748     |   0\n",
      "      10827 |   0.201260  |    0.216439     |   1\n",
      "      10828 |   0.226761  |    0.185218     |   1\n",
      "      10829 |   0.034129  |    0.013474     |   2\n",
      "      10830 |   0.213598  |    0.093565     |   0\n",
      "      10831 |   0.202426  |    0.137482     |   1\n",
      "      10832 |   0.051247  |    0.039956     |   2\n",
      "      10833 |   0.159317  |    0.095825     |   0\n",
      "      10834 |   0.207298  |    0.145612     |   1\n",
      "      10835 |   0.299568  |    0.078478     |   0\n",
      "      10836 |   0.214682  |    0.005515     |   0\n",
      "      10837 |   0.055530  |    0.023588     |   2\n",
      "      10838 |   0.071535  |    0.040082     |   2\n",
      "      10839 |   0.245252  |    0.026155     |   0\n",
      "      10840 |   0.190091  |    0.040960     |   0\n",
      "      10841 |   0.058867  |    0.007401     |   2\n",
      "      10842 |   0.221141  |    0.040074     |   0\n",
      "      10843 |   0.232103  |    0.023371     |   0\n",
      "      10844 |   0.260373  |    0.040949     |   0\n",
      "      10845 |   0.029154  |    0.016294     |   2\n",
      "      10846 |   0.182625  |    0.156710     |   1\n",
      "      10847 |   0.146646  |    0.003254     |   0\n",
      "      10848 |   0.195031  |    0.007284     |   0\n",
      "      10849 |   0.242008  |    0.190186     |   1\n",
      "      10850 |   0.000063  |    0.038739     |   2\n",
      "      10851 |   0.007126  |    0.047061     |   2\n",
      "      10852 |   0.085961  |    0.042186     |   2\n",
      "      10853 |   0.044677  |    0.074475     |   2\n",
      "      10854 |   0.064551  |    0.013893     |   2\n",
      "      10855 |   0.234034  |    0.078954     |   0\n",
      "      10856 |   0.057825  |    0.012346     |   2\n",
      "      10857 |   0.026488  |    0.080071     |   2\n",
      "      10858 |   0.222276  |    0.185165     |   1\n",
      "      10859 |   0.158633  |    0.007295     |   0\n",
      "      10860 |   0.217033  |    0.020011     |   0\n",
      "      10861 |   0.242058  |    0.146348     |   1\n",
      "      10862 |   0.190915  |    0.079543     |   1\n",
      "      10863 |   0.051464  |    0.004858     |   2\n",
      "      10864 |   0.206977  |    0.025023     |   0\n",
      "      10865 |   0.243283  |    0.042287     |   0\n",
      "      10866 |   0.260931  |    0.012851     |   0\n",
      "      10867 |   0.040191  |    0.029135     |   2\n",
      "      10868 |   0.196130  |    0.038826     |   0\n",
      "      10869 |   0.188124  |    0.145415     |   1\n",
      "      10870 |   0.000064  |    0.007888     |   2\n",
      "      10871 |   0.233100  |    0.033757     |   0\n",
      "      10872 |   0.187300  |    0.112127     |   1\n",
      "      10873 |   0.000064  |    0.008256     |   2\n",
      "      10874 |   0.174135  |    0.146364     |   1\n",
      "      10875 |   0.247769  |    0.084662     |   1\n",
      "      10876 |   0.212042  |    0.012446     |   0\n",
      "      10877 |   0.233217  |    0.138900     |   1\n",
      "      10878 |   0.000064  |    0.004332     |   2\n",
      "      10879 |   0.000064  |    0.010681     |   2\n",
      "      10880 |   0.209319  |    0.046843     |   0\n",
      "      10881 |   0.164570  |    0.120152     |   1\n",
      "      10882 |   0.000064  |    0.024399     |   2\n",
      "      10883 |   0.258028  |    0.133822     |   1\n",
      "      10884 |   0.208242  |    0.016258     |   0\n",
      "      10885 |   0.161810  |    0.033005     |   1\n",
      "      10886 |   0.156331  |    0.040403     |   0\n",
      "      10887 |   0.194661  |    0.137688     |   1\n",
      "      10888 |   0.217477  |    0.047481     |   1\n",
      "      10889 |   0.213068  |    0.008467     |   0\n",
      "      10890 |   0.227116  |    0.039319     |   0\n",
      "      10891 |   0.198240  |    0.141365     |   1\n",
      "      10892 |   0.217885  |    0.006706     |   0\n",
      "      10893 |   0.000063  |    0.025347     |   2\n",
      "      10894 |   0.065130  |    0.017301     |   2\n",
      "      10895 |   0.057819  |    0.038458     |   2\n",
      "      10896 |   0.191742  |    0.129438     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 10899: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      10897 |   0.182397  |    0.005899     |   0\n",
      "      10898 |   0.160456  |    0.024176     |   0\n",
      "      10899 |   0.066348  |    0.020050     |   2\n",
      "      10900 |   0.048990  |    0.027055     |   2\n",
      "      10901 |   0.215722  |    0.153764     |   1\n",
      "      10902 |   0.173854  |    0.074449     |   1\n",
      "      10903 |   0.181305  |    0.036056     |   0\n",
      "      10904 |   0.048855  |    0.022003     |   2\n",
      "      10905 |   0.209127  |    0.154455     |   1\n",
      "      10906 |   0.193531  |    0.003285     |   0\n",
      "      10907 |   0.188637  |    0.005992     |   0\n",
      "      10908 |   0.064925  |    0.059196     |   2\n",
      "      10909 |   0.224577  |    0.004786     |   0\n",
      "      10910 |   0.273906  |    0.036191     |   0\n",
      "      10911 |   0.183133  |    0.133078     |   1\n",
      "      10912 |   0.227992  |    0.016138     |   0\n",
      "      10913 |   0.033376  |    0.008946     |   2\n",
      "      10914 |   0.284975  |    0.042165     |   0\n",
      "      10915 |   0.215365  |    0.134552     |   1\n",
      "      10916 |   0.197247  |    0.061652     |   1\n",
      "      10917 |   0.265849  |    0.088578     |   1\n",
      "      10918 |   0.050055  |    0.018171     |   2\n",
      "      10919 |   0.059877  |    0.029328     |   2\n",
      "      10920 |   0.274746  |    0.083934     |   1\n",
      "      10921 |   0.200709  |    0.030987     |   0\n",
      "      10922 |   0.171799  |    0.160919     |   1\n",
      "      10923 |   0.245349  |    0.034509     |   1\n",
      "      10924 |   0.210126  |    0.141788     |   1\n",
      "      10925 |   0.226102  |    0.003189     |   0\n",
      "      10926 |   0.071706  |    0.004178     |   2\n",
      "      10927 |   0.060650  |    0.036088     |   2\n",
      "      10928 |   0.216744  |    0.147083     |   1\n",
      "      10929 |   0.185909  |    0.058312     |   1\n",
      "      10930 |   0.231754  |    0.141850     |   1\n",
      "      10931 |   0.030972  |    0.002900     |   2\n",
      "      10932 |   0.000064  |    0.006556     |   2\n",
      "      10933 |   0.008294  |    0.047912     |   2\n",
      "      10934 |   0.081831  |    0.009981     |   2\n",
      "      10935 |   0.041986  |    0.031698     |   2\n",
      "      10936 |   0.194619  |    0.035335     |   0\n",
      "      10937 |   0.202317  |    0.133707     |   1\n",
      "      10938 |   0.236079  |    0.002906     |   0\n",
      "      10939 |   0.063190  |    0.013401     |   2\n",
      "      10940 |   0.235560  |    0.156458     |   1\n",
      "      10941 |   0.269474  |    0.082486     |   1\n",
      "      10942 |   0.287338  |    0.099586     |   1\n",
      "      10943 |   0.193799  |    0.011446     |   0\n",
      "      10944 |   0.254193  |    0.080904     |   1\n",
      "      10945 |   0.215100  |    0.016022     |   0\n",
      "      10946 |   0.167731  |    0.043139     |   0\n",
      "      10947 |   0.217822  |    0.018412     |   0\n",
      "      10948 |   0.056444  |    0.043264     |   2\n",
      "      10949 |   0.247536  |    0.050861     |   1\n",
      "      10950 |   0.023577  |    0.026030     |   2\n",
      "      10951 |   0.050324  |    0.036820     |   2\n",
      "      10952 |   0.189333  |    0.091868     |   1\n",
      "      10953 |   0.202297  |    0.009323     |   0\n",
      "      10954 |   0.218294  |    0.030585     |   0\n",
      "      10955 |   0.194925  |    0.089241     |   1\n",
      "      10956 |   0.249903  |    0.035345     |   0\n",
      "      10957 |   0.211227  |    0.088637     |   1\n",
      "      10958 |   0.224913  |    0.018110     |   0\n",
      "      10959 |   0.189696  |    0.043936     |   0\n",
      "      10960 |   0.176406  |    0.012809     |   0\n",
      "      10961 |   0.164848  |    0.048673     |   0\n",
      "      10962 |   0.038859  |    0.012900     |   2\n",
      "      10963 |   0.000064  |    0.029299     |   2\n",
      "      10964 |   0.210784  |    0.032297     |   0\n",
      "      10965 |   0.237718  |    0.035485     |   0\n",
      "      10966 |   0.000064  |    0.036115     |   2\n",
      "      10967 |   0.236399  |    0.113690     |   1\n",
      "      10968 |   0.243274  |    0.084797     |   1\n",
      "      10969 |   0.000064  |    0.010756     |   2\n",
      "      10970 |   0.220299  |    0.143344     |   1\n",
      "      10971 |   0.000065  |    0.004781     |   2\n",
      "      10972 |   0.000064  |    0.015199     |   2\n",
      "      10973 |   0.248097  |    0.137985     |   1\n",
      "      10974 |   0.251165  |    0.004222     |   0\n",
      "      10975 |   0.000064  |    0.006138     |   2\n",
      "      10976 |   0.255489  |    0.049722     |   0\n",
      "      10977 |   0.256101  |    0.031188     |   0\n",
      "      10978 |   0.293559  |    0.091815     |   1\n",
      "      10979 |   0.211655  |    0.012360     |   0\n",
      "      10980 |   0.241922  |    0.127626     |   1\n",
      "      10981 |   0.068147  |    0.007039     |   2\n",
      "      10982 |   0.058144  |    0.058743     |   2\n",
      "      10983 |   0.239083  |    0.082295     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 10984: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      10984 |   0.187200  |    0.093964     |   1\n",
      "      10985 |   0.067343  |    0.009505     |   2\n",
      "      10986 |   0.275363  |    0.115374     |   1\n",
      "      10987 |   0.212270  |    0.087575     |   1\n",
      "      10988 |   0.168481  |    0.096077     |   1\n",
      "      10989 |   0.050523  |    0.007529     |   2\n",
      "      10990 |   0.215476  |    0.069490     |   0\n",
      "      10991 |   0.197128  |    0.081333     |   1\n",
      "      10992 |   0.047484  |    0.014474     |   2\n",
      "      10993 |   0.320615  |    0.145743     |   1\n",
      "      10994 |   0.262655  |    0.051649     |   1\n",
      "      10995 |   0.188393  |    0.046023     |   0\n",
      "      10996 |   0.062292  |    0.009860     |   2\n",
      "      10997 |   0.033663  |    0.041581     |   2\n",
      "      10998 |   0.179568  |    0.015621     |   0\n",
      "      10999 |   0.166047  |    0.031655     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 11000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 11000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      11000 |   0.049363  |    0.016211     |   2\n",
      "      11001 |   0.061974  |    0.042113     |   2\n",
      "      11002 |   0.211591  |    0.025559     |   0\n",
      "      11003 |   0.274951  |    0.029231     |   0\n",
      "      11004 |   0.047038  |    0.030094     |   2\n",
      "      11005 |   0.303774  |    0.102031     |   1\n",
      "      11006 |   0.046415  |    0.005987     |   2\n",
      "      11007 |   0.264896  |    0.037843     |   0\n",
      "      11008 |   0.060757  |    0.026110     |   2\n",
      "      11009 |   0.297911  |    0.051145     |   0\n",
      "      11010 |   0.222914  |    0.094275     |   1\n",
      "      11011 |   0.274563  |    0.138053     |   1\n",
      "      11012 |   0.234650  |    0.003080     |   0\n",
      "      11013 |   0.285391  |    0.015774     |   0\n",
      "      11014 |   0.258838  |    0.140122     |   1\n",
      "      11015 |   0.033631  |    0.003059     |   2\n",
      "      11016 |   0.211151  |    0.016898     |   0\n",
      "      11017 |   0.185293  |    0.131617     |   1\n",
      "      11018 |   0.049500  |    0.003080     |   2\n",
      "      11019 |   0.257455  |    0.020481     |   0\n",
      "      11020 |   0.059450  |    0.048156     |   2\n",
      "      11021 |   0.226545  |    0.013109     |   0\n",
      "      11022 |   0.071186  |    0.029200     |   2\n",
      "      11023 |   0.264572  |    0.082055     |   1\n",
      "      11024 |   0.253067  |    0.027067     |   0\n",
      "      11025 |   0.056689  |    0.027120     |   2\n",
      "      11026 |   0.203796  |    0.050392     |   0\n",
      "      11027 |   0.247166  |    0.084336     |   1\n",
      "      11028 |   0.159809  |    0.096371     |   1\n",
      "      11029 |   0.030354  |    0.012952     |   2\n",
      "      11030 |   0.000064  |    0.023638     |   2\n",
      "      11031 |   0.162998  |    0.033832     |   0\n",
      "      11032 |   0.186608  |    0.025129     |   0\n",
      "      11033 |   0.273622  |    0.130003     |   1\n",
      "      11034 |   0.007252  |    0.007806     |   2\n",
      "      11035 |   0.203902  |    0.015956     |   0\n",
      "      11036 |   0.084705  |    0.032315     |   2\n",
      "      11037 |   0.231134  |    0.027113     |   0\n",
      "      11038 |   0.192007  |    0.027765     |   0\n",
      "      11039 |   0.042961  |    0.026772     |   2\n",
      "      11040 |   0.224666  |    0.139197     |   1\n",
      "      11041 |   0.209080  |    0.004274     |   0\n",
      "      11042 |   0.067194  |    0.011093     |   2\n",
      "      11043 |   0.208218  |    0.138722     |   1\n",
      "      11044 |   0.056054  |    0.008336     |   2\n",
      "      11045 |   0.236852  |    0.022571     |   0\n",
      "      11046 |   0.261694  |    0.046593     |   0\n",
      "      11047 |   0.025599  |    0.018835     |   2\n",
      "      11048 |   0.054904  |    0.045773     |   2\n",
      "      11049 |   0.201917  |    0.093800     |   1\n",
      "      11050 |   0.200390  |    0.008980     |   0\n",
      "      11051 |   0.197266  |    0.047584     |   0\n",
      "      11052 |   0.200412  |    0.010078     |   0\n",
      "      11053 |   0.235321  |    0.138666     |   1\n",
      "      11054 |   0.039318  |    0.005261     |   2\n",
      "      11055 |   0.213185  |    0.032998     |   0\n",
      "      11056 |   0.000063  |    0.031035     |   2\n",
      "      11057 |   0.273826  |    0.100938     |   1\n",
      "      11058 |   0.000064  |    0.008367     |   2\n",
      "      11059 |   0.000064  |    0.016455     |   2\n",
      "      11060 |   0.290362  |    0.140858     |   1\n",
      "      11061 |   0.197056  |    0.082195     |   1\n",
      "      11062 |   0.000065  |    0.005842     |   2\n",
      "      11063 |   0.302525  |    0.098816     |   1\n",
      "      11064 |   0.217492  |    0.079801     |   1\n",
      "      11065 |   0.194384  |    0.082788     |   1\n",
      "      11066 |   0.261698  |    0.079461     |   1\n",
      "      11067 |   0.000064  |    0.010135     |   2\n",
      "      11068 |   0.000064  |    0.023339     |   2\n",
      "      11069 |   0.064976  |    0.027278     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 11071: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      11070 |   0.058733  |    0.039325     |   2\n",
      "      11071 |   0.222223  |    0.157639     |   1\n",
      "      11072 |   0.208320  |    0.036171     |   1\n",
      "      11073 |   0.064791  |    0.029072     |   2\n",
      "      11074 |   0.196839  |    0.105394     |   1\n",
      "      11075 |   0.188498  |    0.089355     |   1\n",
      "      11076 |   0.261711  |    0.004774     |   0\n",
      "      11077 |   0.234276  |    0.017232     |   0\n",
      "      11078 |   0.235243  |    0.033971     |   0\n",
      "      11079 |   0.202455  |    0.106358     |   1\n",
      "      11080 |   0.225081  |    0.013368     |   0\n",
      "      11081 |   0.311899  |    0.142672     |   1\n",
      "      11082 |   0.189041  |    0.058155     |   1\n",
      "      11083 |   0.179872  |    0.010440     |   0\n",
      "      11084 |   0.048173  |    0.043769     |   2\n",
      "      11085 |   0.196429  |    0.014400     |   0\n",
      "      11086 |   0.217728  |    0.033678     |   0\n",
      "      11087 |   0.047221  |    0.026084     |   2\n",
      "      11088 |   0.226295  |    0.163993     |   1\n",
      "      11089 |   0.299766  |    0.017875     |   1\n",
      "      11090 |   0.236055  |    0.049316     |   0\n",
      "      11091 |   0.229788  |    0.095387     |   1\n",
      "      11092 |   0.059790  |    0.011783     |   2\n",
      "      11093 |   0.226394  |    0.144881     |   1\n",
      "      11094 |   0.033391  |    0.004173     |   2\n",
      "      11095 |   0.051047  |    0.010825     |   2\n",
      "      11096 |   0.201851  |    0.048454     |   0\n",
      "      11097 |   0.251902  |    0.090622     |   1\n",
      "      11098 |   0.271282  |    0.007377     |   0\n",
      "      11099 |   0.244703  |    0.093161     |   1\n",
      "      11100 |   0.059270  |    0.004759     |   2\n",
      "      11101 |   0.207376  |    0.052350     |   0\n",
      "      11102 |   0.246085  |    0.006434     |   0\n",
      "      11103 |   0.176407  |    0.043108     |   0\n",
      "      11104 |   0.208271  |    0.009708     |   0\n",
      "      11105 |   0.198068  |    0.044321     |   0\n",
      "      11106 |   0.252212  |    0.015281     |   0\n",
      "      11107 |   0.260001  |    0.161554     |   1\n",
      "      11108 |   0.230641  |    0.011796     |   0\n",
      "      11109 |   0.246009  |    0.063534     |   1\n",
      "      11110 |   0.225132  |    0.032622     |   0\n",
      "      11111 |   0.273574  |    0.138907     |   1\n",
      "      11112 |   0.244512  |    0.032404     |   1\n",
      "      11113 |   0.222159  |    0.028460     |   0\n",
      "      11114 |   0.261503  |    0.148423     |   1\n",
      "      11115 |   0.127410  |    0.007396     |   0\n",
      "      11116 |   0.178273  |    0.007542     |   0\n",
      "      11117 |   0.072405  |    0.032352     |   2\n",
      "      11118 |   0.253479  |    0.106339     |   1\n",
      "      11119 |   0.212975  |    0.090020     |   1\n",
      "      11120 |   0.250511  |    0.026000     |   0\n",
      "      11121 |   0.058547  |    0.022665     |   2\n",
      "      11122 |   0.028492  |    0.022754     |   2\n",
      "      11123 |   0.243338  |    0.028618     |   0\n",
      "      11124 |   0.192345  |    0.025188     |   0\n",
      "      11125 |   0.218305  |    0.135747     |   1\n",
      "      11126 |   0.000064  |    0.004318     |   2\n",
      "      11127 |   0.172749  |    0.041891     |   0\n",
      "      11128 |   0.253384  |    0.150701     |   1\n",
      "      11129 |   0.223489  |    0.011814     |   1\n",
      "      11130 |   0.007517  |    0.042307     |   2\n",
      "      11131 |   0.229188  |    0.020939     |   0\n",
      "      11132 |   0.312179  |    0.149677     |   1\n",
      "      11133 |   0.211308  |    0.054926     |   1\n",
      "      11134 |   0.241173  |    0.090098     |   1\n",
      "      11135 |   0.089036  |    0.015831     |   2\n",
      "      11136 |   0.151337  |    0.052013     |   0\n",
      "      11137 |   0.043032  |    0.008017     |   2\n",
      "      11138 |   0.251367  |    0.145001     |   1\n",
      "      11139 |   0.244525  |    0.006463     |   0\n",
      "      11140 |   0.209766  |    0.008363     |   0\n",
      "      11141 |   0.225256  |    0.023958     |   0\n",
      "      11142 |   0.168474  |    0.045262     |   0\n",
      "      11143 |   0.250507  |    0.095071     |   1\n",
      "      11144 |   0.230898  |    0.091105     |   1\n",
      "      11145 |   0.066178  |    0.008201     |   2\n",
      "      11146 |   0.056347  |    0.042606     |   2\n",
      "      11147 |   0.242274  |    0.020161     |   0\n",
      "      11148 |   0.196211  |    0.145968     |   1\n",
      "      11149 |   0.192184  |    0.002919     |   0\n",
      "      11150 |   0.023704  |    0.015284     |   2\n",
      "      11151 |   0.253054  |    0.147245     |   1\n",
      "      11152 |   0.234545  |    0.002803     |   0\n",
      "      11153 |   0.227781  |    0.008059     |   0\n",
      "      11154 |   0.050229  |    0.043413     |   2\n",
      "      11155 |   0.040366  |    0.016567     |   2\n",
      "      11156 |   0.163998  |    0.044750     |   0\n",
      "      11157 |   0.000064  |    0.004380     |   2\n",
      "      11158 |   0.241858  |    0.046734     |   0\n",
      "      11159 |   0.289474  |    0.095386     |   1\n",
      "      11160 |   0.253510  |    0.027146     |   0\n",
      "      11161 |   0.194266  |    0.022636     |   0\n",
      "      11162 |   0.211464  |    0.016039     |   0\n",
      "      11163 |   0.000064  |    0.031716     |   2\n",
      "      11164 |   0.000064  |    0.032309     |   2\n",
      "      11165 |   0.272223  |    0.028058     |   0\n",
      "      11166 |   0.237004  |    0.140864     |   1\n",
      "      11167 |   0.145288  |    0.018862     |   0\n",
      "      11168 |   0.297110  |    0.048493     |   1\n",
      "      11169 |   0.169104  |    0.099619     |   1\n",
      "      11170 |   0.256338  |    0.047477     |   1\n",
      "      11171 |   0.000065  |    0.014402     |   2\n",
      "      11172 |   0.275247  |    0.161213     |   1\n",
      "      11173 |   0.255767  |    0.011866     |   0\n",
      "      11174 |   0.209521  |    0.048056     |   1\n",
      "      11175 |   0.234703  |    0.010644     |   0\n",
      "      11176 |   0.000064  |    0.048458     |   2\n",
      "      11177 |   0.216296  |    0.008104     |   0\n",
      "      11178 |   0.228244  |    0.073020     |   0\n",
      "      11179 |   0.157519  |    0.064262     |   1\n",
      "      11180 |   0.000064  |    0.022197     |   2\n",
      "      11181 |   0.066469  |    0.041958     |   2\n",
      "      11182 |   0.224322  |    0.012283     |   0\n",
      "      11183 |   0.179771  |    0.028221     |   0\n",
      "      11184 |   0.251019  |    0.124415     |   1\n",
      "      11185 |   0.188564  |    0.014678     |   0\n",
      "      11186 |   0.207828  |    0.089947     |   1\n",
      "      11187 |   0.262364  |    0.009758     |   0\n",
      "      11188 |   0.060470  |    0.046966     |   2\n",
      "      11189 |   0.237557  |    0.087961     |   1\n",
      "      11190 |   0.158642  |    0.007150     |   0\n",
      "      11191 |   0.245143  |    0.084583     |   1\n",
      "      11192 |   0.215127  |    0.021757     |   0\n",
      "      11193 |   0.200760  |    0.103594     |   1\n",
      "      11194 |   0.231603  |    0.093806     |   1\n",
      "      11195 |   0.304124  |    0.129741     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 11198: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      11196 |   0.199578  |    0.010762     |   0\n",
      "      11197 |   0.180364  |    0.011927     |   0\n",
      "      11198 |   0.067371  |    0.031369     |   2\n",
      "      11199 |   0.051488  |    0.024046     |   2\n",
      "      11200 |   0.246705  |    0.044895     |   0\n",
      "      11201 |   0.048281  |    0.006839     |   2\n",
      "      11202 |   0.226959  |    0.056656     |   0\n",
      "      11203 |   0.256925  |    0.104240     |   1\n",
      "      11204 |   0.282988  |    0.099033     |   1\n",
      "      11205 |   0.059923  |    0.008481     |   2\n",
      "      11206 |   0.166967  |    0.027876     |   0\n",
      "      11207 |   0.176448  |    0.043534     |   0\n",
      "      11208 |   0.211845  |    0.016210     |   0\n",
      "      11209 |   0.033476  |    0.047862     |   2\n",
      "      11210 |   0.163085  |    0.091695     |   1\n",
      "      11211 |   0.205362  |    0.085840     |   1\n",
      "      11212 |   0.217230  |    0.029223     |   0\n",
      "      11213 |   0.164241  |    0.033557     |   0\n",
      "      11214 |   0.212330  |    0.092732     |   1\n",
      "      11215 |   0.048001  |    0.018766     |   2\n",
      "      11216 |   0.205856  |    0.039757     |   0\n",
      "      11217 |   0.254491  |    0.090286     |   1\n",
      "      11218 |   0.063637  |    0.014799     |   2\n",
      "      11219 |   0.314019  |    0.142406     |   1\n",
      "      11220 |   0.066836  |    0.003878     |   2\n",
      "      11221 |   0.055996  |    0.003783     |   2\n",
      "      11222 |   0.235540  |    0.137241     |   1\n",
      "      11223 |   0.028364  |    0.002960     |   2\n",
      "      11224 |   0.144515  |    0.011806     |   0\n",
      "      11225 |   0.233668  |    0.136818     |   1\n",
      "      11226 |   0.181061  |    0.014443     |   0\n",
      "      11227 |   0.000064  |    0.053451     |   2\n",
      "      11228 |   0.256708  |    0.087085     |   1\n",
      "      11229 |   0.007719  |    0.023100     |   2\n",
      "      11230 |   0.222521  |    0.104938     |   1\n",
      "      11231 |   0.177679  |    0.065447     |   1\n",
      "      11232 |   0.203232  |    0.151709     |   1\n",
      "      11233 |   0.228562  |    0.039703     |   1\n",
      "      11234 |   0.205892  |    0.022528     |   0\n",
      "      11235 |   0.088928  |    0.032154     |   2\n",
      "      11236 |   0.198505  |    0.156004     |   1\n",
      "      11237 |   0.197255  |    0.058386     |   1\n",
      "      11238 |   0.225444  |    0.104272     |   1\n",
      "      11239 |   0.268934  |    0.097649     |   1\n",
      "      11240 |   0.258085  |    0.080095     |   1\n",
      "      11241 |   0.240802  |    0.013649     |   0\n",
      "      11242 |   0.227341  |    0.137978     |   1\n",
      "      11243 |   0.248178  |    0.093209     |   1\n",
      "      11244 |   0.168456  |    0.005558     |   0\n",
      "      11245 |   0.038853  |    0.022126     |   2\n",
      "      11246 |   0.217094  |    0.142864     |   1\n",
      "      11247 |   0.065205  |    0.002860     |   2\n",
      "      11248 |   0.054568  |    0.005591     |   2\n",
      "      11249 |   0.023955  |    0.044449     |   2\n",
      "      11250 |   0.046069  |    0.007128     |   2\n",
      "      11251 |   0.037996  |    0.047561     |   2\n",
      "      11252 |   0.209187  |    0.006821     |   0\n",
      "      11253 |   0.199108  |    0.033136     |   0\n",
      "      11254 |   0.154816  |    0.139632     |   1\n",
      "      11255 |   0.247001  |    0.047755     |   1\n",
      "      11256 |   0.000063  |    0.011295     |   2\n",
      "      11257 |   0.198334  |    0.027603     |   0\n",
      "      11258 |   0.243898  |    0.047711     |   0\n",
      "      11259 |   0.258747  |    0.084772     |   1\n",
      "      11260 |   0.203880  |    0.028656     |   0\n",
      "      11261 |   0.000063  |    0.035454     |   2\n",
      "      11262 |   0.000063  |    0.011644     |   2\n",
      "      11263 |   0.191992  |    0.030959     |   0\n",
      "      11264 |   0.000064  |    0.033133     |   2\n",
      "      11265 |   0.221562  |    0.054856     |   0\n",
      "      11266 |   0.250106  |    0.090267     |   1\n",
      "      11267 |   0.000063  |    0.018942     |   2\n",
      "      11268 |   0.000062  |    0.029217     |   2\n",
      "      11269 |   0.287007  |    0.083555     |   1\n",
      "      11270 |   0.245120  |    0.028925     |   0\n",
      "      11271 |   0.244394  |    0.144008     |   1\n",
      "      11272 |   0.067711  |    0.002956     |   2\n",
      "      11273 |   0.056889  |    0.025518     |   2\n",
      "      11274 |   0.261717  |    0.130368     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 11276: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      11275 |   0.183091  |    0.002995     |   0\n",
      "      11276 |   0.179604  |    0.007044     |   0\n",
      "      11277 |   0.210593  |    0.033588     |   0\n",
      "      11278 |   0.244564  |    0.134346     |   1\n",
      "      11279 |   0.062987  |    0.005385     |   2\n",
      "      11280 |   0.245703  |    0.087981     |   1\n",
      "      11281 |   0.048157  |    0.016016     |   2\n",
      "      11282 |   0.169879  |    0.146584     |   1\n",
      "      11283 |   0.273859  |    0.049725     |   1\n",
      "      11284 |   0.197707  |    0.140995     |   1\n",
      "      11285 |   0.197848  |    0.048400     |   1\n",
      "      11286 |   0.167415  |    0.149466     |   1\n",
      "      11287 |   0.047947  |    0.002937     |   2\n",
      "      11288 |   0.218074  |    0.006616     |   0\n",
      "      11289 |   0.206526  |    0.040834     |   0\n",
      "      11290 |   0.059957  |    0.022994     |   2\n",
      "      11291 |   0.168426  |    0.151355     |   1\n",
      "      11292 |   0.213060  |    0.002944     |   0\n",
      "      11293 |   0.032291  |    0.008992     |   2\n",
      "      11294 |   0.217543  |    0.047637     |   0\n",
      "      11295 |   0.048908  |    0.006922     |   2\n",
      "      11296 |   0.201139  |    0.033567     |   0\n",
      "      11297 |   0.058658  |    0.031988     |   2\n",
      "      11298 |   0.237849  |    0.092671     |   1\n",
      "      11299 |   0.246294  |    0.133029     |   1\n",
      "      11300 |   0.071352  |    0.002903     |   2\n",
      "      11301 |   0.244594  |    0.018106     |   0\n",
      "      11302 |   0.296075  |    0.093704     |   1\n",
      "      11303 |   0.199844  |    0.020466     |   0\n",
      "      11304 |   0.235017  |    0.133802     |   1\n",
      "      11305 |   0.057027  |    0.004372     |   2\n",
      "      11306 |   0.204610  |    0.053846     |   0\n",
      "      11307 |   0.245708  |    0.102700     |   1\n",
      "      11308 |   0.203402  |    0.049898     |   1\n",
      "      11309 |   0.028803  |    0.028459     |   2\n",
      "      11310 |   0.223832  |    0.162374     |   1\n",
      "      11311 |   0.231671  |    0.047802     |   1\n",
      "      11312 |   0.138507  |    0.098805     |   1\n",
      "      11313 |   0.000062  |    0.006021     |   2\n",
      "      11314 |   0.007464  |    0.056400     |   2\n",
      "      11315 |   0.087153  |    0.008388     |   2\n",
      "      11316 |   0.039984  |    0.046643     |   2\n",
      "      11317 |   0.143922  |    0.018477     |   0\n",
      "      11318 |   0.063984  |    0.024528     |   2\n",
      "      11319 |   0.054202  |    0.016031     |   2\n",
      "      11320 |   0.251908  |    0.050841     |   0\n",
      "      11321 |   0.024712  |    0.014103     |   2\n",
      "      11322 |   0.190118  |    0.136575     |   1\n",
      "      11323 |   0.218917  |    0.009399     |   0\n",
      "      11324 |   0.258256  |    0.039388     |   0\n",
      "      11325 |   0.049225  |    0.017577     |   2\n",
      "      11326 |   0.210343  |    0.040866     |   0\n",
      "      11327 |   0.198760  |    0.011558     |   0\n",
      "      11328 |   0.266473  |    0.143427     |   1\n",
      "      11329 |   0.204022  |    0.004458     |   0\n",
      "      11330 |   0.208726  |    0.013090     |   0\n",
      "      11331 |   0.235983  |    0.039559     |   0\n",
      "      11332 |   0.191347  |    0.009644     |   0\n",
      "      11333 |   0.195986  |    0.057122     |   0\n",
      "      11334 |   0.201069  |    0.081130     |   1\n",
      "      11335 |   0.212869  |    0.015834     |   0\n",
      "      11336 |   0.039965  |    0.024236     |   2\n",
      "      11337 |   0.000062  |    0.016430     |   2\n",
      "      11338 |   0.000062  |    0.033727     |   2\n",
      "      11339 |   0.197020  |    0.151214     |   1\n",
      "      11340 |   0.232440  |    0.049458     |   1\n",
      "      11341 |   0.160918  |    0.011868     |   0\n",
      "      11342 |   0.207413  |    0.034366     |   0\n",
      "      11343 |   0.158209  |    0.021704     |   0\n",
      "      11344 |   0.208530  |    0.029284     |   0\n",
      "      11345 |   0.152253  |    0.020802     |   0\n",
      "      11346 |   0.000062  |    0.027107     |   2\n",
      "      11347 |   0.294619  |    0.035325     |   0\n",
      "      11348 |   0.215950  |    0.022121     |   0\n",
      "      11349 |   0.166529  |    0.028556     |   0\n",
      "      11350 |   0.177914  |    0.133784     |   1\n",
      "      11351 |   0.151052  |    0.089847     |   1\n",
      "      11352 |   0.235246  |    0.025566     |   0\n",
      "      11353 |   0.000062  |    0.036384     |   2\n",
      "      11354 |   0.181241  |    0.128044     |   1\n",
      "      11355 |   0.234832  |    0.093407     |   1\n",
      "      11356 |   0.190351  |    0.062873     |   1\n",
      "      11357 |   0.201854  |    0.017879     |   0\n",
      "      11358 |   0.256055  |    0.042246     |   0\n",
      "      11359 |   0.190901  |    0.023838     |   0\n",
      "      11360 |   0.213301  |    0.021274     |   0\n",
      "      11361 |   0.222242  |    0.066053     |   0\n",
      "      11362 |   0.223901  |    0.090862     |   1\n",
      "      11363 |   0.000061  |    0.006892     |   2\n",
      "      11364 |   0.167843  |    0.138307     |   1\n",
      "      11365 |   0.243650  |    0.088842     |   1\n",
      "      11366 |   0.180121  |    0.007231     |   0\n",
      "      11367 |   0.000061  |    0.003859     |   2\n",
      "      11368 |   0.071150  |    0.056101     |   2\n",
      "      11369 |   0.260496  |    0.101200     |   1\n",
      "      11370 |   0.060059  |    0.019179     |   2\n",
      "      11371 |   0.184296  |    0.158455     |   1\n",
      "      11372 |   0.269994  |    0.018400     |   1\n",
      "      11373 |   0.252625  |    0.141956     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 11374: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      11374 |   0.070884  |    0.002946     |   2\n",
      "      11375 |   0.050205  |    0.013491     |   2\n",
      "      11376 |   0.183728  |    0.146400     |   1\n",
      "      11377 |   0.050101  |    0.002944     |   2\n",
      "      11378 |   0.182202  |    0.010801     |   0\n",
      "      11379 |   0.228233  |    0.137491     |   1\n",
      "      11380 |   0.060926  |    0.006445     |   2\n",
      "      11381 |   0.266737  |    0.025407     |   0\n",
      "      11382 |   0.200908  |    0.049214     |   0\n",
      "      11383 |   0.179248  |    0.079907     |   1\n",
      "      11384 |   0.218766  |    0.030780     |   0\n",
      "      11385 |   0.159998  |    0.134400     |   1\n",
      "      11386 |   0.033267  |    0.005673     |   2\n",
      "      11387 |   0.208449  |    0.021779     |   0\n",
      "      11388 |   0.211286  |    0.026433     |   0\n",
      "      11389 |   0.050484  |    0.019299     |   2\n",
      "      11390 |   0.059311  |    0.026000     |   2\n",
      "      11391 |   0.265635  |    0.143392     |   1\n",
      "      11392 |   0.232543  |    0.057057     |   1\n",
      "      11393 |   0.191497  |    0.019999     |   0\n",
      "      11394 |   0.262467  |    0.041993     |   0\n",
      "      11395 |   0.214376  |    0.059579     |   0\n",
      "      11396 |   0.260602  |    0.107056     |   1\n",
      "      11397 |   0.256587  |    0.063317     |   1\n",
      "      11398 |   0.186963  |    0.153203     |   1\n",
      "      11399 |   0.220557  |    0.075891     |   1\n",
      "      11400 |   0.214986  |    0.085631     |   1\n",
      "      11401 |   0.200876  |    0.054386     |   1\n",
      "      11402 |   0.261486  |    0.021916     |   0\n",
      "      11403 |   0.211640  |    0.145344     |   1\n",
      "      11404 |   0.190371  |    0.062313     |   1\n",
      "      11405 |   0.195634  |    0.023737     |   0\n",
      "      11406 |   0.067935  |    0.034682     |   2\n",
      "      11407 |   0.250861  |    0.026004     |   0\n",
      "      11408 |   0.059715  |    0.029682     |   2\n",
      "      11409 |   0.184371  |    0.029322     |   0\n",
      "      11410 |   0.192729  |    0.138594     |   1\n",
      "      11411 |   0.192345  |    0.088625     |   1\n",
      "      11412 |   0.268635  |    0.009010     |   0\n",
      "      11413 |   0.198696  |    0.009261     |   0\n",
      "      11414 |   0.226849  |    0.040826     |   0\n",
      "      11415 |   0.185071  |    0.010399     |   0\n",
      "      11416 |   0.198137  |    0.153203     |   1\n",
      "      11417 |   0.200226  |    0.005228     |   0\n",
      "      11418 |   0.186881  |    0.005331     |   0\n",
      "      11419 |   0.192293  |    0.031130     |   0\n",
      "      11420 |   0.275232  |    0.091628     |   1\n",
      "      11421 |   0.226846  |    0.016825     |   0\n",
      "      11422 |   0.177582  |    0.155700     |   1\n",
      "      11423 |   0.244127  |    0.054204     |   1\n",
      "      11424 |   0.028659  |    0.018811     |   2\n",
      "      11425 |   0.246317  |    0.136724     |   1\n",
      "      11426 |   0.000062  |    0.003114     |   2\n",
      "      11427 |   0.210188  |    0.008498     |   0\n",
      "      11428 |   0.247650  |    0.146644     |   1\n",
      "      11429 |   0.240293  |    0.058300     |   1\n",
      "      11430 |   0.007939  |    0.023449     |   2\n",
      "      11431 |   0.238463  |    0.050012     |   0\n",
      "      11432 |   0.247691  |    0.082729     |   1\n",
      "      11433 |   0.088117  |    0.004305     |   2\n",
      "      11434 |   0.043800  |    0.043075     |   2\n",
      "      11435 |   0.066687  |    0.010205     |   2\n",
      "      11436 |   0.199198  |    0.041151     |   0\n",
      "      11437 |   0.232141  |    0.018260     |   0\n",
      "      11438 |   0.057221  |    0.044423     |   2\n",
      "      11439 |   0.023630  |    0.012774     |   2\n",
      "      11440 |   0.231178  |    0.145082     |   1\n",
      "      11441 |   0.162981  |    0.007813     |   0\n",
      "      11442 |   0.051245  |    0.021841     |   2\n",
      "      11443 |   0.203331  |    0.135157     |   1\n",
      "      11444 |   0.225216  |    0.007728     |   0\n",
      "      11445 |   0.272836  |    0.023736     |   0\n",
      "      11446 |   0.225750  |    0.137105     |   1\n",
      "      11447 |   0.041930  |    0.006087     |   2\n",
      "      11448 |   0.208392  |    0.018469     |   0\n",
      "      11449 |   0.000062  |    0.038521     |   2\n",
      "      11450 |   0.188206  |    0.097325     |   1\n",
      "      11451 |   0.293240  |    0.087338     |   1\n",
      "      11452 |   0.205736  |    0.017953     |   0\n",
      "      11453 |   0.249143  |    0.178360     |   1\n",
      "      11454 |   0.230012  |    0.007648     |   0\n",
      "      11455 |   0.242871  |    0.053326     |   1\n",
      "      11456 |   0.277082  |    0.143243     |   1\n",
      "      11457 |   0.211152  |    0.053640     |   1\n",
      "      11458 |   0.194427  |    0.045082     |   0\n",
      "      11459 |   0.209016  |    0.086598     |   1\n",
      "      11460 |   0.229069  |    0.032230     |   0\n",
      "      11461 |   0.000062  |    0.017836     |   2\n",
      "      11462 |   0.000062  |    0.024659     |   2\n",
      "      11463 |   0.213008  |    0.138759     |   1\n",
      "      11464 |   0.000063  |    0.005925     |   2\n",
      "      11465 |   0.191550  |    0.024258     |   0\n",
      "      11466 |   0.231983  |    0.039278     |   0\n",
      "      11467 |   0.224671  |    0.020978     |   0\n",
      "      11468 |   0.000062  |    0.030390     |   2\n",
      "      11469 |   0.154674  |    0.131401     |   1\n",
      "      11470 |   0.000062  |    0.006951     |   2\n",
      "      11471 |   0.202811  |    0.045049     |   0\n",
      "      11472 |   0.238137  |    0.022966     |   0\n",
      "      11473 |   0.066065  |    0.034218     |   2\n",
      "      11474 |   0.216537  |    0.099939     |   1\n",
      "      11475 |   0.222853  |    0.018936     |   0\n",
      "      11476 |   0.206773  |    0.134771     |   1\n",
      "      11477 |   0.057403  |    0.014951     |   2\n",
      "      11478 |   0.277996  |    0.089618     |   1\n",
      "      11479 |   0.216919  |    0.107163     |   1\n",
      "      11480 |   0.178958  |    0.105613     |   1\n",
      "      11481 |   0.265632  |    0.112548     |   1\n",
      "      11482 |   0.235032  |    0.097188     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 11483: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      11483 |   0.259156  |    0.005347     |   0\n",
      "      11484 |   0.164273  |    0.013343     |   0\n",
      "      11485 |   0.216460  |    0.148340     |   1\n",
      "      11486 |   0.062837  |    0.005473     |   2\n",
      "      11487 |   0.183176  |    0.021218     |   0\n",
      "      11488 |   0.224218  |    0.166333     |   1\n",
      "      11489 |   0.198776  |    0.023215     |   0\n",
      "      11490 |   0.185054  |    0.072384     |   1\n",
      "      11491 |   0.224574  |    0.130576     |   1\n",
      "      11492 |   0.283303  |    0.075548     |   1\n",
      "      11493 |   0.224865  |    0.088309     |   1\n",
      "      11494 |   0.217435  |    0.090233     |   1\n",
      "      11495 |   0.193377  |    0.140297     |   1\n",
      "      11496 |   0.236594  |    0.019729     |   0\n",
      "      11497 |   0.230670  |    0.076548     |   1\n",
      "      11498 |   0.275953  |    0.056984     |   1\n",
      "      11499 |   0.301626  |    0.085906     |   1\n",
      "      11500 |   0.204774  |    0.032083     |   0\n",
      "      11501 |   0.171448  |    0.051059     |   0\n",
      "      11502 |   0.223909  |    0.017272     |   0\n",
      "      11503 |   0.059204  |    0.029055     |   2\n",
      "      11504 |   0.193177  |    0.110007     |   1\n",
      "      11505 |   0.045572  |    0.007780     |   2\n",
      "      11506 |   0.048476  |    0.055600     |   2\n",
      "      11507 |   0.203302  |    0.154864     |   1\n",
      "      11508 |   0.261634  |    0.067390     |   1\n",
      "      11509 |   0.255104  |    0.088337     |   1\n",
      "      11510 |   0.194679  |    0.033703     |   0\n",
      "      11511 |   0.058514  |    0.017675     |   2\n",
      "      11512 |   0.247030  |    0.087866     |   1\n",
      "      11513 |   0.257142  |    0.119930     |   1\n",
      "      11514 |   0.032471  |    0.020638     |   2\n",
      "      11515 |   0.209593  |    0.047110     |   0\n",
      "      11516 |   0.049084  |    0.013536     |   2\n",
      "      11517 |   0.178476  |    0.137848     |   1\n",
      "      11518 |   0.056453  |    0.009279     |   2\n",
      "      11519 |   0.209916  |    0.087569     |   1\n",
      "      11520 |   0.067610  |    0.003877     |   2\n",
      "      11521 |   0.056093  |    0.018239     |   2\n",
      "      11522 |   0.276033  |    0.044971     |   0\n",
      "      11523 |   0.029796  |    0.015220     |   2\n",
      "      11524 |   0.248447  |    0.135884     |   1\n",
      "      11525 |   0.228897  |    0.087343     |   1\n",
      "      11526 |   0.184204  |    0.088467     |   1\n",
      "      11527 |   0.241807  |    0.073531     |   1\n",
      "      11528 |   0.000061  |    0.036465     |   2\n",
      "      11529 |   0.007177  |    0.020383     |   2\n",
      "      11530 |   0.089396  |    0.018838     |   2\n",
      "      11531 |   0.258320  |    0.133278     |   1\n",
      "      11532 |   0.255459  |    0.007528     |   0\n",
      "      11533 |   0.237594  |    0.030430     |   0\n",
      "      11534 |   0.266963  |    0.058979     |   0\n",
      "      11535 |   0.257425  |    0.079731     |   1\n",
      "      11536 |   0.225339  |    0.015738     |   0\n",
      "      11537 |   0.250514  |    0.135996     |   1\n",
      "      11538 |   0.040814  |    0.005324     |   2\n",
      "      11539 |   0.063872  |    0.018817     |   2\n",
      "      11540 |   0.054842  |    0.024173     |   2\n",
      "      11541 |   0.021980  |    0.023694     |   2\n",
      "      11542 |   0.229059  |    0.039226     |   0\n",
      "      11543 |   0.048086  |    0.008857     |   2\n",
      "      11544 |   0.211459  |    0.043345     |   0\n",
      "      11545 |   0.160268  |    0.081644     |   1\n",
      "      11546 |   0.038164  |    0.029419     |   2\n",
      "      11547 |   0.184419  |    0.152683     |   1\n",
      "      11548 |   0.262919  |    0.076591     |   1\n",
      "      11549 |   0.182051  |    0.010603     |   0\n",
      "      11550 |   0.184680  |    0.042572     |   0\n",
      "      11551 |   0.181939  |    0.146442     |   1\n",
      "      11552 |   0.259133  |    0.050155     |   1\n",
      "      11553 |   0.167427  |    0.090770     |   1\n",
      "      11554 |   0.229557  |    0.024992     |   0\n",
      "      11555 |   0.159956  |    0.036252     |   0\n",
      "      11556 |   0.228984  |    0.079644     |   1\n",
      "      11557 |   0.000060  |    0.024146     |   2\n",
      "      11558 |   0.235973  |    0.111396     |   1\n",
      "      11559 |   0.000060  |    0.008349     |   2\n",
      "      11560 |   0.228023  |    0.051028     |   0\n",
      "      11561 |   0.000060  |    0.007778     |   2\n",
      "      11562 |   0.172401  |    0.044577     |   0\n",
      "      11563 |   0.223161  |    0.120119     |   1\n",
      "      11564 |   0.188305  |    0.010231     |   0\n",
      "      11565 |   0.200242  |    0.082182     |   1\n",
      "      11566 |   0.180574  |    0.006356     |   0\n",
      "      11567 |   0.000061  |    0.044720     |   2\n",
      "      11568 |   0.000060  |    0.011949     |   2\n",
      "      11569 |   0.000060  |    0.024256     |   2\n",
      "      11570 |   0.065194  |    0.045788     |   2\n",
      "      11571 |   0.213225  |    0.097831     |   1\n",
      "      11572 |   0.242581  |    0.009535     |   0\n",
      "      11573 |   0.179216  |    0.026812     |   0\n",
      "      11574 |   0.230689  |    0.022884     |   0\n",
      "      11575 |   0.056449  |    0.028100     |   2\n",
      "      11576 |   0.192999  |    0.030223     |   0\n",
      "      11577 |   0.232199  |    0.025035     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 11578: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      11578 |   0.196359  |    0.027270     |   0\n",
      "      11579 |   0.063731  |    0.046621     |   2\n",
      "      11580 |   0.212924  |    0.083612     |   1\n",
      "      11581 |   0.047159  |    0.023798     |   2\n",
      "      11582 |   0.260012  |    0.130227     |   1\n",
      "      11583 |   0.048348  |    0.003665     |   2\n",
      "      11584 |   0.185716  |    0.027561     |   0\n",
      "      11585 |   0.168591  |    0.141001     |   1\n",
      "      11586 |   0.197598  |    0.007213     |   0\n",
      "      11587 |   0.250427  |    0.031161     |   0\n",
      "      11588 |   0.214742  |    0.082461     |   1\n",
      "      11589 |   0.063635  |    0.025021     |   2\n",
      "      11590 |   0.033322  |    0.037506     |   2\n",
      "      11591 |   0.257539  |    0.033115     |   0\n",
      "      11592 |   0.048970  |    0.029073     |   2\n",
      "      11593 |   0.062053  |    0.017948     |   2\n",
      "      11594 |   0.070581  |    0.047757     |   2\n",
      "      11595 |   0.056986  |    0.011174     |   2\n",
      "      11596 |   0.184097  |    0.151260     |   1\n",
      "      11597 |   0.252311  |    0.055328     |   1\n",
      "      11598 |   0.267117  |    0.132823     |   1\n",
      "      11599 |   0.204896  |    0.095624     |   1\n",
      "      11600 |   0.238069  |    0.060854     |   1\n",
      "      11601 |   0.028406  |    0.018937     |   2\n",
      "      11602 |   0.217374  |    0.055402     |   0\n",
      "      11603 |   0.161640  |    0.087456     |   1\n",
      "      11604 |   0.000060  |    0.015566     |   2\n",
      "      11605 |   0.271554  |    0.115928     |   1\n",
      "      11606 |   0.006654  |    0.008243     |   2\n",
      "      11607 |   0.088066  |    0.046528     |   2\n",
      "      11608 |   0.040514  |    0.009996     |   2\n",
      "      11609 |   0.065864  |    0.033660     |   2\n",
      "      11610 |   0.262749  |    0.145916     |   1\n",
      "      11611 |   0.184828  |    0.054594     |   1\n",
      "      11612 |   0.187358  |    0.098232     |   1\n",
      "      11613 |   0.239854  |    0.104922     |   1\n",
      "      11614 |   0.222608  |    0.080621     |   1\n",
      "      11615 |   0.051556  |    0.021182     |   2\n",
      "      11616 |   0.198492  |    0.147245     |   1\n",
      "      11617 |   0.231698  |    0.006269     |   0\n",
      "      11618 |   0.022586  |    0.005378     |   2\n",
      "      11619 |   0.144561  |    0.016362     |   0\n",
      "      11620 |   0.178555  |    0.025345     |   0\n",
      "      11621 |   0.191058  |    0.078695     |   0\n",
      "      11622 |   0.238667  |    0.055850     |   1\n",
      "      11623 |   0.048411  |    0.018361     |   2\n",
      "      11624 |   0.182863  |    0.034464     |   0\n",
      "      11625 |   0.226222  |    0.102245     |   1\n",
      "      11626 |   0.039351  |    0.023133     |   2\n",
      "      11627 |   0.000060  |    0.030432     |   2\n",
      "      11628 |   0.000060  |    0.022046     |   2\n",
      "      11629 |   0.191924  |    0.043737     |   0\n",
      "      11630 |   0.000060  |    0.018915     |   2\n",
      "      11631 |   0.181697  |    0.139605     |   1\n",
      "      11632 |   0.163131  |    0.010402     |   0\n",
      "      11633 |   0.000061  |    0.006005     |   2\n",
      "      11634 |   0.000060  |    0.027657     |   2\n",
      "      11635 |   0.000060  |    0.010440     |   2\n",
      "      11636 |   0.193495  |    0.142784     |   1\n",
      "      11637 |   0.199527  |    0.004001     |   0\n",
      "      11638 |   0.224609  |    0.010678     |   0\n",
      "      11639 |   0.224015  |    0.044170     |   0\n",
      "      11640 |   0.062857  |    0.007575     |   2\n",
      "      11641 |   0.274882  |    0.055733     |   0\n",
      "      11642 |   0.206228  |    0.086505     |   1\n",
      "      11643 |   0.057321  |    0.009886     |   2\n",
      "      11644 |   0.242536  |    0.137023     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 11645: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      11645 |   0.188827  |    0.012899     |   0\n",
      "      11646 |   0.257988  |    0.090830     |   1\n",
      "      11647 |   0.063070  |    0.011489     |   2\n",
      "      11648 |   0.049322  |    0.043825     |   2\n",
      "      11649 |   0.047322  |    0.005219     |   2\n",
      "      11650 |   0.249630  |    0.150612     |   1\n",
      "      11651 |   0.061747  |    0.021508     |   2\n",
      "      11652 |   0.232550  |    0.173531     |   1\n",
      "      11653 |   0.234775  |    0.010388     |   0\n",
      "      11654 |   0.185056  |    0.055196     |   1\n",
      "      11655 |   0.166787  |    0.023850     |   0\n",
      "      11656 |   0.176752  |    0.043493     |   0\n",
      "      11657 |   0.237456  |    0.025255     |   0\n",
      "      11658 |   0.272202  |    0.101984     |   1\n",
      "      11659 |   0.184490  |    0.023338     |   0\n",
      "      11660 |   0.188451  |    0.139053     |   1\n",
      "      11661 |   0.226461  |    0.010261     |   0\n",
      "      11662 |   0.200907  |    0.043140     |   0\n",
      "      11663 |   0.248249  |    0.020883     |   0\n",
      "      11664 |   0.186453  |    0.142232     |   1\n",
      "      11665 |   0.150876  |    0.079194     |   1\n",
      "      11666 |   0.184526  |    0.005928     |   0\n",
      "      11667 |   0.206471  |    0.020517     |   0\n",
      "      11668 |   0.033251  |    0.046123     |   2\n",
      "      11669 |   0.265076  |    0.025251     |   0\n",
      "      11670 |   0.261831  |    0.135252     |   1\n",
      "      11671 |   0.241158  |    0.010135     |   0\n",
      "      11672 |   0.049334  |    0.008719     |   2\n",
      "      11673 |   0.237807  |    0.044962     |   0\n",
      "      11674 |   0.332878  |    0.083721     |   1\n",
      "      11675 |   0.204457  |    0.019155     |   0\n",
      "      11676 |   0.208683  |    0.039499     |   0\n",
      "      11677 |   0.240269  |    0.029729     |   0\n",
      "      11678 |   0.230569  |    0.136400     |   1\n",
      "      11679 |   0.064901  |    0.009124     |   2\n",
      "      11680 |   0.226332  |    0.137952     |   1\n",
      "      11681 |   0.207815  |    0.013725     |   0\n",
      "      11682 |   0.263872  |    0.096981     |   1\n",
      "      11683 |   0.069059  |    0.004268     |   2\n",
      "      11684 |   0.059478  |    0.011699     |   2\n",
      "      11685 |   0.203700  |    0.135779     |   1\n",
      "      11686 |   0.230005  |    0.009720     |   0\n",
      "      11687 |   0.177030  |    0.027551     |   0\n",
      "      11688 |   0.133700  |    0.026174     |   0\n",
      "      11689 |   0.258954  |    0.090522     |   1\n",
      "      11690 |   0.028498  |    0.030470     |   2\n",
      "      11691 |   0.198869  |    0.127209     |   1\n",
      "      11692 |   0.235008  |    0.020881     |   0\n",
      "      11693 |   0.182027  |    0.141307     |   1\n",
      "      11694 |   0.000060  |    0.005680     |   2\n",
      "      11695 |   0.248596  |    0.158150     |   1\n",
      "      11696 |   0.206283  |    0.007217     |   0\n",
      "      11697 |   0.157088  |    0.085141     |   1\n",
      "      11698 |   0.215634  |    0.048143     |   0\n",
      "      11699 |   0.238519  |    0.138060     |   1\n",
      "      11700 |   0.006817  |    0.003890     |   2\n",
      "      11701 |   0.089926  |    0.012016     |   2\n",
      "      11702 |   0.043077  |    0.046662     |   2\n",
      "      11703 |   0.215596  |    0.009895     |   0\n",
      "      11704 |   0.069229  |    0.042143     |   2\n",
      "      11705 |   0.188154  |    0.021900     |   0\n",
      "      11706 |   0.232745  |    0.031071     |   0\n",
      "      11707 |   0.139745  |    0.146764     |   1\n",
      "      11708 |   0.209202  |    0.009470     |   0\n",
      "      11709 |   0.137694  |    0.084575     |   1\n",
      "      11710 |   0.214381  |    0.008361     |   0\n",
      "      11711 |   0.167835  |    0.030383     |   0\n",
      "      11712 |   0.220746  |    0.149515     |   1\n",
      "      11713 |   0.239033  |    0.054257     |   1\n",
      "      11714 |   0.214769  |    0.077434     |   1\n",
      "      11715 |   0.218234  |    0.082934     |   1\n",
      "      11716 |   0.057902  |    0.007960     |   2\n",
      "      11717 |   0.194942  |    0.059520     |   0\n",
      "      11718 |   0.213795  |    0.086261     |   1\n",
      "      11719 |   0.261121  |    0.088394     |   1\n",
      "      11720 |   0.024084  |    0.021294     |   2\n",
      "      11721 |   0.224387  |    0.041832     |   0\n",
      "      11722 |   0.051593  |    0.010837     |   2\n",
      "      11723 |   0.205393  |    0.041880     |   0\n",
      "      11724 |   0.176362  |    0.014978     |   0\n",
      "      11725 |   0.038494  |    0.039007     |   2\n",
      "      11726 |   0.193848  |    0.101510     |   1\n",
      "      11727 |   0.000060  |    0.011619     |   2\n",
      "      11728 |   0.243981  |    0.109270     |   1\n",
      "      11729 |   0.264366  |    0.110397     |   1\n",
      "      11730 |   0.000060  |    0.008579     |   2\n",
      "      11731 |   0.317031  |    0.046912     |   0\n",
      "      11732 |   0.000060  |    0.009487     |   2\n",
      "      11733 |   0.222590  |    0.047512     |   0\n",
      "      11734 |   0.175606  |    0.013448     |   0\n",
      "      11735 |   0.258690  |    0.158246     |   1\n",
      "      11736 |   0.143783  |    0.059984     |   1\n",
      "      11737 |   0.212917  |    0.019241     |   0\n",
      "      11738 |   0.000061  |    0.021241     |   2\n",
      "      11739 |   0.215129  |    0.027993     |   0\n",
      "      11740 |   0.000060  |    0.022849     |   2\n",
      "      11741 |   0.000060  |    0.056046     |   2\n",
      "      11742 |   0.171836  |    0.048406     |   1\n",
      "      11743 |   0.218530  |    0.023064     |   0\n",
      "      11744 |   0.251433  |    0.046318     |   0\n",
      "      11745 |   0.225138  |    0.104065     |   1\n",
      "      11746 |   0.062866  |    0.008081     |   2\n",
      "      11747 |   0.262834  |    0.097080     |   1\n",
      "      11748 |   0.188314  |    0.060534     |   1\n",
      "      11749 |   0.241942  |    0.090530     |   1\n",
      "      11750 |   0.056530  |    0.029198     |   2\n",
      "      11751 |   0.191436  |    0.038489     |   0\n",
      "      11752 |   0.186483  |    0.121246     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 11753: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      11753 |   0.169456  |    0.046709     |   1\n",
      "      11754 |   0.064246  |    0.027832     |   2\n",
      "      11755 |   0.213125  |    0.150364     |   1\n",
      "      11756 |   0.187812  |    0.054694     |   1\n",
      "      11757 |   0.237569  |    0.093007     |   1\n",
      "      11758 |   0.195408  |    0.147947     |   1\n",
      "      11759 |   0.046691  |    0.004958     |   2\n",
      "      11760 |   0.165864  |    0.006981     |   0\n",
      "      11761 |   0.046721  |    0.043096     |   2\n",
      "      11762 |   0.056811  |    0.018980     |   2\n",
      "      11763 |   0.032228  |    0.021895     |   2\n",
      "      11764 |   0.047302  |    0.012438     |   2\n",
      "      11765 |   0.276266  |    0.049342     |   0\n",
      "      11766 |   0.176468  |    0.014539     |   0\n",
      "      11767 |   0.299279  |    0.046672     |   0\n",
      "      11768 |   0.058841  |    0.032303     |   2\n",
      "      11769 |   0.212895  |    0.088319     |   1\n",
      "      11770 |   0.259277  |    0.120262     |   1\n",
      "      11771 |   0.223382  |    0.057062     |   1\n",
      "      11772 |   0.233869  |    0.017936     |   0\n",
      "      11773 |   0.182238  |    0.029121     |   0\n",
      "      11774 |   0.068357  |    0.042393     |   2\n",
      "      11775 |   0.208528  |    0.024266     |   0\n",
      "      11776 |   0.191757  |    0.029532     |   0\n",
      "      11777 |   0.056273  |    0.033669     |   2\n",
      "      11778 |   0.028799  |    0.019866     |   2\n",
      "      11779 |   0.178907  |    0.115523     |   1\n",
      "      11780 |   0.000060  |    0.007146     |   2\n",
      "      11781 |   0.007107  |    0.053413     |   2\n",
      "      11782 |   0.226433  |    0.137789     |   1\n",
      "      11783 |   0.209923  |    0.003460     |   0\n",
      "      11784 |   0.089095  |    0.006177     |   2\n",
      "      11785 |   0.238572  |    0.062004     |   0\n",
      "      11786 |   0.233982  |    0.083210     |   1\n",
      "      11787 |   0.041600  |    0.027400     |   2\n",
      "      11788 |   0.162986  |    0.049505     |   0\n",
      "      11789 |   0.197418  |    0.089011     |   1\n",
      "      11790 |   0.169274  |    0.143830     |   1\n",
      "      11791 |   0.067605  |    0.010019     |   2\n",
      "      11792 |   0.196980  |    0.091092     |   1\n",
      "      11793 |   0.246539  |    0.125820     |   1\n",
      "      11794 |   0.053563  |    0.008479     |   2\n",
      "      11795 |   0.022729  |    0.025753     |   2\n",
      "      11796 |   0.052393  |    0.043443     |   2\n",
      "      11797 |   0.264583  |    0.088521     |   1\n",
      "      11798 |   0.175300  |    0.139376     |   1\n",
      "      11799 |   0.233969  |    0.059950     |   1\n",
      "      11800 |   0.209398  |    0.134326     |   1\n",
      "      11801 |   0.038242  |    0.014297     |   2\n",
      "      11802 |   0.199885  |    0.135329     |   1\n",
      "      11803 |   0.251057  |    0.046289     |   1\n",
      "      11804 | \u001b[94m  0.000059\u001b[0m  |    0.020084     |   2\n",
      "      11805 |   0.167789  |    0.133227     |   1\n",
      "      11806 |   0.000060  |    0.008713     |   2\n",
      "      11807 |   0.236838  |    0.041999     |   0\n",
      "      11808 |   0.268088  |    0.136249     |   1\n",
      "      11809 |   0.257262  |    0.047752     |   1\n",
      "      11810 |   0.000060  |    0.019239     |   2\n",
      "      11811 |   0.193333  |    0.045097     |   0\n",
      "      11812 |   0.134051  |    0.148349     |   1\n",
      "      11813 |   0.000061  |    0.002939     |   2\n",
      "      11814 | \u001b[94m  0.000059\u001b[0m  |    0.012254     |   2\n",
      "      11815 |   0.211559  |    0.044148     |   0\n",
      "      11816 | \u001b[94m  0.000059\u001b[0m  |    0.008512     |   2\n",
      "      11817 |   0.173921  |    0.032986     |   0\n",
      "      11818 |   0.182635  |    0.033359     |   0\n",
      "      11819 |   0.268137  |    0.114911     |   1\n",
      "      11820 |   0.206219  |    0.082216     |   1\n",
      "      11821 |   0.058085  |    0.009665     |   2\n",
      "      11822 |   0.184424  |    0.066625     |   0\n",
      "      11823 |   0.211812  |    0.087853     |   1\n",
      "      11824 |   0.224974  |    0.010979     |   0\n",
      "      11825 |   0.056558  |    0.056214     |   2\n",
      "      11826 |   0.272409  |    0.083860     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 11827: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      11827 |   0.059268  |    0.007064     |   2\n",
      "      11828 |   0.046117  |    0.042947     |   2\n",
      "      11829 |   0.046040  |    0.010458     |   2\n",
      "      11830 |   0.361227  |    0.136531     |   1\n",
      "      11831 |   0.208704  |    0.012821     |   0\n",
      "      11832 |   0.192677  |    0.137724     |   1\n",
      "      11833 |   0.184633  |    0.024376     |   0\n",
      "      11834 |   0.059459  |    0.038538     |   2\n",
      "      11835 |   0.300142  |    0.082539     |   1\n",
      "      11836 |   0.031804  |    0.011447     |   2\n",
      "      11837 |   0.254484  |    0.049392     |   0\n",
      "      11838 |   0.048663  |    0.007893     |   2\n",
      "      11839 |   0.217634  |    0.046241     |   0\n",
      "      11840 |   0.217191  |    0.020181     |   0\n",
      "      11841 |   0.168453  |    0.136296     |   1\n",
      "      11842 |   0.192949  |    0.005982     |   0\n",
      "      11843 |   0.062019  |    0.035773     |   2\n",
      "      11844 |   0.198240  |    0.041767     |   0\n",
      "      11845 |   0.251046  |    0.032097     |   0\n",
      "      11846 |   0.068650  |    0.022137     |   2\n",
      "      11847 |   0.208072  |    0.028063     |   0\n",
      "      11848 |   0.060095  |    0.024599     |   2\n",
      "      11849 |   0.216556  |    0.041546     |   0\n",
      "      11850 |   0.158189  |    0.013490     |   0\n",
      "      11851 |   0.247105  |    0.030190     |   0\n",
      "      11852 |   0.028681  |    0.026727     |   2\n",
      "      11853 |   0.321659  |    0.137040     |   1\n",
      "      11854 | \u001b[94m  0.000058\u001b[0m  |    0.006508     |   2\n",
      "      11855 |   0.007035  |    0.036488     |   2\n",
      "      11856 |   0.087861  |    0.037385     |   2\n",
      "      11857 |   0.234185  |    0.027592     |   0\n",
      "      11858 |   0.043915  |    0.034444     |   2\n",
      "      11859 |   0.068038  |    0.029198     |   2\n",
      "      11860 |   0.056684  |    0.041616     |   2\n",
      "      11861 |   0.169200  |    0.114709     |   1\n",
      "      11862 |   0.249168  |    0.094274     |   1\n",
      "      11863 |   0.022823  |    0.056703     |   2\n",
      "      11864 |   0.170386  |    0.078633     |   1\n",
      "      11865 |   0.213508  |    0.136280     |   1\n",
      "      11866 |   0.246592  |    0.006797     |   0\n",
      "      11867 |   0.191388  |    0.030138     |   0\n",
      "      11868 |   0.050557  |    0.032306     |   2\n",
      "      11869 |   0.215985  |    0.090673     |   1\n",
      "      11870 |   0.036777  |    0.011098     |   2\n",
      "      11871 |   0.260256  |    0.138756     |   1\n",
      "      11872 |   0.212013  |    0.104868     |   1\n",
      "      11873 |   0.203272  |    0.012218     |   0\n",
      "      11874 |   0.224020  |    0.106451     |   1\n",
      "      11875 |   0.332722  |    0.055589     |   1\n",
      "      11876 |   0.205247  |    0.142939     |   1\n",
      "      11877 |   0.000059  |    0.008237     |   2\n",
      "      11878 |   0.243339  |    0.055036     |   1\n",
      "      11879 |   0.224744  |    0.027282     |   0\n",
      "      11880 |   0.000059  |    0.032358     |   2\n",
      "      11881 |   0.196688  |    0.139172     |   1\n",
      "      11882 |   0.000059  |    0.011802     |   2\n",
      "      11883 |   0.189293  |    0.133979     |   1\n",
      "      11884 |   0.168365  |    0.006791     |   0\n",
      "      11885 |   0.210545  |    0.013368     |   0\n",
      "      11886 |   0.000060  |    0.048011     |   2\n",
      "      11887 |   0.187423  |    0.011554     |   0\n",
      "      11888 |   0.183676  |    0.055108     |   0\n",
      "      11889 |   0.000059  |    0.008212     |   2\n",
      "      11890 |   0.000059  |    0.031050     |   2\n",
      "      11891 |   0.056785  |    0.033322     |   2\n",
      "      11892 |   0.246587  |    0.139602     |   1\n",
      "      11893 |   0.235383  |    0.011595     |   0\n",
      "      11894 |   0.168403  |    0.082729     |   1\n",
      "      11895 |   0.056390  |    0.003966     |   2\n",
      "      11896 |   0.196161  |    0.135080     |   1\n",
      "      11897 |   0.198785  |    0.092236     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 11900: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      11898 |   0.223669  |    0.009156     |   0\n",
      "      11899 |   0.197234  |    0.011432     |   0\n",
      "      11900 |   0.192299  |    0.046763     |   0\n",
      "      11901 |   0.060238  |    0.022066     |   2\n",
      "      11902 |   0.263475  |    0.154195     |   1\n",
      "      11903 |   0.194522  |    0.014170     |   1\n",
      "      11904 |   0.231789  |    0.133773     |   1\n",
      "      11905 |   0.047184  |    0.005038     |   2\n",
      "      11906 |   0.237091  |    0.096361     |   1\n",
      "      11907 |   0.174372  |    0.005733     |   0\n",
      "      11908 |   0.186696  |    0.047188     |   0\n",
      "      11909 |   0.250989  |    0.085553     |   1\n",
      "      11910 |   0.045709  |    0.027798     |   2\n",
      "      11911 |   0.061304  |    0.022649     |   2\n",
      "      11912 |   0.033011  |    0.029490     |   2\n",
      "      11913 |   0.328413  |    0.045522     |   0\n",
      "      11914 |   0.186039  |    0.013716     |   0\n",
      "      11915 |   0.048705  |    0.038363     |   2\n",
      "      11916 |   0.232863  |    0.098782     |   1\n",
      "      11917 |   0.197721  |    0.147488     |   1\n",
      "      11918 |   0.057415  |    0.005516     |   2\n",
      "      11919 |   0.226909  |    0.071126     |   1\n",
      "      11920 |   0.069513  |    0.031290     |   2\n",
      "      11921 |   0.239602  |    0.083549     |   1\n",
      "      11922 |   0.055319  |    0.007607     |   2\n",
      "      11923 |   0.026249  |    0.040414     |   2\n",
      "      11924 |   0.178710  |    0.020531     |   0\n",
      "      11925 |   0.136335  |    0.151387     |   1\n",
      "      11926 |   0.239612  |    0.099262     |   1\n",
      "      11927 |   0.238681  |    0.140064     |   1\n",
      "      11928 |   0.258038  |    0.056562     |   1\n",
      "      11929 |   0.246741  |    0.103136     |   1\n",
      "      11930 |   0.280710  |    0.071317     |   1\n",
      "      11931 |   0.249911  |    0.090017     |   1\n",
      "      11932 |   0.212527  |    0.032279     |   0\n",
      "      11933 |   0.000058  |    0.030951     |   2\n",
      "      11934 |   0.006785  |    0.017140     |   2\n",
      "      11935 |   0.216595  |    0.156640     |   1\n",
      "      11936 |   0.218848  |    0.065273     |   1\n",
      "      11937 |   0.263007  |    0.027407     |   0\n",
      "      11938 |   0.081425  |    0.051722     |   2\n",
      "      11939 |   0.039736  |    0.009484     |   2\n",
      "      11940 |   0.063508  |    0.043714     |   2\n",
      "      11941 |   0.054267  |    0.023241     |   2\n",
      "      11942 |   0.211424  |    0.036560     |   0\n",
      "      11943 |   0.202296  |    0.014908     |   0\n",
      "      11944 |   0.164245  |    0.076102     |   0\n",
      "      11945 |   0.218491  |    0.045243     |   1\n",
      "      11946 |   0.223875  |    0.079107     |   1\n",
      "      11947 |   0.023054  |    0.004288     |   2\n",
      "      11948 |   0.210165  |    0.025653     |   0\n",
      "      11949 |   0.047568  |    0.057037     |   2\n",
      "      11950 |   0.227703  |    0.097263     |   1\n",
      "      11951 |   0.217901  |    0.089810     |   1\n",
      "      11952 |   0.038434  |    0.005507     |   2\n",
      "      11953 |   0.000058  |    0.028098     |   2\n",
      "      11954 |   0.207155  |    0.158035     |   1\n",
      "      11955 |   0.223215  |    0.033836     |   1\n",
      "      11956 |   0.274639  |    0.142961     |   1\n",
      "      11957 |   0.245308  |    0.032637     |   1\n",
      "      11958 |   0.182387  |    0.092680     |   1\n",
      "      11959 |   0.198041  |    0.017082     |   0\n",
      "      11960 |   0.219354  |    0.158911     |   1\n",
      "      11961 |   0.000058  |    0.002853     |   2\n",
      "      11962 |   0.000058  |    0.007764     |   2\n",
      "      11963 |   0.196151  |    0.133762     |   1\n",
      "      11964 |   0.209177  |    0.010738     |   0\n",
      "      11965 |   0.187700  |    0.025514     |   0\n",
      "      11966 |   0.222662  |    0.043926     |   0\n",
      "      11967 |   0.000059  |    0.021892     |   2\n",
      "      11968 | \u001b[94m  0.000058\u001b[0m  |    0.031064     |   2\n",
      "      11969 |   0.256303  |    0.130431     |   1\n",
      "      11970 |   0.266331  |    0.015838     |   0\n",
      "      11971 |   0.189687  |    0.003380     |   0\n",
      "      11972 |   0.259977  |    0.084879     |   1\n",
      "      11973 |   0.212651  |    0.014550     |   0\n",
      "      11974 |   0.214696  |    0.146187     |   1\n",
      "      11975 |   0.272049  |    0.051180     |   1\n",
      "      11976 |   0.174175  |    0.013352     |   0\n",
      "      11977 |   0.191720  |    0.149978     |   1\n",
      "      11978 |   0.276095  |    0.020024     |   0\n",
      "      11979 |   0.225675  |    0.072835     |   1\n",
      "      11980 |   0.283430  |    0.068751     |   1\n",
      "      11981 |   0.175929  |    0.082630     |   1\n",
      "      11982 |   0.231012  |    0.027683     |   0\n",
      "      11983 | \u001b[94m  0.000058\u001b[0m  |    0.049145     |   2\n",
      "      11984 |   0.218420  |    0.013876     |   0\n",
      "      11985 |   0.188720  |    0.147773     |   1\n",
      "      11986 |   0.185193  |    0.097207     |   1\n",
      "      11987 |   0.216733  |    0.113079     |   1\n",
      "      11988 |   0.204484  |    0.095909     |   1\n",
      "      11989 |   0.186989  |    0.010349     |   0\n",
      "      11990 |   0.232841  |    0.044294     |   0\n",
      "      11991 |   0.233102  |    0.011140     |   0\n",
      "      11992 |   0.229963  |    0.054353     |   0\n",
      "      11993 |   0.194150  |    0.079995     |   1\n",
      "      11994 |   0.206728  |    0.145033     |   1\n",
      "      11995 |   0.257414  |    0.059813     |   1\n",
      "      11996 |   0.063201  |    0.010325     |   2\n",
      "      11997 |   0.190630  |    0.026076     |   0\n",
      "      11998 |   0.193576  |    0.045920     |   0\n",
      "      11999 |   0.291072  |    0.087669     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 12000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 12000: Plotting estimates.\n",
      "Exception in thread neuralnilm-data-process:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 810, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/dk3810/workspace/python/neuralnilm/neuralnilm/data/datathread.py\", line 16, in run\n",
      "    batch = self.data_pipeline.get_batch(**self._get_batch_kwargs)\n",
      "  File \"/home/dk3810/workspace/python/neuralnilm/neuralnilm/data/datapipeline.py\", line 46, in get_batch\n",
      "    batch = self._source_iterators[source_id].next()\n",
      "ValueError: generator already executing\n",
      "\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      12000 |   0.055057  |    0.006070     |   2\n",
      "      12001 |   0.177406  |    0.046388     |   0\n",
      "      12002 |   0.061691  |    0.023391     |   2\n",
      "      12003 |   0.044422  |    0.027942     |   2\n",
      "      12004 |   0.201992  |    0.022790     |   0\n",
      "      12005 |   0.221968  |    0.051944     |   0\n",
      "      12006 |   0.045884  |    0.011756     |   2\n",
      "      12007 |   0.190493  |    0.048407     |   0\n",
      "      12008 |   0.223165  |    0.091401     |   1\n",
      "      12009 |   0.156145  |    0.089518     |   1\n",
      "      12010 |   0.061914  |    0.012690     |   2\n",
      "      12011 |   0.230123  |    0.090784     |   1\n",
      "      12012 |   0.033408  |    0.022050     |   2\n",
      "      12013 |   0.254205  |    0.133556     |   1\n",
      "      12014 |   0.182028  |    0.055886     |   1\n",
      "      12015 |   0.209132  |    0.077595     |   1\n",
      "      12016 |   0.269774  |    0.085006     |   1\n",
      "      12017 |   0.047183  |    0.011580     |   2\n",
      "      12018 |   0.056661  |    0.044333     |   2\n",
      "      12019 |   0.179977  |    0.026097     |   0\n",
      "      12020 |   0.326934  |    0.044619     |   0\n",
      "      12021 |   0.175924  |    0.018559     |   0\n",
      "      12022 |   0.069559  |    0.035888     |   2\n",
      "      12023 |   0.053036  |    0.012873     |   2\n",
      "      12024 |   0.027649  |    0.046993     |   2\n",
      "      12025 |   0.228656  |    0.082805     |   1\n",
      "      12026 |   0.000058  |    0.019359     |   2\n",
      "      12027 |   0.006720  |    0.036182     |   2\n",
      "      12028 |   0.239938  |    0.136407     |   1\n",
      "      12029 |   0.244155  |    0.080099     |   1\n",
      "      12030 |   0.160525  |    0.081602     |   1\n",
      "      12031 |   0.239484  |    0.007672     |   0\n",
      "      12032 |   0.194974  |    0.041978     |   0\n",
      "      12033 |   0.084284  |    0.024834     |   2\n",
      "      12034 |   0.209510  |    0.111757     |   1\n",
      "      12035 |   0.041036  |    0.022217     |   2\n",
      "      12036 |   0.298817  |    0.134150     |   1\n",
      "      12037 |   0.207596  |    0.047345     |   1\n",
      "      12038 |   0.213015  |    0.069176     |   1\n",
      "      12039 |   0.062378  |    0.018565     |   2\n",
      "      12040 |   0.227373  |    0.142937     |   1\n",
      "      12041 |   0.052542  |    0.005211     |   2\n",
      "      12042 |   0.265020  |    0.022831     |   0\n",
      "      12043 |   0.022013  |    0.025187     |   2\n",
      "      12044 |   0.251656  |    0.048637     |   0\n",
      "      12045 |   0.048431  |    0.004370     |   2\n",
      "      12046 |   0.230351  |    0.047680     |   0\n",
      "      12047 |   0.232927  |    0.102757     |   1\n",
      "      12048 |   0.231292  |    0.076450     |   1\n",
      "      12049 |   0.146583  |    0.013875     |   0\n",
      "      12050 |   0.201501  |    0.048727     |   0\n",
      "      12051 |   0.222284  |    0.083245     |   1\n",
      "      12052 |   0.228222  |    0.013825     |   0\n",
      "      12053 |   0.236998  |    0.156476     |   1\n",
      "      12054 |   0.299398  |    0.040612     |   1\n",
      "      12055 |   0.037972  |    0.029761     |   2\n",
      "      12056 | \u001b[94m  0.000057\u001b[0m  |    0.023770     |   2\n",
      "      12057 |   0.231713  |    0.146248     |   1\n",
      "      12058 | \u001b[94m  0.000057\u001b[0m  |    0.004860     |   2\n",
      "      12059 | \u001b[94m  0.000057\u001b[0m  |    0.016330     |   2\n",
      "      12060 |   0.000058  |    0.030733     |   2\n",
      "      12061 |   0.237912  |    0.133544     |   1\n",
      "      12062 |   0.225829  |    0.003922     |   0\n",
      "      12063 | \u001b[94m  0.000057\u001b[0m  |    0.020988     |   2\n",
      "      12064 |   0.220731  |    0.101338     |   1\n",
      "      12065 | \u001b[94m  0.000057\u001b[0m  |    0.019253     |   2\n",
      "      12066 |   0.246607  |    0.145584     |   1\n",
      "      12067 |   0.246834  |    0.047165     |   1\n",
      "      12068 |   0.191995  |    0.023906     |   0\n",
      "      12069 |   0.062527  |    0.030278     |   2\n",
      "      12070 |   0.289670  |    0.148606     |   1\n",
      "      12071 |   0.054847  |    0.007686     |   2\n",
      "      12072 |   0.209376  |    0.059996     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 12073: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      12073 |   0.200270  |    0.094453     |   1\n",
      "      12074 |   0.202061  |    0.075214     |   1\n",
      "      12075 |   0.212290  |    0.026808     |   0\n",
      "      12076 |   0.061242  |    0.033998     |   2\n",
      "      12077 |   0.227914  |    0.025487     |   0\n",
      "      12078 |   0.191593  |    0.023880     |   0\n",
      "      12079 |   0.244611  |    0.033165     |   0\n",
      "      12080 |   0.046807  |    0.025362     |   2\n",
      "      12081 |   0.228875  |    0.045966     |   0\n",
      "      12082 |   0.045052  |    0.006233     |   2\n",
      "      12083 |   0.174003  |    0.041533     |   0\n",
      "      12084 |   0.142370  |    0.151997     |   1\n",
      "      12085 |   0.235940  |    0.085013     |   1\n",
      "      12086 |   0.206564  |    0.012421     |   0\n",
      "      12087 |   0.059984  |    0.048338     |   2\n",
      "      12088 |   0.243534  |    0.014902     |   0\n",
      "      12089 |   0.223454  |    0.155265     |   1\n",
      "      12090 |   0.236292  |    0.049043     |   1\n",
      "      12091 |   0.199455  |    0.090281     |   1\n",
      "      12092 |   0.271560  |    0.165724     |   1\n",
      "      12093 |   0.225834  |    0.003806     |   0\n",
      "      12094 |   0.264895  |    0.012001     |   0\n",
      "      12095 |   0.203338  |    0.047718     |   0\n",
      "      12096 |   0.230684  |    0.096083     |   1\n",
      "      12097 |   0.033127  |    0.006814     |   2\n",
      "      12098 |   0.048817  |    0.035116     |   2\n",
      "      12099 |   0.263597  |    0.046612     |   0\n",
      "      12100 |   0.055684  |    0.007520     |   2\n",
      "      12101 |   0.218765  |    0.046670     |   0\n",
      "      12102 |   0.172398  |    0.096957     |   1\n",
      "      12103 |   0.232729  |    0.068729     |   1\n",
      "      12104 |   0.238322  |    0.092339     |   1\n",
      "      12105 |   0.232420  |    0.099809     |   1\n",
      "      12106 |   0.067168  |    0.005438     |   2\n",
      "      12107 |   0.186493  |    0.032337     |   0\n",
      "      12108 |   0.062178  |    0.028475     |   2\n",
      "      12109 |   0.222647  |    0.021875     |   0\n",
      "      12110 |   0.251700  |    0.043705     |   0\n",
      "      12111 |   0.205825  |    0.014457     |   0\n",
      "      12112 |   0.248998  |    0.138243     |   1\n",
      "      12113 |   0.030661  |    0.007526     |   2\n",
      "      12114 |   0.201059  |    0.020907     |   0\n",
      "      12115 |   0.168408  |    0.141435     |   1\n",
      "      12116 |   0.182587  |    0.002943     |   0\n",
      "      12117 | \u001b[94m  0.000057\u001b[0m  |    0.009821     |   2\n",
      "      12118 |   0.242369  |    0.044236     |   0\n",
      "      12119 |   0.006952  |    0.008271     |   2\n",
      "      12120 |   0.212520  |    0.140350     |   1\n",
      "      12121 |   0.186862  |    0.058893     |   1\n",
      "      12122 |   0.084000  |    0.027961     |   2\n",
      "      12123 |   0.220188  |    0.140116     |   1\n",
      "      12124 |   0.177413  |    0.004092     |   0\n",
      "      12125 |   0.180061  |    0.006569     |   0\n",
      "      12126 |   0.041397  |    0.045263     |   2\n",
      "      12127 |   0.172014  |    0.035517     |   0\n",
      "      12128 |   0.193415  |    0.078029     |   1\n",
      "      12129 |   0.200654  |    0.009524     |   0\n",
      "      12130 |   0.064815  |    0.032403     |   2\n",
      "      12131 |   0.240187  |    0.141124     |   1\n",
      "      12132 |   0.269753  |    0.057185     |   1\n",
      "      12133 |   0.056218  |    0.009896     |   2\n",
      "      12134 |   0.249296  |    0.141605     |   1\n",
      "      12135 |   0.205814  |    0.102099     |   1\n",
      "      12136 |   0.272012  |    0.051446     |   1\n",
      "      12137 |   0.207347  |    0.016728     |   0\n",
      "      12138 |   0.200190  |    0.030614     |   0\n",
      "      12139 |   0.244225  |    0.089418     |   1\n",
      "      12140 |   0.024197  |    0.014324     |   2\n",
      "      12141 |   0.200468  |    0.135663     |   1\n",
      "      12142 |   0.185731  |    0.095233     |   1\n",
      "      12143 |   0.049633  |    0.016408     |   2\n",
      "      12144 |   0.203455  |    0.098165     |   1\n",
      "      12145 |   0.233347  |    0.007035     |   0\n",
      "      12146 |   0.037529  |    0.015726     |   2\n",
      "      12147 |   0.204760  |    0.026629     |   0\n",
      "      12148 |   0.000057  |    0.028361     |   2\n",
      "      12149 |   0.000057  |    0.067281     |   2\n",
      "      12150 |   0.203280  |    0.124012     |   1\n",
      "      12151 |   0.258929  |    0.032498     |   1\n",
      "      12152 |   0.223994  |    0.045939     |   0\n",
      "      12153 |   0.197816  |    0.086112     |   1\n",
      "      12154 |   0.199255  |    0.021672     |   0\n",
      "      12155 |   0.000057  |    0.028571     |   2\n",
      "      12156 |   0.000057  |    0.014802     |   2\n",
      "      12157 |   0.000057  |    0.048978     |   2\n",
      "      12158 |   0.000057  |    0.007318     |   2\n",
      "      12159 |   0.065758  |    0.036751     |   2\n",
      "      12160 |   0.056882  |    0.012111     |   2\n",
      "      12161 |   0.220943  |    0.065217     |   0\n",
      "      12162 |   0.164818  |    0.094816     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 12164: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      12163 |   0.177814  |    0.005725     |   0\n",
      "      12164 |   0.179431  |    0.057459     |   1\n",
      "      12165 |   0.226170  |    0.103317     |   1\n",
      "      12166 |   0.061864  |    0.012697     |   2\n",
      "      12167 |   0.253438  |    0.061836     |   1\n",
      "      12168 |   0.211141  |    0.097212     |   1\n",
      "      12169 |   0.173398  |    0.090011     |   1\n",
      "      12170 |   0.167036  |    0.093286     |   1\n",
      "      12171 |   0.047017  |    0.004200     |   2\n",
      "      12172 |   0.195799  |    0.058422     |   0\n",
      "      12173 |   0.226617  |    0.094252     |   1\n",
      "      12174 |   0.229837  |    0.005650     |   0\n",
      "      12175 |   0.045683  |    0.026739     |   2\n",
      "      12176 |   0.210784  |    0.034325     |   0\n",
      "      12177 |   0.059037  |    0.028734     |   2\n",
      "      12178 |   0.230740  |    0.135807     |   1\n",
      "      12179 |   0.244652  |    0.077794     |   1\n",
      "      12180 |   0.032460  |    0.006477     |   2\n",
      "      12181 |   0.241626  |    0.081960     |   0\n",
      "      12182 |   0.295212  |    0.046160     |   1\n",
      "      12183 |   0.189255  |    0.149453     |   1\n",
      "      12184 |   0.047076  |    0.003503     |   2\n",
      "      12185 |   0.057148  |    0.006854     |   2\n",
      "      12186 |   0.207237  |    0.036312     |   0\n",
      "      12187 |   0.218526  |    0.083929     |   1\n",
      "      12188 |   0.066137  |    0.010599     |   2\n",
      "      12189 |   0.056078  |    0.033404     |   2\n",
      "      12190 |   0.214286  |    0.101135     |   1\n",
      "      12191 |   0.026625  |    0.010358     |   2\n",
      "      12192 |   0.274132  |    0.046082     |   0\n",
      "      12193 |   0.200818  |    0.022896     |   0\n",
      "      12194 | \u001b[94m  0.000056\u001b[0m  |    0.025413     |   2\n",
      "      12195 |   0.224565  |    0.022448     |   0\n",
      "      12196 |   0.006655  |    0.030425     |   2\n",
      "      12197 |   0.188629  |    0.031541     |   0\n",
      "      12198 |   0.277203  |    0.153914     |   1\n",
      "      12199 |   0.174630  |    0.053528     |   1\n",
      "      12200 |   0.230480  |    0.099299     |   1\n",
      "      12201 |   0.234350  |    0.005959     |   0\n",
      "      12202 |   0.085546  |    0.025764     |   2\n",
      "      12203 |   0.200392  |    0.145309     |   1\n",
      "      12204 |   0.253026  |    0.044355     |   1\n",
      "      12205 |   0.041118  |    0.041264     |   2\n",
      "      12206 |   0.063558  |    0.008532     |   2\n",
      "      12207 |   0.184021  |    0.048549     |   0\n",
      "      12208 |   0.056798  |    0.011169     |   2\n",
      "      12209 |   0.229739  |    0.131966     |   1\n",
      "      12210 |   0.024082  |    0.020643     |   2\n",
      "      12211 |   0.196960  |    0.088683     |   1\n",
      "      12212 |   0.050019  |    0.013994     |   2\n",
      "      12213 |   0.039196  |    0.034737     |   2\n",
      "      12214 |   0.204683  |    0.036763     |   0\n",
      "      12215 |   0.183347  |    0.085090     |   1\n",
      "      12216 |   0.232828  |    0.051249     |   0\n",
      "      12217 |   0.288938  |    0.094478     |   1\n",
      "      12218 |   0.220043  |    0.083414     |   1\n",
      "      12219 | \u001b[94m  0.000056\u001b[0m  |    0.005084     |   2\n",
      "      12220 |   0.200736  |    0.047336     |   0\n",
      "      12221 |   0.185134  |    0.090008     |   1\n",
      "      12222 | \u001b[94m  0.000056\u001b[0m  |    0.006971     |   2\n",
      "      12223 |   0.232890  |    0.040999     |   0\n",
      "      12224 |   0.176944  |    0.018881     |   0\n",
      "      12225 |   0.180755  |    0.140933     |   1\n",
      "      12226 | \u001b[94m  0.000056\u001b[0m  |    0.004195     |   2\n",
      "      12227 |   0.251759  |    0.017886     |   0\n",
      "      12228 |   0.223519  |    0.048110     |   0\n",
      "      12229 |   0.216368  |    0.095013     |   1\n",
      "      12230 |   0.000056  |    0.004492     |   2\n",
      "      12231 |   0.177441  |    0.021180     |   0\n",
      "      12232 | \u001b[94m  0.000056\u001b[0m  |    0.033541     |   2\n",
      "      12233 | \u001b[94m  0.000055\u001b[0m  |    0.011617     |   2\n",
      "      12234 |   0.215724  |    0.032309     |   0\n",
      "      12235 |   0.065320  |    0.031460     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 12237: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      12236 |   0.056205  |    0.016343     |   2\n",
      "      12237 |   0.064483  |    0.032810     |   2\n",
      "      12238 |   0.208050  |    0.023334     |   0\n",
      "      12239 |   0.047458  |    0.033540     |   2\n",
      "      12240 |   0.188128  |    0.019764     |   0\n",
      "      12241 |   0.186707  |    0.022328     |   0\n",
      "      12242 |   0.200878  |    0.048507     |   0\n",
      "      12243 |   0.044765  |    0.009045     |   2\n",
      "      12244 |   0.177490  |    0.137338     |   1\n",
      "      12245 |   0.057485  |    0.007952     |   2\n",
      "      12246 |   0.179904  |    0.141707     |   1\n",
      "      12247 |   0.264025  |    0.005242     |   0\n",
      "      12248 |   0.183457  |    0.015952     |   0\n",
      "      12249 |   0.033156  |    0.033160     |   2\n",
      "      12250 |   0.046741  |    0.007775     |   2\n",
      "      12251 |   0.178480  |    0.043006     |   0\n",
      "      12252 |   0.207622  |    0.031054     |   0\n",
      "      12253 |   0.233707  |    0.165724     |   1\n",
      "      12254 |   0.060926  |    0.014662     |   2\n",
      "      12255 |   0.212810  |    0.028302     |   1\n",
      "      12256 |   0.174282  |    0.153177     |   1\n",
      "      12257 |   0.151609  |    0.016103     |   0\n",
      "      12258 |   0.240674  |    0.045865     |   1\n",
      "      12259 |   0.239412  |    0.025455     |   0\n",
      "      12260 |   0.274186  |    0.039739     |   0\n",
      "      12261 |   0.179899  |    0.094409     |   1\n",
      "      12262 |   0.067772  |    0.023292     |   2\n",
      "      12263 |   0.184767  |    0.165717     |   1\n",
      "      12264 |   0.056374  |    0.012492     |   2\n",
      "      12265 |   0.208127  |    0.081955     |   1\n",
      "      12266 |   0.204799  |    0.122282     |   1\n",
      "      12267 |   0.210018  |    0.075164     |   1\n",
      "      12268 |   0.208846  |    0.007711     |   0\n",
      "      12269 |   0.026771  |    0.018194     |   2\n",
      "      12270 | \u001b[94m  0.000055\u001b[0m  |    0.016268     |   2\n",
      "      12271 |   0.006241  |    0.030378     |   2\n",
      "      12272 |   0.184489  |    0.033390     |   0\n",
      "      12273 |   0.189473  |    0.098610     |   1\n",
      "      12274 |   0.206748  |    0.041463     |   0\n",
      "      12275 |   0.083986  |    0.020427     |   2\n",
      "      12276 |   0.292603  |    0.020508     |   0\n",
      "      12277 |   0.294272  |    0.132642     |   1\n",
      "      12278 |   0.039082  |    0.002791     |   2\n",
      "      12279 |   0.066547  |    0.010558     |   2\n",
      "      12280 |   0.054436  |    0.048607     |   2\n",
      "      12281 |   0.022279  |    0.012076     |   2\n",
      "      12282 |   0.211079  |    0.041279     |   0\n",
      "      12283 |   0.247754  |    0.017000     |   0\n",
      "      12284 |   0.220812  |    0.027554     |   0\n",
      "      12285 |   0.288587  |    0.145779     |   1\n",
      "      12286 |   0.173575  |    0.014920     |   0\n",
      "      12287 |   0.221688  |    0.090117     |   1\n",
      "      12288 |   0.049088  |    0.015193     |   2\n",
      "      12289 |   0.230166  |    0.135866     |   1\n",
      "      12290 |   0.036482  |    0.004923     |   2\n",
      "      12291 |   0.195523  |    0.016608     |   0\n",
      "      12292 |   0.245165  |    0.105092     |   1\n",
      "      12293 | \u001b[94m  0.000055\u001b[0m  |    0.019364     |   2\n",
      "      12294 |   0.316209  |    0.140279     |   1\n",
      "      12295 |   0.000055  |    0.011412     |   2\n",
      "      12296 |   0.195586  |    0.086296     |   1\n",
      "      12297 |   0.223475  |    0.079755     |   1\n",
      "      12298 |   0.242136  |    0.029625     |   0\n",
      "      12299 |   0.000055  |    0.029667     |   2\n",
      "      12300 |   0.000056  |    0.027388     |   2\n",
      "      12301 |   0.183323  |    0.024655     |   0\n",
      "      12302 |   0.000055  |    0.011484     |   2\n",
      "      12303 |   0.217520  |    0.037309     |   0\n",
      "      12304 |   0.216886  |    0.015842     |   0\n",
      "      12305 |   0.000055  |    0.028099     |   2\n",
      "      12306 |   0.232631  |    0.160165     |   1\n",
      "      12307 |   0.200292  |    0.050658     |   1\n",
      "      12308 |   0.215353  |    0.004804     |   0\n",
      "      12309 |   0.216302  |    0.060362     |   0\n",
      "      12310 |   0.201934  |    0.086509     |   1\n",
      "      12311 |   0.153827  |    0.027413     |   0\n",
      "      12312 |   0.062240  |    0.017228     |   2\n",
      "      12313 |   0.054998  |    0.034093     |   2\n",
      "      12314 |   0.174817  |    0.095720     |   1\n",
      "      12315 |   0.233964  |    0.089278     |   1\n",
      "      12316 |   0.173667  |    0.098007     |   1\n",
      "      12317 |   0.207054  |    0.096902     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 12318: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      12318 |   0.061796  |    0.014374     |   2\n",
      "      12319 |   0.045369  |    0.036369     |   2\n",
      "      12320 |   0.046706  |    0.012260     |   2\n",
      "      12321 |   0.154315  |    0.049916     |   0\n",
      "      12322 |   0.160557  |    0.093519     |   1\n",
      "      12323 |   0.226934  |    0.033736     |   0\n",
      "      12324 |   0.210811  |    0.113368     |   1\n",
      "      12325 |   0.221787  |    0.015386     |   0\n",
      "      12326 |   0.057983  |    0.020556     |   2\n",
      "      12327 |   0.279779  |    0.060006     |   0\n",
      "      12328 |   0.152404  |    0.099372     |   1\n",
      "      12329 |   0.031969  |    0.007416     |   2\n",
      "      12330 |   0.235785  |    0.028417     |   0\n",
      "      12331 |   0.046373  |    0.038775     |   2\n",
      "      12332 |   0.053812  |    0.022644     |   2\n",
      "      12333 |   0.064607  |    0.027942     |   2\n",
      "      12334 |   0.175137  |    0.028701     |   0\n",
      "      12335 |   0.189678  |    0.134045     |   1\n",
      "      12336 |   0.240632  |    0.062043     |   1\n",
      "      12337 |   0.296957  |    0.100792     |   1\n",
      "      12338 |   0.231917  |    0.007810     |   0\n",
      "      12339 |   0.187042  |    0.045787     |   0\n",
      "      12340 |   0.218224  |    0.009676     |   0\n",
      "      12341 |   0.055323  |    0.044827     |   2\n",
      "      12342 |   0.212577  |    0.018226     |   0\n",
      "      12343 |   0.028850  |    0.026240     |   2\n",
      "      12344 |   0.205744  |    0.091844     |   1\n",
      "      12345 | \u001b[94m  0.000055\u001b[0m  |    0.019514     |   2\n",
      "      12346 |   0.006816  |    0.033170     |   2\n",
      "      12347 |   0.083461  |    0.023232     |   2\n",
      "      12348 |   0.040564  |    0.035755     |   2\n",
      "      12349 |   0.213248  |    0.027479     |   0\n",
      "      12350 |   0.200112  |    0.026674     |   0\n",
      "      12351 |   0.222189  |    0.020324     |   0\n",
      "      12352 |   0.065588  |    0.047623     |   2\n",
      "      12353 |   0.056628  |    0.006080     |   2\n",
      "      12354 |   0.231974  |    0.116554     |   1\n",
      "      12355 |   0.163442  |    0.079111     |   1\n",
      "      12356 |   0.232151  |    0.012825     |   0\n",
      "      12357 |   0.171907  |    0.160382     |   1\n",
      "      12358 |   0.227832  |    0.103702     |   1\n",
      "      12359 |   0.285397  |    0.078432     |   1\n",
      "      12360 |   0.024182  |    0.007990     |   2\n",
      "      12361 |   0.053304  |    0.045999     |   2\n",
      "      12362 |   0.038147  |    0.006908     |   2\n",
      "      12363 |   0.209224  |    0.046709     |   0\n",
      "      12364 |   0.216454  |    0.019408     |   0\n",
      "      12365 |   0.259334  |    0.149667     |   1\n",
      "      12366 |   0.271284  |    0.003259     |   0\n",
      "      12367 | \u001b[94m  0.000055\u001b[0m  |    0.007692     |   2\n",
      "      12368 |   0.255470  |    0.091634     |   1\n",
      "      12369 |   0.210584  |    0.011300     |   0\n",
      "      12370 | \u001b[94m  0.000055\u001b[0m  |    0.043703     |   2\n",
      "      12371 |   0.222559  |    0.011886     |   0\n",
      "      12372 | \u001b[94m  0.000054\u001b[0m  |    0.055239     |   2\n",
      "      12373 |   0.000055  |    0.013396     |   2\n",
      "      12374 | \u001b[94m  0.000054\u001b[0m  |    0.032974     |   2\n",
      "      12375 | \u001b[94m  0.000054\u001b[0m  |    0.037611     |   2\n",
      "      12376 |   0.061868  |    0.031787     |   2\n",
      "      12377 |   0.055787  |    0.024939     |   2\n",
      "      12378 |   0.173728  |    0.043101     |   0\n",
      "      12379 |   0.212667  |    0.005990     |   0\n",
      "      12380 |   0.168031  |    0.094025     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 12382: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      12381 |   0.184272  |    0.029097     |   0\n",
      "      12382 |   0.065742  |    0.023531     |   2\n",
      "      12383 |   0.046927  |    0.022275     |   2\n",
      "      12384 |   0.182765  |    0.033859     |   0\n",
      "      12385 |   0.193183  |    0.007736     |   0\n",
      "      12386 |   0.213594  |    0.045044     |   0\n",
      "      12387 |   0.045626  |    0.042294     |   2\n",
      "      12388 |   0.198435  |    0.138981     |   1\n",
      "      12389 |   0.058212  |    0.012546     |   2\n",
      "      12390 |   0.221106  |    0.088747     |   1\n",
      "      12391 |   0.032731  |    0.009969     |   2\n",
      "      12392 |   0.221573  |    0.134896     |   1\n",
      "      12393 |   0.046165  |    0.012499     |   2\n",
      "      12394 |   0.213496  |    0.133995     |   1\n",
      "      12395 |   0.058358  |    0.005324     |   2\n",
      "      12396 |   0.065881  |    0.030935     |   2\n",
      "      12397 |   0.252884  |    0.126589     |   1\n",
      "      12398 |   0.198169  |    0.102324     |   1\n",
      "      12399 |   0.193113  |    0.019474     |   0\n",
      "      12400 |   0.229327  |    0.052219     |   1\n",
      "      12401 |   0.201079  |    0.041729     |   0\n",
      "      12402 |   0.055230  |    0.020052     |   2\n",
      "      12403 |   0.218688  |    0.079141     |   1\n",
      "      12404 |   0.026236  |    0.014963     |   2\n",
      "      12405 |   0.193833  |    0.049027     |   0\n",
      "      12406 |   0.000054  |    0.010256     |   2\n",
      "      12407 |   0.206602  |    0.132001     |   1\n",
      "      12408 |   0.007295  |    0.008197     |   2\n",
      "      12409 |   0.236166  |    0.039501     |   0\n",
      "      12410 |   0.266829  |    0.012708     |   0\n",
      "      12411 |   0.080627  |    0.043437     |   2\n",
      "      12412 |   0.177843  |    0.080829     |   1\n",
      "      12413 |   0.242187  |    0.051364     |   0\n",
      "      12414 |   0.287082  |    0.055817     |   1\n",
      "      12415 |   0.041043  |    0.026219     |   2\n",
      "      12416 |   0.231066  |    0.039061     |   0\n",
      "      12417 |   0.258309  |    0.021911     |   0\n",
      "      12418 |   0.063983  |    0.025423     |   2\n",
      "      12419 |   0.282344  |    0.145103     |   1\n",
      "      12420 |   0.195198  |    0.005149     |   0\n",
      "      12421 |   0.186224  |    0.006987     |   0\n",
      "      12422 |   0.213168  |    0.102531     |   1\n",
      "      12423 |   0.210408  |    0.098726     |   1\n",
      "      12424 |   0.224496  |    0.012051     |   0\n",
      "      12425 |   0.056612  |    0.023543     |   2\n",
      "      12426 |   0.187838  |    0.159412     |   1\n",
      "      12427 |   0.125988  |    0.066559     |   1\n",
      "      12428 |   0.026108  |    0.015822     |   2\n",
      "      12429 |   0.197537  |    0.048876     |   0\n",
      "      12430 |   0.238265  |    0.091274     |   1\n",
      "      12431 |   0.168626  |    0.010549     |   0\n",
      "      12432 |   0.184251  |    0.049814     |   0\n",
      "      12433 |   0.053190  |    0.013967     |   2\n",
      "      12434 |   0.251796  |    0.047262     |   0\n",
      "      12435 |   0.039112  |    0.010235     |   2\n",
      "      12436 |   0.232832  |    0.052856     |   0\n",
      "      12437 | \u001b[94m  0.000054\u001b[0m  |    0.009693     |   2\n",
      "      12438 |   0.000054  |    0.043782     |   2\n",
      "      12439 |   0.203884  |    0.011200     |   0\n",
      "      12440 |   0.197411  |    0.049745     |   0\n",
      "      12441 |   0.268644  |    0.016140     |   0\n",
      "      12442 | \u001b[94m  0.000054\u001b[0m  |    0.035240     |   2\n",
      "      12443 |   0.218576  |    0.106079     |   1\n",
      "      12444 |   0.000055  |    0.006643     |   2\n",
      "      12445 |   0.187766  |    0.163534     |   1\n",
      "      12446 |   0.000054  |    0.005119     |   2\n",
      "      12447 |   0.232085  |    0.088751     |   1\n",
      "      12448 |   0.164063  |    0.078935     |   1\n",
      "      12449 |   0.287346  |    0.091784     |   1\n",
      "      12450 |   0.201128  |    0.137311     |   1\n",
      "      12451 | \u001b[94m  0.000054\u001b[0m  |    0.007156     |   2\n",
      "      12452 |   0.273306  |    0.086881     |   1\n",
      "      12453 |   0.059718  |    0.007618     |   2\n",
      "      12454 |   0.054262  |    0.041510     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 12455: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      12455 |   0.241300  |    0.025334     |   0\n",
      "      12456 |   0.191849  |    0.028720     |   0\n",
      "      12457 |   0.170546  |    0.029437     |   0\n",
      "      12458 |   0.201123  |    0.033762     |   0\n",
      "      12459 |   0.061845  |    0.014055     |   2\n",
      "      12460 |   0.213660  |    0.037046     |   0\n",
      "      12461 |   0.048619  |    0.015882     |   2\n",
      "      12462 |   0.187257  |    0.162192     |   1\n",
      "      12463 |   0.044377  |    0.010280     |   2\n",
      "      12464 |   0.057829  |    0.005343     |   2\n",
      "      12465 |   0.032467  |    0.025472     |   2\n",
      "      12466 |   0.199553  |    0.030069     |   0\n",
      "      12467 |   0.184443  |    0.024139     |   0\n",
      "      12468 |   0.046221  |    0.027226     |   2\n",
      "      12469 |   0.199491  |    0.142080     |   1\n",
      "      12470 |   0.061851  |    0.004082     |   2\n",
      "      12471 |   0.170664  |    0.025604     |   0\n",
      "      12472 |   0.065460  |    0.031756     |   2\n",
      "      12473 |   0.055783  |    0.019016     |   2\n",
      "      12474 |   0.228575  |    0.148415     |   1\n",
      "      12475 |   0.189607  |    0.091970     |   1\n",
      "      12476 |   0.228721  |    0.021425     |   0\n",
      "      12477 |   0.185990  |    0.081129     |   1\n",
      "      12478 |   0.213471  |    0.135223     |   1\n",
      "      12479 |   0.027177  |    0.011486     |   2\n",
      "      12480 |   0.000054  |    0.024831     |   2\n",
      "      12481 |   0.269186  |    0.156861     |   1\n",
      "      12482 |   0.006182  |    0.013431     |   2\n",
      "      12483 |   0.202928  |    0.089356     |   1\n",
      "      12484 |   0.225283  |    0.006940     |   0\n",
      "      12485 |   0.161300  |    0.013632     |   0\n",
      "      12486 |   0.082715  |    0.043589     |   2\n",
      "      12487 |   0.038894  |    0.018263     |   2\n",
      "      12488 |   0.216504  |    0.149530     |   1\n",
      "      12489 |   0.223054  |    0.015009     |   0\n",
      "      12490 |   0.172274  |    0.081983     |   1\n",
      "      12491 |   0.220944  |    0.013654     |   0\n",
      "      12492 |   0.234778  |    0.090432     |   1\n",
      "      12493 |   0.191499  |    0.040731     |   0\n",
      "      12494 |   0.134452  |    0.086291     |   1\n",
      "      12495 |   0.065446  |    0.009242     |   2\n",
      "      12496 |   0.219902  |    0.038114     |   0\n",
      "      12497 |   0.218735  |    0.019968     |   0\n",
      "      12498 |   0.179109  |    0.040663     |   0\n",
      "      12499 |   0.053303  |    0.016258     |   2\n",
      "      12500 |   0.025634  |    0.026187     |   2\n",
      "      12501 |   0.250712  |    0.155675     |   1\n",
      "      12502 |   0.218408  |    0.060337     |   1\n",
      "      12503 |   0.058451  |    0.043981     |   2\n",
      "      12504 |   0.241933  |    0.143260     |   1\n",
      "      12505 |   0.043994  |    0.003065     |   2\n",
      "      12506 |   0.045046  |    0.010772     |   2\n",
      "      12507 |   0.058503  |    0.050024     |   2\n",
      "      12508 |   0.253843  |    0.086382     |   1\n",
      "      12509 |   0.215487  |    0.021224     |   0\n",
      "      12510 |   0.031041  |    0.052086     |   2\n",
      "      12511 |   0.224538  |    0.083069     |   1\n",
      "      12512 |   0.047017  |    0.009010     |   2\n",
      "      12513 |   0.058775  |    0.030443     |   2\n",
      "      12514 |   0.066623  |    0.037846     |   2\n",
      "      12515 |   0.233790  |    0.094739     |   1\n",
      "      12516 |   0.257135  |    0.093312     |   1\n",
      "      12517 |   0.338094  |    0.086141     |   1\n",
      "      12518 |   0.167965  |    0.010867     |   0\n",
      "      12519 |   0.225647  |    0.051651     |   0\n",
      "      12520 |   0.191914  |    0.027249     |   0\n",
      "      12521 |   0.183766  |    0.099291     |   1\n",
      "      12522 |   0.251573  |    0.006168     |   0\n",
      "      12523 |   0.213881  |    0.013746     |   0\n",
      "      12524 |   0.055955  |    0.036397     |   2\n",
      "      12525 |   0.200809  |    0.039277     |   0\n",
      "      12526 |   0.027623  |    0.017181     |   2\n",
      "      12527 |   0.000054  |    0.028899     |   2\n",
      "      12528 |   0.208612  |    0.149468     |   1\n",
      "      12529 |   0.006894  |    0.015005     |   2\n",
      "      12530 |   0.174495  |    0.092839     |   1\n",
      "      12531 |   0.219132  |    0.006291     |   0\n",
      "      12532 |   0.083033  |    0.035390     |   2\n",
      "      12533 |   0.162540  |    0.146074     |   1\n",
      "      12534 |   0.131235  |    0.054507     |   1\n",
      "      12535 |   0.040339  |    0.014798     |   2\n",
      "      12536 |   0.312856  |    0.062677     |   0\n",
      "      12537 |   0.168330  |    0.085502     |   1\n",
      "      12538 |   0.159409  |    0.136183     |   1\n",
      "      12539 |   0.195281  |    0.083401     |   1\n",
      "      12540 |   0.061682  |    0.004375     |   2\n",
      "      12541 |   0.177608  |    0.046503     |   0\n",
      "      12542 |   0.051900  |    0.021193     |   2\n",
      "      12543 |   0.207723  |    0.141568     |   1\n",
      "      12544 |   0.198289  |    0.016743     |   0\n",
      "      12545 |   0.199261  |    0.100735     |   1\n",
      "      12546 |   0.143819  |    0.095885     |   1\n",
      "      12547 |   0.175925  |    0.013265     |   0\n",
      "      12548 |   0.288023  |    0.138936     |   1\n",
      "      12549 |   0.288472  |    0.097190     |   1\n",
      "      12550 |   0.022370  |    0.010954     |   2\n",
      "      12551 |   0.218718  |    0.099039     |   1\n",
      "      12552 |   0.199846  |    0.014403     |   0\n",
      "      12553 |   0.215090  |    0.081036     |   1\n",
      "      12554 |   0.203579  |    0.138882     |   1\n",
      "      12555 |   0.274739  |    0.063445     |   1\n",
      "      12556 |   0.303561  |    0.091084     |   1\n",
      "      12557 |   0.230896  |    0.005868     |   0\n",
      "      12558 |   0.175496  |    0.024174     |   0\n",
      "      12559 |   0.048743  |    0.030085     |   2\n",
      "      12560 |   0.234573  |    0.029988     |   0\n",
      "      12561 |   0.037568  |    0.047930     |   2\n",
      "      12562 |   0.220891  |    0.086934     |   1\n",
      "      12563 |   0.270890  |    0.133150     |   1\n",
      "      12564 |   0.000054  |    0.002947     |   2\n",
      "      12565 |   0.000054  |    0.004389     |   2\n",
      "      12566 |   0.187883  |    0.055337     |   0\n",
      "      12567 | \u001b[94m  0.000054\u001b[0m  |    0.005508     |   2\n",
      "      12568 |   0.184463  |    0.054042     |   0\n",
      "      12569 |   0.278789  |    0.087640     |   1\n",
      "      12570 |   0.239989  |    0.140052     |   1\n",
      "      12571 |   0.217039  |    0.063463     |   1\n",
      "      12572 |   0.000055  |    0.007742     |   2\n",
      "      12573 |   0.221069  |    0.044588     |   0\n",
      "      12574 |   0.000054  |    0.016377     |   2\n",
      "      12575 |   0.212300  |    0.034575     |   0\n",
      "      12576 | \u001b[94m  0.000054\u001b[0m  |    0.026014     |   2\n",
      "      12577 |   0.059971  |    0.032832     |   2\n",
      "      12578 |   0.205264  |    0.109488     |   1\n",
      "      12579 |   0.184732  |    0.013274     |   0\n",
      "      12580 |   0.268512  |    0.081700     |   1\n",
      "      12581 |   0.055055  |    0.011349     |   2\n",
      "      12582 |   0.313931  |    0.133179     |   1\n",
      "      12583 |   0.147348  |    0.090524     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 12585: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      12584 |   0.237902  |    0.018331     |   0\n",
      "      12585 |   0.256352  |    0.082505     |   1\n",
      "      12586 |   0.208588  |    0.019550     |   0\n",
      "      12587 |   0.309891  |    0.044645     |   0\n",
      "      12588 |   0.227748  |    0.021079     |   0\n",
      "      12589 |   0.201639  |    0.135194     |   1\n",
      "      12590 |   0.061512  |    0.012821     |   2\n",
      "      12591 |   0.197057  |    0.134029     |   1\n",
      "      12592 |   0.047262  |    0.011193     |   2\n",
      "      12593 |   0.180836  |    0.011945     |   0\n",
      "      12594 |   0.168933  |    0.019911     |   0\n",
      "      12595 |   0.045227  |    0.020287     |   2\n",
      "      12596 |   0.175270  |    0.030725     |   0\n",
      "      12597 |   0.059748  |    0.030202     |   2\n",
      "      12598 |   0.245301  |    0.159214     |   1\n",
      "      12599 |   0.292122  |    0.027747     |   1\n",
      "      12600 |   0.195914  |    0.051473     |   0\n",
      "      12601 |   0.203927  |    0.007210     |   0\n",
      "      12602 |   0.183221  |    0.040317     |   0\n",
      "      12603 |   0.206148  |    0.037454     |   0\n",
      "      12604 |   0.289269  |    0.070599     |   1\n",
      "      12605 |   0.228925  |    0.026966     |   0\n",
      "      12606 |   0.033279  |    0.023890     |   2\n",
      "      12607 |   0.255600  |    0.136537     |   1\n",
      "      12608 |   0.046217  |    0.004656     |   2\n",
      "      12609 |   0.057255  |    0.015470     |   2\n",
      "      12610 |   0.173677  |    0.026819     |   0\n",
      "      12611 |   0.065052  |    0.027758     |   2\n",
      "      12612 |   0.222878  |    0.041559     |   0\n",
      "      12613 |   0.210084  |    0.014048     |   0\n",
      "      12614 |   0.197449  |    0.107308     |   1\n",
      "      12615 |   0.235147  |    0.016564     |   0\n",
      "      12616 |   0.263301  |    0.153114     |   1\n",
      "      12617 |   0.246726  |    0.050437     |   1\n",
      "      12618 |   0.055363  |    0.013907     |   2\n",
      "      12619 |   0.203625  |    0.027691     |   0\n",
      "      12620 |   0.027313  |    0.020830     |   2\n",
      "      12621 |   0.218555  |    0.028485     |   0\n",
      "      12622 | \u001b[94m  0.000054\u001b[0m  |    0.018765     |   2\n",
      "      12623 |   0.008060  |    0.045104     |   2\n",
      "      12624 |   0.082460  |    0.009445     |   2\n",
      "      12625 |   0.175708  |    0.046725     |   0\n",
      "      12626 |   0.041214  |    0.012810     |   2\n",
      "      12627 |   0.193676  |    0.150764     |   1\n",
      "      12628 |   0.212558  |    0.062129     |   1\n",
      "      12629 |   0.351151  |    0.078237     |   1\n",
      "      12630 |   0.246656  |    0.095962     |   1\n",
      "      12631 |   0.062189  |    0.008084     |   2\n",
      "      12632 |   0.175787  |    0.045728     |   0\n",
      "      12633 |   0.203909  |    0.090587     |   1\n",
      "      12634 |   0.054207  |    0.007914     |   2\n",
      "      12635 |   0.191568  |    0.049185     |   0\n",
      "      12636 |   0.191735  |    0.009249     |   0\n",
      "      12637 |   0.291586  |    0.044654     |   0\n",
      "      12638 |   0.023129  |    0.018008     |   2\n",
      "      12639 |   0.237599  |    0.034918     |   0\n",
      "      12640 |   0.228781  |    0.147902     |   1\n",
      "      12641 |   0.048317  |    0.013554     |   2\n",
      "      12642 |   0.188040  |    0.012947     |   0\n",
      "      12643 |   0.171377  |    0.014177     |   0\n",
      "      12644 |   0.254579  |    0.143678     |   1\n",
      "      12645 |   0.170230  |    0.002927     |   0\n",
      "      12646 |   0.039154  |    0.005021     |   2\n",
      "      12647 |   0.192058  |    0.054700     |   0\n",
      "      12648 |   0.293808  |    0.134883     |   1\n",
      "      12649 |   0.224313  |    0.003045     |   0\n",
      "      12650 | \u001b[94m  0.000053\u001b[0m  |    0.005685     |   2\n",
      "      12651 |   0.000053  |    0.037591     |   2\n",
      "      12652 |   0.000053  |    0.028041     |   2\n",
      "      12653 |   0.170716  |    0.145630     |   1\n",
      "      12654 |   0.237265  |    0.094426     |   1\n",
      "      12655 |   0.208623  |    0.086297     |   1\n",
      "      12656 |   0.176951  |    0.015126     |   0\n",
      "      12657 |   0.305433  |    0.136267     |   1\n",
      "      12658 |   0.000054  |    0.005870     |   2\n",
      "      12659 |   0.228464  |    0.092218     |   1\n",
      "      12660 |   0.000053  |    0.011189     |   2\n",
      "      12661 |   0.176767  |    0.043415     |   0\n",
      "      12662 |   0.213304  |    0.101293     |   1\n",
      "      12663 |   0.249448  |    0.100979     |   1\n",
      "      12664 |   0.000053  |    0.006118     |   2\n",
      "      12665 |   0.198420  |    0.131582     |   1\n",
      "      12666 |   0.219927  |    0.002971     |   0\n",
      "      12667 |   0.197207  |    0.005250     |   0\n",
      "      12668 |   0.202209  |    0.050936     |   0\n",
      "      12669 |   0.170482  |    0.149183     |   1\n",
      "      12670 |   0.171663  |    0.082525     |   1\n",
      "      12671 |   0.197016  |    0.004971     |   0\n",
      "      12672 |   0.058936  |    0.030914     |   2\n",
      "      12673 |   0.055921  |    0.028179     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 12674: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      12674 |   0.060582  |    0.020603     |   2\n",
      "      12675 |   0.046403  |    0.024554     |   2\n",
      "      12676 |   0.198589  |    0.038765     |   0\n",
      "      12677 |   0.185476  |    0.014269     |   0\n",
      "      12678 |   0.180834  |    0.029319     |   0\n",
      "      12679 |   0.227793  |    0.141746     |   1\n",
      "      12680 |   0.180354  |    0.086678     |   1\n",
      "      12681 |   0.047537  |    0.006726     |   2\n",
      "      12682 |   0.241621  |    0.101898     |   1\n",
      "      12683 |   0.055575  |    0.011005     |   2\n",
      "      12684 |   0.151715  |    0.160706     |   1\n",
      "      12685 |   0.194059  |    0.007498     |   0\n",
      "      12686 |   0.208962  |    0.081876     |   1\n",
      "      12687 |   0.032397  |    0.011586     |   2\n",
      "      12688 |   0.219457  |    0.142523     |   1\n",
      "      12689 |   0.187091  |    0.084990     |   1\n",
      "      12690 |   0.153942  |    0.006956     |   0\n",
      "      12691 |   0.047008  |    0.017731     |   2\n",
      "      12692 |   0.057423  |    0.025725     |   2\n",
      "      12693 |   0.066205  |    0.034477     |   2\n",
      "      12694 |   0.055156  |    0.023361     |   2\n",
      "      12695 |   0.027259  |    0.030270     |   2\n",
      "      12696 |   0.145773  |    0.128149     |   1\n",
      "      12697 |   0.000054  |    0.006393     |   2\n",
      "      12698 |   0.211987  |    0.133149     |   1\n",
      "      12699 |   0.197331  |    0.007778     |   0\n",
      "      12700 |   0.252811  |    0.026442     |   0\n",
      "      12701 |   0.218267  |    0.038665     |   0\n",
      "      12702 |   0.221696  |    0.020574     |   0\n",
      "      12703 |   0.007538  |    0.023909     |   2\n",
      "      12704 |   0.188087  |    0.045574     |   0\n",
      "      12705 |   0.216603  |    0.089075     |   1\n",
      "      12706 |   0.175263  |    0.084923     |   1\n",
      "      12707 |   0.079715  |    0.009906     |   2\n",
      "      12708 |   0.040775  |    0.026003     |   2\n",
      "      12709 |   0.167331  |    0.040379     |   0\n",
      "      12710 |   0.198724  |    0.012909     |   0\n",
      "      12711 |   0.061817  |    0.039239     |   2\n",
      "      12712 |   0.054724  |    0.005976     |   2\n",
      "      12713 |   0.023284  |    0.049420     |   2\n",
      "      12714 |   0.207433  |    0.008516     |   0\n",
      "      12715 |   0.136637  |    0.045408     |   0\n",
      "      12716 |   0.177076  |    0.022759     |   0\n",
      "      12717 |   0.166471  |    0.108467     |   1\n",
      "      12718 |   0.211526  |    0.089762     |   1\n",
      "      12719 |   0.196945  |    0.077946     |   1\n",
      "      12720 |   0.254994  |    0.104566     |   1\n",
      "      12721 |   0.193384  |    0.080168     |   1\n",
      "      12722 |   0.048471  |    0.005773     |   2\n",
      "      12723 |   0.036177  |    0.061649     |   2\n",
      "      12724 |   0.202613  |    0.048449     |   1\n",
      "      12725 |   0.000053  |    0.011079     |   2\n",
      "      12726 |   0.178734  |    0.141542     |   1\n",
      "      12727 |   0.214136  |    0.009490     |   0\n",
      "      12728 |   0.150914  |    0.013217     |   0\n",
      "      12729 |   0.184326  |    0.137159     |   1\n",
      "      12730 |   0.000053  |    0.004366     |   2\n",
      "      12731 |   0.276878  |    0.029808     |   0\n",
      "      12732 |   0.000053  |    0.034789     |   2\n",
      "      12733 |   0.228402  |    0.023591     |   0\n",
      "      12734 |   0.258681  |    0.110840     |   1\n",
      "      12735 |   0.299919  |    0.090183     |   1\n",
      "      12736 |   0.203646  |    0.040562     |   0\n",
      "      12737 |   0.236838  |    0.017723     |   0\n",
      "      12738 |   0.294838  |    0.048948     |   0\n",
      "      12739 |   0.000054  |    0.007045     |   2\n",
      "      12740 |   0.000053  |    0.047222     |   2\n",
      "      12741 |   0.258551  |    0.105043     |   1\n",
      "      12742 |   0.252267  |    0.093913     |   1\n",
      "      12743 |   0.204715  |    0.104249     |   1\n",
      "      12744 |   0.233705  |    0.069151     |   1\n",
      "      12745 |   0.256084  |    0.102312     |   1\n",
      "      12746 |   0.238294  |    0.088349     |   1\n",
      "      12747 |   0.195104  |    0.012503     |   0\n",
      "      12748 |   0.203835  |    0.038027     |   0\n",
      "      12749 |   0.231574  |    0.133302     |   1\n",
      "      12750 |   0.179760  |    0.012411     |   0\n",
      "      12751 |   0.244835  |    0.087658     |   1\n",
      "      12752 |   0.000053  |    0.007586     |   2\n",
      "      12753 |   0.060649  |    0.018105     |   2\n",
      "      12754 |   0.057263  |    0.036473     |   2\n",
      "      12755 |   0.253367  |    0.150518     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 12757: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      12756 |   0.290506  |    0.002937     |   0\n",
      "      12757 |   0.057267  |    0.006496     |   2\n",
      "      12758 |   0.042316  |    0.051127     |   2\n",
      "      12759 |   0.239199  |    0.017743     |   0\n",
      "      12760 |   0.212805  |    0.044117     |   0\n",
      "      12761 |   0.046590  |    0.006123     |   2\n",
      "      12762 |   0.058001  |    0.043769     |   2\n",
      "      12763 |   0.212683  |    0.087737     |   1\n",
      "      12764 |   0.179316  |    0.018796     |   0\n",
      "      12765 |   0.031282  |    0.037193     |   2\n",
      "      12766 |   0.282237  |    0.015301     |   0\n",
      "      12767 |   0.211291  |    0.139226     |   1\n",
      "      12768 |   0.047926  |    0.005045     |   2\n",
      "      12769 |   0.214360  |    0.021196     |   0\n",
      "      12770 |   0.057273  |    0.030419     |   2\n",
      "      12771 |   0.180101  |    0.063454     |   0\n",
      "      12772 |   0.183379  |    0.050419     |   1\n",
      "      12773 |   0.253880  |    0.036331     |   0\n",
      "      12774 |   0.064696  |    0.026073     |   2\n",
      "      12775 |   0.050722  |    0.034483     |   2\n",
      "      12776 |   0.027355  |    0.028554     |   2\n",
      "      12777 |   0.232628  |    0.092649     |   1\n",
      "      12778 |   0.271925  |    0.054790     |   1\n",
      "      12779 |   0.301659  |    0.114474     |   1\n",
      "      12780 |   0.155488  |    0.138167     |   1\n",
      "      12781 |   0.160397  |    0.015298     |   0\n",
      "      12782 |   0.259685  |    0.078836     |   1\n",
      "      12783 |   0.212244  |    0.028426     |   0\n",
      "      12784 |   0.238115  |    0.139947     |   1\n",
      "      12785 |   0.241017  |    0.062501     |   1\n",
      "      12786 |   0.203525  |    0.020367     |   0\n",
      "      12787 | \u001b[94m  0.000053\u001b[0m  |    0.047329     |   2\n",
      "      12788 |   0.243915  |    0.011219     |   0\n",
      "      12789 |   0.007093  |    0.045597     |   2\n",
      "      12790 |   0.249219  |    0.087824     |   1\n",
      "      12791 |   0.080194  |    0.007126     |   2\n",
      "      12792 |   0.213715  |    0.147020     |   1\n",
      "      12793 |   0.042703  |    0.008167     |   2\n",
      "      12794 |   0.300327  |    0.087653     |   1\n",
      "      12795 |   0.062069  |    0.006749     |   2\n",
      "      12796 |   0.210903  |    0.028289     |   0\n",
      "      12797 |   0.239624  |    0.039000     |   0\n",
      "      12798 |   0.213499  |    0.154904     |   1\n",
      "      12799 |   0.184227  |    0.011847     |   0\n",
      "      12800 |   0.197629  |    0.045105     |   1\n",
      "      12801 |   0.223647  |    0.169303     |   1\n",
      "      12802 |   0.255144  |    0.008831     |   0\n",
      "      12803 |   0.223505  |    0.082435     |   1\n",
      "      12804 |   0.285964  |    0.057778     |   1\n",
      "      12805 |   0.229454  |    0.090304     |   1\n",
      "      12806 |   0.053298  |    0.018354     |   2\n",
      "      12807 |   0.024218  |    0.046413     |   2\n",
      "      12808 |   0.048564  |    0.009836     |   2\n",
      "      12809 |   0.194251  |    0.153861     |   1\n",
      "      12810 |   0.201976  |    0.059481     |   1\n",
      "      12811 |   0.179980  |    0.042961     |   0\n",
      "      12812 |   0.235408  |    0.085650     |   1\n",
      "      12813 |   0.038517  |    0.015013     |   2\n",
      "      12814 |   0.000053  |    0.030542     |   2\n",
      "      12815 |   0.211510  |    0.050967     |   1\n",
      "      12816 |   0.179452  |    0.021301     |   0\n",
      "      12817 |   0.000053  |    0.041496     |   2\n",
      "      12818 |   0.230828  |    0.147427     |   1\n",
      "      12819 |   0.245471  |    0.021138     |   0\n",
      "      12820 |   0.244877  |    0.059447     |   1\n",
      "      12821 |   0.197004  |    0.028073     |   0\n",
      "      12822 |   0.000053  |    0.021871     |   2\n",
      "      12823 |   0.201395  |    0.120784     |   1\n",
      "      12824 |   0.176036  |    0.045808     |   1\n",
      "      12825 |   0.210404  |    0.081825     |   1\n",
      "      12826 |   0.211476  |    0.012740     |   0\n",
      "      12827 |   0.258176  |    0.040096     |   0\n",
      "      12828 |   0.214512  |    0.016458     |   0\n",
      "      12829 |   0.233654  |    0.105016     |   1\n",
      "      12830 |   0.214021  |    0.080266     |   1\n",
      "      12831 |   0.180406  |    0.015620     |   0\n",
      "      12832 |   0.000053  |    0.051211     |   2\n",
      "      12833 |   0.184744  |    0.106223     |   1\n",
      "      12834 |   0.289685  |    0.081521     |   1\n",
      "      12835 | \u001b[94m  0.000053\u001b[0m  |    0.006659     |   2\n",
      "      12836 |   0.225137  |    0.121979     |   1\n",
      "      12837 | \u001b[94m  0.000053\u001b[0m  |    0.008081     |   2\n",
      "      12838 |   0.206642  |    0.046437     |   0\n",
      "      12839 |   0.061364  |    0.015566     |   2\n",
      "      12840 |   0.056332  |    0.026439     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 12842: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      12841 |   0.177020  |    0.030986     |   0\n",
      "      12842 |   0.059302  |    0.020840     |   2\n",
      "      12843 |   0.043971  |    0.043215     |   2\n",
      "      12844 |   0.045032  |    0.011510     |   2\n",
      "      12845 |   0.224058  |    0.029212     |   0\n",
      "      12846 |   0.315858  |    0.092045     |   1\n",
      "      12847 |   0.059224  |    0.017620     |   2\n",
      "      12848 |   0.194653  |    0.026541     |   0\n",
      "      12849 |   0.032724  |    0.026050     |   2\n",
      "      12850 |   0.296120  |    0.039671     |   0\n",
      "      12851 |   0.219673  |    0.083715     |   1\n",
      "      12852 |   0.260100  |    0.030012     |   0\n",
      "      12853 |   0.152693  |    0.147861     |   1\n",
      "      12854 |   0.046498  |    0.011731     |   2\n",
      "      12855 |   0.196771  |    0.052833     |   1\n",
      "      12856 |   0.152954  |    0.043313     |   0\n",
      "      12857 |   0.281707  |    0.089431     |   1\n",
      "      12858 |   0.056848  |    0.026004     |   2\n",
      "      12859 |   0.193183  |    0.038409     |   0\n",
      "      12860 |   0.275197  |    0.089125     |   1\n",
      "      12861 |   0.201909  |    0.006599     |   0\n",
      "      12862 |   0.205213  |    0.024030     |   0\n",
      "      12863 |   0.169557  |    0.026691     |   0\n",
      "      12864 |   0.063995  |    0.048287     |   2\n",
      "      12865 |   0.168242  |    0.051602     |   1\n",
      "      12866 |   0.275112  |    0.127799     |   1\n",
      "      12867 |   0.215310  |    0.082915     |   1\n",
      "      12868 |   0.152779  |    0.016862     |   0\n",
      "      12869 |   0.156711  |    0.017717     |   0\n",
      "      12870 |   0.052581  |    0.034410     |   2\n",
      "      12871 |   0.026059  |    0.021951     |   2\n",
      "      12872 | \u001b[94m  0.000052\u001b[0m  |    0.050068     |   2\n",
      "      12873 |   0.210798  |    0.012423     |   0\n",
      "      12874 |   0.196328  |    0.046145     |   0\n",
      "      12875 |   0.227887  |    0.101289     |   1\n",
      "      12876 |   0.168381  |    0.061187     |   1\n",
      "      12877 |   0.246780  |    0.035726     |   0\n",
      "      12878 |   0.181541  |    0.134921     |   1\n",
      "      12879 |   0.198042  |    0.078825     |   1\n",
      "      12880 |   0.006216  |    0.011763     |   2\n",
      "      12881 |   0.247118  |    0.100261     |   1\n",
      "      12882 |   0.084617  |    0.018639     |   2\n",
      "      12883 |   0.040459  |    0.067041     |   2\n",
      "      12884 |   0.209367  |    0.088019     |   1\n",
      "      12885 |   0.067187  |    0.006688     |   2\n",
      "      12886 |   0.050345  |    0.058875     |   2\n",
      "      12887 |   0.180930  |    0.047369     |   1\n",
      "      12888 |   0.021138  |    0.004840     |   2\n",
      "      12889 |   0.046637  |    0.047829     |   2\n",
      "      12890 |   0.208776  |    0.139423     |   1\n",
      "      12891 |   0.201527  |    0.002883     |   0\n",
      "      12892 |   0.037434  |    0.007540     |   2\n",
      "      12893 |   0.188552  |    0.028485     |   0\n",
      "      12894 |   0.268371  |    0.049419     |   0\n",
      "      12895 |   0.262439  |    0.105613     |   1\n",
      "      12896 |   0.299605  |    0.059729     |   1\n",
      "      12897 |   0.291795  |    0.138750     |   1\n",
      "      12898 |   0.201354  |    0.061433     |   1\n",
      "      12899 | \u001b[94m  0.000052\u001b[0m  |    0.011051     |   2\n",
      "      12900 |   0.000052  |    0.040164     |   2\n",
      "      12901 |   0.248563  |    0.022315     |   0\n",
      "      12902 |   0.202855  |    0.096175     |   1\n",
      "      12903 | \u001b[94m  0.000052\u001b[0m  |    0.027038     |   2\n",
      "      12904 |   0.286856  |    0.026172     |   0\n",
      "      12905 |   0.244316  |    0.043317     |   0\n",
      "      12906 |   0.177524  |    0.109509     |   1\n",
      "      12907 |   0.152157  |    0.141983     |   1\n",
      "      12908 |   0.192772  |    0.007314     |   0\n",
      "      12909 |   0.213893  |    0.110914     |   1\n",
      "      12910 |   0.191279  |    0.063659     |   1\n",
      "      12911 |   0.000053  |    0.015813     |   2\n",
      "      12912 |   0.247449  |    0.036271     |   0\n",
      "      12913 |   0.224021  |    0.105350     |   1\n",
      "      12914 |   0.183446  |    0.107961     |   1\n",
      "      12915 | \u001b[94m  0.000052\u001b[0m  |    0.005343     |   2\n",
      "      12916 | \u001b[94m  0.000051\u001b[0m  |    0.047615     |   2\n",
      "      12917 |   0.058605  |    0.011055     |   2\n",
      "      12918 |   0.055709  |    0.041228     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 12920: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      12919 |   0.250003  |    0.017028     |   0\n",
      "      12920 |   0.250939  |    0.027360     |   0\n",
      "      12921 |   0.182785  |    0.043739     |   0\n",
      "      12922 |   0.231189  |    0.099316     |   1\n",
      "      12923 |   0.062661  |    0.005879     |   2\n",
      "      12924 |   0.204284  |    0.049583     |   0\n",
      "      12925 |   0.190355  |    0.078215     |   1\n",
      "      12926 |   0.249727  |    0.006559     |   0\n",
      "      12927 |   0.213599  |    0.028182     |   0\n",
      "      12928 |   0.047629  |    0.023344     |   2\n",
      "      12929 |   0.045067  |    0.052157     |   2\n",
      "      12930 |   0.167150  |    0.016001     |   0\n",
      "      12931 |   0.232001  |    0.096002     |   1\n",
      "      12932 |   0.058120  |    0.023664     |   2\n",
      "      12933 |   0.217947  |    0.138889     |   1\n",
      "      12934 |   0.166231  |    0.006490     |   0\n",
      "      12935 |   0.179580  |    0.009484     |   0\n",
      "      12936 |   0.206967  |    0.038587     |   0\n",
      "      12937 |   0.305268  |    0.093616     |   1\n",
      "      12938 |   0.167505  |    0.022922     |   0\n",
      "      12939 |   0.244530  |    0.094054     |   1\n",
      "      12940 |   0.170911  |    0.017086     |   0\n",
      "      12941 |   0.248544  |    0.144367     |   1\n",
      "      12942 |   0.033879  |    0.003512     |   2\n",
      "      12943 |   0.045182  |    0.006574     |   2\n",
      "      12944 |   0.220018  |    0.035615     |   0\n",
      "      12945 |   0.216695  |    0.127210     |   1\n",
      "      12946 |   0.191581  |    0.034537     |   0\n",
      "      12947 |   0.300239  |    0.090252     |   1\n",
      "      12948 |   0.321461  |    0.029189     |   0\n",
      "      12949 |   0.293152  |    0.155739     |   1\n",
      "      12950 |   0.191778  |    0.008434     |   0\n",
      "      12951 |   0.184756  |    0.007608     |   0\n",
      "      12952 |   0.206355  |    0.031173     |   0\n",
      "      12953 |   0.196322  |    0.102275     |   1\n",
      "      12954 |   0.314080  |    0.085652     |   1\n",
      "      12955 |   0.247779  |    0.013896     |   0\n",
      "      12956 |   0.056950  |    0.030271     |   2\n",
      "      12957 |   0.066234  |    0.043148     |   2\n",
      "      12958 |   0.224523  |    0.155511     |   1\n",
      "      12959 |   0.054320  |    0.005615     |   2\n",
      "      12960 |   0.210545  |    0.010283     |   0\n",
      "      12961 |   0.026393  |    0.033845     |   2\n",
      "      12962 |   0.000052  |    0.010581     |   2\n",
      "      12963 |   0.165981  |    0.159274     |   1\n",
      "      12964 |   0.207206  |    0.079058     |   1\n",
      "      12965 |   0.207474  |    0.103424     |   1\n",
      "      12966 |   0.233215  |    0.062635     |   1\n",
      "      12967 |   0.007436  |    0.010642     |   2\n",
      "      12968 |   0.182266  |    0.030156     |   0\n",
      "      12969 |   0.186529  |    0.031100     |   0\n",
      "      12970 |   0.164012  |    0.034524     |   0\n",
      "      12971 |   0.215126  |    0.027786     |   0\n",
      "      12972 |   0.200929  |    0.051714     |   0\n",
      "      12973 |   0.217603  |    0.076610     |   1\n",
      "      12974 |   0.083503  |    0.005551     |   2\n",
      "      12975 |   0.041008  |    0.048872     |   2\n",
      "      12976 |   0.062302  |    0.010494     |   2\n",
      "      12977 |   0.207847  |    0.043297     |   0\n",
      "      12978 |   0.054529  |    0.020285     |   2\n",
      "      12979 |   0.287066  |    0.110482     |   1\n",
      "      12980 |   0.287580  |    0.012189     |   0\n",
      "      12981 |   0.233436  |    0.127141     |   1\n",
      "      12982 |   0.184164  |    0.020092     |   0\n",
      "      12983 |   0.158028  |    0.035635     |   0\n",
      "      12984 |   0.242125  |    0.026676     |   0\n",
      "      12985 |   0.185998  |    0.033629     |   0\n",
      "      12986 |   0.183274  |    0.140136     |   1\n",
      "      12987 |   0.024194  |    0.012149     |   2\n",
      "      12988 |   0.224707  |    0.086748     |   1\n",
      "      12989 |   0.046594  |    0.013674     |   2\n",
      "      12990 |   0.195086  |    0.025151     |   0\n",
      "      12991 |   0.185536  |    0.042571     |   0\n",
      "      12992 |   0.189233  |    0.096082     |   1\n",
      "      12993 |   0.226994  |    0.099945     |   1\n",
      "      12994 |   0.038753  |    0.012778     |   2\n",
      "      12995 |   0.000052  |    0.035867     |   2\n",
      "      12996 |   0.338290  |    0.159033     |   1\n",
      "      12997 |   0.161871  |    0.041953     |   1\n",
      "      12998 |   0.201685  |    0.091661     |   1\n",
      "      12999 |   0.211824  |    0.007497     |   0\n",
      "      13000 |   0.210913  |    0.045910     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 13000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 13000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      13001 |   0.060070  |    0.051778     |   2\n",
      "      13002 |   0.043059  |    0.028958     |   2\n",
      "      13003 |   0.245964  |    0.149055     |   1\n",
      "      13004 |   0.252333  |    0.048660     |   1\n",
      "      13005 |   0.222885  |    0.029191     |   0\n",
      "      13006 |   0.046385  |    0.031874     |   2\n",
      "      13007 |   0.057722  |    0.019928     |   2\n",
      "      13008 |   0.245974  |    0.047251     |   0\n",
      "      13009 |   0.031369  |    0.010036     |   2\n",
      "      13010 |   0.045544  |    0.042957     |   2\n",
      "      13011 |   0.182386  |    0.016078     |   0\n",
      "      13012 |   0.055676  |    0.029934     |   2\n",
      "      13013 |   0.210057  |    0.023606     |   0\n",
      "      13014 |   0.065907  |    0.017259     |   2\n",
      "      13015 |   0.267850  |    0.161322     |   1\n",
      "      13016 |   0.255126  |    0.011307     |   0\n",
      "      13017 |   0.220420  |    0.067760     |   1\n",
      "      13018 |   0.233727  |    0.016890     |   0\n",
      "      13019 |   0.235717  |    0.115791     |   1\n",
      "      13020 |   0.216579  |    0.112865     |   1\n",
      "      13021 |   0.199774  |    0.089202     |   1\n",
      "      13022 |   0.198421  |    0.006280     |   0\n",
      "      13023 |   0.053070  |    0.008361     |   2\n",
      "      13024 |   0.176973  |    0.166185     |   1\n",
      "      13025 |   0.025904  |    0.007111     |   2\n",
      "      13026 |   0.246091  |    0.109010     |   1\n",
      "      13027 |   0.193102  |    0.050403     |   1\n",
      "      13028 |   0.230922  |    0.027484     |   0\n",
      "      13029 | \u001b[94m  0.000051\u001b[0m  |    0.027322     |   2\n",
      "      13030 |   0.168610  |    0.031329     |   0\n",
      "      13031 |   0.007524  |    0.023570     |   2\n",
      "      13032 |   0.195294  |    0.027000     |   0\n",
      "      13033 |   0.078544  |    0.024676     |   2\n",
      "      13034 |   0.152534  |    0.023234     |   0\n",
      "      13035 |   0.198239  |    0.133161     |   1\n",
      "      13036 |   0.214322  |    0.008071     |   0\n",
      "      13037 |   0.038863  |    0.024010     |   2\n",
      "      13038 |   0.247008  |    0.044502     |   0\n",
      "      13039 |   0.243881  |    0.081780     |   1\n",
      "      13040 |   0.170338  |    0.014903     |   0\n",
      "      13041 |   0.285155  |    0.152307     |   1\n",
      "      13042 |   0.064275  |    0.002886     |   2\n",
      "      13043 |   0.181617  |    0.006055     |   0\n",
      "      13044 |   0.161870  |    0.144611     |   1\n",
      "      13045 |   0.244922  |    0.004407     |   0\n",
      "      13046 |   0.168686  |    0.099183     |   1\n",
      "      13047 |   0.058585  |    0.007413     |   2\n",
      "      13048 |   0.219351  |    0.129061     |   1\n",
      "      13049 |   0.023002  |    0.008416     |   2\n",
      "      13050 |   0.047721  |    0.034346     |   2\n",
      "      13051 |   0.249951  |    0.026538     |   0\n",
      "      13052 |   0.232094  |    0.043746     |   0\n",
      "      13053 |   0.220807  |    0.034637     |   0\n",
      "      13054 |   0.224162  |    0.082702     |   1\n",
      "      13055 |   0.238008  |    0.007812     |   0\n",
      "      13056 |   0.035643  |    0.036957     |   2\n",
      "      13057 |   0.275244  |    0.097484     |   1\n",
      "      13058 |   0.335725  |    0.083185     |   1\n",
      "      13059 |   0.180638  |    0.016054     |   0\n",
      "      13060 |   0.185143  |    0.138709     |   1\n",
      "      13061 | \u001b[94m  0.000051\u001b[0m  |    0.008597     |   2\n",
      "      13062 |   0.197144  |    0.018604     |   0\n",
      "      13063 |   0.000051  |    0.039623     |   2\n",
      "      13064 |   0.296706  |    0.085984     |   1\n",
      "      13065 |   0.231428  |    0.009346     |   0\n",
      "      13066 |   0.168960  |    0.189634     |   1\n",
      "      13067 |   0.217765  |    0.081690     |   1\n",
      "      13068 |   0.178190  |    0.086656     |   1\n",
      "      13069 |   0.216640  |    0.111639     |   1\n",
      "      13070 |   0.223458  |    0.044643     |   1\n",
      "      13071 |   0.000051  |    0.010714     |   2\n",
      "      13072 |   0.233110  |    0.039768     |   0\n",
      "      13073 |   0.000051  |    0.013315     |   2\n",
      "      13074 |   0.000051  |    0.041681     |   2\n",
      "      13075 |   0.143298  |    0.124820     |   1\n",
      "      13076 |   0.228349  |    0.036482     |   1\n",
      "      13077 |   0.203598  |    0.028999     |   0\n",
      "      13078 |   0.215503  |    0.034163     |   0\n",
      "      13079 |   0.189048  |    0.133825     |   1\n",
      "      13080 |   0.197396  |    0.049492     |   1\n",
      "      13081 |   0.211812  |    0.038029     |   0\n",
      "      13082 | \u001b[94m  0.000050\u001b[0m  |    0.022289     |   2\n",
      "      13083 |   0.255148  |    0.024104     |   0\n",
      "      13084 |   0.210979  |    0.041217     |   0\n",
      "      13085 |   0.057727  |    0.027187     |   2\n",
      "      13086 |   0.187301  |    0.140186     |   1\n",
      "      13087 |   0.246340  |    0.055897     |   1\n",
      "      13088 |   0.225151  |    0.089182     |   1\n",
      "      13089 |   0.181515  |    0.101978     |   1\n",
      "      13090 |   0.188764  |    0.124688     |   1\n",
      "      13091 |   0.141369  |    0.078472     |   1\n",
      "      13092 |   0.214923  |    0.013537     |   0\n",
      "      13093 |   0.231842  |    0.038108     |   0\n",
      "      13094 |   0.198386  |    0.036514     |   0\n",
      "      13095 |   0.196777  |    0.140816     |   1\n",
      "      13096 |   0.211672  |    0.003034     |   0\n",
      "      13097 |   0.225851  |    0.022217     |   0\n",
      "      13098 |   0.217971  |    0.095783     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 13100: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      13099 |   0.055547  |    0.018774     |   2\n",
      "      13100 |   0.158651  |    0.154141     |   1\n",
      "      13101 |   0.066426  |    0.009799     |   2\n",
      "      13102 |   0.225668  |    0.059230     |   1\n",
      "      13103 |   0.047005  |    0.017052     |   2\n",
      "      13104 |   0.256626  |    0.106106     |   1\n",
      "      13105 |   0.046196  |    0.012149     |   2\n",
      "      13106 |   0.161751  |    0.043859     |   0\n",
      "      13107 |   0.194566  |    0.007848     |   0\n",
      "      13108 |   0.261999  |    0.048652     |   0\n",
      "      13109 |   0.197560  |    0.018655     |   0\n",
      "      13110 |   0.184298  |    0.143793     |   1\n",
      "      13111 |   0.190318  |    0.003789     |   0\n",
      "      13112 |   0.061774  |    0.016412     |   2\n",
      "      13113 |   0.032275  |    0.060687     |   2\n",
      "      13114 |   0.374486  |    0.055625     |   1\n",
      "      13115 |   0.181716  |    0.029889     |   0\n",
      "      13116 |   0.194039  |    0.139732     |   1\n",
      "      13117 |   0.145259  |    0.003030     |   0\n",
      "      13118 |   0.045715  |    0.007923     |   2\n",
      "      13119 |   0.058552  |    0.035855     |   2\n",
      "      13120 |   0.065620  |    0.010011     |   2\n",
      "      13121 |   0.220589  |    0.048453     |   0\n",
      "      13122 |   0.249168  |    0.101850     |   1\n",
      "      13123 |   0.197348  |    0.119561     |   1\n",
      "      13124 |   0.274770  |    0.071949     |   1\n",
      "      13125 |   0.238929  |    0.006048     |   0\n",
      "      13126 |   0.208744  |    0.024509     |   0\n",
      "      13127 |   0.054453  |    0.028922     |   2\n",
      "      13128 |   0.254826  |    0.141058     |   1\n",
      "      13129 |   0.155915  |    0.003087     |   0\n",
      "      13130 |   0.025362  |    0.038280     |   2\n",
      "      13131 |   0.191329  |    0.083810     |   1\n",
      "      13132 |   0.000051  |    0.010452     |   2\n",
      "      13133 |   0.248785  |    0.145451     |   1\n",
      "      13134 |   0.256439  |    0.060572     |   1\n",
      "      13135 |   0.157836  |    0.027709     |   0\n",
      "      13136 |   0.228338  |    0.027309     |   0\n",
      "      13137 |   0.006325  |    0.028934     |   2\n",
      "      13138 |   0.168656  |    0.133532     |   1\n",
      "      13139 |   0.207431  |    0.007983     |   0\n",
      "      13140 |   0.080116  |    0.012477     |   2\n",
      "      13141 |   0.039748  |    0.031288     |   2\n",
      "      13142 |   0.252216  |    0.023641     |   0\n",
      "      13143 |   0.174446  |    0.045989     |   0\n",
      "      13144 |   0.064327  |    0.010329     |   2\n",
      "      13145 |   0.053161  |    0.029841     |   2\n",
      "      13146 |   0.253043  |    0.046204     |   0\n",
      "      13147 |   0.023036  |    0.015967     |   2\n",
      "      13148 |   0.160036  |    0.134417     |   1\n",
      "      13149 |   0.048011  |    0.009337     |   2\n",
      "      13150 |   0.185720  |    0.028399     |   0\n",
      "      13151 |   0.234501  |    0.031254     |   0\n",
      "      13152 |   0.158335  |    0.025375     |   0\n",
      "      13153 |   0.158029  |    0.130731     |   1\n",
      "      13154 |   0.035241  |    0.011711     |   2\n",
      "      13155 |   0.219085  |    0.147061     |   1\n",
      "      13156 |   0.170400  |    0.002861     |   0\n",
      "      13157 |   0.000050  |    0.009550     |   2\n",
      "      13158 |   0.230853  |    0.139229     |   1\n",
      "      13159 |   0.157030  |    0.006634     |   0\n",
      "      13160 |   0.000051  |    0.007148     |   2\n",
      "      13161 |   0.000051  |    0.048149     |   2\n",
      "      13162 |   0.193202  |    0.019934     |   0\n",
      "      13163 |   0.225671  |    0.088979     |   1\n",
      "      13164 |   0.214993  |    0.029371     |   0\n",
      "      13165 |   0.000051  |    0.024325     |   2\n",
      "      13166 |   0.168365  |    0.029934     |   0\n",
      "      13167 |   0.309890  |    0.144106     |   1\n",
      "      13168 |   0.177069  |    0.080919     |   1\n",
      "      13169 |   0.224098  |    0.009449     |   0\n",
      "      13170 |   0.199357  |    0.027307     |   0\n",
      "      13171 |   0.208581  |    0.038240     |   0\n",
      "      13172 |   0.000051  |    0.027377     |   2\n",
      "      13173 |   0.239872  |    0.144555     |   1\n",
      "      13174 |   0.196938  |    0.009415     |   0\n",
      "      13175 |   0.262511  |    0.087626     |   1\n",
      "      13176 |   0.273959  |    0.057347     |   1\n",
      "      13177 |   0.208891  |    0.107833     |   1\n",
      "      13178 |   0.237670  |    0.104661     |   1\n",
      "      13179 |   0.243847  |    0.068699     |   1\n",
      "      13180 |   0.220778  |    0.094108     |   1\n",
      "      13181 |   0.232021  |    0.077855     |   1\n",
      "      13182 |   0.000051  |    0.010762     |   2\n",
      "      13183 |   0.058969  |    0.049993     |   2\n",
      "      13184 |   0.168925  |    0.088681     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 13186: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      13185 |   0.055520  |    0.007512     |   2\n",
      "      13186 |   0.225017  |    0.059197     |   0\n",
      "      13187 |   0.268244  |    0.091408     |   1\n",
      "      13188 |   0.060643  |    0.008421     |   2\n",
      "      13189 |   0.215291  |    0.096156     |   1\n",
      "      13190 |   0.044278  |    0.019037     |   2\n",
      "      13191 |   0.044743  |    0.024900     |   2\n",
      "      13192 |   0.229694  |    0.041205     |   0\n",
      "      13193 |   0.250786  |    0.105491     |   1\n",
      "      13194 |   0.219495  |    0.084221     |   1\n",
      "      13195 |   0.239376  |    0.033423     |   0\n",
      "      13196 |   0.058043  |    0.038436     |   2\n",
      "      13197 |   0.201509  |    0.082773     |   1\n",
      "      13198 |   0.210748  |    0.019281     |   0\n",
      "      13199 |   0.031173  |    0.030815     |   2\n",
      "      13200 |   0.045484  |    0.011775     |   2\n",
      "      13201 |   0.057919  |    0.043816     |   2\n",
      "      13202 |   0.259090  |    0.012523     |   0\n",
      "      13203 |   0.224156  |    0.052295     |   0\n",
      "      13204 |   0.220308  |    0.118531     |   1\n",
      "      13205 |   0.250677  |    0.056689     |   1\n",
      "      13206 |   0.196548  |    0.030229     |   0\n",
      "      13207 |   0.063662  |    0.036426     |   2\n",
      "      13208 |   0.053045  |    0.008409     |   2\n",
      "      13209 |   0.220945  |    0.111725     |   1\n",
      "      13210 |   0.206855  |    0.011380     |   0\n",
      "      13211 |   0.024692  |    0.034089     |   2\n",
      "      13212 |   0.000050  |    0.017421     |   2\n",
      "      13213 |   0.158441  |    0.141982     |   1\n",
      "      13214 |   0.226566  |    0.022347     |   0\n",
      "      13215 |   0.261227  |    0.068389     |   1\n",
      "      13216 |   0.171153  |    0.092390     |   1\n",
      "      13217 |   0.158775  |    0.015625     |   0\n",
      "      13218 |   0.007195  |    0.051922     |   2\n",
      "      13219 |   0.081136  |    0.014156     |   2\n",
      "      13220 |   0.278614  |    0.034600     |   0\n",
      "      13221 |   0.231125  |    0.144829     |   1\n",
      "      13222 |   0.217953  |    0.003109     |   0\n",
      "      13223 |   0.038791  |    0.011330     |   2\n",
      "      13224 |   0.165385  |    0.028455     |   0\n",
      "      13225 |   0.151809  |    0.132790     |   1\n",
      "      13226 |   0.170565  |    0.009387     |   0\n",
      "      13227 |   0.064043  |    0.026840     |   2\n",
      "      13228 |   0.199337  |    0.104775     |   1\n",
      "      13229 |   0.210693  |    0.012354     |   0\n",
      "      13230 |   0.246636  |    0.183487     |   1\n",
      "      13231 |   0.180820  |    0.009295     |   0\n",
      "      13232 |   0.198367  |    0.058360     |   1\n",
      "      13233 |   0.053371  |    0.010667     |   2\n",
      "      13234 |   0.022443  |    0.049686     |   2\n",
      "      13235 |   0.046178  |    0.017565     |   2\n",
      "      13236 |   0.221533  |    0.145997     |   1\n",
      "      13237 |   0.038419  |    0.002899     |   2\n",
      "      13238 |   0.000050  |    0.005321     |   2\n",
      "      13239 |   0.160273  |    0.048659     |   0\n",
      "      13240 |   0.162196  |    0.142338     |   1\n",
      "      13241 |   0.215786  |    0.090490     |   1\n",
      "      13242 |   0.235945  |    0.007365     |   0\n",
      "      13243 |   0.000050  |    0.016623     |   2\n",
      "      13244 |   0.227321  |    0.155513     |   1\n",
      "      13245 |   0.197689  |    0.002948     |   0\n",
      "      13246 | \u001b[94m  0.000050\u001b[0m  |    0.013338     |   2\n",
      "      13247 |   0.165093  |    0.143074     |   1\n",
      "      13248 |   0.174075  |    0.085615     |   1\n",
      "      13249 |   0.226427  |    0.100802     |   1\n",
      "      13250 |   0.212321  |    0.095511     |   1\n",
      "      13251 |   0.195062  |    0.081846     |   1\n",
      "      13252 |   0.217612  |    0.026415     |   0\n",
      "      13253 |   0.258429  |    0.151323     |   1\n",
      "      13254 |   0.210112  |    0.012831     |   0\n",
      "      13255 |   0.249498  |    0.081023     |   1\n",
      "      13256 |   0.212333  |    0.087023     |   1\n",
      "      13257 |   0.000051  |    0.014377     |   2\n",
      "      13258 | \u001b[94m  0.000050\u001b[0m  |    0.038718     |   2\n",
      "      13259 |   0.217543  |    0.087595     |   1\n",
      "      13260 |   0.207596  |    0.137597     |   1\n",
      "      13261 |   0.205319  |    0.062855     |   1\n",
      "      13262 |   0.221616  |    0.086912     |   1\n",
      "      13263 |   0.237904  |    0.010841     |   0\n",
      "      13264 |   0.196954  |    0.156233     |   1\n",
      "      13265 |   0.000050  |    0.004160     |   2\n",
      "      13266 |   0.056165  |    0.008367     |   2\n",
      "      13267 |   0.184865  |    0.149271     |   1\n",
      "      13268 |   0.279186  |    0.008698     |   0\n",
      "      13269 |   0.211547  |    0.026334     |   0\n",
      "      13270 |   0.204018  |    0.046348     |   0\n",
      "      13271 |   0.170623  |    0.017959     |   0\n",
      "      13272 |   0.174843  |    0.038811     |   0\n",
      "      13273 |   0.211669  |    0.052538     |   1\n",
      "      13274 |   0.053387  |    0.006488     |   2\n",
      "      13275 |   0.196951  |    0.066155     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 13276: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      13276 |   0.221008  |    0.052355     |   1\n",
      "      13277 |   0.204457  |    0.036751     |   0\n",
      "      13278 |   0.303037  |    0.089335     |   1\n",
      "      13279 |   0.186820  |    0.032184     |   0\n",
      "      13280 |   0.061175  |    0.027506     |   2\n",
      "      13281 |   0.179214  |    0.031210     |   0\n",
      "      13282 |   0.223781  |    0.019558     |   0\n",
      "      13283 |   0.211797  |    0.019914     |   0\n",
      "      13284 |   0.044685  |    0.050245     |   2\n",
      "      13285 |   0.280867  |    0.081538     |   1\n",
      "      13286 |   0.227988  |    0.014075     |   0\n",
      "      13287 |   0.203097  |    0.031576     |   0\n",
      "      13288 |   0.241311  |    0.088145     |   1\n",
      "      13289 |   0.237698  |    0.011892     |   0\n",
      "      13290 |   0.254529  |    0.050040     |   0\n",
      "      13291 |   0.237660  |    0.090161     |   1\n",
      "      13292 |   0.196468  |    0.018505     |   0\n",
      "      13293 |   0.046977  |    0.014456     |   2\n",
      "      13294 |   0.182741  |    0.038310     |   0\n",
      "      13295 |   0.183946  |    0.014713     |   0\n",
      "      13296 |   0.059661  |    0.032729     |   2\n",
      "      13297 |   0.228850  |    0.039515     |   0\n",
      "      13298 |   0.208632  |    0.132155     |   1\n",
      "      13299 |   0.033030  |    0.007842     |   2\n",
      "      13300 |   0.222275  |    0.023289     |   0\n",
      "      13301 |   0.047604  |    0.026331     |   2\n",
      "      13302 |   0.060195  |    0.023653     |   2\n",
      "      13303 |   0.067740  |    0.046969     |   2\n",
      "      13304 |   0.226409  |    0.014718     |   0\n",
      "      13305 |   0.056148  |    0.035983     |   2\n",
      "      13306 |   0.208561  |    0.022185     |   0\n",
      "      13307 |   0.026679  |    0.042666     |   2\n",
      "      13308 | \u001b[94m  0.000050\u001b[0m  |    0.017164     |   2\n",
      "      13309 |   0.218289  |    0.138930     |   1\n",
      "      13310 |   0.007577  |    0.004603     |   2\n",
      "      13311 |   0.226837  |    0.019760     |   0\n",
      "      13312 |   0.079837  |    0.034818     |   2\n",
      "      13313 |   0.201637  |    0.026106     |   0\n",
      "      13314 |   0.298539  |    0.091229     |   1\n",
      "      13315 |   0.041945  |    0.031154     |   2\n",
      "      13316 |   0.194327  |    0.132267     |   1\n",
      "      13317 |   0.202227  |    0.013045     |   0\n",
      "      13318 |   0.214683  |    0.139022     |   1\n",
      "      13319 |   0.064671  |    0.016565     |   2\n",
      "      13320 |   0.157810  |    0.135182     |   1\n",
      "      13321 |   0.056140  |    0.006263     |   2\n",
      "      13322 |   0.023450  |    0.029538     |   2\n",
      "      13323 |   0.211544  |    0.032039     |   0\n",
      "      13324 |   0.047990  |    0.020611     |   2\n",
      "      13325 |   0.037814  |    0.043501     |   2\n",
      "      13326 |   0.193587  |    0.011553     |   0\n",
      "      13327 |   0.172508  |    0.028047     |   0\n",
      "      13328 |   0.217609  |    0.051597     |   0\n",
      "      13329 |   0.208705  |    0.096269     |   1\n",
      "      13330 |   0.220519  |    0.081554     |   1\n",
      "      13331 |   0.181512  |    0.011373     |   0\n",
      "      13332 |   0.307710  |    0.135656     |   1\n",
      "      13333 |   0.000050  |    0.004178     |   2\n",
      "      13334 |   0.224332  |    0.032378     |   0\n",
      "      13335 |   0.000050  |    0.029273     |   2\n",
      "      13336 |   0.216381  |    0.077739     |   1\n",
      "      13337 |   0.000050  |    0.034201     |   2\n",
      "      13338 |   0.188457  |    0.013168     |   0\n",
      "      13339 |   0.279828  |    0.040809     |   0\n",
      "      13340 |   0.000051  |    0.012235     |   2\n",
      "      13341 |   0.206256  |    0.032987     |   0\n",
      "      13342 |   0.000050  |    0.032735     |   2\n",
      "      13343 |   0.274759  |    0.117168     |   1\n",
      "      13344 |   0.170676  |    0.005672     |   0\n",
      "      13345 |   0.000050  |    0.044865     |   2\n",
      "      13346 |   0.192155  |    0.092608     |   1\n",
      "      13347 |   0.228058  |    0.088199     |   1\n",
      "      13348 |   0.241892  |    0.105841     |   1\n",
      "      13349 |   0.237083  |    0.084939     |   1\n",
      "      13350 |   0.060790  |    0.008301     |   2\n",
      "      13351 |   0.179264  |    0.040376     |   0\n",
      "      13352 |   0.202883  |    0.008107     |   0\n",
      "      13353 |   0.230246  |    0.044546     |   0\n",
      "      13354 |   0.199984  |    0.018414     |   0\n",
      "      13355 |   0.054726  |    0.032981     |   2\n",
      "      13356 |   0.180661  |    0.016277     |   0\n",
      "      13357 |   0.176576  |    0.065629     |   0\n",
      "      13358 |   0.224269  |    0.059087     |   1\n",
      "      13359 |   0.190768  |    0.051409     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 13360: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      13360 |   0.189671  |    0.049342     |   1\n",
      "      13361 |   0.154442  |    0.032920     |   0\n",
      "      13362 |   0.298031  |    0.095847     |   1\n",
      "      13363 |   0.061691  |    0.011660     |   2\n",
      "      13364 |   0.046499  |    0.046782     |   2\n",
      "      13365 |   0.211298  |    0.131649     |   1\n",
      "      13366 |   0.044127  |    0.005102     |   2\n",
      "      13367 |   0.226709  |    0.008849     |   0\n",
      "      13368 |   0.247782  |    0.051460     |   0\n",
      "      13369 |   0.188424  |    0.096779     |   1\n",
      "      13370 |   0.057016  |    0.016637     |   2\n",
      "      13371 |   0.032028  |    0.029161     |   2\n",
      "      13372 |   0.045522  |    0.015904     |   2\n",
      "      13373 |   0.181149  |    0.051106     |   0\n",
      "      13374 |   0.057025  |    0.015238     |   2\n",
      "      13375 |   0.215024  |    0.103445     |   1\n",
      "      13376 |   0.065073  |    0.017412     |   2\n",
      "      13377 |   0.247676  |    0.151832     |   1\n",
      "      13378 |   0.178487  |    0.087746     |   1\n",
      "      13379 |   0.232571  |    0.022665     |   0\n",
      "      13380 |   0.176105  |    0.093948     |   1\n",
      "      13381 |   0.051898  |    0.019144     |   2\n",
      "      13382 |   0.337533  |    0.140760     |   1\n",
      "      13383 |   0.205687  |    0.013763     |   0\n",
      "      13384 |   0.214507  |    0.072162     |   1\n",
      "      13385 |   0.024605  |    0.007661     |   2\n",
      "      13386 |   0.000050  |    0.070900     |   2\n",
      "      13387 |   0.227983  |    0.059964     |   1\n",
      "      13388 |   0.006564  |    0.009234     |   2\n",
      "      13389 |   0.225833  |    0.047363     |   0\n",
      "      13390 |   0.173215  |    0.023336     |   0\n",
      "      13391 |   0.265710  |    0.032843     |   0\n",
      "      13392 |   0.262420  |    0.097223     |   1\n",
      "      13393 |   0.207781  |    0.008232     |   0\n",
      "      13394 |   0.153546  |    0.025148     |   0\n",
      "      13395 |   0.209080  |    0.128079     |   1\n",
      "      13396 |   0.077378  |    0.003195     |   2\n",
      "      13397 |   0.039177  |    0.006719     |   2\n",
      "      13398 |   0.152715  |    0.027895     |   0\n",
      "      13399 |   0.224993  |    0.026343     |   0\n",
      "      13400 |   0.198146  |    0.044334     |   0\n",
      "      13401 |   0.062327  |    0.008508     |   2\n",
      "      13402 |   0.260620  |    0.036992     |   0\n",
      "      13403 |   0.052618  |    0.025177     |   2\n",
      "      13404 |   0.023009  |    0.026700     |   2\n",
      "      13405 |   0.204954  |    0.070176     |   0\n",
      "      13406 |   0.178857  |    0.043485     |   1\n",
      "      13407 |   0.169444  |    0.013956     |   0\n",
      "      13408 |   0.176682  |    0.028102     |   0\n",
      "      13409 |   0.204467  |    0.027004     |   0\n",
      "      13410 |   0.188202  |    0.055429     |   0\n",
      "      13411 |   0.046091  |    0.009302     |   2\n",
      "      13412 |   0.140882  |    0.039344     |   0\n",
      "      13413 |   0.195080  |    0.089962     |   1\n",
      "      13414 |   0.218072  |    0.151701     |   1\n",
      "      13415 |   0.249347  |    0.030519     |   1\n",
      "      13416 |   0.213492  |    0.028231     |   0\n",
      "      13417 |   0.130217  |    0.018058     |   0\n",
      "      13418 |   0.278147  |    0.057146     |   0\n",
      "      13419 |   0.037933  |    0.020669     |   2\n",
      "      13420 |   0.249074  |    0.098211     |   1\n",
      "      13421 |   0.000050  |    0.029104     |   2\n",
      "      13422 |   0.246879  |    0.135746     |   1\n",
      "      13423 |   0.243003  |    0.015642     |   0\n",
      "      13424 |   0.180967  |    0.046619     |   1\n",
      "      13425 |   0.265434  |    0.135721     |   1\n",
      "      13426 |   0.165617  |    0.007520     |   0\n",
      "      13427 |   0.000050  |    0.021225     |   2\n",
      "      13428 |   0.238939  |    0.050463     |   0\n",
      "      13429 |   0.223963  |    0.006628     |   0\n",
      "      13430 |   0.197364  |    0.048320     |   0\n",
      "      13431 |   0.000050  |    0.012508     |   2\n",
      "      13432 |   0.000050  |    0.035780     |   2\n",
      "      13433 |   0.000050  |    0.022303     |   2\n",
      "      13434 |   0.000050  |    0.030223     |   2\n",
      "      13435 |   0.164528  |    0.027199     |   0\n",
      "      13436 |   0.228393  |    0.138907     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 13439: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      13437 |   0.060641  |    0.009083     |   2\n",
      "      13438 |   0.056107  |    0.005459     |   2\n",
      "      13439 |   0.062603  |    0.022829     |   2\n",
      "      13440 |   0.045315  |    0.013316     |   2\n",
      "      13441 |   0.202821  |    0.155436     |   1\n",
      "      13442 |   0.207341  |    0.007418     |   0\n",
      "      13443 |   0.046421  |    0.005129     |   2\n",
      "      13444 |   0.057270  |    0.033315     |   2\n",
      "      13445 |   0.190994  |    0.017817     |   0\n",
      "      13446 |   0.218379  |    0.102604     |   1\n",
      "      13447 |   0.030822  |    0.017723     |   2\n",
      "      13448 |   0.244631  |    0.155696     |   1\n",
      "      13449 |   0.169426  |    0.011348     |   0\n",
      "      13450 |   0.236457  |    0.057352     |   1\n",
      "      13451 |   0.301706  |    0.113282     |   1\n",
      "      13452 |   0.044986  |    0.013932     |   2\n",
      "      13453 |   0.212235  |    0.155744     |   1\n",
      "      13454 |   0.278292  |    0.044898     |   1\n",
      "      13455 |   0.276961  |    0.141544     |   1\n",
      "      13456 |   0.230436  |    0.005273     |   0\n",
      "      13457 |   0.203415  |    0.018884     |   0\n",
      "      13458 |   0.054691  |    0.029661     |   2\n",
      "      13459 |   0.064607  |    0.026933     |   2\n",
      "      13460 |   0.223857  |    0.052050     |   0\n",
      "      13461 |   0.203375  |    0.096110     |   1\n",
      "      13462 |   0.051987  |    0.015889     |   2\n",
      "      13463 |   0.259833  |    0.146945     |   1\n",
      "      13464 |   0.025453  |    0.002828     |   2\n",
      "      13465 |   0.000050  |    0.024758     |   2\n",
      "      13466 |   0.191998  |    0.140492     |   1\n",
      "      13467 |   0.006104  |    0.012819     |   2\n",
      "      13468 |   0.191485  |    0.088312     |   1\n",
      "      13469 |   0.075996  |    0.005135     |   2\n",
      "      13470 |   0.036288  |    0.031559     |   2\n",
      "      13471 |   0.061944  |    0.028096     |   2\n",
      "      13472 |   0.051482  |    0.039172     |   2\n",
      "      13473 |   0.258032  |    0.094694     |   1\n",
      "      13474 |   0.021925  |    0.008701     |   2\n",
      "      13475 |   0.149005  |    0.056817     |   1\n",
      "      13476 |   0.043213  |    0.025995     |   2\n",
      "      13477 |   0.268592  |    0.142776     |   1\n",
      "      13478 |   0.177299  |    0.002901     |   0\n",
      "      13479 |   0.173757  |    0.007312     |   0\n",
      "      13480 |   0.205155  |    0.027536     |   0\n",
      "      13481 |   0.201058  |    0.020526     |   0\n",
      "      13482 |   0.227997  |    0.027966     |   0\n",
      "      13483 |   0.144779  |    0.028607     |   0\n",
      "      13484 |   0.200780  |    0.025105     |   0\n",
      "      13485 |   0.136696  |    0.117556     |   1\n",
      "      13486 |   0.225789  |    0.019352     |   0\n",
      "      13487 |   0.036248  |    0.032745     |   2\n",
      "      13488 |   0.182288  |    0.147359     |   1\n",
      "      13489 | \u001b[94m  0.000049\u001b[0m  |    0.003560     |   2\n",
      "      13490 |   0.222945  |    0.010345     |   0\n",
      "      13491 |   0.000049  |    0.029943     |   2\n",
      "      13492 |   0.168344  |    0.048779     |   0\n",
      "      13493 |   0.245426  |    0.081140     |   1\n",
      "      13494 |   0.200636  |    0.008018     |   0\n",
      "      13495 |   0.207718  |    0.089206     |   1\n",
      "      13496 |   0.182248  |    0.016139     |   0\n",
      "      13497 | \u001b[94m  0.000049\u001b[0m  |    0.034672     |   2\n",
      "      13498 |   0.243250  |    0.100747     |   1\n",
      "      13499 |   0.208339  |    0.082404     |   1\n",
      "      13500 |   0.000049  |    0.018652     |   2\n",
      "      13501 |   0.063486  |    0.078569     |   2\n",
      "      13502 |   0.212530  |    0.073018     |   1\n",
      "      13503 |   0.265290  |    0.099437     |   1\n",
      "      13504 |   0.046308  |    0.008759     |   2\n",
      "      13505 |   0.174796  |    0.026378     |   0\n",
      "      13506 |   0.210207  |    0.029756     |   0\n",
      "      13507 |   0.219334  |    0.106923     |   1\n",
      "      13508 |   0.244174  |    0.095039     |   1\n",
      "      13509 |   0.044773  |    0.004857     |   2\n",
      "      13510 |   0.210097  |    0.043544     |   0\n",
      "      13511 |   0.224124  |    0.009178     |   0\n",
      "      13512 |   0.218316  |    0.047431     |   0\n",
      "      13513 |   0.055506  |    0.010525     |   2\n",
      "      13514 |   0.194723  |    0.047204     |   0\n",
      "      13515 |   0.205626  |    0.092317     |   1\n",
      "      13516 |   0.031282  |    0.027087     |   2\n",
      "      13517 |   0.197200  |    0.162720     |   1\n",
      "      13518 |   0.172825  |    0.008170     |   0\n",
      "      13519 |   0.237299  |    0.112951     |   1\n",
      "      13520 |   0.223806  |    0.052704     |   1\n",
      "      13521 |   0.045484  |    0.008919     |   2\n",
      "      13522 |   0.057783  |    0.064476     |   2\n",
      "      13523 |   0.169122  |    0.092377     |   1\n",
      "      13524 |   0.193746  |    0.016816     |   0\n",
      "      13525 |   0.063926  |    0.050330     |   2\n",
      "      13526 |   0.217546  |    0.094321     |   1\n",
      "      13527 |   0.180325  |    0.020991     |   0\n",
      "      13528 |   0.288146  |    0.111059     |   1\n",
      "      13529 |   0.204704  |    0.062753     |   1\n",
      "      13530 |   0.206040  |    0.171173     |   1\n",
      "      13531 |   0.197067  |    0.026875     |   1\n",
      "      13532 |   0.052758  |    0.026847     |   2\n",
      "      13533 |   0.219782  |    0.021092     |   0\n",
      "      13534 |   0.250276  |    0.024898     |   0\n",
      "      13535 |   0.208040  |    0.026405     |   0\n",
      "      13536 |   0.026191  |    0.045752     |   2\n",
      "      13537 |   0.237353  |    0.010350     |   0\n",
      "      13538 |   0.000049  |    0.037419     |   2\n",
      "      13539 |   0.228634  |    0.093653     |   1\n",
      "      13540 |   0.006127  |    0.015952     |   2\n",
      "      13541 |   0.157996  |    0.032968     |   0\n",
      "      13542 |   0.079104  |    0.006246     |   2\n",
      "      13543 |   0.039400  |    0.035347     |   2\n",
      "      13544 |   0.211942  |    0.081629     |   1\n",
      "      13545 |   0.181130  |    0.042487     |   0\n",
      "      13546 |   0.232540  |    0.016669     |   0\n",
      "      13547 |   0.064286  |    0.022458     |   2\n",
      "      13548 |   0.183753  |    0.041158     |   0\n",
      "      13549 |   0.054246  |    0.012297     |   2\n",
      "      13550 |   0.023783  |    0.028974     |   2\n",
      "      13551 |   0.205083  |    0.028408     |   0\n",
      "      13552 |   0.208505  |    0.142404     |   1\n",
      "      13553 |   0.251693  |    0.046102     |   1\n",
      "      13554 |   0.196291  |    0.025991     |   0\n",
      "      13555 |   0.154413  |    0.148124     |   1\n",
      "      13556 |   0.234001  |    0.007077     |   0\n",
      "      13557 |   0.205434  |    0.012570     |   0\n",
      "      13558 |   0.244393  |    0.051833     |   0\n",
      "      13559 |   0.222094  |    0.081798     |   1\n",
      "      13560 |   0.047456  |    0.008842     |   2\n",
      "      13561 |   0.035989  |    0.031346     |   2\n",
      "      13562 |   0.198204  |    0.138368     |   1\n",
      "      13563 |   0.220482  |    0.095614     |   1\n",
      "      13564 |   0.000049  |    0.003655     |   2\n",
      "      13565 |   0.000049  |    0.026036     |   2\n",
      "      13566 |   0.000049  |    0.028482     |   2\n",
      "      13567 |   0.000050  |    0.022165     |   2\n",
      "      13568 |   0.000049  |    0.035985     |   2\n",
      "      13569 |   0.190186  |    0.098035     |   1\n",
      "      13570 |   0.000049  |    0.021384     |   2\n",
      "      13571 |   0.174995  |    0.036341     |   0\n",
      "      13572 |   0.057378  |    0.015525     |   2\n",
      "      13573 |   0.053738  |    0.056172     |   2\n",
      "      13574 |   0.208037  |    0.101827     |   1\n",
      "      13575 |   0.278253  |    0.006391     |   0\n",
      "      13576 |   0.183520  |    0.014002     |   0\n",
      "      13577 |   0.216394  |    0.054439     |   0\n",
      "      13578 |   0.259517  |    0.079955     |   1\n",
      "      13579 |   0.214984  |    0.008318     |   0\n",
      "      13580 |   0.238065  |    0.055888     |   0\n",
      "      13581 |   0.171023  |    0.088792     |   1\n",
      "      13582 |   0.257770  |    0.008134     |   0\n",
      "      13583 |   0.170531  |    0.016363     |   0\n",
      "      13584 |   0.247149  |    0.034947     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 13585: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      13585 |   0.182285  |    0.063108     |   1\n",
      "      13586 |   0.244259  |    0.020286     |   0\n",
      "      13587 |   0.263578  |    0.105114     |   1\n",
      "      13588 |   0.060624  |    0.023440     |   2\n",
      "      13589 |   0.210525  |    0.150454     |   1\n",
      "      13590 |   0.044081  |    0.004516     |   2\n",
      "      13591 |   0.197470  |    0.090449     |   1\n",
      "      13592 |   0.210887  |    0.101968     |   1\n",
      "      13593 |   0.196862  |    0.003572     |   0\n",
      "      13594 |   0.042962  |    0.003382     |   2\n",
      "      13595 |   0.166992  |    0.053962     |   0\n",
      "      13596 |   0.183272  |    0.090698     |   1\n",
      "      13597 |   0.054819  |    0.008783     |   2\n",
      "      13598 |   0.257153  |    0.031579     |   0\n",
      "      13599 |   0.247802  |    0.040013     |   0\n",
      "      13600 |   0.237064  |    0.081295     |   1\n",
      "      13601 |   0.175979  |    0.020086     |   0\n",
      "      13602 |   0.228334  |    0.157999     |   1\n",
      "      13603 |   0.031540  |    0.005315     |   2\n",
      "      13604 |   0.177607  |    0.055040     |   1\n",
      "      13605 |   0.173322  |    0.009229     |   0\n",
      "      13606 |   0.044601  |    0.035549     |   2\n",
      "      13607 |   0.212630  |    0.148345     |   1\n",
      "      13608 |   0.202739  |    0.052709     |   1\n",
      "      13609 |   0.054326  |    0.013811     |   2\n",
      "      13610 |   0.064783  |    0.032912     |   2\n",
      "      13611 |   0.053756  |    0.005942     |   2\n",
      "      13612 |   0.026666  |    0.041979     |   2\n",
      "      13613 |   0.220767  |    0.140860     |   1\n",
      "      13614 |   0.000049  |    0.009697     |   2\n",
      "      13615 |   0.305130  |    0.082906     |   1\n",
      "      13616 |   0.197716  |    0.008541     |   0\n",
      "      13617 |   0.170302  |    0.042153     |   0\n",
      "      13618 |   0.153462  |    0.091918     |   1\n",
      "      13619 |   0.006535  |    0.015946     |   2\n",
      "      13620 |   0.225711  |    0.048846     |   0\n",
      "      13621 |   0.076547  |    0.014974     |   2\n",
      "      13622 |   0.039485  |    0.030729     |   2\n",
      "      13623 |   0.061881  |    0.015996     |   2\n",
      "      13624 |   0.284228  |    0.140759     |   1\n",
      "      13625 |   0.213639  |    0.007296     |   0\n",
      "      13626 |   0.200001  |    0.102238     |   1\n",
      "      13627 |   0.249722  |    0.082844     |   1\n",
      "      13628 |   0.051652  |    0.009885     |   2\n",
      "      13629 |   0.151987  |    0.048036     |   0\n",
      "      13630 |   0.180418  |    0.007100     |   0\n",
      "      13631 |   0.263976  |    0.040265     |   0\n",
      "      13632 |   0.195208  |    0.019328     |   0\n",
      "      13633 |   0.226376  |    0.042847     |   0\n",
      "      13634 |   0.215686  |    0.086894     |   1\n",
      "      13635 |   0.214607  |    0.026452     |   0\n",
      "      13636 |   0.191827  |    0.068375     |   1\n",
      "      13637 |   0.217253  |    0.024905     |   0\n",
      "      13638 |   0.155990  |    0.032883     |   0\n",
      "      13639 |   0.206085  |    0.160448     |   1\n",
      "      13640 |   0.263302  |    0.025876     |   1\n",
      "      13641 |   0.022990  |    0.054162     |   2\n",
      "      13642 |   0.048218  |    0.012599     |   2\n",
      "      13643 |   0.180224  |    0.147337     |   1\n",
      "      13644 |   0.035963  |    0.002825     |   2\n",
      "      13645 | \u001b[94m  0.000048\u001b[0m  |    0.009270     |   2\n",
      "      13646 |   0.221231  |    0.160884     |   1\n",
      "      13647 |   0.189790  |    0.087266     |   1\n",
      "      13648 |   0.211194  |    0.012944     |   0\n",
      "      13649 |   0.000049  |    0.028842     |   2\n",
      "      13650 |   0.000049  |    0.011409     |   2\n",
      "      13651 |   0.170608  |    0.034976     |   0\n",
      "      13652 |   0.278840  |    0.086143     |   1\n",
      "      13653 |   0.210899  |    0.009936     |   0\n",
      "      13654 |   0.214202  |    0.149528     |   1\n",
      "      13655 |   0.000049  |    0.003098     |   2\n",
      "      13656 |   0.195206  |    0.011781     |   0\n",
      "      13657 |   0.253016  |    0.148332     |   1\n",
      "      13658 |   0.000049  |    0.011589     |   2\n",
      "      13659 |   0.206131  |    0.075468     |   1\n",
      "      13660 |   0.188212  |    0.011822     |   0\n",
      "      13661 |   0.000049  |    0.030412     |   2\n",
      "      13662 |   0.056570  |    0.019430     |   2\n",
      "      13663 |   0.054277  |    0.017861     |   2\n",
      "      13664 |   0.201657  |    0.150180     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 13665: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      13665 |   0.262682  |    0.015496     |   1\n",
      "      13666 |   0.211225  |    0.035696     |   0\n",
      "      13667 |   0.220234  |    0.107080     |   1\n",
      "      13668 |   0.201699  |    0.037905     |   1\n",
      "      13669 |   0.217781  |    0.031773     |   0\n",
      "      13670 |   0.059253  |    0.016859     |   2\n",
      "      13671 |   0.236584  |    0.140235     |   1\n",
      "      13672 |   0.193129  |    0.080194     |   1\n",
      "      13673 |   0.042958  |    0.010409     |   2\n",
      "      13674 |   0.219418  |    0.045688     |   0\n",
      "      13675 |   0.207299  |    0.023376     |   0\n",
      "      13676 |   0.280995  |    0.042485     |   0\n",
      "      13677 |   0.044413  |    0.013470     |   2\n",
      "      13678 |   0.055187  |    0.046326     |   2\n",
      "      13679 |   0.031201  |    0.012180     |   2\n",
      "      13680 |   0.044176  |    0.029360     |   2\n",
      "      13681 |   0.221800  |    0.147047     |   1\n",
      "      13682 |   0.203059  |    0.012008     |   0\n",
      "      13683 |   0.057310  |    0.006882     |   2\n",
      "      13684 |   0.065169  |    0.038578     |   2\n",
      "      13685 |   0.202392  |    0.018583     |   0\n",
      "      13686 |   0.225224  |    0.032021     |   0\n",
      "      13687 |   0.210800  |    0.116574     |   1\n",
      "      13688 |   0.272584  |    0.050920     |   1\n",
      "      13689 |   0.242082  |    0.080322     |   1\n",
      "      13690 |   0.184962  |    0.025304     |   0\n",
      "      13691 |   0.052442  |    0.031971     |   2\n",
      "      13692 |   0.180781  |    0.022377     |   0\n",
      "      13693 |   0.025792  |    0.031152     |   2\n",
      "      13694 | \u001b[94m  0.000048\u001b[0m  |    0.033383     |   2\n",
      "      13695 |   0.243505  |    0.088470     |   1\n",
      "      13696 |   0.258404  |    0.110119     |   1\n",
      "      13697 |   0.203676  |    0.072913     |   1\n",
      "      13698 |   0.187471  |    0.100537     |   1\n",
      "      13699 |   0.282595  |    0.058568     |   1\n",
      "      13700 |   0.006200  |    0.017853     |   2\n",
      "      13701 |   0.214478  |    0.106051     |   1\n",
      "      13702 |   0.220922  |    0.024981     |   0\n",
      "      13703 |   0.076609  |    0.039531     |   2\n",
      "      13704 |   0.199932  |    0.084288     |   1\n",
      "      13705 |   0.223785  |    0.045863     |   0\n",
      "      13706 |   0.206769  |    0.023625     |   0\n",
      "      13707 |   0.214609  |    0.147705     |   1\n",
      "      13708 |   0.232281  |    0.010519     |   0\n",
      "      13709 |   0.178310  |    0.098619     |   1\n",
      "      13710 |   0.231679  |    0.061092     |   1\n",
      "      13711 |   0.151207  |    0.055710     |   1\n",
      "      13712 |   0.040640  |    0.014293     |   2\n",
      "      13713 |   0.202741  |    0.139824     |   1\n",
      "      13714 |   0.232482  |    0.096067     |   1\n",
      "      13715 |   0.061166  |    0.011989     |   2\n",
      "      13716 |   0.223368  |    0.160828     |   1\n",
      "      13717 |   0.225734  |    0.031166     |   1\n",
      "      13718 |   0.235343  |    0.053599     |   0\n",
      "      13719 |   0.051169  |    0.005872     |   2\n",
      "      13720 |   0.022720  |    0.045229     |   2\n",
      "      13721 |   0.211866  |    0.137625     |   1\n",
      "      13722 |   0.161925  |    0.095639     |   1\n",
      "      13723 |   0.247298  |    0.084529     |   1\n",
      "      13724 |   0.045984  |    0.013527     |   2\n",
      "      13725 |   0.165916  |    0.132494     |   1\n",
      "      13726 |   0.219183  |    0.011164     |   0\n",
      "      13727 |   0.167875  |    0.065156     |   0\n",
      "      13728 |   0.192986  |    0.089412     |   1\n",
      "      13729 |   0.207219  |    0.008639     |   0\n",
      "      13730 |   0.204540  |    0.137154     |   1\n",
      "      13731 |   0.199857  |    0.102073     |   1\n",
      "      13732 |   0.197950  |    0.083647     |   1\n",
      "      13733 |   0.033894  |    0.004642     |   2\n",
      "      13734 |   0.209324  |    0.045047     |   0\n",
      "      13735 | \u001b[94m  0.000048\u001b[0m  |    0.007111     |   2\n",
      "      13736 | \u001b[94m  0.000048\u001b[0m  |    0.017202     |   2\n",
      "      13737 |   0.232095  |    0.030905     |   0\n",
      "      13738 | \u001b[94m  0.000048\u001b[0m  |    0.051091     |   2\n",
      "      13739 |   0.178617  |    0.134833     |   1\n",
      "      13740 |   0.000048  |    0.005499     |   2\n",
      "      13741 |   0.000048  |    0.024119     |   2\n",
      "      13742 |   0.248324  |    0.086033     |   1\n",
      "      13743 | \u001b[94m  0.000048\u001b[0m  |    0.013011     |   2\n",
      "      13744 |   0.058492  |    0.042587     |   2\n",
      "      13745 |   0.239949  |    0.015655     |   0\n",
      "      13746 |   0.224180  |    0.064822     |   0\n",
      "      13747 |   0.210888  |    0.051317     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 13749: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      13748 |   0.053628  |    0.026832     |   2\n",
      "      13749 |   0.057006  |    0.022370     |   2\n",
      "      13750 |   0.245591  |    0.031282     |   0\n",
      "      13751 |   0.241260  |    0.088460     |   1\n",
      "      13752 |   0.217837  |    0.031369     |   0\n",
      "      13753 |   0.200943  |    0.136374     |   1\n",
      "      13754 |   0.044389  |    0.009055     |   2\n",
      "      13755 |   0.205930  |    0.083202     |   1\n",
      "      13756 |   0.041011  |    0.035083     |   2\n",
      "      13757 |   0.254015  |    0.136999     |   1\n",
      "      13758 |   0.198219  |    0.079666     |   1\n",
      "      13759 |   0.054271  |    0.008163     |   2\n",
      "      13760 |   0.030791  |    0.047375     |   2\n",
      "      13761 |   0.223103  |    0.010382     |   0\n",
      "      13762 |   0.223176  |    0.131488     |   1\n",
      "      13763 |   0.261550  |    0.006564     |   0\n",
      "      13764 |   0.172226  |    0.016931     |   0\n",
      "      13765 |   0.043563  |    0.027059     |   2\n",
      "      13766 |   0.056497  |    0.028687     |   2\n",
      "      13767 |   0.240286  |    0.044665     |   0\n",
      "      13768 |   0.235019  |    0.078703     |   1\n",
      "      13769 |   0.242344  |    0.006183     |   0\n",
      "      13770 |   0.207430  |    0.048016     |   0\n",
      "      13771 |   0.240196  |    0.023608     |   0\n",
      "      13772 |   0.193629  |    0.108668     |   1\n",
      "      13773 |   0.219790  |    0.094656     |   1\n",
      "      13774 |   0.188313  |    0.100423     |   1\n",
      "      13775 |   0.063101  |    0.009051     |   2\n",
      "      13776 |   0.164649  |    0.044538     |   0\n",
      "      13777 |   0.056706  |    0.008816     |   2\n",
      "      13778 |   0.216571  |    0.049505     |   0\n",
      "      13779 |   0.027366  |    0.006574     |   2\n",
      "      13780 | \u001b[94m  0.000047\u001b[0m  |    0.067085     |   2\n",
      "      13781 |   0.199874  |    0.085960     |   1\n",
      "      13782 |   0.278631  |    0.103400     |   1\n",
      "      13783 |   0.006651  |    0.004196     |   2\n",
      "      13784 |   0.074488  |    0.005226     |   2\n",
      "      13785 |   0.038267  |    0.049294     |   2\n",
      "      13786 |   0.182713  |    0.135907     |   1\n",
      "      13787 |   0.222536  |    0.084178     |   1\n",
      "      13788 |   0.199001  |    0.038186     |   1\n",
      "      13789 |   0.063188  |    0.053233     |   2\n",
      "      13790 |   0.276407  |    0.069336     |   1\n",
      "      13791 |   0.052500  |    0.009819     |   2\n",
      "      13792 |   0.191973  |    0.073462     |   0\n",
      "      13793 |   0.195353  |    0.056915     |   1\n",
      "      13794 |   0.021818  |    0.024938     |   2\n",
      "      13795 |   0.231904  |    0.152515     |   1\n",
      "      13796 |   0.040986  |    0.002883     |   2\n",
      "      13797 |   0.262650  |    0.053411     |   0\n",
      "      13798 |   0.188664  |    0.033611     |   1\n",
      "      13799 |   0.188874  |    0.035187     |   0\n",
      "      13800 |   0.204982  |    0.113120     |   1\n",
      "      13801 |   0.163588  |    0.067445     |   1\n",
      "      13802 |   0.148985  |    0.027854     |   0\n",
      "      13803 |   0.297128  |    0.107826     |   1\n",
      "      13804 |   0.036432  |    0.012995     |   2\n",
      "      13805 |   0.255152  |    0.153328     |   1\n",
      "      13806 | \u001b[94m  0.000047\u001b[0m  |    0.011426     |   2\n",
      "      13807 |   0.270922  |    0.103552     |   1\n",
      "      13808 |   0.195589  |    0.048512     |   1\n",
      "      13809 |   0.215571  |    0.085298     |   1\n",
      "      13810 |   0.191356  |    0.013700     |   0\n",
      "      13811 |   0.220351  |    0.040300     |   0\n",
      "      13812 |   0.183611  |    0.033913     |   0\n",
      "      13813 |   0.000047  |    0.023626     |   2\n",
      "      13814 |   0.220084  |    0.111422     |   1\n",
      "      13815 |   0.226170  |    0.107258     |   1\n",
      "      13816 |   0.199359  |    0.082652     |   1\n",
      "      13817 |   0.000047  |    0.006349     |   2\n",
      "      13818 |   0.000048  |    0.044896     |   2\n",
      "      13819 |   0.211539  |    0.076898     |   1\n",
      "      13820 |   0.175043  |    0.028100     |   0\n",
      "      13821 |   0.000047  |    0.034466     |   2\n",
      "      13822 |   0.000047  |    0.027496     |   2\n",
      "      13823 |   0.201788  |    0.143093     |   1\n",
      "      13824 |   0.162252  |    0.011510     |   0\n",
      "      13825 |   0.187663  |    0.097293     |   1\n",
      "      13826 |   0.157302  |    0.110878     |   1\n",
      "      13827 |   0.137581  |    0.038375     |   1\n",
      "      13828 |   0.209685  |    0.145383     |   1\n",
      "      13829 |   0.057526  |    0.007338     |   2\n",
      "      13830 |   0.218199  |    0.080600     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 13832: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      13831 |   0.052403  |    0.010409     |   2\n",
      "      13832 |   0.055414  |    0.021494     |   2\n",
      "      13833 |   0.265599  |    0.068319     |   0\n",
      "      13834 |   0.213476  |    0.088832     |   1\n",
      "      13835 |   0.237481  |    0.084966     |   1\n",
      "      13836 |   0.041187  |    0.011566     |   2\n",
      "      13837 |   0.275010  |    0.145116     |   1\n",
      "      13838 |   0.043818  |    0.003253     |   2\n",
      "      13839 |   0.219857  |    0.009727     |   0\n",
      "      13840 |   0.185558  |    0.145355     |   1\n",
      "      13841 |   0.170703  |    0.002862     |   0\n",
      "      13842 |   0.056411  |    0.015244     |   2\n",
      "      13843 |   0.029993  |    0.031162     |   2\n",
      "      13844 |   0.045168  |    0.013118     |   2\n",
      "      13845 |   0.208184  |    0.047056     |   0\n",
      "      13846 |   0.268494  |    0.090085     |   1\n",
      "      13847 |   0.208103  |    0.095822     |   1\n",
      "      13848 |   0.185037  |    0.093385     |   1\n",
      "      13849 |   0.244511  |    0.087906     |   1\n",
      "      13850 |   0.054048  |    0.013023     |   2\n",
      "      13851 |   0.061871  |    0.009590     |   2\n",
      "      13852 |   0.215748  |    0.056975     |   0\n",
      "      13853 |   0.154054  |    0.090474     |   1\n",
      "      13854 |   0.196192  |    0.090941     |   1\n",
      "      13855 |   0.229123  |    0.099744     |   1\n",
      "      13856 |   0.184876  |    0.010947     |   0\n",
      "      13857 |   0.056069  |    0.034876     |   2\n",
      "      13858 |   0.028377  |    0.016043     |   2\n",
      "      13859 |   0.211246  |    0.147597     |   1\n",
      "      13860 |   0.154171  |    0.091786     |   1\n",
      "      13861 |   0.174339  |    0.089255     |   1\n",
      "      13862 | \u001b[94m  0.000046\u001b[0m  |    0.007117     |   2\n",
      "      13863 |   0.161044  |    0.029387     |   0\n",
      "      13864 |   0.007093  |    0.043613     |   2\n",
      "      13865 |   0.205252  |    0.083848     |   1\n",
      "      13866 |   0.184010  |    0.029329     |   0\n",
      "      13867 |   0.208435  |    0.145587     |   1\n",
      "      13868 |   0.078361  |    0.006881     |   2\n",
      "      13869 |   0.037725  |    0.008448     |   2\n",
      "      13870 |   0.243262  |    0.044770     |   0\n",
      "      13871 |   0.258046  |    0.019127     |   0\n",
      "      13872 |   0.059270  |    0.024567     |   2\n",
      "      13873 |   0.194209  |    0.037163     |   0\n",
      "      13874 |   0.262839  |    0.136970     |   1\n",
      "      13875 |   0.204216  |    0.062201     |   1\n",
      "      13876 |   0.048915  |    0.010529     |   2\n",
      "      13877 |   0.252014  |    0.135457     |   1\n",
      "      13878 |   0.208540  |    0.005449     |   0\n",
      "      13879 |   0.173136  |    0.050116     |   0\n",
      "      13880 |   0.179088  |    0.101620     |   1\n",
      "      13881 |   0.154878  |    0.082423     |   1\n",
      "      13882 |   0.228031  |    0.013654     |   0\n",
      "      13883 |   0.025132  |    0.043530     |   2\n",
      "      13884 |   0.244778  |    0.019991     |   0\n",
      "      13885 |   0.220315  |    0.140535     |   1\n",
      "      13886 |   0.047753  |    0.013615     |   2\n",
      "      13887 |   0.207868  |    0.089533     |   1\n",
      "      13888 |   0.037768  |    0.026587     |   2\n",
      "      13889 |   0.225811  |    0.112023     |   1\n",
      "      13890 | \u001b[94m  0.000046\u001b[0m  |    0.024295     |   2\n",
      "      13891 |   0.000046  |    0.032228     |   2\n",
      "      13892 | \u001b[94m  0.000046\u001b[0m  |    0.015713     |   2\n",
      "      13893 |   0.000046  |    0.029303     |   2\n",
      "      13894 |   0.214016  |    0.025452     |   0\n",
      "      13895 |   0.197277  |    0.093887     |   1\n",
      "      13896 |   0.000046  |    0.022182     |   2\n",
      "      13897 | \u001b[94m  0.000046\u001b[0m  |    0.054282     |   2\n",
      "      13898 |   0.217259  |    0.083385     |   1\n",
      "      13899 |   0.263157  |    0.067381     |   1\n",
      "      13900 |   0.060662  |    0.072387     |   2\n",
      "      13901 |   0.053943  |    0.017158     |   2\n",
      "      13902 |   0.240929  |    0.144592     |   1\n",
      "      13903 |   0.261244  |    0.066513     |   1\n",
      "      13904 |   0.174078  |    0.099289     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 13905: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      13905 |   0.054246  |    0.007372     |   2\n",
      "      13906 |   0.041981  |    0.015954     |   2\n",
      "      13907 |   0.169168  |    0.056677     |   0\n",
      "      13908 |   0.042144  |    0.004569     |   2\n",
      "      13909 |   0.056704  |    0.047792     |   2\n",
      "      13910 |   0.030418  |    0.016688     |   2\n",
      "      13911 |   0.191708  |    0.034135     |   0\n",
      "      13912 |   0.043984  |    0.023102     |   2\n",
      "      13913 |   0.052070  |    0.032777     |   2\n",
      "      13914 |   0.061990  |    0.015699     |   2\n",
      "      13915 |   0.220142  |    0.047007     |   0\n",
      "      13916 |   0.055273  |    0.030205     |   2\n",
      "      13917 |   0.217093  |    0.032370     |   0\n",
      "      13918 |   0.233583  |    0.082982     |   1\n",
      "      13919 |   0.248735  |    0.090186     |   1\n",
      "      13920 |   0.201881  |    0.024833     |   0\n",
      "      13921 |   0.223528  |    0.158305     |   1\n",
      "      13922 |   0.163836  |    0.088251     |   1\n",
      "      13923 |   0.241234  |    0.017208     |   0\n",
      "      13924 |   0.213274  |    0.130397     |   1\n",
      "      13925 |   0.276915  |    0.008099     |   0\n",
      "      13926 |   0.204847  |    0.139536     |   1\n",
      "      13927 |   0.026962  |    0.002924     |   2\n",
      "      13928 | \u001b[94m  0.000045\u001b[0m  |    0.009585     |   2\n",
      "      13929 |   0.006068  |    0.026722     |   2\n",
      "      13930 |   0.250803  |    0.040733     |   0\n",
      "      13931 |   0.077101  |    0.019950     |   2\n",
      "      13932 |   0.038447  |    0.022496     |   2\n",
      "      13933 |   0.060909  |    0.012335     |   2\n",
      "      13934 |   0.050657  |    0.050193     |   2\n",
      "      13935 |   0.212646  |    0.093441     |   1\n",
      "      13936 |   0.212975  |    0.019957     |   0\n",
      "      13937 |   0.184854  |    0.036718     |   0\n",
      "      13938 |   0.200554  |    0.086689     |   1\n",
      "      13939 |   0.203402  |    0.016304     |   0\n",
      "      13940 |   0.197334  |    0.043750     |   0\n",
      "      13941 |   0.023513  |    0.015141     |   2\n",
      "      13942 |   0.045899  |    0.049661     |   2\n",
      "      13943 |   0.189816  |    0.087095     |   1\n",
      "      13944 |   0.174973  |    0.028020     |   0\n",
      "      13945 |   0.215526  |    0.043519     |   0\n",
      "      13946 |   0.186870  |    0.013413     |   0\n",
      "      13947 |   0.195285  |    0.054166     |   0\n",
      "      13948 |   0.266586  |    0.109179     |   1\n",
      "      13949 |   0.130059  |    0.093384     |   1\n",
      "      13950 |   0.272172  |    0.084588     |   1\n",
      "      13951 |   0.231039  |    0.090934     |   1\n",
      "      13952 |   0.242333  |    0.085434     |   1\n",
      "      13953 |   0.036168  |    0.033442     |   2\n",
      "      13954 | \u001b[94m  0.000045\u001b[0m  |    0.027039     |   2\n",
      "      13955 |   0.337185  |    0.085433     |   1\n",
      "      13956 |   0.261894  |    0.078944     |   1\n",
      "      13957 |   0.250206  |    0.021657     |   0\n",
      "      13958 |   0.221027  |    0.141634     |   1\n",
      "      13959 |   0.219699  |    0.005967     |   0\n",
      "      13960 |   0.000045  |    0.014639     |   2\n",
      "      13961 |   0.000045  |    0.041083     |   2\n",
      "      13962 |   0.206838  |    0.128180     |   1\n",
      "      13963 |   0.000046  |    0.002856     |   2\n",
      "      13964 |   0.000045  |    0.021704     |   2\n",
      "      13965 |   0.186731  |    0.129605     |   1\n",
      "      13966 |   0.000045  |    0.010120     |   2\n",
      "      13967 |   0.219578  |    0.145380     |   1\n",
      "      13968 |   0.197090  |    0.002879     |   0\n",
      "      13969 |   0.177534  |    0.005514     |   0\n",
      "      13970 |   0.056948  |    0.049529     |   2\n",
      "      13971 |   0.052513  |    0.007986     |   2\n",
      "      13972 |   0.197154  |    0.054476     |   0\n",
      "      13973 |   0.228033  |    0.102765     |   1\n",
      "      13974 |   0.282667  |    0.057419     |   1\n",
      "      13975 |   0.191892  |    0.015304     |   0\n",
      "      13976 |   0.201139  |    0.042891     |   0\n",
      "      13977 |   0.243939  |    0.011969     |   0\n",
      "      13978 |   0.162472  |    0.030428     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 13979: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      13979 |   0.265671  |    0.096330     |   1\n",
      "      13980 |   0.054326  |    0.006587     |   2\n",
      "      13981 |   0.204278  |    0.041155     |   0\n",
      "      13982 |   0.040952  |    0.021434     |   2\n",
      "      13983 |   0.041898  |    0.031336     |   2\n",
      "      13984 |   0.054044  |    0.005430     |   2\n",
      "      13985 |   0.030866  |    0.043584     |   2\n",
      "      13986 |   0.223852  |    0.133522     |   1\n",
      "      13987 |   0.179646  |    0.009913     |   0\n",
      "      13988 |   0.181778  |    0.089775     |   1\n",
      "      13989 |   0.043703  |    0.008151     |   2\n",
      "      13990 |   0.056791  |    0.050928     |   2\n",
      "      13991 |   0.062143  |    0.006566     |   2\n",
      "      13992 |   0.055972  |    0.048190     |   2\n",
      "      13993 |   0.027167  |    0.010244     |   2\n",
      "      13994 |   0.188026  |    0.056209     |   0\n",
      "      13995 |   0.165861  |    0.090321     |   1\n",
      "      13996 |   0.237883  |    0.110711     |   1\n",
      "      13997 |   0.224493  |    0.058607     |   1\n",
      "      13998 |   0.219729  |    0.028127     |   0\n",
      "      13999 |   0.216294  |    0.019514     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 14000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 14000: Plotting estimates.\n",
      "Exception in thread neuralnilm-data-process:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 810, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/dk3810/workspace/python/neuralnilm/neuralnilm/data/datathread.py\", line 16, in run\n",
      "    batch = self.data_pipeline.get_batch(**self._get_batch_kwargs)\n",
      "  File \"/home/dk3810/workspace/python/neuralnilm/neuralnilm/data/datapipeline.py\", line 46, in get_batch\n",
      "    batch = self._source_iterators[source_id].next()\n",
      "ValueError: generator already executing\n",
      "\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      14000 |   0.181984  |    0.031887     |   0\n",
      "      14001 |   0.184990  |    0.045002     |   0\n",
      "      14002 |   0.198542  |    0.022688     |   0\n",
      "      14003 |   0.153348  |    0.026553     |   0\n",
      "      14004 |   0.056492  |    0.017097     |   2\n",
      "      14005 |   0.182768  |    0.029117     |   0\n",
      "      14006 |   0.195376  |    0.032963     |   0\n",
      "      14007 |   0.292446  |    0.133223     |   1\n",
      "      14008 |   0.186458  |    0.068691     |   1\n",
      "      14009 |   0.214706  |    0.140038     |   1\n",
      "      14010 |   0.223242  |    0.094226     |   1\n",
      "      14011 |   0.238247  |    0.047964     |   1\n",
      "      14012 |   0.161562  |    0.092543     |   1\n",
      "      14013 |   0.040423  |    0.016475     |   2\n",
      "      14014 |   0.289986  |    0.141994     |   1\n",
      "      14015 |   0.311735  |    0.064865     |   1\n",
      "      14016 |   0.042983  |    0.019939     |   2\n",
      "      14017 |   0.161838  |    0.129067     |   1\n",
      "      14018 |   0.211770  |    0.009613     |   0\n",
      "      14019 |   0.195106  |    0.049342     |   0\n",
      "      14020 |   0.218931  |    0.085140     |   1\n",
      "      14021 |   0.055112  |    0.006781     |   2\n",
      "      14022 |   0.160620  |    0.161897     |   1\n",
      "      14023 |   0.030549  |    0.005220     |   2\n",
      "      14024 |   0.188345  |    0.098365     |   1\n",
      "      14025 |   0.218648  |    0.074467     |   1\n",
      "      14026 |   0.042264  |    0.006689     |   2\n",
      "      14027 |   0.210015  |    0.053958     |   0\n",
      "      14028 |   0.054493  |    0.037141     |   2\n",
      "      14029 |   0.058764  |    0.059983     |   2\n",
      "      14030 |   0.052465  |    0.021953     |   2\n",
      "      14031 |   0.026442  |    0.029167     |   2\n",
      "      14032 |   0.221778  |    0.041104     |   0\n",
      "      14033 |   0.000046  |    0.014825     |   2\n",
      "      14034 |   0.006007  |    0.034590     |   2\n",
      "      14035 |   0.204312  |    0.036926     |   0\n",
      "      14036 |   0.224330  |    0.081714     |   1\n",
      "      14037 |   0.232694  |    0.031022     |   0\n",
      "      14038 |   0.164848  |    0.025475     |   0\n",
      "      14039 |   0.213336  |    0.059503     |   0\n",
      "      14040 |   0.277506  |    0.057069     |   1\n",
      "      14041 |   0.188457  |    0.009523     |   0\n",
      "      14042 |   0.242559  |    0.043386     |   0\n",
      "      14043 |   0.180880  |    0.013885     |   0\n",
      "      14044 |   0.211586  |    0.031501     |   0\n",
      "      14045 |   0.158070  |    0.025136     |   0\n",
      "      14046 |   0.180493  |    0.031630     |   0\n",
      "      14047 |   0.076991  |    0.019644     |   2\n",
      "      14048 |   0.214366  |    0.138201     |   1\n",
      "      14049 |   0.192234  |    0.019273     |   0\n",
      "      14050 |   0.163096  |    0.092307     |   1\n",
      "      14051 |   0.263328  |    0.077141     |   1\n",
      "      14052 |   0.226154  |    0.087729     |   1\n",
      "      14053 |   0.242505  |    0.143468     |   1\n",
      "      14054 |   0.039103  |    0.011010     |   2\n",
      "      14055 |   0.217874  |    0.048569     |   1\n",
      "      14056 |   0.215638  |    0.024549     |   0\n",
      "      14057 |   0.228207  |    0.032677     |   0\n",
      "      14058 |   0.229179  |    0.137597     |   1\n",
      "      14059 |   0.195738  |    0.003917     |   0\n",
      "      14060 |   0.063486  |    0.004659     |   2\n",
      "      14061 |   0.185954  |    0.044869     |   0\n",
      "      14062 |   0.189127  |    0.012382     |   0\n",
      "      14063 |   0.261743  |    0.135273     |   1\n",
      "      14064 |   0.052341  |    0.009120     |   2\n",
      "      14065 |   0.023754  |    0.018791     |   2\n",
      "      14066 |   0.161633  |    0.044347     |   0\n",
      "      14067 |   0.226512  |    0.017137     |   0\n",
      "      14068 |   0.216904  |    0.038875     |   0\n",
      "      14069 |   0.051239  |    0.011947     |   2\n",
      "      14070 |   0.033977  |    0.026089     |   2\n",
      "      14071 |   0.000046  |    0.051217     |   2\n",
      "      14072 |   0.000046  |    0.006604     |   2\n",
      "      14073 |   0.247019  |    0.047302     |   0\n",
      "      14074 |   0.218635  |    0.080224     |   1\n",
      "      14075 |   0.197669  |    0.017566     |   0\n",
      "      14076 |   0.214098  |    0.104479     |   1\n",
      "      14077 |   0.202875  |    0.007534     |   0\n",
      "      14078 |   0.000046  |    0.045855     |   2\n",
      "      14079 |   0.167883  |    0.017060     |   0\n",
      "      14080 |   0.248553  |    0.036971     |   0\n",
      "      14081 |   0.212670  |    0.012685     |   0\n",
      "      14082 |   0.173400  |    0.028685     |   0\n",
      "      14083 |   0.200087  |    0.132568     |   1\n",
      "      14084 |   0.257313  |    0.005807     |   0\n",
      "      14085 |   0.000046  |    0.033817     |   2\n",
      "      14086 |   0.200300  |    0.042192     |   0\n",
      "      14087 |   0.191593  |    0.029312     |   0\n",
      "      14088 |   0.203526  |    0.097002     |   1\n",
      "      14089 |   0.211824  |    0.101014     |   1\n",
      "      14090 |   0.201312  |    0.105487     |   1\n",
      "      14091 |   0.234415  |    0.131173     |   1\n",
      "      14092 |   0.000046  |    0.005178     |   2\n",
      "      14093 |   0.243179  |    0.009096     |   0\n",
      "      14094 |   0.209099  |    0.145389     |   1\n",
      "      14095 |   0.243721  |    0.051531     |   1\n",
      "      14096 |   0.189786  |    0.031906     |   0\n",
      "      14097 |   0.227025  |    0.100651     |   1\n",
      "      14098 |   0.000046  |    0.009513     |   2\n",
      "      14099 |   0.058401  |    0.028882     |   2\n",
      "      14100 |   0.253005  |    0.041422     |   0\n",
      "      14101 |   0.209069  |    0.036228     |   0\n",
      "      14102 |   0.215587  |    0.093077     |   1\n",
      "      14103 |   0.215433  |    0.025484     |   0\n",
      "      14104 |   0.053333  |    0.031501     |   2\n",
      "      14105 |   0.182826  |    0.023451     |   0\n",
      "      14106 |   0.220316  |    0.140299     |   1\n",
      "      14107 |   0.217128  |    0.002877     |   0\n",
      "      14108 |   0.189037  |    0.011416     |   0\n",
      "      14109 |   0.164504  |    0.049784     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 14110: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      14110 |   0.180018  |    0.067541     |   1\n",
      "      14111 |   0.152241  |    0.088110     |   1\n",
      "      14112 |   0.207115  |    0.010975     |   0\n",
      "      14113 |   0.062205  |    0.039049     |   2\n",
      "      14114 |   0.225328  |    0.085103     |   1\n",
      "      14115 |   0.045648  |    0.019176     |   2\n",
      "      14116 |   0.278124  |    0.150267     |   1\n",
      "      14117 |   0.206338  |    0.060942     |   1\n",
      "      14118 |   0.042443  |    0.012634     |   2\n",
      "      14119 |   0.052965  |    0.038962     |   2\n",
      "      14120 |   0.166688  |    0.082054     |   1\n",
      "      14121 |   0.196077  |    0.030398     |   0\n",
      "      14122 |   0.168139  |    0.127814     |   1\n",
      "      14123 |   0.235822  |    0.019124     |   0\n",
      "      14124 |   0.175507  |    0.132859     |   1\n",
      "      14125 |   0.031823  |    0.004586     |   2\n",
      "      14126 |   0.247680  |    0.032432     |   0\n",
      "      14127 |   0.196497  |    0.040692     |   0\n",
      "      14128 |   0.201350  |    0.013256     |   0\n",
      "      14129 |   0.046309  |    0.041378     |   2\n",
      "      14130 |   0.187126  |    0.081879     |   1\n",
      "      14131 |   0.057574  |    0.013940     |   2\n",
      "      14132 |   0.244167  |    0.052160     |   0\n",
      "      14133 |   0.063126  |    0.007062     |   2\n",
      "      14134 |   0.052738  |    0.042912     |   2\n",
      "      14135 |   0.188127  |    0.026123     |   0\n",
      "      14136 |   0.027755  |    0.028999     |   2\n",
      "      14137 |   0.279188  |    0.085881     |   1\n",
      "      14138 |   0.194746  |    0.038683     |   0\n",
      "      14139 |   0.148261  |    0.101706     |   1\n",
      "      14140 |   0.229501  |    0.139480     |   1\n",
      "      14141 | \u001b[94m  0.000045\u001b[0m  |    0.002919     |   2\n",
      "      14142 |   0.005980  |    0.010105     |   2\n",
      "      14143 |   0.227265  |    0.141183     |   1\n",
      "      14144 |   0.078809  |    0.009288     |   2\n",
      "      14145 |   0.039597  |    0.022731     |   2\n",
      "      14146 |   0.176175  |    0.045352     |   0\n",
      "      14147 |   0.186217  |    0.007854     |   0\n",
      "      14148 |   0.260355  |    0.054604     |   0\n",
      "      14149 |   0.223360  |    0.086242     |   1\n",
      "      14150 |   0.067659  |    0.023089     |   2\n",
      "      14151 |   0.052353  |    0.026212     |   2\n",
      "      14152 |   0.021278  |    0.026081     |   2\n",
      "      14153 |   0.229811  |    0.041019     |   0\n",
      "      14154 |   0.183460  |    0.011427     |   0\n",
      "      14155 |   0.049388  |    0.049489     |   2\n",
      "      14156 |   0.177882  |    0.008884     |   0\n",
      "      14157 |   0.177431  |    0.028669     |   0\n",
      "      14158 |   0.160458  |    0.045142     |   0\n",
      "      14159 |   0.247430  |    0.019624     |   0\n",
      "      14160 |   0.034435  |    0.024832     |   2\n",
      "      14161 |   0.250914  |    0.046546     |   0\n",
      "      14162 |   0.176167  |    0.019091     |   0\n",
      "      14163 |   0.184100  |    0.036251     |   0\n",
      "      14164 |   0.232641  |    0.145999     |   1\n",
      "      14165 |   0.215292  |    0.013343     |   1\n",
      "      14166 |   0.189049  |    0.038329     |   0\n",
      "      14167 |   0.000045  |    0.014331     |   2\n",
      "      14168 |   0.217539  |    0.045547     |   0\n",
      "      14169 |   0.000045  |    0.016009     |   2\n",
      "      14170 |   0.000045  |    0.037005     |   2\n",
      "      14171 |   0.000046  |    0.015956     |   2\n",
      "      14172 |   0.205273  |    0.060566     |   0\n",
      "      14173 |   0.251495  |    0.083789     |   1\n",
      "      14174 |   0.000045  |    0.006356     |   2\n",
      "      14175 |   0.000045  |    0.029736     |   2\n",
      "      14176 |   0.061854  |    0.042377     |   2\n",
      "      14177 |   0.055304  |    0.011903     |   2\n",
      "      14178 |   0.221829  |    0.050885     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 14179: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      14179 |   0.207749  |    0.075267     |   1\n",
      "      14180 |   0.059929  |    0.009524     |   2\n",
      "      14181 |   0.206640  |    0.047451     |   0\n",
      "      14182 |   0.043119  |    0.011140     |   2\n",
      "      14183 |   0.224429  |    0.044631     |   0\n",
      "      14184 |   0.214346  |    0.015435     |   0\n",
      "      14185 |   0.042430  |    0.028410     |   2\n",
      "      14186 |   0.187383  |    0.036432     |   0\n",
      "      14187 |   0.154062  |    0.016095     |   0\n",
      "      14188 |   0.184921  |    0.046389     |   0\n",
      "      14189 |   0.217597  |    0.098783     |   1\n",
      "      14190 |   0.056001  |    0.007668     |   2\n",
      "      14191 |   0.178602  |    0.041012     |   0\n",
      "      14192 |   0.214801  |    0.027153     |   0\n",
      "      14193 |   0.032902  |    0.027018     |   2\n",
      "      14194 |   0.251960  |    0.151745     |   1\n",
      "      14195 |   0.243164  |    0.065575     |   1\n",
      "      14196 |   0.194991  |    0.137998     |   1\n",
      "      14197 |   0.045096  |    0.011210     |   2\n",
      "      14198 |   0.060576  |    0.007521     |   2\n",
      "      14199 |   0.061139  |    0.039090     |   2\n",
      "      14200 |   0.050823  |    0.021213     |   2\n",
      "      14201 |   0.159344  |    0.147714     |   1\n",
      "      14202 |   0.278883  |    0.070891     |   1\n",
      "      14203 |   0.025190  |    0.008073     |   2\n",
      "      14204 |   0.000045  |    0.050723     |   2\n",
      "      14205 |   0.163163  |    0.092211     |   1\n",
      "      14206 |   0.007256  |    0.022708     |   2\n",
      "      14207 |   0.078045  |    0.055692     |   2\n",
      "      14208 |   0.039155  |    0.014340     |   2\n",
      "      14209 |   0.170985  |    0.091313     |   1\n",
      "      14210 |   0.213154  |    0.023768     |   0\n",
      "      14211 |   0.065643  |    0.033348     |   2\n",
      "      14212 |   0.294351  |    0.038856     |   0\n",
      "      14213 |   0.193465  |    0.049810     |   1\n",
      "      14214 |   0.198346  |    0.028133     |   0\n",
      "      14215 |   0.236657  |    0.037264     |   0\n",
      "      14216 |   0.051658  |    0.025657     |   2\n",
      "      14217 |   0.176364  |    0.039656     |   0\n",
      "      14218 |   0.259280  |    0.095843     |   1\n",
      "      14219 |   0.277934  |    0.072841     |   1\n",
      "      14220 |   0.022172  |    0.009419     |   2\n",
      "      14221 |   0.217997  |    0.045464     |   0\n",
      "      14222 |   0.046799  |    0.008281     |   2\n",
      "      14223 |   0.283687  |    0.156064     |   1\n",
      "      14224 |   0.213261  |    0.016948     |   0\n",
      "      14225 |   0.205597  |    0.068379     |   1\n",
      "      14226 |   0.236124  |    0.085463     |   1\n",
      "      14227 |   0.197602  |    0.018465     |   0\n",
      "      14228 |   0.255706  |    0.139898     |   1\n",
      "      14229 |   0.035617  |    0.004680     |   2\n",
      "      14230 | \u001b[94m  0.000045\u001b[0m  |    0.010184     |   2\n",
      "      14231 |   0.218089  |    0.032470     |   0\n",
      "      14232 | \u001b[94m  0.000045\u001b[0m  |    0.012851     |   2\n",
      "      14233 |   0.225941  |    0.047690     |   0\n",
      "      14234 | \u001b[94m  0.000045\u001b[0m  |    0.007797     |   2\n",
      "      14235 |   0.179381  |    0.048365     |   0\n",
      "      14236 |   0.000045  |    0.012546     |   2\n",
      "      14237 |   0.198491  |    0.038321     |   0\n",
      "      14238 |   0.000045  |    0.014002     |   2\n",
      "      14239 |   0.216741  |    0.145386     |   1\n",
      "      14240 |   0.244249  |    0.010077     |   0\n",
      "      14241 |   0.185857  |    0.102423     |   1\n",
      "      14242 | \u001b[94m  0.000045\u001b[0m  |    0.014852     |   2\n",
      "      14243 |   0.223550  |    0.136790     |   1\n",
      "      14244 |   0.358639  |    0.015555     |   0\n",
      "      14245 |   0.226382  |    0.087986     |   1\n",
      "      14246 |   0.218994  |    0.151081     |   1\n",
      "      14247 |   0.223802  |    0.006431     |   0\n",
      "      14248 |   0.219737  |    0.077835     |   1\n",
      "      14249 |   0.055842  |    0.016100     |   2\n",
      "      14250 |   0.054494  |    0.046722     |   2\n",
      "      14251 |   0.222585  |    0.119479     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 14253: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      14252 |   0.212907  |    0.003100     |   0\n",
      "      14253 |   0.059777  |    0.006196     |   2\n",
      "      14254 |   0.183457  |    0.055435     |   0\n",
      "      14255 |   0.245556  |    0.087991     |   1\n",
      "      14256 |   0.203702  |    0.129796     |   1\n",
      "      14257 |   0.042420  |    0.002946     |   2\n",
      "      14258 |   0.045596  |    0.005773     |   2\n",
      "      14259 |   0.261680  |    0.140013     |   1\n",
      "      14260 |   0.056271  |    0.008687     |   2\n",
      "      14261 |   0.030530  |    0.006849     |   2\n",
      "      14262 |   0.194469  |    0.045224     |   0\n",
      "      14263 |   0.046824  |    0.012776     |   2\n",
      "      14264 |   0.251118  |    0.048690     |   0\n",
      "      14265 |   0.264925  |    0.051148     |   1\n",
      "      14266 |   0.254994  |    0.022599     |   0\n",
      "      14267 |   0.183649  |    0.032091     |   0\n",
      "      14268 |   0.238947  |    0.100715     |   1\n",
      "      14269 |   0.280305  |    0.008616     |   0\n",
      "      14270 |   0.051923  |    0.025723     |   2\n",
      "      14271 |   0.264903  |    0.045544     |   0\n",
      "      14272 |   0.063803  |    0.005000     |   2\n",
      "      14273 |   0.052642  |    0.056284     |   2\n",
      "      14274 |   0.242184  |    0.095836     |   1\n",
      "      14275 |   0.221552  |    0.055549     |   1\n",
      "      14276 |   0.228514  |    0.092859     |   1\n",
      "      14277 |   0.025082  |    0.009668     |   2\n",
      "      14278 | \u001b[94m  0.000044\u001b[0m  |    0.054230     |   2\n",
      "      14279 |   0.151710  |    0.092084     |   1\n",
      "      14280 |   0.005982  |    0.005100     |   2\n",
      "      14281 |   0.178722  |    0.039265     |   0\n",
      "      14282 |   0.075457  |    0.021005     |   2\n",
      "      14283 |   0.223251  |    0.022220     |   0\n",
      "      14284 |   0.272860  |    0.034370     |   0\n",
      "      14285 |   0.040354  |    0.018561     |   2\n",
      "      14286 |   0.272807  |    0.033631     |   0\n",
      "      14287 |   0.206217  |    0.121611     |   1\n",
      "      14288 |   0.272846  |    0.076473     |   1\n",
      "      14289 |   0.061216  |    0.005342     |   2\n",
      "      14290 |   0.191119  |    0.024606     |   0\n",
      "      14291 |   0.194552  |    0.062361     |   0\n",
      "      14292 |   0.211827  |    0.092610     |   1\n",
      "      14293 |   0.050725  |    0.020431     |   2\n",
      "      14294 |   0.231557  |    0.143422     |   1\n",
      "      14295 |   0.233645  |    0.086260     |   1\n",
      "      14296 |   0.151682  |    0.046033     |   1\n",
      "      14297 |   0.197839  |    0.050870     |   0\n",
      "      14298 |   0.161271  |    0.082941     |   1\n",
      "      14299 |   0.198763  |    0.008490     |   0\n",
      "      14300 |   0.187123  |    0.033334     |   0\n",
      "      14301 |   0.205456  |    0.023941     |   0\n",
      "      14302 |   0.178192  |    0.047020     |   0\n",
      "      14303 |   0.184800  |    0.100519     |   1\n",
      "      14304 |   0.203561  |    0.088494     |   1\n",
      "      14305 |   0.197278  |    0.014398     |   0\n",
      "      14306 |   0.020969  |    0.047908     |   2\n",
      "      14307 |   0.169118  |    0.010795     |   0\n",
      "      14308 |   0.046667  |    0.073280     |   2\n",
      "      14309 |   0.178365  |    0.059171     |   1\n",
      "      14310 |   0.165768  |    0.031336     |   0\n",
      "      14311 |   0.036327  |    0.028395     |   2\n",
      "      14312 |   0.151978  |    0.023729     |   0\n",
      "      14313 | \u001b[94m  0.000044\u001b[0m  |    0.035955     |   2\n",
      "      14314 |   0.155173  |    0.147308     |   1\n",
      "      14315 |   0.190040  |    0.062981     |   1\n",
      "      14316 |   0.154211  |    0.014484     |   0\n",
      "      14317 |   0.000044  |    0.038452     |   2\n",
      "      14318 |   0.243952  |    0.094120     |   1\n",
      "      14319 |   0.000044  |    0.006468     |   2\n",
      "      14320 |   0.234887  |    0.129436     |   1\n",
      "      14321 |   0.285530  |    0.019924     |   0\n",
      "      14322 |   0.315902  |    0.135909     |   1\n",
      "      14323 |   0.234734  |    0.007905     |   0\n",
      "      14324 |   0.000044  |    0.007926     |   2\n",
      "      14325 |   0.000044  |    0.034391     |   2\n",
      "      14326 |   0.173376  |    0.030472     |   0\n",
      "      14327 | \u001b[94m  0.000044\u001b[0m  |    0.037850     |   2\n",
      "      14328 |   0.229258  |    0.091904     |   1\n",
      "      14329 |   0.218322  |    0.032172     |   0\n",
      "      14330 |   0.277458  |    0.148370     |   1\n",
      "      14331 |   0.061048  |    0.020196     |   2\n",
      "      14332 |   0.271866  |    0.051023     |   1\n",
      "      14333 |   0.248471  |    0.087205     |   1\n",
      "      14334 |   0.240024  |    0.026752     |   0\n",
      "      14335 |   0.184465  |    0.035558     |   0\n",
      "      14336 |   0.175855  |    0.089111     |   1\n",
      "      14337 |   0.171598  |    0.015424     |   0\n",
      "      14338 |   0.053580  |    0.021609     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 14340: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      14339 |   0.168072  |    0.029948     |   0\n",
      "      14340 |   0.060108  |    0.014666     |   2\n",
      "      14341 |   0.180665  |    0.073076     |   1\n",
      "      14342 |   0.045926  |    0.014819     |   2\n",
      "      14343 |   0.191785  |    0.042061     |   0\n",
      "      14344 |   0.267061  |    0.074094     |   1\n",
      "      14345 |   0.044338  |    0.005682     |   2\n",
      "      14346 |   0.214894  |    0.065352     |   0\n",
      "      14347 |   0.172795  |    0.010983     |   0\n",
      "      14348 |   0.052576  |    0.035962     |   2\n",
      "      14349 |   0.195638  |    0.027498     |   0\n",
      "      14350 |   0.150354  |    0.042998     |   0\n",
      "      14351 |   0.180284  |    0.078257     |   1\n",
      "      14352 |   0.031104  |    0.041662     |   2\n",
      "      14353 |   0.044306  |    0.038509     |   2\n",
      "      14354 |   0.164513  |    0.095811     |   1\n",
      "      14355 |   0.057271  |    0.012057     |   2\n",
      "      14356 |   0.062927  |    0.037961     |   2\n",
      "      14357 |   0.142091  |    0.044323     |   0\n",
      "      14358 |   0.224805  |    0.071963     |   1\n",
      "      14359 |   0.053311  |    0.007473     |   2\n",
      "      14360 |   0.214989  |    0.127094     |   1\n",
      "      14361 |   0.228260  |    0.024907     |   0\n",
      "      14362 |   0.261667  |    0.099751     |   1\n",
      "      14363 |   0.211676  |    0.012233     |   0\n",
      "      14364 |   0.283394  |    0.108628     |   1\n",
      "      14365 |   0.227996  |    0.103115     |   1\n",
      "      14366 |   0.025684  |    0.011262     |   2\n",
      "      14367 |   0.000044  |    0.041607     |   2\n",
      "      14368 |   0.252033  |    0.093352     |   1\n",
      "      14369 |   0.171893  |    0.022465     |   0\n",
      "      14370 |   0.210779  |    0.064604     |   0\n",
      "      14371 |   0.231370  |    0.077461     |   1\n",
      "      14372 |   0.143616  |    0.069937     |   1\n",
      "      14373 |   0.238993  |    0.090892     |   1\n",
      "      14374 |   0.006295  |    0.032021     |   2\n",
      "      14375 |   0.199555  |    0.092769     |   1\n",
      "      14376 |   0.255735  |    0.010180     |   0\n",
      "      14377 |   0.233515  |    0.015087     |   0\n",
      "      14378 |   0.226773  |    0.041644     |   0\n",
      "      14379 |   0.077926  |    0.024742     |   2\n",
      "      14380 |   0.181662  |    0.138398     |   1\n",
      "      14381 |   0.235297  |    0.009726     |   0\n",
      "      14382 |   0.038594  |    0.006346     |   2\n",
      "      14383 |   0.182718  |    0.044777     |   0\n",
      "      14384 |   0.196493  |    0.014054     |   0\n",
      "      14385 |   0.059588  |    0.028623     |   2\n",
      "      14386 |   0.228106  |    0.032306     |   0\n",
      "      14387 |   0.050728  |    0.029636     |   2\n",
      "      14388 |   0.238611  |    0.030462     |   0\n",
      "      14389 |   0.172962  |    0.152925     |   1\n",
      "      14390 |   0.022230  |    0.003032     |   2\n",
      "      14391 |   0.044168  |    0.011772     |   2\n",
      "      14392 |   0.223134  |    0.158084     |   1\n",
      "      14393 |   0.035924  |    0.008122     |   2\n",
      "      14394 |   0.222063  |    0.080462     |   1\n",
      "      14395 | \u001b[94m  0.000043\u001b[0m  |    0.010145     |   2\n",
      "      14396 |   0.219049  |    0.060537     |   0\n",
      "      14397 |   0.200467  |    0.054245     |   1\n",
      "      14398 |   0.202392  |    0.023279     |   0\n",
      "      14399 | \u001b[94m  0.000043\u001b[0m  |    0.027364     |   2\n",
      "      14400 | \u001b[94m  0.000043\u001b[0m  |    0.024209     |   2\n",
      "      14401 |   0.000043  |    0.035111     |   2\n",
      "      14402 |   0.274727  |    0.120462     |   1\n",
      "      14403 |   0.143699  |    0.085802     |   1\n",
      "      14404 |   0.000043  |    0.006830     |   2\n",
      "      14405 | \u001b[94m  0.000043\u001b[0m  |    0.046399     |   2\n",
      "      14406 |   0.056366  |    0.014340     |   2\n",
      "      14407 |   0.052168  |    0.040700     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 14409: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      14408 |   0.194406  |    0.016089     |   0\n",
      "      14409 |   0.056605  |    0.026266     |   2\n",
      "      14410 |   0.042570  |    0.013593     |   2\n",
      "      14411 |   0.177221  |    0.136350     |   1\n",
      "      14412 |   0.155129  |    0.005705     |   0\n",
      "      14413 |   0.176974  |    0.020696     |   0\n",
      "      14414 |   0.202715  |    0.129027     |   1\n",
      "      14415 |   0.223787  |    0.093143     |   1\n",
      "      14416 |   0.233716  |    0.021950     |   0\n",
      "      14417 |   0.210253  |    0.153369     |   1\n",
      "      14418 |   0.245795  |    0.033356     |   1\n",
      "      14419 |   0.042266  |    0.043161     |   2\n",
      "      14420 |   0.166896  |    0.093615     |   1\n",
      "      14421 |   0.052086  |    0.013027     |   2\n",
      "      14422 |   0.208066  |    0.155127     |   1\n",
      "      14423 |   0.031449  |    0.010916     |   2\n",
      "      14424 |   0.230597  |    0.088256     |   1\n",
      "      14425 |   0.160108  |    0.077475     |   1\n",
      "      14426 |   0.046276  |    0.008653     |   2\n",
      "      14427 |   0.208893  |    0.147710     |   1\n",
      "      14428 |   0.143454  |    0.002878     |   0\n",
      "      14429 |   0.222197  |    0.004454     |   0\n",
      "      14430 |   0.201169  |    0.051103     |   0\n",
      "      14431 |   0.053480  |    0.007487     |   2\n",
      "      14432 |   0.221318  |    0.045184     |   0\n",
      "      14433 |   0.063531  |    0.009326     |   2\n",
      "      14434 |   0.242561  |    0.040601     |   0\n",
      "      14435 |   0.206422  |    0.017696     |   0\n",
      "      14436 |   0.190044  |    0.051711     |   0\n",
      "      14437 |   0.201913  |    0.090197     |   1\n",
      "      14438 |   0.239870  |    0.080620     |   1\n",
      "      14439 |   0.244522  |    0.009257     |   0\n",
      "      14440 |   0.193830  |    0.038160     |   0\n",
      "      14441 |   0.152054  |    0.108153     |   1\n",
      "      14442 |   0.057156  |    0.008372     |   2\n",
      "      14443 |   0.214262  |    0.037322     |   0\n",
      "      14444 |   0.239307  |    0.099632     |   1\n",
      "      14445 |   0.027535  |    0.009412     |   2\n",
      "      14446 |   0.222866  |    0.042734     |   0\n",
      "      14447 |   0.239161  |    0.007145     |   0\n",
      "      14448 |   0.196475  |    0.040811     |   0\n",
      "      14449 | \u001b[94m  0.000043\u001b[0m  |    0.017555     |   2\n",
      "      14450 |   0.227296  |    0.027792     |   0\n",
      "      14451 |   0.192783  |    0.136200     |   1\n",
      "      14452 |   0.007254  |    0.003234     |   2\n",
      "      14453 |   0.078912  |    0.008395     |   2\n",
      "      14454 |   0.042544  |    0.041998     |   2\n",
      "      14455 |   0.062542  |    0.006719     |   2\n",
      "      14456 |   0.256275  |    0.127201     |   1\n",
      "      14457 |   0.053082  |    0.005693     |   2\n",
      "      14458 |   0.024424  |    0.022717     |   2\n",
      "      14459 |   0.193949  |    0.034370     |   0\n",
      "      14460 |   0.233629  |    0.107823     |   1\n",
      "      14461 |   0.143847  |    0.090556     |   1\n",
      "      14462 |   0.209232  |    0.024448     |   0\n",
      "      14463 |   0.181364  |    0.026203     |   0\n",
      "      14464 |   0.244072  |    0.077896     |   1\n",
      "      14465 |   0.180361  |    0.041760     |   0\n",
      "      14466 |   0.243878  |    0.035677     |   0\n",
      "      14467 |   0.280095  |    0.082129     |   1\n",
      "      14468 |   0.250882  |    0.009069     |   0\n",
      "      14469 |   0.186537  |    0.043715     |   0\n",
      "      14470 |   0.191112  |    0.010209     |   0\n",
      "      14471 |   0.048181  |    0.031728     |   2\n",
      "      14472 |   0.036972  |    0.026001     |   2\n",
      "      14473 |   0.266503  |    0.112924     |   1\n",
      "      14474 |   0.000043  |    0.016840     |   2\n",
      "      14475 |   0.215638  |    0.154511     |   1\n",
      "      14476 |   0.000043  |    0.010337     |   2\n",
      "      14477 |   0.000043  |    0.012386     |   2\n",
      "      14478 |   0.172006  |    0.113899     |   1\n",
      "      14479 |   0.191319  |    0.054545     |   1\n",
      "      14480 |   0.219734  |    0.026670     |   0\n",
      "      14481 |   0.225482  |    0.152405     |   1\n",
      "      14482 |   0.240597  |    0.044501     |   1\n",
      "      14483 |   0.145232  |    0.024251     |   0\n",
      "      14484 |   0.198136  |    0.015444     |   0\n",
      "      14485 |   0.158153  |    0.055393     |   0\n",
      "      14486 |   0.000043  |    0.004024     |   2\n",
      "      14487 |   0.164227  |    0.042712     |   0\n",
      "      14488 |   0.000043  |    0.013415     |   2\n",
      "      14489 |   0.000043  |    0.031994     |   2\n",
      "      14490 |   0.211775  |    0.028277     |   0\n",
      "      14491 |   0.058156  |    0.026816     |   2\n",
      "      14492 |   0.054554  |    0.012182     |   2\n",
      "      14493 |   0.216642  |    0.081520     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 14494: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      14494 |   0.245235  |    0.130911     |   1\n",
      "      14495 |   0.058941  |    0.004999     |   2\n",
      "      14496 |   0.151798  |    0.015902     |   0\n",
      "      14497 |   0.222985  |    0.159724     |   1\n",
      "      14498 |   0.044315  |    0.011759     |   2\n",
      "      14499 |   0.219109  |    0.078008     |   1\n",
      "      14500 |   0.178948  |    0.004721     |   0\n",
      "      14501 |   0.057474  |    0.055137     |   2\n",
      "      14502 |   0.251187  |    0.099263     |   1\n",
      "      14503 |   0.042900  |    0.005226     |   2\n",
      "      14504 |   0.211241  |    0.051716     |   0\n",
      "      14505 |   0.221429  |    0.078997     |   1\n",
      "      14506 |   0.182122  |    0.007111     |   0\n",
      "      14507 |   0.199210  |    0.052299     |   0\n",
      "      14508 |   0.227015  |    0.104692     |   1\n",
      "      14509 |   0.212883  |    0.089557     |   1\n",
      "      14510 |   0.221296  |    0.076276     |   1\n",
      "      14511 |   0.043561  |    0.008417     |   2\n",
      "      14512 |   0.209309  |    0.028262     |   0\n",
      "      14513 |   0.178293  |    0.035984     |   0\n",
      "      14514 |   0.169366  |    0.084576     |   1\n",
      "      14515 |   0.052333  |    0.029558     |   2\n",
      "      14516 |   0.031137  |    0.035201     |   2\n",
      "      14517 |   0.045135  |    0.016040     |   2\n",
      "      14518 |   0.211857  |    0.147062     |   1\n",
      "      14519 |   0.205178  |    0.104265     |   1\n",
      "      14520 |   0.211890  |    0.035863     |   1\n",
      "      14521 |   0.052639  |    0.054403     |   2\n",
      "      14522 |   0.176659  |    0.127163     |   1\n",
      "      14523 |   0.269543  |    0.032651     |   1\n",
      "      14524 |   0.066428  |    0.037871     |   2\n",
      "      14525 |   0.162940  |    0.014335     |   0\n",
      "      14526 |   0.203436  |    0.042677     |   0\n",
      "      14527 |   0.194575  |    0.020259     |   0\n",
      "      14528 |   0.224668  |    0.029214     |   0\n",
      "      14529 |   0.053661  |    0.026868     |   2\n",
      "      14530 |   0.210397  |    0.027275     |   0\n",
      "      14531 |   0.245196  |    0.031614     |   0\n",
      "      14532 |   0.280175  |    0.162198     |   1\n",
      "      14533 |   0.176147  |    0.084494     |   1\n",
      "      14534 |   0.163900  |    0.011550     |   0\n",
      "      14535 |   0.024890  |    0.016531     |   2\n",
      "      14536 |   0.178417  |    0.026858     |   0\n",
      "      14537 |   0.242735  |    0.094292     |   1\n",
      "      14538 |   0.195926  |    0.012099     |   0\n",
      "      14539 |   0.196015  |    0.141036     |   1\n",
      "      14540 |   0.230467  |    0.053645     |   1\n",
      "      14541 |   0.000043  |    0.011976     |   2\n",
      "      14542 |   0.187595  |    0.129023     |   1\n",
      "      14543 |   0.006159  |    0.010647     |   2\n",
      "      14544 |   0.251200  |    0.140338     |   1\n",
      "      14545 |   0.224186  |    0.013981     |   0\n",
      "      14546 |   0.129202  |    0.090664     |   1\n",
      "      14547 |   0.149231  |    0.035353     |   0\n",
      "      14548 |   0.229382  |    0.141851     |   1\n",
      "      14549 |   0.077411  |    0.002961     |   2\n",
      "      14550 |   0.212943  |    0.011883     |   0\n",
      "      14551 |   0.221291  |    0.136321     |   1\n",
      "      14552 |   0.180280  |    0.089116     |   1\n",
      "      14553 |   0.214058  |    0.089286     |   1\n",
      "      14554 |   0.156895  |    0.009248     |   0\n",
      "      14555 |   0.137599  |    0.026847     |   0\n",
      "      14556 |   0.202740  |    0.050769     |   0\n",
      "      14557 |   0.040226  |    0.011553     |   2\n",
      "      14558 |   0.207810  |    0.124537     |   1\n",
      "      14559 |   0.176456  |    0.014644     |   0\n",
      "      14560 |   0.060713  |    0.022178     |   2\n",
      "      14561 |   0.049500  |    0.010176     |   2\n",
      "      14562 |   0.023710  |    0.032196     |   2\n",
      "      14563 |   0.236515  |    0.088022     |   1\n",
      "      14564 |   0.180840  |    0.025386     |   0\n",
      "      14565 |   0.222297  |    0.037128     |   0\n",
      "      14566 |   0.047628  |    0.017265     |   2\n",
      "      14567 |   0.168209  |    0.029015     |   0\n",
      "      14568 |   0.037180  |    0.020182     |   2\n",
      "      14569 |   0.000043  |    0.016540     |   2\n",
      "      14570 |   0.187471  |    0.027107     |   0\n",
      "      14571 |   0.211964  |    0.083139     |   1\n",
      "      14572 |   0.000043  |    0.004929     |   2\n",
      "      14573 |   0.230990  |    0.142682     |   1\n",
      "      14574 |   0.192672  |    0.084991     |   1\n",
      "      14575 |   0.193071  |    0.088539     |   1\n",
      "      14576 |   0.211896  |    0.010323     |   0\n",
      "      14577 |   0.000043  |    0.031956     |   2\n",
      "      14578 |   0.215233  |    0.031388     |   0\n",
      "      14579 |   0.222137  |    0.019707     |   0\n",
      "      14580 |   0.176833  |    0.137617     |   1\n",
      "      14581 |   0.000044  |    0.005603     |   2\n",
      "      14582 |   0.000043  |    0.025921     |   2\n",
      "      14583 |   0.182587  |    0.033467     |   0\n",
      "      14584 |   0.000043  |    0.010835     |   2\n",
      "      14585 |   0.051955  |    0.042240     |   2\n",
      "      14586 |   0.186346  |    0.031201     |   0\n",
      "      14587 |   0.160000  |    0.162230     |   1\n",
      "      14588 |   0.217843  |    0.051647     |   1\n",
      "      14589 |   0.230713  |    0.084321     |   1\n",
      "      14590 |   0.181816  |    0.008064     |   0\n",
      "      14591 |   0.149600  |    0.022929     |   0\n",
      "      14592 |   0.227550  |    0.164685     |   1\n",
      "      14593 |   0.224708  |    0.032276     |   1\n",
      "      14594 |   0.195138  |    0.140891     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 14596: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      14595 |   0.053167  |    0.005958     |   2\n",
      "      14596 |   0.237367  |    0.005836     |   0\n",
      "      14597 |   0.055449  |    0.040665     |   2\n",
      "      14598 |   0.040632  |    0.026016     |   2\n",
      "      14599 |   0.333609  |    0.130114     |   1\n",
      "      14600 |   0.042951  |    0.003438     |   2\n",
      "      14601 |   0.179487  |    0.005771     |   0\n",
      "      14602 |   0.052576  |    0.042940     |   2\n",
      "      14603 |   0.246870  |    0.012785     |   0\n",
      "      14604 |   0.204341  |    0.150709     |   1\n",
      "      14605 |   0.214128  |    0.090805     |   1\n",
      "      14606 |   0.230533  |    0.004857     |   0\n",
      "      14607 |   0.030723  |    0.014693     |   2\n",
      "      14608 |   0.197972  |    0.027762     |   0\n",
      "      14609 |   0.263155  |    0.109818     |   1\n",
      "      14610 |   0.043973  |    0.004711     |   2\n",
      "      14611 |   0.258010  |    0.036922     |   0\n",
      "      14612 |   0.055318  |    0.022901     |   2\n",
      "      14613 |   0.277700  |    0.126534     |   1\n",
      "      14614 |   0.167510  |    0.109517     |   1\n",
      "      14615 |   0.064717  |    0.005808     |   2\n",
      "      14616 |   0.243443  |    0.112021     |   1\n",
      "      14617 |   0.252303  |    0.012632     |   0\n",
      "      14618 |   0.186325  |    0.091473     |   1\n",
      "      14619 |   0.053605  |    0.007788     |   2\n",
      "      14620 |   0.231439  |    0.041975     |   0\n",
      "      14621 |   0.202432  |    0.028366     |   0\n",
      "      14622 |   0.148383  |    0.149047     |   1\n",
      "      14623 |   0.147422  |    0.003751     |   0\n",
      "      14624 |   0.024814  |    0.017730     |   2\n",
      "      14625 |   0.216609  |    0.139786     |   1\n",
      "      14626 |   0.000043  |    0.004266     |   2\n",
      "      14627 |   0.154721  |    0.019192     |   0\n",
      "      14628 |   0.215969  |    0.121768     |   1\n",
      "      14629 |   0.006696  |    0.006394     |   2\n",
      "      14630 |   0.207190  |    0.027615     |   0\n",
      "      14631 |   0.187795  |    0.027081     |   0\n",
      "      14632 |   0.224531  |    0.041799     |   0\n",
      "      14633 |   0.210684  |    0.090605     |   1\n",
      "      14634 |   0.183921  |    0.019576     |   0\n",
      "      14635 |   0.250882  |    0.150046     |   1\n",
      "      14636 |   0.228086  |    0.099023     |   1\n",
      "      14637 |   0.215476  |    0.058820     |   1\n",
      "      14638 |   0.206345  |    0.014844     |   0\n",
      "      14639 |   0.221733  |    0.150350     |   1\n",
      "      14640 |   0.209328  |    0.002989     |   0\n",
      "      14641 |   0.076220  |    0.015014     |   2\n",
      "      14642 |   0.284877  |    0.142217     |   1\n",
      "      14643 |   0.211614  |    0.002957     |   0\n",
      "      14644 |   0.039164  |    0.006897     |   2\n",
      "      14645 |   0.060722  |    0.048494     |   2\n",
      "      14646 |   0.050877  |    0.018979     |   2\n",
      "      14647 |   0.025093  |    0.038014     |   2\n",
      "      14648 |   0.221867  |    0.082844     |   1\n",
      "      14649 |   0.047283  |    0.036297     |   2\n",
      "      14650 |   0.252399  |    0.085799     |   1\n",
      "      14651 |   0.215480  |    0.028019     |   0\n",
      "      14652 |   0.238253  |    0.023383     |   0\n",
      "      14653 |   0.188722  |    0.062263     |   0\n",
      "      14654 |   0.215639  |    0.058828     |   1\n",
      "      14655 |   0.224558  |    0.089435     |   1\n",
      "      14656 |   0.035990  |    0.017917     |   2\n",
      "      14657 |   0.234788  |    0.107879     |   1\n",
      "      14658 |   0.226807  |    0.093289     |   1\n",
      "      14659 |   0.251294  |    0.112327     |   1\n",
      "      14660 |   0.000043  |    0.009268     |   2\n",
      "      14661 |   0.197321  |    0.033972     |   1\n",
      "      14662 |   0.172630  |    0.032011     |   0\n",
      "      14663 |   0.000043  |    0.009594     |   2\n",
      "      14664 |   0.212589  |    0.048272     |   0\n",
      "      14665 |   0.235272  |    0.018504     |   0\n",
      "      14666 |   0.216409  |    0.043445     |   0\n",
      "      14667 |   0.000043  |    0.010745     |   2\n",
      "      14668 |   0.000044  |    0.026199     |   2\n",
      "      14669 |   0.000043  |    0.035843     |   2\n",
      "      14670 |   0.000043  |    0.011689     |   2\n",
      "      14671 |   0.185821  |    0.042016     |   0\n",
      "      14672 |   0.054755  |    0.012927     |   2\n",
      "      14673 |   0.238966  |    0.050865     |   0\n",
      "      14674 |   0.173080  |    0.012964     |   0\n",
      "      14675 |   0.052745  |    0.030241     |   2\n",
      "      14676 |   0.241323  |    0.031200     |   0\n",
      "      14677 |   0.193089  |    0.023313     |   0\n",
      "      14678 |   0.194800  |    0.050187     |   0\n",
      "      14679 |   0.190311  |    0.134420     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 14681: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      14680 |   0.169164  |    0.004432     |   0\n",
      "      14681 |   0.175588  |    0.006425     |   0\n",
      "      14682 |   0.237626  |    0.022127     |   0\n",
      "      14683 |   0.058442  |    0.030386     |   2\n",
      "      14684 |   0.209147  |    0.145118     |   1\n",
      "      14685 |   0.240325  |    0.022162     |   0\n",
      "      14686 |   0.165282  |    0.078892     |   1\n",
      "      14687 |   0.041909  |    0.005128     |   2\n",
      "      14688 |   0.043898  |    0.025341     |   2\n",
      "      14689 |   0.205513  |    0.047759     |   0\n",
      "      14690 |   0.210373  |    0.017118     |   0\n",
      "      14691 |   0.055065  |    0.029536     |   2\n",
      "      14692 |   0.171244  |    0.033049     |   0\n",
      "      14693 |   0.185128  |    0.032848     |   0\n",
      "      14694 |   0.031473  |    0.030932     |   2\n",
      "      14695 |   0.044936  |    0.026565     |   2\n",
      "      14696 |   0.060229  |    0.025831     |   2\n",
      "      14697 |   0.209222  |    0.029075     |   0\n",
      "      14698 |   0.065910  |    0.024161     |   2\n",
      "      14699 |   0.207495  |    0.129350     |   1\n",
      "      14700 |   0.161101  |    0.004599     |   0\n",
      "      14701 |   0.182819  |    0.032947     |   0\n",
      "      14702 |   0.174491  |    0.025961     |   0\n",
      "      14703 |   0.241551  |    0.037446     |   0\n",
      "      14704 |   0.195683  |    0.088365     |   1\n",
      "      14705 |   0.232444  |    0.016974     |   0\n",
      "      14706 |   0.052073  |    0.030487     |   2\n",
      "      14707 |   0.025777  |    0.028077     |   2\n",
      "      14708 |   0.186646  |    0.024741     |   0\n",
      "      14709 |   0.159288  |    0.042429     |   0\n",
      "      14710 |   0.000043  |    0.022263     |   2\n",
      "      14711 |   0.269977  |    0.082434     |   1\n",
      "      14712 |   0.147109  |    0.011720     |   0\n",
      "      14713 |   0.186815  |    0.031675     |   0\n",
      "      14714 |   0.006945  |    0.016206     |   2\n",
      "      14715 |   0.076039  |    0.034575     |   2\n",
      "      14716 |   0.039258  |    0.022534     |   2\n",
      "      14717 |   0.184158  |    0.150642     |   1\n",
      "      14718 |   0.063736  |    0.002937     |   2\n",
      "      14719 |   0.194495  |    0.005835     |   0\n",
      "      14720 |   0.147626  |    0.047327     |   0\n",
      "      14721 |   0.053655  |    0.009850     |   2\n",
      "      14722 |   0.236762  |    0.047666     |   0\n",
      "      14723 |   0.024134  |    0.019772     |   2\n",
      "      14724 |   0.046113  |    0.035511     |   2\n",
      "      14725 |   0.249545  |    0.135753     |   1\n",
      "      14726 |   0.213039  |    0.060535     |   1\n",
      "      14727 |   0.038682  |    0.020583     |   2\n",
      "      14728 |   0.000043  |    0.034947     |   2\n",
      "      14729 |   0.203195  |    0.155635     |   1\n",
      "      14730 |   0.000044  |    0.015832     |   2\n",
      "      14731 |   0.219414  |    0.058357     |   1\n",
      "      14732 |   0.000044  |    0.015287     |   2\n",
      "      14733 |   0.000044  |    0.027717     |   2\n",
      "      14734 |   0.000044  |    0.027479     |   2\n",
      "      14735 |   0.181541  |    0.041130     |   0\n",
      "      14736 |   0.162671  |    0.011657     |   0\n",
      "      14737 |   0.181605  |    0.155618     |   1\n",
      "      14738 |   0.000044  |    0.005719     |   2\n",
      "      14739 |   0.235327  |    0.078927     |   1\n",
      "      14740 |   0.056834  |    0.029975     |   2\n",
      "      14741 |   0.054169  |    0.024850     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 14742: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      14742 |   0.173513  |    0.018157     |   0\n",
      "      14743 |   0.159335  |    0.042347     |   0\n",
      "      14744 |   0.050063  |    0.012117     |   2\n",
      "      14745 |   0.238545  |    0.144477     |   1\n",
      "      14746 |   0.178430  |    0.002849     |   0\n",
      "      14747 |   0.037687  |    0.014376     |   2\n",
      "      14748 |   0.041638  |    0.027186     |   2\n",
      "      14749 |   0.213548  |    0.081271     |   1\n",
      "      14750 |   0.249495  |    0.021482     |   0\n",
      "      14751 |   0.181143  |    0.029515     |   0\n",
      "      14752 |   0.051720  |    0.026207     |   2\n",
      "      14753 |   0.192340  |    0.136694     |   1\n",
      "      14754 |   0.205311  |    0.059170     |   1\n",
      "      14755 |   0.275013  |    0.028704     |   0\n",
      "      14756 |   0.209541  |    0.015634     |   0\n",
      "      14757 |   0.196580  |    0.017029     |   0\n",
      "      14758 |   0.309906  |    0.098905     |   1\n",
      "      14759 |   0.030926  |    0.030360     |   2\n",
      "      14760 |   0.209752  |    0.146575     |   1\n",
      "      14761 |   0.042242  |    0.004404     |   2\n",
      "      14762 |   0.058696  |    0.003569     |   2\n",
      "      14763 |   0.219975  |    0.028137     |   0\n",
      "      14764 |   0.249840  |    0.134232     |   1\n",
      "      14765 |   0.202696  |    0.003530     |   0\n",
      "      14766 |   0.222321  |    0.005887     |   0\n",
      "      14767 |   0.154822  |    0.047229     |   0\n",
      "      14768 |   0.178831  |    0.088435     |   1\n",
      "      14769 |   0.248198  |    0.024564     |   0\n",
      "      14770 |   0.171603  |    0.017448     |   0\n",
      "      14771 |   0.176638  |    0.028538     |   0\n",
      "      14772 |   0.064914  |    0.026681     |   2\n",
      "      14773 |   0.237338  |    0.052778     |   0\n",
      "      14774 |   0.260422  |    0.094259     |   1\n",
      "      14775 |   0.052340  |    0.005096     |   2\n",
      "      14776 |   0.231184  |    0.043785     |   0\n",
      "      14777 |   0.025325  |    0.015531     |   2\n",
      "      14778 |   0.000043  |    0.030602     |   2\n",
      "      14779 |   0.006379  |    0.036911     |   2\n",
      "      14780 |   0.077808  |    0.029642     |   2\n",
      "      14781 |   0.177436  |    0.037357     |   0\n",
      "      14782 |   0.040583  |    0.014087     |   2\n",
      "      14783 |   0.159996  |    0.051402     |   0\n",
      "      14784 |   0.064944  |    0.013095     |   2\n",
      "      14785 |   0.227715  |    0.031465     |   0\n",
      "      14786 |   0.221205  |    0.131043     |   1\n",
      "      14787 |   0.243037  |    0.130183     |   1\n",
      "      14788 |   0.050752  |    0.007035     |   2\n",
      "      14789 |   0.207420  |    0.057082     |   0\n",
      "      14790 |   0.212506  |    0.093985     |   1\n",
      "      14791 |   0.198279  |    0.078260     |   1\n",
      "      14792 |   0.185079  |    0.024365     |   0\n",
      "      14793 |   0.181072  |    0.017783     |   0\n",
      "      14794 |   0.226912  |    0.095605     |   1\n",
      "      14795 |   0.326368  |    0.142588     |   1\n",
      "      14796 |   0.155654  |    0.057252     |   1\n",
      "      14797 |   0.023850  |    0.010277     |   2\n",
      "      14798 |   0.163248  |    0.045805     |   0\n",
      "      14799 |   0.044731  |    0.012084     |   2\n",
      "      14800 |   0.164757  |    0.142296     |   1\n",
      "      14801 |   0.037564  |    0.003921     |   2\n",
      "      14802 |   0.000043  |    0.013330     |   2\n",
      "      14803 |   0.000043  |    0.032132     |   2\n",
      "      14804 |   0.000043  |    0.044318     |   2\n",
      "      14805 |   0.184084  |    0.027799     |   0\n",
      "      14806 |   0.222930  |    0.150753     |   1\n",
      "      14807 |   0.226640  |    0.082167     |   1\n",
      "      14808 |   0.183500  |    0.026966     |   0\n",
      "      14809 |   0.182213  |    0.144171     |   1\n",
      "      14810 |   0.000044  |    0.002983     |   2\n",
      "      14811 |   0.000043  |    0.015912     |   2\n",
      "      14812 |   0.000043  |    0.021957     |   2\n",
      "      14813 |   0.151109  |    0.027232     |   0\n",
      "      14814 |   0.056721  |    0.042343     |   2\n",
      "      14815 |   0.185342  |    0.083208     |   1\n",
      "      14816 |   0.210689  |    0.135860     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 14818: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      14817 |   0.052617  |    0.002948     |   2\n",
      "      14818 |   0.056322  |    0.011907     |   2\n",
      "      14819 |   0.243639  |    0.139249     |   1\n",
      "      14820 |   0.041052  |    0.008528     |   2\n",
      "      14821 |   0.044688  |    0.036524     |   2\n",
      "      14822 |   0.171996  |    0.028057     |   0\n",
      "      14823 |   0.053037  |    0.027822     |   2\n",
      "      14824 |   0.030319  |    0.028636     |   2\n",
      "      14825 |   0.178654  |    0.148559     |   1\n",
      "      14826 |   0.240010  |    0.063529     |   1\n",
      "      14827 |   0.305420  |    0.091864     |   1\n",
      "      14828 |   0.044366  |    0.013825     |   2\n",
      "      14829 |   0.211416  |    0.043629     |   0\n",
      "      14830 |   0.267309  |    0.133808     |   1\n",
      "      14831 |   0.226110  |    0.002890     |   0\n",
      "      14832 |   0.053176  |    0.006386     |   2\n",
      "      14833 |   0.155796  |    0.153496     |   1\n",
      "      14834 |   0.246836  |    0.089249     |   1\n",
      "      14835 |   0.191971  |    0.011287     |   0\n",
      "      14836 |   0.278654  |    0.146987     |   1\n",
      "      14837 |   0.227934  |    0.002867     |   0\n",
      "      14838 |   0.062451  |    0.007466     |   2\n",
      "      14839 |   0.185241  |    0.040210     |   0\n",
      "      14840 |   0.227879  |    0.019274     |   0\n",
      "      14841 |   0.051768  |    0.029055     |   2\n",
      "      14842 |   0.214009  |    0.092310     |   1\n",
      "      14843 |   0.024745  |    0.019293     |   2\n",
      "      14844 |   0.000043  |    0.040860     |   2\n",
      "      14845 |   0.193225  |    0.012531     |   0\n",
      "      14846 |   0.172225  |    0.059070     |   0\n",
      "      14847 |   0.217141  |    0.086351     |   1\n",
      "      14848 |   0.007731  |    0.010646     |   2\n",
      "      14849 |   0.075496  |    0.013188     |   2\n",
      "      14850 |   0.144961  |    0.027472     |   0\n",
      "      14851 |   0.248520  |    0.037881     |   0\n",
      "      14852 |   0.212938  |    0.130432     |   1\n",
      "      14853 |   0.165689  |    0.011109     |   0\n",
      "      14854 |   0.038531  |    0.010844     |   2\n",
      "      14855 |   0.204318  |    0.041717     |   0\n",
      "      14856 |   0.256845  |    0.015464     |   0\n",
      "      14857 |   0.210019  |    0.050618     |   0\n",
      "      14858 |   0.062522  |    0.006927     |   2\n",
      "      14859 |   0.053255  |    0.055146     |   2\n",
      "      14860 |   0.280806  |    0.097596     |   1\n",
      "      14861 |   0.169757  |    0.091219     |   1\n",
      "      14862 |   0.022699  |    0.005894     |   2\n",
      "      14863 |   0.166192  |    0.042548     |   0\n",
      "      14864 |   0.139347  |    0.025471     |   0\n",
      "      14865 |   0.259525  |    0.134884     |   1\n",
      "      14866 |   0.204120  |    0.003764     |   0\n",
      "      14867 |   0.046465  |    0.012111     |   2\n",
      "      14868 |   0.149358  |    0.167674     |   1\n",
      "      14869 |   0.037266  |    0.018565     |   2\n",
      "      14870 |   0.242118  |    0.091024     |   1\n",
      "      14871 |   0.000043  |    0.006268     |   2\n",
      "      14872 |   0.180935  |    0.054199     |   0\n",
      "      14873 |   0.000043  |    0.008959     |   2\n",
      "      14874 |   0.219881  |    0.146941     |   1\n",
      "      14875 |   0.000043  |    0.012730     |   2\n",
      "      14876 |   0.000044  |    0.053766     |   2\n",
      "      14877 |   0.203436  |    0.088167     |   1\n",
      "      14878 |   0.000043  |    0.019244     |   2\n",
      "      14879 |   0.167652  |    0.144030     |   1\n",
      "      14880 |   0.286766  |    0.106308     |   1\n",
      "      14881 |   0.201402  |    0.052586     |   1\n",
      "      14882 |   0.171809  |    0.023930     |   0\n",
      "      14883 |   0.298122  |    0.140593     |   1\n",
      "      14884 |   0.000043  |    0.002939     |   2\n",
      "      14885 |   0.049796  |    0.019647     |   2\n",
      "      14886 |   0.165378  |    0.144764     |   1\n",
      "      14887 |   0.212574  |    0.003346     |   0\n",
      "      14888 |   0.218286  |    0.009443     |   0\n",
      "      14889 |   0.190680  |    0.143359     |   1\n",
      "      14890 |   0.208548  |    0.005429     |   0\n",
      "      14891 |   0.179442  |    0.013369     |   0\n",
      "      14892 |   0.052263  |    0.044424     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 14894: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      14893 |   0.202704  |    0.020853     |   0\n",
      "      14894 |   0.256115  |    0.157203     |   1\n",
      "      14895 |   0.197400  |    0.053796     |   1\n",
      "      14896 |   0.051095  |    0.006310     |   2\n",
      "      14897 |   0.038709  |    0.030152     |   2\n",
      "      14898 |   0.041038  |    0.058092     |   2\n",
      "      14899 |   0.213246  |    0.086969     |   1\n",
      "      14900 |   0.207557  |    0.015188     |   0\n",
      "      14901 |   0.241650  |    0.031461     |   0\n",
      "      14902 |   0.172538  |    0.099790     |   1\n",
      "      14903 |   0.193738  |    0.152579     |   1\n",
      "      14904 |   0.191721  |    0.030805     |   1\n",
      "      14905 |   0.052373  |    0.031955     |   2\n",
      "      14906 |   0.153806  |    0.093113     |   1\n",
      "      14907 |   0.194892  |    0.018318     |   0\n",
      "      14908 |   0.174543  |    0.147197     |   1\n",
      "      14909 |   0.259058  |    0.057183     |   1\n",
      "      14910 |   0.030473  |    0.018804     |   2\n",
      "      14911 |   0.173399  |    0.143450     |   1\n",
      "      14912 |   0.184128  |    0.060721     |   1\n",
      "      14913 |   0.156790  |    0.028768     |   0\n",
      "      14914 |   0.207646  |    0.037594     |   0\n",
      "      14915 |   0.042975  |    0.011143     |   2\n",
      "      14916 |   0.194258  |    0.143480     |   1\n",
      "      14917 |   0.050817  |    0.005455     |   2\n",
      "      14918 |   0.062826  |    0.008709     |   2\n",
      "      14919 |   0.206490  |    0.038591     |   0\n",
      "      14920 |   0.228401  |    0.135531     |   1\n",
      "      14921 |   0.208179  |    0.043937     |   1\n",
      "      14922 |   0.173082  |    0.032141     |   0\n",
      "      14923 |   0.049637  |    0.008986     |   2\n",
      "      14924 |   0.227225  |    0.042001     |   0\n",
      "      14925 |   0.159099  |    0.088377     |   1\n",
      "      14926 |   0.022750  |    0.009072     |   2\n",
      "      14927 |   0.262982  |    0.042535     |   0\n",
      "      14928 |   0.218892  |    0.016672     |   0\n",
      "      14929 |   0.000043  |    0.038665     |   2\n",
      "      14930 |   0.005895  |    0.026769     |   2\n",
      "      14931 |   0.194401  |    0.040060     |   0\n",
      "      14932 |   0.193929  |    0.012594     |   0\n",
      "      14933 |   0.073969  |    0.036177     |   2\n",
      "      14934 |   0.038037  |    0.011838     |   2\n",
      "      14935 |   0.183335  |    0.032520     |   0\n",
      "      14936 |   0.232412  |    0.093627     |   1\n",
      "      14937 |   0.063362  |    0.027884     |   2\n",
      "      14938 |   0.199395  |    0.135577     |   1\n",
      "      14939 |   0.177617  |    0.012100     |   0\n",
      "      14940 |   0.051618  |    0.014530     |   2\n",
      "      14941 |   0.246023  |    0.140517     |   1\n",
      "      14942 |   0.021348  |    0.003320     |   2\n",
      "      14943 |   0.233925  |    0.010610     |   0\n",
      "      14944 |   0.042133  |    0.050048     |   2\n",
      "      14945 |   0.035522  |    0.011773     |   2\n",
      "      14946 |   0.230504  |    0.143026     |   1\n",
      "      14947 |   0.216658  |    0.004726     |   0\n",
      "      14948 |   0.201659  |    0.014359     |   0\n",
      "      14949 |   0.000043  |    0.030655     |   2\n",
      "      14950 |   0.253150  |    0.033376     |   0\n",
      "      14951 |   0.299830  |    0.146661     |   1\n",
      "      14952 |   0.209295  |    0.003069     |   0\n",
      "      14953 |   0.000043  |    0.006791     |   2\n",
      "      14954 |   0.000043  |    0.045595     |   2\n",
      "      14955 |   0.000043  |    0.016540     |   2\n",
      "      14956 |   0.155444  |    0.031567     |   0\n",
      "      14957 |   0.159479  |    0.017903     |   0\n",
      "      14958 |   0.245837  |    0.050003     |   0\n",
      "      14959 |   0.198865  |    0.094330     |   1\n",
      "      14960 |   0.274682  |    0.104884     |   1\n",
      "      14961 |   0.000043  |    0.011528     |   2\n",
      "      14962 |   0.196620  |    0.041991     |   0\n",
      "      14963 |   0.000043  |    0.038873     |   2\n",
      "      14964 |   0.178153  |    0.137372     |   1\n",
      "      14965 |   0.054814  |    0.002913     |   2\n",
      "      14966 |   0.052852  |    0.013724     |   2\n",
      "      14967 |   0.190199  |    0.141365     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 14969: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      14968 |   0.173422  |    0.005549     |   0\n",
      "      14969 |   0.163093  |    0.016539     |   0\n",
      "      14970 |   0.247328  |    0.087238     |   1\n",
      "      14971 |   0.055345  |    0.010769     |   2\n",
      "      14972 |   0.195400  |    0.134009     |   1\n",
      "      14973 |   0.041537  |    0.010022     |   2\n",
      "      14974 |   0.205277  |    0.100984     |   1\n",
      "      14975 |   0.172298  |    0.006625     |   0\n",
      "      14976 |   0.043488  |    0.047900     |   2\n",
      "      14977 |   0.219271  |    0.025208     |   0\n",
      "      14978 |   0.211167  |    0.151495     |   1\n",
      "      14979 |   0.190491  |    0.089709     |   1\n",
      "      14980 |   0.196757  |    0.086096     |   1\n",
      "      14981 |   0.051427  |    0.005601     |   2\n",
      "      14982 |   0.224616  |    0.045997     |   0\n",
      "      14983 |   0.030805  |    0.015886     |   2\n",
      "      14984 |   0.204562  |    0.145608     |   1\n",
      "      14985 |   0.147319  |    0.076619     |   1\n",
      "      14986 |   0.046333  |    0.004122     |   2\n",
      "      14987 |   0.241354  |    0.082647     |   1\n",
      "      14988 |   0.187548  |    0.026598     |   0\n",
      "      14989 |   0.253427  |    0.038057     |   0\n",
      "      14990 |   0.056609  |    0.009523     |   2\n",
      "      14991 |   0.212077  |    0.148756     |   1\n",
      "      14992 |   0.182640  |    0.007141     |   0\n",
      "      14993 |   0.178862  |    0.010989     |   0\n",
      "      14994 |   0.178508  |    0.039532     |   0\n",
      "      14995 |   0.063565  |    0.011973     |   2\n",
      "      14996 |   0.278542  |    0.046305     |   0\n",
      "      14997 |   0.049653  |    0.019050     |   2\n",
      "      14998 |   0.254347  |    0.142678     |   1\n",
      "      14999 |   0.023048  |    0.008203     |   2\n",
      "      15000 |   0.207557  |    0.131315     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 15000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 15000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      15001 |   0.053202  |    0.062065     |   2\n",
      "      15002 |   0.240131  |    0.091023     |   1\n",
      "      15003 |   0.041060  |    0.012387     |   2\n",
      "      15004 |   0.270948  |    0.084947     |   1\n",
      "      15005 |   0.218823  |    0.040950     |   0\n",
      "      15006 |   0.224923  |    0.097690     |   1\n",
      "      15007 |   0.197469  |    0.018538     |   0\n",
      "      15008 |   0.043221  |    0.032782     |   2\n",
      "      15009 |   0.051181  |    0.017932     |   2\n",
      "      15010 |   0.317978  |    0.097680     |   1\n",
      "      15011 |   0.169369  |    0.037652     |   0\n",
      "      15012 |   0.184980  |    0.146983     |   1\n",
      "      15013 |   0.030599  |    0.003046     |   2\n",
      "      15014 |   0.044076  |    0.008558     |   2\n",
      "      15015 |   0.051746  |    0.052592     |   2\n",
      "      15016 |   0.158972  |    0.046545     |   1\n",
      "      15017 |   0.064033  |    0.013536     |   2\n",
      "      15018 |   0.200460  |    0.043704     |   0\n",
      "      15019 |   0.046095  |    0.008327     |   2\n",
      "      15020 |   0.255488  |    0.054354     |   0\n",
      "      15021 |   0.177235  |    0.093159     |   1\n",
      "      15022 |   0.227613  |    0.009997     |   0\n",
      "      15023 |   0.223822  |    0.045654     |   0\n",
      "      15024 |   0.233198  |    0.024860     |   0\n",
      "      15025 |   0.146841  |    0.115780     |   1\n",
      "      15026 |   0.157738  |    0.082591     |   1\n",
      "      15027 |   0.159863  |    0.007156     |   0\n",
      "      15028 |   0.177260  |    0.055292     |   0\n",
      "      15029 |   0.165895  |    0.149795     |   1\n",
      "      15030 |   0.163221  |    0.009995     |   0\n",
      "      15031 |   0.197637  |    0.086666     |   1\n",
      "      15032 |   0.022176  |    0.014676     |   2\n",
      "      15033 |   0.138411  |    0.157978     |   1\n",
      "      15034 | \u001b[94m  0.000043\u001b[0m  |    0.003175     |   2\n",
      "      15035 |   0.206972  |    0.036034     |   0\n",
      "      15036 |   0.238418  |    0.078708     |   1\n",
      "      15037 |   0.005959  |    0.006851     |   2\n",
      "      15038 |   0.249571  |    0.059797     |   0\n",
      "      15039 |   0.254228  |    0.081824     |   1\n",
      "      15040 |   0.075126  |    0.006089     |   2\n",
      "      15041 |   0.146385  |    0.016993     |   0\n",
      "      15042 |   0.039618  |    0.044375     |   2\n",
      "      15043 |   0.212850  |    0.131692     |   1\n",
      "      15044 |   0.233469  |    0.055508     |   1\n",
      "      15045 |   0.062676  |    0.026490     |   2\n",
      "      15046 |   0.192099  |    0.034141     |   0\n",
      "      15047 |   0.286388  |    0.095771     |   1\n",
      "      15048 |   0.049688  |    0.003159     |   2\n",
      "      15049 |   0.242922  |    0.147138     |   1\n",
      "      15050 |   0.222449  |    0.079953     |   1\n",
      "      15051 |   0.019874  |    0.005026     |   2\n",
      "      15052 |   0.042346  |    0.028629     |   2\n",
      "      15053 |   0.221096  |    0.040284     |   0\n",
      "      15054 |   0.217925  |    0.029252     |   0\n",
      "      15055 |   0.191073  |    0.134337     |   1\n",
      "      15056 |   0.037772  |    0.016105     |   2\n",
      "      15057 |   0.196333  |    0.094411     |   1\n",
      "      15058 | \u001b[94m  0.000043\u001b[0m  |    0.025516     |   2\n",
      "      15059 |   0.000043  |    0.031030     |   2\n",
      "      15060 | \u001b[94m  0.000042\u001b[0m  |    0.023146     |   2\n",
      "      15061 |   0.194573  |    0.142003     |   1\n",
      "      15062 |   0.192865  |    0.004546     |   0\n",
      "      15063 |   0.224678  |    0.020304     |   0\n",
      "      15064 |   0.000043  |    0.024271     |   2\n",
      "      15065 |   0.206099  |    0.028821     |   0\n",
      "      15066 |   0.199845  |    0.040037     |   0\n",
      "      15067 |   0.196559  |    0.089401     |   1\n",
      "      15068 | \u001b[94m  0.000042\u001b[0m  |    0.015663     |   2\n",
      "      15069 |   0.233936  |    0.158506     |   1\n",
      "      15070 |   0.172358  |    0.028172     |   0\n",
      "      15071 |   0.301944  |    0.035234     |   1\n",
      "      15072 | \u001b[94m  0.000042\u001b[0m  |    0.019195     |   2\n",
      "      15073 |   0.055121  |    0.030537     |   2\n",
      "      15074 |   0.051664  |    0.021834     |   2\n",
      "      15075 |   0.165841  |    0.117496     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 15077: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      15076 |   0.179959  |    0.005476     |   0\n",
      "      15077 |   0.168780  |    0.062305     |   0\n",
      "      15078 |   0.218163  |    0.075020     |   1\n",
      "      15079 |   0.054514  |    0.016495     |   2\n",
      "      15080 |   0.222351  |    0.045985     |   0\n",
      "      15081 |   0.040233  |    0.020432     |   2\n",
      "      15082 |   0.043309  |    0.031215     |   2\n",
      "      15083 |   0.050207  |    0.027645     |   2\n",
      "      15084 |   0.160237  |    0.161803     |   1\n",
      "      15085 |   0.179360  |    0.045375     |   1\n",
      "      15086 |   0.161374  |    0.015148     |   0\n",
      "      15087 |   0.030972  |    0.036713     |   2\n",
      "      15088 |   0.224352  |    0.090084     |   1\n",
      "      15089 |   0.196342  |    0.034666     |   0\n",
      "      15090 |   0.179228  |    0.099294     |   1\n",
      "      15091 |   0.201446  |    0.016917     |   0\n",
      "      15092 |   0.045288  |    0.033150     |   2\n",
      "      15093 |   0.209567  |    0.024888     |   0\n",
      "      15094 |   0.148567  |    0.029709     |   0\n",
      "      15095 |   0.209901  |    0.139094     |   1\n",
      "      15096 |   0.215244  |    0.010289     |   0\n",
      "      15097 |   0.206077  |    0.086213     |   1\n",
      "      15098 |   0.052462  |    0.017706     |   2\n",
      "      15099 |   0.160304  |    0.128614     |   1\n",
      "      15100 |   0.212405  |    0.003331     |   0\n",
      "      15101 |   0.210512  |    0.162927     |   1\n",
      "      15102 |   0.061420  |    0.002871     |   2\n",
      "      15103 |   0.050986  |    0.005945     |   2\n",
      "      15104 |   0.023661  |    0.042594     |   2\n",
      "      15105 | \u001b[94m  0.000042\u001b[0m  |    0.004826     |   2\n",
      "      15106 |   0.175654  |    0.048821     |   0\n",
      "      15107 |   0.005380  |    0.008205     |   2\n",
      "      15108 |   0.199387  |    0.135184     |   1\n",
      "      15109 |   0.204746  |    0.012819     |   0\n",
      "      15110 |   0.074045  |    0.013552     |   2\n",
      "      15111 |   0.038854  |    0.044698     |   2\n",
      "      15112 |   0.234174  |    0.013223     |   0\n",
      "      15113 |   0.183595  |    0.029586     |   0\n",
      "      15114 |   0.164665  |    0.024153     |   0\n",
      "      15115 |   0.244787  |    0.045371     |   0\n",
      "      15116 |   0.227909  |    0.012155     |   0\n",
      "      15117 |   0.325301  |    0.092675     |   1\n",
      "      15118 |   0.209813  |    0.015214     |   0\n",
      "      15119 |   0.229280  |    0.048593     |   0\n",
      "      15120 |   0.250035  |    0.099404     |   1\n",
      "      15121 |   0.063136  |    0.005401     |   2\n",
      "      15122 |   0.048602  |    0.026717     |   2\n",
      "      15123 |   0.215210  |    0.146206     |   1\n",
      "      15124 |   0.023880  |    0.002906     |   2\n",
      "      15125 |   0.147568  |    0.008433     |   0\n",
      "      15126 |   0.174698  |    0.044368     |   0\n",
      "      15127 |   0.210626  |    0.013487     |   0\n",
      "      15128 |   0.189029  |    0.032637     |   0\n",
      "      15129 |   0.047292  |    0.036168     |   2\n",
      "      15130 |   0.197178  |    0.144882     |   1\n",
      "      15131 |   0.237396  |    0.053094     |   1\n",
      "      15132 |   0.167806  |    0.085260     |   1\n",
      "      15133 |   0.238453  |    0.027273     |   0\n",
      "      15134 |   0.197481  |    0.029527     |   0\n",
      "      15135 |   0.175334  |    0.134821     |   1\n",
      "      15136 |   0.184798  |    0.003179     |   0\n",
      "      15137 |   0.038509  |    0.006391     |   2\n",
      "      15138 |   0.000042  |    0.053224     |   2\n",
      "      15139 |   0.200970  |    0.021799     |   0\n",
      "      15140 |   0.211890  |    0.136476     |   1\n",
      "      15141 |   0.000042  |    0.003754     |   2\n",
      "      15142 |   0.219084  |    0.025042     |   0\n",
      "      15143 |   0.249142  |    0.146509     |   1\n",
      "      15144 |   0.260545  |    0.055035     |   1\n",
      "      15145 |   0.173596  |    0.015297     |   0\n",
      "      15146 |   0.208856  |    0.147521     |   1\n",
      "      15147 |   0.262331  |    0.014751     |   0\n",
      "      15148 |   0.187871  |    0.057738     |   1\n",
      "      15149 |   0.196630  |    0.032198     |   0\n",
      "      15150 |   0.000042  |    0.030843     |   2\n",
      "      15151 |   0.000042  |    0.010014     |   2\n",
      "      15152 |   0.221334  |    0.050042     |   0\n",
      "      15153 |   0.000042  |    0.008575     |   2\n",
      "      15154 |   0.221695  |    0.060898     |   0\n",
      "      15155 |   0.219326  |    0.096411     |   1\n",
      "      15156 |   0.264697  |    0.096063     |   1\n",
      "      15157 |   0.148398  |    0.030274     |   0\n",
      "      15158 |   0.154587  |    0.101467     |   1\n",
      "      15159 |   0.220371  |    0.146039     |   1\n",
      "      15160 |   0.173328  |    0.063183     |   1\n",
      "      15161 |   0.192778  |    0.138811     |   1\n",
      "      15162 |   0.199488  |    0.054756     |   1\n",
      "      15163 |   0.000042  |    0.022270     |   2\n",
      "      15164 |   0.057804  |    0.023239     |   2\n",
      "      15165 |   0.052048  |    0.009341     |   2\n",
      "      15166 |   0.224724  |    0.051623     |   0\n",
      "      15167 |   0.257634  |    0.083900     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 15168: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      15168 |   0.200210  |    0.087696     |   1\n",
      "      15169 |   0.185735  |    0.043730     |   0\n",
      "      15170 |   0.206023  |    0.150442     |   1\n",
      "      15171 |   0.191504  |    0.115680     |   1\n",
      "      15172 |   0.224537  |    0.004991     |   0\n",
      "      15173 |   0.254245  |    0.107578     |   1\n",
      "      15174 |   0.172913  |    0.020391     |   1\n",
      "      15175 |   0.210345  |    0.049637     |   0\n",
      "      15176 |   0.200875  |    0.013561     |   0\n",
      "      15177 |   0.220533  |    0.038416     |   0\n",
      "      15178 |   0.051705  |    0.025622     |   2\n",
      "      15179 |   0.037602  |    0.029427     |   2\n",
      "      15180 |   0.045165  |    0.012267     |   2\n",
      "      15181 |   0.218938  |    0.061316     |   0\n",
      "      15182 |   0.183484  |    0.086965     |   1\n",
      "      15183 |   0.214150  |    0.031307     |   0\n",
      "      15184 |   0.222108  |    0.087265     |   1\n",
      "      15185 |   0.053380  |    0.009233     |   2\n",
      "      15186 |   0.201630  |    0.044753     |   0\n",
      "      15187 |   0.262122  |    0.029988     |   0\n",
      "      15188 |   0.172615  |    0.021969     |   0\n",
      "      15189 |   0.205791  |    0.032713     |   0\n",
      "      15190 |   0.030291  |    0.027600     |   2\n",
      "      15191 |   0.045853  |    0.018464     |   2\n",
      "      15192 |   0.182237  |    0.142468     |   1\n",
      "      15193 |   0.221399  |    0.077841     |   1\n",
      "      15194 |   0.057127  |    0.010308     |   2\n",
      "      15195 |   0.247886  |    0.150219     |   1\n",
      "      15196 |   0.151881  |    0.077678     |   1\n",
      "      15197 |   0.195298  |    0.008860     |   0\n",
      "      15198 |   0.160831  |    0.045380     |   0\n",
      "      15199 |   0.215284  |    0.012291     |   0\n",
      "      15200 |   0.189621  |    0.046333     |   0\n",
      "      15201 |   0.176709  |    0.088697     |   1\n",
      "      15202 |   0.163760  |    0.097649     |   1\n",
      "      15203 |   0.215678  |    0.015526     |   0\n",
      "      15204 |   0.199878  |    0.148082     |   1\n",
      "      15205 |   0.269193  |    0.074735     |   1\n",
      "      15206 |   0.061471  |    0.011536     |   2\n",
      "      15207 |   0.230371  |    0.139935     |   1\n",
      "      15208 |   0.200140  |    0.076632     |   1\n",
      "      15209 |   0.256300  |    0.074721     |   1\n",
      "      15210 |   0.149574  |    0.033576     |   0\n",
      "      15211 |   0.287543  |    0.137160     |   1\n",
      "      15212 |   0.050369  |    0.002904     |   2\n",
      "      15213 |   0.240222  |    0.012454     |   0\n",
      "      15214 |   0.218645  |    0.044388     |   0\n",
      "      15215 |   0.165974  |    0.009840     |   0\n",
      "      15216 |   0.303591  |    0.161709     |   1\n",
      "      15217 |   0.249402  |    0.066015     |   1\n",
      "      15218 |   0.238489  |    0.054247     |   1\n",
      "      15219 |   0.283065  |    0.148759     |   1\n",
      "      15220 |   0.026381  |    0.009169     |   2\n",
      "      15221 |   0.190311  |    0.050323     |   1\n",
      "      15222 |   0.238078  |    0.032263     |   0\n",
      "      15223 |   0.279530  |    0.090267     |   1\n",
      "      15224 |   0.000042  |    0.032294     |   2\n",
      "      15225 |   0.006246  |    0.014674     |   2\n",
      "      15226 |   0.216697  |    0.049138     |   0\n",
      "      15227 |   0.073839  |    0.014769     |   2\n",
      "      15228 |   0.282144  |    0.154347     |   1\n",
      "      15229 |   0.187469  |    0.038587     |   1\n",
      "      15230 |   0.269794  |    0.098934     |   1\n",
      "      15231 |   0.213929  |    0.138430     |   1\n",
      "      15232 |   0.281525  |    0.002949     |   0\n",
      "      15233 |   0.214189  |    0.007632     |   0\n",
      "      15234 |   0.239808  |    0.038441     |   0\n",
      "      15235 |   0.255843  |    0.076047     |   1\n",
      "      15236 |   0.226819  |    0.012632     |   0\n",
      "      15237 |   0.038250  |    0.038314     |   2\n",
      "      15238 |   0.190388  |    0.146034     |   1\n",
      "      15239 |   0.215310  |    0.004210     |   0\n",
      "      15240 |   0.220589  |    0.003310     |   0\n",
      "      15241 |   0.213439  |    0.155232     |   1\n",
      "      15242 |   0.237762  |    0.053727     |   1\n",
      "      15243 |   0.057703  |    0.007399     |   2\n",
      "      15244 |   0.175688  |    0.047778     |   0\n",
      "      15245 |   0.222056  |    0.007429     |   0\n",
      "      15246 |   0.050876  |    0.035600     |   2\n",
      "      15247 |   0.020079  |    0.025577     |   2\n",
      "      15248 |   0.040349  |    0.030058     |   2\n",
      "      15249 |   0.035626  |    0.028146     |   2\n",
      "      15250 |   0.224490  |    0.139222     |   1\n",
      "      15251 |   0.193888  |    0.005351     |   0\n",
      "      15252 | \u001b[94m  0.000041\u001b[0m  |    0.018739     |   2\n",
      "      15253 |   0.230920  |    0.149210     |   1\n",
      "      15254 |   0.285255  |    0.034919     |   1\n",
      "      15255 | \u001b[94m  0.000041\u001b[0m  |    0.025390     |   2\n",
      "      15256 |   0.200829  |    0.038485     |   0\n",
      "      15257 |   0.204250  |    0.134127     |   1\n",
      "      15258 | \u001b[94m  0.000041\u001b[0m  |    0.003238     |   2\n",
      "      15259 |   0.261298  |    0.013167     |   0\n",
      "      15260 |   0.000041  |    0.030736     |   2\n",
      "      15261 |   0.000041  |    0.024487     |   2\n",
      "      15262 |   0.218546  |    0.035509     |   0\n",
      "      15263 |   0.198242  |    0.024726     |   0\n",
      "      15264 | \u001b[94m  0.000041\u001b[0m  |    0.055063     |   2\n",
      "      15265 |   0.274156  |    0.085527     |   1\n",
      "      15266 |   0.054000  |    0.009921     |   2\n",
      "      15267 |   0.050395  |    0.010839     |   2\n",
      "      15268 |   0.206515  |    0.152755     |   1\n",
      "      15269 |   0.197452  |    0.004035     |   0\n",
      "      15270 |   0.179370  |    0.011384     |   0\n",
      "      15271 |   0.211761  |    0.133310     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 15272: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      15272 |   0.054732  |    0.005783     |   2\n",
      "      15273 |   0.153573  |    0.015599     |   0\n",
      "      15274 |   0.040103  |    0.041065     |   2\n",
      "      15275 |   0.043664  |    0.008653     |   2\n",
      "      15276 |   0.209253  |    0.043189     |   0\n",
      "      15277 |   0.225440  |    0.027965     |   0\n",
      "      15278 |   0.051538  |    0.021665     |   2\n",
      "      15279 |   0.229773  |    0.028289     |   0\n",
      "      15280 |   0.030079  |    0.034284     |   2\n",
      "      15281 |   0.045449  |    0.020157     |   2\n",
      "      15282 |   0.159415  |    0.143078     |   1\n",
      "      15283 |   0.197483  |    0.040026     |   1\n",
      "      15284 |   0.243531  |    0.086001     |   1\n",
      "      15285 |   0.052806  |    0.003714     |   2\n",
      "      15286 |   0.064697  |    0.044089     |   2\n",
      "      15287 |   0.051396  |    0.005903     |   2\n",
      "      15288 |   0.241619  |    0.041248     |   0\n",
      "      15289 |   0.025531  |    0.015361     |   2\n",
      "      15290 |   0.166007  |    0.145428     |   1\n",
      "      15291 | \u001b[94m  0.000041\u001b[0m  |    0.007397     |   2\n",
      "      15292 |   0.005845  |    0.006271     |   2\n",
      "      15293 |   0.074879  |    0.024948     |   2\n",
      "      15294 |   0.039199  |    0.019411     |   2\n",
      "      15295 |   0.176369  |    0.030758     |   0\n",
      "      15296 |   0.230940  |    0.156152     |   1\n",
      "      15297 |   0.060123  |    0.010843     |   2\n",
      "      15298 |   0.201711  |    0.087218     |   1\n",
      "      15299 |   0.048158  |    0.006353     |   2\n",
      "      15300 |   0.021001  |    0.017810     |   2\n",
      "      15301 |   0.041402  |    0.024657     |   2\n",
      "      15302 |   0.192352  |    0.050144     |   0\n",
      "      15303 |   0.133077  |    0.089710     |   1\n",
      "      15304 |   0.201379  |    0.020316     |   0\n",
      "      15305 |   0.178791  |    0.134842     |   1\n",
      "      15306 |   0.252829  |    0.006758     |   0\n",
      "      15307 |   0.035447  |    0.045342     |   2\n",
      "      15308 |   0.212809  |    0.081585     |   1\n",
      "      15309 |   0.000041  |    0.013398     |   2\n",
      "      15310 |   0.297656  |    0.143605     |   1\n",
      "      15311 |   0.209083  |    0.004162     |   0\n",
      "      15312 |   0.000041  |    0.013734     |   2\n",
      "      15313 |   0.000041  |    0.035415     |   2\n",
      "      15314 |   0.000041  |    0.013898     |   2\n",
      "      15315 |   0.188850  |    0.045048     |   0\n",
      "      15316 |   0.166535  |    0.013205     |   0\n",
      "      15317 |   0.000041  |    0.030969     |   2\n",
      "      15318 |   0.000041  |    0.041669     |   2\n",
      "      15319 |   0.290119  |    0.098223     |   1\n",
      "      15320 |   0.057515  |    0.005410     |   2\n",
      "      15321 |   0.220295  |    0.048116     |   0\n",
      "      15322 |   0.052191  |    0.009703     |   2\n",
      "      15323 |   0.221567  |    0.052744     |   0\n",
      "      15324 |   0.257494  |    0.095549     |   1\n",
      "      15325 |   0.209186  |    0.009895     |   0\n",
      "      15326 |   0.194153  |    0.031131     |   0\n",
      "      15327 |   0.245747  |    0.092656     |   1\n",
      "      15328 |   0.210017  |    0.078675     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 15330: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      15329 |   0.168407  |    0.038249     |   0\n",
      "      15330 |   0.053688  |    0.010390     |   2\n",
      "      15331 |   0.183057  |    0.021637     |   0\n",
      "      15332 |   0.042682  |    0.035514     |   2\n",
      "      15333 |   0.044009  |    0.033804     |   2\n",
      "      15334 |   0.215921  |    0.152701     |   1\n",
      "      15335 |   0.052308  |    0.003983     |   2\n",
      "      15336 |   0.030678  |    0.007356     |   2\n",
      "      15337 |   0.044398  |    0.026745     |   2\n",
      "      15338 |   0.051271  |    0.020940     |   2\n",
      "      15339 |   0.063890  |    0.046359     |   2\n",
      "      15340 |   0.052047  |    0.008886     |   2\n",
      "      15341 |   0.224342  |    0.056689     |   0\n",
      "      15342 |   0.193755  |    0.110009     |   1\n",
      "      15343 |   0.194762  |    0.081084     |   1\n",
      "      15344 |   0.023993  |    0.019124     |   2\n",
      "      15345 |   0.191461  |    0.083564     |   1\n",
      "      15346 |   0.188639  |    0.028913     |   0\n",
      "      15347 |   0.000041  |    0.046046     |   2\n",
      "      15348 |   0.006358  |    0.009317     |   2\n",
      "      15349 |   0.183297  |    0.049261     |   0\n",
      "      15350 |   0.203527  |    0.089402     |   1\n",
      "      15351 |   0.208132  |    0.029597     |   0\n",
      "      15352 |   0.198238  |    0.152102     |   1\n",
      "      15353 |   0.151982  |    0.010756     |   0\n",
      "      15354 |   0.260310  |    0.052947     |   1\n",
      "      15355 |   0.071069  |    0.008012     |   2\n",
      "      15356 |   0.037871  |    0.040863     |   2\n",
      "      15357 |   0.213066  |    0.028461     |   0\n",
      "      15358 |   0.188066  |    0.119703     |   1\n",
      "      15359 |   0.189543  |    0.086863     |   1\n",
      "      15360 |   0.205465  |    0.097724     |   1\n",
      "      15361 |   0.153619  |    0.144196     |   1\n",
      "      15362 |   0.060075  |    0.012661     |   2\n",
      "      15363 |   0.227983  |    0.045382     |   1\n",
      "      15364 |   0.196396  |    0.080546     |   1\n",
      "      15365 |   0.206832  |    0.018188     |   0\n",
      "      15366 |   0.191102  |    0.149000     |   1\n",
      "      15367 |   0.242175  |    0.089859     |   1\n",
      "      15368 |   0.218659  |    0.070010     |   1\n",
      "      15369 |   0.047729  |    0.013660     |   2\n",
      "      15370 |   0.164446  |    0.035065     |   0\n",
      "      15371 |   0.156927  |    0.016122     |   0\n",
      "      15372 |   0.205484  |    0.067801     |   0\n",
      "      15373 |   0.185899  |    0.092312     |   1\n",
      "      15374 |   0.237366  |    0.007942     |   0\n",
      "      15375 |   0.196260  |    0.091893     |   1\n",
      "      15376 |   0.169209  |    0.006131     |   0\n",
      "      15377 |   0.204073  |    0.059262     |   0\n",
      "      15378 |   0.244923  |    0.084731     |   1\n",
      "      15379 |   0.263487  |    0.011885     |   0\n",
      "      15380 |   0.238751  |    0.079005     |   1\n",
      "      15381 |   0.189625  |    0.029400     |   0\n",
      "      15382 |   0.023011  |    0.030227     |   2\n",
      "      15383 |   0.223478  |    0.062023     |   0\n",
      "      15384 |   0.202567  |    0.066661     |   1\n",
      "      15385 |   0.041685  |    0.010651     |   2\n",
      "      15386 |   0.034172  |    0.046407     |   2\n",
      "      15387 |   0.191020  |    0.011688     |   0\n",
      "      15388 |   0.233126  |    0.050600     |   0\n",
      "      15389 |   0.214693  |    0.103841     |   1\n",
      "      15390 |   0.209055  |    0.088325     |   1\n",
      "      15391 |   0.220091  |    0.013124     |   0\n",
      "      15392 |   0.227530  |    0.152900     |   1\n",
      "      15393 | \u001b[94m  0.000040\u001b[0m  |    0.007264     |   2\n",
      "      15394 |   0.223668  |    0.072176     |   1\n",
      "      15395 |   0.204271  |    0.026787     |   0\n",
      "      15396 |   0.183916  |    0.023074     |   0\n",
      "      15397 |   0.201371  |    0.031492     |   0\n",
      "      15398 |   0.000040  |    0.008181     |   2\n",
      "      15399 |   0.204668  |    0.045039     |   0\n",
      "      15400 |   0.204487  |    0.008814     |   0\n",
      "      15401 |   0.137379  |    0.062704     |   0\n",
      "      15402 |   0.205589  |    0.048520     |   1\n",
      "      15403 |   0.000040  |    0.009696     |   2\n",
      "      15404 |   0.144877  |    0.159240     |   1\n",
      "      15405 |   0.000041  |    0.002995     |   2\n",
      "      15406 |   0.000041  |    0.012256     |   2\n",
      "      15407 |   0.000040  |    0.040683     |   2\n",
      "      15408 |   0.208469  |    0.081225     |   1\n",
      "      15409 |   0.225383  |    0.028272     |   0\n",
      "      15410 |   0.060116  |    0.035650     |   2\n",
      "      15411 |   0.149798  |    0.080392     |   1\n",
      "      15412 |   0.229096  |    0.109682     |   1\n",
      "      15413 |   0.208035  |    0.138404     |   1\n",
      "      15414 |   0.167803  |    0.006691     |   0\n",
      "      15415 |   0.174420  |    0.150218     |   1\n",
      "      15416 |   0.211049  |    0.023379     |   1\n",
      "      15417 |   0.125037  |    0.146678     |   1\n",
      "      15418 |   0.208372  |    0.016498     |   0\n",
      "      15419 |   0.180674  |    0.101278     |   1\n",
      "      15420 |   0.051281  |    0.015959     |   2\n",
      "      15421 |   0.200583  |    0.104669     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 15423: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      15422 |   0.176126  |    0.031447     |   0\n",
      "      15423 |   0.179257  |    0.018138     |   0\n",
      "      15424 |   0.240010  |    0.052973     |   0\n",
      "      15425 |   0.056801  |    0.019421     |   2\n",
      "      15426 |   0.188603  |    0.136018     |   1\n",
      "      15427 |   0.042249  |    0.009795     |   2\n",
      "      15428 |   0.043692  |    0.025220     |   2\n",
      "      15429 |   0.231842  |    0.132353     |   1\n",
      "      15430 |   0.240225  |    0.082602     |   1\n",
      "      15431 |   0.225490  |    0.095141     |   1\n",
      "      15432 |   0.052254  |    0.007801     |   2\n",
      "      15433 |   0.159620  |    0.161869     |   1\n",
      "      15434 |   0.238563  |    0.080097     |   1\n",
      "      15435 |   0.031235  |    0.008430     |   2\n",
      "      15436 |   0.243560  |    0.091804     |   1\n",
      "      15437 |   0.042686  |    0.021986     |   2\n",
      "      15438 |   0.050969  |    0.033723     |   2\n",
      "      15439 |   0.063631  |    0.022355     |   2\n",
      "      15440 |   0.199233  |    0.026191     |   0\n",
      "      15441 |   0.191997  |    0.025750     |   0\n",
      "      15442 |   0.051290  |    0.029830     |   2\n",
      "      15443 |   0.026356  |    0.018112     |   2\n",
      "      15444 |   0.000040  |    0.036379     |   2\n",
      "      15445 |   0.238560  |    0.084351     |   1\n",
      "      15446 |   0.005947  |    0.009036     |   2\n",
      "      15447 |   0.198468  |    0.046712     |   0\n",
      "      15448 |   0.199067  |    0.139395     |   1\n",
      "      15449 |   0.276145  |    0.027724     |   1\n",
      "      15450 |   0.209765  |    0.148476     |   1\n",
      "      15451 |   0.192183  |    0.013695     |   0\n",
      "      15452 |   0.165122  |    0.050439     |   1\n",
      "      15453 |   0.224457  |    0.020961     |   0\n",
      "      15454 |   0.230407  |    0.040793     |   0\n",
      "      15455 |   0.231030  |    0.014103     |   0\n",
      "      15456 |   0.235218  |    0.053831     |   0\n",
      "      15457 |   0.292356  |    0.084150     |   1\n",
      "      15458 |   0.184580  |    0.008360     |   0\n",
      "      15459 |   0.154493  |    0.140764     |   1\n",
      "      15460 |   0.252532  |    0.100265     |   1\n",
      "      15461 |   0.233160  |    0.106104     |   1\n",
      "      15462 |   0.205101  |    0.085003     |   1\n",
      "      15463 |   0.073619  |    0.030963     |   2\n",
      "      15464 |   0.039213  |    0.027273     |   2\n",
      "      15465 |   0.062181  |    0.020107     |   2\n",
      "      15466 |   0.051875  |    0.031910     |   2\n",
      "      15467 |   0.211277  |    0.023636     |   0\n",
      "      15468 |   0.216707  |    0.028026     |   0\n",
      "      15469 |   0.024273  |    0.019691     |   2\n",
      "      15470 |   0.248697  |    0.044116     |   0\n",
      "      15471 |   0.238267  |    0.098556     |   1\n",
      "      15472 |   0.184703  |    0.086787     |   1\n",
      "      15473 |   0.044378  |    0.026860     |   2\n",
      "      15474 |   0.034028  |    0.028458     |   2\n",
      "      15475 | \u001b[94m  0.000040\u001b[0m  |    0.030261     |   2\n",
      "      15476 |   0.277436  |    0.118705     |   1\n",
      "      15477 |   0.000040  |    0.006388     |   2\n",
      "      15478 |   0.220027  |    0.033771     |   0\n",
      "      15479 |   0.180690  |    0.019578     |   0\n",
      "      15480 |   0.000040  |    0.034383     |   2\n",
      "      15481 |   0.293706  |    0.089007     |   1\n",
      "      15482 |   0.230752  |    0.145421     |   1\n",
      "      15483 |   0.000041  |    0.003161     |   2\n",
      "      15484 |   0.198979  |    0.008502     |   0\n",
      "      15485 |   0.230769  |    0.145431     |   1\n",
      "      15486 |   0.149795  |    0.114430     |   1\n",
      "      15487 |   0.199807  |    0.098168     |   1\n",
      "      15488 |   0.228113  |    0.080530     |   1\n",
      "      15489 |   0.000040  |    0.011161     |   2\n",
      "      15490 |   0.187293  |    0.027439     |   0\n",
      "      15491 |   0.139562  |    0.153941     |   1\n",
      "      15492 |   0.224040  |    0.026248     |   1\n",
      "      15493 |   0.194244  |    0.041638     |   0\n",
      "      15494 |   0.207871  |    0.009460     |   0\n",
      "      15495 |   0.199631  |    0.134837     |   1\n",
      "      15496 |   0.218958  |    0.022446     |   0\n",
      "      15497 |   0.195286  |    0.145226     |   1\n",
      "      15498 |   0.187514  |    0.034584     |   1\n",
      "      15499 |   0.211330  |    0.029515     |   0\n",
      "      15500 |   0.000040  |    0.025097     |   2\n",
      "      15501 |   0.142604  |    0.152025     |   1\n",
      "      15502 |   0.053745  |    0.020955     |   2\n",
      "      15503 |   0.284063  |    0.141783     |   1\n",
      "      15504 |   0.226694  |    0.014609     |   0\n",
      "      15505 |   0.191477  |    0.089687     |   1\n",
      "      15506 |   0.038479  |    0.009132     |   2\n",
      "      15507 |   0.230056  |    0.159283     |   1\n",
      "      15508 |   0.175985  |    0.030326     |   1\n",
      "      15509 |   0.196547  |    0.108712     |   1\n",
      "      15510 |   0.241729  |    0.030290     |   0\n",
      "      15511 |   0.188553  |    0.142014     |   1\n",
      "      15512 |   0.160915  |    0.061056     |   1\n",
      "      15513 |   0.044254  |    0.021264     |   2\n",
      "      15514 |   0.244812  |    0.128863     |   1\n",
      "      15515 |   0.224220  |    0.006263     |   0\n",
      "      15516 |   0.243063  |    0.134993     |   1\n",
      "      15517 |   0.221358  |    0.056793     |   1\n",
      "      15518 |   0.053158  |    0.010084     |   2\n",
      "      15519 |   0.187710  |    0.038183     |   0\n",
      "      15520 |   0.030004  |    0.014590     |   2\n",
      "      15521 |   0.295287  |    0.153305     |   1\n",
      "      15522 |   0.044882  |    0.012021     |   2\n",
      "      15523 |   0.216736  |    0.034746     |   1\n",
      "      15524 |   0.050659  |    0.016157     |   2\n",
      "      15525 |   0.174283  |    0.142733     |   1\n",
      "      15526 |   0.062692  |    0.009454     |   2\n",
      "      15527 |   0.048858  |    0.019470     |   2\n",
      "      15528 |   0.026411  |    0.024712     |   2\n",
      "      15529 |   0.225868  |    0.023700     |   0\n",
      "      15530 |   0.166603  |    0.158237     |   1\n",
      "      15531 |   0.235888  |    0.058456     |   1\n",
      "      15532 |   0.203025  |    0.022811     |   0\n",
      "      15533 |   0.260993  |    0.142872     |   1\n",
      "      15534 |   0.205483  |    0.047637     |   1\n",
      "      15535 |   0.178406  |    0.032512     |   0\n",
      "      15536 |   0.173668  |    0.131610     |   1\n",
      "      15537 |   0.239527  |    0.090163     |   1\n",
      "      15538 |   0.313640  |    0.043510     |   1\n",
      "      15539 |   0.269887  |    0.084476     |   1\n",
      "      15540 |   0.164872  |    0.013893     |   0\n",
      "      15541 |   0.183560  |    0.039074     |   0\n",
      "      15542 |   0.215345  |    0.112567     |   1\n",
      "      15543 |   0.183015  |    0.050474     |   1\n",
      "      15544 |   0.173594  |    0.139963     |   1\n",
      "      15545 |   0.202109  |    0.101965     |   1\n",
      "      15546 |   0.284595  |    0.090036     |   1\n",
      "      15547 |   0.247338  |    0.097094     |   1\n",
      "      15548 |   0.242032  |    0.084058     |   1\n",
      "      15549 | \u001b[94m  0.000039\u001b[0m  |    0.013507     |   2\n",
      "      15550 |   0.006446  |    0.046182     |   2\n",
      "      15551 |   0.262428  |    0.083723     |   1\n",
      "      15552 |   0.073901  |    0.006430     |   2\n",
      "      15553 |   0.248343  |    0.055353     |   0\n",
      "      15554 |   0.197064  |    0.069484     |   1\n",
      "      15555 |   0.227856  |    0.031506     |   0\n",
      "      15556 |   0.036945  |    0.022090     |   2\n",
      "      15557 |   0.062203  |    0.008329     |   2\n",
      "      15558 |   0.255197  |    0.142210     |   1\n",
      "      15559 |   0.211684  |    0.005117     |   0\n",
      "      15560 |   0.048434  |    0.012402     |   2\n",
      "      15561 |   0.022552  |    0.040133     |   2\n",
      "      15562 |   0.194629  |    0.105738     |   1\n",
      "      15563 |   0.211981  |    0.060062     |   1\n",
      "      15564 |   0.187817  |    0.118598     |   1\n",
      "      15565 |   0.042319  |    0.015180     |   2\n",
      "      15566 |   0.031969  |    0.036981     |   2\n",
      "      15567 | \u001b[94m  0.000039\u001b[0m  |    0.021758     |   2\n",
      "      15568 |   0.221170  |    0.100786     |   1\n",
      "      15569 |   0.179927  |    0.084148     |   1\n",
      "      15570 |   0.000039  |    0.023211     |   2\n",
      "      15571 |   0.222796  |    0.142921     |   1\n",
      "      15572 |   0.241470  |    0.048029     |   1\n",
      "      15573 |   0.000039  |    0.014059     |   2\n",
      "      15574 |   0.209836  |    0.094817     |   1\n",
      "      15575 |   0.188411  |    0.023601     |   0\n",
      "      15576 |   0.200471  |    0.144140     |   1\n",
      "      15577 |   0.209353  |    0.060208     |   1\n",
      "      15578 |   0.272062  |    0.131052     |   1\n",
      "      15579 |   0.202530  |    0.009413     |   0\n",
      "      15580 |   0.000040  |    0.007722     |   2\n",
      "      15581 |   0.244817  |    0.091416     |   1\n",
      "      15582 |   0.000039  |    0.021246     |   2\n",
      "      15583 |   0.000039  |    0.041778     |   2\n",
      "      15584 |   0.217094  |    0.152236     |   1\n",
      "      15585 |   0.213656  |    0.037886     |   1\n",
      "      15586 |   0.052248  |    0.017115     |   2\n",
      "      15587 |   0.206707  |    0.027211     |   0\n",
      "      15588 |   0.203035  |    0.158296     |   1\n",
      "      15589 |   0.239614  |    0.042196     |   1\n",
      "      15590 |   0.166606  |    0.046757     |   0\n",
      "      15591 |   0.281009  |    0.115755     |   1\n",
      "      15592 |   0.199267  |    0.019433     |   0\n",
      "      15593 |   0.172264  |    0.101357     |   1\n",
      "      15594 |   0.197521  |    0.068357     |   1\n",
      "      15595 |   0.210163  |    0.009585     |   0\n",
      "      15596 |   0.158283  |    0.043963     |   0\n",
      "      15597 |   0.193458  |    0.036584     |   0\n",
      "      15598 |   0.301391  |    0.084933     |   1\n",
      "      15599 |   0.173638  |    0.100499     |   1\n",
      "      15600 |   0.196578  |    0.036624     |   0\n",
      "      15601 |   0.050911  |    0.009825     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 15602: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      15602 |   0.192373  |    0.048634     |   0\n",
      "      15603 |   0.054643  |    0.014877     |   2\n",
      "      15604 |   0.189786  |    0.142345     |   1\n",
      "      15605 |   0.173284  |    0.093787     |   1\n",
      "      15606 |   0.211542  |    0.018484     |   0\n",
      "      15607 |   0.201291  |    0.078470     |   1\n",
      "      15608 |   0.149859  |    0.132492     |   1\n",
      "      15609 |   0.222008  |    0.077860     |   1\n",
      "      15610 |   0.039881  |    0.003750     |   2\n",
      "      15611 |   0.214433  |    0.044079     |   0\n",
      "      15612 |   0.184064  |    0.016723     |   0\n",
      "      15613 |   0.198524  |    0.146230     |   1\n",
      "      15614 |   0.243994  |    0.078726     |   1\n",
      "      15615 |   0.041795  |    0.006306     |   2\n",
      "      15616 |   0.266623  |    0.019368     |   0\n",
      "      15617 |   0.151548  |    0.027966     |   0\n",
      "      15618 |   0.150060  |    0.025095     |   0\n",
      "      15619 |   0.051555  |    0.031606     |   2\n",
      "      15620 |   0.186499  |    0.019156     |   0\n",
      "      15621 |   0.030244  |    0.033632     |   2\n",
      "      15622 |   0.043447  |    0.023025     |   2\n",
      "      15623 |   0.179114  |    0.037197     |   0\n",
      "      15624 |   0.144192  |    0.139576     |   1\n",
      "      15625 |   0.145997  |    0.068731     |   1\n",
      "      15626 |   0.049298  |    0.010578     |   2\n",
      "      15627 |   0.216552  |    0.042015     |   0\n",
      "      15628 |   0.178806  |    0.010604     |   0\n",
      "      15629 |   0.062897  |    0.042772     |   2\n",
      "      15630 |   0.182129  |    0.024901     |   0\n",
      "      15631 |   0.172857  |    0.147378     |   1\n",
      "      15632 |   0.049425  |    0.003285     |   2\n",
      "      15633 |   0.023046  |    0.006951     |   2\n",
      "      15634 |   0.000039  |    0.049482     |   2\n",
      "      15635 |   0.006510  |    0.021911     |   2\n",
      "      15636 |   0.165308  |    0.135673     |   1\n",
      "      15637 |   0.075028  |    0.002873     |   2\n",
      "      15638 |   0.243564  |    0.004459     |   0\n",
      "      15639 |   0.190836  |    0.059699     |   0\n",
      "      15640 |   0.191032  |    0.082434     |   1\n",
      "      15641 |   0.203727  |    0.018501     |   0\n",
      "      15642 |   0.226478  |    0.138987     |   1\n",
      "      15643 |   0.038283  |    0.005651     |   2\n",
      "      15644 |   0.202293  |    0.017055     |   0\n",
      "      15645 |   0.201054  |    0.155774     |   1\n",
      "      15646 |   0.301814  |    0.085971     |   1\n",
      "      15647 |   0.062540  |    0.011213     |   2\n",
      "      15648 |   0.238381  |    0.087300     |   1\n",
      "      15649 |   0.049678  |    0.013263     |   2\n",
      "      15650 |   0.225477  |    0.068262     |   0\n",
      "      15651 |   0.255691  |    0.065606     |   1\n",
      "      15652 |   0.223876  |    0.042723     |   0\n",
      "      15653 |   0.211948  |    0.098689     |   1\n",
      "      15654 |   0.208258  |    0.088547     |   1\n",
      "      15655 |   0.021560  |    0.006867     |   2\n",
      "      15656 |   0.182325  |    0.111950     |   1\n",
      "      15657 |   0.188479  |    0.089258     |   1\n",
      "      15658 |   0.042125  |    0.013946     |   2\n",
      "      15659 |   0.031277  |    0.027744     |   2\n",
      "      15660 | \u001b[94m  0.000039\u001b[0m  |    0.023590     |   2\n",
      "      15661 |   0.000039  |    0.018275     |   2\n",
      "      15662 |   0.000039  |    0.031767     |   2\n",
      "      15663 |   0.227539  |    0.094939     |   1\n",
      "      15664 |   0.000039  |    0.014084     |   2\n",
      "      15665 |   0.179084  |    0.151651     |   1\n",
      "      15666 | \u001b[94m  0.000039\u001b[0m  |    0.006009     |   2\n",
      "      15667 |   0.231249  |    0.006897     |   0\n",
      "      15668 |   0.239060  |    0.049176     |   0\n",
      "      15669 |   0.190411  |    0.007683     |   0\n",
      "      15670 | \u001b[94m  0.000039\u001b[0m  |    0.052114     |   2\n",
      "      15671 |   0.283193  |    0.111598     |   1\n",
      "      15672 |   0.164869  |    0.003789     |   0\n",
      "      15673 |   0.195004  |    0.097199     |   1\n",
      "      15674 |   0.191739  |    0.084480     |   1\n",
      "      15675 |   0.054271  |    0.015946     |   2\n",
      "      15676 |   0.051160  |    0.044406     |   2\n",
      "      15677 |   0.246505  |    0.107439     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 15678: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      15678 |   0.220210  |    0.049095     |   1\n",
      "      15679 |   0.054109  |    0.010002     |   2\n",
      "      15680 |   0.038230  |    0.047804     |   2\n",
      "      15681 |   0.041075  |    0.007363     |   2\n",
      "      15682 |   0.252131  |    0.043400     |   0\n",
      "      15683 |   0.196858  |    0.013723     |   0\n",
      "      15684 |   0.048194  |    0.029144     |   2\n",
      "      15685 |   0.213843  |    0.094848     |   1\n",
      "      15686 |   0.211601  |    0.093105     |   1\n",
      "      15687 |   0.029579  |    0.010015     |   2\n",
      "      15688 |   0.043608  |    0.045203     |   2\n",
      "      15689 |   0.051727  |    0.009462     |   2\n",
      "      15690 |   0.065410  |    0.046549     |   2\n",
      "      15691 |   0.049464  |    0.014025     |   2\n",
      "      15692 |   0.269684  |    0.136163     |   1\n",
      "      15693 |   0.024794  |    0.008143     |   2\n",
      "      15694 |   0.215869  |    0.151349     |   1\n",
      "      15695 |   0.341945  |    0.037655     |   1\n",
      "      15696 |   0.167738  |    0.030044     |   0\n",
      "      15697 |   0.226803  |    0.091430     |   1\n",
      "      15698 | \u001b[94m  0.000038\u001b[0m  |    0.029690     |   2\n",
      "      15699 |   0.161593  |    0.019969     |   0\n",
      "      15700 |   0.185140  |    0.020845     |   0\n",
      "      15701 |   0.216680  |    0.088767     |   1\n",
      "      15702 |   0.186923  |    0.139294     |   1\n",
      "      15703 |   0.005817  |    0.002958     |   2\n",
      "      15704 |   0.071506  |    0.008932     |   2\n",
      "      15705 |   0.231581  |    0.040765     |   0\n",
      "      15706 |   0.172084  |    0.133729     |   1\n",
      "      15707 |   0.172870  |    0.093849     |   1\n",
      "      15708 |   0.211816  |    0.098631     |   1\n",
      "      15709 |   0.037086  |    0.013158     |   2\n",
      "      15710 |   0.247352  |    0.133137     |   1\n",
      "      15711 |   0.238667  |    0.007105     |   0\n",
      "      15712 |   0.237662  |    0.024036     |   0\n",
      "      15713 |   0.058994  |    0.035587     |   2\n",
      "      15714 |   0.217906  |    0.147758     |   1\n",
      "      15715 |   0.051002  |    0.009969     |   2\n",
      "      15716 |   0.210844  |    0.097807     |   1\n",
      "      15717 |   0.232354  |    0.077693     |   1\n",
      "      15718 |   0.195835  |    0.021699     |   0\n",
      "      15719 |   0.245403  |    0.035996     |   0\n",
      "      15720 |   0.022081  |    0.009375     |   2\n",
      "      15721 |   0.039898  |    0.042056     |   2\n",
      "      15722 |   0.214750  |    0.082864     |   1\n",
      "      15723 |   0.239397  |    0.140127     |   1\n",
      "      15724 |   0.346349  |    0.053868     |   1\n",
      "      15725 |   0.033245  |    0.012512     |   2\n",
      "      15726 |   0.235104  |    0.045018     |   0\n",
      "      15727 |   0.168499  |    0.022093     |   0\n",
      "      15728 | \u001b[94m  0.000038\u001b[0m  |    0.019232     |   2\n",
      "      15729 |   0.164497  |    0.030714     |   0\n",
      "      15730 |   0.223328  |    0.041758     |   0\n",
      "      15731 | \u001b[94m  0.000038\u001b[0m  |    0.014600     |   2\n",
      "      15732 |   0.219137  |    0.045347     |   0\n",
      "      15733 | \u001b[94m  0.000038\u001b[0m  |    0.006324     |   2\n",
      "      15734 |   0.224805  |    0.056844     |   0\n",
      "      15735 |   0.000038  |    0.018864     |   2\n",
      "      15736 |   0.181818  |    0.102744     |   1\n",
      "      15737 | \u001b[94m  0.000038\u001b[0m  |    0.017567     |   2\n",
      "      15738 |   0.176483  |    0.036673     |   0\n",
      "      15739 |   0.155510  |    0.023485     |   0\n",
      "      15740 |   0.224217  |    0.175086     |   1\n",
      "      15741 |   0.246082  |    0.022217     |   1\n",
      "      15742 | \u001b[94m  0.000038\u001b[0m  |    0.021588     |   2\n",
      "      15743 |   0.053840  |    0.024493     |   2\n",
      "      15744 |   0.224612  |    0.096727     |   1\n",
      "      15745 |   0.050821  |    0.005750     |   2\n",
      "      15746 |   0.168237  |    0.022615     |   0\n",
      "      15747 |   0.163877  |    0.148619     |   1\n",
      "      15748 |   0.232989  |    0.015963     |   0\n",
      "      15749 |   0.148473  |    0.083644     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 15751: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      15750 |   0.181220  |    0.023219     |   0\n",
      "      15751 |   0.231833  |    0.137887     |   1\n",
      "      15752 |   0.181953  |    0.067395     |   1\n",
      "      15753 |   0.247659  |    0.095808     |   1\n",
      "      15754 |   0.056391  |    0.007363     |   2\n",
      "      15755 |   0.222890  |    0.148938     |   1\n",
      "      15756 |   0.217789  |    0.015152     |   0\n",
      "      15757 |   0.143311  |    0.052121     |   1\n",
      "      15758 |   0.252917  |    0.101324     |   1\n",
      "      15759 |   0.233864  |    0.021981     |   0\n",
      "      15760 |   0.231853  |    0.045903     |   0\n",
      "      15761 |   0.183814  |    0.086542     |   1\n",
      "      15762 |   0.216517  |    0.146553     |   1\n",
      "      15763 |   0.039548  |    0.007579     |   2\n",
      "      15764 |   0.216214  |    0.083547     |   1\n",
      "      15765 |   0.228909  |    0.044513     |   0\n",
      "      15766 |   0.183427  |    0.105767     |   1\n",
      "      15767 |   0.041572  |    0.010433     |   2\n",
      "      15768 |   0.202582  |    0.093984     |   1\n",
      "      15769 |   0.215888  |    0.115635     |   1\n",
      "      15770 |   0.242867  |    0.005731     |   0\n",
      "      15771 |   0.175638  |    0.019589     |   0\n",
      "      15772 |   0.236924  |    0.055296     |   1\n",
      "      15773 |   0.167340  |    0.025151     |   0\n",
      "      15774 |   0.212089  |    0.163158     |   1\n",
      "      15775 |   0.187450  |    0.027087     |   1\n",
      "      15776 |   0.207843  |    0.088234     |   1\n",
      "      15777 |   0.050817  |    0.010364     |   2\n",
      "      15778 |   0.209579  |    0.054819     |   0\n",
      "      15779 |   0.247041  |    0.086741     |   1\n",
      "      15780 |   0.030708  |    0.011681     |   2\n",
      "      15781 |   0.044694  |    0.041465     |   2\n",
      "      15782 |   0.173194  |    0.013113     |   0\n",
      "      15783 |   0.252287  |    0.138486     |   1\n",
      "      15784 |   0.048254  |    0.002947     |   2\n",
      "      15785 |   0.065313  |    0.014219     |   2\n",
      "      15786 |   0.230606  |    0.160123     |   1\n",
      "      15787 |   0.055462  |    0.002981     |   2\n",
      "      15788 |   0.028607  |    0.014604     |   2\n",
      "      15789 |   0.146186  |    0.132370     |   1\n",
      "      15790 |   0.236710  |    0.010441     |   0\n",
      "      15791 |   0.193639  |    0.162236     |   1\n",
      "      15792 |   0.209796  |    0.007695     |   0\n",
      "      15793 |   0.187549  |    0.100726     |   1\n",
      "      15794 |   0.000038  |    0.004583     |   2\n",
      "      15795 |   0.163859  |    0.044300     |   0\n",
      "      15796 |   0.006413  |    0.007865     |   2\n",
      "      15797 |   0.073054  |    0.048096     |   2\n",
      "      15798 |   0.037532  |    0.015527     |   2\n",
      "      15799 |   0.241672  |    0.146921     |   1\n",
      "      15800 |   0.214956  |    0.051711     |   1\n",
      "      15801 |   0.058643  |    0.013912     |   2\n",
      "      15802 |   0.250911  |    0.068526     |   0\n",
      "      15803 |   0.170599  |    0.098382     |   1\n",
      "      15804 |   0.224871  |    0.008353     |   0\n",
      "      15805 |   0.178094  |    0.135076     |   1\n",
      "      15806 |   0.199934  |    0.007703     |   0\n",
      "      15807 |   0.048829  |    0.008427     |   2\n",
      "      15808 |   0.196727  |    0.133827     |   1\n",
      "      15809 |   0.019723  |    0.006308     |   2\n",
      "      15810 |   0.237471  |    0.047454     |   0\n",
      "      15811 |   0.211336  |    0.090169     |   1\n",
      "      15812 |   0.039410  |    0.013339     |   2\n",
      "      15813 |   0.197051  |    0.045720     |   0\n",
      "      15814 |   0.033336  |    0.011327     |   2\n",
      "      15815 |   0.201752  |    0.046421     |   0\n",
      "      15816 |   0.185661  |    0.016881     |   0\n",
      "      15817 |   0.000038  |    0.042150     |   2\n",
      "      15818 |   0.234733  |    0.105852     |   1\n",
      "      15819 |   0.000038  |    0.012101     |   2\n",
      "      15820 |   0.172627  |    0.093776     |   1\n",
      "      15821 |   0.181184  |    0.127204     |   1\n",
      "      15822 | \u001b[94m  0.000038\u001b[0m  |    0.004015     |   2\n",
      "      15823 |   0.178436  |    0.010484     |   0\n",
      "      15824 |   0.226729  |    0.043236     |   0\n",
      "      15825 |   0.000038  |    0.009054     |   2\n",
      "      15826 |   0.232731  |    0.035241     |   0\n",
      "      15827 | \u001b[94m  0.000038\u001b[0m  |    0.052481     |   2\n",
      "      15828 |   0.211241  |    0.107755     |   1\n",
      "      15829 |   0.231417  |    0.078176     |   1\n",
      "      15830 | \u001b[94m  0.000037\u001b[0m  |    0.012451     |   2\n",
      "      15831 |   0.058523  |    0.043408     |   2\n",
      "      15832 |   0.167791  |    0.021850     |   0\n",
      "      15833 |   0.051985  |    0.024837     |   2\n",
      "      15834 |   0.194932  |    0.027576     |   0\n",
      "      15835 |   0.194937  |    0.035845     |   0\n",
      "      15836 |   0.143444  |    0.023198     |   0\n",
      "      15837 |   0.157613  |    0.143867     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 15838: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      15838 |   0.059568  |    0.004254     |   2\n",
      "      15839 |   0.204339  |    0.012771     |   0\n",
      "      15840 |   0.042085  |    0.044930     |   2\n",
      "      15841 |   0.043377  |    0.008903     |   2\n",
      "      15842 |   0.052023  |    0.052154     |   2\n",
      "      15843 |   0.193392  |    0.129895     |   1\n",
      "      15844 |   0.246485  |    0.033472     |   1\n",
      "      15845 |   0.191764  |    0.085737     |   1\n",
      "      15846 |   0.203836  |    0.146976     |   1\n",
      "      15847 |   0.183714  |    0.003897     |   0\n",
      "      15848 |   0.276405  |    0.028851     |   0\n",
      "      15849 |   0.162536  |    0.164047     |   1\n",
      "      15850 |   0.216456  |    0.009319     |   0\n",
      "      15851 |   0.190855  |    0.043647     |   1\n",
      "      15852 |   0.188303  |    0.101007     |   1\n",
      "      15853 |   0.225466  |    0.077868     |   1\n",
      "      15854 |   0.211137  |    0.011865     |   0\n",
      "      15855 |   0.175309  |    0.045535     |   0\n",
      "      15856 |   0.029703  |    0.037312     |   2\n",
      "      15857 |   0.272900  |    0.106255     |   1\n",
      "      15858 |   0.218051  |    0.096973     |   1\n",
      "      15859 |   0.178440  |    0.081165     |   1\n",
      "      15860 |   0.223480  |    0.010561     |   0\n",
      "      15861 |   0.159666  |    0.129825     |   1\n",
      "      15862 |   0.043899  |    0.009075     |   2\n",
      "      15863 |   0.053052  |    0.030604     |   2\n",
      "      15864 |   0.204244  |    0.043864     |   0\n",
      "      15865 |   0.246920  |    0.017315     |   0\n",
      "      15866 |   0.164738  |    0.143056     |   1\n",
      "      15867 |   0.061311  |    0.008488     |   2\n",
      "      15868 |   0.053523  |    0.005010     |   2\n",
      "      15869 |   0.026840  |    0.046910     |   2\n",
      "      15870 | \u001b[94m  0.000037\u001b[0m  |    0.017019     |   2\n",
      "      15871 |   0.005950  |    0.043961     |   2\n",
      "      15872 |   0.074636  |    0.004450     |   2\n",
      "      15873 |   0.210785  |    0.057771     |   0\n",
      "      15874 |   0.251528  |    0.098768     |   1\n",
      "      15875 |   0.241933  |    0.071594     |   1\n",
      "      15876 |   0.198992  |    0.142607     |   1\n",
      "      15877 |   0.241528  |    0.003044     |   0\n",
      "      15878 |   0.245940  |    0.008953     |   0\n",
      "      15879 |   0.035296  |    0.045172     |   2\n",
      "      15880 |   0.061614  |    0.009831     |   2\n",
      "      15881 |   0.196420  |    0.050647     |   0\n",
      "      15882 |   0.253413  |    0.164409     |   1\n",
      "      15883 |   0.179112  |    0.006672     |   0\n",
      "      15884 |   0.150216  |    0.066859     |   1\n",
      "      15885 |   0.239298  |    0.018824     |   0\n",
      "      15886 |   0.050494  |    0.044873     |   2\n",
      "      15887 |   0.156449  |    0.092172     |   1\n",
      "      15888 |   0.212351  |    0.008613     |   0\n",
      "      15889 |   0.242210  |    0.128842     |   1\n",
      "      15890 |   0.020974  |    0.008566     |   2\n",
      "      15891 |   0.041285  |    0.038339     |   2\n",
      "      15892 |   0.033970  |    0.011074     |   2\n",
      "      15893 |   0.237772  |    0.046058     |   0\n",
      "      15894 | \u001b[94m  0.000037\u001b[0m  |    0.010984     |   2\n",
      "      15895 |   0.168549  |    0.152348     |   1\n",
      "      15896 |   0.268311  |    0.085000     |   1\n",
      "      15897 |   0.190234  |    0.011916     |   0\n",
      "      15898 |   0.179582  |    0.014610     |   0\n",
      "      15899 |   0.209990  |    0.029222     |   0\n",
      "      15900 | \u001b[94m  0.000037\u001b[0m  |    0.030089     |   2\n",
      "      15901 |   0.274773  |    0.090053     |   1\n",
      "      15902 |   0.223416  |    0.094636     |   1\n",
      "      15903 |   0.000037  |    0.020389     |   2\n",
      "      15904 |   0.000038  |    0.063701     |   2\n",
      "      15905 |   0.176154  |    0.089422     |   1\n",
      "      15906 |   0.000037  |    0.005600     |   2\n",
      "      15907 |   0.000037  |    0.044560     |   2\n",
      "      15908 |   0.055083  |    0.012897     |   2\n",
      "      15909 |   0.200390  |    0.034773     |   0\n",
      "      15910 |   0.188432  |    0.028240     |   0\n",
      "      15911 |   0.153148  |    0.033288     |   0\n",
      "      15912 |   0.142438  |    0.142039     |   1\n",
      "      15913 |   0.209550  |    0.005362     |   0\n",
      "      15914 |   0.178807  |    0.007500     |   0\n",
      "      15915 |   0.184143  |    0.040502     |   0\n",
      "      15916 |   0.050519  |    0.009764     |   2\n",
      "      15917 |   0.260674  |    0.044303     |   0\n",
      "      15918 |   0.183344  |    0.018833     |   0\n",
      "      15919 |   0.215577  |    0.045441     |   0\n",
      "      15920 |   0.223905  |    0.010460     |   0\n",
      "      15921 |   0.184448  |    0.046616     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 15922: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      15922 |   0.055929  |    0.012967     |   2\n",
      "      15923 |   0.039355  |    0.044575     |   2\n",
      "      15924 |   0.214483  |    0.144126     |   1\n",
      "      15925 |   0.158024  |    0.006639     |   0\n",
      "      15926 |   0.209604  |    0.087554     |   1\n",
      "      15927 |   0.202908  |    0.006932     |   0\n",
      "      15928 |   0.165328  |    0.147684     |   1\n",
      "      15929 |   0.043049  |    0.006640     |   2\n",
      "      15930 |   0.246109  |    0.082930     |   1\n",
      "      15931 |   0.053869  |    0.022938     |   2\n",
      "      15932 |   0.204016  |    0.054034     |   0\n",
      "      15933 |   0.205886  |    0.073799     |   1\n",
      "      15934 |   0.196252  |    0.024946     |   0\n",
      "      15935 |   0.168527  |    0.140624     |   1\n",
      "      15936 |   0.189726  |    0.077183     |   1\n",
      "      15937 |   0.179258  |    0.006386     |   0\n",
      "      15938 |   0.167463  |    0.028680     |   0\n",
      "      15939 |   0.186280  |    0.045398     |   0\n",
      "      15940 |   0.030282  |    0.020223     |   2\n",
      "      15941 |   0.290523  |    0.143875     |   1\n",
      "      15942 |   0.208868  |    0.002984     |   0\n",
      "      15943 |   0.191001  |    0.023795     |   0\n",
      "      15944 |   0.167796  |    0.140515     |   1\n",
      "      15945 |   0.207390  |    0.007523     |   0\n",
      "      15946 |   0.233751  |    0.018422     |   0\n",
      "      15947 |   0.046250  |    0.033216     |   2\n",
      "      15948 |   0.053268  |    0.027540     |   2\n",
      "      15949 |   0.166230  |    0.154732     |   1\n",
      "      15950 |   0.188116  |    0.009053     |   0\n",
      "      15951 |   0.165684  |    0.101189     |   1\n",
      "      15952 |   0.183227  |    0.062822     |   1\n",
      "      15953 |   0.064707  |    0.010814     |   2\n",
      "      15954 |   0.165637  |    0.152830     |   1\n",
      "      15955 |   0.051150  |    0.004848     |   2\n",
      "      15956 |   0.192704  |    0.012741     |   0\n",
      "      15957 |   0.025952  |    0.034436     |   2\n",
      "      15958 |   0.000037  |    0.024504     |   2\n",
      "      15959 |   0.232442  |    0.140898     |   1\n",
      "      15960 |   0.197976  |    0.003609     |   0\n",
      "      15961 |   0.127087  |    0.013733     |   0\n",
      "      15962 |   0.196052  |    0.140674     |   1\n",
      "      15963 |   0.254577  |    0.092582     |   1\n",
      "      15964 |   0.219168  |    0.065408     |   1\n",
      "      15965 |   0.185442  |    0.096989     |   1\n",
      "      15966 |   0.187506  |    0.099199     |   1\n",
      "      15967 |   0.180824  |    0.019226     |   0\n",
      "      15968 |   0.006404  |    0.026751     |   2\n",
      "      15969 |   0.221907  |    0.026392     |   0\n",
      "      15970 |   0.070653  |    0.023474     |   2\n",
      "      15971 |   0.181219  |    0.134391     |   1\n",
      "      15972 |   0.236012  |    0.003913     |   0\n",
      "      15973 |   0.248869  |    0.010008     |   0\n",
      "      15974 |   0.036472  |    0.048922     |   2\n",
      "      15975 |   0.061329  |    0.006465     |   2\n",
      "      15976 |   0.049564  |    0.043221     |   2\n",
      "      15977 |   0.022078  |    0.013430     |   2\n",
      "      15978 |   0.045470  |    0.046698     |   2\n",
      "      15979 |   0.185209  |    0.083429     |   1\n",
      "      15980 |   0.033589  |    0.004394     |   2\n",
      "      15981 |   0.175233  |    0.026028     |   0\n",
      "      15982 |   0.194457  |    0.150677     |   1\n",
      "      15983 |   0.209232  |    0.008701     |   0\n",
      "      15984 |   0.172983  |    0.011197     |   0\n",
      "      15985 |   0.000037  |    0.042236     |   2\n",
      "      15986 |   0.000037  |    0.008220     |   2\n",
      "      15987 |   0.193413  |    0.048132     |   0\n",
      "      15988 |   0.000037  |    0.010615     |   2\n",
      "      15989 |   0.205466  |    0.033460     |   0\n",
      "      15990 |   0.234181  |    0.029283     |   0\n",
      "      15991 |   0.228837  |    0.027898     |   0\n",
      "      15992 |   0.000038  |    0.015752     |   2\n",
      "      15993 |   0.205940  |    0.047937     |   0\n",
      "      15994 |   0.155444  |    0.016655     |   0\n",
      "      15995 |   0.277523  |    0.172189     |   1\n",
      "      15996 |   0.185118  |    0.015509     |   0\n",
      "      15997 |   0.237136  |    0.041454     |   1\n",
      "      15998 |   0.000037  |    0.020629     |   2\n",
      "      15999 |   0.000037  |    0.041770     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 16000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 16000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      16000 |   0.176518  |    0.013047     |   0\n",
      "      16001 |   0.207140  |    0.051213     |   0\n",
      "      16002 |   0.059199  |    0.014894     |   2\n",
      "      16003 |   0.042250  |    0.042048     |   2\n",
      "      16004 |   0.041863  |    0.024171     |   2\n",
      "      16005 |   0.248369  |    0.106803     |   1\n",
      "      16006 |   0.210332  |    0.102561     |   1\n",
      "      16007 |   0.219542  |    0.089127     |   1\n",
      "      16008 |   0.225023  |    0.094328     |   1\n",
      "      16009 |   0.255284  |    0.034725     |   0\n",
      "      16010 |   0.051572  |    0.035258     |   2\n",
      "      16011 |   0.161944  |    0.088371     |   1\n",
      "      16012 |   0.235768  |    0.143476     |   1\n",
      "      16013 |   0.030368  |    0.002895     |   2\n",
      "      16014 |   0.043706  |    0.009209     |   2\n",
      "      16015 |   0.229746  |    0.143226     |   1\n",
      "      16016 |   0.212731  |    0.007708     |   0\n",
      "      16017 |   0.192385  |    0.045362     |   0\n",
      "      16018 |   0.055183  |    0.015396     |   2\n",
      "      16019 |   0.207648  |    0.037652     |   0\n",
      "      16020 |   0.233388  |    0.145044     |   1\n",
      "      16021 |   0.261000  |    0.060327     |   1\n",
      "      16022 |   0.223386  |    0.098437     |   1\n",
      "      16023 |   0.201140  |    0.009844     |   0\n",
      "      16024 |   0.064207  |    0.018855     |   2\n",
      "      16025 |   0.189898  |    0.028753     |   0\n",
      "      16026 |   0.171554  |    0.026383     |   0\n",
      "      16027 |   0.265392  |    0.159563     |   1\n",
      "      16028 |   0.201284  |    0.053136     |   1\n",
      "      16029 |   0.050348  |    0.012707     |   2\n",
      "      16030 |   0.141109  |    0.043650     |   0\n",
      "      16031 |   0.025937  |    0.010924     |   2\n",
      "      16032 |   0.181115  |    0.131511     |   1\n",
      "      16033 |   0.000037  |    0.012306     |   2\n",
      "      16034 |   0.138550  |    0.055023     |   0\n",
      "      16035 |   0.190027  |    0.089451     |   1\n",
      "      16036 |   0.005887  |    0.009259     |   2\n",
      "      16037 |   0.071164  |    0.042492     |   2\n",
      "      16038 |   0.227062  |    0.020192     |   0\n",
      "      16039 |   0.224221  |    0.045429     |   0\n",
      "      16040 |   0.213225  |    0.103330     |   1\n",
      "      16041 |   0.036756  |    0.007893     |   2\n",
      "      16042 |   0.062601  |    0.064320     |   2\n",
      "      16043 |   0.226233  |    0.097575     |   1\n",
      "      16044 |   0.049527  |    0.009615     |   2\n",
      "      16045 |   0.196832  |    0.041782     |   0\n",
      "      16046 |   0.186528  |    0.117803     |   1\n",
      "      16047 |   0.189421  |    0.046286     |   1\n",
      "      16048 |   0.167645  |    0.107025     |   1\n",
      "      16049 |   0.021342  |    0.014039     |   2\n",
      "      16050 |   0.227812  |    0.050284     |   1\n",
      "      16051 |   0.177663  |    0.026290     |   0\n",
      "      16052 |   0.045275  |    0.024105     |   2\n",
      "      16053 |   0.213381  |    0.099953     |   1\n",
      "      16054 |   0.193728  |    0.011862     |   0\n",
      "      16055 |   0.138864  |    0.057022     |   0\n",
      "      16056 |   0.159039  |    0.007363     |   0\n",
      "      16057 |   0.233167  |    0.037241     |   0\n",
      "      16058 |   0.033445  |    0.029596     |   2\n",
      "      16059 |   0.000038  |    0.026952     |   2\n",
      "      16060 |   0.171427  |    0.048197     |   1\n",
      "      16061 |   0.323733  |    0.092148     |   1\n",
      "      16062 |   0.000038  |    0.009468     |   2\n",
      "      16063 |   0.000038  |    0.038396     |   2\n",
      "      16064 |   0.000038  |    0.006409     |   2\n",
      "      16065 |   0.197872  |    0.049414     |   0\n",
      "      16066 |   0.000038  |    0.012275     |   2\n",
      "      16067 |   0.000038  |    0.039187     |   2\n",
      "      16068 |   0.220464  |    0.080175     |   1\n",
      "      16069 |   0.190318  |    0.044045     |   0\n",
      "      16070 |   0.209780  |    0.026450     |   0\n",
      "      16071 |   0.054215  |    0.040638     |   2\n",
      "      16072 |   0.051823  |    0.022842     |   2\n",
      "      16073 |   0.257221  |    0.147233     |   1\n",
      "      16074 |   0.242771  |    0.021187     |   1\n",
      "      16075 |   0.220490  |    0.032774     |   0\n",
      "      16076 |   0.186350  |    0.089625     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 16077: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      16077 |   0.207446  |    0.012224     |   0\n",
      "      16078 |   0.215421  |    0.149416     |   1\n",
      "      16079 |   0.163284  |    0.106816     |   1\n",
      "      16080 |   0.201309  |    0.086009     |   1\n",
      "      16081 |   0.219483  |    0.006699     |   0\n",
      "      16082 |   0.223119  |    0.029556     |   0\n",
      "      16083 |   0.053844  |    0.030851     |   2\n",
      "      16084 |   0.241501  |    0.136468     |   1\n",
      "      16085 |   0.213244  |    0.004884     |   0\n",
      "      16086 |   0.208759  |    0.006613     |   0\n",
      "      16087 |   0.233548  |    0.046097     |   0\n",
      "      16088 |   0.037125  |    0.015767     |   2\n",
      "      16089 |   0.183797  |    0.150841     |   1\n",
      "      16090 |   0.212344  |    0.085276     |   1\n",
      "      16091 |   0.231233  |    0.136104     |   1\n",
      "      16092 |   0.189896  |    0.014221     |   0\n",
      "      16093 |   0.198548  |    0.064133     |   1\n",
      "      16094 |   0.140084  |    0.142615     |   1\n",
      "      16095 |   0.042013  |    0.009178     |   2\n",
      "      16096 |   0.187750  |    0.038034     |   1\n",
      "      16097 |   0.213064  |    0.147123     |   1\n",
      "      16098 |   0.051403  |    0.004803     |   2\n",
      "      16099 |   0.217609  |    0.075447     |   1\n",
      "      16100 |   0.029394  |    0.009742     |   2\n",
      "      16101 |   0.218700  |    0.033726     |   0\n",
      "      16102 |   0.208715  |    0.023231     |   0\n",
      "      16103 |   0.041588  |    0.026130     |   2\n",
      "      16104 |   0.224569  |    0.034041     |   0\n",
      "      16105 |   0.054874  |    0.031173     |   2\n",
      "      16106 |   0.229294  |    0.100528     |   1\n",
      "      16107 |   0.172065  |    0.015121     |   0\n",
      "      16108 |   0.191198  |    0.146791     |   1\n",
      "      16109 |   0.257565  |    0.074893     |   1\n",
      "      16110 |   0.206732  |    0.152273     |   1\n",
      "      16111 |   0.228152  |    0.047354     |   1\n",
      "      16112 |   0.215753  |    0.020910     |   0\n",
      "      16113 |   0.063275  |    0.034875     |   2\n",
      "      16114 |   0.255882  |    0.142039     |   1\n",
      "      16115 |   0.163966  |    0.002995     |   0\n",
      "      16116 |   0.049159  |    0.004864     |   2\n",
      "      16117 |   0.226975  |    0.047673     |   0\n",
      "      16118 |   0.177407  |    0.010234     |   0\n",
      "      16119 |   0.025334  |    0.047220     |   2\n",
      "      16120 |   0.176895  |    0.153310     |   1\n",
      "      16121 | \u001b[94m  0.000037\u001b[0m  |    0.012328     |   2\n",
      "      16122 |   0.201301  |    0.083773     |   1\n",
      "      16123 |   0.006134  |    0.007710     |   2\n",
      "      16124 |   0.193636  |    0.037364     |   0\n",
      "      16125 |   0.170434  |    0.087228     |   1\n",
      "      16126 |   0.278351  |    0.019093     |   0\n",
      "      16127 |   0.186926  |    0.028070     |   0\n",
      "      16128 |   0.263872  |    0.081873     |   1\n",
      "      16129 |   0.154090  |    0.018110     |   0\n",
      "      16130 |   0.069455  |    0.026881     |   2\n",
      "      16131 |   0.035742  |    0.049149     |   2\n",
      "      16132 |   0.194087  |    0.079043     |   1\n",
      "      16133 |   0.062808  |    0.011411     |   2\n",
      "      16134 |   0.227054  |    0.091739     |   1\n",
      "      16135 |   0.213586  |    0.146877     |   1\n",
      "      16136 |   0.221296  |    0.003123     |   0\n",
      "      16137 |   0.181803  |    0.019337     |   0\n",
      "      16138 |   0.177374  |    0.036660     |   0\n",
      "      16139 |   0.217386  |    0.105331     |   1\n",
      "      16140 |   0.233313  |    0.006410     |   0\n",
      "      16141 |   0.143382  |    0.089668     |   1\n",
      "      16142 |   0.171702  |    0.029669     |   0\n",
      "      16143 |   0.254488  |    0.137957     |   1\n",
      "      16144 |   0.167982  |    0.082569     |   1\n",
      "      16145 |   0.049587  |    0.019113     |   2\n",
      "      16146 |   0.194134  |    0.135859     |   1\n",
      "      16147 |   0.288642  |    0.087596     |   1\n",
      "      16148 |   0.198564  |    0.024225     |   0\n",
      "      16149 |   0.192268  |    0.093128     |   1\n",
      "      16150 |   0.143314  |    0.064063     |   0\n",
      "      16151 |   0.187442  |    0.093648     |   1\n",
      "      16152 |   0.018951  |    0.011362     |   2\n",
      "      16153 |   0.043138  |    0.044924     |   2\n",
      "      16154 |   0.206937  |    0.014731     |   0\n",
      "      16155 |   0.214271  |    0.113620     |   1\n",
      "      16156 |   0.203713  |    0.012595     |   0\n",
      "      16157 |   0.219813  |    0.155389     |   1\n",
      "      16158 |   0.199050  |    0.028621     |   0\n",
      "      16159 |   0.178846  |    0.063867     |   1\n",
      "      16160 |   0.217602  |    0.142808     |   1\n",
      "      16161 |   0.254912  |    0.066543     |   1\n",
      "      16162 |   0.031229  |    0.007045     |   2\n",
      "      16163 |   0.208082  |    0.133286     |   1\n",
      "      16164 |   0.000037  |    0.008367     |   2\n",
      "      16165 |   0.315978  |    0.022145     |   0\n",
      "      16166 |   0.244467  |    0.035221     |   0\n",
      "      16167 |   0.000037  |    0.009013     |   2\n",
      "      16168 |   0.171134  |    0.041054     |   0\n",
      "      16169 |   0.000037  |    0.023869     |   2\n",
      "      16170 |   0.000038  |    0.027247     |   2\n",
      "      16171 |   0.000037  |    0.027373     |   2\n",
      "      16172 |   0.234668  |    0.137835     |   1\n",
      "      16173 |   0.154506  |    0.010048     |   0\n",
      "      16174 |   0.000037  |    0.015066     |   2\n",
      "      16175 |   0.225967  |    0.046354     |   0\n",
      "      16176 |   0.057959  |    0.023204     |   2\n",
      "      16177 |   0.197930  |    0.144769     |   1\n",
      "      16178 |   0.140076  |    0.057436     |   1\n",
      "      16179 |   0.050545  |    0.014863     |   2\n",
      "      16180 |   0.214006  |    0.057574     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 16181: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      16181 |   0.191526  |    0.084210     |   1\n",
      "      16182 |   0.172997  |    0.163312     |   1\n",
      "      16183 |   0.201768  |    0.014048     |   1\n",
      "      16184 |   0.211292  |    0.043936     |   0\n",
      "      16185 |   0.194748  |    0.010794     |   0\n",
      "      16186 |   0.175777  |    0.039756     |   0\n",
      "      16187 |   0.058305  |    0.013754     |   2\n",
      "      16188 |   0.044145  |    0.045231     |   2\n",
      "      16189 |   0.212902  |    0.023838     |   0\n",
      "      16190 |   0.166333  |    0.191061     |   1\n",
      "      16191 |   0.199670  |    0.023173     |   1\n",
      "      16192 |   0.197200  |    0.090090     |   1\n",
      "      16193 |   0.257618  |    0.007496     |   0\n",
      "      16194 |   0.176887  |    0.048739     |   0\n",
      "      16195 |   0.188396  |    0.106418     |   1\n",
      "      16196 |   0.256571  |    0.083846     |   1\n",
      "      16197 |   0.199933  |    0.011963     |   0\n",
      "      16198 |   0.155553  |    0.041787     |   0\n",
      "      16199 |   0.221683  |    0.015679     |   0\n",
      "      16200 |   0.042102  |    0.025885     |   2\n",
      "      16201 |   0.247520  |    0.133865     |   1\n",
      "      16202 |   0.215114  |    0.003249     |   0\n",
      "      16203 |   0.176343  |    0.009763     |   0\n",
      "      16204 |   0.196806  |    0.050339     |   0\n",
      "      16205 |   0.051167  |    0.031384     |   2\n",
      "      16206 |   0.183517  |    0.160025     |   1\n",
      "      16207 |   0.210229  |    0.076532     |   1\n",
      "      16208 |   0.226672  |    0.054510     |   1\n",
      "      16209 |   0.030883  |    0.006125     |   2\n",
      "      16210 |   0.221792  |    0.165703     |   1\n",
      "      16211 |   0.190647  |    0.056464     |   1\n",
      "      16212 |   0.244854  |    0.011192     |   0\n",
      "      16213 |   0.044722  |    0.038167     |   2\n",
      "      16214 |   0.194585  |    0.154268     |   1\n",
      "      16215 |   0.205879  |    0.003346     |   0\n",
      "      16216 |   0.052085  |    0.007380     |   2\n",
      "      16217 |   0.244324  |    0.144383     |   1\n",
      "      16218 |   0.144283  |    0.057167     |   1\n",
      "      16219 |   0.065243  |    0.019995     |   2\n",
      "      16220 |   0.236658  |    0.052075     |   0\n",
      "      16221 |   0.051016  |    0.017132     |   2\n",
      "      16222 |   0.198999  |    0.152418     |   1\n",
      "      16223 |   0.186695  |    0.007505     |   0\n",
      "      16224 |   0.205721  |    0.091457     |   1\n",
      "      16225 |   0.198773  |    0.093086     |   1\n",
      "      16226 |   0.230803  |    0.014101     |   0\n",
      "      16227 |   0.178217  |    0.144288     |   1\n",
      "      16228 |   0.183198  |    0.085591     |   1\n",
      "      16229 |   0.025774  |    0.006192     |   2\n",
      "      16230 |   0.195973  |    0.136298     |   1\n",
      "      16231 | \u001b[94m  0.000037\u001b[0m  |    0.003057     |   2\n",
      "      16232 |   0.005944  |    0.009566     |   2\n",
      "      16233 |   0.153380  |    0.037251     |   0\n",
      "      16234 |   0.071874  |    0.008664     |   2\n",
      "      16235 |   0.036225  |    0.027085     |   2\n",
      "      16236 |   0.246748  |    0.080044     |   1\n",
      "      16237 |   0.198280  |    0.031119     |   0\n",
      "      16238 |   0.206291  |    0.153230     |   1\n",
      "      16239 |   0.151624  |    0.071669     |   1\n",
      "      16240 |   0.061860  |    0.005091     |   2\n",
      "      16241 |   0.151384  |    0.032051     |   0\n",
      "      16242 |   0.048419  |    0.015617     |   2\n",
      "      16243 |   0.019384  |    0.023736     |   2\n",
      "      16244 |   0.042065  |    0.024380     |   2\n",
      "      16245 |   0.217324  |    0.044488     |   0\n",
      "      16246 |   0.033427  |    0.007602     |   2\n",
      "      16247 |   0.219766  |    0.084560     |   1\n",
      "      16248 |   0.225194  |    0.036310     |   0\n",
      "      16249 |   0.216790  |    0.083599     |   1\n",
      "      16250 |   0.229997  |    0.104879     |   1\n",
      "      16251 |   0.201621  |    0.006410     |   0\n",
      "      16252 |   0.186505  |    0.050063     |   0\n",
      "      16253 |   0.280494  |    0.111122     |   1\n",
      "      16254 |   0.000037  |    0.011770     |   2\n",
      "      16255 |   0.217742  |    0.091864     |   1\n",
      "      16256 |   0.231103  |    0.106910     |   1\n",
      "      16257 |   0.212400  |    0.080932     |   1\n",
      "      16258 |   0.000037  |    0.022616     |   2\n",
      "      16259 |   0.000037  |    0.018296     |   2\n",
      "      16260 |   0.000038  |    0.032916     |   2\n",
      "      16261 |   0.200337  |    0.035724     |   0\n",
      "      16262 |   0.000037  |    0.017574     |   2\n",
      "      16263 |   0.000037  |    0.033984     |   2\n",
      "      16264 |   0.192183  |    0.101726     |   1\n",
      "      16265 |   0.245825  |    0.039865     |   0\n",
      "      16266 |   0.213628  |    0.086765     |   1\n",
      "      16267 |   0.161914  |    0.012799     |   0\n",
      "      16268 |   0.053292  |    0.056201     |   2\n",
      "      16269 |   0.049335  |    0.014178     |   2\n",
      "      16270 |   0.213289  |    0.032386     |   0\n",
      "      16271 |   0.198355  |    0.033628     |   0\n",
      "      16272 |   0.217978  |    0.080943     |   1\n",
      "      16273 |   0.291771  |    0.089100     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 16275: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      16274 |   0.194230  |    0.023502     |   0\n",
      "      16275 |   0.212370  |    0.139411     |   1\n",
      "      16276 |   0.264650  |    0.063537     |   1\n",
      "      16277 |   0.277039  |    0.028558     |   0\n",
      "      16278 |   0.220691  |    0.049597     |   0\n",
      "      16279 |   0.298574  |    0.089467     |   1\n",
      "      16280 |   0.053088  |    0.010225     |   2\n",
      "      16281 |   0.176412  |    0.072692     |   1\n",
      "      16282 |   0.254659  |    0.033268     |   0\n",
      "      16283 |   0.162274  |    0.030522     |   0\n",
      "      16284 |   0.039407  |    0.010913     |   2\n",
      "      16285 |   0.231961  |    0.091129     |   1\n",
      "      16286 |   0.213907  |    0.014387     |   0\n",
      "      16287 |   0.245596  |    0.052736     |   0\n",
      "      16288 |   0.042864  |    0.009600     |   2\n",
      "      16289 |   0.231503  |    0.045889     |   0\n",
      "      16290 |   0.052197  |    0.027460     |   2\n",
      "      16291 |   0.189009  |    0.148671     |   1\n",
      "      16292 |   0.030399  |    0.003130     |   2\n",
      "      16293 |   0.043381  |    0.008339     |   2\n",
      "      16294 |   0.054454  |    0.039469     |   2\n",
      "      16295 |   0.197306  |    0.140681     |   1\n",
      "      16296 |   0.155889  |    0.003173     |   0\n",
      "      16297 |   0.244944  |    0.023040     |   0\n",
      "      16298 |   0.063596  |    0.029066     |   2\n",
      "      16299 |   0.214757  |    0.085966     |   1\n",
      "      16300 |   0.182524  |    0.028825     |   0\n",
      "      16301 |   0.245653  |    0.118783     |   1\n",
      "      16302 |   0.049118  |    0.016275     |   2\n",
      "      16303 |   0.024717  |    0.026750     |   2\n",
      "      16304 |   0.247025  |    0.114574     |   1\n",
      "      16305 |   0.171441  |    0.067730     |   1\n",
      "      16306 | \u001b[94m  0.000036\u001b[0m  |    0.018388     |   2\n",
      "      16307 |   0.186143  |    0.136453     |   1\n",
      "      16308 |   0.005804  |    0.003054     |   2\n",
      "      16309 |   0.191187  |    0.016563     |   0\n",
      "      16310 |   0.203622  |    0.096504     |   1\n",
      "      16311 |   0.206995  |    0.038162     |   0\n",
      "      16312 |   0.231350  |    0.112990     |   1\n",
      "      16313 |   0.070273  |    0.019776     |   2\n",
      "      16314 |   0.237598  |    0.069707     |   1\n",
      "      16315 |   0.182866  |    0.010562     |   0\n",
      "      16316 |   0.037965  |    0.039729     |   2\n",
      "      16317 |   0.152611  |    0.012974     |   0\n",
      "      16318 |   0.060150  |    0.039927     |   2\n",
      "      16319 |   0.047236  |    0.037103     |   2\n",
      "      16320 |   0.233271  |    0.111837     |   1\n",
      "      16321 |   0.205209  |    0.108813     |   1\n",
      "      16322 |   0.205631  |    0.083803     |   1\n",
      "      16323 |   0.218251  |    0.015686     |   0\n",
      "      16324 |   0.019286  |    0.039795     |   2\n",
      "      16325 |   0.208643  |    0.131100     |   1\n",
      "      16326 |   0.162135  |    0.006630     |   0\n",
      "      16327 |   0.231849  |    0.016870     |   0\n",
      "      16328 |   0.196256  |    0.152370     |   1\n",
      "      16329 |   0.041799  |    0.002902     |   2\n",
      "      16330 |   0.033623  |    0.010916     |   2\n",
      "      16331 |   0.000036  |    0.025864     |   2\n",
      "      16332 |   0.172189  |    0.022447     |   0\n",
      "      16333 |   0.229128  |    0.030493     |   0\n",
      "      16334 | \u001b[94m  0.000036\u001b[0m  |    0.020038     |   2\n",
      "      16335 | \u001b[94m  0.000036\u001b[0m  |    0.027263     |   2\n",
      "      16336 |   0.000037  |    0.020102     |   2\n",
      "      16337 |   0.000036  |    0.018563     |   2\n",
      "      16338 |   0.177607  |    0.031539     |   0\n",
      "      16339 | \u001b[94m  0.000036\u001b[0m  |    0.023699     |   2\n",
      "      16340 |   0.180769  |    0.053599     |   0\n",
      "      16341 |   0.221971  |    0.079660     |   1\n",
      "      16342 |   0.228553  |    0.049989     |   0\n",
      "      16343 |   0.060785  |    0.005153     |   2\n",
      "      16344 |   0.051375  |    0.026357     |   2\n",
      "      16345 |   0.210650  |    0.028831     |   0\n",
      "      16346 |   0.282891  |    0.135759     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 16349: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      16347 |   0.190853  |    0.003173     |   0\n",
      "      16348 |   0.184584  |    0.017478     |   0\n",
      "      16349 |   0.153450  |    0.124075     |   1\n",
      "      16350 |   0.191385  |    0.083692     |   1\n",
      "      16351 |   0.294378  |    0.079979     |   1\n",
      "      16352 |   0.264411  |    0.099131     |   1\n",
      "      16353 |   0.055910  |    0.012255     |   2\n",
      "      16354 |   0.182161  |    0.147610     |   1\n",
      "      16355 |   0.040304  |    0.002950     |   2\n",
      "      16356 |   0.043352  |    0.011688     |   2\n",
      "      16357 |   0.210971  |    0.027502     |   0\n",
      "      16358 |   0.049454  |    0.041737     |   2\n",
      "      16359 |   0.155387  |    0.156347     |   1\n",
      "      16360 |   0.030394  |    0.005154     |   2\n",
      "      16361 |   0.041288  |    0.005382     |   2\n",
      "      16362 |   0.152884  |    0.020901     |   0\n",
      "      16363 |   0.156263  |    0.028733     |   0\n",
      "      16364 |   0.184390  |    0.023369     |   0\n",
      "      16365 |   0.159386  |    0.145943     |   1\n",
      "      16366 |   0.201412  |    0.052173     |   1\n",
      "      16367 |   0.193834  |    0.143062     |   1\n",
      "      16368 |   0.221678  |    0.059212     |   1\n",
      "      16369 |   0.048782  |    0.012161     |   2\n",
      "      16370 |   0.064315  |    0.032042     |   2\n",
      "      16371 |   0.169511  |    0.024493     |   0\n",
      "      16372 |   0.182541  |    0.027004     |   0\n",
      "      16373 |   0.224086  |    0.032929     |   0\n",
      "      16374 |   0.220743  |    0.146996     |   1\n",
      "      16375 |   0.250209  |    0.082103     |   1\n",
      "      16376 |   0.170978  |    0.014486     |   0\n",
      "      16377 |   0.198327  |    0.091147     |   1\n",
      "      16378 |   0.237395  |    0.006339     |   0\n",
      "      16379 |   0.215646  |    0.037704     |   0\n",
      "      16380 |   0.155679  |    0.089894     |   1\n",
      "      16381 |   0.165904  |    0.143450     |   1\n",
      "      16382 |   0.049826  |    0.002907     |   2\n",
      "      16383 |   0.024456  |    0.007413     |   2\n",
      "      16384 |   0.164840  |    0.043653     |   0\n",
      "      16385 |   0.179010  |    0.012168     |   0\n",
      "      16386 |   0.000036  |    0.041527     |   2\n",
      "      16387 |   0.213646  |    0.016401     |   0\n",
      "      16388 |   0.241484  |    0.135025     |   1\n",
      "      16389 |   0.202607  |    0.007518     |   0\n",
      "      16390 |   0.235623  |    0.022201     |   0\n",
      "      16391 |   0.185199  |    0.137757     |   1\n",
      "      16392 |   0.181447  |    0.008244     |   0\n",
      "      16393 |   0.250640  |    0.011078     |   0\n",
      "      16394 |   0.006591  |    0.039083     |   2\n",
      "      16395 |   0.172049  |    0.012335     |   0\n",
      "      16396 |   0.071536  |    0.042173     |   2\n",
      "      16397 |   0.226884  |    0.011737     |   0\n",
      "      16398 |   0.038007  |    0.035691     |   2\n",
      "      16399 |   0.225023  |    0.093879     |   1\n",
      "      16400 |   0.061431  |    0.013497     |   2\n",
      "      16401 |   0.155821  |    0.069750     |   0\n",
      "      16402 |   0.238274  |    0.077544     |   1\n",
      "      16403 |   0.232462  |    0.010429     |   0\n",
      "      16404 |   0.199676  |    0.131198     |   1\n",
      "      16405 |   0.050227  |    0.003168     |   2\n",
      "      16406 |   0.189968  |    0.027739     |   0\n",
      "      16407 |   0.196152  |    0.153362     |   1\n",
      "      16408 |   0.246986  |    0.003111     |   0\n",
      "      16409 |   0.021462  |    0.010188     |   2\n",
      "      16410 |   0.215790  |    0.133952     |   1\n",
      "      16411 |   0.045092  |    0.003819     |   2\n",
      "      16412 |   0.199323  |    0.023763     |   0\n",
      "      16413 |   0.169105  |    0.149517     |   1\n",
      "      16414 |   0.243982  |    0.080482     |   1\n",
      "      16415 |   0.292454  |    0.006217     |   0\n",
      "      16416 |   0.203415  |    0.044093     |   0\n",
      "      16417 |   0.187924  |    0.099791     |   1\n",
      "      16418 |   0.033410  |    0.017978     |   2\n",
      "      16419 |   0.000036  |    0.032069     |   2\n",
      "      16420 |   0.000036  |    0.020335     |   2\n",
      "      16421 |   0.000036  |    0.032533     |   2\n",
      "      16422 |   0.219439  |    0.132556     |   1\n",
      "      16423 |   0.210816  |    0.059737     |   1\n",
      "      16424 |   0.154277  |    0.147203     |   1\n",
      "      16425 |   0.000037  |    0.003085     |   2\n",
      "      16426 |   0.224212  |    0.007373     |   0\n",
      "      16427 |   0.209396  |    0.059627     |   0\n",
      "      16428 |   0.211310  |    0.018644     |   0\n",
      "      16429 |   0.000036  |    0.018243     |   2\n",
      "      16430 |   0.177721  |    0.093754     |   1\n",
      "      16431 |   0.137098  |    0.023523     |   0\n",
      "      16432 |   0.190758  |    0.041046     |   0\n",
      "      16433 |   0.179622  |    0.111335     |   1\n",
      "      16434 |   0.000036  |    0.002982     |   2\n",
      "      16435 |   0.219249  |    0.005907     |   0\n",
      "      16436 |   0.054867  |    0.046781     |   2\n",
      "      16437 |   0.050436  |    0.024175     |   2\n",
      "      16438 |   0.247370  |    0.117595     |   1\n",
      "      16439 |   0.157118  |    0.101150     |   1\n",
      "      16440 |   0.225608  |    0.015819     |   0\n",
      "      16441 |   0.181621  |    0.116847     |   1\n",
      "      16442 |   0.157085  |    0.006732     |   0\n",
      "      16443 |   0.216756  |    0.063558     |   0\n",
      "      16444 |   0.205982  |    0.116279     |   1\n",
      "      16445 |   0.210893  |    0.076500     |   1\n",
      "      16446 |   0.175890  |    0.064401     |   1\n",
      "      16447 |   0.217534  |    0.092480     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 16448: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      16448 |   0.055403  |    0.017009     |   2\n",
      "      16449 |   0.244267  |    0.142738     |   1\n",
      "      16450 |   0.187007  |    0.005699     |   0\n",
      "      16451 |   0.128510  |    0.009057     |   0\n",
      "      16452 |   0.235468  |    0.042987     |   0\n",
      "      16453 |   0.039675  |    0.014657     |   2\n",
      "      16454 |   0.181547  |    0.152603     |   1\n",
      "      16455 |   0.179697  |    0.002914     |   0\n",
      "      16456 |   0.044318  |    0.011309     |   2\n",
      "      16457 |   0.155603  |    0.176917     |   1\n",
      "      16458 |   0.148783  |    0.064242     |   1\n",
      "      16459 |   0.051768  |    0.011807     |   2\n",
      "      16460 |   0.029743  |    0.037168     |   2\n",
      "      16461 |   0.189542  |    0.091730     |   1\n",
      "      16462 |   0.154055  |    0.028831     |   0\n",
      "      16463 |   0.230198  |    0.025774     |   0\n",
      "      16464 |   0.041267  |    0.030700     |   2\n",
      "      16465 |   0.051660  |    0.035773     |   2\n",
      "      16466 |   0.182093  |    0.098372     |   1\n",
      "      16467 |   0.061583  |    0.007740     |   2\n",
      "      16468 |   0.146046  |    0.040417     |   0\n",
      "      16469 |   0.165757  |    0.022640     |   0\n",
      "      16470 |   0.049650  |    0.031921     |   2\n",
      "      16471 |   0.250381  |    0.094892     |   1\n",
      "      16472 |   0.024978  |    0.014919     |   2\n",
      "      16473 |   0.233885  |    0.063025     |   0\n",
      "      16474 |   0.198894  |    0.089423     |   1\n",
      "      16475 | \u001b[94m  0.000036\u001b[0m  |    0.005738     |   2\n",
      "      16476 |   0.005692  |    0.033338     |   2\n",
      "      16477 |   0.200648  |    0.025413     |   0\n",
      "      16478 |   0.191853  |    0.024534     |   0\n",
      "      16479 |   0.072622  |    0.007751     |   2\n",
      "      16480 |   0.226019  |    0.049998     |   0\n",
      "      16481 |   0.169244  |    0.083978     |   1\n",
      "      16482 |   0.037822  |    0.030642     |   2\n",
      "      16483 |   0.236402  |    0.171778     |   1\n",
      "      16484 |   0.060158  |    0.009633     |   2\n",
      "      16485 |   0.218777  |    0.091261     |   1\n",
      "      16486 |   0.219023  |    0.059114     |   1\n",
      "      16487 |   0.048164  |    0.025667     |   2\n",
      "      16488 |   0.217739  |    0.030253     |   0\n",
      "      16489 |   0.020635  |    0.026002     |   2\n",
      "      16490 |   0.165490  |    0.035852     |   0\n",
      "      16491 |   0.237454  |    0.088786     |   1\n",
      "      16492 |   0.268202  |    0.033242     |   0\n",
      "      16493 |   0.041245  |    0.041627     |   2\n",
      "      16494 |   0.207890  |    0.038916     |   0\n",
      "      16495 |   0.033630  |    0.028039     |   2\n",
      "      16496 |   0.000036  |    0.012967     |   2\n",
      "      16497 |   0.192109  |    0.128905     |   1\n",
      "      16498 |   0.167022  |    0.015279     |   0\n",
      "      16499 |   0.247218  |    0.153771     |   1\n",
      "      16500 |   0.200254  |    0.009925     |   0\n",
      "      16501 |   0.169938  |    0.225341     |   1\n",
      "      16502 |   0.056906  |    0.009063     |   2\n",
      "      16503 |   0.216710  |    0.079933     |   1\n",
      "      16504 |   0.040030  |    0.007270     |   2\n",
      "      16505 |   0.044375  |    0.046165     |   2\n",
      "      16506 |   0.234081  |    0.084809     |   1\n",
      "      16507 |   0.179831  |    0.026869     |   0\n",
      "      16508 |   0.173274  |    0.040461     |   0\n",
      "      16509 |   0.162865  |    0.089063     |   1\n",
      "      16510 |   0.159272  |    0.010070     |   0\n",
      "      16511 |   0.049498  |    0.023932     |   2\n",
      "      16512 |   0.029331  |    0.029811     |   2\n",
      "      16513 |   0.243232  |    0.080087     |   1\n",
      "      16514 |   0.042024  |    0.036527     |   2\n",
      "      16515 |   0.048564  |    0.017349     |   2\n",
      "      16516 |   0.192489  |    0.151768     |   1\n",
      "      16517 |   0.062045  |    0.003360     |   2\n",
      "      16518 |   0.044875  |    0.006342     |   2\n",
      "      16519 |   0.022403  |    0.043517     |   2\n",
      "      16520 |   0.165683  |    0.014595     |   0\n",
      "      16521 |   0.161481  |    0.048298     |   0\n",
      "      16522 |   0.230292  |    0.093182     |   1\n",
      "      16523 |   0.238600  |    0.005991     |   0\n",
      "      16524 |   0.172708  |    0.042164     |   0\n",
      "      16525 |   0.189009  |    0.019154     |   0\n",
      "      16526 |   0.164379  |    0.156405     |   1\n",
      "      16527 |   0.207723  |    0.007982     |   0\n",
      "      16528 |   0.222317  |    0.035127     |   1\n",
      "      16529 |   0.215105  |    0.145630     |   1\n",
      "      16530 | \u001b[94m  0.000036\u001b[0m  |    0.008970     |   2\n",
      "      16531 |   0.158912  |    0.095069     |   1\n",
      "      16532 |   0.202485  |    0.015390     |   0\n",
      "      16533 |   0.212252  |    0.028343     |   0\n",
      "      16534 |   0.254985  |    0.094471     |   1\n",
      "      16535 |   0.005434  |    0.011480     |   2\n",
      "      16536 |   0.069627  |    0.033195     |   2\n",
      "      16537 |   0.189562  |    0.032568     |   0\n",
      "      16538 |   0.035152  |    0.017349     |   2\n",
      "      16539 |   0.058394  |    0.026245     |   2\n",
      "      16540 |   0.195399  |    0.047639     |   0\n",
      "      16541 |   0.046055  |    0.010544     |   2\n",
      "      16542 |   0.262509  |    0.030539     |   0\n",
      "      16543 |   0.146960  |    0.022235     |   0\n",
      "      16544 |   0.021724  |    0.045444     |   2\n",
      "      16545 |   0.179392  |    0.029414     |   0\n",
      "      16546 |   0.268062  |    0.139726     |   1\n",
      "      16547 |   0.199895  |    0.014577     |   0\n",
      "      16548 |   0.215720  |    0.014010     |   0\n",
      "      16549 |   0.209774  |    0.083036     |   1\n",
      "      16550 |   0.215627  |    0.042692     |   0\n",
      "      16551 |   0.041409  |    0.014137     |   2\n",
      "      16552 |   0.239949  |    0.132868     |   1\n",
      "      16553 |   0.230860  |    0.006856     |   0\n",
      "      16554 |   0.035326  |    0.019939     |   2\n",
      "      16555 |   0.227408  |    0.135592     |   1\n",
      "      16556 |   0.142913  |    0.018940     |   0\n",
      "      16557 |   0.240888  |    0.146773     |   1\n",
      "      16558 |   0.000036  |    0.003023     |   2\n",
      "      16559 | \u001b[94m  0.000036\u001b[0m  |    0.011240     |   2\n",
      "      16560 | \u001b[94m  0.000036\u001b[0m  |    0.032312     |   2\n",
      "      16561 |   0.184492  |    0.140796     |   1\n",
      "      16562 |   0.195229  |    0.005575     |   0\n",
      "      16563 |   0.209297  |    0.085950     |   1\n",
      "      16564 |   0.222903  |    0.132890     |   1\n",
      "      16565 |   0.214403  |    0.048326     |   1\n",
      "      16566 |   0.223659  |    0.091551     |   1\n",
      "      16567 |   0.198340  |    0.094938     |   1\n",
      "      16568 |   0.000036  |    0.009032     |   2\n",
      "      16569 |   0.218080  |    0.142557     |   1\n",
      "      16570 |   0.000036  |    0.007317     |   2\n",
      "      16571 |   0.145184  |    0.110790     |   1\n",
      "      16572 |   0.000036  |    0.007795     |   2\n",
      "      16573 |   0.055538  |    0.081495     |   2\n",
      "      16574 |   0.162083  |    0.060966     |   1\n",
      "      16575 |   0.200827  |    0.030606     |   0\n",
      "      16576 |   0.049944  |    0.027735     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 16577: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      16577 |   0.186993  |    0.100814     |   1\n",
      "      16578 |   0.158991  |    0.086473     |   1\n",
      "      16579 |   0.202781  |    0.093514     |   1\n",
      "      16580 |   0.049783  |    0.012776     |   2\n",
      "      16581 |   0.220425  |    0.043749     |   0\n",
      "      16582 |   0.164954  |    0.006025     |   0\n",
      "      16583 |   0.038173  |    0.051266     |   2\n",
      "      16584 |   0.165313  |    0.094539     |   1\n",
      "      16585 |   0.196311  |    0.138378     |   1\n",
      "      16586 |   0.202969  |    0.004963     |   0\n",
      "      16587 |   0.219130  |    0.006090     |   0\n",
      "      16588 |   0.227443  |    0.047657     |   0\n",
      "      16589 |   0.040132  |    0.009406     |   2\n",
      "      16590 |   0.184064  |    0.050949     |   0\n",
      "      16591 |   0.047521  |    0.016725     |   2\n",
      "      16592 |   0.260791  |    0.144268     |   1\n",
      "      16593 |   0.029570  |    0.002915     |   2\n",
      "      16594 |   0.039817  |    0.005874     |   2\n",
      "      16595 |   0.214262  |    0.048238     |   0\n",
      "      16596 |   0.194398  |    0.010417     |   0\n",
      "      16597 |   0.227096  |    0.046972     |   0\n",
      "      16598 |   0.221205  |    0.022913     |   0\n",
      "      16599 |   0.053806  |    0.027419     |   2\n",
      "      16600 |   0.199271  |    0.029174     |   0\n",
      "      16601 |   0.061167  |    0.024915     |   2\n",
      "      16602 |   0.052644  |    0.020806     |   2\n",
      "      16603 |   0.155591  |    0.038939     |   0\n",
      "      16604 |   0.226992  |    0.110800     |   1\n",
      "      16605 |   0.266963  |    0.049070     |   1\n",
      "      16606 |   0.025431  |    0.032074     |   2\n",
      "      16607 |   0.242386  |    0.035247     |   0\n",
      "      16608 |   0.218593  |    0.080442     |   1\n",
      "      16609 |   0.274236  |    0.155293     |   1\n",
      "      16610 |   0.209981  |    0.018791     |   1\n",
      "      16611 | \u001b[94m  0.000036\u001b[0m  |    0.026817     |   2\n",
      "      16612 |   0.006093  |    0.012083     |   2\n",
      "      16613 |   0.224411  |    0.047216     |   0\n",
      "      16614 |   0.196456  |    0.015291     |   0\n",
      "      16615 |   0.069375  |    0.040686     |   2\n",
      "      16616 |   0.034249  |    0.024830     |   2\n",
      "      16617 |   0.166339  |    0.098992     |   1\n",
      "      16618 |   0.060607  |    0.026240     |   2\n",
      "      16619 |   0.206171  |    0.027638     |   0\n",
      "      16620 |   0.050741  |    0.021888     |   2\n",
      "      16621 |   0.020890  |    0.029325     |   2\n",
      "      16622 |   0.188261  |    0.141049     |   1\n",
      "      16623 |   0.039128  |    0.002940     |   2\n",
      "      16624 |   0.146547  |    0.011309     |   0\n",
      "      16625 |   0.032867  |    0.023710     |   2\n",
      "      16626 |   0.000036  |    0.045951     |   2\n",
      "      16627 |   0.180842  |    0.038074     |   0\n",
      "      16628 |   0.200035  |    0.113308     |   1\n",
      "      16629 |   0.238356  |    0.089052     |   1\n",
      "      16630 |   0.000036  |    0.021317     |   2\n",
      "      16631 |   0.000036  |    0.029931     |   2\n",
      "      16632 |   0.000036  |    0.021312     |   2\n",
      "      16633 |   0.000036  |    0.032103     |   2\n",
      "      16634 |   0.320506  |    0.150605     |   1\n",
      "      16635 |   0.159760  |    0.006836     |   0\n",
      "      16636 |   0.220125  |    0.015076     |   0\n",
      "      16637 |   0.233285  |    0.050157     |   0\n",
      "      16638 |   0.260199  |    0.010444     |   0\n",
      "      16639 |   0.224936  |    0.133353     |   1\n",
      "      16640 |   0.282552  |    0.088251     |   1\n",
      "      16641 |   0.000036  |    0.008197     |   2\n",
      "      16642 |   0.054267  |    0.014761     |   2\n",
      "      16643 |   0.175271  |    0.032699     |   0\n",
      "      16644 |   0.244559  |    0.146285     |   1\n",
      "      16645 |   0.167396  |    0.010232     |   0\n",
      "      16646 |   0.215401  |    0.089985     |   1\n",
      "      16647 |   0.201244  |    0.028476     |   0\n",
      "      16648 |   0.201441  |    0.109053     |   1\n",
      "      16649 |   0.165585  |    0.052627     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 16651: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      16650 |   0.050530  |    0.013930     |   2\n",
      "      16651 |   0.209365  |    0.026186     |   0\n",
      "      16652 |   0.224155  |    0.144207     |   1\n",
      "      16653 |   0.213780  |    0.022356     |   0\n",
      "      16654 |   0.271028  |    0.042079     |   1\n",
      "      16655 |   0.170558  |    0.018705     |   0\n",
      "      16656 |   0.204580  |    0.063989     |   0\n",
      "      16657 |   0.135487  |    0.055956     |   1\n",
      "      16658 |   0.182367  |    0.156089     |   1\n",
      "      16659 |   0.165410  |    0.058616     |   1\n",
      "      16660 |   0.186207  |    0.155752     |   1\n",
      "      16661 |   0.205072  |    0.012097     |   0\n",
      "      16662 |   0.160262  |    0.085688     |   1\n",
      "      16663 |   0.177073  |    0.084253     |   1\n",
      "      16664 |   0.233148  |    0.013640     |   0\n",
      "      16665 |   0.052761  |    0.035250     |   2\n",
      "      16666 |   0.038383  |    0.016913     |   2\n",
      "      16667 |   0.127783  |    0.020143     |   0\n",
      "      16668 |   0.042295  |    0.016568     |   2\n",
      "      16669 |   0.299480  |    0.151356     |   1\n",
      "      16670 |   0.206271  |    0.008865     |   0\n",
      "      16671 |   0.244922  |    0.081159     |   1\n",
      "      16672 |   0.160725  |    0.013219     |   0\n",
      "      16673 |   0.269831  |    0.163537     |   1\n",
      "      16674 |   0.051478  |    0.006737     |   2\n",
      "      16675 |   0.190265  |    0.004916     |   0\n",
      "      16676 |   0.156578  |    0.027784     |   0\n",
      "      16677 |   0.264680  |    0.087440     |   1\n",
      "      16678 |   0.029955  |    0.005513     |   2\n",
      "      16679 |   0.130109  |    0.143569     |   1\n",
      "      16680 |   0.041048  |    0.006180     |   2\n",
      "      16681 |   0.049105  |    0.010716     |   2\n",
      "      16682 |   0.060950  |    0.044362     |   2\n",
      "      16683 |   0.187432  |    0.115945     |   1\n",
      "      16684 |   0.196681  |    0.052459     |   1\n",
      "      16685 |   0.275366  |    0.030476     |   0\n",
      "      16686 |   0.238960  |    0.082420     |   1\n",
      "      16687 |   0.052853  |    0.018123     |   2\n",
      "      16688 |   0.227330  |    0.160162     |   1\n",
      "      16689 |   0.203732  |    0.048244     |   1\n",
      "      16690 |   0.224425  |    0.023818     |   0\n",
      "      16691 |   0.026194  |    0.030046     |   2\n",
      "      16692 | \u001b[94m  0.000035\u001b[0m  |    0.010879     |   2\n",
      "      16693 |   0.218615  |    0.030513     |   0\n",
      "      16694 |   0.228984  |    0.021184     |   0\n",
      "      16695 |   0.216750  |    0.046226     |   0\n",
      "      16696 |   0.005582  |    0.021723     |   2\n",
      "      16697 |   0.247923  |    0.124947     |   1\n",
      "      16698 |   0.247677  |    0.016687     |   1\n",
      "      16699 |   0.187251  |    0.152683     |   1\n",
      "      16700 |   0.070444  |    0.008993     |   2\n",
      "      16701 |   0.200672  |    0.101699     |   1\n",
      "      16702 |   0.036474  |    0.005399     |   2\n",
      "      16703 |   0.181449  |    0.027131     |   0\n",
      "      16704 |   0.181212  |    0.026690     |   0\n",
      "      16705 |   0.231658  |    0.030435     |   0\n",
      "      16706 |   0.248627  |    0.142974     |   1\n",
      "      16707 |   0.059358  |    0.002975     |   2\n",
      "      16708 |   0.210812  |    0.011561     |   0\n",
      "      16709 |   0.211859  |    0.040151     |   0\n",
      "      16710 |   0.044823  |    0.021271     |   2\n",
      "      16711 |   0.020321  |    0.024908     |   2\n",
      "      16712 |   0.158163  |    0.146327     |   1\n",
      "      16713 |   0.161236  |    0.009020     |   0\n",
      "      16714 |   0.130896  |    0.085137     |   1\n",
      "      16715 |   0.244156  |    0.019280     |   0\n",
      "      16716 |   0.216767  |    0.087797     |   1\n",
      "      16717 |   0.188494  |    0.006203     |   0\n",
      "      16718 |   0.214883  |    0.046377     |   0\n",
      "      16719 |   0.201592  |    0.010709     |   0\n",
      "      16720 |   0.178824  |    0.025548     |   0\n",
      "      16721 |   0.045258  |    0.043819     |   2\n",
      "      16722 |   0.032882  |    0.018986     |   2\n",
      "      16723 |   0.193143  |    0.149562     |   1\n",
      "      16724 |   0.182723  |    0.003081     |   0\n",
      "      16725 |   0.000035  |    0.005117     |   2\n",
      "      16726 |   0.285252  |    0.060241     |   0\n",
      "      16727 |   0.198599  |    0.080826     |   1\n",
      "      16728 |   0.268150  |    0.013452     |   0\n",
      "      16729 |   0.211012  |    0.036784     |   0\n",
      "      16730 |   0.000035  |    0.011704     |   2\n",
      "      16731 |   0.000035  |    0.042265     |   2\n",
      "      16732 |   0.246662  |    0.024126     |   0\n",
      "      16733 |   0.000036  |    0.027024     |   2\n",
      "      16734 |   0.000036  |    0.016330     |   2\n",
      "      16735 |   0.000035  |    0.047041     |   2\n",
      "      16736 |   0.260237  |    0.035282     |   0\n",
      "      16737 |   0.156199  |    0.143714     |   1\n",
      "      16738 |   0.055171  |    0.002931     |   2\n",
      "      16739 |   0.051016  |    0.009720     |   2\n",
      "      16740 |   0.166428  |    0.143626     |   1\n",
      "      16741 |   0.202135  |    0.007045     |   0\n",
      "      16742 |   0.180746  |    0.050094     |   0\n",
      "      16743 |   0.291273  |    0.080394     |   1\n",
      "      16744 |   0.214642  |    0.135473     |   1\n",
      "      16745 |   0.242798  |    0.082953     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 16746: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      16746 |   0.213204  |    0.071513     |   1\n",
      "      16747 |   0.185638  |    0.104490     |   1\n",
      "      16748 |   0.162730  |    0.086559     |   1\n",
      "      16749 |   0.173842  |    0.087572     |   1\n",
      "      16750 |   0.203432  |    0.011702     |   0\n",
      "      16751 |   0.055000  |    0.041019     |   2\n",
      "      16752 |   0.174899  |    0.031696     |   0\n",
      "      16753 |   0.262724  |    0.135809     |   1\n",
      "      16754 |   0.250320  |    0.012685     |   0\n",
      "      16755 |   0.156546  |    0.096076     |   1\n",
      "      16756 |   0.037912  |    0.013967     |   2\n",
      "      16757 |   0.280708  |    0.104274     |   1\n",
      "      16758 |   0.211156  |    0.016278     |   0\n",
      "      16759 |   0.040256  |    0.045572     |   2\n",
      "      16760 |   0.047874  |    0.008197     |   2\n",
      "      16761 |   0.258990  |    0.132011     |   1\n",
      "      16762 |   0.252563  |    0.011994     |   0\n",
      "      16763 |   0.029712  |    0.044852     |   2\n",
      "      16764 |   0.040799  |    0.006759     |   2\n",
      "      16765 |   0.194841  |    0.047217     |   0\n",
      "      16766 |   0.054727  |    0.010635     |   2\n",
      "      16767 |   0.245146  |    0.134877     |   1\n",
      "      16768 |   0.205933  |    0.005000     |   0\n",
      "      16769 |   0.194952  |    0.062874     |   0\n",
      "      16770 |   0.253578  |    0.078589     |   1\n",
      "      16771 |   0.226903  |    0.010108     |   0\n",
      "      16772 |   0.062983  |    0.033165     |   2\n",
      "      16773 |   0.226455  |    0.094106     |   1\n",
      "      16774 |   0.172509  |    0.009271     |   0\n",
      "      16775 |   0.195307  |    0.130345     |   1\n",
      "      16776 |   0.049406  |    0.018792     |   2\n",
      "      16777 |   0.158617  |    0.144952     |   1\n",
      "      16778 |   0.243049  |    0.008638     |   0\n",
      "      16779 |   0.025845  |    0.008829     |   2\n",
      "      16780 |   0.193009  |    0.152083     |   1\n",
      "      16781 |   0.215352  |    0.038722     |   1\n",
      "      16782 |   0.193323  |    0.033155     |   0\n",
      "      16783 |   0.241637  |    0.082994     |   1\n",
      "      16784 |   0.225771  |    0.145043     |   1\n",
      "      16785 |   0.231003  |    0.016706     |   0\n",
      "      16786 |   0.182154  |    0.076837     |   1\n",
      "      16787 |   0.160200  |    0.022592     |   0\n",
      "      16788 |   0.000035  |    0.053170     |   2\n",
      "      16789 |   0.186922  |    0.076735     |   1\n",
      "      16790 |   0.222583  |    0.023604     |   0\n",
      "      16791 |   0.170272  |    0.129800     |   1\n",
      "      16792 |   0.005219  |    0.005916     |   2\n",
      "      16793 |   0.226532  |    0.044198     |   0\n",
      "      16794 |   0.070176  |    0.019967     |   2\n",
      "      16795 |   0.178014  |    0.152164     |   1\n",
      "      16796 |   0.170416  |    0.091711     |   1\n",
      "      16797 |   0.211623  |    0.114165     |   1\n",
      "      16798 |   0.228968  |    0.071513     |   1\n",
      "      16799 |   0.244215  |    0.018826     |   0\n",
      "      16800 |   0.035011  |    0.028417     |   2\n",
      "      16801 |   0.057565  |    0.014316     |   2\n",
      "      16802 |   0.226486  |    0.053252     |   0\n",
      "      16803 |   0.203412  |    0.013174     |   0\n",
      "      16804 |   0.045821  |    0.044744     |   2\n",
      "      16805 |   0.021340  |    0.014866     |   2\n",
      "      16806 |   0.157040  |    0.133857     |   1\n",
      "      16807 |   0.147977  |    0.006251     |   0\n",
      "      16808 |   0.189168  |    0.052662     |   0\n",
      "      16809 |   0.159123  |    0.111307     |   1\n",
      "      16810 |   0.040110  |    0.008579     |   2\n",
      "      16811 |   0.034276  |    0.050048     |   2\n",
      "      16812 |   0.000036  |    0.009706     |   2\n",
      "      16813 |   0.151762  |    0.029023     |   0\n",
      "      16814 |   0.229897  |    0.098066     |   1\n",
      "      16815 |   0.000036  |    0.007635     |   2\n",
      "      16816 |   0.207355  |    0.051474     |   0\n",
      "      16817 |   0.000035  |    0.016719     |   2\n",
      "      16818 |   0.271075  |    0.158090     |   1\n",
      "      16819 |   0.000036  |    0.010593     |   2\n",
      "      16820 |   0.203469  |    0.050284     |   1\n",
      "      16821 |   0.222611  |    0.029411     |   0\n",
      "      16822 |   0.191479  |    0.051744     |   0\n",
      "      16823 |   0.230538  |    0.097463     |   1\n",
      "      16824 |   0.180221  |    0.006182     |   0\n",
      "      16825 |   0.198116  |    0.061712     |   0\n",
      "      16826 |   0.175966  |    0.069056     |   1\n",
      "      16827 |   0.228339  |    0.112617     |   1\n",
      "      16828 |   0.227665  |    0.086846     |   1\n",
      "      16829 |   0.000036  |    0.003714     |   2\n",
      "      16830 |   0.000035  |    0.030270     |   2\n",
      "      16831 |   0.057269  |    0.017920     |   2\n",
      "      16832 |   0.048672  |    0.030584     |   2\n",
      "      16833 |   0.171922  |    0.042033     |   0\n",
      "      16834 |   0.177854  |    0.098299     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 16836: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      16835 |   0.198419  |    0.006586     |   0\n",
      "      16836 |   0.201970  |    0.012697     |   0\n",
      "      16837 |   0.176709  |    0.044032     |   0\n",
      "      16838 |   0.052580  |    0.010372     |   2\n",
      "      16839 |   0.171331  |    0.022163     |   0\n",
      "      16840 |   0.215405  |    0.047849     |   0\n",
      "      16841 |   0.180434  |    0.013552     |   0\n",
      "      16842 |   0.204156  |    0.027288     |   0\n",
      "      16843 |   0.138712  |    0.031071     |   0\n",
      "      16844 |   0.216835  |    0.024700     |   0\n",
      "      16845 |   0.139506  |    0.024864     |   0\n",
      "      16846 |   0.150850  |    0.019970     |   0\n",
      "      16847 |   0.188216  |    0.039958     |   0\n",
      "      16848 |   0.041489  |    0.018179     |   2\n",
      "      16849 |   0.245238  |    0.127969     |   1\n",
      "      16850 |   0.166084  |    0.006948     |   0\n",
      "      16851 |   0.155500  |    0.007493     |   0\n",
      "      16852 |   0.238446  |    0.050130     |   0\n",
      "      16853 |   0.234481  |    0.106100     |   1\n",
      "      16854 |   0.198704  |    0.010813     |   0\n",
      "      16855 |   0.042622  |    0.008398     |   2\n",
      "      16856 |   0.050306  |    0.055584     |   2\n",
      "      16857 |   0.211762  |    0.106155     |   1\n",
      "      16858 |   0.030617  |    0.013518     |   2\n",
      "      16859 |   0.160509  |    0.081462     |   1\n",
      "      16860 |   0.161267  |    0.008571     |   0\n",
      "      16861 |   0.197781  |    0.048393     |   0\n",
      "      16862 |   0.232982  |    0.107824     |   1\n",
      "      16863 |   0.243689  |    0.060827     |   1\n",
      "      16864 |   0.041975  |    0.029806     |   2\n",
      "      16865 |   0.257484  |    0.138541     |   1\n",
      "      16866 |   0.196705  |    0.005691     |   0\n",
      "      16867 |   0.237305  |    0.004752     |   0\n",
      "      16868 |   0.189960  |    0.055024     |   0\n",
      "      16869 |   0.211592  |    0.084164     |   1\n",
      "      16870 |   0.053158  |    0.012850     |   2\n",
      "      16871 |   0.057202  |    0.029691     |   2\n",
      "      16872 |   0.210098  |    0.136362     |   1\n",
      "      16873 |   0.183782  |    0.006689     |   0\n",
      "      16874 |   0.214045  |    0.015343     |   0\n",
      "      16875 |   0.167860  |    0.151253     |   1\n",
      "      16876 |   0.283107  |    0.022190     |   1\n",
      "      16877 |   0.228662  |    0.106648     |   1\n",
      "      16878 |   0.218451  |    0.030559     |   0\n",
      "      16879 |   0.047876  |    0.030059     |   2\n",
      "      16880 |   0.021824  |    0.016647     |   2\n",
      "      16881 |   0.250636  |    0.053152     |   0\n",
      "      16882 |   0.000036  |    0.008631     |   2\n",
      "      16883 |   0.006547  |    0.032557     |   2\n",
      "      16884 |   0.301855  |    0.150114     |   1\n",
      "      16885 |   0.160167  |    0.034201     |   1\n",
      "      16886 |   0.192167  |    0.049859     |   0\n",
      "      16887 |   0.071840  |    0.008703     |   2\n",
      "      16888 |   0.156600  |    0.057463     |   0\n",
      "      16889 |   0.034564  |    0.019274     |   2\n",
      "      16890 |   0.202980  |    0.046679     |   0\n",
      "      16891 |   0.061215  |    0.019438     |   2\n",
      "      16892 |   0.231606  |    0.152027     |   1\n",
      "      16893 |   0.212672  |    0.031270     |   0\n",
      "      16894 |   0.234038  |    0.018708     |   1\n",
      "      16895 |   0.231541  |    0.028659     |   0\n",
      "      16896 |   0.043516  |    0.045678     |   2\n",
      "      16897 |   0.211396  |    0.085821     |   1\n",
      "      16898 |   0.248950  |    0.076571     |   1\n",
      "      16899 |   0.209737  |    0.021862     |   1\n",
      "      16900 |   0.019836  |    0.042467     |   2\n",
      "      16901 |   0.167966  |    0.087018     |   1\n",
      "      16902 |   0.040416  |    0.045465     |   2\n",
      "      16903 |   0.179162  |    0.012791     |   0\n",
      "      16904 |   0.278130  |    0.095183     |   1\n",
      "      16905 |   0.181420  |    0.014260     |   0\n",
      "      16906 |   0.191774  |    0.032740     |   0\n",
      "      16907 |   0.246882  |    0.103950     |   1\n",
      "      16908 |   0.032069  |    0.012852     |   2\n",
      "      16909 |   0.169303  |    0.025126     |   0\n",
      "      16910 |   0.195528  |    0.052876     |   0\n",
      "      16911 |   0.000036  |    0.014039     |   2\n",
      "      16912 |   0.229445  |    0.101399     |   1\n",
      "      16913 |   0.172705  |    0.093865     |   1\n",
      "      16914 |   0.215205  |    0.036007     |   0\n",
      "      16915 |   0.175962  |    0.087845     |   1\n",
      "      16916 |   0.000036  |    0.015873     |   2\n",
      "      16917 |   0.000036  |    0.049490     |   2\n",
      "      16918 |   0.198758  |    0.042464     |   1\n",
      "      16919 |   0.000036  |    0.034872     |   2\n",
      "      16920 |   0.239576  |    0.089798     |   1\n",
      "      16921 |   0.000036  |    0.010411     |   2\n",
      "      16922 |   0.000036  |    0.031906     |   2\n",
      "      16923 |   0.222555  |    0.046455     |   0\n",
      "      16924 |   0.053780  |    0.021680     |   2\n",
      "      16925 |   0.049998  |    0.017553     |   2\n",
      "      16926 |   0.163864  |    0.115484     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 16927: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      16927 |   0.210001  |    0.066971     |   1\n",
      "      16928 |   0.052829  |    0.012763     |   2\n",
      "      16929 |   0.154380  |    0.036162     |   0\n",
      "      16930 |   0.207619  |    0.028894     |   0\n",
      "      16931 |   0.231934  |    0.151507     |   1\n",
      "      16932 |   0.261294  |    0.060899     |   1\n",
      "      16933 |   0.209005  |    0.025208     |   1\n",
      "      16934 |   0.203503  |    0.047784     |   0\n",
      "      16935 |   0.039699  |    0.007477     |   2\n",
      "      16936 |   0.040326  |    0.036259     |   2\n",
      "      16937 |   0.047166  |    0.034419     |   2\n",
      "      16938 |   0.228303  |    0.093301     |   1\n",
      "      16939 |   0.028980  |    0.010832     |   2\n",
      "      16940 |   0.183007  |    0.034698     |   0\n",
      "      16941 |   0.267040  |    0.134264     |   1\n",
      "      16942 |   0.177691  |    0.002932     |   0\n",
      "      16943 |   0.044161  |    0.009139     |   2\n",
      "      16944 |   0.263062  |    0.096461     |   1\n",
      "      16945 |   0.050296  |    0.012160     |   2\n",
      "      16946 |   0.190010  |    0.077967     |   0\n",
      "      16947 |   0.231298  |    0.064351     |   1\n",
      "      16948 |   0.062163  |    0.014361     |   2\n",
      "      16949 |   0.186338  |    0.050460     |   0\n",
      "      16950 |   0.047924  |    0.014671     |   2\n",
      "      16951 |   0.202794  |    0.091812     |   1\n",
      "      16952 |   0.197970  |    0.028143     |   0\n",
      "      16953 |   0.257824  |    0.139135     |   1\n",
      "      16954 |   0.023280  |    0.004095     |   2\n",
      "      16955 | \u001b[94m  0.000035\u001b[0m  |    0.017108     |   2\n",
      "      16956 |   0.155504  |    0.041516     |   0\n",
      "      16957 |   0.220566  |    0.013966     |   0\n",
      "      16958 |   0.217841  |    0.030455     |   0\n",
      "      16959 |   0.006234  |    0.016767     |   2\n",
      "      16960 |   0.070963  |    0.038752     |   2\n",
      "      16961 |   0.034262  |    0.007289     |   2\n",
      "      16962 |   0.060340  |    0.056149     |   2\n",
      "      16963 |   0.255570  |    0.090032     |   1\n",
      "      16964 |   0.178931  |    0.020267     |   0\n",
      "      16965 |   0.205128  |    0.148959     |   1\n",
      "      16966 |   0.046003  |    0.014644     |   2\n",
      "      16967 |   0.236519  |    0.081154     |   1\n",
      "      16968 |   0.195130  |    0.005790     |   0\n",
      "      16969 |   0.019008  |    0.042506     |   2\n",
      "      16970 |   0.246066  |    0.093017     |   1\n",
      "      16971 |   0.040855  |    0.021178     |   2\n",
      "      16972 |   0.260159  |    0.139109     |   1\n",
      "      16973 |   0.189881  |    0.011019     |   0\n",
      "      16974 |   0.235909  |    0.096321     |   1\n",
      "      16975 |   0.254100  |    0.009248     |   0\n",
      "      16976 |   0.189921  |    0.033946     |   0\n",
      "      16977 |   0.030549  |    0.018649     |   2\n",
      "      16978 |   0.176836  |    0.160819     |   1\n",
      "      16979 |   0.168432  |    0.003923     |   0\n",
      "      16980 |   0.176775  |    0.088389     |   1\n",
      "      16981 |   0.288831  |    0.013948     |   0\n",
      "      16982 | \u001b[94m  0.000035\u001b[0m  |    0.029526     |   2\n",
      "      16983 | \u001b[94m  0.000035\u001b[0m  |    0.038663     |   2\n",
      "      16984 |   0.182886  |    0.138871     |   1\n",
      "      16985 | \u001b[94m  0.000034\u001b[0m  |    0.003134     |   2\n",
      "      16986 |   0.000035  |    0.009314     |   2\n",
      "      16987 |   0.207749  |    0.136047     |   1\n",
      "      16988 |   0.000035  |    0.014376     |   2\n",
      "      16989 |   0.200825  |    0.035814     |   0\n",
      "      16990 |   0.193753  |    0.094571     |   1\n",
      "      16991 |   0.214296  |    0.027791     |   0\n",
      "      16992 |   0.193225  |    0.029725     |   0\n",
      "      16993 |   0.202012  |    0.093794     |   1\n",
      "      16994 |   0.193325  |    0.012998     |   0\n",
      "      16995 |   0.248815  |    0.051858     |   0\n",
      "      16996 |   0.212109  |    0.080167     |   1\n",
      "      16997 | \u001b[94m  0.000034\u001b[0m  |    0.024448     |   2\n",
      "      16998 |   0.051287  |    0.024052     |   2\n",
      "      16999 |   0.049876  |    0.046552     |   2\n",
      "      17000 |   0.243673  |    0.090383     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 17000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 17000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      17001 |   0.189704  |    0.047584     |   0\n",
      "      17002 |   0.053214  |    0.023163     |   2\n",
      "      17003 |   0.040231  |    0.045245     |   2\n",
      "      17004 |   0.282285  |    0.091442     |   1\n",
      "      17005 |   0.246812  |    0.008443     |   0\n",
      "      17006 |   0.194712  |    0.035323     |   0\n",
      "      17007 |   0.041252  |    0.008382     |   2\n",
      "      17008 |   0.048816  |    0.043086     |   2\n",
      "      17009 |   0.196172  |    0.006221     |   0\n",
      "      17010 |   0.028683  |    0.042752     |   2\n",
      "      17011 |   0.167358  |    0.018822     |   0\n",
      "      17012 |   0.177686  |    0.024501     |   0\n",
      "      17013 |   0.187663  |    0.036881     |   0\n",
      "      17014 |   0.042452  |    0.006998     |   2\n",
      "      17015 |   0.246974  |    0.053296     |   0\n",
      "      17016 |   0.056589  |    0.006975     |   2\n",
      "      17017 |   0.059984  |    0.066552     |   2\n",
      "      17018 |   0.192025  |    0.096333     |   1\n",
      "      17019 |   0.209220  |    0.080993     |   1\n",
      "      17020 |   0.198257  |    0.005527     |   0\n",
      "      17021 |   0.215845  |    0.145067     |   1\n",
      "      17022 |   0.049306  |    0.004323     |   2\n",
      "      17023 |   0.023843  |    0.008363     |   2\n",
      "      17024 |   0.210093  |    0.053084     |   0\n",
      "      17025 |   0.000035  |    0.009611     |   2\n",
      "      17026 |   0.190383  |    0.129640     |   1\n",
      "      17027 |   0.006005  |    0.009133     |   2\n",
      "      17028 |   0.070611  |    0.049771     |   2\n",
      "      17029 |   0.194238  |    0.011771     |   0\n",
      "      17030 |   0.034284  |    0.032449     |   2\n",
      "      17031 |   0.059422  |    0.033220     |   2\n",
      "      17032 |   0.220284  |    0.026755     |   0\n",
      "      17033 |   0.047696  |    0.026235     |   2\n",
      "      17034 |   0.017746  |    0.025471     |   2\n",
      "      17035 |   0.166795  |    0.025321     |   0\n",
      "      17036 |   0.041830  |    0.052974     |   2\n",
      "      17037 |   0.033737  |    0.016374     |   2\n",
      "      17038 |   0.222445  |    0.091684     |   1\n",
      "      17039 |   0.000035  |    0.028353     |   2\n",
      "      17040 |   0.108762  |    0.159849     |   1\n",
      "      17041 |   0.000035  |    0.003645     |   2\n",
      "      17042 |   0.184738  |    0.004670     |   0\n",
      "      17043 |   0.133449  |    0.028129     |   0\n",
      "      17044 |   0.000035  |    0.029275     |   2\n",
      "      17045 |   0.000035  |    0.036489     |   2\n",
      "      17046 |   0.250975  |    0.090161     |   1\n",
      "      17047 |   0.202258  |    0.024408     |   0\n",
      "      17048 |   0.186675  |    0.030565     |   0\n",
      "      17049 |   0.000035  |    0.024123     |   2\n",
      "      17050 |   0.000035  |    0.024004     |   2\n",
      "      17051 |   0.052912  |    0.027398     |   2\n",
      "      17052 |   0.049184  |    0.026971     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 17053: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      17053 |   0.051089  |    0.019898     |   2\n",
      "      17054 |   0.037853  |    0.029937     |   2\n",
      "      17055 |   0.040945  |    0.014123     |   2\n",
      "      17056 |   0.155465  |    0.046155     |   0\n",
      "      17057 |   0.048767  |    0.005955     |   2\n",
      "      17058 |   0.028771  |    0.056436     |   2\n",
      "      17059 |   0.235077  |    0.114851     |   1\n",
      "      17060 |   0.188003  |    0.060921     |   1\n",
      "      17061 |   0.237035  |    0.096886     |   1\n",
      "      17062 |   0.041747  |    0.011192     |   2\n",
      "      17063 |   0.266316  |    0.086197     |   1\n",
      "      17064 |   0.051327  |    0.008463     |   2\n",
      "      17065 |   0.191383  |    0.060233     |   0\n",
      "      17066 |   0.221767  |    0.093894     |   1\n",
      "      17067 |   0.058954  |    0.006111     |   2\n",
      "      17068 |   0.276782  |    0.046258     |   0\n",
      "      17069 |   0.224721  |    0.046253     |   0\n",
      "      17070 |   0.243708  |    0.086647     |   1\n",
      "      17071 |   0.265578  |    0.006138     |   0\n",
      "      17072 |   0.186495  |    0.047136     |   0\n",
      "      17073 |   0.162834  |    0.017730     |   0\n",
      "      17074 |   0.181953  |    0.143260     |   1\n",
      "      17075 |   0.051724  |    0.010170     |   2\n",
      "      17076 |   0.026053  |    0.014841     |   2\n",
      "      17077 |   0.189791  |    0.133435     |   1\n",
      "      17078 | \u001b[94m  0.000034\u001b[0m  |    0.006919     |   2\n",
      "      17079 |   0.005744  |    0.018604     |   2\n",
      "      17080 |   0.070356  |    0.029114     |   2\n",
      "      17081 |   0.185337  |    0.037557     |   0\n",
      "      17082 |   0.035527  |    0.016495     |   2\n",
      "      17083 |   0.225151  |    0.048672     |   0\n",
      "      17084 |   0.172875  |    0.081188     |   1\n",
      "      17085 |   0.226051  |    0.025103     |   0\n",
      "      17086 |   0.310751  |    0.132575     |   1\n",
      "      17087 |   0.199132  |    0.006878     |   0\n",
      "      17088 |   0.061263  |    0.022343     |   2\n",
      "      17089 |   0.252790  |    0.104121     |   1\n",
      "      17090 |   0.047350  |    0.009319     |   2\n",
      "      17091 |   0.167731  |    0.038702     |   0\n",
      "      17092 |   0.017778  |    0.024478     |   2\n",
      "      17093 |   0.152618  |    0.030629     |   0\n",
      "      17094 |   0.222580  |    0.141730     |   1\n",
      "      17095 |   0.038840  |    0.003839     |   2\n",
      "      17096 |   0.166430  |    0.005918     |   0\n",
      "      17097 |   0.033928  |    0.048194     |   2\n",
      "      17098 |   0.200863  |    0.044679     |   1\n",
      "      17099 |   0.160913  |    0.027637     |   0\n",
      "      17100 |   0.000035  |    0.024068     |   2\n",
      "      17101 |   0.273765  |    0.035878     |   0\n",
      "      17102 |   0.192918  |    0.165336     |   1\n",
      "      17103 |   0.146598  |    0.087375     |   1\n",
      "      17104 |   0.000034  |    0.003908     |   2\n",
      "      17105 |   0.000034  |    0.017595     |   2\n",
      "      17106 |   0.000035  |    0.024637     |   2\n",
      "      17107 |   0.197146  |    0.049952     |   0\n",
      "      17108 |   0.227568  |    0.091458     |   1\n",
      "      17109 |   0.240810  |    0.010137     |   0\n",
      "      17110 |   0.000035  |    0.037167     |   2\n",
      "      17111 |   0.238644  |    0.102044     |   1\n",
      "      17112 |   0.239517  |    0.078185     |   1\n",
      "      17113 |   0.000034  |    0.042658     |   2\n",
      "      17114 |   0.195439  |    0.015494     |   0\n",
      "      17115 |   0.183166  |    0.130790     |   1\n",
      "      17116 |   0.052997  |    0.003019     |   2\n",
      "      17117 |   0.049289  |    0.020456     |   2\n",
      "      17118 |   0.166277  |    0.115220     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 17119: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      17119 |   0.050986  |    0.013111     |   2\n",
      "      17120 |   0.194401  |    0.045530     |   0\n",
      "      17121 |   0.182880  |    0.009907     |   0\n",
      "      17122 |   0.204432  |    0.046755     |   0\n",
      "      17123 |   0.181338  |    0.081954     |   1\n",
      "      17124 |   0.040436  |    0.030688     |   2\n",
      "      17125 |   0.212253  |    0.144509     |   1\n",
      "      17126 |   0.041183  |    0.005372     |   2\n",
      "      17127 |   0.214969  |    0.016073     |   0\n",
      "      17128 |   0.153240  |    0.032238     |   0\n",
      "      17129 |   0.214483  |    0.089691     |   1\n",
      "      17130 |   0.214476  |    0.126723     |   1\n",
      "      17131 |   0.048818  |    0.008047     |   2\n",
      "      17132 |   0.204825  |    0.084603     |   1\n",
      "      17133 |   0.028474  |    0.014645     |   2\n",
      "      17134 |   0.161401  |    0.044181     |   0\n",
      "      17135 |   0.044641  |    0.015573     |   2\n",
      "      17136 |   0.049786  |    0.043666     |   2\n",
      "      17137 |   0.058508  |    0.016962     |   2\n",
      "      17138 |   0.193621  |    0.043760     |   0\n",
      "      17139 |   0.181643  |    0.012957     |   0\n",
      "      17140 |   0.229255  |    0.042260     |   0\n",
      "      17141 |   0.050992  |    0.015843     |   2\n",
      "      17142 |   0.024360  |    0.050506     |   2\n",
      "      17143 |   0.146328  |    0.084825     |   1\n",
      "      17144 |   0.135380  |    0.007599     |   0\n",
      "      17145 |   0.263806  |    0.027112     |   0\n",
      "      17146 |   0.000034  |    0.046374     |   2\n",
      "      17147 |   0.225011  |    0.096271     |   1\n",
      "      17148 |   0.005491  |    0.027240     |   2\n",
      "      17149 |   0.206729  |    0.138028     |   1\n",
      "      17150 |   0.203679  |    0.061288     |   1\n",
      "      17151 |   0.209305  |    0.092079     |   1\n",
      "      17152 |   0.189740  |    0.088366     |   1\n",
      "      17153 |   0.171280  |    0.009801     |   0\n",
      "      17154 |   0.209830  |    0.042574     |   0\n",
      "      17155 |   0.200442  |    0.017176     |   0\n",
      "      17156 |   0.217621  |    0.187732     |   1\n",
      "      17157 |   0.070239  |    0.014362     |   2\n",
      "      17158 |   0.170879  |    0.100875     |   1\n",
      "      17159 |   0.245916  |    0.089983     |   1\n",
      "      17160 |   0.170599  |    0.008350     |   0\n",
      "      17161 |   0.035794  |    0.012382     |   2\n",
      "      17162 |   0.059428  |    0.031105     |   2\n",
      "      17163 |   0.047265  |    0.022016     |   2\n",
      "      17164 |   0.200778  |    0.047269     |   0\n",
      "      17165 |   0.214958  |    0.143310     |   1\n",
      "      17166 |   0.234945  |    0.002896     |   0\n",
      "      17167 |   0.018550  |    0.007244     |   2\n",
      "      17168 |   0.037594  |    0.033792     |   2\n",
      "      17169 |   0.142111  |    0.133107     |   1\n",
      "      17170 |   0.031688  |    0.007258     |   2\n",
      "      17171 |   0.242877  |    0.047926     |   0\n",
      "      17172 |   0.194614  |    0.026971     |   0\n",
      "      17173 |   0.204983  |    0.141606     |   1\n",
      "      17174 |   0.177627  |    0.005172     |   0\n",
      "      17175 |   0.173375  |    0.019586     |   0\n",
      "      17176 |   0.000034  |    0.052199     |   2\n",
      "      17177 |   0.218625  |    0.087990     |   1\n",
      "      17178 |   0.139684  |    0.146133     |   1\n",
      "      17179 |   0.220437  |    0.093876     |   1\n",
      "      17180 |   0.000034  |    0.008287     |   2\n",
      "      17181 |   0.204995  |    0.042645     |   0\n",
      "      17182 |   0.211930  |    0.096957     |   1\n",
      "      17183 |   0.169023  |    0.026652     |   0\n",
      "      17184 |   0.142420  |    0.030968     |   0\n",
      "      17185 |   0.189563  |    0.053310     |   0\n",
      "      17186 |   0.274565  |    0.050499     |   1\n",
      "      17187 |   0.000034  |    0.019286     |   2\n",
      "      17188 |   0.265863  |    0.109840     |   1\n",
      "      17189 |   0.211674  |    0.018669     |   0\n",
      "      17190 |   0.163613  |    0.032534     |   0\n",
      "      17191 |   0.204640  |    0.034517     |   0\n",
      "      17192 |   0.000035  |    0.023751     |   2\n",
      "      17193 |   0.186062  |    0.008983     |   0\n",
      "      17194 |   0.000034  |    0.046937     |   2\n",
      "      17195 |   0.000034  |    0.014458     |   2\n",
      "      17196 |   0.052417  |    0.037866     |   2\n",
      "      17197 |   0.168599  |    0.074608     |   1\n",
      "      17198 |   0.048636  |    0.014763     |   2\n",
      "      17199 |   0.252296  |    0.041304     |   0\n",
      "      17200 |   0.244216  |    0.033066     |   0\n",
      "      17201 |   0.173045  |    0.030036     |   0\n",
      "      17202 |   0.210530  |    0.143250     |   1\n",
      "      17203 |   0.219363  |    0.045418     |   1\n",
      "      17204 |   0.228094  |    0.141599     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 17205: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      17205 |   0.243068  |    0.046966     |   1\n",
      "      17206 |   0.199765  |    0.042980     |   0\n",
      "      17207 |   0.050957  |    0.013891     |   2\n",
      "      17208 |   0.231489  |    0.143382     |   1\n",
      "      17209 |   0.037821  |    0.004995     |   2\n",
      "      17210 |   0.040209  |    0.017449     |   2\n",
      "      17211 |   0.048708  |    0.045093     |   2\n",
      "      17212 |   0.236086  |    0.094866     |   1\n",
      "      17213 |   0.146742  |    0.133692     |   1\n",
      "      17214 |   0.176143  |    0.079490     |   1\n",
      "      17215 |   0.203728  |    0.019211     |   0\n",
      "      17216 |   0.029232  |    0.030263     |   2\n",
      "      17217 |   0.221007  |    0.021212     |   0\n",
      "      17218 |   0.211336  |    0.044500     |   0\n",
      "      17219 |   0.041389  |    0.011591     |   2\n",
      "      17220 |   0.052502  |    0.031273     |   2\n",
      "      17221 |   0.207950  |    0.034735     |   0\n",
      "      17222 |   0.059853  |    0.014377     |   2\n",
      "      17223 |   0.206132  |    0.029596     |   0\n",
      "      17224 |   0.047538  |    0.051539     |   2\n",
      "      17225 |   0.022891  |    0.006776     |   2\n",
      "      17226 |   0.163625  |    0.048559     |   0\n",
      "      17227 |   0.223084  |    0.086234     |   1\n",
      "      17228 |   0.186496  |    0.106874     |   1\n",
      "      17229 |   0.214619  |    0.094616     |   1\n",
      "      17230 |   0.201605  |    0.090503     |   1\n",
      "      17231 | \u001b[94m  0.000034\u001b[0m  |    0.007051     |   2\n",
      "      17232 |   0.231858  |    0.105231     |   1\n",
      "      17233 |   0.005846  |    0.011966     |   2\n",
      "      17234 |   0.230848  |    0.152639     |   1\n",
      "      17235 |   0.073718  |    0.003122     |   2\n",
      "      17236 |   0.199714  |    0.006585     |   0\n",
      "      17237 |   0.194989  |    0.048108     |   0\n",
      "      17238 |   0.214988  |    0.076980     |   1\n",
      "      17239 |   0.033831  |    0.029146     |   2\n",
      "      17240 |   0.159704  |    0.140142     |   1\n",
      "      17241 |   0.208232  |    0.005641     |   0\n",
      "      17242 |   0.160781  |    0.139912     |   1\n",
      "      17243 |   0.249968  |    0.027751     |   0\n",
      "      17244 |   0.219526  |    0.101722     |   1\n",
      "      17245 |   0.225719  |    0.050595     |   1\n",
      "      17246 |   0.057763  |    0.015471     |   2\n",
      "      17247 |   0.239290  |    0.149450     |   1\n",
      "      17248 |   0.046038  |    0.003028     |   2\n",
      "      17249 |   0.017354  |    0.019057     |   2\n",
      "      17250 |   0.035732  |    0.020751     |   2\n",
      "      17251 |   0.143503  |    0.032169     |   0\n",
      "      17252 |   0.031501  |    0.030019     |   2\n",
      "      17253 |   0.000034  |    0.020657     |   2\n",
      "      17254 |   0.231738  |    0.053567     |   0\n",
      "      17255 |   0.204318  |    0.096684     |   1\n",
      "      17256 |   0.148097  |    0.020372     |   0\n",
      "      17257 |   0.188934  |    0.112185     |   1\n",
      "      17258 |   0.193308  |    0.106849     |   1\n",
      "      17259 |   0.182236  |    0.083221     |   1\n",
      "      17260 |   0.258460  |    0.008440     |   0\n",
      "      17261 |   0.193282  |    0.041944     |   0\n",
      "      17262 | \u001b[94m  0.000034\u001b[0m  |    0.022713     |   2\n",
      "      17263 | \u001b[94m  0.000034\u001b[0m  |    0.052058     |   2\n",
      "      17264 |   0.147706  |    0.126342     |   1\n",
      "      17265 |   0.000034  |    0.008801     |   2\n",
      "      17266 |   0.000034  |    0.012598     |   2\n",
      "      17267 |   0.209211  |    0.153031     |   1\n",
      "      17268 | \u001b[94m  0.000034\u001b[0m  |    0.003119     |   2\n",
      "      17269 |   0.050745  |    0.010669     |   2\n",
      "      17270 |   0.047341  |    0.037900     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 17271: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      17271 |   0.049333  |    0.009393     |   2\n",
      "      17272 |   0.037301  |    0.026959     |   2\n",
      "      17273 |   0.206670  |    0.046516     |   0\n",
      "      17274 |   0.040802  |    0.010986     |   2\n",
      "      17275 |   0.048653  |    0.029915     |   2\n",
      "      17276 |   0.142560  |    0.146364     |   1\n",
      "      17277 |   0.251192  |    0.002964     |   0\n",
      "      17278 |   0.219396  |    0.010178     |   0\n",
      "      17279 |   0.209269  |    0.048357     |   0\n",
      "      17280 |   0.028921  |    0.019931     |   2\n",
      "      17281 |   0.042533  |    0.035969     |   2\n",
      "      17282 |   0.315895  |    0.083992     |   1\n",
      "      17283 |   0.204887  |    0.018665     |   0\n",
      "      17284 |   0.226878  |    0.144530     |   1\n",
      "      17285 |   0.169897  |    0.026377     |   1\n",
      "      17286 |   0.231754  |    0.149488     |   1\n",
      "      17287 |   0.184689  |    0.065441     |   1\n",
      "      17288 |   0.159266  |    0.132359     |   1\n",
      "      17289 |   0.200494  |    0.006724     |   0\n",
      "      17290 |   0.225745  |    0.005457     |   0\n",
      "      17291 |   0.175613  |    0.026306     |   0\n",
      "      17292 |   0.213532  |    0.026669     |   0\n",
      "      17293 |   0.192542  |    0.038012     |   0\n",
      "      17294 |   0.159913  |    0.017692     |   0\n",
      "      17295 |   0.233814  |    0.136977     |   1\n",
      "      17296 |   0.185966  |    0.004828     |   0\n",
      "      17297 |   0.193340  |    0.012598     |   0\n",
      "      17298 |   0.055929  |    0.048285     |   2\n",
      "      17299 |   0.224956  |    0.081015     |   1\n",
      "      17300 |   0.271677  |    0.027647     |   0\n",
      "      17301 |   0.186335  |    0.114456     |   1\n",
      "      17302 |   0.062216  |    0.011718     |   2\n",
      "      17303 |   0.182209  |    0.146613     |   1\n",
      "      17304 |   0.166638  |    0.002818     |   0\n",
      "      17305 |   0.049545  |    0.003724     |   2\n",
      "      17306 |   0.025103  |    0.027944     |   2\n",
      "      17307 |   0.118414  |    0.108173     |   1\n",
      "      17308 | \u001b[94m  0.000033\u001b[0m  |    0.012183     |   2\n",
      "      17309 |   0.180363  |    0.047054     |   0\n",
      "      17310 |   0.131640  |    0.150168     |   1\n",
      "      17311 |   0.194781  |    0.015441     |   0\n",
      "      17312 |   0.193776  |    0.080635     |   1\n",
      "      17313 |   0.005611  |    0.010553     |   2\n",
      "      17314 |   0.188056  |    0.153886     |   1\n",
      "      17315 |   0.202125  |    0.081404     |   1\n",
      "      17316 |   0.234563  |    0.072419     |   0\n",
      "      17317 |   0.180902  |    0.096351     |   1\n",
      "      17318 |   0.256499  |    0.084767     |   1\n",
      "      17319 |   0.072205  |    0.025471     |   2\n",
      "      17320 |   0.293136  |    0.130851     |   1\n",
      "      17321 |   0.035183  |    0.009566     |   2\n",
      "      17322 |   0.208306  |    0.019668     |   0\n",
      "      17323 |   0.227758  |    0.061285     |   0\n",
      "      17324 |   0.196885  |    0.104991     |   1\n",
      "      17325 |   0.223506  |    0.053344     |   1\n",
      "      17326 |   0.056565  |    0.013357     |   2\n",
      "      17327 |   0.253206  |    0.143762     |   1\n",
      "      17328 |   0.203443  |    0.086583     |   1\n",
      "      17329 |   0.047093  |    0.029189     |   2\n",
      "      17330 |   0.186512  |    0.139298     |   1\n",
      "      17331 |   0.197052  |    0.003021     |   0\n",
      "      17332 |   0.173727  |    0.005784     |   0\n",
      "      17333 |   0.185873  |    0.056786     |   0\n",
      "      17334 |   0.256112  |    0.092114     |   1\n",
      "      17335 |   0.019584  |    0.007241     |   2\n",
      "      17336 |   0.217634  |    0.031336     |   0\n",
      "      17337 |   0.038829  |    0.031867     |   2\n",
      "      17338 |   0.171983  |    0.033498     |   0\n",
      "      17339 |   0.033266  |    0.014858     |   2\n",
      "      17340 |   0.000034  |    0.030980     |   2\n",
      "      17341 |   0.184292  |    0.143840     |   1\n",
      "      17342 |   0.000034  |    0.004966     |   2\n",
      "      17343 |   0.167409  |    0.034497     |   0\n",
      "      17344 |   0.135402  |    0.083204     |   1\n",
      "      17345 |   0.000034  |    0.027001     |   2\n",
      "      17346 |   0.187352  |    0.132634     |   1\n",
      "      17347 |   0.000034  |    0.003765     |   2\n",
      "      17348 |   0.315865  |    0.023854     |   0\n",
      "      17349 |   0.201145  |    0.031732     |   0\n",
      "      17350 |   0.000034  |    0.013469     |   2\n",
      "      17351 |   0.000034  |    0.031256     |   2\n",
      "      17352 |   0.182872  |    0.116350     |   1\n",
      "      17353 |   0.194656  |    0.078722     |   1\n",
      "      17354 |   0.051979  |    0.032224     |   2\n",
      "      17355 |   0.049762  |    0.020772     |   2\n",
      "      17356 |   0.206977  |    0.013569     |   0\n",
      "      17357 |   0.178902  |    0.158829     |   1\n",
      "      17358 |   0.186883  |    0.003100     |   0\n",
      "      17359 |   0.208747  |    0.016900     |   0\n",
      "      17360 |   0.228522  |    0.027811     |   0\n",
      "      17361 |   0.257930  |    0.082829     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 17362: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      17362 |   0.244067  |    0.013290     |   0\n",
      "      17363 |   0.055469  |    0.049781     |   2\n",
      "      17364 |   0.039126  |    0.009591     |   2\n",
      "      17365 |   0.180725  |    0.068316     |   0\n",
      "      17366 |   0.237033  |    0.084113     |   1\n",
      "      17367 |   0.219707  |    0.089210     |   1\n",
      "      17368 |   0.042952  |    0.017361     |   2\n",
      "      17369 |   0.303269  |    0.149977     |   1\n",
      "      17370 |   0.213555  |    0.051814     |   1\n",
      "      17371 |   0.048098  |    0.023194     |   2\n",
      "      17372 |   0.030212  |    0.043887     |   2\n",
      "      17373 |   0.042091  |    0.009311     |   2\n",
      "      17374 |   0.171049  |    0.031410     |   0\n",
      "      17375 |   0.208027  |    0.138991     |   1\n",
      "      17376 |   0.269300  |    0.051877     |   1\n",
      "      17377 |   0.190626  |    0.023996     |   0\n",
      "      17378 |   0.260150  |    0.050655     |   0\n",
      "      17379 |   0.181921  |    0.009821     |   0\n",
      "      17380 |   0.051650  |    0.046451     |   2\n",
      "      17381 |   0.219715  |    0.086251     |   1\n",
      "      17382 |   0.059959  |    0.006496     |   2\n",
      "      17383 |   0.047725  |    0.045290     |   2\n",
      "      17384 |   0.247064  |    0.020839     |   0\n",
      "      17385 |   0.189628  |    0.141046     |   1\n",
      "      17386 |   0.247215  |    0.003061     |   0\n",
      "      17387 |   0.022647  |    0.013181     |   2\n",
      "      17388 |   0.241227  |    0.147974     |   1\n",
      "      17389 |   0.195962  |    0.003027     |   0\n",
      "      17390 |   0.000033  |    0.005179     |   2\n",
      "      17391 |   0.181638  |    0.053862     |   0\n",
      "      17392 |   0.005509  |    0.014322     |   2\n",
      "      17393 |   0.072683  |    0.036230     |   2\n",
      "      17394 |   0.168965  |    0.143706     |   1\n",
      "      17395 |   0.209436  |    0.054246     |   1\n",
      "      17396 |   0.036430  |    0.029613     |   2\n",
      "      17397 |   0.057244  |    0.032257     |   2\n",
      "      17398 |   0.044816  |    0.023311     |   2\n",
      "      17399 |   0.216331  |    0.142758     |   1\n",
      "      17400 |   0.168877  |    0.007708     |   0\n",
      "      17401 |   0.019787  |    0.004319     |   2\n",
      "      17402 |   0.040391  |    0.034756     |   2\n",
      "      17403 |   0.032175  |    0.016808     |   2\n",
      "      17404 |   0.209492  |    0.171032     |   1\n",
      "      17405 |   0.000034  |    0.006030     |   2\n",
      "      17406 |   0.220930  |    0.022018     |   1\n",
      "      17407 |   0.272296  |    0.058977     |   0\n",
      "      17408 |   0.201093  |    0.088640     |   1\n",
      "      17409 |   0.220181  |    0.034984     |   1\n",
      "      17410 |   0.000034  |    0.031860     |   2\n",
      "      17411 |   0.000034  |    0.008940     |   2\n",
      "      17412 |   0.215268  |    0.045308     |   0\n",
      "      17413 |   0.000034  |    0.007846     |   2\n",
      "      17414 |   0.224064  |    0.147773     |   1\n",
      "      17415 |   0.186481  |    0.002900     |   0\n",
      "      17416 |   0.000034  |    0.007331     |   2\n",
      "      17417 |   0.000033  |    0.041185     |   2\n",
      "      17418 |   0.169472  |    0.012804     |   0\n",
      "      17419 |   0.051223  |    0.038662     |   2\n",
      "      17420 |   0.171309  |    0.013752     |   0\n",
      "      17421 |   0.209176  |    0.142458     |   1\n",
      "      17422 |   0.226614  |    0.004889     |   0\n",
      "      17423 |   0.199867  |    0.017899     |   0\n",
      "      17424 |   0.204847  |    0.161785     |   1\n",
      "      17425 |   0.216862  |    0.051126     |   1\n",
      "      17426 |   0.192391  |    0.028568     |   0\n",
      "      17427 |   0.048775  |    0.018542     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 17428: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      17428 |   0.232334  |    0.090854     |   1\n",
      "      17429 |   0.048275  |    0.009456     |   2\n",
      "      17430 |   0.214739  |    0.037052     |   0\n",
      "      17431 |   0.034739  |    0.006308     |   2\n",
      "      17432 |   0.244861  |    0.148965     |   1\n",
      "      17433 |   0.232885  |    0.067590     |   1\n",
      "      17434 |   0.266545  |    0.078503     |   1\n",
      "      17435 |   0.230733  |    0.029066     |   0\n",
      "      17436 |   0.040913  |    0.019559     |   2\n",
      "      17437 |   0.049813  |    0.028416     |   2\n",
      "      17438 |   0.029688  |    0.027589     |   2\n",
      "      17439 |   0.040708  |    0.025788     |   2\n",
      "      17440 |   0.163506  |    0.025161     |   0\n",
      "      17441 |   0.167091  |    0.022602     |   0\n",
      "      17442 |   0.255966  |    0.158632     |   1\n",
      "      17443 |   0.141997  |    0.046140     |   1\n",
      "      17444 |   0.256748  |    0.045264     |   0\n",
      "      17445 |   0.217524  |    0.093605     |   1\n",
      "      17446 |   0.048818  |    0.009606     |   2\n",
      "      17447 |   0.058369  |    0.040586     |   2\n",
      "      17448 |   0.046969  |    0.009870     |   2\n",
      "      17449 |   0.295867  |    0.049259     |   0\n",
      "      17450 |   0.249675  |    0.100710     |   1\n",
      "      17451 |   0.024454  |    0.005069     |   2\n",
      "      17452 | \u001b[94m  0.000033\u001b[0m  |    0.022335     |   2\n",
      "      17453 |   0.207888  |    0.151919     |   1\n",
      "      17454 |   0.161562  |    0.028153     |   1\n",
      "      17455 |   0.005590  |    0.051646     |   2\n",
      "      17456 |   0.255968  |    0.086540     |   1\n",
      "      17457 |   0.232339  |    0.016755     |   0\n",
      "      17458 |   0.068836  |    0.022742     |   2\n",
      "      17459 |   0.220389  |    0.078313     |   1\n",
      "      17460 |   0.036616  |    0.040842     |   2\n",
      "      17461 |   0.057791  |    0.021861     |   2\n",
      "      17462 |   0.186872  |    0.092050     |   1\n",
      "      17463 |   0.045481  |    0.008577     |   2\n",
      "      17464 |   0.174260  |    0.046197     |   0\n",
      "      17465 |   0.149473  |    0.090909     |   1\n",
      "      17466 |   0.019269  |    0.015659     |   2\n",
      "      17467 |   0.223954  |    0.143699     |   1\n",
      "      17468 |   0.209967  |    0.042151     |   1\n",
      "      17469 |   0.180516  |    0.036268     |   0\n",
      "      17470 |   0.216733  |    0.091024     |   1\n",
      "      17471 |   0.231352  |    0.028009     |   0\n",
      "      17472 |   0.039514  |    0.018281     |   2\n",
      "      17473 |   0.164112  |    0.031351     |   0\n",
      "      17474 |   0.175939  |    0.037550     |   0\n",
      "      17475 |   0.189669  |    0.145147     |   1\n",
      "      17476 |   0.204775  |    0.051375     |   1\n",
      "      17477 |   0.250813  |    0.093502     |   1\n",
      "      17478 |   0.034076  |    0.016174     |   2\n",
      "      17479 |   0.250619  |    0.133178     |   1\n",
      "      17480 |   0.187599  |    0.007684     |   0\n",
      "      17481 |   0.277881  |    0.027988     |   0\n",
      "      17482 |   0.173772  |    0.105687     |   1\n",
      "      17483 |   0.209401  |    0.020292     |   0\n",
      "      17484 |   0.266066  |    0.148563     |   1\n",
      "      17485 |   0.204687  |    0.051899     |   1\n",
      "      17486 |   0.000033  |    0.009745     |   2\n",
      "      17487 |   0.000033  |    0.042955     |   2\n",
      "      17488 |   0.256241  |    0.023800     |   0\n",
      "      17489 |   0.199704  |    0.164600     |   1\n",
      "      17490 |   0.223419  |    0.028765     |   1\n",
      "      17491 |   0.267029  |    0.131768     |   1\n",
      "      17492 |   0.197439  |    0.007922     |   0\n",
      "      17493 |   0.000033  |    0.023807     |   2\n",
      "      17494 |   0.219837  |    0.036691     |   0\n",
      "      17495 |   0.161402  |    0.020090     |   0\n",
      "      17496 |   0.211279  |    0.031139     |   0\n",
      "      17497 |   0.000033  |    0.020471     |   2\n",
      "      17498 |   0.173096  |    0.045276     |   0\n",
      "      17499 |   0.177960  |    0.010318     |   0\n",
      "      17500 |   0.280626  |    0.055063     |   0\n",
      "      17501 |   0.247773  |    0.165838     |   1\n",
      "      17502 |   0.171856  |    0.089813     |   1\n",
      "      17503 |   0.052158  |    0.008890     |   2\n",
      "      17504 |   0.176050  |    0.045648     |   0\n",
      "      17505 |   0.155120  |    0.005435     |   0\n",
      "      17506 |   0.232324  |    0.043889     |   0\n",
      "      17507 |   0.144941  |    0.019341     |   0\n",
      "      17508 |   0.038373  |    0.035053     |   2\n",
      "      17509 |   0.042759  |    0.026064     |   2\n",
      "      17510 |   0.177487  |    0.042320     |   0\n",
      "      17511 |   0.218192  |    0.095036     |   1\n",
      "      17512 |   0.264249  |    0.085727     |   1\n",
      "      17513 |   0.206895  |    0.022802     |   0\n",
      "      17514 |   0.221136  |    0.054591     |   0\n",
      "      17515 |   0.051641  |    0.006736     |   2\n",
      "      17516 |   0.030314  |    0.049374     |   2\n",
      "      17517 |   0.201326  |    0.016014     |   0\n",
      "      17518 |   0.042554  |    0.042197     |   2\n",
      "      17519 |   0.184007  |    0.012218     |   0\n",
      "      17520 |   0.188211  |    0.046445     |   0\n",
      "      17521 |   0.180473  |    0.085404     |   1\n",
      "      17522 |   0.173028  |    0.082692     |   1\n",
      "      17523 |   0.196175  |    0.018232     |   0\n",
      "      17524 |   0.242572  |    0.134934     |   1\n",
      "      17525 |   0.202712  |    0.006184     |   0\n",
      "      17526 |   0.266702  |    0.094625     |   1\n",
      "      17527 |   0.199275  |    0.016521     |   0\n",
      "      17528 |   0.228123  |    0.032659     |   0\n",
      "      17529 |   0.257840  |    0.027470     |   0\n",
      "      17530 |   0.167658  |    0.028510     |   0\n",
      "      17531 |   0.214985  |    0.051253     |   0\n",
      "      17532 |   0.268953  |    0.097842     |   1\n",
      "      17533 |   0.055238  |    0.010676     |   2\n",
      "      17534 |   0.060843  |    0.048392     |   2\n",
      "      17535 |   0.048437  |    0.012113     |   2\n",
      "      17536 |   0.023523  |    0.027402     |   2\n",
      "      17537 |   0.195058  |    0.055520     |   0\n",
      "      17538 |   0.281274  |    0.100751     |   1\n",
      "      17539 |   0.203776  |    0.018217     |   0\n",
      "      17540 |   0.000033  |    0.073199     |   2\n",
      "      17541 |   0.236094  |    0.030191     |   1\n",
      "      17542 |   0.006387  |    0.013256     |   2\n",
      "      17543 |   0.201956  |    0.046618     |   0\n",
      "      17544 |   0.068172  |    0.024234     |   2\n",
      "      17545 |   0.034399  |    0.030403     |   2\n",
      "      17546 |   0.058648  |    0.029316     |   2\n",
      "      17547 |   0.174981  |    0.045607     |   0\n",
      "      17548 |   0.050982  |    0.033856     |   2\n",
      "      17549 |   0.241448  |    0.092298     |   1\n",
      "      17550 |   0.164262  |    0.033482     |   0\n",
      "      17551 |   0.170002  |    0.108600     |   1\n",
      "      17552 |   0.222481  |    0.023390     |   0\n",
      "      17553 |   0.018858  |    0.023255     |   2\n",
      "      17554 |   0.156896  |    0.029768     |   0\n",
      "      17555 |   0.212182  |    0.112390     |   1\n",
      "      17556 |   0.038961  |    0.022017     |   2\n",
      "      17557 |   0.034183  |    0.034185     |   2\n",
      "      17558 |   0.279721  |    0.052661     |   1\n",
      "      17559 |   0.169797  |    0.039795     |   0\n",
      "      17560 |   0.227586  |    0.061969     |   1\n",
      "      17561 |   0.000034  |    0.032280     |   2\n",
      "      17562 |   0.169220  |    0.110778     |   1\n",
      "      17563 |   0.212735  |    0.018810     |   0\n",
      "      17564 |   0.271034  |    0.141442     |   1\n",
      "      17565 |   0.000034  |    0.002889     |   2\n",
      "      17566 |   0.000034  |    0.011203     |   2\n",
      "      17567 |   0.192916  |    0.134442     |   1\n",
      "      17568 |   0.198980  |    0.097014     |   1\n",
      "      17569 |   0.193092  |    0.067482     |   1\n",
      "      17570 |   0.000034  |    0.032896     |   2\n",
      "      17571 |   0.219594  |    0.098601     |   1\n",
      "      17572 |   0.189368  |    0.015355     |   0\n",
      "      17573 |   0.000034  |    0.028829     |   2\n",
      "      17574 |   0.266378  |    0.036587     |   0\n",
      "      17575 |   0.000034  |    0.030757     |   2\n",
      "      17576 |   0.052066  |    0.008466     |   2\n",
      "      17577 |   0.048642  |    0.065150     |   2\n",
      "      17578 |   0.196496  |    0.094840     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 17579: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      17579 |   0.142569  |    0.060135     |   1\n",
      "      17580 |   0.049670  |    0.030649     |   2\n",
      "      17581 |   0.223766  |    0.130054     |   1\n",
      "      17582 |   0.035309  |    0.011182     |   2\n",
      "      17583 |   0.043108  |    0.006623     |   2\n",
      "      17584 |   0.145974  |    0.128783     |   1\n",
      "      17585 |   0.226891  |    0.082422     |   1\n",
      "      17586 |   0.188637  |    0.154026     |   1\n",
      "      17587 |   0.187327  |    0.002970     |   0\n",
      "      17588 |   0.047484  |    0.008641     |   2\n",
      "      17589 |   0.217729  |    0.044680     |   0\n",
      "      17590 |   0.176833  |    0.017695     |   0\n",
      "      17591 |   0.028555  |    0.027146     |   2\n",
      "      17592 |   0.200737  |    0.032873     |   0\n",
      "      17593 |   0.039896  |    0.020162     |   2\n",
      "      17594 |   0.192502  |    0.029348     |   0\n",
      "      17595 |   0.049530  |    0.026454     |   2\n",
      "      17596 |   0.060172  |    0.013611     |   2\n",
      "      17597 |   0.247989  |    0.189205     |   1\n",
      "      17598 |   0.047800  |    0.019495     |   2\n",
      "      17599 |   0.201324  |    0.008104     |   1\n",
      "      17600 |   0.022459  |    0.035751     |   2\n",
      "      17601 |   0.172233  |    0.020317     |   0\n",
      "      17602 |   0.000033  |    0.041887     |   2\n",
      "      17603 |   0.152952  |    0.011447     |   0\n",
      "      17604 |   0.005671  |    0.032056     |   2\n",
      "      17605 |   0.184665  |    0.056983     |   0\n",
      "      17606 |   0.165955  |    0.085738     |   1\n",
      "      17607 |   0.189068  |    0.023335     |   0\n",
      "      17608 |   0.193900  |    0.053474     |   0\n",
      "      17609 |   0.068106  |    0.012593     |   2\n",
      "      17610 |   0.161663  |    0.155625     |   1\n",
      "      17611 |   0.327058  |    0.048662     |   1\n",
      "      17612 |   0.033594  |    0.031774     |   2\n",
      "      17613 |   0.236850  |    0.033939     |   0\n",
      "      17614 |   0.056968  |    0.021146     |   2\n",
      "      17615 |   0.225267  |    0.143209     |   1\n",
      "      17616 |   0.160439  |    0.006600     |   0\n",
      "      17617 |   0.185348  |    0.039709     |   0\n",
      "      17618 |   0.263235  |    0.099987     |   1\n",
      "      17619 |   0.189152  |    0.014940     |   0\n",
      "      17620 |   0.045853  |    0.019284     |   2\n",
      "      17621 |   0.185650  |    0.154642     |   1\n",
      "      17622 |   0.020335  |    0.008170     |   2\n",
      "      17623 |   0.194265  |    0.083618     |   1\n",
      "      17624 |   0.152448  |    0.034545     |   0\n",
      "      17625 |   0.037216  |    0.027623     |   2\n",
      "      17626 |   0.220148  |    0.029677     |   0\n",
      "      17627 |   0.249185  |    0.028071     |   0\n",
      "      17628 |   0.147943  |    0.096230     |   1\n",
      "      17629 |   0.032416  |    0.021563     |   2\n",
      "      17630 |   0.218301  |    0.100300     |   1\n",
      "      17631 |   0.000033  |    0.016142     |   2\n",
      "      17632 |   0.160553  |    0.136924     |   1\n",
      "      17633 |   0.000033  |    0.004972     |   2\n",
      "      17634 |   0.000033  |    0.018585     |   2\n",
      "      17635 |   0.162810  |    0.146909     |   1\n",
      "      17636 |   0.158391  |    0.004751     |   0\n",
      "      17637 |   0.000033  |    0.007510     |   2\n",
      "      17638 |   0.213404  |    0.056187     |   0\n",
      "      17639 |   0.244653  |    0.079537     |   1\n",
      "      17640 |   0.253744  |    0.029052     |   0\n",
      "      17641 |   0.172678  |    0.135455     |   1\n",
      "      17642 |   0.000033  |    0.004322     |   2\n",
      "      17643 |   0.249931  |    0.039967     |   0\n",
      "      17644 |   0.202746  |    0.092584     |   1\n",
      "      17645 |   0.000033  |    0.007006     |   2\n",
      "      17646 |   0.054001  |    0.031817     |   2\n",
      "      17647 |   0.235311  |    0.032590     |   0\n",
      "      17648 |   0.206218  |    0.030265     |   0\n",
      "      17649 |   0.207601  |    0.141335     |   1\n",
      "      17650 |   0.176563  |    0.009692     |   0\n",
      "      17651 |   0.048524  |    0.009796     |   2\n",
      "      17652 |   0.250864  |    0.144148     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 17654: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      17653 |   0.196237  |    0.005274     |   0\n",
      "      17654 |   0.178625  |    0.007060     |   0\n",
      "      17655 |   0.054393  |    0.048137     |   2\n",
      "      17656 |   0.234163  |    0.089045     |   1\n",
      "      17657 |   0.040603  |    0.009935     |   2\n",
      "      17658 |   0.042088  |    0.042766     |   2\n",
      "      17659 |   0.048341  |    0.007305     |   2\n",
      "      17660 |   0.163570  |    0.055057     |   0\n",
      "      17661 |   0.206693  |    0.094145     |   1\n",
      "      17662 |   0.300255  |    0.096112     |   1\n",
      "      17663 |   0.192553  |    0.077451     |   1\n",
      "      17664 |   0.203887  |    0.010570     |   0\n",
      "      17665 |   0.202939  |    0.040592     |   0\n",
      "      17666 |   0.226210  |    0.142035     |   1\n",
      "      17667 |   0.211155  |    0.058388     |   1\n",
      "      17668 |   0.206732  |    0.111852     |   1\n",
      "      17669 |   0.226321  |    0.088027     |   1\n",
      "      17670 |   0.029843  |    0.007797     |   2\n",
      "      17671 |   0.160362  |    0.052830     |   0\n",
      "      17672 |   0.212874  |    0.063064     |   1\n",
      "      17673 |   0.041098  |    0.009658     |   2\n",
      "      17674 |   0.049994  |    0.032467     |   2\n",
      "      17675 |   0.211721  |    0.143144     |   1\n",
      "      17676 |   0.059031  |    0.002865     |   2\n",
      "      17677 |   0.046063  |    0.013263     |   2\n",
      "      17678 |   0.021600  |    0.055203     |   2\n",
      "      17679 |   0.173324  |    0.054779     |   1\n",
      "      17680 |   0.164428  |    0.009035     |   0\n",
      "      17681 |   0.207581  |    0.043497     |   0\n",
      "      17682 |   0.292879  |    0.116751     |   1\n",
      "      17683 |   0.000033  |    0.014100     |   2\n",
      "      17684 |   0.155650  |    0.022066     |   0\n",
      "      17685 |   0.204097  |    0.136422     |   1\n",
      "      17686 |   0.005793  |    0.014307     |   2\n",
      "      17687 |   0.230621  |    0.084584     |   1\n",
      "      17688 |   0.066090  |    0.011162     |   2\n",
      "      17689 |   0.197413  |    0.040516     |   0\n",
      "      17690 |   0.157642  |    0.013093     |   0\n",
      "      17691 |   0.161136  |    0.031365     |   0\n",
      "      17692 |   0.170897  |    0.151210     |   1\n",
      "      17693 |   0.274775  |    0.044500     |   1\n",
      "      17694 |   0.033461  |    0.016055     |   2\n",
      "      17695 |   0.212197  |    0.045790     |   0\n",
      "      17696 |   0.220908  |    0.079202     |   1\n",
      "      17697 |   0.198973  |    0.106781     |   1\n",
      "      17698 |   0.200582  |    0.008622     |   0\n",
      "      17699 |   0.190601  |    0.044055     |   0\n",
      "      17700 |   0.203839  |    0.091616     |   1\n",
      "      17701 |   0.057809  |    0.046364     |   2\n",
      "      17702 |   0.224187  |    0.046039     |   1\n",
      "      17703 |   0.045593  |    0.013360     |   2\n",
      "      17704 |   0.019343  |    0.051228     |   2\n",
      "      17705 |   0.204432  |    0.047525     |   1\n",
      "      17706 |   0.243282  |    0.020468     |   0\n",
      "      17707 |   0.179960  |    0.030524     |   0\n",
      "      17708 |   0.283682  |    0.103430     |   1\n",
      "      17709 |   0.160933  |    0.111318     |   1\n",
      "      17710 |   0.152712  |    0.045667     |   1\n",
      "      17711 |   0.222162  |    0.046446     |   0\n",
      "      17712 |   0.197035  |    0.148205     |   1\n",
      "      17713 |   0.039272  |    0.005937     |   2\n",
      "      17714 |   0.182510  |    0.078990     |   1\n",
      "      17715 |   0.031158  |    0.005008     |   2\n",
      "      17716 |   0.000033  |    0.016591     |   2\n",
      "      17717 |   0.188314  |    0.028686     |   0\n",
      "      17718 |   0.000033  |    0.021699     |   2\n",
      "      17719 |   0.165301  |    0.045313     |   0\n",
      "      17720 |   0.165578  |    0.009895     |   0\n",
      "      17721 |   0.234925  |    0.189442     |   1\n",
      "      17722 |   0.204315  |    0.015651     |   1\n",
      "      17723 |   0.000033  |    0.028947     |   2\n",
      "      17724 |   0.204440  |    0.021628     |   0\n",
      "      17725 |   0.174628  |    0.054981     |   0\n",
      "      17726 |   0.180537  |    0.098146     |   1\n",
      "      17727 |   0.201135  |    0.013677     |   0\n",
      "      17728 |   0.200239  |    0.085079     |   1\n",
      "      17729 |   0.000033  |    0.006126     |   2\n",
      "      17730 |   0.166798  |    0.043016     |   0\n",
      "      17731 |   0.000033  |    0.013403     |   2\n",
      "      17732 |   0.000033  |    0.026074     |   2\n",
      "      17733 |   0.237469  |    0.048066     |   0\n",
      "      17734 |   0.225270  |    0.019210     |   0\n",
      "      17735 |   0.186067  |    0.146303     |   1\n",
      "      17736 |   0.055424  |    0.009117     |   2\n",
      "      17737 |   0.048119  |    0.009069     |   2\n",
      "      17738 |   0.161979  |    0.030587     |   0\n",
      "      17739 |   0.149394  |    0.023438     |   0\n",
      "      17740 |   0.159587  |    0.029911     |   0\n",
      "      17741 |   0.181684  |    0.051252     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 17742: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      17742 |   0.216691  |    0.090314     |   1\n",
      "      17743 |   0.188863  |    0.051709     |   1\n",
      "      17744 |   0.167795  |    0.010977     |   0\n",
      "      17745 |   0.055962  |    0.030127     |   2\n",
      "      17746 |   0.199884  |    0.030246     |   0\n",
      "      17747 |   0.198413  |    0.098283     |   1\n",
      "      17748 |   0.205950  |    0.145694     |   1\n",
      "      17749 |   0.206170  |    0.055366     |   1\n",
      "      17750 |   0.160712  |    0.016020     |   0\n",
      "      17751 |   0.039712  |    0.028646     |   2\n",
      "      17752 |   0.200419  |    0.104245     |   1\n",
      "      17753 |   0.207723  |    0.085934     |   1\n",
      "      17754 |   0.243836  |    0.067311     |   1\n",
      "      17755 |   0.191502  |    0.049835     |   0\n",
      "      17756 |   0.042243  |    0.015566     |   2\n",
      "      17757 |   0.181467  |    0.147712     |   1\n",
      "      17758 |   0.159056  |    0.003605     |   0\n",
      "      17759 |   0.159754  |    0.021665     |   0\n",
      "      17760 |   0.047144  |    0.016887     |   2\n",
      "      17761 |   0.029877  |    0.043068     |   2\n",
      "      17762 |   0.180729  |    0.011249     |   0\n",
      "      17763 |   0.197624  |    0.121765     |   1\n",
      "      17764 |   0.268367  |    0.031793     |   1\n",
      "      17765 |   0.209525  |    0.038412     |   0\n",
      "      17766 |   0.279623  |    0.079900     |   1\n",
      "      17767 |   0.231455  |    0.018534     |   0\n",
      "      17768 |   0.236720  |    0.050979     |   0\n",
      "      17769 |   0.177315  |    0.082888     |   1\n",
      "      17770 |   0.163200  |    0.030801     |   0\n",
      "      17771 |   0.040032  |    0.024211     |   2\n",
      "      17772 |   0.148517  |    0.046498     |   0\n",
      "      17773 |   0.204459  |    0.080165     |   1\n",
      "      17774 |   0.049272  |    0.021034     |   2\n",
      "      17775 |   0.175232  |    0.144842     |   1\n",
      "      17776 |   0.060638  |    0.008302     |   2\n",
      "      17777 |   0.048663  |    0.029194     |   2\n",
      "      17778 |   0.023096  |    0.019628     |   2\n",
      "      17779 |   0.000033  |    0.025876     |   2\n",
      "      17780 |   0.006013  |    0.026349     |   2\n",
      "      17781 |   0.241343  |    0.153611     |   1\n",
      "      17782 |   0.225377  |    0.050421     |   1\n",
      "      17783 |   0.158409  |    0.013331     |   0\n",
      "      17784 |   0.177274  |    0.025628     |   0\n",
      "      17785 |   0.065856  |    0.057313     |   2\n",
      "      17786 |   0.032912  |    0.013099     |   2\n",
      "      17787 |   0.059469  |    0.054055     |   2\n",
      "      17788 |   0.233661  |    0.091856     |   1\n",
      "      17789 |   0.207403  |    0.082601     |   1\n",
      "      17790 |   0.044770  |    0.008046     |   2\n",
      "      17791 |   0.018275  |    0.017105     |   2\n",
      "      17792 |   0.214127  |    0.143123     |   1\n",
      "      17793 |   0.035225  |    0.002909     |   2\n",
      "      17794 |   0.034300  |    0.010092     |   2\n",
      "      17795 |   0.221493  |    0.145335     |   1\n",
      "      17796 |   0.181735  |    0.010466     |   0\n",
      "      17797 |   0.180263  |    0.090526     |   1\n",
      "      17798 |   0.217702  |    0.139224     |   1\n",
      "      17799 |   0.212380  |    0.002990     |   0\n",
      "      17800 |   0.000034  |    0.004906     |   2\n",
      "      17801 |   0.165861  |    0.051276     |   0\n",
      "      17802 |   0.240385  |    0.091544     |   1\n",
      "      17803 |   0.000034  |    0.005394     |   2\n",
      "      17804 |   0.175371  |    0.164448     |   1\n",
      "      17805 |   0.172233  |    0.013369     |   0\n",
      "      17806 |   0.247226  |    0.062234     |   1\n",
      "      17807 |   0.220822  |    0.027131     |   0\n",
      "      17808 |   0.213993  |    0.139572     |   1\n",
      "      17809 |   0.188747  |    0.007863     |   0\n",
      "      17810 |   0.199374  |    0.008922     |   0\n",
      "      17811 |   0.219298  |    0.030536     |   0\n",
      "      17812 |   0.206229  |    0.020565     |   0\n",
      "      17813 |   0.000033  |    0.033915     |   2\n",
      "      17814 |   0.000034  |    0.018736     |   2\n",
      "      17815 |   0.181534  |    0.158518     |   1\n",
      "      17816 |   0.251755  |    0.048817     |   1\n",
      "      17817 |   0.181860  |    0.037886     |   0\n",
      "      17818 |   0.171677  |    0.107778     |   1\n",
      "      17819 |   0.219193  |    0.079957     |   1\n",
      "      17820 |   0.183820  |    0.021723     |   0\n",
      "      17821 |   0.263492  |    0.049018     |   0\n",
      "      17822 |   0.206033  |    0.057791     |   1\n",
      "      17823 |   0.192320  |    0.138748     |   1\n",
      "      17824 |   0.000033  |    0.006940     |   2\n",
      "      17825 |   0.242909  |    0.007933     |   0\n",
      "      17826 |   0.195424  |    0.040775     |   0\n",
      "      17827 |   0.162727  |    0.108379     |   1\n",
      "      17828 |   0.224314  |    0.092491     |   1\n",
      "      17829 |   0.267211  |    0.097224     |   1\n",
      "      17830 |   0.173725  |    0.011151     |   0\n",
      "      17831 |   0.169541  |    0.147728     |   1\n",
      "      17832 |   0.000033  |    0.003021     |   2\n",
      "      17833 |   0.052943  |    0.008401     |   2\n",
      "      17834 |   0.165994  |    0.028183     |   0\n",
      "      17835 |   0.202249  |    0.032914     |   0\n",
      "      17836 |   0.221680  |    0.045405     |   0\n",
      "      17837 |   0.048261  |    0.027728     |   2\n",
      "      17838 |   0.224658  |    0.120276     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 17839: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      17839 |   0.230928  |    0.055737     |   1\n",
      "      17840 |   0.052352  |    0.010252     |   2\n",
      "      17841 |   0.221362  |    0.030806     |   0\n",
      "      17842 |   0.040062  |    0.057092     |   2\n",
      "      17843 |   0.246879  |    0.082811     |   1\n",
      "      17844 |   0.197439  |    0.086053     |   1\n",
      "      17845 |   0.040670  |    0.011535     |   2\n",
      "      17846 |   0.046532  |    0.038059     |   2\n",
      "      17847 |   0.186163  |    0.095350     |   1\n",
      "      17848 |   0.228580  |    0.030462     |   0\n",
      "      17849 |   0.210267  |    0.021256     |   0\n",
      "      17850 |   0.167596  |    0.139141     |   1\n",
      "      17851 |   0.247413  |    0.059045     |   1\n",
      "      17852 |   0.199244  |    0.092483     |   1\n",
      "      17853 |   0.030147  |    0.013604     |   2\n",
      "      17854 |   0.251623  |    0.100085     |   1\n",
      "      17855 |   0.157409  |    0.024675     |   0\n",
      "      17856 |   0.284704  |    0.030005     |   0\n",
      "      17857 |   0.040412  |    0.024267     |   2\n",
      "      17858 |   0.047876  |    0.032940     |   2\n",
      "      17859 |   0.193849  |    0.176109     |   1\n",
      "      17860 |   0.060531  |    0.018827     |   2\n",
      "      17861 |   0.229585  |    0.015030     |   1\n",
      "      17862 |   0.048052  |    0.022859     |   2\n",
      "      17863 |   0.297019  |    0.096182     |   1\n",
      "      17864 |   0.243276  |    0.022677     |   0\n",
      "      17865 |   0.025480  |    0.030877     |   2\n",
      "      17866 |   0.150049  |    0.020996     |   0\n",
      "      17867 |   0.202950  |    0.028737     |   0\n",
      "      17868 |   0.238097  |    0.090668     |   1\n",
      "      17869 |   0.000033  |    0.017124     |   2\n",
      "      17870 |   0.005542  |    0.064791     |   2\n",
      "      17871 |   0.235591  |    0.059237     |   1\n",
      "      17872 |   0.138203  |    0.018307     |   0\n",
      "      17873 |   0.218459  |    0.134104     |   1\n",
      "      17874 |   0.220870  |    0.006168     |   0\n",
      "      17875 |   0.185339  |    0.033415     |   0\n",
      "      17876 |   0.235817  |    0.014087     |   0\n",
      "      17877 |   0.069138  |    0.046301     |   2\n",
      "      17878 |   0.035458  |    0.014575     |   2\n",
      "      17879 |   0.230652  |    0.134948     |   1\n",
      "      17880 |   0.214649  |    0.083626     |   1\n",
      "      17881 |   0.060624  |    0.012322     |   2\n",
      "      17882 |   0.267249  |    0.083316     |   1\n",
      "      17883 |   0.194665  |    0.091158     |   1\n",
      "      17884 |   0.046895  |    0.009762     |   2\n",
      "      17885 |   0.180824  |    0.043963     |   0\n",
      "      17886 |   0.192866  |    0.081229     |   1\n",
      "      17887 |   0.017867  |    0.021053     |   2\n",
      "      17888 |   0.166410  |    0.132459     |   1\n",
      "      17889 |   0.037931  |    0.026819     |   2\n",
      "      17890 |   0.033244  |    0.039917     |   2\n",
      "      17891 |   0.182500  |    0.130229     |   1\n",
      "      17892 |   0.221035  |    0.086518     |   1\n",
      "      17893 |   0.166089  |    0.005730     |   0\n",
      "      17894 |   0.271518  |    0.104791     |   1\n",
      "      17895 |   0.253648  |    0.082780     |   1\n",
      "      17896 |   0.000033  |    0.005079     |   2\n",
      "      17897 |   0.237417  |    0.143062     |   1\n",
      "      17898 |   0.000033  |    0.003101     |   2\n",
      "      17899 |   0.000033  |    0.009824     |   2\n",
      "      17900 |   0.223108  |    0.026229     |   0\n",
      "      17901 |   0.000033  |    0.046060     |   2\n",
      "      17902 |   0.215402  |    0.088882     |   1\n",
      "      17903 |   0.178435  |    0.012349     |   0\n",
      "      17904 |   0.159914  |    0.047837     |   0\n",
      "      17905 |   0.152586  |    0.078221     |   1\n",
      "      17906 |   0.000033  |    0.014884     |   2\n",
      "      17907 |   0.212247  |    0.057228     |   0\n",
      "      17908 |   0.243010  |    0.096927     |   1\n",
      "      17909 |   0.208885  |    0.076411     |   1\n",
      "      17910 |   0.141592  |    0.102251     |   1\n",
      "      17911 |   0.232180  |    0.099301     |   1\n",
      "      17912 |   0.000033  |    0.031940     |   2\n",
      "      17913 |   0.277369  |    0.101991     |   1\n",
      "      17914 |   0.051234  |    0.030539     |   2\n",
      "      17915 |   0.219360  |    0.080959     |   1\n",
      "      17916 |   0.047838  |    0.009715     |   2\n",
      "      17917 |   0.255968  |    0.058531     |   1\n",
      "      17918 |   0.212159  |    0.043014     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 17919: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      17919 |   0.048298  |    0.014353     |   2\n",
      "      17920 |   0.034963  |    0.031800     |   2\n",
      "      17921 |   0.042813  |    0.023687     |   2\n",
      "      17922 |   0.047345  |    0.034284     |   2\n",
      "      17923 |   0.189163  |    0.146127     |   1\n",
      "      17924 |   0.189762  |    0.059230     |   1\n",
      "      17925 |   0.167314  |    0.016157     |   0\n",
      "      17926 |   0.179436  |    0.146884     |   1\n",
      "      17927 |   0.259915  |    0.054155     |   1\n",
      "      17928 |   0.192521  |    0.017135     |   0\n",
      "      17929 |   0.225102  |    0.144962     |   1\n",
      "      17930 |   0.233995  |    0.007004     |   0\n",
      "      17931 |   0.186849  |    0.013824     |   0\n",
      "      17932 |   0.182896  |    0.050557     |   0\n",
      "      17933 |   0.284302  |    0.018158     |   0\n",
      "      17934 |   0.029315  |    0.056402     |   2\n",
      "      17935 |   0.040585  |    0.012805     |   2\n",
      "      17936 |   0.193281  |    0.029764     |   0\n",
      "      17937 |   0.157089  |    0.033117     |   0\n",
      "      17938 |   0.049066  |    0.017080     |   2\n",
      "      17939 |   0.252026  |    0.142862     |   1\n",
      "      17940 |   0.210240  |    0.056698     |   1\n",
      "      17941 |   0.058194  |    0.017220     |   2\n",
      "      17942 |   0.167486  |    0.028136     |   0\n",
      "      17943 |   0.207068  |    0.042197     |   0\n",
      "      17944 |   0.049967  |    0.018531     |   2\n",
      "      17945 |   0.228291  |    0.021654     |   0\n",
      "      17946 |   0.193862  |    0.134905     |   1\n",
      "      17947 |   0.024446  |    0.006383     |   2\n",
      "      17948 | \u001b[94m  0.000032\u001b[0m  |    0.045276     |   2\n",
      "      17949 |   0.006035  |    0.019349     |   2\n",
      "      17950 |   0.068122  |    0.036531     |   2\n",
      "      17951 |   0.034262  |    0.022442     |   2\n",
      "      17952 |   0.198468  |    0.046228     |   0\n",
      "      17953 |   0.061186  |    0.010464     |   2\n",
      "      17954 |   0.046903  |    0.035942     |   2\n",
      "      17955 |   0.215758  |    0.116443     |   1\n",
      "      17956 |   0.205735  |    0.090619     |   1\n",
      "      17957 |   0.018852  |    0.012354     |   2\n",
      "      17958 |   0.038115  |    0.045313     |   2\n",
      "      17959 |   0.031478  |    0.009484     |   2\n",
      "      17960 |   0.219016  |    0.046246     |   0\n",
      "      17961 |   0.000032  |    0.019949     |   2\n",
      "      17962 |   0.194369  |    0.049782     |   0\n",
      "      17963 |   0.253705  |    0.081276     |   1\n",
      "      17964 |   0.000032  |    0.009765     |   2\n",
      "      17965 |   0.234310  |    0.028247     |   0\n",
      "      17966 |   0.193965  |    0.041164     |   0\n",
      "      17967 |   0.214592  |    0.028351     |   0\n",
      "      17968 |   0.236717  |    0.035769     |   0\n",
      "      17969 |   0.179079  |    0.094276     |   1\n",
      "      17970 |   0.190237  |    0.036114     |   0\n",
      "      17971 |   0.201424  |    0.146464     |   1\n",
      "      17972 |   0.180968  |    0.015451     |   0\n",
      "      17973 |   0.177294  |    0.088627     |   1\n",
      "      17974 |   0.209366  |    0.081749     |   1\n",
      "      17975 |   0.161343  |    0.008897     |   0\n",
      "      17976 |   0.195094  |    0.055864     |   0\n",
      "      17977 |   0.000032  |    0.004092     |   2\n",
      "      17978 |   0.000032  |    0.053657     |   2\n",
      "      17979 |   0.259224  |    0.107058     |   1\n",
      "      17980 |   0.198771  |    0.095884     |   1\n",
      "      17981 |   0.178907  |    0.013761     |   0\n",
      "      17982 |   0.260908  |    0.082495     |   1\n",
      "      17983 |   0.187107  |    0.098034     |   1\n",
      "      17984 |   0.000032  |    0.022077     |   2\n",
      "      17985 |   0.127139  |    0.026016     |   0\n",
      "      17986 |   0.161177  |    0.142270     |   1\n",
      "      17987 |   0.186262  |    0.097897     |   1\n",
      "      17988 |   0.227411  |    0.004877     |   0\n",
      "      17989 |   0.000032  |    0.025947     |   2\n",
      "      17990 |   0.221830  |    0.140157     |   1\n",
      "      17991 |   0.196016  |    0.086934     |   1\n",
      "      17992 |   0.201638  |    0.014650     |   0\n",
      "      17993 |   0.213718  |    0.049729     |   0\n",
      "      17994 |   0.239012  |    0.057738     |   1\n",
      "      17995 |   0.151379  |    0.093906     |   1\n",
      "      17996 |   0.182044  |    0.089386     |   1\n",
      "      17997 |   0.246452  |    0.079728     |   1\n",
      "      17998 |   0.048230  |    0.024990     |   2\n",
      "      17999 |   0.047230  |    0.044885     |   2\n",
      "      18000 |   0.191168  |    0.083331     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 18000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 18000: Plotting estimates.\n",
      "Exception in thread neuralnilm-data-process:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 810, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/dk3810/workspace/python/neuralnilm/neuralnilm/data/datathread.py\", line 16, in run\n",
      "    batch = self.data_pipeline.get_batch(**self._get_batch_kwargs)\n",
      "  File \"/home/dk3810/workspace/python/neuralnilm/neuralnilm/data/datapipeline.py\", line 46, in get_batch\n",
      "    batch = self._source_iterators[source_id].next()\n",
      "ValueError: generator already executing\n",
      "\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      18001 |   0.210210  |    0.154823     |   1\n",
      "      18002 |   0.047814  |    0.012901     |   2\n",
      "      18003 |   0.205162  |    0.044761     |   0\n",
      "      18004 |   0.217206  |    0.011849     |   0\n",
      "      18005 |   0.142457  |    0.154074     |   1\n",
      "      18006 |   0.225255  |    0.008958     |   0\n",
      "      18007 |   0.292008  |    0.022106     |   0\n",
      "      18008 |   0.193449  |    0.045270     |   0\n",
      "      18009 |   0.038279  |    0.012209     |   2\n",
      "      18010 |   0.041329  |    0.046376     |   2\n",
      "      18011 |   0.221562  |    0.101790     |   1\n",
      "      18012 |   0.046572  |    0.010870     |   2\n",
      "      18013 |   0.029158  |    0.033125     |   2\n",
      "      18014 |   0.239460  |    0.025379     |   0\n",
      "      18015 |   0.040336  |    0.023849     |   2\n",
      "      18016 |   0.195494  |    0.021880     |   0\n",
      "      18017 |   0.049987  |    0.032191     |   2\n",
      "      18018 |   0.171588  |    0.025843     |   0\n",
      "      18019 |   0.057491  |    0.038383     |   2\n",
      "      18020 |   0.234544  |    0.140430     |   1\n",
      "      18021 |   0.256300  |    0.071291     |   1\n",
      "      18022 |   0.216615  |    0.062059     |   1\n",
      "      18023 |   0.049118  |    0.008487     |   2\n",
      "      18024 |   0.168331  |    0.049061     |   0\n",
      "      18025 |   0.224582  |    0.073985     |   1\n",
      "      18026 |   0.226134  |    0.144417     |   1\n",
      "      18027 |   0.023959  |    0.005638     |   2\n",
      "      18028 |   0.140793  |    0.015804     |   0\n",
      "      18029 |   0.187661  |    0.135887     |   1\n",
      "      18030 |   0.212644  |    0.095840     |   1\n",
      "      18031 |   0.177955  |    0.002978     |   0\n",
      "      18032 |   0.000032  |    0.010208     |   2\n",
      "      18033 |   0.244339  |    0.130604     |   1\n",
      "      18034 |   0.165533  |    0.010152     |   0\n",
      "      18035 |   0.005119  |    0.034042     |   2\n",
      "      18036 |   0.067445  |    0.017923     |   2\n",
      "      18037 |   0.178222  |    0.041338     |   0\n",
      "      18038 |   0.033776  |    0.018375     |   2\n",
      "      18039 |   0.141528  |    0.139881     |   1\n",
      "      18040 |   0.058573  |    0.006205     |   2\n",
      "      18041 |   0.043877  |    0.012425     |   2\n",
      "      18042 |   0.019921  |    0.042881     |   2\n",
      "      18043 |   0.036625  |    0.026250     |   2\n",
      "      18044 |   0.165969  |    0.131774     |   1\n",
      "      18045 |   0.031430  |    0.014462     |   2\n",
      "      18046 |   0.123480  |    0.038033     |   0\n",
      "      18047 |   0.000032  |    0.006640     |   2\n",
      "      18048 |   0.167338  |    0.047822     |   0\n",
      "      18049 |   0.245553  |    0.022076     |   0\n",
      "      18050 |   0.168714  |    0.152642     |   1\n",
      "      18051 |   0.222351  |    0.061950     |   1\n",
      "      18052 |   0.000032  |    0.009859     |   2\n",
      "      18053 |   0.201871  |    0.067149     |   0\n",
      "      18054 |   0.255601  |    0.078165     |   1\n",
      "      18055 |   0.000032  |    0.005280     |   2\n",
      "      18056 |   0.186609  |    0.054071     |   0\n",
      "      18057 |   0.222591  |    0.083862     |   1\n",
      "      18058 |   0.251768  |    0.124844     |   1\n",
      "      18059 |   0.000033  |    0.011693     |   2\n",
      "      18060 |   0.000032  |    0.017846     |   2\n",
      "      18061 |   0.219649  |    0.128496     |   1\n",
      "      18062 |   0.000032  |    0.012093     |   2\n",
      "      18063 |   0.186960  |    0.102154     |   1\n",
      "      18064 |   0.051207  |    0.008198     |   2\n",
      "      18065 |   0.196442  |    0.045478     |   0\n",
      "      18066 |   0.047614  |    0.012816     |   2\n",
      "      18067 |   0.200700  |    0.092024     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 18068: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      18068 |   0.047977  |    0.005554     |   2\n",
      "      18069 |   0.183923  |    0.042395     |   0\n",
      "      18070 |   0.038641  |    0.020529     |   2\n",
      "      18071 |   0.039799  |    0.040930     |   2\n",
      "      18072 |   0.222533  |    0.093968     |   1\n",
      "      18073 |   0.236843  |    0.080719     |   1\n",
      "      18074 |   0.046647  |    0.012118     |   2\n",
      "      18075 |   0.029407  |    0.046076     |   2\n",
      "      18076 |   0.159438  |    0.018488     |   0\n",
      "      18077 |   0.037940  |    0.023690     |   2\n",
      "      18078 |   0.208194  |    0.039668     |   0\n",
      "      18079 |   0.050180  |    0.023065     |   2\n",
      "      18080 |   0.055180  |    0.019116     |   2\n",
      "      18081 |   0.047432  |    0.037332     |   2\n",
      "      18082 |   0.245470  |    0.097130     |   1\n",
      "      18083 |   0.174413  |    0.005800     |   0\n",
      "      18084 |   0.167440  |    0.019924     |   0\n",
      "      18085 |   0.023020  |    0.026604     |   2\n",
      "      18086 |   0.239009  |    0.145460     |   1\n",
      "      18087 |   0.000032  |    0.007265     |   2\n",
      "      18088 |   0.224908  |    0.103381     |   1\n",
      "      18089 |   0.005623  |    0.004728     |   2\n",
      "      18090 |   0.189287  |    0.017023     |   0\n",
      "      18091 |   0.067830  |    0.047019     |   2\n",
      "      18092 |   0.032599  |    0.012017     |   2\n",
      "      18093 |   0.266479  |    0.142074     |   1\n",
      "      18094 |   0.174897  |    0.002942     |   0\n",
      "      18095 |   0.224871  |    0.007733     |   0\n",
      "      18096 |   0.058469  |    0.031089     |   2\n",
      "      18097 |   0.158542  |    0.032491     |   0\n",
      "      18098 |   0.043229  |    0.030057     |   2\n",
      "      18099 |   0.020710  |    0.027402     |   2\n",
      "      18100 |   0.274157  |    0.045740     |   0\n",
      "      18101 |   0.036139  |    0.013463     |   2\n",
      "      18102 |   0.180087  |    0.035410     |   0\n",
      "      18103 |   0.033573  |    0.023820     |   2\n",
      "      18104 |   0.000032  |    0.026735     |   2\n",
      "      18105 |   0.197800  |    0.034688     |   0\n",
      "      18106 |   0.228504  |    0.129740     |   1\n",
      "      18107 |   0.199101  |    0.004794     |   0\n",
      "      18108 |   0.124610  |    0.103988     |   1\n",
      "      18109 |   0.174508  |    0.011199     |   0\n",
      "      18110 |   0.000032  |    0.053176     |   2\n",
      "      18111 |   0.210287  |    0.080928     |   1\n",
      "      18112 |   0.224034  |    0.009089     |   0\n",
      "      18113 |   0.172382  |    0.058009     |   0\n",
      "      18114 |   0.205381  |    0.154559     |   1\n",
      "      18115 |   0.194086  |    0.040951     |   1\n",
      "      18116 |   0.323420  |    0.117549     |   1\n",
      "      18117 |   0.228513  |    0.060153     |   1\n",
      "      18118 |   0.247102  |    0.032021     |   0\n",
      "      18119 |   0.193468  |    0.149164     |   1\n",
      "      18120 |   0.000032  |    0.002885     |   2\n",
      "      18121 |   0.000032  |    0.008049     |   2\n",
      "      18122 |   0.302296  |    0.046267     |   0\n",
      "      18123 |   0.000032  |    0.005346     |   2\n",
      "      18124 |   0.000032  |    0.049077     |   2\n",
      "      18125 |   0.320625  |    0.098548     |   1\n",
      "      18126 |   0.048700  |    0.009081     |   2\n",
      "      18127 |   0.164008  |    0.047992     |   0\n",
      "      18128 |   0.227452  |    0.097872     |   1\n",
      "      18129 |   0.183293  |    0.020872     |   0\n",
      "      18130 |   0.255494  |    0.153035     |   1\n",
      "      18131 |   0.218762  |    0.041959     |   1\n",
      "      18132 |   0.196196  |    0.049393     |   0\n",
      "      18133 |   0.212862  |    0.089223     |   1\n",
      "      18134 |   0.195335  |    0.089935     |   1\n",
      "      18135 |   0.195326  |    0.051395     |   0\n",
      "      18136 |   0.187230  |    0.011758     |   0\n",
      "      18137 |   0.207242  |    0.047695     |   0\n",
      "      18138 |   0.157590  |    0.138305     |   1\n",
      "      18139 |   0.047846  |    0.004155     |   2\n",
      "      18140 |   0.145478  |    0.008638     |   0\n",
      "      18141 |   0.183997  |    0.034558     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 18142: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      18142 |   0.208556  |    0.010466     |   0\n",
      "      18143 |   0.162804  |    0.046811     |   0\n",
      "      18144 |   0.256307  |    0.009751     |   0\n",
      "      18145 |   0.216929  |    0.030568     |   0\n",
      "      18146 |   0.051373  |    0.036002     |   2\n",
      "      18147 |   0.041114  |    0.018707     |   2\n",
      "      18148 |   0.291126  |    0.138718     |   1\n",
      "      18149 |   0.133934  |    0.003163     |   0\n",
      "      18150 |   0.041052  |    0.005184     |   2\n",
      "      18151 |   0.178306  |    0.048372     |   0\n",
      "      18152 |   0.049772  |    0.008824     |   2\n",
      "      18153 |   0.223735  |    0.045923     |   0\n",
      "      18154 |   0.030148  |    0.017323     |   2\n",
      "      18155 |   0.269804  |    0.144587     |   1\n",
      "      18156 |   0.040935  |    0.002911     |   2\n",
      "      18157 |   0.159492  |    0.006465     |   0\n",
      "      18158 |   0.219118  |    0.035003     |   0\n",
      "      18159 |   0.251754  |    0.100070     |   1\n",
      "      18160 |   0.159277  |    0.134222     |   1\n",
      "      18161 |   0.051378  |    0.009453     |   2\n",
      "      18162 |   0.057021  |    0.014494     |   2\n",
      "      18163 |   0.214854  |    0.135675     |   1\n",
      "      18164 |   0.047491  |    0.008906     |   2\n",
      "      18165 |   0.024661  |    0.009801     |   2\n",
      "      18166 |   0.223829  |    0.032379     |   0\n",
      "      18167 |   0.189420  |    0.108019     |   1\n",
      "      18168 |   0.174004  |    0.071670     |   1\n",
      "      18169 |   0.214463  |    0.010570     |   0\n",
      "      18170 |   0.000032  |    0.051303     |   2\n",
      "      18171 |   0.268072  |    0.083053     |   1\n",
      "      18172 |   0.005840  |    0.011971     |   2\n",
      "      18173 |   0.071381  |    0.043251     |   2\n",
      "      18174 |   0.034523  |    0.017465     |   2\n",
      "      18175 |   0.238665  |    0.149156     |   1\n",
      "      18176 |   0.226659  |    0.058417     |   1\n",
      "      18177 |   0.055356  |    0.025830     |   2\n",
      "      18178 |   0.185024  |    0.047845     |   0\n",
      "      18179 |   0.043885  |    0.023010     |   2\n",
      "      18180 |   0.233030  |    0.099566     |   1\n",
      "      18181 |   0.216044  |    0.025418     |   0\n",
      "      18182 |   0.221009  |    0.137804     |   1\n",
      "      18183 |   0.018943  |    0.007103     |   2\n",
      "      18184 |   0.175007  |    0.063081     |   1\n",
      "      18185 |   0.250445  |    0.011102     |   0\n",
      "      18186 |   0.202865  |    0.145156     |   1\n",
      "      18187 |   0.240999  |    0.049605     |   1\n",
      "      18188 |   0.259678  |    0.091188     |   1\n",
      "      18189 |   0.035046  |    0.008955     |   2\n",
      "      18190 |   0.030908  |    0.045972     |   2\n",
      "      18191 |   0.264192  |    0.080273     |   1\n",
      "      18192 |   0.200049  |    0.031048     |   0\n",
      "      18193 |   0.154819  |    0.099619     |   1\n",
      "      18194 |   0.234237  |    0.029576     |   0\n",
      "      18195 |   0.000032  |    0.026903     |   2\n",
      "      18196 |   0.156088  |    0.027367     |   0\n",
      "      18197 |   0.000032  |    0.026918     |   2\n",
      "      18198 |   0.273765  |    0.037957     |   0\n",
      "      18199 |   0.241764  |    0.100402     |   1\n",
      "      18200 |   0.000032  |    0.008816     |   2\n",
      "      18201 |   0.000032  |    0.040124     |   2\n",
      "      18202 |   0.000032  |    0.015156     |   2\n",
      "      18203 |   0.000032  |    0.045474     |   2\n",
      "      18204 |   0.202236  |    0.016390     |   0\n",
      "      18205 |   0.052464  |    0.035452     |   2\n",
      "      18206 |   0.294941  |    0.127588     |   1\n",
      "      18207 |   0.175467  |    0.003080     |   0\n",
      "      18208 |   0.047398  |    0.009495     |   2\n",
      "      18209 |   0.199798  |    0.138530     |   1\n",
      "      18210 |   0.186137  |    0.083269     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 18212: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      18211 |   0.223350  |    0.004043     |   0\n",
      "      18212 |   0.223837  |    0.018252     |   0\n",
      "      18213 |   0.280613  |    0.084522     |   1\n",
      "      18214 |   0.050688  |    0.017536     |   2\n",
      "      18215 |   0.193544  |    0.044863     |   0\n",
      "      18216 |   0.227105  |    0.029281     |   0\n",
      "      18217 |   0.036964  |    0.031203     |   2\n",
      "      18218 |   0.230107  |    0.031671     |   0\n",
      "      18219 |   0.164641  |    0.151807     |   1\n",
      "      18220 |   0.228196  |    0.029440     |   0\n",
      "      18221 |   0.218085  |    0.105859     |   1\n",
      "      18222 |   0.203383  |    0.010784     |   0\n",
      "      18223 |   0.229515  |    0.084987     |   1\n",
      "      18224 |   0.041605  |    0.003873     |   2\n",
      "      18225 |   0.245510  |    0.057271     |   0\n",
      "      18226 |   0.150744  |    0.098970     |   1\n",
      "      18227 |   0.046422  |    0.014859     |   2\n",
      "      18228 |   0.241471  |    0.153175     |   1\n",
      "      18229 |   0.229385  |    0.076497     |   1\n",
      "      18230 |   0.029100  |    0.006989     |   2\n",
      "      18231 |   0.167740  |    0.034105     |   0\n",
      "      18232 |   0.184112  |    0.028104     |   0\n",
      "      18233 |   0.198336  |    0.031532     |   0\n",
      "      18234 |   0.262780  |    0.140855     |   1\n",
      "      18235 |   0.039430  |    0.009195     |   2\n",
      "      18236 |   0.220736  |    0.014892     |   0\n",
      "      18237 |   0.053213  |    0.030006     |   2\n",
      "      18238 |   0.153347  |    0.162934     |   1\n",
      "      18239 |   0.241070  |    0.027302     |   1\n",
      "      18240 |   0.287664  |    0.156343     |   1\n",
      "      18241 |   0.242150  |    0.035192     |   1\n",
      "      18242 |   0.058715  |    0.028436     |   2\n",
      "      18243 |   0.137994  |    0.029607     |   0\n",
      "      18244 |   0.047639  |    0.032406     |   2\n",
      "      18245 |   0.200652  |    0.146716     |   1\n",
      "      18246 |   0.140515  |    0.008392     |   0\n",
      "      18247 |   0.213316  |    0.087323     |   1\n",
      "      18248 |   0.258510  |    0.004858     |   0\n",
      "      18249 |   0.189170  |    0.026873     |   0\n",
      "      18250 |   0.024514  |    0.035614     |   2\n",
      "      18251 | \u001b[94m  0.000032\u001b[0m  |    0.030094     |   2\n",
      "      18252 |   0.211410  |    0.154636     |   1\n",
      "      18253 |   0.181390  |    0.082643     |   1\n",
      "      18254 |   0.228559  |    0.082914     |   1\n",
      "      18255 |   0.005609  |    0.024993     |   2\n",
      "      18256 |   0.193795  |    0.103970     |   1\n",
      "      18257 |   0.173398  |    0.133472     |   1\n",
      "      18258 |   0.226174  |    0.054593     |   1\n",
      "      18259 |   0.069284  |    0.015417     |   2\n",
      "      18260 |   0.208639  |    0.159865     |   1\n",
      "      18261 |   0.214750  |    0.052260     |   1\n",
      "      18262 |   0.034311  |    0.020584     |   2\n",
      "      18263 |   0.057251  |    0.030911     |   2\n",
      "      18264 |   0.236634  |    0.082942     |   1\n",
      "      18265 |   0.182113  |    0.015188     |   0\n",
      "      18266 |   0.199913  |    0.029736     |   0\n",
      "      18267 |   0.043631  |    0.027630     |   2\n",
      "      18268 |   0.019073  |    0.026944     |   2\n",
      "      18269 |   0.239923  |    0.053307     |   0\n",
      "      18270 |   0.035958  |    0.006147     |   2\n",
      "      18271 |   0.196261  |    0.042569     |   0\n",
      "      18272 |   0.029479  |    0.021325     |   2\n",
      "      18273 | \u001b[94m  0.000031\u001b[0m  |    0.046030     |   2\n",
      "      18274 | \u001b[94m  0.000031\u001b[0m  |    0.009945     |   2\n",
      "      18275 |   0.190021  |    0.151375     |   1\n",
      "      18276 |   0.178984  |    0.004177     |   0\n",
      "      18277 | \u001b[94m  0.000031\u001b[0m  |    0.009190     |   2\n",
      "      18278 |   0.243356  |    0.146099     |   1\n",
      "      18279 |   0.247470  |    0.093052     |   1\n",
      "      18280 |   0.214115  |    0.077722     |   1\n",
      "      18281 |   0.000032  |    0.003758     |   2\n",
      "      18282 |   0.247575  |    0.052435     |   0\n",
      "      18283 |   0.238955  |    0.108401     |   1\n",
      "      18284 |   0.174957  |    0.055434     |   1\n",
      "      18285 |   0.237153  |    0.010922     |   0\n",
      "      18286 |   0.000032  |    0.033334     |   2\n",
      "      18287 |   0.000031  |    0.012811     |   2\n",
      "      18288 |   0.203565  |    0.141008     |   1\n",
      "      18289 |   0.173707  |    0.084949     |   1\n",
      "      18290 |   0.049153  |    0.021673     |   2\n",
      "      18291 |   0.217128  |    0.106378     |   1\n",
      "      18292 |   0.046720  |    0.008660     |   2\n",
      "      18293 |   0.158974  |    0.056793     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 18294: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      18294 |   0.221335  |    0.086648     |   1\n",
      "      18295 |   0.232933  |    0.080499     |   1\n",
      "      18296 |   0.186061  |    0.013123     |   0\n",
      "      18297 |   0.151480  |    0.067539     |   0\n",
      "      18298 |   0.209220  |    0.071000     |   1\n",
      "      18299 |   0.292702  |    0.097848     |   1\n",
      "      18300 |   0.048659  |    0.005884     |   2\n",
      "      18301 |   0.183338  |    0.057135     |   0\n",
      "      18302 |   0.182470  |    0.086026     |   1\n",
      "      18303 |   0.222569  |    0.010254     |   0\n",
      "      18304 |   0.163763  |    0.145813     |   1\n",
      "      18305 |   0.035525  |    0.004748     |   2\n",
      "      18306 |   0.187559  |    0.018993     |   0\n",
      "      18307 |   0.040944  |    0.030975     |   2\n",
      "      18308 |   0.238865  |    0.024291     |   0\n",
      "      18309 |   0.218158  |    0.044277     |   0\n",
      "      18310 |   0.205020  |    0.080078     |   1\n",
      "      18311 |   0.177229  |    0.033980     |   0\n",
      "      18312 |   0.194571  |    0.153613     |   1\n",
      "      18313 |   0.265362  |    0.089627     |   1\n",
      "      18314 |   0.044887  |    0.005476     |   2\n",
      "      18315 |   0.029726  |    0.022562     |   2\n",
      "      18316 |   0.209942  |    0.137841     |   1\n",
      "      18317 |   0.039452  |    0.010205     |   2\n",
      "      18318 |   0.164336  |    0.028833     |   0\n",
      "      18319 |   0.050223  |    0.046285     |   2\n",
      "      18320 |   0.059170  |    0.017476     |   2\n",
      "      18321 |   0.185075  |    0.104844     |   1\n",
      "      18322 |   0.217304  |    0.008283     |   0\n",
      "      18323 |   0.221416  |    0.143102     |   1\n",
      "      18324 |   0.147775  |    0.005437     |   0\n",
      "      18325 |   0.178894  |    0.025779     |   0\n",
      "      18326 |   0.046963  |    0.046787     |   2\n",
      "      18327 |   0.025312  |    0.014073     |   2\n",
      "      18328 |   0.146553  |    0.131996     |   1\n",
      "      18329 |   0.216159  |    0.012900     |   0\n",
      "      18330 |   0.207557  |    0.030185     |   0\n",
      "      18331 |   0.220112  |    0.081336     |   1\n",
      "      18332 |   0.177297  |    0.159767     |   1\n",
      "      18333 | \u001b[94m  0.000031\u001b[0m  |    0.004785     |   2\n",
      "      18334 |   0.204772  |    0.028748     |   0\n",
      "      18335 |   0.221072  |    0.100591     |   1\n",
      "      18336 |   0.006347  |    0.016403     |   2\n",
      "      18337 |   0.229294  |    0.102803     |   1\n",
      "      18338 |   0.251825  |    0.005574     |   0\n",
      "      18339 |   0.070071  |    0.042783     |   2\n",
      "      18340 |   0.192902  |    0.029723     |   0\n",
      "      18341 |   0.036257  |    0.023156     |   2\n",
      "      18342 |   0.207468  |    0.047376     |   0\n",
      "      18343 |   0.125090  |    0.100598     |   1\n",
      "      18344 |   0.160691  |    0.093723     |   1\n",
      "      18345 |   0.169470  |    0.102165     |   1\n",
      "      18346 |   0.243309  |    0.078541     |   1\n",
      "      18347 |   0.061320  |    0.033858     |   2\n",
      "      18348 |   0.048746  |    0.033018     |   2\n",
      "      18349 |   0.190855  |    0.032959     |   0\n",
      "      18350 |   0.165938  |    0.136092     |   1\n",
      "      18351 |   0.185630  |    0.021903     |   0\n",
      "      18352 |   0.020783  |    0.028203     |   2\n",
      "      18353 |   0.041193  |    0.020655     |   2\n",
      "      18354 |   0.164629  |    0.041849     |   0\n",
      "      18355 |   0.028858  |    0.024785     |   2\n",
      "      18356 |   0.239059  |    0.133934     |   1\n",
      "      18357 |   0.212028  |    0.004078     |   0\n",
      "      18358 |   0.190153  |    0.038167     |   0\n",
      "      18359 |   0.325518  |    0.089879     |   1\n",
      "      18360 |   0.000031  |    0.005967     |   2\n",
      "      18361 |   0.000031  |    0.038894     |   2\n",
      "      18362 |   0.149414  |    0.024387     |   0\n",
      "      18363 |   0.229058  |    0.024626     |   0\n",
      "      18364 |   0.000031  |    0.027662     |   2\n",
      "      18365 |   0.235920  |    0.027823     |   0\n",
      "      18366 |   0.254236  |    0.084412     |   1\n",
      "      18367 |   0.160198  |    0.018113     |   0\n",
      "      18368 |   0.000032  |    0.049373     |   2\n",
      "      18369 |   0.168162  |    0.081493     |   1\n",
      "      18370 |   0.230346  |    0.087972     |   1\n",
      "      18371 |   0.215695  |    0.032524     |   0\n",
      "      18372 |   0.161624  |    0.134857     |   1\n",
      "      18373 |   0.000031  |    0.004843     |   2\n",
      "      18374 |   0.000031  |    0.012204     |   2\n",
      "      18375 |   0.189473  |    0.167728     |   1\n",
      "      18376 |   0.191238  |    0.032613     |   1\n",
      "      18377 |   0.171730  |    0.033759     |   0\n",
      "      18378 |   0.048746  |    0.017861     |   2\n",
      "      18379 |   0.263359  |    0.044599     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 18381: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      18380 |   0.046695  |    0.010318     |   2\n",
      "      18381 |   0.185403  |    0.031980     |   0\n",
      "      18382 |   0.220634  |    0.141344     |   1\n",
      "      18383 |   0.234507  |    0.093694     |   1\n",
      "      18384 |   0.177001  |    0.015289     |   0\n",
      "      18385 |   0.256336  |    0.026033     |   0\n",
      "      18386 |   0.050144  |    0.026619     |   2\n",
      "      18387 |   0.196226  |    0.025514     |   0\n",
      "      18388 |   0.246131  |    0.046709     |   0\n",
      "      18389 |   0.036353  |    0.014587     |   2\n",
      "      18390 |   0.180201  |    0.041328     |   0\n",
      "      18391 |   0.041410  |    0.025259     |   2\n",
      "      18392 |   0.208644  |    0.141620     |   1\n",
      "      18393 |   0.046764  |    0.003087     |   2\n",
      "      18394 |   0.029985  |    0.007733     |   2\n",
      "      18395 |   0.175166  |    0.028131     |   0\n",
      "      18396 |   0.225975  |    0.038068     |   0\n",
      "      18397 |   0.040794  |    0.025653     |   2\n",
      "      18398 |   0.054770  |    0.044557     |   2\n",
      "      18399 |   0.243354  |    0.014924     |   0\n",
      "      18400 |   0.212795  |    0.099339     |   1\n",
      "      18401 |   0.141631  |    0.013438     |   0\n",
      "      18402 |   0.162680  |    0.162987     |   1\n",
      "      18403 |   0.153825  |    0.063702     |   1\n",
      "      18404 |   0.058532  |    0.026994     |   2\n",
      "      18405 |   0.049660  |    0.014062     |   2\n",
      "      18406 |   0.199966  |    0.037151     |   0\n",
      "      18407 |   0.227643  |    0.145807     |   1\n",
      "      18408 |   0.025894  |    0.024268     |   2\n",
      "      18409 |   0.253648  |    0.045424     |   1\n",
      "      18410 |   0.000031  |    0.026066     |   2\n",
      "      18411 |   0.005818  |    0.032801     |   2\n",
      "      18412 |   0.212703  |    0.024514     |   0\n",
      "      18413 |   0.220898  |    0.049657     |   0\n",
      "      18414 |   0.163389  |    0.012284     |   0\n",
      "      18415 |   0.067683  |    0.042896     |   2\n",
      "      18416 |   0.154189  |    0.089541     |   1\n",
      "      18417 |   0.169936  |    0.130781     |   1\n",
      "      18418 |   0.216559  |    0.070511     |   1\n",
      "      18419 |   0.222877  |    0.140311     |   1\n",
      "      18420 |   0.220753  |    0.005002     |   0\n",
      "      18421 |   0.218328  |    0.033201     |   0\n",
      "      18422 |   0.225942  |    0.144455     |   1\n",
      "      18423 |   0.171967  |    0.048628     |   1\n",
      "      18424 |   0.033930  |    0.030202     |   2\n",
      "      18425 |   0.246889  |    0.150327     |   1\n",
      "      18426 |   0.169413  |    0.098005     |   1\n",
      "      18427 |   0.206694  |    0.089321     |   1\n",
      "      18428 |   0.175509  |    0.013350     |   0\n",
      "      18429 |   0.177634  |    0.034360     |   0\n",
      "      18430 |   0.057074  |    0.044079     |   2\n",
      "      18431 |   0.198277  |    0.156842     |   1\n",
      "      18432 |   0.210710  |    0.053373     |   1\n",
      "      18433 |   0.162529  |    0.027346     |   0\n",
      "      18434 |   0.044875  |    0.051606     |   2\n",
      "      18435 |   0.019490  |    0.013140     |   2\n",
      "      18436 |   0.183610  |    0.133912     |   1\n",
      "      18437 |   0.206541  |    0.016453     |   0\n",
      "      18438 |   0.243642  |    0.037536     |   0\n",
      "      18439 |   0.037093  |    0.008576     |   2\n",
      "      18440 |   0.032237  |    0.055644     |   2\n",
      "      18441 |   0.145170  |    0.092878     |   1\n",
      "      18442 |   0.000031  |    0.008502     |   2\n",
      "      18443 |   0.000031  |    0.041357     |   2\n",
      "      18444 |   0.207849  |    0.048503     |   0\n",
      "      18445 |   0.000031  |    0.018503     |   2\n",
      "      18446 |   0.155105  |    0.149655     |   1\n",
      "      18447 |   0.226855  |    0.099390     |   1\n",
      "      18448 |   0.232097  |    0.094613     |   1\n",
      "      18449 |   0.000032  |    0.005083     |   2\n",
      "      18450 |   0.274728  |    0.043962     |   0\n",
      "      18451 |   0.000031  |    0.005651     |   2\n",
      "      18452 |   0.246250  |    0.043277     |   0\n",
      "      18453 |   0.187755  |    0.029250     |   0\n",
      "      18454 |   0.198072  |    0.037577     |   0\n",
      "      18455 |   0.278024  |    0.136862     |   1\n",
      "      18456 |   0.192064  |    0.068936     |   1\n",
      "      18457 |   0.202236  |    0.013796     |   0\n",
      "      18458 |   0.222753  |    0.125759     |   1\n",
      "      18459 |   0.222425  |    0.010362     |   0\n",
      "      18460 |   0.150629  |    0.136678     |   1\n",
      "      18461 |   0.192236  |    0.020908     |   0\n",
      "      18462 |   0.000031  |    0.042213     |   2\n",
      "      18463 |   0.257157  |    0.012785     |   0\n",
      "      18464 |   0.212718  |    0.044853     |   0\n",
      "      18465 |   0.171837  |    0.017484     |   0\n",
      "      18466 |   0.231001  |    0.149749     |   1\n",
      "      18467 |   0.055590  |    0.004384     |   2\n",
      "      18468 |   0.046225  |    0.003733     |   2\n",
      "      18469 |   0.208605  |    0.046810     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 18470: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      18470 |   0.159691  |    0.013739     |   0\n",
      "      18471 |   0.052065  |    0.036439     |   2\n",
      "      18472 |   0.251260  |    0.142091     |   1\n",
      "      18473 |   0.186379  |    0.006543     |   0\n",
      "      18474 |   0.203541  |    0.093016     |   1\n",
      "      18475 |   0.173869  |    0.030731     |   0\n",
      "      18476 |   0.177830  |    0.084714     |   1\n",
      "      18477 |   0.037225  |    0.030343     |   2\n",
      "      18478 |   0.125256  |    0.011370     |   0\n",
      "      18479 |   0.156219  |    0.015866     |   0\n",
      "      18480 |   0.041463  |    0.042650     |   2\n",
      "      18481 |   0.048292  |    0.025122     |   2\n",
      "      18482 |   0.172428  |    0.088201     |   1\n",
      "      18483 |   0.231494  |    0.054572     |   0\n",
      "      18484 |   0.030368  |    0.006704     |   2\n",
      "      18485 |   0.041879  |    0.045842     |   2\n",
      "      18486 |   0.054171  |    0.014169     |   2\n",
      "      18487 |   0.217934  |    0.159722     |   1\n",
      "      18488 |   0.054355  |    0.007996     |   2\n",
      "      18489 |   0.242989  |    0.054633     |   1\n",
      "      18490 |   0.048645  |    0.007287     |   2\n",
      "      18491 |   0.223433  |    0.058816     |   0\n",
      "      18492 |   0.194464  |    0.081611     |   1\n",
      "      18493 |   0.024119  |    0.011311     |   2\n",
      "      18494 |   0.163250  |    0.142467     |   1\n",
      "      18495 |   0.222079  |    0.057735     |   1\n",
      "      18496 |   0.195662  |    0.033292     |   0\n",
      "      18497 |   0.154758  |    0.160512     |   1\n",
      "      18498 | \u001b[94m  0.000030\u001b[0m  |    0.006413     |   2\n",
      "      18499 |   0.136766  |    0.007780     |   0\n",
      "      18500 |   0.209901  |    0.024573     |   0\n",
      "      18501 |   0.203172  |    0.186621     |   1\n",
      "      18502 |   0.205842  |    0.016158     |   1\n",
      "      18503 |   0.209852  |    0.049945     |   0\n",
      "      18504 |   0.049354  |    0.006981     |   2\n",
      "      18505 |   0.035962  |    0.047888     |   2\n",
      "      18506 |   0.040198  |    0.046770     |   2\n",
      "      18507 |   0.234587  |    0.024873     |   0\n",
      "      18508 |   0.239067  |    0.141517     |   1\n",
      "      18509 |   0.045742  |    0.007650     |   2\n",
      "      18510 |   0.199399  |    0.010440     |   0\n",
      "      18511 |   0.227920  |    0.046545     |   0\n",
      "      18512 |   0.029195  |    0.010263     |   2\n",
      "      18513 |   0.040763  |    0.038372     |   2\n",
      "      18514 |   0.047690  |    0.027104     |   2\n",
      "      18515 |   0.246945  |    0.048808     |   0\n",
      "      18516 |   0.056336  |    0.016047     |   2\n",
      "      18517 |   0.189726  |    0.151147     |   1\n",
      "      18518 |   0.210710  |    0.086343     |   1\n",
      "      18519 |   0.173625  |    0.133453     |   1\n",
      "      18520 |   0.221830  |    0.005840     |   0\n",
      "      18521 |   0.045583  |    0.012100     |   2\n",
      "      18522 |   0.217758  |    0.146298     |   1\n",
      "      18523 |   0.235241  |    0.048774     |   1\n",
      "      18524 |   0.024927  |    0.009250     |   2\n",
      "      18525 |   0.144229  |    0.040460     |   0\n",
      "      18526 |   0.000031  |    0.009967     |   2\n",
      "      18527 |   0.165751  |    0.043946     |   0\n",
      "      18528 |   0.230435  |    0.091259     |   1\n",
      "      18529 |   0.005426  |    0.008756     |   2\n",
      "      18530 |   0.069334  |    0.041840     |   2\n",
      "      18531 |   0.036309  |    0.015211     |   2\n",
      "      18532 |   0.203853  |    0.029613     |   0\n",
      "      18533 |   0.171321  |    0.023951     |   0\n",
      "      18534 |   0.162491  |    0.046215     |   0\n",
      "      18535 |   0.057676  |    0.013116     |   2\n",
      "      18536 |   0.186568  |    0.045277     |   0\n",
      "      18537 |   0.229687  |    0.013586     |   0\n",
      "      18538 |   0.173745  |    0.037557     |   0\n",
      "      18539 |   0.043687  |    0.026527     |   2\n",
      "      18540 |   0.207838  |    0.163510     |   1\n",
      "      18541 |   0.159420  |    0.058630     |   1\n",
      "      18542 |   0.019667  |    0.006286     |   2\n",
      "      18543 |   0.236768  |    0.154099     |   1\n",
      "      18544 |   0.040179  |    0.006723     |   2\n",
      "      18545 |   0.257691  |    0.084072     |   1\n",
      "      18546 |   0.030503  |    0.014429     |   2\n",
      "      18547 |   0.228247  |    0.145995     |   1\n",
      "      18548 |   0.259980  |    0.037377     |   1\n",
      "      18549 |   0.174003  |    0.042731     |   0\n",
      "      18550 |   0.183300  |    0.027552     |   0\n",
      "      18551 |   0.000031  |    0.023650     |   2\n",
      "      18552 |   0.209635  |    0.044951     |   0\n",
      "      18553 |   0.000031  |    0.022548     |   2\n",
      "      18554 |   0.213039  |    0.101360     |   1\n",
      "      18555 |   0.211287  |    0.024572     |   0\n",
      "      18556 |   0.000031  |    0.043917     |   2\n",
      "      18557 |   0.213368  |    0.007061     |   0\n",
      "      18558 |   0.206044  |    0.133234     |   1\n",
      "      18559 |   0.209258  |    0.019087     |   0\n",
      "      18560 |   0.285954  |    0.140980     |   1\n",
      "      18561 |   0.000031  |    0.004108     |   2\n",
      "      18562 |   0.192553  |    0.063695     |   1\n",
      "      18563 |   0.196975  |    0.024698     |   0\n",
      "      18564 |   0.170203  |    0.141791     |   1\n",
      "      18565 |   0.188045  |    0.010827     |   0\n",
      "      18566 |   0.293262  |    0.093132     |   1\n",
      "      18567 |   0.236312  |    0.056051     |   1\n",
      "      18568 |   0.186418  |    0.097856     |   1\n",
      "      18569 |   0.262801  |    0.024354     |   0\n",
      "      18570 |   0.000031  |    0.026000     |   2\n",
      "      18571 |   0.201447  |    0.051208     |   0\n",
      "      18572 |   0.256236  |    0.087353     |   1\n",
      "      18573 |   0.277280  |    0.026584     |   0\n",
      "      18574 |   0.164835  |    0.038241     |   0\n",
      "      18575 |   0.000031  |    0.014688     |   2\n",
      "      18576 |   0.265130  |    0.150184     |   1\n",
      "      18577 |   0.057198  |    0.004108     |   2\n",
      "      18578 |   0.175154  |    0.009861     |   0\n",
      "      18579 |   0.152893  |    0.051081     |   0\n",
      "      18580 |   0.170799  |    0.091424     |   1\n",
      "      18581 |   0.047320  |    0.028639     |   2\n",
      "      18582 |   0.167104  |    0.190981     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 18583: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      18583 |   0.052601  |    0.048202     |   2\n",
      "      18584 |   0.265212  |    0.193545     |   1\n",
      "      18585 |   0.199840  |    0.047405     |   0\n",
      "      18586 |   0.218955  |    0.041833     |   0\n",
      "      18587 |   0.035560  |    0.040315     |   2\n",
      "      18588 |   0.119413  |    0.038014     |   0\n",
      "      18589 |   0.177059  |    0.080272     |   0\n",
      "      18590 |   0.197429  |    0.143158     |   1\n",
      "      18591 |   0.040200  |    0.041422     |   2\n",
      "      18592 |   0.222655  |    0.074133     |   0\n",
      "      18593 |   0.047568  |    0.025859     |   2\n",
      "      18594 |   0.190786  |    0.071270     |   0\n",
      "      18595 |   0.029535  |    0.028110     |   2\n",
      "      18596 |   0.164171  |    0.170455     |   1\n",
      "      18597 |   0.203450  |    0.110158     |   1\n",
      "      18598 |   0.238493  |    0.054369     |   1\n",
      "      18599 |   0.221828  |    0.012828     |   0\n",
      "      18600 |   0.041697  |    0.025354     |   2\n",
      "      18601 |   0.161375  |    0.029590     |   0\n",
      "      18602 |   0.123246  |    0.161768     |   1\n",
      "      18603 |   0.185959  |    0.013665     |   0\n",
      "      18604 |   0.141639  |    0.006339     |   0\n",
      "      18605 |   0.215295  |    0.031673     |   0\n",
      "      18606 |   0.051878  |    0.008946     |   2\n",
      "      18607 |   0.061066  |    0.053176     |   2\n",
      "      18608 |   0.245946  |    0.095682     |   1\n",
      "      18609 |   0.047428  |    0.004932     |   2\n",
      "      18610 |   0.218580  |    0.036873     |   0\n",
      "      18611 |   0.023567  |    0.026444     |   2\n",
      "      18612 | \u001b[94m  0.000030\u001b[0m  |    0.021883     |   2\n",
      "      18613 |   0.221376  |    0.026430     |   0\n",
      "      18614 |   0.005878  |    0.021786     |   2\n",
      "      18615 |   0.133720  |    0.152807     |   1\n",
      "      18616 |   0.194745  |    0.084154     |   1\n",
      "      18617 |   0.266482  |    0.089366     |   1\n",
      "      18618 |   0.231170  |    0.078251     |   1\n",
      "      18619 |   0.066300  |    0.014611     |   2\n",
      "      18620 |   0.038115  |    0.037298     |   2\n",
      "      18621 |   0.059333  |    0.018876     |   2\n",
      "      18622 |   0.196856  |    0.041199     |   0\n",
      "      18623 |   0.188340  |    0.041748     |   0\n",
      "      18624 |   0.175639  |    0.087854     |   1\n",
      "      18625 |   0.049324  |    0.031066     |   2\n",
      "      18626 |   0.268330  |    0.139243     |   1\n",
      "      18627 |   0.018565  |    0.009100     |   2\n",
      "      18628 |   0.194379  |    0.019285     |   0\n",
      "      18629 |   0.201939  |    0.052544     |   0\n",
      "      18630 |   0.215347  |    0.081946     |   1\n",
      "      18631 |   0.212539  |    0.011629     |   0\n",
      "      18632 |   0.035891  |    0.039778     |   2\n",
      "      18633 |   0.034120  |    0.012492     |   2\n",
      "      18634 |   0.241591  |    0.154139     |   1\n",
      "      18635 |   0.238037  |    0.002970     |   0\n",
      "      18636 |   0.000031  |    0.008972     |   2\n",
      "      18637 |   0.000031  |    0.042522     |   2\n",
      "      18638 |   0.000031  |    0.006772     |   2\n",
      "      18639 |   0.000031  |    0.035205     |   2\n",
      "      18640 |   0.000031  |    0.014592     |   2\n",
      "      18641 |   0.000031  |    0.055060     |   2\n",
      "      18642 |   0.242596  |    0.071096     |   1\n",
      "      18643 |   0.199935  |    0.136775     |   1\n",
      "      18644 |   0.187921  |    0.003201     |   0\n",
      "      18645 |   0.209012  |    0.013231     |   0\n",
      "      18646 |   0.217186  |    0.033064     |   0\n",
      "      18647 |   0.214225  |    0.011940     |   0\n",
      "      18648 |   0.213045  |    0.066421     |   0\n",
      "      18649 |   0.158105  |    0.100454     |   1\n",
      "      18650 |   0.228988  |    0.058137     |   1\n",
      "      18651 |   0.276861  |    0.101637     |   1\n",
      "      18652 |   0.226968  |    0.052549     |   1\n",
      "      18653 |   0.297460  |    0.105976     |   1\n",
      "      18654 |   0.048014  |    0.006057     |   2\n",
      "      18655 |   0.171432  |    0.089173     |   1\n",
      "      18656 |   0.151288  |    0.009230     |   0\n",
      "      18657 |   0.200954  |    0.050536     |   0\n",
      "      18658 |   0.125950  |    0.140829     |   1\n",
      "      18659 |   0.048768  |    0.003978     |   2\n",
      "      18660 |   0.207035  |    0.102609     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 18661: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      18661 |   0.207618  |    0.098670     |   1\n",
      "      18662 |   0.189252  |    0.083659     |   1\n",
      "      18663 |   0.186594  |    0.020237     |   0\n",
      "      18664 |   0.211508  |    0.142987     |   1\n",
      "      18665 |   0.178320  |    0.100571     |   1\n",
      "      18666 |   0.189081  |    0.037981     |   1\n",
      "      18667 |   0.224337  |    0.034283     |   0\n",
      "      18668 |   0.271261  |    0.095460     |   1\n",
      "      18669 |   0.250923  |    0.017203     |   0\n",
      "      18670 |   0.199989  |    0.136132     |   1\n",
      "      18671 |   0.046922  |    0.011231     |   2\n",
      "      18672 |   0.035944  |    0.045821     |   2\n",
      "      18673 |   0.189304  |    0.140635     |   1\n",
      "      18674 |   0.041036  |    0.002831     |   2\n",
      "      18675 |   0.204637  |    0.009989     |   0\n",
      "      18676 |   0.216321  |    0.143217     |   1\n",
      "      18677 |   0.249212  |    0.077837     |   1\n",
      "      18678 |   0.214458  |    0.101372     |   1\n",
      "      18679 |   0.223881  |    0.092219     |   1\n",
      "      18680 |   0.175784  |    0.008435     |   0\n",
      "      18681 |   0.045502  |    0.055509     |   2\n",
      "      18682 |   0.162617  |    0.095655     |   1\n",
      "      18683 |   0.184505  |    0.090282     |   1\n",
      "      18684 |   0.028830  |    0.017744     |   2\n",
      "      18685 |   0.161686  |    0.031860     |   0\n",
      "      18686 |   0.041065  |    0.014770     |   2\n",
      "      18687 |   0.215508  |    0.043045     |   0\n",
      "      18688 |   0.050462  |    0.009447     |   2\n",
      "      18689 |   0.155879  |    0.042009     |   0\n",
      "      18690 |   0.217448  |    0.022615     |   0\n",
      "      18691 |   0.192943  |    0.027234     |   0\n",
      "      18692 |   0.171278  |    0.027773     |   0\n",
      "      18693 |   0.181640  |    0.033914     |   0\n",
      "      18694 |   0.056987  |    0.020708     |   2\n",
      "      18695 |   0.047849  |    0.024552     |   2\n",
      "      18696 |   0.196471  |    0.038700     |   0\n",
      "      18697 |   0.209571  |    0.150172     |   1\n",
      "      18698 |   0.025715  |    0.007656     |   2\n",
      "      18699 |   0.215808  |    0.091117     |   1\n",
      "      18700 |   0.203406  |    0.092190     |   1\n",
      "      18701 |   0.233298  |    0.092130     |   1\n",
      "      18702 | \u001b[94m  0.000030\u001b[0m  |    0.005701     |   2\n",
      "      18703 |   0.186619  |    0.137349     |   1\n",
      "      18704 |   0.231618  |    0.139630     |   1\n",
      "      18705 |   0.005898  |    0.010965     |   2\n",
      "      18706 |   0.199790  |    0.024415     |   0\n",
      "      18707 |   0.073111  |    0.009851     |   2\n",
      "      18708 |   0.212982  |    0.040843     |   0\n",
      "      18709 |   0.036578  |    0.016005     |   2\n",
      "      18710 |   0.259664  |    0.143452     |   1\n",
      "      18711 |   0.226966  |    0.035588     |   1\n",
      "      18712 |   0.057380  |    0.028655     |   2\n",
      "      18713 |   0.208883  |    0.052238     |   0\n",
      "      18714 |   0.170695  |    0.009654     |   0\n",
      "      18715 |   0.043253  |    0.053494     |   2\n",
      "      18716 |   0.017561  |    0.007617     |   2\n",
      "      18717 |   0.242949  |    0.040590     |   0\n",
      "      18718 |   0.193692  |    0.020342     |   0\n",
      "      18719 |   0.222340  |    0.149547     |   1\n",
      "      18720 |   0.037819  |    0.005641     |   2\n",
      "      18721 |   0.029431  |    0.008084     |   2\n",
      "      18722 |   0.190306  |    0.152102     |   1\n",
      "      18723 |   0.000030  |    0.007490     |   2\n",
      "      18724 |   0.144578  |    0.096792     |   1\n",
      "      18725 |   0.191924  |    0.103822     |   1\n",
      "      18726 |   0.000030  |    0.007626     |   2\n",
      "      18727 |   0.000030  |    0.044024     |   2\n",
      "      18728 |   0.206790  |    0.025732     |   0\n",
      "      18729 |   0.222397  |    0.124746     |   1\n",
      "      18730 |   0.209656  |    0.079980     |   1\n",
      "      18731 |   0.193429  |    0.006398     |   0\n",
      "      18732 |   0.000030  |    0.021243     |   2\n",
      "      18733 |   0.000030  |    0.045876     |   2\n",
      "      18734 |   0.000030  |    0.012896     |   2\n",
      "      18735 |   0.155262  |    0.023140     |   0\n",
      "      18736 |   0.241844  |    0.047447     |   0\n",
      "      18737 |   0.048584  |    0.005359     |   2\n",
      "      18738 |   0.182519  |    0.045890     |   0\n",
      "      18739 |   0.047737  |    0.010534     |   2\n",
      "      18740 |   0.231210  |    0.054157     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 18741: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      18741 |   0.051181  |    0.011325     |   2\n",
      "      18742 |   0.180662  |    0.143605     |   1\n",
      "      18743 |   0.169202  |    0.059462     |   1\n",
      "      18744 |   0.166431  |    0.037664     |   0\n",
      "      18745 |   0.036692  |    0.014826     |   2\n",
      "      18746 |   0.041445  |    0.042493     |   2\n",
      "      18747 |   0.200832  |    0.087238     |   1\n",
      "      18748 |   0.211949  |    0.035810     |   0\n",
      "      18749 |   0.045205  |    0.019182     |   2\n",
      "      18750 |   0.152940  |    0.028180     |   0\n",
      "      18751 |   0.028969  |    0.051109     |   2\n",
      "      18752 |   0.197036  |    0.091856     |   1\n",
      "      18753 |   0.184164  |    0.097284     |   1\n",
      "      18754 |   0.163440  |    0.008394     |   0\n",
      "      18755 |   0.044472  |    0.046683     |   2\n",
      "      18756 |   0.049476  |    0.013895     |   2\n",
      "      18757 |   0.234193  |    0.055621     |   0\n",
      "      18758 |   0.242524  |    0.084271     |   1\n",
      "      18759 |   0.261880  |    0.084280     |   1\n",
      "      18760 |   0.058724  |    0.004549     |   2\n",
      "      18761 |   0.203872  |    0.025938     |   0\n",
      "      18762 |   0.245267  |    0.160263     |   1\n",
      "      18763 |   0.204764  |    0.009802     |   0\n",
      "      18764 |   0.242748  |    0.072538     |   1\n",
      "      18765 |   0.234064  |    0.083732     |   1\n",
      "      18766 |   0.170024  |    0.006374     |   0\n",
      "      18767 |   0.049121  |    0.017696     |   2\n",
      "      18768 |   0.164138  |    0.157240     |   1\n",
      "      18769 |   0.209910  |    0.099598     |   1\n",
      "      18770 |   0.155646  |    0.094483     |   1\n",
      "      18771 |   0.208673  |    0.056537     |   1\n",
      "      18772 |   0.192413  |    0.008356     |   0\n",
      "      18773 |   0.208254  |    0.042445     |   0\n",
      "      18774 |   0.214201  |    0.025046     |   0\n",
      "      18775 |   0.025357  |    0.018497     |   2\n",
      "      18776 | \u001b[94m  0.000029\u001b[0m  |    0.022649     |   2\n",
      "      18777 |   0.203622  |    0.033761     |   0\n",
      "      18778 |   0.006408  |    0.010564     |   2\n",
      "      18779 |   0.157293  |    0.142134     |   1\n",
      "      18780 |   0.069655  |    0.011276     |   2\n",
      "      18781 |   0.039329  |    0.019458     |   2\n",
      "      18782 |   0.185868  |    0.113304     |   1\n",
      "      18783 |   0.058002  |    0.007044     |   2\n",
      "      18784 |   0.174405  |    0.025789     |   0\n",
      "      18785 |   0.206411  |    0.030586     |   0\n",
      "      18786 |   0.125956  |    0.015338     |   0\n",
      "      18787 |   0.045390  |    0.031065     |   2\n",
      "      18788 |   0.019350  |    0.028608     |   2\n",
      "      18789 |   0.252181  |    0.117415     |   1\n",
      "      18790 |   0.153024  |    0.070184     |   1\n",
      "      18791 |   0.178632  |    0.015919     |   0\n",
      "      18792 |   0.207728  |    0.046957     |   0\n",
      "      18793 |   0.198149  |    0.008840     |   0\n",
      "      18794 |   0.177116  |    0.045247     |   0\n",
      "      18795 |   0.040799  |    0.010892     |   2\n",
      "      18796 |   0.030855  |    0.043422     |   2\n",
      "      18797 |   0.227507  |    0.039311     |   0\n",
      "      18798 |   0.224948  |    0.087378     |   1\n",
      "      18799 |   0.213387  |    0.021868     |   0\n",
      "      18800 |   0.268313  |    0.133688     |   1\n",
      "      18801 |   0.000030  |    0.014302     |   2\n",
      "      18802 |   0.263649  |    0.143379     |   1\n",
      "      18803 |   0.172766  |    0.010665     |   0\n",
      "      18804 |   0.151344  |    0.110510     |   1\n",
      "      18805 |   0.182309  |    0.081309     |   1\n",
      "      18806 |   0.191193  |    0.019994     |   0\n",
      "      18807 |   0.170287  |    0.141545     |   1\n",
      "      18808 |   0.188662  |    0.002903     |   0\n",
      "      18809 |   0.000030  |    0.006767     |   2\n",
      "      18810 |   0.166191  |    0.044998     |   0\n",
      "      18811 |   0.178588  |    0.013836     |   0\n",
      "      18812 |   0.000030  |    0.047980     |   2\n",
      "      18813 |   0.225528  |    0.093460     |   1\n",
      "      18814 |   0.179978  |    0.006347     |   0\n",
      "      18815 |   0.251330  |    0.095859     |   1\n",
      "      18816 |   0.172634  |    0.095422     |   1\n",
      "      18817 |   0.186273  |    0.004511     |   0\n",
      "      18818 |   0.241905  |    0.047520     |   0\n",
      "      18819 |   0.201937  |    0.096507     |   1\n",
      "      18820 |   0.212895  |    0.083577     |   1\n",
      "      18821 |   0.000030  |    0.009232     |   2\n",
      "      18822 |   0.208864  |    0.100632     |   1\n",
      "      18823 |   0.233562  |    0.141071     |   1\n",
      "      18824 |   0.188361  |    0.007757     |   0\n",
      "      18825 |   0.186025  |    0.014055     |   0\n",
      "      18826 |   0.000030  |    0.058737     |   2\n",
      "      18827 |   0.138597  |    0.078211     |   1\n",
      "      18828 |   0.148099  |    0.105977     |   1\n",
      "      18829 |   0.000030  |    0.006210     |   2\n",
      "      18830 |   0.048871  |    0.018182     |   2\n",
      "      18831 |   0.047651  |    0.030527     |   2\n",
      "      18832 |   0.217026  |    0.017560     |   0\n",
      "      18833 |   0.232210  |    0.154128     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 18834: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      18834 |   0.300981  |    0.037047     |   1\n",
      "      18835 |   0.248806  |    0.104502     |   1\n",
      "      18836 |   0.245956  |    0.081907     |   1\n",
      "      18837 |   0.218071  |    0.075915     |   1\n",
      "      18838 |   0.182843  |    0.026111     |   0\n",
      "      18839 |   0.177197  |    0.042409     |   0\n",
      "      18840 |   0.050050  |    0.005538     |   2\n",
      "      18841 |   0.229064  |    0.045134     |   0\n",
      "      18842 |   0.036346  |    0.007762     |   2\n",
      "      18843 |   0.186742  |    0.041663     |   0\n",
      "      18844 |   0.246977  |    0.094629     |   1\n",
      "      18845 |   0.042283  |    0.013289     |   2\n",
      "      18846 |   0.044916  |    0.038591     |   2\n",
      "      18847 |   0.204687  |    0.027318     |   0\n",
      "      18848 |   0.173523  |    0.149908     |   1\n",
      "      18849 |   0.169156  |    0.012227     |   1\n",
      "      18850 |   0.215212  |    0.166662     |   1\n",
      "      18851 |   0.028455  |    0.017555     |   2\n",
      "      18852 |   0.164525  |    0.050076     |   1\n",
      "      18853 |   0.215815  |    0.006705     |   0\n",
      "      18854 |   0.207819  |    0.044892     |   0\n",
      "      18855 |   0.040676  |    0.004966     |   2\n",
      "      18856 |   0.213485  |    0.044322     |   0\n",
      "      18857 |   0.199838  |    0.031590     |   0\n",
      "      18858 |   0.048850  |    0.017905     |   2\n",
      "      18859 |   0.209079  |    0.055683     |   0\n",
      "      18860 |   0.227831  |    0.067427     |   1\n",
      "      18861 |   0.252949  |    0.016499     |   0\n",
      "      18862 |   0.172960  |    0.151339     |   1\n",
      "      18863 |   0.207310  |    0.056285     |   1\n",
      "      18864 |   0.178432  |    0.029194     |   0\n",
      "      18865 |   0.185144  |    0.142214     |   1\n",
      "      18866 |   0.061373  |    0.003023     |   2\n",
      "      18867 |   0.250944  |    0.013960     |   0\n",
      "      18868 |   0.047778  |    0.020613     |   2\n",
      "      18869 |   0.024267  |    0.033558     |   2\n",
      "      18870 |   0.171665  |    0.113985     |   1\n",
      "      18871 |   0.176339  |    0.081106     |   1\n",
      "      18872 |   0.192453  |    0.068662     |   1\n",
      "      18873 |   0.181896  |    0.027035     |   0\n",
      "      18874 |   0.222035  |    0.098859     |   1\n",
      "      18875 |   0.204798  |    0.011182     |   0\n",
      "      18876 |   0.211401  |    0.047663     |   0\n",
      "      18877 | \u001b[94m  0.000029\u001b[0m  |    0.022621     |   2\n",
      "      18878 |   0.245095  |    0.158849     |   1\n",
      "      18879 |   0.006227  |    0.017008     |   2\n",
      "      18880 |   0.209139  |    0.044925     |   1\n",
      "      18881 |   0.202413  |    0.025384     |   0\n",
      "      18882 |   0.068144  |    0.023499     |   2\n",
      "      18883 |   0.193799  |    0.052558     |   0\n",
      "      18884 |   0.252196  |    0.043645     |   1\n",
      "      18885 |   0.038452  |    0.012998     |   2\n",
      "      18886 |   0.059314  |    0.045139     |   2\n",
      "      18887 |   0.195212  |    0.020655     |   0\n",
      "      18888 |   0.176534  |    0.163125     |   1\n",
      "      18889 |   0.195933  |    0.033511     |   1\n",
      "      18890 |   0.223630  |    0.056208     |   0\n",
      "      18891 |   0.045092  |    0.011736     |   2\n",
      "      18892 |   0.020641  |    0.033089     |   2\n",
      "      18893 |   0.042564  |    0.026506     |   2\n",
      "      18894 |   0.028841  |    0.028844     |   2\n",
      "      18895 |   0.237828  |    0.026044     |   0\n",
      "      18896 |   0.182607  |    0.034377     |   0\n",
      "      18897 |   0.000030  |    0.016255     |   2\n",
      "      18898 |   0.282622  |    0.088095     |   1\n",
      "      18899 |   0.000029  |    0.062957     |   2\n",
      "      18900 |   0.178883  |    0.102420     |   1\n",
      "      18901 |   0.284407  |    0.044242     |   1\n",
      "      18902 |   0.000030  |    0.026971     |   2\n",
      "      18903 |   0.000030  |    0.030168     |   2\n",
      "      18904 |   0.208019  |    0.024546     |   0\n",
      "      18905 |   0.000030  |    0.030918     |   2\n",
      "      18906 |   0.218629  |    0.069379     |   1\n",
      "      18907 |   0.188686  |    0.008692     |   0\n",
      "      18908 |   0.211282  |    0.146162     |   1\n",
      "      18909 |   0.163152  |    0.004189     |   0\n",
      "      18910 |   0.168485  |    0.004579     |   0\n",
      "      18911 |   0.195163  |    0.031036     |   0\n",
      "      18912 |   0.186251  |    0.030894     |   0\n",
      "      18913 |   0.000029  |    0.020266     |   2\n",
      "      18914 |   0.048978  |    0.023133     |   2\n",
      "      18915 |   0.200276  |    0.026867     |   0\n",
      "      18916 |   0.229327  |    0.034683     |   0\n",
      "      18917 |   0.046878  |    0.023536     |   2\n",
      "      18918 |   0.241003  |    0.053525     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 18919: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      18919 |   0.231612  |    0.057658     |   1\n",
      "      18920 |   0.196115  |    0.104279     |   1\n",
      "      18921 |   0.053197  |    0.006349     |   2\n",
      "      18922 |   0.241296  |    0.023829     |   0\n",
      "      18923 |   0.038158  |    0.039268     |   2\n",
      "      18924 |   0.178737  |    0.093843     |   1\n",
      "      18925 |   0.200710  |    0.011251     |   0\n",
      "      18926 |   0.195145  |    0.031999     |   0\n",
      "      18927 |   0.165792  |    0.033290     |   0\n",
      "      18928 |   0.204762  |    0.094263     |   1\n",
      "      18929 |   0.214392  |    0.079482     |   1\n",
      "      18930 |   0.195755  |    0.017132     |   0\n",
      "      18931 |   0.207515  |    0.035716     |   0\n",
      "      18932 |   0.042286  |    0.020537     |   2\n",
      "      18933 |   0.185519  |    0.141259     |   1\n",
      "      18934 |   0.221914  |    0.095827     |   1\n",
      "      18935 |   0.186721  |    0.014334     |   0\n",
      "      18936 |   0.223594  |    0.083726     |   1\n",
      "      18937 |   0.191048  |    0.012255     |   0\n",
      "      18938 |   0.045121  |    0.017322     |   2\n",
      "      18939 |   0.140154  |    0.033205     |   0\n",
      "      18940 |   0.223589  |    0.022826     |   0\n",
      "      18941 |   0.029899  |    0.024280     |   2\n",
      "      18942 |   0.184633  |    0.049703     |   0\n",
      "      18943 |   0.170803  |    0.097347     |   1\n",
      "      18944 |   0.041726  |    0.007246     |   2\n",
      "      18945 |   0.052782  |    0.012421     |   2\n",
      "      18946 |   0.061189  |    0.042134     |   2\n",
      "      18947 |   0.164601  |    0.023507     |   0\n",
      "      18948 |   0.198214  |    0.121158     |   1\n",
      "      18949 |   0.187247  |    0.062512     |   1\n",
      "      18950 |   0.048408  |    0.009594     |   2\n",
      "      18951 |   0.025599  |    0.049344     |   2\n",
      "      18952 | \u001b[94m  0.000029\u001b[0m  |    0.008633     |   2\n",
      "      18953 |   0.145366  |    0.026139     |   0\n",
      "      18954 |   0.196688  |    0.050738     |   0\n",
      "      18955 |   0.231168  |    0.090110     |   1\n",
      "      18956 |   0.006159  |    0.003303     |   2\n",
      "      18957 |   0.193031  |    0.029109     |   0\n",
      "      18958 |   0.070211  |    0.026832     |   2\n",
      "      18959 |   0.185845  |    0.026739     |   0\n",
      "      18960 |   0.213386  |    0.016701     |   0\n",
      "      18961 |   0.270585  |    0.032038     |   0\n",
      "      18962 |   0.252192  |    0.145964     |   1\n",
      "      18963 |   0.217925  |    0.058174     |   1\n",
      "      18964 |   0.208211  |    0.012606     |   0\n",
      "      18965 |   0.155810  |    0.028457     |   0\n",
      "      18966 |   0.214834  |    0.046017     |   0\n",
      "      18967 |   0.035404  |    0.008648     |   2\n",
      "      18968 |   0.172729  |    0.044375     |   0\n",
      "      18969 |   0.151345  |    0.007734     |   0\n",
      "      18970 |   0.187535  |    0.067700     |   0\n",
      "      18971 |   0.209395  |    0.069301     |   1\n",
      "      18972 |   0.162966  |    0.088032     |   1\n",
      "      18973 |   0.191171  |    0.018058     |   0\n",
      "      18974 |   0.187624  |    0.030278     |   0\n",
      "      18975 |   0.234599  |    0.043761     |   0\n",
      "      18976 |   0.213525  |    0.017786     |   0\n",
      "      18977 |   0.287269  |    0.045738     |   0\n",
      "      18978 |   0.264329  |    0.105259     |   1\n",
      "      18979 |   0.209484  |    0.090322     |   1\n",
      "      18980 |   0.058857  |    0.008271     |   2\n",
      "      18981 |   0.047060  |    0.028353     |   2\n",
      "      18982 |   0.020604  |    0.043197     |   2\n",
      "      18983 |   0.220209  |    0.011360     |   0\n",
      "      18984 |   0.039183  |    0.045500     |   2\n",
      "      18985 |   0.029438  |    0.010253     |   2\n",
      "      18986 |   0.181848  |    0.051511     |   0\n",
      "      18987 |   0.199815  |    0.062108     |   1\n",
      "      18988 |   0.180371  |    0.029575     |   0\n",
      "      18989 |   0.233925  |    0.042427     |   0\n",
      "      18990 |   0.000030  |    0.014459     |   2\n",
      "      18991 |   0.196183  |    0.150686     |   1\n",
      "      18992 |   0.000029  |    0.004243     |   2\n",
      "      18993 |   0.000030  |    0.005697     |   2\n",
      "      18994 |   0.000030  |    0.031895     |   2\n",
      "      18995 |   0.000030  |    0.022342     |   2\n",
      "      18996 |   0.000030  |    0.029997     |   2\n",
      "      18997 |   0.050763  |    0.024564     |   2\n",
      "      18998 |   0.177608  |    0.052458     |   0\n",
      "      18999 |   0.046532  |    0.005579     |   2\n",
      "      19000 |   0.174923  |    0.050226     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 19000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 19000: Plotting estimates.\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      19001 |   0.184455  |    0.158751     |   1\n",
      "      19002 |   0.051416  |    0.024650     |   2\n",
      "      19003 |   0.244339  |    0.133222     |   1\n",
      "      19004 |   0.157410  |    0.005934     |   0\n",
      "      19005 |   0.224741  |    0.011610     |   0\n",
      "      19006 |   0.037658  |    0.042826     |   2\n",
      "      19007 |   0.040498  |    0.005301     |   2\n",
      "      19008 |   0.183436  |    0.049619     |   0\n",
      "      19009 |   0.193545  |    0.097759     |   1\n",
      "      19010 |   0.046202  |    0.010136     |   2\n",
      "      19011 |   0.245078  |    0.049493     |   0\n",
      "      19012 |   0.029007  |    0.016125     |   2\n",
      "      19013 |   0.122242  |    0.168032     |   1\n",
      "      19014 |   0.040939  |    0.002886     |   2\n",
      "      19015 |   0.051392  |    0.005199     |   2\n",
      "      19016 |   0.222793  |    0.043072     |   0\n",
      "      19017 |   0.218798  |    0.025071     |   0\n",
      "      19018 |   0.202350  |    0.028603     |   0\n",
      "      19019 |   0.187354  |    0.030508     |   0\n",
      "      19020 |   0.176436  |    0.151739     |   1\n",
      "      19021 |   0.219269  |    0.002914     |   0\n",
      "      19022 |   0.056777  |    0.008038     |   2\n",
      "      19023 |   0.218916  |    0.061647     |   0\n",
      "      19024 |   0.181243  |    0.096046     |   1\n",
      "      19025 |   0.228910  |    0.060654     |   1\n",
      "      19026 |   0.184376  |    0.014294     |   0\n",
      "      19027 |   0.210421  |    0.052842     |   0\n",
      "      19028 |   0.221162  |    0.047519     |   1\n",
      "      19029 |   0.047791  |    0.023943     |   2\n",
      "      19030 |   0.156420  |    0.151826     |   1\n",
      "      19031 |   0.166483  |    0.046278     |   1\n",
      "      19032 |   0.022794  |    0.005186     |   2\n",
      "      19033 |   0.210024  |    0.159913     |   1\n",
      "      19034 |   0.204794  |    0.002941     |   0\n",
      "      19035 |   0.198437  |    0.006137     |   0\n",
      "      19036 |   0.198630  |    0.046368     |   0\n",
      "      19037 |   0.000030  |    0.008576     |   2\n",
      "      19038 |   0.005769  |    0.028475     |   2\n",
      "      19039 |   0.172034  |    0.041392     |   0\n",
      "      19040 |   0.217364  |    0.037812     |   0\n",
      "      19041 |   0.206994  |    0.122380     |   1\n",
      "      19042 |   0.203067  |    0.108963     |   1\n",
      "      19043 |   0.189961  |    0.055699     |   1\n",
      "      19044 |   0.069262  |    0.022076     |   2\n",
      "      19045 |   0.197651  |    0.156427     |   1\n",
      "      19046 |   0.036071  |    0.011662     |   2\n",
      "      19047 |   0.202684  |    0.082082     |   1\n",
      "      19048 |   0.195622  |    0.097243     |   1\n",
      "      19049 |   0.059183  |    0.011910     |   2\n",
      "      19050 |   0.047801  |    0.042102     |   2\n",
      "      19051 |   0.021124  |    0.010368     |   2\n",
      "      19052 |   0.259232  |    0.137310     |   1\n",
      "      19053 |   0.223074  |    0.100707     |   1\n",
      "      19054 |   0.203360  |    0.090824     |   1\n",
      "      19055 |   0.039549  |    0.009459     |   2\n",
      "      19056 |   0.032016  |    0.030298     |   2\n",
      "      19057 |   0.000030  |    0.050355     |   2\n",
      "      19058 |   0.236726  |    0.088938     |   1\n",
      "      19059 |   0.000030  |    0.005722     |   2\n",
      "      19060 |   0.222702  |    0.090972     |   1\n",
      "      19061 |   0.000030  |    0.009921     |   2\n",
      "      19062 |   0.174694  |    0.029067     |   0\n",
      "      19063 |   0.000031  |    0.042808     |   2\n",
      "      19064 |   0.177574  |    0.085524     |   1\n",
      "      19065 |   0.000030  |    0.012638     |   2\n",
      "      19066 |   0.000030  |    0.029957     |   2\n",
      "      19067 |   0.048364  |    0.023767     |   2\n",
      "      19068 |   0.222680  |    0.052417     |   0\n",
      "      19069 |   0.046152  |    0.007887     |   2\n",
      "      19070 |   0.238389  |    0.153459     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 19071: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      19071 |   0.190649  |    0.059091     |   1\n",
      "      19072 |   0.047646  |    0.007870     |   2\n",
      "      19073 |   0.193812  |    0.042993     |   0\n",
      "      19074 |   0.208179  |    0.010430     |   0\n",
      "      19075 |   0.184964  |    0.052617     |   0\n",
      "      19076 |   0.035492  |    0.008999     |   2\n",
      "      19077 |   0.224807  |    0.140040     |   1\n",
      "      19078 |   0.041620  |    0.009970     |   2\n",
      "      19079 |   0.197489  |    0.103494     |   1\n",
      "      19080 |   0.224059  |    0.095446     |   1\n",
      "      19081 |   0.265212  |    0.101103     |   1\n",
      "      19082 |   0.225417  |    0.078774     |   1\n",
      "      19083 |   0.189064  |    0.014307     |   0\n",
      "      19084 |   0.191653  |    0.149323     |   1\n",
      "      19085 |   0.169330  |    0.003215     |   0\n",
      "      19086 |   0.045052  |    0.010335     |   2\n",
      "      19087 |   0.028929  |    0.031281     |   2\n",
      "      19088 |   0.040614  |    0.032499     |   2\n",
      "      19089 |   0.049594  |    0.025390     |   2\n",
      "      19090 |   0.232320  |    0.095030     |   1\n",
      "      19091 |   0.193349  |    0.018668     |   0\n",
      "      19092 |   0.233492  |    0.112053     |   1\n",
      "      19093 |   0.059064  |    0.007480     |   2\n",
      "      19094 |   0.046679  |    0.040876     |   2\n",
      "      19095 |   0.203342  |    0.028746     |   0\n",
      "      19096 |   0.211223  |    0.138703     |   1\n",
      "      19097 |   0.184689  |    0.015495     |   0\n",
      "      19098 |   0.189125  |    0.047343     |   1\n",
      "      19099 |   0.025113  |    0.029052     |   2\n",
      "      19100 |   0.229713  |    0.034907     |   0\n",
      "      19101 |   0.171977  |    0.097543     |   1\n",
      "      19102 |   0.000029  |    0.009268     |   2\n",
      "      19103 |   0.206256  |    0.146924     |   1\n",
      "      19104 |   0.213000  |    0.044158     |   1\n",
      "      19105 |   0.191107  |    0.022227     |   0\n",
      "      19106 |   0.005548  |    0.028486     |   2\n",
      "      19107 |   0.180714  |    0.029617     |   0\n",
      "      19108 |   0.066938  |    0.021710     |   2\n",
      "      19109 |   0.195743  |    0.024943     |   0\n",
      "      19110 |   0.203313  |    0.142581     |   1\n",
      "      19111 |   0.235964  |    0.006476     |   0\n",
      "      19112 |   0.285538  |    0.016837     |   0\n",
      "      19113 |   0.166308  |    0.137994     |   1\n",
      "      19114 |   0.221562  |    0.006258     |   0\n",
      "      19115 |   0.184075  |    0.027659     |   0\n",
      "      19116 |   0.181059  |    0.149366     |   1\n",
      "      19117 |   0.201281  |    0.087643     |   1\n",
      "      19118 |   0.035442  |    0.005292     |   2\n",
      "      19119 |   0.191522  |    0.032642     |   0\n",
      "      19120 |   0.059465  |    0.013465     |   2\n",
      "      19121 |   0.047980  |    0.038328     |   2\n",
      "      19122 |   0.206281  |    0.081685     |   1\n",
      "      19123 |   0.203866  |    0.080638     |   1\n",
      "      19124 |   0.020364  |    0.028046     |   2\n",
      "      19125 |   0.173741  |    0.149429     |   1\n",
      "      19126 |   0.039173  |    0.003909     |   2\n",
      "      19127 |   0.029930  |    0.007831     |   2\n",
      "      19128 |   0.315082  |    0.163303     |   1\n",
      "      19129 |   0.000029  |    0.007116     |   2\n",
      "      19130 |   0.255161  |    0.089670     |   1\n",
      "      19131 |   0.172181  |    0.009034     |   0\n",
      "      19132 |   0.199150  |    0.096792     |   1\n",
      "      19133 |   0.221329  |    0.112778     |   1\n",
      "      19134 |   0.238727  |    0.081644     |   1\n",
      "      19135 | \u001b[94m  0.000029\u001b[0m  |    0.008850     |   2\n",
      "      19136 |   0.206119  |    0.051739     |   0\n",
      "      19137 |   0.186349  |    0.150174     |   1\n",
      "      19138 |   0.241459  |    0.016036     |   0\n",
      "      19139 |   0.196303  |    0.057860     |   1\n",
      "      19140 |   0.000029  |    0.012435     |   2\n",
      "      19141 |   0.000030  |    0.042583     |   2\n",
      "      19142 |   0.191482  |    0.015826     |   0\n",
      "      19143 |   0.000029  |    0.028156     |   2\n",
      "      19144 |   0.000029  |    0.030575     |   2\n",
      "      19145 |   0.215617  |    0.134326     |   1\n",
      "      19146 |   0.046164  |    0.008386     |   2\n",
      "      19147 |   0.159825  |    0.085137     |   1\n",
      "      19148 |   0.045408  |    0.010785     |   2\n",
      "      19149 |   0.175402  |    0.139957     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 19150: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      19150 |   0.171493  |    0.023344     |   0\n",
      "      19151 |   0.167690  |    0.136299     |   1\n",
      "      19152 |   0.047774  |    0.006056     |   2\n",
      "      19153 |   0.037020  |    0.008616     |   2\n",
      "      19154 |   0.039397  |    0.030839     |   2\n",
      "      19155 |   0.200102  |    0.021605     |   0\n",
      "      19156 |   0.045719  |    0.033097     |   2\n",
      "      19157 |   0.181942  |    0.155508     |   1\n",
      "      19158 |   0.028219  |    0.003108     |   2\n",
      "      19159 |   0.039671  |    0.007603     |   2\n",
      "      19160 |   0.047765  |    0.050734     |   2\n",
      "      19161 |   0.236139  |    0.088742     |   1\n",
      "      19162 |   0.058312  |    0.008870     |   2\n",
      "      19163 |   0.191655  |    0.042950     |   0\n",
      "      19164 |   0.195861  |    0.013569     |   0\n",
      "      19165 |   0.238971  |    0.140167     |   1\n",
      "      19166 |   0.218577  |    0.014542     |   0\n",
      "      19167 |   0.230522  |    0.014552     |   0\n",
      "      19168 |   0.048493  |    0.028394     |   2\n",
      "      19169 |   0.194832  |    0.135139     |   1\n",
      "      19170 |   0.024273  |    0.007884     |   2\n",
      "      19171 | \u001b[94m  0.000029\u001b[0m  |    0.024844     |   2\n",
      "      19172 |   0.193334  |    0.140295     |   1\n",
      "      19173 |   0.244442  |    0.046818     |   1\n",
      "      19174 |   0.005770  |    0.025564     |   2\n",
      "      19175 |   0.190164  |    0.047674     |   0\n",
      "      19176 |   0.065902  |    0.011581     |   2\n",
      "      19177 |   0.198015  |    0.143625     |   1\n",
      "      19178 |   0.034404  |    0.010870     |   2\n",
      "      19179 |   0.219920  |    0.010004     |   0\n",
      "      19180 |   0.225841  |    0.039293     |   0\n",
      "      19181 |   0.160982  |    0.025356     |   0\n",
      "      19182 |   0.059891  |    0.056910     |   2\n",
      "      19183 |   0.197568  |    0.098947     |   1\n",
      "      19184 |   0.211636  |    0.083441     |   1\n",
      "      19185 |   0.128273  |    0.088670     |   1\n",
      "      19186 |   0.044630  |    0.008329     |   2\n",
      "      19187 |   0.220324  |    0.026215     |   0\n",
      "      19188 |   0.177326  |    0.038187     |   0\n",
      "      19189 |   0.173365  |    0.099728     |   1\n",
      "      19190 |   0.132703  |    0.088575     |   1\n",
      "      19191 |   0.019650  |    0.011784     |   2\n",
      "      19192 |   0.178287  |    0.134264     |   1\n",
      "      19193 |   0.222205  |    0.023315     |   0\n",
      "      19194 |   0.200388  |    0.146732     |   1\n",
      "      19195 |   0.220793  |    0.005642     |   0\n",
      "      19196 |   0.202898  |    0.059233     |   0\n",
      "      19197 |   0.188095  |    0.098436     |   1\n",
      "      19198 |   0.038131  |    0.017213     |   2\n",
      "      19199 |   0.185879  |    0.026941     |   0\n",
      "      19200 |   0.276969  |    0.109816     |   1\n",
      "      19201 |   0.204336  |    0.004807     |   0\n",
      "      19202 |   0.278335  |    0.041808     |   0\n",
      "      19203 |   0.165427  |    0.032004     |   0\n",
      "      19204 |   0.030485  |    0.016494     |   2\n",
      "      19205 |   0.000029  |    0.024918     |   2\n",
      "      19206 |   0.210650  |    0.063613     |   0\n",
      "      19207 |   0.220256  |    0.104153     |   1\n",
      "      19208 |   0.246061  |    0.091678     |   1\n",
      "      19209 |   0.241794  |    0.085851     |   1\n",
      "      19210 |   0.193368  |    0.007822     |   0\n",
      "      19211 |   0.000029  |    0.030981     |   2\n",
      "      19212 |   0.184219  |    0.037783     |   0\n",
      "      19213 |   0.000029  |    0.007183     |   2\n",
      "      19214 |   0.203036  |    0.163710     |   1\n",
      "      19215 |   0.000029  |    0.005186     |   2\n",
      "      19216 |   0.184468  |    0.014982     |   0\n",
      "      19217 |   0.000029  |    0.041433     |   2\n",
      "      19218 |   0.281530  |    0.047007     |   0\n",
      "      19219 |   0.147898  |    0.111664     |   1\n",
      "      19220 |   0.190830  |    0.093357     |   1\n",
      "      19221 |   0.235182  |    0.054002     |   1\n",
      "      19222 |   0.000029  |    0.022825     |   2\n",
      "      19223 |   0.051517  |    0.027596     |   2\n",
      "      19224 |   0.203294  |    0.029267     |   0\n",
      "      19225 |   0.212355  |    0.143750     |   1\n",
      "      19226 |   0.046905  |    0.011230     |   2\n",
      "      19227 |   0.162383  |    0.044878     |   0\n",
      "      19228 |   0.196469  |    0.087993     |   1\n",
      "      19229 |   0.194283  |    0.087139     |   1\n",
      "      19230 |   0.173151  |    0.010720     |   0\n",
      "      19231 |   0.199289  |    0.056739     |   0\n",
      "      19232 |   0.190825  |    0.069119     |   1\n",
      "      19233 |   0.231383  |    0.020968     |   0\n",
      "      19234 |   0.219600  |    0.135147     |   1\n",
      "      19235 |   0.194577  |    0.007885     |   0\n",
      "      19236 |   0.195374  |    0.036824     |   0\n",
      "      19237 |   0.223330  |    0.048230     |   1\n",
      "      19238 |   0.209275  |    0.045252     |   0\n",
      "      19239 |   0.221050  |    0.037905     |   0\n",
      "      19240 |   0.196103  |    0.078172     |   1\n",
      "      19241 |   0.166393  |    0.161503     |   1\n",
      "      19242 |   0.216884  |    0.010074     |   0\n",
      "      19243 |   0.203810  |    0.058556     |   1\n",
      "      19244 |   0.186454  |    0.128575     |   1\n",
      "      19245 |   0.176288  |    0.002973     |   0\n",
      "      19246 |   0.151270  |    0.005493     |   0\n",
      "      19247 |   0.219209  |    0.030146     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 19248: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      19248 |   0.206716  |    0.086151     |   1\n",
      "      19249 |   0.162292  |    0.144740     |   1\n",
      "      19250 |   0.054494  |    0.002956     |   2\n",
      "      19251 |   0.190284  |    0.003502     |   0\n",
      "      19252 |   0.194888  |    0.044508     |   0\n",
      "      19253 |   0.194836  |    0.036508     |   0\n",
      "      19254 |   0.231051  |    0.100876     |   1\n",
      "      19255 |   0.253299  |    0.132106     |   1\n",
      "      19256 |   0.226656  |    0.005380     |   0\n",
      "      19257 |   0.222029  |    0.006560     |   0\n",
      "      19258 |   0.221583  |    0.050136     |   0\n",
      "      19259 |   0.263072  |    0.089020     |   1\n",
      "      19260 |   0.202151  |    0.016655     |   0\n",
      "      19261 |   0.037805  |    0.025065     |   2\n",
      "      19262 |   0.219171  |    0.030165     |   0\n",
      "      19263 |   0.041304  |    0.026316     |   2\n",
      "      19264 |   0.186107  |    0.140429     |   1\n",
      "      19265 |   0.173743  |    0.002960     |   0\n",
      "      19266 |   0.047248  |    0.004689     |   2\n",
      "      19267 |   0.193577  |    0.146585     |   1\n",
      "      19268 |   0.212336  |    0.010267     |   0\n",
      "      19269 |   0.029609  |    0.006370     |   2\n",
      "      19270 |   0.042328  |    0.026576     |   2\n",
      "      19271 |   0.206895  |    0.042293     |   0\n",
      "      19272 |   0.188113  |    0.085105     |   1\n",
      "      19273 |   0.202802  |    0.018244     |   0\n",
      "      19274 |   0.198877  |    0.093839     |   1\n",
      "      19275 |   0.248372  |    0.136389     |   1\n",
      "      19276 |   0.177768  |    0.002960     |   0\n",
      "      19277 |   0.054113  |    0.003594     |   2\n",
      "      19278 |   0.238938  |    0.141042     |   1\n",
      "      19279 |   0.238938  |    0.050134     |   1\n",
      "      19280 |   0.063233  |    0.021340     |   2\n",
      "      19281 |   0.045955  |    0.029207     |   2\n",
      "      19282 |   0.022146  |    0.019738     |   2\n",
      "      19283 |   0.230889  |    0.042638     |   0\n",
      "      19284 |   0.233617  |    0.091169     |   1\n",
      "      19285 |   0.151926  |    0.088955     |   1\n",
      "      19286 |   0.203950  |    0.019854     |   0\n",
      "      19287 |   0.000029  |    0.022591     |   2\n",
      "      19288 |   0.238059  |    0.158771     |   1\n",
      "      19289 |   0.166466  |    0.085980     |   1\n",
      "      19290 |   0.220329  |    0.080514     |   1\n",
      "      19291 |   0.197241  |    0.090561     |   1\n",
      "      19292 |   0.005560  |    0.018907     |   2\n",
      "      19293 |   0.173290  |    0.051394     |   0\n",
      "      19294 |   0.067582  |    0.012743     |   2\n",
      "      19295 |   0.217150  |    0.138907     |   1\n",
      "      19296 |   0.183865  |    0.005003     |   0\n",
      "      19297 |   0.036177  |    0.030048     |   2\n",
      "      19298 |   0.189443  |    0.149278     |   1\n",
      "      19299 |   0.176447  |    0.012538     |   0\n",
      "      19300 |   0.174168  |    0.053219     |   1\n",
      "      19301 |   0.057357  |    0.011593     |   2\n",
      "      19302 |   0.189483  |    0.046367     |   0\n",
      "      19303 |   0.185004  |    0.021649     |   0\n",
      "      19304 |   0.263289  |    0.169757     |   1\n",
      "      19305 |   0.044755  |    0.010475     |   2\n",
      "      19306 |   0.140794  |    0.093657     |   1\n",
      "      19307 |   0.167606  |    0.057695     |   1\n",
      "      19308 |   0.296124  |    0.103876     |   1\n",
      "      19309 |   0.315009  |    0.055662     |   1\n",
      "      19310 |   0.147274  |    0.026841     |   0\n",
      "      19311 |   0.242990  |    0.024352     |   0\n",
      "      19312 |   0.018457  |    0.014892     |   2\n",
      "      19313 |   0.189253  |    0.048439     |   0\n",
      "      19314 |   0.204376  |    0.009708     |   0\n",
      "      19315 |   0.038731  |    0.032291     |   2\n",
      "      19316 |   0.187732  |    0.033396     |   0\n",
      "      19317 |   0.032018  |    0.022325     |   2\n",
      "      19318 |   0.000029  |    0.029853     |   2\n",
      "      19319 |   0.224124  |    0.049398     |   0\n",
      "      19320 |   0.257211  |    0.090215     |   1\n",
      "      19321 |   0.222194  |    0.013920     |   0\n",
      "      19322 |   0.000029  |    0.013762     |   2\n",
      "      19323 |   0.195925  |    0.044313     |   0\n",
      "      19324 |   0.208683  |    0.021413     |   0\n",
      "      19325 |   0.171986  |    0.144074     |   1\n",
      "      19326 |   0.215586  |    0.053483     |   1\n",
      "      19327 |   0.220158  |    0.022328     |   0\n",
      "      19328 |   0.208124  |    0.040456     |   0\n",
      "      19329 |   0.000029  |    0.011224     |   2\n",
      "      19330 |   0.000029  |    0.047501     |   2\n",
      "      19331 |   0.182085  |    0.009033     |   0\n",
      "      19332 |   0.211771  |    0.045530     |   0\n",
      "      19333 |   0.188378  |    0.010899     |   0\n",
      "      19334 |   0.217411  |    0.040096     |   0\n",
      "      19335 |   0.000029  |    0.022908     |   2\n",
      "      19336 |   0.328431  |    0.143796     |   1\n",
      "      19337 |   0.000029  |    0.011426     |   2\n",
      "      19338 |   0.165975  |    0.010563     |   0\n",
      "      19339 |   0.056636  |    0.010899     |   2\n",
      "      19340 |   0.049635  |    0.035787     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 19341: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      19341 |   0.054496  |    0.013244     |   2\n",
      "      19342 |   0.038302  |    0.044616     |   2\n",
      "      19343 |   0.191429  |    0.020302     |   0\n",
      "      19344 |   0.199860  |    0.147892     |   1\n",
      "      19345 |   0.142424  |    0.011509     |   0\n",
      "      19346 |   0.229324  |    0.098124     |   1\n",
      "      19347 |   0.180248  |    0.002858     |   0\n",
      "      19348 |   0.185714  |    0.088335     |   1\n",
      "      19349 |   0.041723  |    0.018944     |   2\n",
      "      19350 |   0.051733  |    0.034694     |   2\n",
      "      19351 |   0.222031  |    0.021919     |   0\n",
      "      19352 |   0.029121  |    0.030398     |   2\n",
      "      19353 |   0.185693  |    0.036869     |   0\n",
      "      19354 |   0.040615  |    0.013217     |   2\n",
      "      19355 |   0.197855  |    0.027253     |   0\n",
      "      19356 |   0.054313  |    0.047323     |   2\n",
      "      19357 |   0.223825  |    0.140436     |   1\n",
      "      19358 |   0.272817  |    0.054973     |   1\n",
      "      19359 |   0.263150  |    0.090702     |   1\n",
      "      19360 |   0.198807  |    0.031932     |   0\n",
      "      19361 |   0.057431  |    0.043381     |   2\n",
      "      19362 |   0.186272  |    0.057014     |   1\n",
      "      19363 |   0.172322  |    0.032188     |   0\n",
      "      19364 |   0.044306  |    0.029174     |   2\n",
      "      19365 |   0.206905  |    0.030292     |   0\n",
      "      19366 |   0.215574  |    0.151130     |   1\n",
      "      19367 |   0.170391  |    0.056588     |   1\n",
      "      19368 |   0.199265  |    0.102955     |   1\n",
      "      19369 |   0.023124  |    0.006957     |   2\n",
      "      19370 |   0.000029  |    0.037579     |   2\n",
      "      19371 |   0.005207  |    0.029087     |   2\n",
      "      19372 |   0.262599  |    0.144599     |   1\n",
      "      19373 |   0.200486  |    0.051489     |   1\n",
      "      19374 |   0.188204  |    0.023811     |   0\n",
      "      19375 |   0.066304  |    0.027358     |   2\n",
      "      19376 |   0.178942  |    0.026977     |   0\n",
      "      19377 |   0.035622  |    0.041714     |   2\n",
      "      19378 |   0.219900  |    0.085458     |   1\n",
      "      19379 |   0.205959  |    0.136303     |   1\n",
      "      19380 |   0.203804  |    0.002968     |   0\n",
      "      19381 |   0.057532  |    0.011077     |   2\n",
      "      19382 |   0.209116  |    0.047857     |   0\n",
      "      19383 |   0.044337  |    0.007366     |   2\n",
      "      19384 |   0.017594  |    0.048026     |   2\n",
      "      19385 |   0.226666  |    0.141184     |   1\n",
      "      19386 |   0.036461  |    0.008827     |   2\n",
      "      19387 |   0.170460  |    0.078665     |   1\n",
      "      19388 |   0.185860  |    0.023615     |   0\n",
      "      19389 |   0.188776  |    0.030415     |   0\n",
      "      19390 |   0.184087  |    0.098048     |   1\n",
      "      19391 |   0.240845  |    0.026555     |   0\n",
      "      19392 |   0.211992  |    0.041457     |   0\n",
      "      19393 |   0.030676  |    0.013908     |   2\n",
      "      19394 |   0.223185  |    0.026133     |   0\n",
      "      19395 |   0.160052  |    0.016969     |   0\n",
      "      19396 |   0.200367  |    0.055057     |   0\n",
      "      19397 |   0.000029  |    0.007259     |   2\n",
      "      19398 |   0.000029  |    0.026213     |   2\n",
      "      19399 |   0.229026  |    0.029385     |   0\n",
      "      19400 |   0.149331  |    0.147622     |   1\n",
      "      19401 |   0.155804  |    0.002949     |   0\n",
      "      19402 |   0.181809  |    0.012673     |   0\n",
      "      19403 |   0.207679  |    0.028186     |   0\n",
      "      19404 |   0.173019  |    0.031193     |   0\n",
      "      19405 |   0.204626  |    0.143700     |   1\n",
      "      19406 |   0.000029  |    0.003613     |   2\n",
      "      19407 |   0.242553  |    0.009244     |   0\n",
      "      19408 |   0.156618  |    0.138000     |   1\n",
      "      19409 |   0.189294  |    0.009824     |   0\n",
      "      19410 |   0.220626  |    0.144649     |   1\n",
      "      19411 |   0.186796  |    0.004231     |   0\n",
      "      19412 |   0.000030  |    0.010918     |   2\n",
      "      19413 |   0.286141  |    0.154826     |   1\n",
      "      19414 |   0.181120  |    0.058327     |   1\n",
      "      19415 |   0.000030  |    0.007035     |   2\n",
      "      19416 |   0.150074  |    0.043633     |   0\n",
      "      19417 |   0.000029  |    0.016668     |   2\n",
      "      19418 |   0.180716  |    0.028853     |   0\n",
      "      19419 |   0.165475  |    0.021670     |   0\n",
      "      19420 |   0.051505  |    0.064264     |   2\n",
      "      19421 |   0.190116  |    0.088948     |   1\n",
      "      19422 |   0.245079  |    0.095018     |   1\n",
      "      19423 |   0.139416  |    0.005335     |   0\n",
      "      19424 |   0.048656  |    0.025230     |   2\n",
      "      19425 |   0.201653  |    0.125777     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 19426: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      19426 |   0.051019  |    0.010892     |   2\n",
      "      19427 |   0.164753  |    0.015868     |   0\n",
      "      19428 |   0.215019  |    0.046215     |   0\n",
      "      19429 |   0.035921  |    0.008895     |   2\n",
      "      19430 |   0.180577  |    0.042114     |   0\n",
      "      19431 |   0.198498  |    0.015287     |   0\n",
      "      19432 |   0.187619  |    0.037656     |   0\n",
      "      19433 |   0.155158  |    0.015755     |   0\n",
      "      19434 |   0.221750  |    0.052017     |   0\n",
      "      19435 |   0.219771  |    0.081460     |   1\n",
      "      19436 |   0.217822  |    0.009072     |   0\n",
      "      19437 |   0.194548  |    0.040029     |   0\n",
      "      19438 |   0.040628  |    0.009015     |   2\n",
      "      19439 |   0.266182  |    0.048666     |   0\n",
      "      19440 |   0.190195  |    0.079977     |   1\n",
      "      19441 |   0.047791  |    0.037890     |   2\n",
      "      19442 |   0.217123  |    0.143797     |   1\n",
      "      19443 |   0.228759  |    0.013176     |   0\n",
      "      19444 |   0.029777  |    0.011058     |   2\n",
      "      19445 |   0.040595  |    0.019561     |   2\n",
      "      19446 |   0.140263  |    0.043888     |   0\n",
      "      19447 |   0.247734  |    0.017821     |   0\n",
      "      19448 |   0.056591  |    0.026754     |   2\n",
      "      19449 |   0.060124  |    0.024998     |   2\n",
      "      19450 |   0.178331  |    0.040498     |   0\n",
      "      19451 |   0.224763  |    0.016392     |   0\n",
      "      19452 |   0.142685  |    0.036306     |   0\n",
      "      19453 |   0.047270  |    0.019694     |   2\n",
      "      19454 |   0.022774  |    0.051717     |   2\n",
      "      19455 |   0.201750  |    0.091313     |   1\n",
      "      19456 |   0.175694  |    0.083493     |   1\n",
      "      19457 |   0.000029  |    0.028170     |   2\n",
      "      19458 |   0.162727  |    0.147187     |   1\n",
      "      19459 |   0.005384  |    0.012341     |   2\n",
      "      19460 |   0.167102  |    0.012325     |   0\n",
      "      19461 |   0.067140  |    0.019736     |   2\n",
      "      19462 |   0.222734  |    0.104702     |   1\n",
      "      19463 |   0.177626  |    0.026071     |   0\n",
      "      19464 |   0.037103  |    0.026371     |   2\n",
      "      19465 |   0.211120  |    0.089365     |   1\n",
      "      19466 |   0.060505  |    0.008944     |   2\n",
      "      19467 |   0.047348  |    0.049248     |   2\n",
      "      19468 |   0.018189  |    0.017609     |   2\n",
      "      19469 |   0.218277  |    0.131841     |   1\n",
      "      19470 |   0.169003  |    0.005767     |   0\n",
      "      19471 |   0.206449  |    0.024994     |   0\n",
      "      19472 |   0.188708  |    0.131401     |   1\n",
      "      19473 |   0.191751  |    0.005623     |   0\n",
      "      19474 |   0.179336  |    0.033147     |   0\n",
      "      19475 |   0.038598  |    0.033396     |   2\n",
      "      19476 |   0.211510  |    0.110994     |   1\n",
      "      19477 |   0.163113  |    0.088753     |   1\n",
      "      19478 |   0.190996  |    0.005738     |   0\n",
      "      19479 |   0.030856  |    0.039911     |   2\n",
      "      19480 |   0.193987  |    0.087626     |   1\n",
      "      19481 |   0.228575  |    0.015318     |   0\n",
      "      19482 |   0.000029  |    0.046447     |   2\n",
      "      19483 |   0.000029  |    0.009639     |   2\n",
      "      19484 |   0.000029  |    0.040683     |   2\n",
      "      19485 |   0.216929  |    0.023659     |   0\n",
      "      19486 |   0.000030  |    0.035494     |   2\n",
      "      19487 |   0.213995  |    0.037134     |   0\n",
      "      19488 |   0.175126  |    0.092862     |   1\n",
      "      19489 |   0.000029  |    0.032828     |   2\n",
      "      19490 |   0.219019  |    0.133922     |   1\n",
      "      19491 |   0.202569  |    0.037143     |   1\n",
      "      19492 |   0.000029  |    0.042550     |   2\n",
      "      19493 |   0.269532  |    0.103313     |   1\n",
      "      19494 |   0.212545  |    0.090231     |   1\n",
      "      19495 |   0.048879  |    0.003601     |   2\n",
      "      19496 |   0.047522  |    0.019899     |   2\n",
      "      19497 |   0.139050  |    0.056335     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 19498: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      19498 |   0.239840  |    0.083219     |   1\n",
      "      19499 |   0.054401  |    0.009094     |   2\n",
      "      19500 |   0.176403  |    0.049092     |   0\n",
      "      19501 |   0.155247  |    0.041839     |   0\n",
      "      19502 |   0.274429  |    0.078881     |   1\n",
      "      19503 |   0.213378  |    0.034031     |   0\n",
      "      19504 |   0.052797  |    0.030221     |   2\n",
      "      19505 |   0.037963  |    0.015572     |   2\n",
      "      19506 |   0.205988  |    0.159410     |   1\n",
      "      19507 |   0.182498  |    0.051952     |   1\n",
      "      19508 |   0.191157  |    0.023828     |   0\n",
      "      19509 |   0.229378  |    0.154292     |   1\n",
      "      19510 |   0.212866  |    0.010212     |   1\n",
      "      19511 |   0.181165  |    0.048234     |   0\n",
      "      19512 |   0.190842  |    0.015504     |   0\n",
      "      19513 |   0.286985  |    0.126492     |   1\n",
      "      19514 |   0.041898  |    0.011533     |   2\n",
      "      19515 |   0.046177  |    0.018015     |   2\n",
      "      19516 |   0.160761  |    0.148650     |   1\n",
      "      19517 |   0.175758  |    0.003079     |   0\n",
      "      19518 |   0.126341  |    0.018516     |   0\n",
      "      19519 |   0.209954  |    0.138029     |   1\n",
      "      19520 |   0.171090  |    0.002921     |   0\n",
      "      19521 |   0.027934  |    0.014800     |   2\n",
      "      19522 |   0.204225  |    0.147159     |   1\n",
      "      19523 |   0.041791  |    0.002838     |   2\n",
      "      19524 |   0.049533  |    0.013924     |   2\n",
      "      19525 |   0.174072  |    0.095721     |   1\n",
      "      19526 |   0.057953  |    0.016974     |   2\n",
      "      19527 |   0.044608  |    0.044054     |   2\n",
      "      19528 |   0.022723  |    0.015498     |   2\n",
      "      19529 |   0.169162  |    0.142824     |   1\n",
      "      19530 |   0.151963  |    0.002912     |   0\n",
      "      19531 |   0.000029  |    0.004124     |   2\n",
      "      19532 |   0.184151  |    0.026028     |   0\n",
      "      19533 |   0.143303  |    0.024634     |   0\n",
      "      19534 |   0.005599  |    0.066099     |   2\n",
      "      19535 |   0.174213  |    0.093837     |   1\n",
      "      19536 |   0.197557  |    0.096278     |   1\n",
      "      19537 |   0.149389  |    0.069992     |   1\n",
      "      19538 |   0.255435  |    0.024121     |   0\n",
      "      19539 |   0.173052  |    0.030313     |   0\n",
      "      19540 |   0.241732  |    0.098080     |   1\n",
      "      19541 |   0.063816  |    0.025421     |   2\n",
      "      19542 |   0.205620  |    0.144698     |   1\n",
      "      19543 |   0.035009  |    0.020247     |   2\n",
      "      19544 |   0.055922  |    0.012355     |   2\n",
      "      19545 |   0.221248  |    0.022112     |   1\n",
      "      19546 |   0.197658  |    0.046028     |   0\n",
      "      19547 |   0.188008  |    0.018174     |   0\n",
      "      19548 |   0.046644  |    0.047861     |   2\n",
      "      19549 |   0.163854  |    0.111585     |   1\n",
      "      19550 |   0.157747  |    0.009475     |   0\n",
      "      19551 |   0.178291  |    0.013009     |   0\n",
      "      19552 |   0.187319  |    0.051658     |   0\n",
      "      19553 |   0.190841  |    0.083874     |   1\n",
      "      19554 |   0.223593  |    0.127385     |   1\n",
      "      19555 |   0.237813  |    0.068811     |   1\n",
      "      19556 |   0.143814  |    0.104687     |   1\n",
      "      19557 |   0.259547  |    0.056878     |   1\n",
      "      19558 |   0.181225  |    0.026602     |   0\n",
      "      19559 |   0.184290  |    0.126803     |   1\n",
      "      19560 |   0.184065  |    0.025831     |   1\n",
      "      19561 |   0.019395  |    0.042828     |   2\n",
      "      19562 |   0.223740  |    0.082293     |   1\n",
      "      19563 |   0.233009  |    0.078765     |   1\n",
      "      19564 |   0.198971  |    0.098146     |   1\n",
      "      19565 |   0.178240  |    0.038506     |   0\n",
      "      19566 |   0.041133  |    0.039456     |   2\n",
      "      19567 |   0.236284  |    0.078766     |   1\n",
      "      19568 |   0.028947  |    0.008491     |   2\n",
      "      19569 |   0.200565  |    0.048390     |   0\n",
      "      19570 |   0.180867  |    0.014132     |   0\n",
      "      19571 |   0.182439  |    0.021836     |   0\n",
      "      19572 |   0.000029  |    0.068422     |   2\n",
      "      19573 |   0.289959  |    0.063599     |   1\n",
      "      19574 |   0.216394  |    0.068924     |   1\n",
      "      19575 |   0.237011  |    0.081137     |   1\n",
      "      19576 |   0.248928  |    0.016125     |   0\n",
      "      19577 |   0.241367  |    0.143215     |   1\n",
      "      19578 | \u001b[94m  0.000028\u001b[0m  |    0.002984     |   2\n",
      "      19579 |   0.000029  |    0.005929     |   2\n",
      "      19580 |   0.258528  |    0.044324     |   0\n",
      "      19581 |   0.000029  |    0.012397     |   2\n",
      "      19582 |   0.211981  |    0.113228     |   1\n",
      "      19583 |   0.203759  |    0.018341     |   0\n",
      "      19584 |   0.000029  |    0.039546     |   2\n",
      "      19585 |   0.229284  |    0.133770     |   1\n",
      "      19586 |   0.000029  |    0.012439     |   2\n",
      "      19587 |   0.207697  |    0.080951     |   1\n",
      "      19588 |   0.210860  |    0.012025     |   0\n",
      "      19589 |   0.211942  |    0.033836     |   0\n",
      "      19590 |   0.192206  |    0.006036     |   0\n",
      "      19591 |   0.191200  |    0.044264     |   0\n",
      "      19592 |   0.210325  |    0.027548     |   0\n",
      "      19593 |   0.051494  |    0.024513     |   2\n",
      "      19594 |   0.189711  |    0.052685     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 19596: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      19595 |   0.047153  |    0.016404     |   2\n",
      "      19596 |   0.186512  |    0.140215     |   1\n",
      "      19597 |   0.182187  |    0.002939     |   0\n",
      "      19598 |   0.054213  |    0.008412     |   2\n",
      "      19599 |   0.037413  |    0.029914     |   2\n",
      "      19600 |   0.178399  |    0.083242     |   1\n",
      "      19601 |   0.221508  |    0.140601     |   1\n",
      "      19602 |   0.147012  |    0.002878     |   0\n",
      "      19603 |   0.042501  |    0.003899     |   2\n",
      "      19604 |   0.048149  |    0.032049     |   2\n",
      "      19605 |   0.029879  |    0.030818     |   2\n",
      "      19606 |   0.043172  |    0.033768     |   2\n",
      "      19607 |   0.053149  |    0.010409     |   2\n",
      "      19608 |   0.203056  |    0.144838     |   1\n",
      "      19609 |   0.271516  |    0.007571     |   0\n",
      "      19610 |   0.174495  |    0.009054     |   0\n",
      "      19611 |   0.225133  |    0.136517     |   1\n",
      "      19612 |   0.057230  |    0.005187     |   2\n",
      "      19613 |   0.044935  |    0.007376     |   2\n",
      "      19614 |   0.024169  |    0.052135     |   2\n",
      "      19615 |   0.217570  |    0.085294     |   1\n",
      "      19616 | \u001b[94m  0.000028\u001b[0m  |    0.005251     |   2\n",
      "      19617 |   0.212603  |    0.030102     |   0\n",
      "      19618 |   0.005590  |    0.014135     |   2\n",
      "      19619 |   0.206130  |    0.103951     |   1\n",
      "      19620 |   0.185955  |    0.022671     |   0\n",
      "      19621 |   0.166435  |    0.031569     |   0\n",
      "      19622 |   0.069271  |    0.016212     |   2\n",
      "      19623 |   0.182716  |    0.039445     |   0\n",
      "      19624 |   0.162506  |    0.088960     |   1\n",
      "      19625 |   0.193071  |    0.049101     |   0\n",
      "      19626 |   0.265294  |    0.069012     |   1\n",
      "      19627 |   0.037863  |    0.008687     |   2\n",
      "      19628 |   0.248541  |    0.140811     |   1\n",
      "      19629 |   0.220213  |    0.008739     |   0\n",
      "      19630 |   0.225204  |    0.022481     |   0\n",
      "      19631 |   0.155237  |    0.138743     |   1\n",
      "      19632 |   0.059072  |    0.008278     |   2\n",
      "      19633 |   0.186507  |    0.017436     |   0\n",
      "      19634 |   0.259778  |    0.141823     |   1\n",
      "      19635 |   0.220958  |    0.009123     |   0\n",
      "      19636 |   0.160977  |    0.013895     |   0\n",
      "      19637 |   0.166204  |    0.043225     |   0\n",
      "      19638 |   0.045658  |    0.007440     |   2\n",
      "      19639 |   0.019358  |    0.042069     |   2\n",
      "      19640 |   0.238331  |    0.019312     |   0\n",
      "      19641 |   0.185180  |    0.146105     |   1\n",
      "      19642 |   0.166615  |    0.074257     |   1\n",
      "      19643 |   0.039674  |    0.006994     |   2\n",
      "      19644 |   0.155996  |    0.148907     |   1\n",
      "      19645 |   0.030934  |    0.011852     |   2\n",
      "      19646 |   0.180598  |    0.018982     |   0\n",
      "      19647 |   0.175790  |    0.090614     |   1\n",
      "      19648 |   0.000029  |    0.019002     |   2\n",
      "      19649 |   0.205464  |    0.152299     |   1\n",
      "      19650 |   0.193588  |    0.002932     |   0\n",
      "      19651 |   0.000028  |    0.006035     |   2\n",
      "      19652 |   0.193785  |    0.050787     |   0\n",
      "      19653 |   0.162099  |    0.026663     |   0\n",
      "      19654 |   0.000028  |    0.023415     |   2\n",
      "      19655 |   0.184700  |    0.032828     |   0\n",
      "      19656 |   0.205289  |    0.144919     |   1\n",
      "      19657 |   0.148232  |    0.005915     |   0\n",
      "      19658 |   0.190272  |    0.014529     |   0\n",
      "      19659 |   0.208202  |    0.050712     |   0\n",
      "      19660 |   0.000029  |    0.006633     |   2\n",
      "      19661 |   0.182930  |    0.149078     |   1\n",
      "      19662 |   0.195517  |    0.083311     |   1\n",
      "      19663 |   0.000029  |    0.004729     |   2\n",
      "      19664 |   0.000028  |    0.032829     |   2\n",
      "      19665 |   0.198329  |    0.159291     |   1\n",
      "      19666 |   0.051773  |    0.004454     |   2\n",
      "      19667 |   0.180944  |    0.092718     |   1\n",
      "      19668 |   0.047782  |    0.012186     |   2\n",
      "      19669 |   0.183807  |    0.045405     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 19670: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      19670 |   0.049911  |    0.012004     |   2\n",
      "      19671 |   0.163741  |    0.044073     |   0\n",
      "      19672 |   0.036583  |    0.014406     |   2\n",
      "      19673 |   0.288281  |    0.142026     |   1\n",
      "      19674 |   0.136628  |    0.072555     |   1\n",
      "      19675 |   0.041426  |    0.006403     |   2\n",
      "      19676 |   0.049912  |    0.067068     |   2\n",
      "      19677 |   0.184139  |    0.083918     |   1\n",
      "      19678 |   0.194884  |    0.013320     |   0\n",
      "      19679 |   0.204616  |    0.030272     |   0\n",
      "      19680 |   0.027744  |    0.014396     |   2\n",
      "      19681 |   0.211668  |    0.049807     |   0\n",
      "      19682 |   0.190081  |    0.021382     |   0\n",
      "      19683 |   0.040595  |    0.026400     |   2\n",
      "      19684 |   0.049325  |    0.029459     |   2\n",
      "      19685 |   0.215898  |    0.097952     |   1\n",
      "      19686 |   0.053507  |    0.011263     |   2\n",
      "      19687 |   0.046598  |    0.035236     |   2\n",
      "      19688 |   0.251935  |    0.094184     |   1\n",
      "      19689 |   0.164084  |    0.022612     |   0\n",
      "      19690 |   0.182185  |    0.134323     |   1\n",
      "      19691 |   0.023922  |    0.006296     |   2\n",
      "      19692 | \u001b[94m  0.000028\u001b[0m  |    0.042295     |   2\n",
      "      19693 |   0.221657  |    0.096902     |   1\n",
      "      19694 |   0.162359  |    0.023237     |   0\n",
      "      19695 |   0.006017  |    0.026411     |   2\n",
      "      19696 |   0.067237  |    0.026357     |   2\n",
      "      19697 |   0.248575  |    0.031431     |   0\n",
      "      19698 |   0.167832  |    0.037634     |   0\n",
      "      19699 |   0.159881  |    0.095006     |   1\n",
      "      19700 |   0.240723  |    0.012600     |   0\n",
      "      19701 |   0.036228  |    0.015545     |   2\n",
      "      19702 |   0.138617  |    0.034470     |   0\n",
      "      19703 |   0.126285  |    0.103479     |   1\n",
      "      19704 |   0.058618  |    0.018809     |   2\n",
      "      19705 |   0.196968  |    0.130538     |   1\n",
      "      19706 |   0.157998  |    0.103418     |   1\n",
      "      19707 |   0.185645  |    0.003080     |   0\n",
      "      19708 |   0.048587  |    0.017326     |   2\n",
      "      19709 |   0.178207  |    0.151020     |   1\n",
      "      19710 |   0.215268  |    0.047379     |   1\n",
      "      19711 |   0.018152  |    0.044822     |   2\n",
      "      19712 |   0.039126  |    0.007704     |   2\n",
      "      19713 |   0.255431  |    0.164549     |   1\n",
      "      19714 |   0.232040  |    0.037980     |   1\n",
      "      19715 |   0.031308  |    0.030280     |   2\n",
      "      19716 |   0.226761  |    0.148344     |   1\n",
      "      19717 |   0.000028  |    0.008613     |   2\n",
      "      19718 |   0.166360  |    0.090477     |   1\n",
      "      19719 |   0.151470  |    0.007865     |   0\n",
      "      19720 |   0.220819  |    0.099432     |   1\n",
      "      19721 | \u001b[94m  0.000028\u001b[0m  |    0.011231     |   2\n",
      "      19722 |   0.218491  |    0.132821     |   1\n",
      "      19723 |   0.189761  |    0.021520     |   0\n",
      "      19724 |   0.232866  |    0.100581     |   1\n",
      "      19725 |   0.220870  |    0.019703     |   0\n",
      "      19726 |   0.000028  |    0.042056     |   2\n",
      "      19727 |   0.000029  |    0.007122     |   2\n",
      "      19728 |   0.177270  |    0.045943     |   0\n",
      "      19729 |   0.213324  |    0.026002     |   0\n",
      "      19730 |   0.000029  |    0.036583     |   2\n",
      "      19731 |   0.232376  |    0.090447     |   1\n",
      "      19732 |   0.216272  |    0.087808     |   1\n",
      "      19733 |   0.000028  |    0.006521     |   2\n",
      "      19734 |   0.179702  |    0.051924     |   0\n",
      "      19735 |   0.047085  |    0.028598     |   2\n",
      "      19736 |   0.183599  |    0.136807     |   1\n",
      "      19737 |   0.045462  |    0.004154     |   2\n",
      "      19738 |   0.168928  |    0.022804     |   0\n",
      "      19739 |   0.262942  |    0.139986     |   1\n",
      "      19740 |   0.233479  |    0.013482     |   0\n",
      "      19741 |   0.177372  |    0.091135     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 19742: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      19742 |   0.180024  |    0.009106     |   0\n",
      "      19743 |   0.211042  |    0.060365     |   1\n",
      "      19744 |   0.213652  |    0.025699     |   0\n",
      "      19745 |   0.227463  |    0.090348     |   1\n",
      "      19746 |   0.195095  |    0.033685     |   0\n",
      "      19747 |   0.051640  |    0.024696     |   2\n",
      "      19748 |   0.231038  |    0.032243     |   0\n",
      "      19749 |   0.251872  |    0.142947     |   1\n",
      "      19750 |   0.184027  |    0.055545     |   1\n",
      "      19751 |   0.037179  |    0.006196     |   2\n",
      "      19752 |   0.041361  |    0.051207     |   2\n",
      "      19753 |   0.219967  |    0.084443     |   1\n",
      "      19754 |   0.047036  |    0.019192     |   2\n",
      "      19755 |   0.166946  |    0.124296     |   1\n",
      "      19756 |   0.163417  |    0.011281     |   0\n",
      "      19757 |   0.028434  |    0.058529     |   2\n",
      "      19758 |   0.187012  |    0.084174     |   1\n",
      "      19759 |   0.041515  |    0.018379     |   2\n",
      "      19760 |   0.161007  |    0.040753     |   0\n",
      "      19761 |   0.201265  |    0.016368     |   0\n",
      "      19762 |   0.170471  |    0.066321     |   0\n",
      "      19763 |   0.254128  |    0.081376     |   1\n",
      "      19764 |   0.207140  |    0.009937     |   0\n",
      "      19765 |   0.229981  |    0.032892     |   0\n",
      "      19766 |   0.179220  |    0.110492     |   1\n",
      "      19767 |   0.203207  |    0.094271     |   1\n",
      "      19768 |   0.051670  |    0.010856     |   2\n",
      "      19769 |   0.055599  |    0.032697     |   2\n",
      "      19770 |   0.048059  |    0.022047     |   2\n",
      "      19771 |   0.222009  |    0.144817     |   1\n",
      "      19772 |   0.025469  |    0.003774     |   2\n",
      "      19773 | \u001b[94m  0.000028\u001b[0m  |    0.024162     |   2\n",
      "      19774 |   0.178305  |    0.142186     |   1\n",
      "      19775 |   0.005709  |    0.005595     |   2\n",
      "      19776 |   0.259162  |    0.095252     |   1\n",
      "      19777 |   0.261219  |    0.083524     |   1\n",
      "      19778 |   0.067440  |    0.005608     |   2\n",
      "      19779 |   0.160066  |    0.045023     |   0\n",
      "      19780 |   0.172657  |    0.086282     |   1\n",
      "      19781 |   0.198683  |    0.009699     |   0\n",
      "      19782 |   0.034783  |    0.034108     |   2\n",
      "      19783 |   0.216038  |    0.090360     |   1\n",
      "      19784 |   0.158817  |    0.008307     |   0\n",
      "      19785 |   0.154701  |    0.029302     |   0\n",
      "      19786 |   0.198684  |    0.034572     |   0\n",
      "      19787 |   0.058128  |    0.011544     |   2\n",
      "      19788 |   0.170678  |    0.049443     |   0\n",
      "      19789 |   0.222847  |    0.037097     |   0\n",
      "      19790 |   0.149188  |    0.056429     |   1\n",
      "      19791 |   0.046015  |    0.011882     |   2\n",
      "      19792 |   0.156612  |    0.043305     |   0\n",
      "      19793 |   0.018999  |    0.029049     |   2\n",
      "      19794 |   0.204186  |    0.107685     |   1\n",
      "      19795 |   0.038323  |    0.010459     |   2\n",
      "      19796 |   0.032312  |    0.063673     |   2\n",
      "      19797 |   0.203922  |    0.074821     |   1\n",
      "      19798 |   0.000028  |    0.016203     |   2\n",
      "      19799 |   0.235106  |    0.156312     |   1\n",
      "      19800 |   0.000028  |    0.008412     |   2\n",
      "      19801 |   0.000028  |    0.010681     |   2\n",
      "      19802 |   0.000029  |    0.007547     |   2\n",
      "      19803 |   0.000029  |    0.031694     |   2\n",
      "      19804 |   0.000028  |    0.017393     |   2\n",
      "      19805 |   0.184038  |    0.029524     |   0\n",
      "      19806 |   0.181720  |    0.038552     |   0\n",
      "      19807 |   0.232531  |    0.111864     |   1\n",
      "      19808 |   0.217633  |    0.069984     |   1\n",
      "      19809 |   0.199213  |    0.018389     |   0\n",
      "      19810 |   0.209755  |    0.049342     |   0\n",
      "      19811 |   0.050770  |    0.011176     |   2\n",
      "      19812 |   0.046831  |    0.052540     |   2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 19813: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      19813 |   0.174778  |    0.058166     |   1\n",
      "      19814 |   0.234152  |    0.024748     |   0\n",
      "      19815 |   0.179521  |    0.029861     |   0\n",
      "      19816 |   0.176890  |    0.140495     |   1\n",
      "      19817 |   0.218476  |    0.004256     |   0\n",
      "      19818 |   0.198931  |    0.007841     |   0\n",
      "      19819 |   0.048238  |    0.045199     |   2\n",
      "      19820 |   0.322857  |    0.106127     |   1\n",
      "      19821 |   0.230659  |    0.086254     |   1\n",
      "      19822 |   0.037044  |    0.004785     |   2\n",
      "      19823 |   0.235761  |    0.049694     |   0\n",
      "      19824 |   0.039423  |    0.008031     |   2\n",
      "      19825 |   0.047599  |    0.034983     |   2\n",
      "      19826 |   0.177912  |    0.026350     |   0\n",
      "      19827 |   0.190407  |    0.033052     |   0\n",
      "      19828 |   0.028586  |    0.020019     |   2\n",
      "      19829 |   0.039569  |    0.028086     |   2\n",
      "      19830 |   0.203692  |    0.026564     |   0\n",
      "      19831 |   0.053136  |    0.034382     |   2\n",
      "      19832 |   0.233664  |    0.025690     |   0\n",
      "      19833 |   0.196319  |    0.036007     |   0\n",
      "      19834 |   0.056016  |    0.023176     |   2\n",
      "      19835 |   0.193538  |    0.154860     |   1\n",
      "      19836 |   0.207050  |    0.010967     |   0\n",
      "      19837 |   0.191896  |    0.012940     |   0\n",
      "      19838 |   0.236576  |    0.025059     |   0\n",
      "      19839 |   0.048276  |    0.031425     |   2\n",
      "      19840 |   0.206471  |    0.029211     |   0\n",
      "      19841 |   0.169756  |    0.033625     |   0\n",
      "      19842 |   0.229318  |    0.104179     |   1\n",
      "      19843 |   0.023469  |    0.007445     |   2\n",
      "      19844 |   0.247286  |    0.115642     |   1\n",
      "      19845 |   0.251337  |    0.088044     |   1\n",
      "      19846 |   0.176207  |    0.005791     |   0\n",
      "      19847 |   0.253928  |    0.053219     |   0\n",
      "      19848 |   0.197188  |    0.088641     |   1\n",
      "      19849 | \u001b[94m  0.000028\u001b[0m  |    0.006435     |   2\n",
      "      19850 |   0.213187  |    0.106656     |   1\n",
      "      19851 |   0.197518  |    0.128938     |   1\n",
      "      19852 |   0.004961  |    0.004157     |   2\n",
      "      19853 |   0.145941  |    0.013740     |   0\n",
      "      19854 |   0.066557  |    0.048745     |   2\n",
      "      19855 |   0.037571  |    0.016897     |   2\n",
      "      19856 |   0.167305  |    0.144559     |   1\n",
      "      19857 |   0.058280  |    0.008149     |   2\n",
      "      19858 |   0.042272  |    0.026641     |   2\n",
      "      19859 |   0.180179  |    0.139059     |   1\n",
      "      19860 |   0.020498  |    0.007318     |   2\n",
      "      19861 |   0.040293  |    0.042865     |   2\n",
      "      19862 |   0.031843  |    0.024151     |   2\n",
      "      19863 |   0.187353  |    0.051469     |   0\n",
      "      19864 |   0.000029  |    0.013421     |   2\n",
      "      19865 |   0.000028  |    0.034621     |   2\n",
      "      19866 |   0.173062  |    0.016961     |   0\n",
      "      19867 |   0.170054  |    0.132706     |   1\n",
      "      19868 |   0.180583  |    0.007586     |   0\n",
      "      19869 |   0.267106  |    0.093041     |   1\n",
      "      19870 |   0.175571  |    0.033069     |   0\n",
      "      19871 |   0.000028  |    0.026893     |   2\n",
      "      19872 |   0.196804  |    0.031985     |   0\n",
      "      19873 |   0.223583  |    0.090652     |   1\n",
      "      19874 |   0.196116  |    0.044026     |   0\n",
      "      19875 |   0.000029  |    0.021156     |   2\n",
      "      19876 |   0.273633  |    0.179911     |   1\n",
      "      19877 |   0.212702  |    0.012470     |   0\n",
      "      19878 |   0.223937  |    0.053590     |   1\n",
      "      19879 |   0.000029  |    0.018832     |   2\n",
      "      19880 |   0.184853  |    0.148759     |   1\n",
      "      19881 |   0.184035  |    0.002938     |   0\n",
      "      19882 |   0.183271  |    0.007308     |   0\n",
      "      19883 |   0.000028  |    0.042050     |   2\n",
      "      19884 |   0.049083  |    0.014602     |   2\n",
      "      19885 |   0.181485  |    0.056821     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 19887: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      19886 |   0.047205  |    0.007746     |   2\n",
      "      19887 |   0.282031  |    0.079428     |   1\n",
      "      19888 |   0.233336  |    0.131607     |   1\n",
      "      19889 |   0.162348  |    0.012284     |   0\n",
      "      19890 |   0.227579  |    0.055029     |   1\n",
      "      19891 |   0.047550  |    0.009936     |   2\n",
      "      19892 |   0.272208  |    0.147949     |   1\n",
      "      19893 |   0.195036  |    0.013703     |   0\n",
      "      19894 |   0.189663  |    0.098115     |   1\n",
      "      19895 |   0.192511  |    0.076613     |   1\n",
      "      19896 |   0.035966  |    0.014559     |   2\n",
      "      19897 |   0.040346  |    0.054217     |   2\n",
      "      19898 |   0.143418  |    0.102049     |   1\n",
      "      19899 |   0.193606  |    0.011645     |   0\n",
      "      19900 |   0.047917  |    0.020804     |   2\n",
      "      19901 |   0.028480  |    0.030434     |   2\n",
      "      19902 |   0.144366  |    0.018069     |   0\n",
      "      19903 |   0.176813  |    0.034434     |   0\n",
      "      19904 |   0.038878  |    0.013167     |   2\n",
      "      19905 |   0.183074  |    0.033884     |   0\n",
      "      19906 |   0.134508  |    0.137610     |   1\n",
      "      19907 |   0.244736  |    0.050341     |   1\n",
      "      19908 |   0.166053  |    0.018513     |   0\n",
      "      19909 |   0.174836  |    0.040956     |   0\n",
      "      19910 |   0.164372  |    0.096649     |   1\n",
      "      19911 |   0.196689  |    0.090452     |   1\n",
      "      19912 |   0.212920  |    0.023061     |   0\n",
      "      19913 |   0.207012  |    0.031599     |   0\n",
      "      19914 |   0.053530  |    0.010929     |   2\n",
      "      19915 |   0.054295  |    0.034836     |   2\n",
      "      19916 |   0.238202  |    0.133780     |   1\n",
      "      19917 |   0.245124  |    0.005273     |   0\n",
      "      19918 |   0.045577  |    0.005170     |   2\n",
      "      19919 |   0.182434  |    0.049214     |   0\n",
      "      19920 |   0.181726  |    0.009718     |   0\n",
      "      19921 |   0.022448  |    0.035275     |   2\n",
      "      19922 |   0.000028  |    0.006417     |   2\n",
      "      19923 |   0.207526  |    0.058291     |   0\n",
      "      19924 |   0.193609  |    0.127224     |   1\n",
      "      19925 |   0.005161  |    0.016215     |   2\n",
      "      19926 |   0.233190  |    0.090563     |   1\n",
      "      19927 |   0.187825  |    0.009759     |   0\n",
      "      19928 |   0.066965  |    0.018183     |   2\n",
      "      19929 |   0.153653  |    0.027019     |   0\n",
      "      19930 |   0.035973  |    0.034391     |   2\n",
      "      19931 |   0.059783  |    0.033943     |   2\n",
      "      19932 |   0.246405  |    0.094526     |   1\n",
      "      19933 |   0.130159  |    0.005911     |   0\n",
      "      19934 |   0.190807  |    0.017780     |   0\n",
      "      19935 |   0.042936  |    0.030389     |   2\n",
      "      19936 |   0.222181  |    0.033889     |   0\n",
      "      19937 |   0.229426  |    0.105088     |   1\n",
      "      19938 |   0.184844  |    0.097521     |   1\n",
      "      19939 |   0.186207  |    0.094797     |   1\n",
      "      19940 |   0.019235  |    0.006192     |   2\n",
      "      19941 |   0.038148  |    0.053201     |   2\n",
      "      19942 |   0.029095  |    0.015368     |   2\n",
      "      19943 |   0.240908  |    0.035326     |   0\n",
      "      19944 |   0.000029  |    0.021924     |   2\n",
      "      19945 |   0.000028  |    0.046646     |   2\n",
      "      19946 |   0.225584  |    0.089289     |   1\n",
      "      19947 |   0.184662  |    0.020768     |   0\n",
      "      19948 |   0.000029  |    0.029602     |   2\n",
      "      19949 |   0.000029  |    0.025243     |   2\n",
      "      19950 |   0.000029  |    0.025584     |   2\n",
      "      19951 |   0.190939  |    0.042080     |   0\n",
      "      19952 |   0.000029  |    0.007593     |   2\n",
      "      19953 |   0.197344  |    0.047558     |   0\n",
      "      19954 |   0.252308  |    0.009225     |   0\n",
      "      19955 |   0.206817  |    0.161577     |   1\n",
      "      19956 |   0.194063  |    0.012215     |   0\n",
      "      19957 |   0.049992  |    0.005614     |   2\n",
      "      19958 |   0.046865  |    0.035597     |   2\n",
      "      19959 |   0.211928  |    0.086917     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 19961: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      19960 |   0.181181  |    0.014458     |   0\n",
      "      19961 |   0.166081  |    0.024748     |   0\n",
      "      19962 |   0.185944  |    0.071663     |   0\n",
      "      19963 |   0.204332  |    0.086944     |   1\n",
      "      19964 |   0.218982  |    0.081699     |   1\n",
      "      19965 |   0.044893  |    0.016517     |   2\n",
      "      19966 |   0.257041  |    0.147513     |   1\n",
      "      19967 |   0.033597  |    0.017224     |   2\n",
      "      19968 |   0.224823  |    0.079868     |   1\n",
      "      19969 |   0.259010  |    0.007614     |   0\n",
      "      19970 |   0.040165  |    0.018009     |   2\n",
      "      19971 |   0.223002  |    0.036960     |   0\n",
      "      19972 |   0.047553  |    0.009332     |   2\n",
      "      19973 |   0.199050  |    0.054000     |   0\n",
      "      19974 |   0.248534  |    0.101956     |   1\n",
      "      19975 |   0.159309  |    0.089822     |   1\n",
      "      19976 |   0.201982  |    0.025459     |   0\n",
      "      19977 |   0.201775  |    0.052493     |   0\n",
      "      19978 |   0.208420  |    0.091088     |   1\n",
      "      19979 |   0.228774  |    0.083435     |   1\n",
      "      19980 |   0.184182  |    0.019675     |   0\n",
      "      19981 |   0.168694  |    0.051509     |   0\n",
      "      19982 |   0.208598  |    0.136612     |   1\n",
      "      19983 |   0.029811  |    0.004915     |   2\n",
      "      19984 |   0.213383  |    0.011846     |   0\n",
      "      19985 |   0.181815  |    0.040555     |   0\n",
      "      19986 |   0.157757  |    0.134520     |   1\n",
      "      19987 |   0.207099  |    0.032643     |   1\n",
      "      19988 |   0.158756  |    0.031245     |   0\n",
      "      19989 |   0.216234  |    0.035257     |   0\n",
      "      19990 |   0.040901  |    0.017063     |   2\n",
      "      19991 |   0.162959  |    0.019570     |   0\n",
      "      19992 |   0.139020  |    0.044423     |   0\n",
      "      19993 |   0.160258  |    0.081151     |   1\n",
      "      19994 |   0.057380  |    0.026734     |   2\n",
      "      19995 |   0.174531  |    0.030583     |   0\n",
      "      19996 |   0.166139  |    0.029848     |   0\n",
      "      19997 |   0.220645  |    0.113389     |   1\n",
      "      19998 |   0.057784  |    0.010124     |   2\n",
      "      19999 |   0.181230  |    0.162592     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 20000: Saving params.\n",
      "INFO:neuralnilm.trainer:Done saving params.\n",
      "INFO:neuralnilm.trainer:Iteration 20000: Plotting estimates.\n",
      "Exception in thread neuralnilm-data-process:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 810, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/dk3810/workspace/python/neuralnilm/neuralnilm/data/datathread.py\", line 16, in run\n",
      "    batch = self.data_pipeline.get_batch(**self._get_batch_kwargs)\n",
      "  File \"/home/dk3810/workspace/python/neuralnilm/neuralnilm/data/datapipeline.py\", line 46, in get_batch\n",
      "    batch = self._source_iterators[source_id].next()\n",
      "ValueError: generator already executing\n",
      "\n",
      "INFO:neuralnilm.trainer:Done plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      20000 |   0.197754  |    0.006156     |   0\n",
      "      20001 |   0.186256  |    0.055682     |   0\n",
      "      20002 |   0.053959  |    0.007798     |   2\n",
      "      20003 |   0.037501  |    0.042118     |   2\n",
      "      20004 |   0.225121  |    0.028558     |   0\n",
      "      20005 |   0.040204  |    0.045360     |   2\n",
      "      20006 |   0.148167  |    0.104183     |   1\n",
      "      20007 |   0.195014  |    0.103706     |   1\n",
      "      20008 |   0.223096  |    0.075423     |   1\n",
      "      20009 |   0.043708  |    0.008231     |   2\n",
      "      20010 |   0.028607  |    0.045381     |   2\n",
      "      20011 |   0.151944  |    0.017433     |   0\n",
      "      20012 |   0.207229  |    0.034186     |   0\n",
      "      20013 |   0.039520  |    0.013783     |   2\n",
      "      20014 |   0.271586  |    0.136199     |   1\n",
      "      20015 |   0.278690  |    0.075450     |   1\n",
      "      20016 |   0.210486  |    0.018561     |   0\n",
      "      20017 |   0.184683  |    0.044615     |   0\n",
      "      20018 |   0.253412  |    0.095006     |   1\n",
      "      20019 |   0.050701  |    0.017628     |   2\n",
      "      20020 |   0.254643  |    0.085230     |   1\n",
      "      20021 |   0.054416  |    0.006549     |   2\n",
      "      20022 |   0.045548  |    0.019895     |   2\n",
      "      20023 |   0.148153  |    0.029228     |   0\n",
      "      20024 |   0.021791  |    0.019089     |   2\n",
      "      20025 |   0.000029  |    0.062871     |   2\n",
      "      20026 |   0.237131  |    0.081446     |   1\n",
      "      20027 |   0.179526  |    0.010725     |   0\n",
      "      20028 |   0.005450  |    0.050050     |   2\n",
      "      20029 |   0.220032  |    0.012057     |   0\n",
      "      20030 |   0.152242  |    0.048748     |   0\n",
      "      20031 |   0.207837  |    0.086567     |   1\n",
      "      20032 |   0.153775  |    0.132649     |   1\n",
      "      20033 |   0.198193  |    0.013543     |   0\n",
      "      20034 |   0.270348  |    0.063189     |   1\n",
      "      20035 |   0.149085  |    0.008419     |   0\n",
      "      20036 |   0.251762  |    0.042399     |   0\n",
      "      20037 |   0.168205  |    0.019688     |   0\n",
      "      20038 |   0.224027  |    0.047959     |   0\n",
      "      20039 |   0.065632  |    0.008221     |   2\n",
      "      20040 |   0.210417  |    0.043901     |   0\n",
      "      20041 |   0.183530  |    0.013165     |   0\n",
      "      20042 |   0.034831  |    0.045510     |   2\n",
      "      20043 |   0.160386  |    0.009845     |   0\n",
      "      20044 |   0.183074  |    0.048066     |   0\n",
      "      20045 |   0.171225  |    0.140623     |   1\n",
      "      20046 |   0.241942  |    0.002914     |   0\n",
      "      20047 |   0.058558  |    0.010311     |   2\n",
      "      20048 |   0.166810  |    0.135613     |   1\n",
      "      20049 |   0.045183  |    0.005363     |   2\n",
      "      20050 |   0.019608  |    0.025320     |   2\n",
      "      20051 |   0.183153  |    0.137813     |   1\n",
      "      20052 |   0.162515  |    0.109704     |   1\n",
      "      20053 |   0.160789  |    0.085752     |   1\n",
      "      20054 |   0.043880  |    0.005739     |   2\n",
      "      20055 |   0.152612  |    0.050212     |   0\n",
      "      20056 |   0.028270  |    0.005978     |   2\n",
      "      20057 |   0.164213  |    0.045755     |   0\n",
      "      20058 |   0.000029  |    0.011633     |   2\n",
      "      20059 |   0.219644  |    0.054398     |   0\n",
      "      20060 |   0.000028  |    0.004577     |   2\n",
      "      20061 |   0.237396  |    0.055357     |   0\n",
      "      20062 |   0.000029  |    0.014962     |   2\n",
      "      20063 |   0.160189  |    0.148976     |   1\n",
      "      20064 |   0.167969  |    0.010091     |   0\n",
      "      20065 |   0.206243  |    0.006703     |   0\n",
      "      20066 |   0.234611  |    0.048416     |   0\n",
      "      20067 |   0.000029  |    0.008107     |   2\n",
      "      20068 |   0.172894  |    0.031894     |   0\n",
      "      20069 |   0.220455  |    0.037459     |   0\n",
      "      20070 |   0.000029  |    0.029600     |   2\n",
      "      20071 |   0.200043  |    0.123478     |   1\n",
      "      20072 |   0.168703  |    0.003170     |   0\n",
      "      20073 |   0.000029  |    0.008638     |   2\n",
      "      20074 |   0.281791  |    0.139335     |   1\n",
      "      20075 |   0.056720  |    0.006335     |   2\n",
      "      20076 |   0.179529  |    0.054726     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 20078: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      20077 |   0.047526  |    0.015998     |   2\n",
      "      20078 |   0.161493  |    0.110576     |   1\n",
      "      20079 |   0.262322  |    0.057404     |   1\n",
      "      20080 |   0.255524  |    0.082414     |   1\n",
      "      20081 |   0.051431  |    0.045988     |   2\n",
      "      20082 |   0.174513  |    0.017818     |   0\n",
      "      20083 |   0.035850  |    0.012200     |   2\n",
      "      20084 |   0.173349  |    0.051880     |   0\n",
      "      20085 |   0.181581  |    0.067144     |   1\n",
      "      20086 |   0.205421  |    0.109247     |   1\n",
      "      20087 |   0.209804  |    0.072955     |   1\n",
      "      20088 |   0.222911  |    0.079097     |   1\n",
      "      20089 |   0.188629  |    0.068583     |   1\n",
      "      20090 |   0.226041  |    0.107516     |   1\n",
      "      20091 |   0.197564  |    0.043514     |   1\n",
      "      20092 |   0.037926  |    0.008927     |   2\n",
      "      20093 |   0.045672  |    0.033902     |   2\n",
      "      20094 |   0.248963  |    0.137890     |   1\n",
      "      20095 |   0.028705  |    0.010642     |   2\n",
      "      20096 |   0.177235  |    0.075082     |   1\n",
      "      20097 |   0.190101  |    0.033559     |   0\n",
      "      20098 |   0.038490  |    0.027867     |   2\n",
      "      20099 |   0.173255  |    0.032323     |   0\n",
      "      20100 |   0.225026  |    0.118885     |   1\n",
      "      20101 |   0.200005  |    0.078138     |   1\n",
      "      20102 |   0.297202  |    0.091250     |   1\n",
      "      20103 |   0.048566  |    0.003811     |   2\n",
      "      20104 |   0.155192  |    0.033208     |   0\n",
      "      20105 |   0.140177  |    0.032982     |   0\n",
      "      20106 |   0.294973  |    0.084422     |   1\n",
      "      20107 |   0.155570  |    0.020671     |   0\n",
      "      20108 |   0.274209  |    0.033348     |   0\n",
      "      20109 |   0.056204  |    0.014248     |   2\n",
      "      20110 |   0.222108  |    0.131537     |   1\n",
      "      20111 |   0.046588  |    0.005104     |   2\n",
      "      20112 |   0.024086  |    0.029867     |   2\n",
      "      20113 |   0.148610  |    0.033964     |   0\n",
      "      20114 |   0.000029  |    0.015708     |   2\n",
      "      20115 |   0.005534  |    0.024580     |   2\n",
      "      20116 |   0.279529  |    0.044648     |   0\n",
      "      20117 |   0.177006  |    0.012378     |   0\n",
      "      20118 |   0.160329  |    0.049050     |   0\n",
      "      20119 |   0.197694  |    0.098514     |   1\n",
      "      20120 |   0.065843  |    0.011130     |   2\n",
      "      20121 |   0.197274  |    0.151399     |   1\n",
      "      20122 |   0.158091  |    0.002996     |   0\n",
      "      20123 |   0.034033  |    0.005980     |   2\n",
      "      20124 |   0.260845  |    0.044757     |   0\n",
      "      20125 |   0.176709  |    0.023281     |   0\n",
      "      20126 |   0.212047  |    0.098195     |   1\n",
      "      20127 |   0.055033  |    0.013605     |   2\n",
      "      20128 |   0.260898  |    0.144976     |   1\n",
      "      20129 |   0.176315  |    0.014769     |   0\n",
      "      20130 |   0.225003  |    0.081113     |   1\n",
      "      20131 |   0.244549  |    0.009238     |   0\n",
      "      20132 |   0.214352  |    0.050316     |   0\n",
      "      20133 |   0.236690  |    0.084773     |   1\n",
      "      20134 |   0.266388  |    0.098128     |   1\n",
      "      20135 |   0.186703  |    0.129343     |   1\n",
      "      20136 |   0.042866  |    0.002979     |   2\n",
      "      20137 |   0.214485  |    0.005796     |   0\n",
      "      20138 |   0.181905  |    0.044629     |   0\n",
      "      20139 |   0.019490  |    0.009462     |   2\n",
      "      20140 |   0.248373  |    0.050316     |   0\n",
      "      20141 |   0.156259  |    0.135815     |   1\n",
      "      20142 |   0.202405  |    0.003430     |   0\n",
      "      20143 |   0.038870  |    0.005276     |   2\n",
      "      20144 |   0.169255  |    0.053228     |   0\n",
      "      20145 |   0.192992  |    0.026935     |   0\n",
      "      20146 |   0.228018  |    0.154394     |   1\n",
      "      20147 |   0.029644  |    0.002974     |   2\n",
      "      20148 |   0.000028  |    0.012110     |   2\n",
      "      20149 |   0.335301  |    0.143542     |   1\n",
      "      20150 |   0.199218  |    0.003144     |   0\n",
      "      20151 |   0.212268  |    0.009864     |   0\n",
      "      20152 |   0.240710  |    0.137091     |   1\n",
      "      20153 |   0.140148  |    0.016986     |   0\n",
      "      20154 |   0.218567  |    0.094683     |   1\n",
      "      20155 |   0.000028  |    0.012741     |   2\n",
      "      20156 |   0.239567  |    0.026348     |   0\n",
      "      20157 |   0.000028  |    0.048141     |   2\n",
      "      20158 |   0.204350  |    0.137933     |   1\n",
      "      20159 |   0.000029  |    0.004627     |   2\n",
      "      20160 |   0.000029  |    0.013890     |   2\n",
      "      20161 |   0.185580  |    0.153408     |   1\n",
      "      20162 |   0.210624  |    0.049330     |   1\n",
      "      20163 |   0.180789  |    0.014646     |   0\n",
      "      20164 |   0.230042  |    0.047869     |   0\n",
      "      20165 |   0.240869  |    0.086581     |   1\n",
      "      20166 |   0.223580  |    0.019239     |   0\n",
      "      20167 |   0.000028  |    0.057354     |   2\n",
      "      20168 |   0.227313  |    0.078693     |   1\n",
      "      20169 |   0.181019  |    0.081340     |   1\n",
      "      20170 |   0.187459  |    0.149002     |   1\n",
      "      20171 |   0.052236  |    0.014399     |   2\n",
      "      20172 |   0.137471  |    0.090299     |   1\n",
      "      20173 |   0.187775  |    0.012105     |   0\n",
      "      20174 |   0.244135  |    0.154538     |   1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 20176: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      20175 |   0.046896  |    0.012457     |   2\n",
      "      20176 |   0.192155  |    0.046096     |   1\n",
      "      20177 |   0.048215  |    0.035199     |   2\n",
      "      20178 |   0.165777  |    0.089414     |   1\n",
      "      20179 |   0.213301  |    0.014405     |   0\n",
      "      20180 |   0.216193  |    0.136476     |   1\n",
      "      20181 |   0.035940  |    0.007468     |   2\n",
      "      20182 |   0.202484  |    0.034704     |   0\n",
      "      20183 |   0.205099  |    0.064602     |   1\n",
      "      20184 |   0.239531  |    0.044522     |   0\n",
      "      20185 |   0.040515  |    0.008005     |   2\n",
      "      20186 |   0.128130  |    0.022457     |   0\n",
      "      20187 |   0.157219  |    0.147441     |   1\n",
      "      20188 |   0.045749  |    0.012336     |   2\n",
      "      20189 |   0.172912  |    0.084923     |   1\n",
      "      20190 |   0.173204  |    0.093061     |   1\n",
      "      20191 |   0.028371  |    0.013642     |   2\n",
      "      20192 |   0.036582  |    0.046281     |   2\n",
      "      20193 |   0.171980  |    0.015099     |   0\n",
      "      20194 |   0.049702  |    0.037516     |   2\n",
      "      20195 |   0.203071  |    0.012856     |   0\n",
      "      20196 |   0.054035  |    0.039663     |   2\n",
      "      20197 |   0.044649  |    0.021813     |   2\n",
      "      20198 |   0.024458  |    0.036507     |   2\n",
      "      20199 |   0.183448  |    0.107271     |   1\n",
      "      20200 | \u001b[94m  0.000028\u001b[0m  |    0.011488     |   2\n",
      "      20201 |   0.209499  |    0.045428     |   0\n",
      "      20202 |   0.204948  |    0.082558     |   1\n",
      "      20203 |   0.182264  |    0.017222     |   0\n",
      "      20204 |   0.005934  |    0.032628     |   2\n",
      "      20205 |   0.068796  |    0.033881     |   2\n",
      "      20206 |   0.175150  |    0.016678     |   0\n",
      "      20207 |   0.036614  |    0.023974     |   2\n",
      "      20208 |   0.161018  |    0.146303     |   1\n",
      "      20209 |   0.227526  |    0.083956     |   1\n",
      "      20210 |   0.180892  |    0.004093     |   0\n",
      "      20211 |   0.056361  |    0.019221     |   2\n",
      "      20212 |   0.163086  |    0.119132     |   1\n",
      "      20213 |   0.047832  |    0.006300     |   2\n",
      "      20214 |   0.020683  |    0.007492     |   2\n",
      "      20215 |   0.039670  |    0.045737     |   2\n",
      "      20216 |   0.252330  |    0.016706     |   0\n",
      "      20217 |   0.157639  |    0.141093     |   1\n",
      "      20218 |   0.184715  |    0.013369     |   0\n",
      "      20219 |   0.199504  |    0.113244     |   1\n",
      "      20220 |   0.207995  |    0.092497     |   1\n",
      "      20221 |   0.211039  |    0.091490     |   1\n",
      "      20222 |   0.188470  |    0.011388     |   0\n",
      "      20223 |   0.207064  |    0.139355     |   1\n",
      "      20224 |   0.119250  |    0.006660     |   0\n",
      "      20225 |   0.190439  |    0.151546     |   1\n",
      "      20226 |   0.204520  |    0.054052     |   1\n",
      "      20227 |   0.169145  |    0.024697     |   0\n",
      "      20228 |   0.214034  |    0.031579     |   0\n",
      "      20229 |   0.221528  |    0.035441     |   0\n",
      "      20230 |   0.237825  |    0.145969     |   1\n",
      "      20231 |   0.171138  |    0.086579     |   1\n",
      "      20232 |   0.200923  |    0.072647     |   1\n",
      "      20233 |   0.152304  |    0.076914     |   1\n",
      "      20234 |   0.027151  |    0.014734     |   2\n",
      "      20235 |   0.173591  |    0.136796     |   1\n",
      "      20236 |   0.150089  |    0.004043     |   0\n",
      "      20237 |   0.000028  |    0.029551     |   2\n",
      "      20238 |   0.198326  |    0.051782     |   0\n",
      "      20239 | \u001b[94m  0.000027\u001b[0m  |    0.014199     |   2\n",
      "      20240 |   0.241778  |    0.149819     |   1\n",
      "      20241 |   0.000027  |    0.002901     |   2\n",
      "      20242 |   0.196916  |    0.009016     |   0\n",
      "      20243 |   0.000028  |    0.043571     |   2\n",
      "      20244 |   0.202570  |    0.089107     |   1\n",
      "      20245 |   0.211319  |    0.031492     |   0\n",
      "      20246 |   0.261250  |    0.048310     |   0\n",
      "      20247 |   0.206362  |    0.086160     |   1\n",
      "      20248 |   0.164289  |    0.013353     |   0\n",
      "      20249 |   0.000028  |    0.027193     |   2\n",
      "      20250 |   0.000027  |    0.041916     |   2\n",
      "      20251 |   0.228642  |    0.014753     |   0\n",
      "      20252 |   0.054093  |    0.043399     |   2\n",
      "      20253 |   0.153640  |    0.015820     |   0\n",
      "      20254 |   0.231958  |    0.160726     |   1\n",
      "      20255 |   0.141475  |    0.056018     |   1\n",
      "      20256 |   0.166004  |    0.102179     |   1\n",
      "      20257 |   0.184885  |    0.008270     |   0\n",
      "      20258 |   0.149332  |    0.014642     |   0\n",
      "      20259 |   0.207645  |    0.065757     |   0\n",
      "      20260 |   0.295739  |    0.103563     |   1\n",
      "      20261 |   0.152603  |    0.012450     |   0\n",
      "      20262 |   0.211934  |    0.054837     |   1\n",
      "      20263 |   0.214852  |    0.135585     |   1\n",
      "      20264 |   0.045952  |    0.008365     |   2\n",
      "      20265 |   0.227217  |    0.084554     |   1\n",
      "      20266 |   0.246153  |    0.025947     |   0\n",
      "      20267 |   0.187994  |    0.021997     |   0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neuralnilm.trainer:Iteration 20268: Finished training epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      20268 |   0.190946  |    0.043746     |   0\n",
      "      20269 |   0.181803  |    0.026680     |   0\n",
      "      20270 |   0.273150  |    0.094663     |   1\n",
      "      20271 |   0.244734  |    0.105353     |   1\n",
      "      20272 |   0.050047  |    0.016564     |   2\n",
      "      20273 |   0.037252  |    0.032833     |   2\n",
      "      20274 |   0.129885  |    0.010452     |   0\n",
      "      20275 |   0.039847  |    0.045829     |   2\n",
      "      20276 |   0.164420  |    0.018364     |   0\n",
      "      20277 |   0.250874  |    0.152828     |   1\n",
      "      20278 |   0.135659  |    0.014748     |   0\n",
      "      20279 |   0.246845  |    0.085833     |   1\n",
      "      20280 |   0.227081  |    0.101589     |   1\n",
      "      20281 |   0.236107  |    0.022723     |   0\n",
      "      20282 |   0.168427  |    0.145199     |   1\n",
      "      20283 |   0.224794  |    0.090901     |   1\n",
      "      20284 |   0.047746  |    0.011712     |   2\n",
      "      20285 |   0.155747  |    0.007305     |   0\n",
      "      20286 |   0.266412  |    0.045511     |   0\n",
      "      20287 |   0.029935  |    0.021653     |   2\n",
      "      20288 |   0.169825  |    0.148374     |   1\n",
      "      20289 |   0.202237  |    0.054649     |   1\n",
      "      20290 |   0.036241  |    0.022036     |   2\n",
      "      20291 |   0.179726  |    0.140301     |   1\n",
      "      20292 |   0.154621  |    0.015045     |   0\n",
      "      20293 |   0.166543  |    0.079693     |   1\n",
      "      20294 |   0.190941  |    0.044611     |   0\n",
      "      20295 |   0.191080  |    0.085485     |   1\n",
      "      20296 |   0.187676  |    0.014271     |   0\n",
      "      20297 |   0.170049  |    0.137918     |   1\n",
      "      20298 |   0.053928  |    0.007694     |   2\n",
      "      20299 |   0.053504  |    0.043839     |   2\n",
      "      20300 |   0.157879  |    0.137257     |   1\n",
      "      20301 |   0.186686  |    0.002968     |   0\n",
      "      20302 |   0.205823  |    0.016008     |   0\n",
      "      20303 |   0.045668  |    0.062120     |   2\n",
      "      20304 |   0.155011  |    0.097721     |   1\n",
      "      20305 |   0.147854  |    0.007881     |   0\n",
      "      20306 |   0.022597  |    0.057432     |   2\n",
      "      20307 | \u001b[94m  0.000027\u001b[0m  |    0.008402     |   2\n",
      "      20308 |   0.005689  |    0.031952     |   2\n",
      "      20309 |   0.068889  |    0.052088     |   2\n",
      "      20310 |   0.036580  |    0.012693     |   2\n",
      "      20311 |   0.171279  |    0.041504     |   0"
     ]
    }
   ],
   "source": [
    "trainer.fit(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.train_iterations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
